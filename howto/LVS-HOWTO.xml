<?xml version="1.0"?>
<!DOCTYPE article PUBLIC "-//OASIS//DTD Docbook XML V4.1.2//EN"
"/usr/local/share/sgml/docbook/xml-dtd-4.1.2/docbookx.dtd">
<article>
	<articleinfo>
	<title>LVS-HOWTO</title>
	<author>
        	<firstname>Joseph</firstname>
        	<surname>Mack</surname>
        	<affiliation>
                	<orgname>jmack (at) wm7d (dot) net </orgname>
                	<orgdiv></orgdiv>
        	</affiliation>
	</author>
	<pubdate>v2009.09 Sep 2009, released under GPL.</pubdate>
	<copyright>
        	<year>1999</year>
        	<year>2000</year>
        	<year>2001</year>
        	<year>2002</year>
        	<year>2003</year>
        	<year>2004</year>
        	<year>2005</year>
        	<year>2006</year>
        	<year>2007</year>
        	<year>2008</year>
        	<year>2009</year>
        	<holder>Joseph Mack</holder>
	</copyright>
	<abstract>
	<para>
Install, testing and running of a Linux Virtual Server with 2.2.x, 2.4.x, 2.6.x kernels
	</para>
	<para>
<emphasis role="bold">search the LVS documentation</emphasis>
	</para>
	<itemizedlist>
		<listitem>
<ulink url="http://www.austintek.com/LVS/htdig/search/search.html">
search the LVS documenation</ulink> with htdig.
		</listitem>
		<listitem>
<ulink url="http://www.linuxvirtualserver.org/mailing.html">
search the various mailing list archives</ulink>
		</listitem>
	</itemizedlist>
	<para>
Hank Leninger's searchable mailing list archive has moved.
It's now at <ulink url="http://marc.info/?l=linux-virtual-server&amp;w=2">
http://marc.info/?l=linux-virtual-server&amp;w=2</ulink>.
	</para>
	</abstract>
	</articleinfo>
<section id="LVS-HOWTO.introduction" xreflabel="LVS Introduction">
<title>LVS: Introduction</title>
<para>
This LVS-HOWTO is posted to the LVS-HOWTO homepage,
<ulink url="http://www.austintek.com/LVS/LVS-HOWTO/">
http://www.austintek.com/LVS/LVS-HOWTO/
</ulink> about once a month (although I do miss occasional months).
</para>
<para>
Some of the material is from my own testing and I've tried to make
it into a coherent story.
Much of the material is from the lvs-users mailing list
and is listed chronologically 
(sometimes forward and sometimes backwards in time)
and will thus look like a blog.
</para>
	<section id="thanks">
	<title>Thanks</title>
	<para>
Contributions to this HOWTO came from the mailing list and are
attibuted to the poster (with e-mail address). Postings may have
been edited to fit into the flow of the HOWTO.
	</para>
	<para>
The LVS logo (Tux with 3 lighter shaded penguins behind him
representing a director and 3 realservers) is by Mike Douglas <emphasis>spike (at) bayside (dot) net</emphasis>
	</para>
	<para>
<ulink url="http://www.linuxvirtualserver.org">LVS homepage</ulink> is running on
a machine donated by Horms. (Until Jul 2002, we used a machine donated by Voxel).
	</para>
	<para>
<ulink url="http://www.linuxvirtualserver.org">LVS mailing list</ulink> is hosted by
Lars in Germany <emphasis>lmb (at) suse (dot) de</emphasis>
	</para>
	</section>
	<section id="about">
	<title>About the HOWTO</title>
		<section id="purpose"><title>Purpose</title>
		<para>
To enable you to understand how a Linux Virtual Server (LVS) works.
		</para>
		<para id="mini-HOWTO">
The
<ulink url="http://www.austintek.com/LVS/LVS-HOWTO/mini-HOWTO/LVS-mini-HOWTO.html">LVS-mini-HOWTO</ulink>
(http://www.austintek.com/LVS/LVS-HOWTO/mini-HOWTO/LVS-mini-HOWTO.html)
tells you how to setup and install an LVS without understanding how the LVS works.
		</para>
		<para>
The material here covers directors and realservers with 2.2, 2.4 and 2.6 kernels.
		</para>
		<note>
		<para>
The original material was written for 2.2.x kernels and ipchains. Not
all material has been updated for 2.4.x kernels and iptables.
		</para>
		</note>
		<para>
The layout of this HOWTO is almost flat -
you go to the section you want information on.
You aren't supposed to read it from start to finish.
Within any section, newer information may be combined
with older information that says different things.
I just don't have time to edit everything - I'll
be glad if you straighten me out.
The only information one level up is
		</para>
		<itemizedlist>
			<listitem>
how LVS works
(from <link linkend="LVS-HOWTO.what_is_an_LVS">this HOWTO</link> or
from documentation on the website, <emphasis>e.g.</emphasis>
Wensong's early documents)
			</listitem>
			<listitem>
setting up an LVS in the
<link linkend="mini-HOWTO">LVS-mini-HOWTO.html</link>.
			</listitem>
		</itemizedlist>
		<para>
The code for 2.0.x kernels still works fine and was used on production
systems when 2.0.x kernels were current, but is not being developed further.
For 2.2 kernels, the Linux kernel networking code was rewritten,
producing for us <xref linkend="LVS-HOWTO.arp_problem"/>.
This changes the installation of LVS from a simple
process that can be done by almost anyone,
to a thought provoking, head scratching exercise,
which requires detailed understanding of the workings of LVS.
For 2.0 and 2.2, LVS is stand-alone code, based on ip_masquerading and
doesn't integrate well with other uses of ip_masquerading.
For 2.4 kernels, LVS was rewritten as much as possible to be a netfilter module, 
to allow it to fit into and be visible to other netfilter modules.
Unfortunately the fit isn't perfect, but cooperation with netfilter does work in most cases.
If ip_vs() was a real netfilter module, it would be really slow.
(The original LVS-NAT code had problems when using your director as a firewall;
see the <xref linkend="LVS-HOWTO.filter_rules"/>, but much of this has been fixed - Feb 2006.)
Being a netfilter module, the latency and throughput are slightly worse
for 2.4 LVS than for the 2.2 code.
However with modern CPUs being running at 800MHz,
the bottleneck now is network throughput rather than LVS throughput
(you only need a small number of realservers to saturate 100Mbps ethernet).
		</para>
		<para>
In general <command>ipvsadm</command> commands and services have not changed between kernels.
		</para>
		</section>
		<section id="source_xml">
		<title>HOWTO source is xml</title>
		<para>
The HOWTO was originally written in sgml. It is now xml.
The char '&amp;' found in C source code
has to be written as &amp;amp; in sgml.
If you swiped patches from the sgml rather than the html rendering,
you would get code that needed to be edited to fix the &amp;.
Now that the HOWTO is in xml, this munging is not needed.
Although I've tried to remove all munged ampersands,
I expect some will persist for a while.
Ampersands in URLs still have to be munged.
		</para>
		</section>
		<section id="e-mail">
		<title>e-mail addresses in the HOWTO are spam protected</title>
		<para>
Well we hope so anyhow.
		</para>
		<para>
An article on <ulink url="http://www.neilgunton.com/spambot_trap/">spambots</ulink>
describes robots which ignore the robots.txt file and scan for e-mail addresses
in readable files on websites.
The author suggests removing any 'mailto:' strings and spam protecting e-mail addresses,
by changing them from machine-readable to human-readable format.
If you have a better scheme than implemented here, (and I can do it with vi) let me know.
		</para>
		<para>
(May 2002): BTW, 160 people have contributed to the HOWTO
(as judged by unique e-mail addresses).
		</para>
		</section>
		<section id="links">
		<title>Links die frequently</title>
		<para>
There are links to 180 urls in this HOWTO (May 2002),
which came from postings to the LVS mailing list.
If people move/rename/delete/change their webpages/links once a year,
then I'm going to have to trackdown 15 websites each month.
If a site is gone and it isn't in google, I'm not going to be able to find it.
		</para>
		</section>
	</section>
	<section id="nomenclature">
	<title>Nomenclature/Abbreviations</title>
	<para>
If you use these terms when you mail us, we'll know what you're talking about.
	</para>
		<section id="preferred_names">
		<title>Preferred names</title>
		<itemizedlist>
			<listitem>
<emphasis>IPVS,ipvs,ip_vs</emphasis>
the code that patches the linux kernel on the <emphasis>director</emphasis>.
			</listitem>
			<listitem>
<emphasis>LVS, linux virtual server</emphasis>
This is the <emphasis>director</emphasis> + <emphasis>realservers</emphasis>.
Together these machines are the <emphasis>virtual server</emphasis>,
which appears as one machine to the <emphasis>client(s)</emphasis>.
			</listitem>
			<listitem>
<emphasis>director</emphasis>: the node that runs the <emphasis>ipvs</emphasis> code.
<emphasis>Clients</emphasis> <emphasis>connect</emphasis> to the <emphasis>director</emphasis>.
The <emphasis>director</emphasis> <emphasis>forwards</emphasis> packets to the realservers.
The <emphasis>director</emphasis> is nothing but an IP router with special rules
that make the <emphasis>LVS</emphasis> work.
			</listitem>
			<listitem>
<emphasis>realservers</emphasis>: the hosts that have the <emphasis>services</emphasis>.
The <emphasis>realservers</emphasis> handle the requests from the clients.
			</listitem>
			<listitem>
<emphasis>client</emphasis> the host or user level process that connects to the <emphasis>VIP</emphasis>
on the <emphasis>director</emphasis>
			</listitem>
			<listitem>
<emphasis>forwarding method</emphasis>
(currently <xref linkend="LVS-HOWTO.LVS-NAT"/>,
<xref linkend="LVS-HOWTO.LVS-DR"/>,
<xref linkend="LVS-HOWTO.LVS-Tun"/>).
The <emphasis>director</emphasis>
is a router with somewhat different rules for forwarding
packets than a normal router.
The <emphasis>forwarding method</emphasis>
determines how the <emphasis>director</emphasis>
sends packets from the <emphasis>client</emphasis>
to the <emphasis>realservers</emphasis>.
			</listitem>
			<listitem>
<emphasis>scheduling</emphasis> (<xref linkend="LVS-HOWTO.ipvsadm"/>) -
the algorithm the <emphasis>director</emphasis> uses to select a
<emphasis>realserver</emphasis> to service a new connection request
from a <emphasis>client</emphasis>.
			</listitem>
		</itemizedlist>
		</section>
		<section id="synonyms">
		<title>synonyms</title>
		<para>
Please use the first term in these lines. The other words are valid but
less precise (or are redundant).
		</para>
		<itemizedlist>
			<listitem>
<emphasis>director</emphasis>: load balancer, dispatcher, redirector.
			</listitem>
			<listitem>
<emphasis>realserver</emphasis>: servers, realservers, real-servers.
			</listitem>
			<listitem>
<emphasis>LVS</emphasis>: the whole cluster, the (linux) virtual server (LVS)
			</listitem>
		</itemizedlist>
		</section>
		<section id="virtual_services">
		<title>virtual services, scheduling groups</title>
		<para>
Here's the <command>ipvsadm</command> output of an LVS serving telnet and squid.
		</para>
<programlisting><![CDATA[
director:/etc/rc.d# ipvsadm
IP Virtual Server version 0.9.4 (size=4096)
Prot LocalAddress:Port Scheduler Flags
  -> RemoteAddress:Port           Forward Weight ActiveConn InActConn
TCP  lvs.mack.net:squid rr
  -> rs1.mack.net:squid        Route   1      0          0
  -> rs2.mack.net:squid        Route   1      0          0
  -> rs3.mack.net:squid        Route   1      0          0
TCP  lvs.mack.net:telnet rr
  -> rs1.mack.net:telnet       Route   1      0          0
  -> rs2.mack.net:telnet       Route   1      0          0
]]></programlisting>
		<para>
In the above LVS, there are two
<emphasis>virtual services</emphasis>, telnet and squid.
There are also two <emphasis>virtual servers</emphasis>;
a <emphasis>virtual server</emphasis> for telnet (which has 2 realservers)
and a <emphasis>virtual server</emphasis> for squid (which has 3 realservers).
This is what the client sees; two services (and two servers).
		</para>
		<para>
Connections to each
<emphasis>virtual server</emphasis> are <emphasis>scheduled</emphasis> (here by "rr", round robin),
to the realservers which belong to the <emphasis>scheduling group</emphasis>.
Here the <emphasis>scheduling group</emphasis> for telnet is rs1,rs2.
The <emphasis>scheduling group</emphasis> for quid is rs1,rs2,rs3.
Connections to the telnet <emphasis>virtual server</emphasis> are scheduled independantly
of connections to the squid <emphasis>virtual server</emphasis>.
		</para>
		<para>
The above nomenclature can be extended for <xref linkend="LVS-HOWTO.fwmark"/>.
		</para>
		</section>
		<section id="scheduled_unit">
		<title>scheduling instance, scheduled unit, virtual connection</title>
		<para>
We don't have a good name for this. Suggestions welcome.
(We also don't talk much about this concept on the mailing list,
so we've done without a name).
		</para>
		<para>
The director needs to know how to schedule packets from the client to
the realservers.
The smallest unit for LVS is a tcpip connection,
<emphasis>i.e.</emphasis> all
packets that are part of a single tcpip session from a client
will be sent to the same realserver.
For a tcp virtual service, each tcp connection is scheduled separately,
with the first tcp connection going to one realserver,
and the next tcp connection going to the next realserver
assigned a connection from the scheduler.
The <emphasis>virtual connection</emphasis> is the same as the tcp connection.
		</para>
		<para>
For a <xref linkend="LVS-HOWTO.persistent_connection"/>
all tcp connections that are separated by less than the timeout period
are regarded as belonging to the same <emphasis>virtual connection</emphasis> and
are scheduled to the same realserver.
		</para>
		<para>
For udp, there is no such thing as a connection or session and
all packets from the client within a timeout period are scheduled to the
same realserver. (People aren't using LVS for udp services a whole lot).
The <emphasis>virtual connection</emphasis> then is all udp packets from a client
within a certain time period.
		</para>
		</section>
		<section id="multi-tier_servers">
		<title>backend (multi-tier) servers</title>
		<para>
The <emphasis>realservers</emphasis> sometimes are frontends
to other <emphasis>backend</emphasis> servers.
The <emphasis>client</emphasis> does not connect
to these <emphasis>backend</emphasis> servers
and they are not in the <command>ipvsadm</command> table.
		</para>
		<para>
<emphasis>e.g.</emphasis>
		</para>
		<itemizedlist>
			<listitem>
a <emphasis>realserver</emphasis> may run a web application.
The web application in turn connects to a database
on another <emphasis>backend</emphasis> server.
			</listitem>
			<listitem>
a webcaching <emphasis>realserver</emphasis> (<emphasis>e.g.</emphasis> a squid).
The squid connects to <emphasis>backend</emphasis> webserver(s).
			</listitem>
		</itemizedlist>
		<para>
These <emphasis>backend</emphasis> servers are setup separately from the LVS.
		</para>
		</section>
		<section id="server_ambiguous"><title>the term "the server" is ambiguous</title>
		<para>
People sometimes call the <emphasis>director</emphasis> or the <emphasis>realservers</emphasis>,
"the server".
Since the whole LVS appears as a server to the <emphasis>client</emphasis>
and since the <emphasis>realservers</emphasis> are also serving services,
the term "server" is ambiguous.
Do not use the term "the server" or "the lvs server" when talking about LVS.
Most often you are referring to the "director" or the "realservers".
Sometimes (<emphasis>e.g.</emphasis> when talking about throughput)
you are talking about the (whole) virtual server.
		</para>
		<para>
I use "realserver" as I despair of finding a reference to a "realserver"
in a webpage using the search keys "real" and "server".
Horms and I (for reasons that neither of us can remember) have been
pushing the term "real-server" for about a year, on the mailing list,
and no-one has adopted it. We're going back to "realserver".
		</para>
		</section>
		<section id="names_of_IPs">
		<title>names of IPs/networks in an LVS</title>
		<para id="lvs-diagram">
		</para>
<programlisting><![CDATA[
                        ________
                       |        |
                       | client | (local or on internet)
                       |________|
                          CIP
                           |
--                      (router)
                          DGW
                           | outside network
                           |
L                         VIP
i                      ____|_____
n                     |          | (director can have 1 or 2 NICs)
u                     | director |
x                     |__________|
                      DIP (and PIP)
V                          |
i                          | DRIP network
r         ----------------------------------
t         |                |               |
u         |                |               |
a        RIP1             RIP2            RIP3
l    _____________   _____________   _____________
    |             | |             | |             |
S   | realserver1 | | realserver2 | | realserver3 |
e   |_____________| |_____________| |_____________|
r
v
e
r
---
]]></programlisting>
<para>
The router has traditionally not been considered part of the LVS, because
often you do not have control over the router. However if you're a paying
customer, then the ISP will be glad to set up the router according to
your specifications. If you have access to the router, it can solve
<xref linkend="LVS-HOWTO.arp_problem"/> and can install filter rules.
</para>
<para>
Here are the names we use for the various IPs.
If you use them when asking questions on the mailing list,
we'll be able to answer your questions more easily.
</para>
<programlisting><![CDATA[
client IP     = CIP
virtual IP    = VIP - the IP on the director that the client connects to)
director IP   = DIP - the IP on the director in the DIP/RIP (DRIP) network
   (this is the realserver gateway for LVS-NAT)
realserver IP = RIP (and RIP1, RIP2...) the IP on the realserver
director GW   = DGW - the director's gw (only needed for LVS-NAT)
   (this can be the realserver gateway for LVS-DR and LVS-Tun)
]]></programlisting>
		<para>
The VIP and DIP are setup as secondary IPs,
(<emphasis>i.e.</emphasis>
there is another primary IP on that NIC),
so they can be moved to another duplicate director
following director failover.
For initial setup with a single director,
setting up the VIP and DIP as secondary IPs will make the
transition to a failover setup easier.
		</para>
		<para>
For a two director LVS (where directors failover),
the IPs on the <link linkend="drip">DRIP network</link> are
		</para>
<programlisting><![CDATA[
primary director IP	= PIP (the director which will be the master on bootup)
secondary director IP	= SIP (the director which will be the backup on bootup)
]]></programlisting>
		<para>
The DIP will be on the same NIC as PIP on bootup and will move to the
same NIC as SIP on director failover.
		</para>
		<para>
We don't seem to need a name for the primary IP on the outside of the director
- no-one ever talks about it.
		</para>
		<para>
We don't often need to explicitely name the networks in an LVS, but
here's some suggestions
		</para>
		<itemizedlist>
			<listitem>
				<para id="drip">
<emphasis role="bold">DRIP network</emphasis>: the network containing the DIP
and RIPs. (OK you come up with a better name.)
				</para>
			</listitem>
			<listitem>
				<para>
<emphasis role="bold">network facing the internet</emphasis>
or the <emphasis role="bold">outside network</emphasis>: the network
on the director which receives packets from the outside world.
This shouldn't be called the VIP network,
as the VIP is also in the DRIP network (but not replying to arp calls)
on the realservers in LVS-DR and LVS-Tun.
				</para>
			</listitem>
		</itemizedlist>
		</section>
	</section>
	<section id="minimal_knowledge">
	<title>Minimal knowledge required</title>
	<para>
The mailing list and HOWTOs cover information specific to LVS.
The rest you have to handle yourself.
All of us knew nothing about computers when we first started,
we learnt it, and you can too (we're not saying it's easy).
If you can't setup a simple LVS from the
<link linkend="mini-HOWTO">LVS-mini-HOWTO</link>,
without breaking into a major sweat
(or being able to tell us what's wrong with the instructions),
then you need to do some more homework.
(Also see 
<ulink url="http://www.austintek.com/LVS/LVS-HOWTO/mini-HOWTO/#doesnt_work">Help! My LVS doesn't work</ulink>.)
	</para>
	<blockquote>
	<para>
Ratz <emphasis>ratz (at) tac (dot) ch</emphasis>
	</para>
	<para>
To be able to setup/maintain an LVS, you need to be able to
	</para>

	<itemizedlist>
		<listitem>
know how to patch and compile a kernel
		</listitem>
		<listitem>
the basics of shell-scripting
		</listitem>
		<listitem>
have intermediate knowledge of TCP/IP
		</listitem>
		<listitem>
have read the man-page, the online-documentation and LVS-HOWTO (this document)
(and the
<link linkend="mini-HOWTO">LVS-mini-HOWTO</link>)
		</listitem>
		<listitem>
know basic system administration (<emphasis>e.g.</emphasis> iptables; syslog; find, compile,
install code from source files; use cpan to find perl modules).
		</listitem>
	</itemizedlist>
	</blockquote>
	</section>
	<section id="getting_technical_help">
	<title>Free Technical Help</title>
	<para>
All of the people on the LVS mailing list are replying for free in 
their spare time. The best we can do is to give 
solutions to technical problems on setting up and running 
LVS. I give about 15secs to a posting to decide if I've got 
something useful to say. The posting has to indicate that 
the person has analysed the problem to a stage where an 
answer exists. If _they_ can't describe the problem, 
there's no point in replying - they won't understand the answer.
	</para>
	<para>
Please don't e-mail me privately with general questions
(feel free to cc: me if you want).
The mailing list will archive your question
and the answer(s) which can be retrieved later.
Other people may have more interesting,
relevant or useful comments than I will.
If you are writing to me in the hopes of avoiding the humiliation
of publically showing your ignorance on the mailing list, it's not going to happen.
We've had too many good ideas from "ignorant" people to let this happen.
If your question has been answered many times before 
and it's in the HOWTO and the archives,
you'll be told to read the HOWTO, that's all.
	</para>
	<para>
To get technical help:
	</para>
	<itemizedlist>
		<listitem> 
Read the docs on the website, the HOWTOs, and search the mailing list archives. 
The HOWTO (at the top) has a link to a search engine of all known LVS documentation. 
It will probably return several webpages.
You'll have to find the entry from there.
		</listitem>
		<listitem> The
<link linkend="mini-HOWTO">
LVS-mini-HOWTO</link>
shows you how to setup a simple 3 node (client, director, realserver)
LVS without you needing to understand a whole lot about how an LVS works.
		</listitem>
		<listitem>
after you've done a search of the docs, then post to the mailing list.
		</listitem>
		<listitem> updates/problems/bugs - post to the mailing list 
		</listitem>
	</itemizedlist>
	<para>
Jakub Suchy <emphasis>jakub (at) rtfm (dot) cz</emphasis> 13 Jan 2005
	</para>
	<para>
Please read:
<ulink url="http://www.catb.org/~esr/faqs/smart-questions.html">smart questions</ulink>
(http://www.catb.org/~esr/faqs/smart-questions.html)
before asking questions.
	</para>
	<para>
Please only post relevant lines of a debug dump.
If you post the whole dump, because you don't understand it,
then it will fill up the archive machine and everyone's mail box. 
If we need the whole debug, we'll ask for it and you can send it to us off-list.
	</para>
		<section id="problem_people_1">
		<title>Problem people 1</title>
		<para>
It's hard to believe, but we get postings like
		</para>
		<blockquote>
recompiling the kernel is hard (or I don't read HOWTOs),
can't you guys cut me some slack and just tell me what to do?
		</blockquote>
		<para>
I expect the people who post these statements don't read this HOWTO,
so I may be wasting my time, but - No.
The people on the mailing list answer questions for free,
and have other important things to do, like keeping up with /. 
and checking our e-mail.
When we're at home, we drink beer and watch Gilligan's Island re-runs.
		</para>
		</section>
		<section id="problem_people_2">
		<title>Problem people 2</title>
		<blockquote>
can anybody tell me how to setup a windows realserver?
thank you very much! I'm in a  hurry.
		</blockquote>
		<para>
<emphasis>robert (dot) gehr (at) web2cad (dot) de</emphasis>
		</para>
		<para>
I can't think of anyone who has set up lvs in a hurry :-)
		</para>
		</section>
		<section id="RedHat">
		<title>Problem People 3: People using RedHat LVS</title>
		<para>
RedHat have LVS in their standard distribution kernel.
This gives people the idea that they can setup
LVS from their standard RedHat distribution just by clicking on a few
buttons or running some scripts.
From reading the postings to the mailing list,
it's more difficult than doing it our way.
You still have to understand LVS and then afterwards,
you have to figure out what RedHat did to it.
One of the major wastes of time
and source of aggravation for me personally on the LVS mailing list,
is postings from people using RedHat LVS who assume that it's the same as LVS,
and who post as if they're using our setup methods.
Just saying that you're using a RedHat distribution doesn't tell us anything,
since you can setup LVS our way in RedHat.
Things you need to know before you post -
		</para>
		<itemizedlist>
			<listitem>
There are reasons for wanting to setup LVS in a standard RedHat distribution
(<emphasis>e.g.</emphasis> RedHat is "approved" in your location whereas "Linux" isn't).
			</listitem>
			<listitem>
There is information in this HOWTO (<xref linkend="pbs_nutshell"/>)
and in the various links from here which show you how to setup RedHat LVS.
			</listitem>
			<listitem>
We have a method of setting up LVS which works for all distributions (including RedHat).
We are not interested in learning, understanding, debugging, supporting or fixing
a setup method that only works for one distibution.
			</listitem>
			<listitem>
RedHat don't talk to us about what they do and while
they may monitor the LVS mailing list,
rarely (only about once a year, that I can tell)
do they reply to people having problems with RedHat LVS.
It appears that RedHat does not think their version of LVS worthy of much support
and I agree with them.
			</listitem>
			<listitem>
If you setup LVS the RedHat way,
you still need an understanding
of how an LVS works and is setup (just like everyone else),
before posting to the mailing list.
			</listitem>
		</itemizedlist>
		<para>
If you are setting up with RedHat and want help with it,
make sure that you describe what you've done,
that you're using the RedHat files and how you've set it up,
otherwise we'll assume that you're setting up using our methods.
		</para>
		</section>
		<section id="why_you_may_not_get_an_answer">
		<title>Why you may not get an answer</title>
		<itemizedlist>
			<listitem>
				<para>
no-one knows.
				</para> 
				<para>
The <xref linkend="LVS-NAT_ftp_bug"/> took a long time to figure out. 
Since no-one else had seen the problem, we didn't know at first if it was a problem with LVS. 
It wasn't till 6 months later, when someone else had the same symptom,
and found that it only occured when the ftp helper module was loaded, 
that we could do something.
				</para>
				<para>
I once needed to do something with <filename>iproute2</filename> 
that I spent about 3 weeks trying to figure out. 
No-one on the list knew the answer. 
I had to post off-line to someone who could figure it out for me.
				</para>
			</listitem>
			<listitem>
				<para>
We may not have a useful answer.
				</para>
				<para>
If you post saying "I want to build an LVS with (list of hardware);
do you think it will work?", all we can say is "probably".
				</para>
				<para>
Often when questions like this come up, 
there are people who are happy to share their experiences, 
so there's no harm in posting such a question.
In general the people who've been working with LVS for years will expect 
you to have read the docs and know what LVS does before you post. 
In the time I alot for a reply, 
I don't have time to figure out whether in your case LVS is best for you 
- you should pay a consultant to do this if you can't do it yourself.
				</para>
			</listitem>
			<listitem>
				<para>
Your question may not be well posed.
				</para>
				<para>
We are reading the postings in our spare time. 
You will get at most 30secs of attention before we figure out whether 
we can help you, an answer will take a bit of thinking, or we can't help you.
				</para>
				<para>
If you have a long posting in which you haven't figured out which parts
are causing the problem and which parts are working, then we aren't
going to try to figure it out either. 
Post the minimum setup that will produce the problem.
				</para>
			</listitem>
			<listitem>
It's obvious that you haven't read the HOWTO.
			</listitem>
		</itemizedlist>
		</section>
		<section id="edit_posts">
		<title>Edit your posts! (top, bottom and in-line posting)</title>
		<para>
Please edit the posting you're replying to, leaving only the parts relevant to your reply.
We don't need to see material from previous posts irrelevant to the current posting,
and the disk archive doesn't either.
		</para>
		<para>
Reply in-line, <emphasis>i.e.</emphasis> following each statement by the poster.
Here's a posting on the subject from one of the kernel mailing lists.
		</para>
		<para>
Greg KH <emphasis>greg (at) kroah (dot) com</emphasis> 16 Nov 2005 
		</para>
<programlisting><![CDATA[
A: http://en.wikipedia.org/wiki/Top_post
Q: Were do I find info about this thing called top-posting?
A: Because it messes up the order in which people normally read text.
Q: Why is top-posting such a bad thing?
A: Top-posting.
Q: What is the most annoying thing in e-mail?
A: No.
Q: Should I include quotations after my reply?
]]></programlisting>
		</section>
	</section>
	<section id="after_youve_got_help">
	<title>After you've Got Technical Help</title>
	<para>
In most cases when a problem is solved, there's enough info on the mailing list
to see how it worked and we can write it up here for the next people. 
Occasionally, we get a posting "I've worked it out. Thanks for the help."
When this happens we have no idea what the solution was 
and will have to reinvent it for the next person.
	</para>
	<para>
If you've got help from the unpaid people on the mailing list, 
who've given their spare time to help you, 
when they could instead have been watching Gilligan's Island reruns, 
please write it up for the HOWTO. 
When I write to people asking for their solution
I don't want to hear that you're busy and have a job. 
We're busy, have jobs, kids, homework to do and tax forms to fill in 
and we stopped what we were doing to help you. 
Here's a template.
	</para>
	<itemizedlist>
		<listitem>
what you wanted to do
		</listitem>
		<listitem>
why/how it didn't work
		</listitem>
		<listitem>
what you needed to do to get it to work
		</listitem>
		<listitem>
how the solution works
		</listitem>
	</itemizedlist>
	</section>
	<section id="paid_technical_help">
	<title>Paid technical help</title>
	<note>
		<para>
We occasionally get requests for people to do an install.
The listing is a service to people looking for paid technical help 
(installs or anything else)
and does not imply that I (Joe) or anyone connected
to the LVS project endorse the services of the listees.
If you want to know more about them, 
check their postings to the LVS mailing list.
		</para>
		<para>
Entries will be listed at no cost, in approximate order of the date I receive/post them. 
Entries will be listed for at least a year 
(HOWTOs come out at erratic intervals and new entries will be added/old entries 
deleted whenever the next HOWTO comes out). 
If you want to be listed again next year, send me an e-mail in a year. 
I'm too busy to keep much of an eye on what goes in here
and your entry may stay longer than a year.
If you really want people to know who you are, 
don't rely on this entry - make sure google knows about you.
		</para>
		<para>
To be listed, send me off-list
		</para>
		<blockquote>
your URL (<emphasis>e.g.</emphasis> &lt;http://www.foo.org&gt;The Foo LVS service centre&lt;/a&gt;) 
and/or e-mail, then a blurb of upto 80chars <emphasis>e.g.</emphasis> "We do it all", 
optionally including your location.
		</blockquote>
		<para>
this will be minimum maintenance - I'm just going to mouse swipe your e-mail 
(<emphasis>i.e.</emphasis> don't plan on changing your URL in the year).
		</para>
		</note>
	<para>
People available for paid technical help.
	</para>
	<itemizedlist>
		<listitem>
			<para>
Oct 2007: http://www.dotnoc.com - solutions for hosting sales@dotnoc.com. Linux load balancing and networking specialists
			</para>
		</listitem>
		<listitem>
			<para>
Oct 2007: Loadbalancer.org Ltd (http://www.loadbalancer.org/) - Specialise in high
availability load balancers based on LVS. Happy for customers to have full
access to the OS and source code and offer 24*7 support. However we don't do
consultancy on home brew implementations. UK and USA offices.
			</para>
		</listitem>
		<listitem>
			<para>
Oct 2007: http://www.netdigix.com Linux solutions for business.
contact@netdigix.com.
We specialize in Linux networking and setup of LVS for hosting and mission
critical infrastructures.
Canada:British Columbia:Lower Mainland:Vancouver
			</para>
		</listitem>
	</itemizedlist>
	</section>
	<section id="subscribing">
	<title>Mailing list: subscribing, unsubscribing, searching </title>
	<para>
Thanks to Hank Leininger for the mailing list archive which is searchable not
only by subject and author, but also by strings in the body.
Hank's resource has been of great help in assembling this HOWTO.
	</para>
	<para>
The <ulink url="http://www.linuxvirtualserver.org/mailing.html">mailing list</ulink>
is available for further questions.
A single mailing list handles developers, new
users and old users and has about 0-20 postings a day.
You don't have to join the mailing list to read the archives.
If you want to post questions, then you have to join.
If you aren't subscribed and you post (or you post from
an unsubscribed address),
you'll get a reply saying that your posting is
"awaiting moderator approval".
It isn't; because of the volume of spam,
we no longer review these messages - they're deleted.
	</para>
	</section>
	<section id="problem_report">
	<title>
	Mailing list: posting to
	</title>
	<para>
Please send e-mail with straight ascii (not html)
and turn line-wrap on (some mails come with each
paragraph on a single long line).
	</para>
	<para>
If you're stuck with posting from a Windows machine
or Lotus notes, or using Lookout, 
where each paragraph is sent as one line: 
	</para>
	<blockquote>
		<para>
Francois JEANMOUGIN <emphasis>Francois (dot) JEANMOUGIN (at) 123multimedia (dot) com</emphasis> 09 Jul 2004
		</para>
<programlisting><![CDATA[
System manager -> Global Settings -> Internet Message Format -> Default (or
the one used) -> Advanced -> word wrap 
]]></programlisting>
		<para>
like shown in
<ulink url="http://www.lemis.com/email/fixing-outlook.html">
fixing outlook</ulink>
(http://www.lemis.com/email/fixing-outlook.html)
especially in
<ulink url="http://www.lemis.com/email/exchsrvr-wordwrap.gif">
word wrap</ulink>
(http://www.lemis.com/email/exchsrvr-wordwrap.gif),
but this is a very old version of exchange.
		</para>
	</blockquote>
	<para>
Please don't turn on your vacation message, intended only for your work mates,
for messages from a list.
<emphasis>e.g.</emphasis>
	</para>
<programlisting><![CDATA[
I will be out of the office starting  07/30/2004 and will not return until 08/03/2004.
]]></programlisting>
	<para>
The LVS mailing list doesn't want to know.
	</para>
	<para>
Dan Moljar Aug 2004
	</para>
	<para>
For Lotus Notes:
The client is not configured correctly.
In the 'Out of Office' enable dialog under the 'Exceptions' tab, 
there is a check box for 'Do not reply to Internet Addresses'. 
Check it.
The server shouldn't do it to begin with, 
but you can make the client stop.
	</para>
	<para>
There's always new ideas and questions being posted on the mailing list.
We don't expect this to stop.
There are many complexities to LVS and we don't expect
new people to understand any more about LVS that we did when we started.
No-one is expected to know/understand everything
in the docs but your questions will be better received,
if you've done your homework,
if you have setup the test configurations here,
have at least perused this HOWTO (yes we know it's big),
and have looked at the
<ulink url="http://www.linuxvirtualserver.org/mailing.html">mail archives</ulink>.
We can't help you if you just tell us that you've read the documents and your LVS
doesn't work.
To you, all problems look the same ("it doesn't work").
To help you, we need more information.
We at least need the forwarding method,
the service(s) being forwarded, the number of networks
and the output of ipvsadm in the problem state.
	</para>
	<para>
Before you come up on the mailing list -
	</para>
	<itemizedlist>
		<listitem>
Read the LVS-HOWTO (this document) and the
<link linkend="mini-HOWTO">LVS-mini-HOWTO</link>
		</listitem>
		<listitem>
		<para>
Set up a simple LVS (3 nodes: client, director, realserver)
with LVS-DR or LVS-NAT forwarding,
with the service telnet using the instructions in the LVS-mini-HOWTO.
You should be able to do this starting from a
freshly downloaded kernel from ftp.kernel.org and the LVS patches
(ipvs and the hidden patch if you have 2.4.x realservers).
		</para>
		<para>
<emphasis role="bold">Don't</emphasis> 
setup first with http, with filter rules, with firewalls, with complicated
file systems (<emphasis>e.g.</emphasis> coda, nfs) or network accelators
- debug all these nifty things after you have LVS working with telnet
and with no filter rules.
		</para>
		<para>
<emphasis role="bold">Do</emphasis> use standard compilers (gcc-2.95.3), tools
and utilities (<command>ifconfig</command> or <filename>iproute2</filename>).
		</para>
		<para>
<emphasis role="bold">Do not</emphasis> use non-standard tools particular to a distribution
designed to capture market share (<emphasis>e.g.</emphasis> <command>ifup</command>).
		</para>
		</listitem>
		<listitem>
If you are using one of the packages that can be used with LVS
(<emphasis>e.g.</emphasis>
heartbeat from the Linux HA project http://www.henge.com/&#126;alanr/ha,
or piranha from Redhat),
again we may know what the problem is,
but they need the feedback that you can't get it to work, not us.
Many of us are on each others'
mailing lists and we try to help when we can,
but the best people to handle the problem are the developers for each package.
		</listitem>
		<listitem>
Consult the
<ulink url="http://marc.theaimsgroup.com/?l=linux-virtual-server&amp;r=1&amp;w=2">
LVS mailing list archives</ulink>.
		</listitem>
		<listitem>
Use our jargon as best you can.
The machine names will be client, director, realserver1, realserver2...
IPs are CIP, VIP, RIP, DIP.
If you do this,
we won't have to translate "susanne" and "annie" to their
functional names as we scan your posting.
		</listitem>
		<listitem>
we need to know your kernel
(<emphasis>e.g.</emphasis> 2.2.14)
and the ip_vs patch that was applied to it (eg 0.9.11),
whether you are using LVS-DR, LVS-NAT or LVS-Tun.
Tell us
		<itemizedlist>
			<listitem>
what you did
			</listitem>
			<listitem>
what you expected
			</listitem>
			<listitem>
what you got and why that's a problem
			</listitem>
		</itemizedlist>
		</listitem>
	</itemizedlist>
	<para>
If you don't understand your problem well,
here's a suggested submission format from Roberto Nibali
<emphasis>ratz (at) tac (dot) ch</emphasis>
	</para>
	<orderedlist>
		<listitem>
System information, such as kernel, tools and their versions.
		<para>
Example:
		</para>

<programlisting><![CDATA[
hog:~ # uname -a
Linux hog 2.2.18 #2 Sun Dec 24 15:27:49 CET 2000 i686 unknown

hog:~ # <command>ipvsadm</command> -L -n | head -1
IP Virtual Server version 1.0.2 (size=4096)

hog:~ # <command>ipvsadm</command> -h | head -1
<command>ipvsadm</command> v1.13 2000/12/17 (compiled with popt and IPVS v1.0.2)
]]></programlisting>
		</listitem>
		<listitem>
Short description and maybe sketch of what you intended to setup.
		<para>
Example for LVS-DR:
		</para>

<programlisting><![CDATA[
	o Using LVS-DR, gatewaying method.
	o Load balancing port 80 (http) non-persistent.
	o Network Setup:

                        ________
                       |        |
                       | client |
                       |________|
			   | CIP
                           |
			(router)
			   |
			   | GEP
                 (packetfilter, firewall)
                           | GIP
                           |       __________
                           |  DIP |          |
                           +------+ director |
                           |  VIP |__________|
                           |
         +-----------------+----------------+
         |                 |                |
     RIP1, VIP         RIP2, VIP        RIP3, VIP
    ____________      ____________    ____________
   |            |    |            |  |            |
   |realserver1 |    |realserver2 |  |realserver3 |
   |____________|    |____________|  |____________|


	CIP  = 212.23.34.83
	GEP  = 81.23.10.2	(external gateway, eth0)
	GIP  = 192.168.1.1	(internal gateway, eth1, masq or NAT)
	DIP  = 192.168.1.2	(eth0:1, or eth1:1)
	VIP1 = 192.168.1.110	(director: eth0:110, realserver: lo0:110)
	RIP1 = 192.168.1.11
	RIP2 = 192.168.1.12
	RIP3 = 192.168.1.13
	DGW  = 192.168.1.1	(GIP for all realserver)

	o ipvsadm -L -n

hog:~ # ipvsadm -L -n
IP Virtual Server version 1.0.2 (size=4096)
Prot LocalAddress:Port Scheduler Flags
  -> RemoteAddress:Port          Forward Weight ActiveConn InActConn
TCP  192.168.1.10:80 wlc
  -> 192.168.1.13:80             Route   0      0          0
  -> 192.168.1.12:80             Route   0      0          0
  -> 192.168.1.11:80             Route   0      0          0
]]></programlisting>
		<para>
The output from ifconfig from all machines (abbreviated, just need the
IP, netmask etc), and the output from netstat -rn.
		</para>
		</listitem>

		<listitem>
What doesn't work.
Show some output from
<command>tcpdump</command>,
<command>ipchains</command>/<command>ip_tables</command>,
<command>ipvsadm</command> and
<filename>kernlog</filename>.
Later we may ask you for a more detailed configuration like routing table,
OS-version or interface setup on some machines used in your setup.
Tell us what you expected. Example:

<programlisting><![CDATA[
ipchains -L -M -n (2.2.x) or cat /proc/net/ip_conntrack (2.4.x)
echo 9 > /proc/sys/net/ipv4/vs/debug_level && tail -f /var/log/kernlog
tcpdump -n -e -i eth0 tcp port 80
route -n
netstat -an
ifconfig -a
]]></programlisting>
		<para>
<command>tcpdump</command> listings are difficult to read.
If you post one, please change the IPs to VIP, CIP, RIP1..n, DIP etc.
Since you'll likely be on a switched network, <command>tcpdump</command>
will only see packets to that NIC. Tell us which machine (director, realserver...)
and the NIC (if there are two NICs on the machine) that it was run on.
		</para>
		</listitem>
	</orderedlist>
	</section>
	<section id="bug_fixes">
	<title>Bug Fixes</title>
	<para>
It's wonderful to get an unsolicited bug fix.
Please let us know what it does and why it's better than the current file.
A new version of a file without any information about what it does,
or what it fixes isn't much use to us.
	</para>
	</section>
	<section id="other_solutions">
	<title>Other load balancing solutions, GPL, opensource and commercial</title>
		<section id="open_source_solutions">
		<title>Open Source and GPL solutions</title>
		<para>
Malcolm <emphasis>lists (at) loadbalancer (dot) org</emphasis> 23 Nov 2006 
		</para>
		<para>
Willy Tarreau's written a nice article 
<ulink url="http://1wt.eu/articles/2006_lb/">
http://1wt.eu/articles/2006_lb/ - Making applications scalable with Load Balancing</ulink>
on load balancing that covers layer 4 and layer 7 options.
I still don't think layer 7 can ever give high availability.. but its a good read:
		</para>
		<para>
Ratz 23 Nov 2006 
		</para>
		<para>
A very nice and to the point introduction. 
Willy, among being a nice person and a good friend, is an
excellent engineer with a lot of expertise in high available, 
high performance and secure web
services, networking and packet filtering and much more. 
It would be nice to have Willy contributing
to/on this list as well :).
		</para>
		<para>
Malcolm <emphasis>lists (at) loadbalancer (dot) org</emphasis> 01 Feb 2007
		</para>
		<para>
HAProxy <ulink url="http://haproxy.1wt.eu/">http://haproxy.1wt.eu</ulink>
is a tcp proxy (fast) but flexible enough to do cookie insertion and SNAT etc.
		</para>
		<para>
from <emphasis>lvs (at) spiderhosting (dot) com</emphasis>
<ulink url="http://dmoz.org/Computers/Software/Internet/Site_Management/Load_Balancing/">a list of load balancers</ulink>
		</para>
		<para>
Brent Cook <emphasis>busterb (at) mail (dot) utexas (dot) edu</emphasis> 28 Mar 2002
		</para>
		<blockquote>
There's the http://www.bsdshell.net/ HighUpTime (HUT) projec (link dead Apr 2003).
It's FreeBSD.
		</blockquote>
		<para>
The HUT author, Sebastian Petit
<emphasis>spe (at) selectbourse (dot) net</emphasis> has joined the LVS mailing list.
		</para>
		<para>
For L7 Switching see the <link linkend="DRWS">DRWS project</link>.
		</para>
		<para>
Dec 2006: Alexandre Cassen, the author of <xref linkend="setup_keepalived"/> has written an 
L7 Switch at <ulink url="http://www.linux-l7sw.org">http://www.linux-l7sw.org"</ulink>.
		</para>
		<para>
BSD load balancing:
		</para>
		<para>
Roberto Nibali <emphasis>ratz (at) tac (dot) ch</emphasis> 05 Nov 2003
		</para>
		<para>
As already mentioned by others, LVS will not work on FreeBSD as director due to
the kernel part. Using FreeBSD on the RS is of course ok.
The BSD folks have not shown bigger interest in adopting the LVS idea or parts
of the code yet.
If you're interested in load balancing and HA Solutions under FreeBSD, you could
check out following links:
		</para>
<programlisting><![CDATA[
http://www.bsdshell.net/hut_fvrrpd.html
http://www.backhand.org/wackamole/
http://unix.derkeiler.com/Mailing-Lists/FreeBSD/isp/2003-05/0026.html
http://redundancy.redundancy.org/fbsd_lb.html
]]></programlisting>

		<para>
Gavin Henry <emphasis>ghenry (at) suretecsystems (dot) com</emphasis> 06/13/2005 
		</para>
		<blockquote>
<ulink url="http://geminis.dyndns.org/wordpress/index.php/2005/06/12/loadbalancer-less-clusters-on-linux/">ClusterIP</ulink> by Harald Welte.
What is the list's view on it?
		</blockquote>
		<para>
Gavin Henry 
<emphasis>ghenry (at) suretecsystems (dot) com</emphasis> 13 Jun 2005
		</para>
		<para>
The man page for more recent versions of iptables says:
		</para>
		<blockquote>
CLUSTERIP: This module allows you to configure a simple
cluster of nodes that share a certain IP and MAC address
without an explicit load balancer in front of them
		</blockquote>
		<para>
Horms 
		</para>
		<para>
Been there, done that. Works, but is it neccessary?
<ulink url="http://www.ultramonkey.org/papers/active_active/">LVS with upto 16 directors active</ulink>
(http://www.ultramonkey.org/papers/active_active/)
		</para>
		<para>
A set of postings on /. 2 Mar 2009 at
<ulink url="http://tech.slashdot.org/article.pl?sid=09/03/02/0231241">Best Solution for HA and Network Loadbalancing</ulink>
(http://tech.slashdot.org/article.pl?sid=09/03/02/0231241) lists the following
		</para>
		<itemizedlist>
			<listitem>
<ulink url="http://haproxy.1wt.eu/">HAproxy</ulink>
			</listitem>
			<listitem> 
<ulink url="http://distributor.sourceforge.net/">Distributor</ulink> 
			</listitem>
			<listitem> 
<ulink url="http://crossroads.e-tunity.com/">Crossroads</ulink> 
			</listitem>
			<listitem> 
<ulink url="http://siag.nu/pen/">Pen</ulink>
			</listitem>
			<listitem> 
<ulink url="http://www.inlab.de/balance.html">Balance/BalanceNG</ulink> 
			</listitem>
			<listitem> 
<ulink url="http://www.apsis.ch/pound/index_html">Pound</ulink>
			</listitem>
		</itemizedlist>
		</section>
		<section id="commercial_solutions">
		<title>List of Commercial Solutions</title>
		<para>
Cahya Wirawan <emphasis>cwirawan (at) email (dot) archlab (dot) tuwien (dot) ac (dot) at</emphasis> 19 Feb 2004
		</para>
		<blockquote>
I'm implementing proxy, smtp and webserver with LVS as local node,
and I have tested it and it's running fine, but because
someone from management section thinks that such an implementation
is easy (just run setup.exe and everything is installed and ready to use),
he pushed me to move the setup into production, 
and create another one as soon as possible.
I want to tell him that such an implementation is not a trivial thing 
and needs time to setup and to test before we go into production.
I want to show him a list of companies who have such complete solutions, 
so he can see the cost. 
Then he can understand that high availability and load balancing is not easy to setup,
and will cost alot of money if we buy a complete solution.
		</blockquote>
		<para>
Vendors just rub their hands with glee on finding management like this
- see my
<ulink url="http://www.austintek.com/book_reviews/the_ibm_way.html">
review of the book &quot;The IBM Way&quot;</ulink>
(http://www.austintek.com/book_reviews/the_ibm_way.html) for
how IBM handles the situation.
		</para>
		<para>
Peter Mueller
		</para>
		<para>
Prices at this level are negotiable.  Who knows what you could pay?
		</para>
		<itemizedlist>
			<listitem>
http://www.cisco.com/ - the old man on the LB-gig.
			</listitem>
			<listitem>
http://www.f5.com/f5products/bigip/LB520/  - the second old man in the LB
gig.
			</listitem>
			<listitem>
http://www.suse.com/us/business/products/server/ - Suse has always been a
big player in the Linux-HA world.
			</listitem>
			<listitem>
http://www.redhat.com/software/rhel/purchase/ - they have clustering based
on LVS, not sure about price.  At this point you have to buy enterprise
edition (or http://www.whiteboxlinux.com) to use the clustering software.
			</listitem>
			<listitem>
http://www.ibm.com/ - always an option...
			</listitem>
			<listitem>
http://www.dell.com/ - moving up in the datacenter world.  I see lots of
Dells now..
			</listitem>
			<listitem>
http://www.ebay.com/ - see how much the gear is worth on the open market.
			</listitem>
			<listitem>
				<para>
http://www.linuxvirtualserver.org/ - $0.
				</para>
				<para>
There's plenty of people on list
who can help you and your boss feel more comfortable with your setup.  I'm
sure if you posted something some people would be willing to help make you
sleep better at night.  BTW, you know about the http://www.ultramonkey.org/
and http://www.keepalived.org/ projects, right?
				</para>
			</listitem>
		</itemizedlist>
		</section>
		<section id="radware" xreflabel="Radware">
		<title>Radware</title>
		<para>
Joe Oct 2005:
From a presentation by 
<ulink url="http://www.radware.com/">Radware</ulink>)
(http://www.radware.com/)
given to <ulink url="http://www.ncsysadmin.org/">North Carolina Systems Administrators (NCSA)</ulink>
(http://www.ncsysadmin.org/) on 10 Oct 2005.
Unfortunately I was the guy getting the pizzas for the
meeting, so I missed most of the talk (which I wanted
to hear).
		</para>
		<para>
Radware is used by Ebay and Accuweather.
Radware has a NAT loadbalancing director that appears to 
function similarly to an LVS-NAT director. The servers can 
have private IPs.
		</para>
		<para>
Radware's loadbalancing director is only a small part of 
their offering. Radware have boxes that filter based on 
packet content (looking for viruses) that sit in the flow of 
packets (possibly before the director, possibly after - didn't 
find this out). They have boxes which just handle SYN 
floods. They use SYN cookies and do a statistical analysis 
of the packets, letting some through to see which machines 
reply to the SYN-ACKs. Radware has a gui to control the 
loadbalancer, which can do things like shutting down some of 
the backend servers at sometime in the future (<emphasis>e.g.</emphasis> at 10pm
later that night) for 
new connections, so that by 8am next morning these machine 
have few or no connections and can be taken offline for 
servicing. Much of their hardware is ASIC based.
		</para>
		<para>
Health checking seems to be done from the director, and 
checks are made through to 3rd-Tier components of the 
backend servers (<emphasis>e.g.</emphasis> database machines 
behind the webservers that the client doesn't directly 
connect to).
		</para>
		<para>
Each local NAT'ed load balancing setup is itself a member of 
a distributed DNS-based load balancer. So www.foo.net might 
have a loadbalanced set of servers in different sites eg 
London, New York, San Francisco and Tokyo. Each local setup 
has an authoritative nameserver for www.foo.net
		</para>
		<para>
The way is works is
		</para>
		<itemizedlist>
			<listitem>
client in Scotland asks for the IP of www.foo.net
			</listitem>
			<listitem>
the client's nameserver doesn't know the IP and asks a 
rootserver for the machine authoritative for foo.net.
			</listitem>
			<listitem>
The rootserver has a list of 4 authoritative nameservers 
for foo.net and selects the next nameserver by round robin. 
If the next one in its list is in New York, it tells the 
client's nameserver to go query the nameserver in New York.
			</listitem>
			<listitem>
The New York nameserver for foo.net measures the packet 
latency to the client's nameserver and then returns the VIP 
for www.foo.net associated with the New York 
installation of www.foo.net. The latency is propagated to 
the other foo.net nameservers (in Tokyo, London and San 
Francisco).
			</listitem>
			<listitem>
Sometime later after the client's nameserver has flushed 
the IP entry for www.foo.net from its cache, another (or the 
same) client using the same nameserver asks for the IP of 
www.foo.net again and this time the rootserver will 
possibly send the request to another of the sites (say 
London).  The London machine already knows the latency from 
New York to the client (without knowing where the client 
is), and sees that its latency to the client is lower than 
the latency from New York to the client, and returns the IP 
of its copy of www.foo.net. The London 
nameserver also updates the latency tables at the other 
sites (New York, San Francisco and Tokyo).
			</listitem>
			<listitem>
If the next nameserver request from the client site is 
sent to Tokyo, then the Tokyo machine updates the latency 
tables in all the other nameservers, and knowing that the 
latency is lowest to the London nameserver, returns the IP 
of www.foo.net in London.
			</listitem>
			<listitem>
In this way the four nameserver accumulate the latencies to 
all nameservers in the world. This works provided that the 
latencies don't change a lot with time of day (or 
throughput). Presumably you could store successive
latencies and pick the shortest as reflecting the
true network distance. The amount of memory required to do this must 
be small - there can't be more than a million nameservers, 
can there? 1 million 8 bit latencies is not much to store in 
memory.
			</listitem>
		</itemizedlist>
		<para>
Although I didn't get to ask how it works, if a client winds
up at a more distant site (network wise), then http redirects will send
the client to a closer site.
		</para>
		<para>
Radware SSL accelarators:
		</para>
		<para>
When I commented to the speaker that the main reason to use 
SSL accelarators is financial, <emphasis>i.e.</emphasis>
to only have one copy of the certificate, 
rather than one on each realserver, they said 
"it's also for certificate management". Presumably some 
sites have large numbers of certificates. (They didn't 
disagree with my statement.)
		</para>
		<para>
The SSL accelarators in the Radware design don't sit between 
the director and the realservers (or in front of the director 
<emphasis>i.e.</emphasis> between the client and the director), 
but sit at the same 
level as the other realservers. The https request is 
balanced by the director to an accelarator, which decrypts 
the packets and sends the decrypted packet back to the 
director for loadbalancing as http traffic. Since the 
director is a NAT balancer, the return http traffic from the 
http servers, goes back through the director, and then 
recursively back to the SSL accelarator then back to the 
director at https traffic and then back to the client.
		</para>
		<para>
Being able to have the SSL accelarator as a realserver in 
LVS would require the realservers to be a client of the 
director, something that we can do for LVS-NAT, but not for 
LVS-DR. This is not a capability that we've paid much attention
to for LVS. If you need a realserver to be in the path in both 
inward and outward directions (like an SSL accelarator) then 
you will have to use LVS-NAT.
		</para>
	<para> 
Francois JEANMOUGIN <emphasis>Francois (dot) JEANMOUGIN (at) 123multimedia (dot) com</emphasis> 12 Oct 2005 
	</para>
	<para>
Note that we removed our Radware appliance to use LVS instead. Load Balancing
using DNS is _evil_, especially with mobile internet and all those
misconfigured operator gateways.
Most mobile gateway are written in Java, and I'm probably the only
one who read the java.security file. Just have a look on this ugly stuff you
can find in it and the unbelievable silly explanation given:
	</para>
<programlisting><![CDATA[
# The Java-level namelookup cache policy for successful lookups:
#
# any negative value: caching forever
# any positive value: the number of seconds to cache an address for
# zero: do not cache
#
# default value is forever (FOREVER). For security reasons, this
# caching is made forever when a security manager is set.
#
# NOTE: setting this to anything other than the default value can have
#       serious security implications. Do not set it unless
#       you are sure you are not exposed to DNS spoofing attack.
#
#networkaddress.cache.ttl=-1
]]></programlisting>
	<para>
For security reasons! Guys! Well. So we removed radware. Note that we had
other problem with radware. The DNS cache of the clients is one, the response
time of the DNS was another. Several technical issues when you reach some
trafic limits was the last.
	</para>
	<para>
Henrik Holst
	</para>
	<blockquote>
still, geographic load balancing would be very nice to have and I
cannot figure out another way to do it than involve DNS round-robin.
	</blockquote>
	<para> 
Francois  
	</para>
	<para>
Round-Robin DNS could work if
	</para>
	<itemizedlist>
		<listitem>
You have enough clients
		</listitem>
		<listitem>
Clients are using DNS as expected
		</listitem>
		<listitem>
Clients are dealing with TTL
		</listitem>
		<listitem>
Client DNS caches or provider DNS are honouring DNS TTL
		</listitem>
		<listitem>
All your sites are always up and working (you can't use a DNS solution for
failover)
		</listitem>
	</itemizedlist>
	<para>
My clients are mobile phones, basically points 1 to 4 are not OK :). And I
have to deal with multiple sources for the same client (the transaction begin
in the gallery gateway and continues in the standard surf gateway, and I have
to use fwmarks to keep the session)...
We used RadWare to try to load-balance between our two peers. It clearly was
not working. Unfortunately, I don't have all the details.
	</para>

	<para>
Horms
	</para>
	<para>
If you want to distribute traffic between hosts
that have fast, reliable links, like a LAN, then LVS is a good option.
No, an excellent option.
If you want to distribute traffic between geographically separated
hosts, then you don't want something like LVS that channles packets
through a single location then to another. Something DNS based is
probably the way to go - though round robin is not nearly smart
enough for my liking.
In practice, if you do have geographically distributed sites,
then each site should probably be an LVS cluster. So essentially
you end up using two techniques to solve different parts of the
same problem.
	</para>
	<para>
I wrote quite a lot of this on supersparrow.org once upon a time,
its still there if people want to read/play/enhance/.
(links through <xref linkend="supersparrow"/>).
	</para>
		</section>
		<section id="review_radware_F5">
		<title>User's view of Radware, F5</title>
		<para>
bak <emphasis>bak (at) picklefactory (dot) org</emphasis> 09 Jan 2007
		</para>
		<para>
I've used Radware, F5, and HP SAs as an admin.
My 2-minute executive overview take:
		</para>
		<para>
Radware is great for a switch-like, low-key experience.  They're relatively
cheap for hardware load balancers.  You get extra functionality like SSL and
link balancing with extra bits of hardware.  Sometimes they can be pretty
hard to troubleshoot.  If you want global balancing/failover, that's part of
all their "AS" type switches.
		</para>
		<para>
F5 is the other 'big name' option.  These boxes are more like Brocade
switches: it's running embedded Linux in there, and if you want to run
tcpdump, you can.  You get extra functionality by buying a 'bigger' box and
then paying F5 for more licensing.  If you want to do global
balancing/failover, you have to get one of their DNS devices.
		</para>
		<para>
If you have money to wave around, I've found both Radware and F5 are more
than happy to give you a demo unit for 2-4 weeks.
		</para>
		</section>
	</section>
	<section id="books">
	<title>Books on LVS</title>
	<para>
Karl Kopper has tackled this. 
Writing a book on a moving target like LVS is a difficult proposition - 
certainly more than I was prepared to take on. 
	</para>
<programlisting><![CDATA[
The Linux Enterprise Cluster
Karl Kopper
Pub: No Starch Press
ISBN 1593270364
]]></programlisting>
	<para>
The book is available at your usual suppliers.
	</para>
	<para>
I'm loath to mention the names of internet booksellers
who require your e-mail address as part of your purchase,
so that they can spam you later. 
I've been buying my books by phone at a marginally higher price 
since realising their business practices.
However recently (Jul 2004) I've discovered disposable e-mail addresses 
<emphasis>e.g.</emphasis> the free service from 
<ulink url="http://www.jetable.org/">Jetable.org</ulink>
(http://www.jetable.org/).
They have a google-like (<emphasis>i.e.</emphasis> simple) interface.
You give them your e-mail address, 
the required lifetime of the address
(1-8days), and click. 
Up comes an e-mail address (test by sending a message to it)
that you can give to your internet vendor, 
and mail will be forwarded to you for the period selected. 
After that time, no more mail will get to you.
I've been using jetable since Jul 2004 (now Sep 2004)
and have not got any spam from Jetable or from internet vendors.
	</para>
	</section>
	<section id="LVS_in_the_news" xreflabel="LVS in the News">
	<title>LVS in the news</title>
	<para>
&quot;Wired&quot; Magazine in Jun 2004 has a small article about LVS, 
illustrating the multinational cooperative nature of GPL software development.
The page is 
<ulink url="http://www.wired.com/wired/archive/12.06/images/atlas_software.pdf">here</ulink>
(http://www.wired.com/wired/archive/12.06/images/atlas_software.pdf),
or a 
<ulink url="files/atlas_software.pdf">local copy of the article</ulink> on this server.
	</para>
	</section>
	<section id="related_info">
	<title>Software/Information/HOWTOs useful/related to LVS</title>
	<para>
<ulink url="http://www.ultramonkey.org/">Ultra Monkey</ulink>
is LVS and HA combined.
	</para>
	<para>
tong <emphasis>tong (at) csusb (dot) net</emphasis>
25 Jun 2003
	</para>
	<para>
Here's a step-by-step
<ulink url="http://www.cula.net/cluster/">
guide for setting up an LVS system with heartbeat</ulink>
(http://www.cula.net/cluster).
	</para>
	<note>
This guide was published a year ago and we've only just heard about it.
The author has never popped up on the mailing list to say hello.
	</note>
	<para>
from <emphasis>lvs (at) spiderhosting (dot) com</emphasis>
<ulink url="http://www.supersparrow.org/">Super Sparrow Global Load Balancing</ulink>
using BGP routing information.
	</para>
	<para>
Ratz is documenting the 
<ulink url="http://www.drugphish.ch/~ratz/IPVS/index.html">
2.6 headers and calls with doxygen</ulink>
(http://www.drugphish.ch/~ratz/IPVS/index.html)
whenever he has reason to fiddle with a piece of code 
(<emphasis>i.e.</emphasis> the documentation isn't exhaustive, at least yet). 
	</para>
	<para>
From ratz, there's a write up on load imbalance with persistence and sticky bits at our friends
at <ulink url="http://www.microsoft.com/technet/prodtechnol/windows2000serv/deploy/confeat/nlbovw.asp">M$</ulink>.
	</para>
	<para>
From ratz, Zero copy patches to the kernel to speed up network throughput,
<ulink url="ftp://ftp.kernel.org/pub/linux/kernel/people/davem">Dave Miller's patches</ulink>,
<ulink url="http://surriel.com/patches/">Rik van Riel's vm-patches</ulink> and
more of Rick van Riel's patches at
http://www.linux-mm.org/ (link dead Dec 2003).
The Zero
copy patches may not work with LVS and may not work with netfilter either 
(from <emphasis>john (at) antefacto (dot) com</emphasis>).
	</para>
	<para>
From Michael Brown <emphasis>michael_e_brown (at) dell (dot) com</emphasis>, the
<ulink url="http://www.redhat.com/software/">TUX kernel level webserver</ulink>.
	</para>
	<para>
Dustin Puryear <emphasis>dustin (at) puryear-it (dot) com</emphasis>
gave a talk on LVS at LISA 2003.
The tutorial, is avaialble at:
<ulink url="http://www.puryear-it.com/publications.htm#6">
LVS: Load Balancing and High Availability for Free</ulink>
(http://www.puryear-it.com/publications.htm#6).
	</para>
	</section>
</section>
<section id="LVS-HOWTO.what_is_an_LVS">
<title>LVS: What is an LVS? Can I use an LVS?</title>
<para>
A Linux Virtual Server (LVS) is a cluster of servers
which appears to be one server to an outside client.
This apparent single server is called here a "virtual server".
The individual servers (realservers) are under
the control of a director (or load balancer),
which runs a Linux kernel patched to include the <emphasis>ipvs</emphasis> code.
The ipvs code running on the director is
<emphasis>the</emphasis> essential feature of LVS.
Other user level code is used to manage the LVS
(set rules for services handled, handle failover).
The director is basically a layer 4 router 
with a modified set of routing rules
(<emphasis>i.e.</emphasis> connections do not originate
or terminate on the director, it doesn't send ACKs etc,
it's just a router).
</para>
<para>
When a new connection is requested from a client to a service provided by the LVS 
(<emphasis>e.g.</emphasis> httpd), 
the director will choose a realserver for the client.
From then, all packets from the client
will go through the director to that particular realserver.
The association between the client and the realserver will
last for only the life of the tcp connection (or udp exchange).
For the next tcp connection, the director will choose a new
realserver (which may or may not be the same as the first realserver).
Thus a web browser connecting to an LVS serving a webpage consisting
of several hits (images, html page), may get each hit from a separate
realserver.
</para>
<para>
Since the director will send the client to an arbitary realserver, 
the services must be either read only
(<emphasis>e.g.</emphasis> web services) or if read/write
(<emphasis>e.g.</emphasis> an on-line shopping cart)
some mechanism external to LVS must be provided for
propagating the writes to the other realservers on 
a timescale appropriate for the service 
(<emphasis>i.e.</emphasis> purchase of an item 
must decrement the stock on all other nodes before
the next client attempts to purchase the same item).
At best LVS is read mostly.
</para>
<para>
If you just want one of several nodes to be up at any one time, 
and the other node(s) to become active on failure of the primary node, 
then you don't need LVS: you need a high availability
setup <emphasis>e.g.</emphasis> Linux-HA (heartbeat), vrrp or carp.
</para>
<para>
If you want independant servers at different locations,
then you want a geographically distributed server like
<link linkend="supersparrow">Supersparrow</link>.
</para>
<para>
Here are some <xref linkend="rrd_images"/>
</para>
<para>
Management of the LVS is through the user space utility <xref linkend="LVS-HOWTO.ipvsadm"/>,
which is used to add/removed realservers/services and to handle failout.
LVS itself does not detect failure conditions; these are detected
by external agents, which then update the state of the LVS through <command>ipvsadm</command>
</para>
	<section id="what_is_a_VIP">
	<title>What is a VIP?</title>
	<para>
The director presents an IP called the Virtual IP (VIP) to clients.
(When using <xref linkend="LVS-HOWTO.fwmark"/>, VIPs are agregated into
groups of IPs, but the same principles apply as for a single IP).
When a client connects to the VIP, the director forwards the client's
packets to one particular realserver for the
duration of the client's connection to the LVS. This connection is chosen
and managed by the director. The realservers serve services
(eg ftp, http, dns, telnet, nntp, smtp) such as are found in
/etc/services or inetd.conf. The LVS presents one IP on the director
(the virtual IP, VIP) to clients.
	</para>
	<para>
Peter Martin <emphasis>p (dot) martin (at) ies (dot) uk (dot) com</emphasis> and John Cronin <emphasis>jsc3 (at) havoc (dot) gtf (dot) org</emphasis> 05 Jul 2001
	</para>
	<blockquote>
	<para>
The VIP is the address which you want to load balance 
<emphasis>i.e.</emphasis> the address of your website. 
The VIP is usually a secondary address 
so that the VIP can be swapped between two directors on failover
(the VIP used to be an alias (<emphasis>e.g.</emphasis> eth0:1).
	</para>
	<para>
The VIP is the IP address
of the "service", not the IP address of any of the particular systems
used in providing the service (ie the director and the realservers).
	</para>
	<para>
The VIP be moved from one director to another backup director
if a fault is directed
(typically this is done by using
<filename>mon</filename> and <filename>heartbeat</filename>,
or something similar).
The director can have <link linkend="multiple_VIPs">multiple VIPs</link>.
Each VIP can have one or more services associated with it
<emphasis>e.g.</emphasis> you could have HTTP/HTTPS
balanced using one VIP, and FTP service (or whatever) balanced using
another VIP, and calls to these VIPs can be answered by the same or different
realservers.
	</para>
	<para>
Groups of VIPs and/or ports can be setup with <xref linkend="LVS-HOWTO.fwmark"/>.
	</para>
	<para>
The realservers have to be configured to work with the VIPs on the director
(this includes handling the <xref linkend="LVS-HOWTO.arp_problem"/>).
	</para>
	<para>
There can be
<xref linkend="LVS-HOWTO.persistent_connection"/> issues,
if you are using cookies or https,
or anything else that expects the realserver fulfilling the requests
to have some connection state information.
This is also addressed on the
<ulink url="http://www.linuxvirtualserver.org/docs/persistence.html">
LVS persistence page
</ulink>
	</para>
	</blockquote>
	</section>
	<section id="where_used">
	<title>Where do you use an LVS?</title>
	<itemizedlist>
		<listitem>
For higher throughput.
The cost of increasing throughput by adding
realservers in an LVS increases linearly,
whereas the cost of increased throughput by buying a larger single machine
increases faster than linearly
		</listitem>
		<listitem>
for redundancy. Individual machines can be switched out of the LVS,
upgraded and brought back on line without interuption of service to the clients.
Machines can move to a new site and brought on line one at a time while machines
are removed from the old site, without interruption of service to the clients.
</listitem><listitem> for adaptability. If the throughput is expected to change gradually (as a
business builds up), or quickly (for an event), the number of servers can be
increased (and then decreased) transparently to the clients.
		</listitem>
	</itemizedlist>
	</section>
	<section id="client_server_relationship">
	<title>Client/Server relationship is preserved in an LVS</title>
	<itemizedlist>
		<listitem>
Client sees only one IP address and believes it is connecting
to a single machine. IPs of all servers is mapped to one IP (the VIP).
While the client is connected to only one machine at a time,
however subsequent connections will be assigned to a new and likely
different machine.
		</listitem>
		<listitem>
servers at different IP addresses believe
they are contacted directly by the client.
		</listitem>
	</itemizedlist>
	</section>
	<section id="L4_switch">
	<title>LVS director is an L4 switch</title>
	<para>
In the computer beastiary, the director is a layer 4 (L4) switch.
The director makes decisions at the IP layer and just sees a stream
of packets going between the client and the realservers.
In particular an L4 switch makes decisions based on the IP information
in the headers of the packets.
	</para>
	<para id="supersparrow" xreflabel="Super Sparrow Project">
Here's a description of an L4 switch from
<ulink url="http://www.supersparrow.org/ss_paper/">Super Sparrow Global Load Balancer documentation</ulink>
	</para>
	<blockquote>
Layer 4 Switching: Determining the path of packets based on
information available at layer 4 of the OSI 7 layer protocol stack.
In the context of the Internet, this implies that the IP address
and port are available as is the underlying protocol, TCP/IP or UCP/IP.
This is used to effect load balancing by keeping an affinity
for a client to a particular server for the duration of a connection.
	</blockquote>
	<para>
This is all fine except
	</para>
	<para>
Nevo Hed <emphasis>nevo (at) aviancommunications (dot) com</emphasis> 13 Jun 2001
	</para>
	<blockquote>
The IP layer is L3.
	</blockquote>
	<para>
Alright, I lied.
TCPIP is a 4 layer protocol and these layers do not map well onto
the 7 layers of the OSI model.
(As far as I can tell the 7 layer OSI model is only used to torture
students in classes.)
It seems that everyone has agreed to pretend that tcpip
uses the OSI model and that tcpip devices like the LVS director
should therefore be named according to the OSI model.
Because of this, the name "L4 switch" really isn't correct,
but we all use it anyhow.
	</para>
	<para>
The director does not inspect the content of the packets and cannot
make decisions based on the content of the packets
(<emphasis>e.g.</emphasis> if the packet contains a <link linkend="cookie">cookie</link>,
the director doesn't know about it and doesn't care).
The director doesn't know anything about the application
generating the packets or what the application is doing.
Because the director does not inspect the content of the packets (layer 7, L7)
it is not capable of session management or providing
service based on packet content. L7 capability would be a useful
feature for LVS and perhaps this will be developed in the future
(preliminary ktcpvs code is out - May 2001 -
<xref linkend="LVS-HOWTO.L7_switch"/>).
	</para>
	<para>
The director is basically a router, with routing tables set up
for the LVS function.
These tables allow the director to forward packets to
realservers for services that are being LVS'ed.
If http (port 80) is a service that is being LVS'ed
then the director will forward those packets.
The director does not
have a socket listener on VIP:80 (i.e. netstat won't see a listener).
	</para>
	<para>
John Cronin <emphasis>jsc3 (at) havoc (dot) gtf (dot) org</emphasis> (19 Oct 2000)
calls these types of servers
(i.e. lots of little boxes appearing to be one machine) "RAILS"
(Redundant Arrays of Inexpensive Linux|Little|Lightweight|L* Servers).
Lorn Kay <emphasis>lorn_kay (at) hotmail (dot) com</emphasis> calls them RAICs (C=computer),
pronounced "rake".
	</para>
	</section>
	<section id="forward_packets">
	<title>LVS forwards packets to realservers</title>
	<para>
The director uses 3 different methods of forwarding.
	</para>
	<itemizedlist>
		<listitem>
LVS-NAT based on network address translation (NAT)
		</listitem>
		<listitem>
LVS-DR (direct routing) where the MAC addresses on the
packet are changed and the packet forwarded to the realserver
		</listitem>
		<listitem>
LVS-Tun (tunnelling) where the packet is IPIP encapsulated
and forwarded to the realserver.
		</listitem>
	</itemizedlist>
	<para>
Some modification of the realserver's ifconfig
and routing tables will be needed for LVS-DR and LVS-Tun forwarding.
For LVS-NAT the realservers only need a functioning tcpip stack (<emphasis>i.e.</emphasis>
the realserver can be a networked printer).
	</para>
	<para>
LVS works with all services tested so far (single and 2 port services)
except that LVS-DR and LVS-Tun cannot work with services that
initiate connects from the realservers (so far; identd and rsh).
	</para>
	<para>
The realservers can be indentical, presenting the same service
(eg http, ftp) working off file systems which are kept in sync
for content. This type of LVS increases the number of clients
able to be served. Or the realservers can be different, presenting a
range of services from machines with different services or
operating systems, enabling the virtual server to present a
total set of services not available on any one server. The
realservers can be local/remote, running Linux (any kernel)
or other OS's. Some methods for setting up an LVS have fast
packet handling (eg LVS-DR which is good for http and ftp)
while others are easier to setup (eg transparent proxy) but
have slower packet throughput. In the latter case, if the
service is CPU or I/O bound, the slower packet throughput
may not be a problem.
	</para>
	<para>
For any one service (eg httpd at port 80) all the realservers
must present identical content since the client could be connected
to any one of them and over many connections/reconnections, will
cycle through the realservers. Thus if the LVS is providing
access to a farm of web, database, file or mail servers, all
realservers must have identical files/content. You cannot split
up a database amongst the realservers and access pieces of it
with LVS.
	</para>
	<para>
The simplest LVS to setup involved clients doing read-only
fetches (<emphasis>e.g.</emphasis> a webfarm).
If the client is allowed to write to the LVS (<emphasis>e.g.</emphasis>
database, mail farm), then some method is required
so that data written on one realserver is
transferred to other realservers before the client disconnects
and reconnects again. This need not be all that fast (you
can tell them that their mail won't be updated for 10mins),
but the simplest (and most expensive) is for the mail farm
to have a common file system for all servers. For a database,
the realservers can be running database clients which connect
to a single backend database, or else the realservers can
be running independant database daemons which replicate their
data.
	</para>
	</section>
	<section id="any_linux">
	<title>LVS runs on Linux and FreeBSD directors</title>
	<para>
LVS was developed on Linux and historically uses a Linux director.
The Intel and Dec Alpha versions of LVS are known to work.
The LVS code doesn't have any Intel specific
instructions and is expected to work on any machine that runs Linux.
	</para>
	<para>
In Apr 2005, LVS was ported to FreeBSD by Li Wang
	</para>
	<para>
Li Wang <emphasis>dragonfly (at) linux-vs (dot) org</emphasis> 2005/04/16
	</para>
	<para>
The URL is:
<ulink url="http://dragon.linux-vs.org/~dragonfly/htm/lvs_freebsd.htm">FreeBSD port of LVS</ulink>
(http://dragon.linux-vs.org/~dragonfly/htm/lvs_freebsd.htm).
Here's a 
<ulink url="http://dragon.linux-vs.org/~dragonfly/software/doc/ipvs_freebsd/performance.html">
performance test on FreeBSD(version 0.4.0)</ulink>
(http://dragon.linux-vs.org/~dragonfly/software/doc/ipvs_freebsd/performance.html).
	</para>
	</section>
	<section id="lvs_different_for_different_kernels">
	<title>Code for LVS is different for each kernel series</title>
	<para>
There are differences in the coding for LVS for the 2.0.x, 2.2.x,
2.4.x and 2.6.x kernels.
Development of LVS on 2.0.36 kernels has stopped (May 99).
Code for 2.6.x kernels is relatively new.
	</para>
	<para>
The 2.0.x and 2.2.x code is based on the masquerading code. Even if you
don't explicitely use ipchains (eg with LVS-DR or LVS-Tun),
you will see masquerading entries with `ipchains -M -L` (or `netstat -M`).
	</para>
	<para>
Code for 2.4.x kernels was rewritten
to be compatible with the netfilter code (i.e. its entries will
show up in netfilter tables).
It is now production level code.
Because of incompatibilities with LVS-NAT for 2.4.x LVS was in
development mode (till about Jan 2001) for LVS-NAT.
	</para>
	</section>
	<section id="2.4_SMP_kernel">
	<title>kernels from 2.4.x series are SMP for kernel code</title>
	<para>
2.4.x kernels are SMP for kernel code as well as user space
code, while 2.2.x kernels are only SMP for user space code.
LVS is all kernel code. A dual CPU director running a 2.4.x
kernel should be able to push packets at twice the rate
of the same machine running a 2.2 kernel (if other resources
on the director don't become limiting).
(Also see the section on <xref linkend="FAQ:smp_doesnt_help"/>.)
	</para>
	</section>
	<section id="realserver_OS">
	<title>OS for realservers</title>
	<para>
You can have almost any OS on the realservers (all are
expected to work, but we haven't tried them all yet).
The realservers only need a tcpip stack -
a networked printer can be a realserver.
	</para>
	</section>
	<section id="ethernet">
	<title>LVS works on ethernet</title>
	<para>
LVS works on
<ulink url="http://www.ethermanage.com/ethernet/ethernet.html">ethernet</ulink>.
	</para>
	<para>
	There are some limitations on using
<link linkend="ATM">ATM</link>.
	</para>
	<para>
Firewire: (from the Beowulf mailing list - Donald Becket 5 Dec 2002):
The firewire transport layer (IEEE1394) does run
<ulink url="http://developer.apple.com/firewire/IP_over_FireWire.html">
IP over FireWire</ulink>.
However firewire is designed for fixed size repeated frames (video or
continuous disk block reads), but has overhead for other communication.
Throughput is 400Mbps but worst case latency is high (msec range).
	</para>
	<para>
Oracle has released GPL libraries for clustering Linux boxes over FireWire
(http://www.ultraviolet.org/mail-archives/beowulf.2002/2977.html, link dead Dec 2003).
	</para>
	</section>
	<section id="ipv6"><title>LVS works on IPv6</title><para>
Seiji Tsuchiike <emphasis>tsuchiike (at) yggr-drasill (dot) com</emphasis> 02 Jun 2002
	<blockquote>
We just implemented IPv6 to lvs.
We think that Basic Mechanism is same.
(http://www.yggr-drasill.com/LVS6/documents.html. link dead Dec 2003,
but Sep 2004 Horms says its alive; Joe Dec 2006 it's alive).
	</blockquote>
	</para>
	</section>
	<section id="ipvs_continually_developed">
	<title>LVS is continually being developed</title>
	<para>
LVS is continually being developed and usually only the more recent kernel
and kernel patches are supported. Usually development is incremental,
but with the 2.2.14 kernels the entries in the /proc file system changed
and all subsequent 2.2.x versions were incompatible with previous versions.
	</para>
	</section>
	<section id="64_bit">
	<title>LVS is 64 bit</title>
	<para>
Kenny Chamber
	</para>
	<blockquote>
Has anybody here successfully setup lvs-director on sparc64 machine?
I need to know which distro is OK for this.
	</blockquote>
	<para>
Ratz 16 Dec 2004
	</para>
	<para>
Yes. Just recently.
Debian is fine, I reckon Gentoo would do as well.
	</para>
	<para>
INFO: It could be that your ipvsadm binary that comes to instrument the 
kernel tables for LVS is broken with regard to 64bit'ness. You then need 
to download the latest sources and recompile adding '-m64' to the 
CFLAGS. That's all, other than that it seems to work nicely.
	</para>
	<para>
Btw: I took Debian testing, probably not too wise but on the other hand 
I needed more up to date tools. I wouldn't know of too many other 
Distros that have up to date Sparc64 support. Suse used to have, but 
they dropped support a while ago unfortunately.
	</para>
	<para>
Justin Ossevoort <emphasis>justin (at) snt (dot) utwente (dot) nl</emphasis> 16 Dec 2004
	</para>
	<para>
Well our plain debian-sarge here did it just as painlessly as our x86
based machines. So as long as your distro has ipvs (and of course a
sparc tree ;)) support you're in the green.
	</para>
	<para>
liuah
	</para>
	<blockquote>
I want to know whether LVS can work with 64-bit boxes.
If I use LVS-DR, how can I apply the hidden patch to 64-bit linux,
using kernel is 2.4.18?
	</blockquote>
	<para>
ratz 29 Nov 2003
	</para>
	<para>
Yes.

The only problem I see is if either the counters or the hashtable
handling has some bug with 32/64-bit signedness and wrong shift
operators. Just let us know if you experience flakyness on your director ;).
The hidden patch for your kernel is:
http://www.ssi.bg/~ja/hidden-2.4.19pre5-1.diff
I hope you are aware of the fact that 2.4.18 is really buggy in many
ways. I know that some 64-bit archs have been lagging behind in the 2.4.x
tree but if I was you I would upgrade to a newer kernel.
	</para>
	<para>
Peter Mueller <emphasis>pmueller (at) sidestep (dot) com</emphasis> 29 Nov 2003
	</para>
	<para>
The one for straight 2.4.18 is http://www.ssi.bg/~ja/hidden-2.4.5-1.diff.
Since he said 2.4.18 I would suspect he's running Debian.  If you want a
Debian kernel with LVS+hidden use the
<ulink url="http://www.ultramonkey.org/">
Ultramonkey kernel</ulink>
(http://www.ultramonkey.org/").
	</para>
	<para>
liuah <emphasis>liuah (at) langchaobj (dot) com (dot) cn</emphasis> 02 Dec 2003
	</para>
	<para>
The hidden patch compiles and runs on our 64-bit servers successfully.
	</para>
	</section>
	<section id="other_documentation">
	<title>Other documentation</title>
	<para>
For more documentation, look at the LVS web site
(eg a talk I gave on how LVS works on
<ulink url="http://www.linuxvirtualserver.org/Joseph.Mack/linuxexpo99/linuxexpo2.html">2.0.36 kernel directors</ulink>)
	</para>
	<para>
Julian has written
<ulink url="http://www.ssi.bg/~ja/">Netparse</ulink>
for which we don't have a lot of documentation yet.
	</para>
	<para>
For those who want more understanding of netfilter/iptables etc, here
are some starting places. These topics are also covered in many
other places.
	</para>
	<itemizedlist>
		<listitem>
<ulink url="http://www.sunbeam.franken.de/projects/packetjourney/">
Harald Welte (of the netfilter team) description of what happens to a packet under 2.4
</ulink>
		</listitem>
		<listitem>
		<para>
<ulink url="http://www.sunbeam.franken.de/projects/conntrack+nat-HOWTO/">
Harald Welte (of the netfilter team) conntrack HOWTO</ulink>.
		</para>
		<para>
Conntrack is used in filter rules as a way of accepting "related" packets, 
<emphasis>e.g.</emphasis>
the data packets associated with an established ftp connection.
Regular filter rules written for these data packets
would accept ftp data packets (port 20) even if
there were not in response to a PORT call from an already
established ftp connection on port 21.
In this case the filter rules would accept packets that are part of a DoS attack.
		</para>
		<para>
Conntrack is CPU intensive and lowers throughput
(see <link linkend="conntrack">effect of conntrack on throughput</link>).
To disable conntrack you have to rmmod all the conntrack modules.
		</para>
		</listitem>
		<listitem>
<ulink url="http://www.netfilter.org">the docs/FAQs/HOWTOs on the netfilter site</ulink>

		</listitem>
		<listitem>
<ulink url="http://www.tldp.org/LDP/nag2/">Linux Network Administrators Guide</ulink>

		</listitem>
	</itemizedlist>
	</section>
	<section id="lvs_is_not_simple">
	<title>LVS is not simple to install, get going or keep running</title>
	<para>
This is not a utility where you run
<command>../configure &amp;&amp; make &amp;&amp; make check &amp;&amp; make install</command>,
put a few values in a <filename>*.conf</filename> file and you're done.
LVS rearranges the way IP works so that a router and server (here called director and realserver),
reply to a client's IP packets as if they were one machine.
You will spend many days, weeks, months figuring out how it works.
LVS is a lifestyle, not a utility.
	</para>
	<para>
That said, you should be able to get a simple LVS-NAT setup working in a few hours without
really understanding a whole lot about what's going one (see the
<link linkend="mini-HOWTO">LVS-mini-HOWTO</link>).
	</para>
	</section>
	<section id="lvs_control">
	<title>LVS Control (Failure, Thundering Herd, Sorry Servers)</title>
	<para>
LVS is kernel code (<filename>ip_vs</filename>) 
and a user space controller (<filename>ipvsadm</filename>).
When adding functionality to LVS (handling failover, bringing new machines on-line), 
we have to figure the best place to put it: in the kernel code or in the user space code?
Such decisions are relevant if you can choose from two equally functional lots of code -
we usually get what the coder wanted to implement.
	</para>
	<para>
Current thinking is to make the kernel code just handle the switching and
to have all control in user space.
	</para>
	<para>
Should the <xref linkend="thundering_herd"/>
be controlled by LVS or by an external user space program 
<emphasis>e.g.</emphasis> <link linkend="feedbackd">feedbackd</link>.
Currently there is both a kernel patch and a script
to change from rr to lc shortly after adding a new realserver.
An alternative (not implemented) would be a scheduler that 
is rr when there's a large difference in the number of connections
to the different realservers and lc when the number of connections
is similar.
	</para>
	<para>
LVS supplies high throughput using multiple identically configured machines.
You would like to be able to swap out machines for planned maintenance and
to automatically handle node failure (high availability).
	</para>
	<para>
The LVS itself does not provide high availability.
The current thinking is that the software layer that provides high availability
should be logically separate to the layer that it monitors.
The writing of software that attempts to determine whether a machine is
working, is somewhat of a black art.
There are several packages used to help provide high availability for LVS
and these are discussed in the <link linkend="LVS-HOWTO.failover">High Availability LVS</link> section.
	</para>
	<para>
While it is relatively easy to monitor the functionality of the realservers,
fail-out of directors is more difficult.
An even greater problem is handling failure of nodes which are holding state information.
	</para>
	<note>
There is a sorry server option in <xref linkend="keepalived_vrrpd"/>
	</note>
	<para>
Gustavo
	</para>
	<blockquote>
I'm trying to create a sorry server for clients that can't connect to my
real servers (limited by u-threshold); ServerA  - 100 conn, ServerB - 110 conn.
When this limit is reached I want my clients to go to a lighttpd served
page saying "come back later"
I'm trying with weights and thresholds... but it's not working the way I thought.
	</blockquote>
	<para>
Ratz 22 Nov 2006
	</para>
	<para>
I suspect the clients scheduled for the sorry server never return back to
the cluster, right (only if you use persistency of course)?
	</para>
	<blockquote>
That's right.
I'm working on a project for an airline companie.
Some times they post some promotional tickets for a small period of time
(only for passengers that buys on the website can have it) and the servers
go high.
	</blockquote>
	<para>
I've written a patch for the 2.4 kernel series extending IPVS to
support the concept of an atomically switching sorry server environment.
Unfortunately I didn't have the time to port the work to 2.6 kernels yet
(the threshold stuff is already in but a bit broken and the sorry server
stuff needs some adjustments in the 2.6 kernel). If you run 2.4 on your LB,
you could try out the patches posted to this list almost exactly one year
ago:
	</para>
<programlisting><![CDATA[
http://marc.theaimsgroup.com/?l=linux-virtual-server&m=113225125532426&w=2
http://marc.theaimsgroup.com/?l=linux-virtual-server&m=113225142406014&w=2
]]></programlisting>
	<para>
The fix to the kernel patch above:
	</para>
<programlisting><![CDATA[
http://marc.theaimsgroup.com/?l=linux-virtual-server&m=113802828120122&w=2
]]></programlisting>
	<para>
And the 3/4 cut-off fix:
	</para>
<programlisting><![CDATA[
http://www.in-addr.de/pipermail/lvs-users/2005-December/015806.html
]]></programlisting>
	<para>
I personally believe that the sorry-server feature is a big missing piece of
framework in IPVS, one that is implemented in all commercial HW load
balancers.
	</para>
	<para>
Horms
	</para>
	<blockquote>
That is true, but its also a piece that is trivially inplemented in
user-space, where higher-level monitoring is usually taking place anyway.
Is there a strong argument for having it in the kernel?
	</blockquote>
	<para>
ratz 14 Feb 2007
	</para>
	<para>
Yes, it won't work reliably in user space because of missing atomicity. From
the point the user space daemon decides that it's time to switch over to the
sorry-server pool to the actual switch in the kernel by modifying the
according service flag, there's a couple of us to ms time frame in which the
kernel TCP stack will happily proceed with its normal tasks, including
service more requests to the previously elected service for sorry-server
forwarding. This can lead to broken (half-shown) page views an the
customer's side inside their browser.
	</para>
	<para>
In the field I had to implement load balancing, this was simply not
accepted, especially because it irritated our customer's clients and also
because everybody knew that HW load balancers do it right (tm).
	</para>
	<para>
YMMV and I still didn't sit down and forward port my code to 2.6 but I first
need some interest by enough people before I start :).
	</para>
	<para>
I wrote the 2.4 server pool implementation for a ticket reseller company that
probably had the same problems as your airline company. Normal selling
activities not needing high end web servers and then from time to time (in
your case promotional tickets, in my case Christina Aguilera, U2 or Robbie
Williams or World Soccer Championship tickets) peak selling where tickets
need to be sold in the first 15 minutes having tens of thousands of requests
per second, plus the illicit traffic generated by scripters trying to
sanction the event. These peaks, however, do not warrant the acquisition of
high-end servers and on-demand servers cannot be organized/prepared so
quickly.
	</para>
	<blockquote>
I need to manually limit each server capacity and the remaining connections
need to go to this sorry server.
	</blockquote>
	<para>
That's exactly the purpose of my patch, plus you get to see how many
connections (persistent as in session and active/passive connections) are
forwarded to either the normal webservers (so long as they are within the
u_thresh and l_thresh) or the overflow (sorry server) pool. As soon as one
of the RS in the serving pool drops below l_thresh future connection
requests are immediately sent to the service pool again.
	</para>
	<blockquote>
We have tried F5 Big-IP for a while and it worked perfectly, but it is
very expensive for us :(
	</blockquote>
	<para>
Yep, about USD 20k-30k to have them in a HA-pair.
	</para>
	<para>
So for the 2.4 kernel, I have a patch that has been tested extensively and
is running in production for one year now, having survived some hype events.
I don't know if I find time to sit down for a 2.6 version. Anyway, as has
been suggested, you can also try the sorry server of keepalived, however I'm
quite sure that this is not atomically (since keepalived is user space) and
works more like:
	</para>
<programlisting><![CDATA[
while true {
  for all RS {
    if RS.conns > u_thresh then quiesce RS
    if RS.isQuiesced and RS.conns < l_tresh then {
       if sorry server active then remove sorry server
       set RS.weight to old RS.weight
  }
  if sum_weight of all RS == 0 then invoke sorry server with weight > 0
}
]]></programlisting>
	<para>
If this is the case, it will not work for our use cases with high peak
requests, since sessions are not switched to either one service pool
atomically and thus this will result in people being sent to the overflow
pool even though they would have had a legitimate session and others again
get broken pages back, because in midst of the page view the LB's user space
process gets a scheduler call to update its FSM and so further requests sent
for HTTP 1.0 for example will be broken. The browser hangs on your customers
side and your management gets the angry phone calls of the business users,
to whom you had promised B2B access.
	</para>
	<para>
This is roughly how I came around to implementing the server overflow
(spillover server, sorry server) functionality for IPVS.
	</para>
	</section>
	<section id="clients_on_realservers">
	<title>clients on realservers</title>
	<para>
Sometimes you want a client process that has nothing to do with LVS,
to connect to machines outside the LVS. 
The client could be fetching DNS, running telnet/ssh or sending mail for logging.
None of these client calls are part of the service being balanced by LVS. 
This is covered in <xref linkend="LVS-HOWTO.non-lvs_clients_on_realservers"/>. 
	</para>
	<para>
Sometimes the LVS'ed service (<emphasis>e.g.</emphasis> http)
will fire up a client process 
(<emphasis>e.g.</emphasis> filling in a webpage 
will result in the realserver writing to a database). 
People then want to loadbalance these client calls coming
from the RIPs through a VIP on the same director.
This is covered in 
<xref linkend="LVS-HOWTO.lvs_clients_on_realservers"/>. 
	</para>
	</section>
</section>
<section id="LVS-HOWTO.install">
<title>LVS: Install, Configure, Setup</title>
	<section id="from_source">
	<title>Installing from Source Code</title>
	<para>
Doing this from source code is now described in the
<ulink url="http://www.austintek.com/LVS/LVS-HOWTO/mini-HOWTO/LVS-mini-HOWTO.html">LVS-mini-HOWTO</ulink>.
Two methods of setup are described
	</para>
	<itemizedlist>
		<listitem>
Setup from the command line.
This is fine to understand what's going on,
and if you only want to have a single type of setup.
For LVSs which you're reconfiguring a lot, it's tedious and mistake prone.
If it doesn't work, you will spend some time figuring out why.
		</listitem>
		<listitem>
From a configure script which sets up an LVS with a single director.
This script is fine for initial setups: it's mistake proof 
(will give you enough information about failures to figure
out what might be wrong) and I used it for all my testing of LVS.
Since it's not easily expandable to handle director failover
and other configuration tools handle this now,
the configure script is not being developed anymore.
For production, where you need failover directors, you
should use other setup tools or save your hand-built setup as a script
(<emphasis>e.g.</emphasis> with <command>ipvsadm-sav</command>).
		</listitem>
	</itemizedlist>
	</section>
	<section id="setup_ultramonkey">
	<title>Ultra Monkey</title>
	<para>
<ulink url="http://www.ultramonkey.org">Ultra Monkey</ulink> is a packaged
set of binaries for LVS, including Linux-HA for director failover and
ldirectord for realserver failover.
It's written by Horms, one of the LVS developers.
Ultra Monkey was used on many of the server setups sold by VA Linux
and presumably made lots of money for them.
Ultra Monkey has been around since 2000 and is mature and stable.
Questions about Ultra Monkey are answered on the LVS mailing list.
Ultra Monkey is mentioned in many places in the LVS-HOWTO.
	</para>
	<para>
Ben Hollingsworth <emphasis>ben (dot) hollingsworth (at) bryanlgh (dot) org</emphasis> 29 Jun 2007
	</para>
	<para>
There's step by step instructions on 
<ulink url="http://www.jedi.com/obiwan/technology/ultramonkey-rhel4.html">
How to install Ultra Monkey LVS in a 2-Node HA/LB Setup on CentOS/RHEL4
</ulink>
(http://www.jedi.com/obiwan/technology/ultramonkey-rhel4.html).
	</para>
	<para>
Dan Thagard <emphasis>daniel (at) gehringgroup (dot) com</emphasis> 3 Jul 2007 
	</para>
	<para>
I recently setup LVS using the Ultramonkey RPMs.  
The following is a (based on my understanding) complete howto for setting up CentOS 5 with LVS:
Generic CentOS 5 x64 Install on 2 PCs using Ultramonkey and Streamlined/HA topology with Apache
The following assumptions were made:
	</para>
	<itemizedlist>
		<listitem>
Real Server names are ws01.testlab.local and ws02.testlab.local 
(replace these with the result from uname -n from each RS) 
		</listitem>
		<listitem>
Real Server IPs are 10.0.0.10/24 and 10.0.0.20/24, 
		</listitem>
		<listitem>
Gateway: 10.0.0.1
		</listitem>
		<listitem>
Virtual IP: 10.0.0.100
		</listitem>
		<listitem>
Username: tester
		</listitem>
	</itemizedlist>
	<orderedlist>
		<listitem>
      Power PC and insert CD during BIOS.
		</listitem>
		<listitem>
      Boot to CD.
		</listitem>
		<listitem>
      Hit 'Enter' for Graphical Installer.
		</listitem>
		<listitem>
      You will be prompted to test the installation media.  
You may choose to test the media or skip the test (usually you can skip this step).
		</listitem>
		<listitem>
      Click 'Next' to begin installation.
		</listitem>
		<listitem>
      Select 'English' as installation language and click 'Next'.
		</listitem>
		<listitem>
      Select 'U.S. English' as the keyboard configuration and click 'Next'.
		</listitem>
		<listitem>
      Select 'Remove all partitions on selected drivers and create default layout' and click 'Next'.
		</listitem>
		<listitem>
		<para>
      Configure the network settings for each adapter.
		</para>
		<itemizedlist>
			<listitem>
a.      Click 'Edit'.
			</listitem>
			<listitem>
i.      Uncheck Configure using DHCP
			</listitem>
			<listitem>
ii.     Input the IP Address and Netmask.
			</listitem>
			<listitem>
iii.    Click 'OK'.
			</listitem>
			<listitem>
b.      Input the Gateway and DNS and click 'Next'.
			</listitem>
		</itemizedlist>
		</listitem>
		<listitem>
     Select 'America/ New York' and click 'Next'.
		</listitem>
		<listitem>
     Enter the root password twice and click 'Next'.
		</listitem>
		<listitem>
			<para>
     Select the system packages
			</para>.
			<itemizedlist>>
				<listitem>
a.      Check 'Desktop-Gnome', 'Server', 'Server-GUI', 'Clustering', 'Storage Clustering'
				</listitem>
				<listitem>
b.      Select 'Customize Now'
				</listitem>
				<listitem>
c.      Click 'Next'.
				</listitem>
			</itemizedlist>
		</listitem>
		<listitem>
			<para>
     Configure the system packages.
			</para>
			<itemizedlist>
				<listitem>
a.      Expand and click 'Details' on Desktop Environments->GNOME Desktop Environment.
				</listitem>
				<listitem>
i.      Uncheck 'desktop-printing', 'dvd+rw tools', 'esc', 'gimp-print-utils', 'gnome-audio', 'gnome-backgrounds', 'gnome-mag', 'gnome-pilot', 'gnome-themes', 'gok', and 'nautilus-cd'
				</listitem>
				<listitem>
b.      Expand Servers.
				</listitem>
				<listitem>
i.      Uncheck 'DNS', 'Legacy Network Server', 'Mail Server', 'Network Servers', 'News', and 'Printing Support'
				</listitem>
				<listitem>
c.      Expand Base System.
				</listitem>
				<listitem>
i.      Uncheck 'Dialup Networking Support'
				</listitem>
				<listitem>
d.      Expand and click 'Details' on Base System->Base.
				</listitem>
				<listitem>
i.      Uncheck 'bluez-utils' and 'ccid'
				</listitem>
				<listitem>
e.      Click 'Next'
				</listitem>
			</itemizedlist>
		</listitem>
		<listitem>
     Click 'Next' to begin copying over the files.
		</listitem>
		<listitem>
     Remove DVD and click 'Reboot' to reboot the machine after installation.
		</listitem>
		<listitem>
			<para>
     Set firewall to 'Disabled' and click 'Forward'.
			</para>
		<itemizedlist>
			<listitem>
     Click 'Yes' on pop-up.
			</listitem>
		</itemizedlist>
		</listitem>
		<listitem>
     Set SELinux to 'Disabled' and click 'Forward'.
		</listitem>
		<listitem>
     Select the 'Network Time Protocol' tab, check 'Enable Network Time Protocol', and click 'Forward'.
		</listitem>
		<listitem>
     Enter tester in the username field, 'Test User' in the Full name field, type in the password twice, and click 'Forward'.
		</listitem>
		<listitem>
     Click 'Forward' to skip the audio test.
		</listitem>
		<listitem>
     Click 'Finish' to complete the installation routine.
		</listitem>
		<listitem>
     Login to the local system using the root username and password.
		</listitem>
		<listitem>
			<para>
     Edit the '/etc/group' file
			</para>
<programlisting><![CDATA[
vi /etc/group
]]></programlisting>
		<itemizedlist>
			<listitem>
a.      Locate the user 'tester' and append 'wheel' (i to insert, [ESC] to stop editing).
			</listitem>
			<listitem>
b.      Save the file and exit by typing ':wq'.
			</listitem>
		</itemizedlist>
		</listitem>
		<listitem>
     Leave the server, goto your PC and SSH into the server (<emphasis>e.g.</emphasis> PuTTY)
		</listitem>
		<listitem>
     Login as user 'tester'
		</listitem>
		<listitem>
		<para>
     Su to root
		</para>
<programlisting><![CDATA[
su -
]]></programlisting>
		</listitem>
		<listitem>
			<para>
     Install the dries yum repository by creating dries.repo in the /etc/yum.repo.d/ directory with the following contents
			</para>
<programlisting><![CDATA[
[/etc/yum.repo.d/dries.repo]
[dries]
name=Extra Fedora rpms dries - $releasever \
- $basearch baseurl=http://ftp.belnet.be/packages/dries.ulyssis.org/redhat/el5/en/x86_64/dries/RPMS
]]></programlisting>
		</listitem>
		<listitem>
			<para>
     Install the dries GPG key
			</para>
<programlisting><![CDATA[
rpm --import http://dries.ulyssis.org/rpm/RPM-GPG-KEY.dries.txt
]]></programlisting>

		</listitem>
		<listitem>
			<para>
     Update your local packages and install some additional ones
			</para>
<programlisting><![CDATA[
yum update -y && yum -y install lynx libawt xorg-x11-deprecated-libs nx freenx arptables_jf httpd-devel
]]></programlisting>

		</listitem>
		<listitem>
			<para>
     Correct release version
			</para>
<programlisting><![CDATA[
mv /etc/redhat-release /etc/redhat-release.orig && \
echo "Red Hat Enterprise Linux Server release 5 (Tikanga)" > /etc/redhat-release
]]></programlisting>

		</listitem>
		<listitem>
     Download the Ultramonkey RPMs from http://www.ultramonkey.org (also grab perl-MAIL-POP3Client, available from http://rpm.pbone.net/index.php3/stat/4/idpl/4508518/com/perl-Mail-POP3Client-2.17-1.el5.centos.noarch.rpm.html as of the time of this writing)
		</listitem>
		<listitem>
			<para>
     Install the <filename>arptables-noarp-addr</filename> and <filename>perl-Mail-POP3Client</filename> RPMs 
(change the cd path to wherever you downloaded Ultramonkey to)
			</para>
<programlisting><![CDATA[
cd /usr/local/src/Ultramonkey && rpm -Uvh arptables-noarp-addr-0.99.2-1.rh.el.um.1.noarch.rpm && \
rpm -Uvh perl-Mail-POP3Client-2.17-1.el5.centos.noarch.rpm
]]></programlisting>
		</listitem>
		<listitem>
			<para>
    Install Ultramonkey
			</para>
<programlisting><![CDATA[
yum install -y heartbeat*
]]></programlisting>
		</listitem>
		<listitem>
			<para>
     Download and edit the Ultramonkey config files that relate your desired topology from 
http://www.ultramonkey.org to the /etc/ha.d/ directory 
and edit them to meet your desired configuration.  
Examples as follows:
			</para>
<programlisting><![CDATA[
[/etc/ha.d/authkeys]
auth 2
2 sha1 Ultramonkey!

[/etc/ha.d/ha.cf]
logfacility     local0
mcast eth0 225.0.0.1 694 1 0
auto_failback off
node    ws01.testlab.local
node    ws02.testlab.local
ping 10.0.0.1
respawn hacluster /usr/lib64/heartbeat/ipfail
apiauth ipfail gid=haclient uid=hacluster

[/etc/ha.d/haresources]
ws01.testlab.local      \
        ldirectord::ldirectord.cf \
        LVSSyncDaemonSwap::master \
        IPaddr2::10.0.0.100/24/eth0/10.0.0.255

[/etc/ha.d./ldirector.cf]
checktimeout=10
checkinterval=2
autoreload=yes
logfile="/var/log/ldirectord.log"
quiescent=no
# Virtual Service for HTTP
virtual=10.0.0.100:80
        fallback=127.0.0.1:80
        real=10.0.0.10:80 gate
        real=10.0.0.20:80 gate
        service=http
        request="alive.html"
        receive="I'm alive!"
        scheduler=wrr
        persistent=1800
        protocol=tcp
          checktype=negotiate
# Virtual Service for HTTPS
virtual=10.0.0.100:443
        fallback=127.0.0.1:443
        real=10.0.0.10:443 gate
        real=10.0.0.20:443 gate
        service=https
        request="alive.html"
        receive="I'm alive!"
        scheduler=wrr
        persistent=1800
        protocol=tcp
          checktype=negotiate
]]></programlisting>
		</listitem>
		<listitem>
			<para>
     Set the permission on authkeys
			</para>
<programlisting><![CDATA[
chmod 600 /etc/ha.d/authkeys
]]></programlisting>
		</listitem>
		<listitem>
			<para>
     Start the httpd server
			</para>
<programlisting><![CDATA[
httpd -k start
]]></programlisting>
		</listitem>
		<listitem>
			<para>
     Create <filename>alive.html</filename> in the <filename>/var/www/html</filename> 
folder with the following text (set this to whatever file you have set in the monitoring script)
			</para>
<programlisting><![CDATA[
I'm alive!
]]></programlisting>
			<para>
      Edit the <filename>/etc/hosts</filename> file to include the FQDN of all of the machines in your LVS 
(not strictly necessary, but it helps avoid problems)
			</para>
<programlisting><![CDATA[
# Do not remove the following line, or various programs # that require network functionality will fail.
127.0.0.1               localhost.localdomain localhost
10.0.0.10               ws01.testlab.local      ws01
10.0.0.20               ws02.testlab.local      ws02
::1             localhost6.localdomain6 localhost6
]]></programlisting>

		</listitem>
		<listitem>
			<para>
     Edit the <filename>/etc/sysconfig/network-scripts/ifcfg-lo</filename> file with your virtual IP
			</para>
<programlisting><![CDATA[
DEVICE=lo
IPADDR=127.0.0.1
NETMASK=255.0.0.0
NETWORK=127.0.0.0
BROADCAST=127.255.255.255
ONBOOT=yes
NAME=loopback

DEVICE=lo:0
IPADDR=10.0.0.100
NETMASK=255.255.255.255
NETWORK=10.0.0.0
BROADCAST=10.0.0.255
ONBOOT=yes
NAME=loopback
]]></programlisting>
		</listitem>
		<listitem>
			<para>
     Edit the <filename>/etc/sysconfig/network-scripts/ifcfg-eth0</filename> file to match this 
(edit the IP address for each director/real server, change from <filename>eth0</filename> 
to whatever active interface you are using):
			</para>
<programlisting><![CDATA[
[/etc/sysconfig/network-scripts/ifcfg-eth0 on ws01] \
DEVICE=eth0 ONBOOT=yes BOOTPROTO=static IPADDR=10.0.0.10 NETMASK=255.255.252.0 GATEWAY=10.0.0.1

[/etc/sysconfig/network-scripts/ifcfg-eth0 on ws02] \
DEVICE=eth0 ONBOOT=yes BOOTPROTO=static IPADDR=10.0.0.20 NETMASK=255.255.252.0 GATEWAY=10.0.0.1
]]></programlisting>
		</listitem>
		<listitem>
			<para>
     Restart the network
			</para>
<programlisting><![CDATA[
service network restart
]]></programlisting>
		</listitem>
		<listitem>
			<para>
     Enable packet forwarding and arp ignore in the /etc/sysctl.conf file
			</para>
<programlisting><![CDATA[
net.ipv4.ip_forward = 1
net.ipv4.conf.eth0.arp_ignore = 1
net.ipv4.conf.eth0.arp_announce = 2
net.ipv4.conf.all.arp_ignore = 1
net.ipv4.conf.all.arp_announce = 2
]]></programlisting>
		</listitem>
		<listitem>
			<para>
     Reparse the sysctl.conf file
			</para>
<programlisting><![CDATA[
/sbin/sysctl -p
]]></programlisting>
		</listitem>
		<listitem>
			<para>
     Make sure all services set to start at system boot.
			</para>
<programlisting><![CDATA[
chkconfig httpd on && chkconfig --level 2345 heartbeat on && chkconfig --del ldirectord
]]></programlisting>
		</listitem>
		<listitem>
			<para>
 Start the heartbeat service
			</para>
<programlisting><![CDATA[
/etc/init.d/ldirectord stop && /etc/init.d/heartbeat start
]]></programlisting>
		</listitem>
	</orderedlist>
	</section>
	<section id="setup_keepalived">
	<title>Keepalived</title>
	<para>
<ulink url="http://keepalived.sourceforge.net">Keepalived</ulink>
is written by Alexandre Cassen <emphasis>Alexandre (dot) Cassen (at) free (dot) fr</emphasis>, 
and is based on vrrpd for director failover.
Health checking for realservers is included.
It has a lengthy but logical conf file and sets up an LVS for you.
Alexandre released code for this in late 2001.
There is a keepalived mailing list and Alexandre also monitors the LVS mailing list
(May 2004, most of the postings have moved to the keepalived mailing list).
The LVS-HOWTO has some information about
<ulink url="LVS-HOWTO.failover.html#keepalived_vrrpd">Keepalived</ulink>.
	</para>
	</section>
	<section id="ipvsadmd">
       	<title>ipvsman(d)</title>
	<para>
Volker Jaenisch <emphasis>volker (dot) jaenisch (at) inqbus (dot) de</emphasis> 2007-07-04
	</para>
	<para>
http://sourceforge.net/projects/ipvsman/
	</para>
	<para>
ipvsman is a curses based GUI to the IPVS loadbalancer written in python.
ipvsmand is a monitoring instance of ipvs to achive the desired state
of the loadbalancing as ldirectord or keepalived do.
	</para>
	<itemizedlist>
		<listitem>
 ipvsman/d now comes with tcp regular expression chat to check any
tcp-service you can imagine
		</listitem>
		<listitem>
Sorry-Servers can be checked for their avability.
		</listitem>
		<listitem>
Fedora 7 packages are contributed by Gerry Reno.
		</listitem>
	</itemizedlist>
	</section>
	<section id="soekris">
       	<title>Alternate hardware: Soekris (and embedded hardware)</title>
	<para>
Clint Byrum <emphasis>cbyrum (at) spamaps (dot) org</emphasis> 27 Sep 2004
	</para>
	<blockquote>
		<para>
I'd like to setup a two node Heartbeat/LVS load balancer using Soekris
Net4801 machines. These have a 266Mhz Geode CPU, 3 Ethernet, and 128MB
of RAM. The OS (probably LEAF) would live on a CF disk. If these are
overkill, I'd also consider a Net4501, which has a 133Mhz CPU, 64MB RAM,
and 3 ethernet.
		</para>
		<para>
I'd need to balance about 300 HTTP requests per second, totaling about
150kB/sec, between two servers. I'm doing this now with the servers
themselves (big dual P4 3.02 Ghz servers with lots and lots of RAM).
This is proving problematic as failover and ARP hiding are just a major
pain. I'd rather have a dedicated LVS setup.
		</para>
		<para>
1) anybody else doing this?
		</para>
		<para>
2) IIRC, using the DR method, CPU usage is not a real problem because
reply traffic doesn't go through the LVS boxes, but there is some RAM
overhead per connection. How much traffic do you guys think these should
be able to handle? 
		</para>
	</blockquote>
	<para>		
Ratz 28 Sep 2004 
	</para>
	<para>
The Net4801 machines are horribly slow but for your purpose enough. 
The limiting factor on those 
boxes are almost always the cache sizes. I've waded through too many 
processor sheets of those Geode derivates to give your specific details 
on your processor but I would be surprised if it had more than 16kb 
i/d-cache each.
	</para>
	<blockquote>
16k unified cache. :-/
	</blockquote>
	<para>
Make sure that your I/O rate is as low as possible or the first thing to 
blow is your CF disk. I've worked with hundreds of those little boxes in 
all shapes, sizes and configurations. The biggest common mode failures 
were CF disk due to temperature problems and I/O pressure (MTTF was 23 
days); other problems only showed up in really bad NICs locking up half 
of the time.
	</para>
	<blockquote>
I haven't ever had an actual CF card blow on me. LEAF is made to live on
readonly media.. so its not like it will be written to a lot.
	</blockquote>
	<para>
Sorry, blow is exaggerated, I mean they simply fail because they only 
have limited write capacity on the cells.
	</para>
	<para>
RO doesn't mean that there's no I/O going to your disk as you correctly 
noted. The problem is that if you plan on using them 24/7 I suggest you 
monitor your block I/O on your RO partitions using the values from 
/proc/partitions or the wonderful iostat tool. Then extrapolate about 4 
hours worth of samples, check your CF vendor specification on how many 
writes it can endure and see how long you can expect the thing to run.
	</para>
	<para>
I have to add that thermal issues were adding to our high failure rates. 
We wanted to ship those little nifty boxes to every branch of a big 
customer to do a big VPN network. Unfortunately the customer is in the 
automobile industry and this means that those boxes were put in the 
stranges places imaginable in garages sometimes causing major heat 
congestion. Also as it is usual in this sector of industry people are 
used to reliable hardware and so they don't care if at the end of a 
working day they simply shut down the power of the whole garage. 
Needless to say that this adds up to the reduced lifetime of a CF.
	</para>
	<para>
I then did a reliability analysis using the MGL (multiple greek letter, 
derived from the beta-factor model) model to calculate the average risk 
in terms of failure*consequence and we had to refrain from using those 
little nifty things. The costs of repair (detection of failure -> 
replacement of product) at a customer would exceed the income our 
service provided through a mesh of those boxes.
	</para>
	<blockquote>
If these are
overkill, I'd also consider a Net4501, which has a 133Mhz CPU, 64MB RAM,
and 3 ethernet.
	</blockquote>
	<para>
I'd go with the former ones, just to be sure ;).
	</para>
	<blockquote>
Forgive me for being frank, but it sounds like you wouldn't go with
either of them.
	</blockquote>
	<para>
I don't know your business case so it's very difficult to give you a 
definite answer. I only give you an (somewhat intimidating) experience 
report, someone might just as well give you a much better report.
	</para>
	<blockquote>
I'd need to balance about 300 HTTP requests per second, totaling about
150kB/sec, between two servers.
	</blockquote>
	<para>
So one can assume a typical request to your website is 512 Bytes, which 
is rather quite high. But not really an issue for LVS-DR.
	</para>
	<blockquote>
I didn't clarify that. The 150kB/sec is outgoing. This isn't for all of
the website, just the static images/html/css.
	</blockquote>
	<blockquote>
I'm doing this now with the servers
themselves (big dual P4 3.02 Ghz servers with lots and lots of RAM).
This is proving problematic as failover and ARP hiding are just a major
pain. I'd rather have a dedicated LVS setup.
	</blockquote>
	<para>
I'd have to agree to this.
	</para>
	<blockquote>
1) anybody else doing this?
	</blockquote>
	<para>
Maybe. Stupid questions: How often did you have to failover and how 
often did it work out of the box?
	</para>
	<blockquote>
Maybe once every 2 or 3 months I'd need to do some maintenance and
switch to the backup. Every time there was some problem with noarp not
coming up or some weird routing issue with the IPs. Complexity bad. :)
	</blockquote>
	<para>
So frankly speaking: your HA solution didn't work as expected ;).
	</para>
	<blockquote>
2) IIRC, using the DR method, CPU usage is not a real problem because
reply traffic doesn't go through the LVS boxes, but there is some RAM
overhead per connection. How much traffic do you guys think these should
be able to handle? 
	</blockquote>
	<para>
This is very difficult to say since these boxes impose limits also 
through their inefficiant PCI busses, their rather broken NICs and the 
dramatically reduced cache. Also it would be interesting to know if 
you're planning on using persistency on your setup.
	</para>
	<blockquote>
Persistency is not a requirement. Note that most of the time a client
opens a connection once, and keeps it up as long as they're browsing
with keepalives.
	</blockquote>
	<para>
Yes, provided most clients use HTTP/1.1. But since on an application 
level you don't need persistency.
	</para>
	<para>
But to give you a number to start with, I would say those boxes should 
be able (given your constraints) to sustain 5Mbit/s of traffic with 
about 2000pps (~350 Bytes/packet) and only consume 30 Mbyte of your 
precious RAM when running without persistency. This is if every packet 
of your 2000pps is a new client requesting a new connection to the LVS 
and will be inserted by the template at an average of 1 Minute.
	</para>
	<para>
As mentioned previously, you HW configuration is very hard to compare to 
actual benchmarks, thus take those numbers with a grain of salt, please.
	</para>
	<blockquote>
Thats not encouraging. I need something fairly cheap.. otherwise I might
as well go down the commercial load balancer route. 
	</blockquote>
	<para>
Well, I have given you number which are (at a second look) rather low 
estimates ;). Technically, your system should be able to deliver 
25000pps (yes, 25k) at a 50Mbit/s rate. You would then, if every packet 
was a new client, consume about all the memory of your system :). So 
somewhere in between those two numbers I would place the performance of 
your machine.
	</para>
	<para>
Bubba Parker <emphasis>sysadmin (at) citynetwireless (dot) net</emphasis> 27 Sep 2004
	</para>
	<para>
In my tests, the Soekris net4501, 4511, and 4521 all were able to route almost 20Mbps at wire-speed.
I would suspect the 4801 to be in excess of 50Mbps, 
but remember, your Soekris board has 3 nics, 
but what they don't tell you is that they all share the same interrupt, 
so performance degredation is exponential with many packets per second.
	</para>
	<para>
Ratz 28 Sep 2004
	</para>
	<para>
For all Geode based boards I've received more technical documentation 
than I was ever prepared to dive in. Most of the time you get a very 
accurate depiction of your hardware including south and north bridges 
and there you can see that the interrupt lines are hardwired and require 
a interrupt sharing.
	</para>
	<para>
However this is not a problem since there's not a lot of devices on the 
bus anyway that would occupy it and if you're really unhappy about the 
bus speed, use setpci to reduce latency for the NIC's IRQs.
	</para>
	<para>
Newer kernels have excellent handling for shared IRQs btw.
	</para>
	<para>
Did you measure exponential degradation? I know you get a pretty steep performance 
reduction once you push the pps too high but I newer saw exponential 
behaviour.
	</para>


	<para>
Peter Mueller 2004-09-27 
	</para>
	<blockquote>
What about not using these Soekris's and just using those two beefy servers?
e.g.,  http://www.ultramonkey.org/2.0.1/topologies/ha-overview.html or
 http://www.ultramonkey.org/2.0.1/topologies/sl-ha-lb-overview.html
	</blockquote>
	<para>
Clint Byrum 27 Sep 2004
	</para>
	<para>
Thats what I'm doing now. The setup works, but its complexity causes
issues. Bringing up IPs over here, moving them from eth0 to lo over
there, running noarpctl on that box. Its all very hard to keep track of.
Its much simpler to just have two boxes running LVS, and not worry about
whats on the servers.
	</para>
	<para>
Simple things are generally easier to fix if they break. It took me
quite a while to find a simple typo in a script on my current setup,
because it was very non-obvious at what layer things were failing.
	</para>
	</section>
	<section id="turnbull">
       	<title>LVS on a CD: Malcolm Turnbull's ISO files</title>
       	<para>
Malcolm Turnbull <emphasis>Malcolm (dot) Turnbull (at) crocus (dot) co (dot) uk</emphasis>
03 Jun 2003, has released a Bootable ISO image of his Loadbalancer.org appliance software.
The link was at
http://www.loadbalancer.org/modules.php?name=Downloads&amp;d_op=viewdownload&amp;cid=2
but is now dead (Dec 2003).
Checking the website (Apr 2004) I find that the code is available as a
30 day demo
(http://www.loadbalancer.org/download.html, link dead Feb 2005).
	</para>
	<para>
Here's the original blurb from Malcolm
	</para>
	<blockquote>
       		<para>
The basic idea is creating an easy to use layer 4 switch appliance to
compete with Coyote Point Equalizer/ CISCO local director...
All my source code is GPL, but the ISO distribution contains
files that are non-GPL to protect the work and allow vendors to licence the software.
The ISO requires a license before you can legally use it in production.
       		</para>
       		<para>
Burn it to CD and then use it to boot a spare server with
pentium/celeron + ATAPI CD + 64MB RAM + 1 or 2 NICs+20GB HD
       		</para>
<programlisting><![CDATA[
root password is : loadbalancer
ip address is : 10.0.0.21/255.255.0.0
web based login is : loadbalancer
web based password is : loadbalancer
]]></programlisting>
       		<para>
Default setup is DR so just plug it straight into the same hub as your
web servers and have a play..
Download the manuals for configuration info...
       		</para>
	</blockquote>
	</section>
</section>
<section id="LVS-HOWTO.ipvsadm" xreflabel="ipvsadm and schedulers">
<title>LVS: Ipvsadm and Schedulers</title>
<para>
<command>ipvsadm</command> is the user code interface to LVS. 
The scheduler is the part of the ipvs
kernel code which decides which realserver will get the next new connection.
</para>
<para>
There are patches for ipvsadm
</para>
<itemizedlist>
	<listitem>
<link linkend="Padraig">machine readable error codes for ipvsadm</link>
	</listitem>
	<listitem>
<link linkend="stateless_ipvsadm">stateless entry of <command>ipvsadm</command> commands</link>
	</listitem>
	<listitem>
		<para>
Mar 2004. There appears to have been introduced a bug in the wrr code. 
Presumably this will be fixed sometime in the main code, and presumably
older versions of <filename>ipvs</filename> still work (but I don't 
know how far back you need to go, presumably to the 2.4 kernels).
Here are some postings on the matter and links to a patch.
		</para>
		<para>
Jan Kasprzak <emphasis>kas (at) fi (dot) muni (dot) cz</emphasis> 2005/03/25
		</para>
		<blockquote>
			<para>
port unreachable after RS removal:
			</para>
			<para>
   I use IPVS with direct routing and wrr scheduler. The problem is
that for some configurations I get "icmp port unreachable" when one of the
real servers fails and is removed from the ip_vs tables. 
The smallest case where I can
replicate the problem is the following:
			</para>
<programlisting><![CDATA[
ipvs# ipvsadm -A -t virtual.service:http -s wrr
ipvs# ipvsadm -a -t virtual.service:http -r realserver1:http -w 100
ipvs# ipvsadm -a -t virtual.service:http -r realserver2:http -w 1000

client$ wget -O - http://virtual.service/
[works as expected]

ipvs# ipvsadm -d -t virtual.service:http -r realserver2

client$ wget -O - http://virtual.service/
--14:46:29--  http://virtual.service/
           => `-'
Resolving virtual.service... 1.2.3.4
Connecting to virtual.service[1.2.3.4]:80... failed: Connection refused.
]]></programlisting>
			<para>
   I have verified by tcpdump that no traffic is sent to realserver2
after it is removed from the virtual.service pool. The ICMP "tcp port
unreachable" is sent by the ipvs director.
This appears to be a problem in the wrr scheduler. With wlc or rr
it works as expected.
The director is Fedora Core 3 with vanilla 2.6.11.3 kernel,
but I have been experiencing this for a longer time.
			</para>
		</blockquote>
		<para>
Sent by: lvs-users-bounces@LinuxVirtualServer.org 2005/03/26
		</para>
		<para>	
This is exactly the problem I described in my previous mails, 
and for which a patch is available from Wensong and/or Horms.
Search the mailinglist archive for 'overload flag not
resetting' which was my initial (wrong) diagnosis.
See
		</para>
<programlisting><![CDATA[
http://marc.theaimsgroup.com/?l=linux-virtual-server&m=110604584821192&w=2

and the (inital) patch:
http://marc.theaimsgroup.com/?l=linux-virtual-server&m=110749794000222&w=2
]]></programlisting>
	</listitem>
</itemizedlist>
	<section id="using_ipvsadm">
	<title>Using ipvsadm</title>
	<para>
You use <command>ipvsadm</command> from the command line (or in rc files) to setup: -
	</para>
	<itemizedlist>
		<listitem>
services/servers that the director directs
(<emphasis>e.g.</emphasis> http goes to all realservers,
while ftp goes only to one of the realservers).
		</listitem>
		<listitem>
			<para>
weighting given to each realserver - useful if some servers
are faster than others.
			</para>
			<para>
Horms 30 Nov 2004
			</para>
			<para>
The weights are integers, but sometimes they are assigned to an
atomic_t, so they can only be 24bits <emphasis>i.e.</emphasis>
values so 0 to (2^24-1) should work.
			</para>
		</listitem>
		<listitem>
		<link linkend="scheduler">scheduling algorithm</link>
		</listitem>
	</itemizedlist>
	<para>
You use can also use <command>ipvsadm</command> to
	</para>
	<itemizedlist>
		<listitem>
		add services: add a service with weight &gt;0
		</listitem>
		<listitem>
		shutdown (or quiesce) services: set the weight to 0.
		<para>
This allows current connections to continue,
untill they disconnect or expire,
but will not allow new connections.
When there are no connections remaining,
you can bring down the service/realserver.
		</para>
		</listitem>
		<listitem>
delete services: this stops traffic for the service (the connection will hang),
but the entry in the connection table is not deleted till it times out.
This allows deletion, followed shortly thereafter by adding back the service,
to not affect established (but quiescent) connections.
		</listitem>
		<listitem>
			<para>
		Once you have a working LVS, save the 
<command>ipsvadm</command> settings with <command>ipvsadm-sav</command>
<programlisting><![CDATA[
$ipvsadm-sav > ipvsadm.sav
]]></programlisting>
			</para>
			<para>
		and then after reboot, 
restore the <command>ipvsadm</command> settings, with ipvsadm-restore
<programlisting><![CDATA[
$ipvsadm-restore < ipvsadm.sav
]]></programlisting>
			</para>
			<para>
Both of these commands can be part of an <command>ipvsadm</command> init script.
			</para>
		</listitem>
		<listitem>
		list version of ip_vs (here 0.9.4, with a hash table size of 4096)
<programlisting><![CDATA[
director:/etc/lvs# ipvsadm
IP Virtual Server version 0.9.4 (size=4096)
]]></programlisting>
		</listitem>
		<listitem>
		list version of <command>ipvsadm</command> (here 1.20)
<programlisting><![CDATA[
director:/etc/lvs# ipvsadm --version
director:/etc/lvs# ipvsadm v1.20 2001/09/18 (compiled with popt and IPVS v0.9.4)
]]></programlisting>
		</listitem>
</itemizedlist>
	</section>
	<section id="memory_requirements">
	<title>Memory Requirements</title>
	<para>
On the director, the entries for each connection are stored in a hash table 
(number of buckets set when compiling <filename>ipvsadm</filename>). Each
entry takes 128 bytes. 
Even large numbers of connections will use only a small amount of memory.
	</para>
	<blockquote>
We would like to use LVS in a system where 700Mbit/s traffic is flowing
through it. Concurrent connection number is about 420.000   . Our main
purpose for using LVS is to direct 80. port requests into number of squid
servers (~80 servers)
I have read performance documents and I just wonder I can handle this much
of traffic with a 2x3.2 Xeon  and 4GB of RAM of hardware.
	</blockquote>
	<para>
Ratz 22 Nov 2006 
      	</para>
	<para>
If you use LVS-DR and your squid caches have a moderate hit rate, the amount
of RAM you'll need to load balance 420'000 connections is:
	</para>
<programlisting><![CDATA[
420000 x 128 x [RTTmin up to RTTmin+maxIdleTime] [bytes]
]]></programlisting>
	<para>
This means with 4GB and a standard 3/1GB split (your Xeon CPU is 32bit only
with 64bit EMT) in the 2.6 kernel (I take it as 3000000000 Bytes), you will
be able to serve half a million parallel connections, each connection
lasting at most 3000000000/(500000*128) [secs] = 46.875 secs.
	</para>
	</section>
	<section id="sysctl documentation">
	<title>sysctl documentation</title>
	<para>
the <filename>sysctl</filename> for ipvs will be in 
<filename>Documentation/networking/ipvs-sysctl.txt</filename> for 2.6.18 (hopefully).
It is derived from http://www.linuxvirtualserver.org/docs/sysctl.html v1.4.
	</para>
	<para>
Graeme Fowler <emphasis>graeme (at) graemef (dot) net</emphasis> 08 Mar 2007
	</para>
	<para>
A couple of times recently people have posted to the keepalived list or
the LVS list about different issues which were resolved by toggling
sysctls (most recently expire_quiescent_template - see <xref linkend="new_persistence"/>).
This got me thinking: these sysctls are pretty important, and not
everyone knows what to do with them (or how to change them) since the
recommended ways to modify them can vary between distributions.
So, why not give ipvsadm the capability to modify appropriate sysctls
found in <filename>/proc/sys/net/ipv4/vs/</filename>?
The more I thought about it, the more I considered that the easiest way
to do so would be to use a "generic" option along the lines of the
e2fsprogs style "-O option,option,option=value" with "^option" as a
negation for booleans.
So you'd be able to say:
	</para>
<programlisting><![CDATA[
ipvsadm -O expire_quiescent_template,expire_nodest_conn
ipvsadm -O expire_nodest_conn
ipvsadm -O drop_packet=1,drop_entry=1,expire_nodest_conn
]]></programlisting>
	<para>
By making the option handler "generic" like this, as other sysctls
arrive as the kernel develops they can simply be toggled or changed as
necessary; in all cases, where no corresponding sysctl exists, an error
is thrown to that effect.
In my mind it makes ipvsadm more of a "one stop shop" for the various
settings - not only will it manage the virtual and real servers, but more
of the underlying infrastructure too.
	</para>
	<para>
Ratz  08 Mar 2007
	</para>
	<para>
I tend to agree, however people that want to setup LVS do need to know Linux
on the level of also understanding sysctrl variables and their meaning. I've
always hoped that with having them in the <command>ipvsadm</command> man page, the problem
would be solved.
I know only of one application that modifies sysctls, and this is
the broken pluto of Free/OpenSwan :).
	</para>
	<para>
You still have to know what the options mean, correct? I favour a
different approach more: Make LVS really user friendly, in that you provide
the users with a tool that takes away the low level configuration, just like
in linux-ha or commercial load balancers. It's not so difficult to write
this, it's just that someone has to sit down and do it.
	</para>
	<para>
You still need to absolutely know the semantics of these settings. So what
is the real gain between
	</para>
<programlisting><![CDATA[
   ipvsadm -O expire_quiescent_template=1

and

   echo 1 > /proc/sys/net/ipv4/vs/expire_quiescent_template
]]></programlisting>

	<para>
Horms
	</para>
	<para>
Of late I've been thinking of the idea of enabling LVS to be configured
via netlink rather than the current /proc + get/setsockopt fun.
I think this was Ratz idea, but it seems like a good one to me,
as it should allow a lot more flexibility in the user-space to kernel
communication, which has always been a problem from the point
of backwards compatibility. So I have kind of been thinking of ipvsadm2
or ipvsadm-nl.
	</para>
	<para>
Ratz
	</para>
	<para>
I've already started once with the conversion of IPVS to netlink and I've
named the new ipvsadm ipvsctl :). I've attached my work (actually the part I
could find right now ... I know on some of my dozens of crashed Laptop
harddisks there should be more) in this email, so it doesn't get lost and
you don't have to duplicate it. This would also allow us to easily implement
the missing features and enable us to move more towards
netfilter-friendliness.
	</para>
	</section>
	<section id="ipvs_kernel_match">
	<title>Compile a version of ipvsadm that matches your ipvs</title>
	<para>
Compile and install <command>ipvsadm</command> on the
director using the supplied Makefile. You can optionally compile ipvsadm
with popt libraries, which allows <command>ipvsadm</command> to handle more complicated
arguments on the command line.
If your <filename>libpopt.a</filename> is too old, your <command>ipvsadm</command> will segv.
(I'm using the dynamic libpopt and don't have this problem).
	</para><para>
Since you compile <filename>ipvs</filename> and <command>ipvsadm</command> independantly and
you cannot compile <command>ipvsadm</command> until you have patched the kernel headers,
a common mistake is to compile the kernel and reboot, forgetting to
compile/install ipvsadm.
	</para><para>
Unfortunately there is only rudimentary version detection code into ipvs/ipvsadm.
If you have a mismatched ipvs/<command>ipvsadm</command> pair,
many times there won't be problems, as any particular
version of <command>ipvsadm</command> will work with a wide range of patched kernels.
Usually with 2.2.x kernels,
if the ipvs/<command>ipvsadm</command> versions mismatch, you'll get weird but non-obvious
errors about not being able to install your LVS. Other possibilities are
that the output of <command>ipvsadm</command> -L will have IP's that are clearly not IPs (or
not the IP's you put in) and ports that are all wrong. It will look something
like this
	</para>
<programlisting><![CDATA[
[root@infra /root]# ipvsadm
IP Virtual Server version 1.0.4 (size=3D4096)
Prot LocalAddress:Port Scheduler Flags
  -> RemoteAddress:Port Forward Weight ActiveConn InActConn
TCP  C0A864D8:0050 rr
  -> 01000000:0000      Masq    0      0          0
]]></programlisting>
	<para>
rather than
	</para>
<programlisting><![CDATA[
director:/etc/lvs# ipvsadm
IP Virtual Server version 0.9.4 (size=4096)
Prot LocalAddress:Port Scheduler Flags
  -> RemoteAddress:Port           Forward Weight ActiveConn InActConn
TCP  lvs2.mack.net:ssh rr
  -> RS2.mack.net:ssh             Route   1      0          0
]]></programlisting>
	<para>
There was a change in the /proc file system for
ipvs about 2.2.14 which caused problems
for anyone with a mismatched ipvsadm/ipvs.
The <command>ipvsadm</command> from different kernel series (2.2/2.4) do not
recognise the ipvs kernel patches from the other series (they appear to
not be patched for ipvs).
	</para><para>
The later 2.2.x ipvsadms know the minimum version of ipvs that they'll run on,
and will complain about a mismatch.
They don't know the maximum version
(which will be produced presumably some time in the future)
that they will run on.
This protects you against the unlikely event of installing a new 2.2.x version of
director:/etc/lvs# ipvsadm on an older version of ipvs, but will not protect you against the
more likely scenerio where you forget to compile <command>ipvsadm</command> after building your kernel.
The <command>ipvsadm</command> maintainers are aware of the problem.
Fixing it will break the current code and they're waiting
for the next code revision which breaks backward compatibility.
	</para><para>
If you didn't even apply the kernel patches for ipvs, then ipvsadm
will complain about missing modules and exit
(<emphasis>i.e.</emphasis> you can't even do `<command>ipvsadm -h</command>`).
	</para>
		<section id="other_compile_problems">
		<title>Other compile problems</title>
		<para>
Ty Beede <emphasis>tybeede (at) metrolist (dot) net</emphasis>
		</para>
		<blockquote>
		<para>
Ty Beede <emphasis>tybeede (at) metrolist (dot) net</emphasis>
on a slackware 4.0 machine I went to compile <command>ipvsadm</command> and it gave
me an error indicating that the iphdr type was undefined and
it didn't like that when it saw
		</para>
		<para>
Ty Beede <emphasis>tybeede (at) metrolist (dot) net</emphasis>
to <filename>ip_fw.h</filename> I added
		</para>
<programlisting><![CDATA[
#include <linux/ip.h>
]]></programlisting>
		<para>
Ty Beede <emphasis>tybeede (at) metrolist (dot) net</emphasis>
in ipvsadm.c, which is where the iphdr
#structure is defined and everything went ok
		</para>
		</blockquote>
		<para>
Doug Bagley <emphasis>doug (at) deja (dot) com</emphasis>
		</para>
		<para>
The reason that it fails "out of the box" is because fwp_iph's
type definition (struct iphdr) was
		</para>
<programlisting><![CDATA[
#ifdef'd out in <linux/ip_fw.h>
]]></programlisting>
		<para>
(and not included anywhere else) since the symbol __KERNEL_ was
undefined.
		</para>
<programlisting><![CDATA[
Including <linux/ip.h> before <linux/ip_fw.h>
]]></programlisting>
		<para>
in the .c file did the trick.
		</para>
		</section>
	</section>
	<section id="realservers_in_etc_hosts">
	<title>put realservers in /etc/hosts</title>
	<para>
(from a note by Horms 26 Jul 2002)
	</para>
	<para>
<filename>ipvsadm</filename> by default outputs the <emphasis>names</emphasis> 
of the realservers rather than the IPs.
The director then needs name resolution.
If you don't have it, 
<command>ipvsadm</command> will take a long time (upto a minute) to return,
as it waits for name resolution to timeout.
The only IPs that the director needs to resolve are of the realservers.
DNS is slow. To prevent the director from needing DNS,
put the names of the realservers in <filename>/etc/hosts</filename>.
This lookup is quicker than DNS and you won't need
to open a route from the director to a nameserver.
	</para>
	<para>
Or you could use `<command>ipvsadm -n</command>` which outputs the IPs
of the realservers instead.
	</para>
	</section>
	<section id="scheduler">
	<title>RR and LC schedulers</title>
	<para>
On receiving a connect request from a client, the director
assigns a realserver to the client based on a &quot;schedule&quot;.
The scheduler type is set with <command>ipvsadm</command>.
The schedulers available are
	</para>
	<itemizedlist>
		<listitem>
		round robin (rr), weighted round robin (wrr) - new
connections are assigned to each realserver in turn
		</listitem>
		<listitem>
		<para>
		least connected (lc), weighted least connection (wlc) - new
connections go to realserver with the least number of connections.
This is not neccessarily the least busy realserver, but is a step in
that direction.
		</para>
		<para>
		<note>
Doug Bagley <emphasis>doug (at) deja (dot) com</emphasis>
points out that *lc schedulers will not work properly 
if a particular realserver is used in two different LVSs.
		</note>
		</para>
		<para>
Willy Tarreau (in 
<ulink url="http://1wt.eu/articles/2006_lb/">
http://1wt.eu/articles/2006_lb/ Making applications scalable with Load Balancing</ulink>)
says that *lc is suited for very long sessions, 
but not for webservers where the load varies on a short time scale.
		</para>
		</listitem>
		<listitem>
		<xref linkend="LVS-HOWTO.persistent_connection"/>
		</listitem>
		<listitem>
		LBLC: a persistent memory algorythm
		</listitem>
		<listitem>
		DH: destination hash
		</listitem>
		<listitem>
		<para>
		SH: source hash
		</para>
		<para>
Again from Willy: this is used when you want a client to always appear on the same
realserver (<emphasis>e.g.</emphasis> a shopping cart, or database). 
The SH scheduler has not been much used in LVS,
possibly because no-one knew the syntax for a long time and couldn't get it to work.
Most shopping cart type servers are using persistence, 
which has many undesirable side effects.
		</para>
		</listitem>
	</itemizedlist>
	<para>
The original schedulers are rr, and lc (and their weighted versions).
Any of these will do for a test setup. In particular,
round robin will cycle connections
to each realserver in turn, allowing you to check that all
realservers are functioning in the LVS.
The rr,wrr,lc,wlc schedulers should all work similarly when
the director is directing identical realservers with identical services.
The lc scheduler will better handle situations where machines
are brought down and up again
(see <link linkend="thundering_herd">thundering herd problem</link>).
If the realservers are offering different services and some have clients
connected for a long time while others are connected for a short time,
or some are compute bound, while others are network bound,
then none of the schedulers will do a good job of distributing
the load between the realservers.
LVS doesn't have any load monitoring of the realservers.
Figuring out a way of doing this that will work for a range of different types
of services isn't simple (see <link linkend="agent">load and failure monitoring</link>).
	</para>
	<note>
		<para>
Ratz Nov 2006
		</para>
		<para>
After almost 10 years of my involvement with load balancers, 
I have to admit that no customer _ever_ truly asked or cared 
about the scheduling algorithm :). 
This is academia for the rest of the world.
		</para>
	</note>
	</section>
	<section id="netmask_for_VIP">
	<title>Netmask for VIP</title>
	<para>
You setup the RIPs, DIP and other networking with whatever netmask you
choose. For the VIP
	</para>
	<itemizedlist>
		<listitem>
For LVS-DR, LVS-Tun: netmask for VIP on director, realservers must be /32.
		</listitem>
		<listitem>
For LVS-NAT: the netmask can be /32 or the netmask of the RIPs, DIP.
		</listitem>
	</itemizedlist>
	<para>
You will need to setup the routing for the VIP to match the netmask.
For more details, see the chapters for each forwarding method.
	</para>
	<para>
Horms 12 Aug 2004 
	</para>
	<para>
The real story is that the netmask works a little differently
on lo to other interfaces. On lo the interface will answer to
_all_ addresses covered by the netmask. This is how 127.0.0.1/8 on
lo ends up answering 127.0.0.0-127.255.255.255. So if
you add 172.16.4.222/16 to eth0 then it will answer 172.16.4.222 and
only 172.16.4.222. But if you add the same thing to lo then it 
will answer 172.16.0.0-172.16.255.255. So you need to use
172.16.4.222/32 instead.
	</para>
	<para>
To clarify -
	</para>
<programlisting><![CDATA[
ifconfig eth0:0 192.168.10.10 netmask 255.255.255.0 broadcast 192.168.10.255 up
   -> Add 192.168.10.10 to eth0

ifconfig lo:0 192.168.10.10 netmask 255.255.255.0 broadcast 192.168.10.255 up
   -> Add 192.168.10.0 - 192.168.10.255 to lo

ifconfig lo:0 192.168.10.0 netmask 255.255.255.0 broadcast 192.168.10.255 up
   -> Same as above, add 192.168.10.0 - 192.168.10.255 to lo

ifconfig lo:0 192.168.10.10 netmask 255.255.255.255 broadcast 192.168.10.10 up
   -> Add 192.168.10.10 to lo
]]></programlisting>

	<para>
Malcolm Turnbull <emphasis>malcolm (at) loadbalancer (dot) org</emphasis> 2005/04/21
	</para>
	<para>
On all platforms apart from windows you want 255.255.255.255 for the 
loopback.
On windows you can get away with 255.255.255.0 IF you use a priority 254 
80% of the time.
255.255.255.255 can be used if you mod the registry...
But we've found that 255.0.0.0 will work better 99% of the time because 
windows by default uses the smallest subnet first for routing
and a class  A will never be used instead of a class C.
	</para>
	</section>
	<section id="DH">
	<title>LBLC, DH schedulers</title>
	<para>
The LBLC code (by Wensong) and the DH scheduler
(by Wensong, inspired by code submitted by Thomas Proell
<emphasis>proellt (at) gmx (dot) de</emphasis>)
are designed for web caching realservers
(<emphasis>e.g.</emphasis> squids).
For normal LVS services (eg ftp, http), the content
offered by each realserver is the same and it doesn't
matter which realserver the client is connected to.
For a web cache, after the first fetch has been made,
the web caches have different content.
As more pages are fetched, the contents of the web caches will diverge.
Since the web caches will be setup as peers,
they can communicate by ICP (internet caching protocol)
to find the cache(s) with the required page.
This is faster than fetching the page from the original webserver.
However, it would be better after the first fetch of a page
from http://www.foo.com/*, for all subsequent clients wanting a
page from http://www.foo.com/ to be connected to that realserver.
	</para>
	<para>
The original method for handling this was to make
connections to the realservers persistent,
so that all fetches from a client went to the same realserver.
	</para>
	<para>
The -dh (destination hash) algorythm makes a hash from the target IP
and all requests to that IP will be sent to the same realserver.
This means that content from a URL will not be retrieved
multiple times from the remote server.
The realservers (eg squids in this case)
will each be retreiving content from different URLs.
	</para>
	<para>
Wensong Zhang <emphasis>wensong (at) gnuchina (dot) org</emphasis> 16 Feb 2001
	</para>
	<para>
Please see "man ipvsadm" for short description of DH and SH
schedulers. I think some examples to use those two schedulers.
	</para>
	<para>
Example:  cache cluster shared by several load balancers.
	</para>
<programlisting><![CDATA[
		Internet
		|
                |------cache array
                |
		|-----------------------------
		   |                |
		   DH               DH
		   |                |
		 Access            Access
                 Network1          Network2
]]></programlisting>
	<para>
The DH scheduler can keep the two load balancer redirect requests
destined for the same IP address to the same cache server. If the server
is dead or overloaded, the load balancer can use cache_bypass feature to
send requests to the original server directly. (Make sure that the cache
servers are added in the two load balancers in the same order)
	</para>
	<para>
Diego Woitasen 12 Aug 2003
	</para>
	<blockquote>
The scheduling algorithms that use dest IP for selecting
the realserver to use (like DH, LBLC, LBLCR) is only aplicable to
transparent proxy, this being the only aplication where the dest ip
could be variable.
	</blockquote>
	<para>
Wensong Zhang <emphasis>wensong (at) linux-vs (dot) org</emphasis> 12 Aug 2003
	</para>
	<para>
Yes, you are almost right. LBLC and LBLCR are written for transparent
proxy clusters only. DH can be used for transparent proxy cluster and can
be used in other clusters needing static mapping.
	</para>
	<para>
	<note>
Here's follows a set of exchanges between a Chinese person and Wensong,
that were in English, that I didn't follow at all. Apparently it was
clear to Wensong.
	</note>
	</para>
	<blockquote>
If lblc uses dh, then is lblc = dh + lc?
	</blockquote>
	<para>
Wensong Zhang 09 Mar 2004
	</para>
	<para>
Maybe lblc = dh + wlc.
	</para>
<programlisting><![CDATA[
/*
 * The lblc algorithm is as follows (pseudo code):
 *
 *       if cachenode[dest_ip] is null then
 *               n, cachenode[dest_ip] <- {weighted least-conn node};
 *       else
 *               n <- cachenode[dest_ip];
 *               if (n is dead) OR
 *                  (n.conns>n.weight AND
 *                   there is a node m with m.conns<m.weight/2) then
 *                 n, cachenode[dest_ip] <- {weighted least-conn node};
 *
 *       return n;
 *
 */
]]></programlisting>

	<para>
	The difference between lblc and lblcr is that cachenode[dest_ip] in
lblc is a server, and cachenode[dest_ip] in lblcr is a server set.
	</para>
	<blockquote>
In lblc the server has overloaded and lvs use wlc and allocate a server in
half load of the server,
Allocate the weighted least-connection server to IP address.
Is this means after allocation for ip address, it will not return to past
server ?
	</blockquote>
	<para>
No, it will not in most cases. There is only one possible situation that
the current map expires after it is not used for six minutes, and the past
server is the one with least connections when next access to the ip
address comes.
	</para>
		<section id="scheduling_squids">
		<title>scheduling <link linkend="squids">squids</link></title>
		<para>
The usual problem with squids not using a cache friendly scheduler
is that fetches are slow. In this case the website is sending hits
to several different RIPs. Some websites detect this and won't
even serve you the pages.
		</para>
		<para>
Palmer J.D.F. <emphasis>J (dot) D (dot) F (dot) Palmer (at) Swansea (dot) ac (dot) uk</emphasis> 18 Mar 2002/
		</para>
		<blockquote>
		<para>
I tried https and online banking sites (<emphasis>e.g.</emphasis> www.hsbc.co.uk).
It seems that this site and undoubtedly many other secure sites don't like
to see connections split across several IP addresses as happens with my
cluster.
Different parts of the pages are requested by different realservers, and
hence different IP addresses.
		</para>
		<para>
It gives an error saying...
"...For your security, we have disconnected you from internet banking due to
a period of inactivity..."
		</para>
		<para>
I have had caching issues with HSBC before, they seem to be a bit more
stringent than other sites.
If I send the requests through one of the squids on it's own it works fine,
so I can only assume it's because it is seeing fragmented requests, maybe
there is a keepalive component that is requested.
How do I combat this?  Is this what persistence does or is there a way of
making the realservers appear to all have the same IP address?
		</para>
		</blockquote>
		<para>
Joe
		</para>
		<para>
change -rr (or whatever you're running) to -dh.
		</para>
		<para>
Lars
		</para>
		<para>
Use a different scheduler, like lblc or lblcr.
		</para>
		<para>
Harry Yen <emphasis>hyen1 (at) yahoo (dot) com</emphasis> 16 April 2002
		</para>
		<para>
What is the purpose of using LVS with Squid to a https site?
HTTPs based material typically is not cachable.
I don't understand why you need Squid at all.
		</para>
		<para>
Once a request reaches a Squid and incurs a cache miss, the forwarded
request will have Squid IP as the source address.  So you need to find a
way to make sure all connections from the same client IP to go to the
same Squid farm. Then when they incur cache misses, they will wind up
via LVS persistency to the same real sever.
		</para>
		<blockquote>
			<para>
The reason https is sent to the squids is because it's much easier to send
all browser traffic to the squids and then let them handle it.
The only way I seemed to be able to get this to work (IE access the bank
site) is to set a persistence (360 seconds), and using lblc scheduling.
The current output of <command>ipvsadm</command> is this... I am a tad concerned at the
apparent lack of load balancing.
			</para>
<programlisting><![CDATA[
TCP  wwwcache-vip.swan.ac.uk:squi lblc persistent 360
  -> squidfarm1.swan.ac.uk:squid  Route   1      202        1045
  -> squidfarm2.swan.ac.uk:squid  Route   1      14         8
]]></programlisting>
			<para>
HSBC seems to be a bit more
stringent than other sites. If I send the requests through one of the
squids on it's own it works fine, so I can only assume it's because it is
seeing fragmented requests, maybe there is a keepalive component that is
requested.
How do I combat this? Is this what persistence does or is there a way
of making the realservers appear to all have the same IP address?
I have sorted it by using persistence, couldn't get any of the dedicated
squid schedulers to work properly. I'm currently running wlc, and 360s
persistance.  Seems to be holding up really well.  Still watching it with
eagle eyes though.
			</para>
		</blockquote>
		<para>
The -dh scheduler was written expressly to handle squids.
Jezz tried it and didn't get it to work satisfactorily but found that
persistence worked. We don't understand this yet.
		</para>
		<para>
Jakub Suchy <emphasis>jakub (at) rtfm (dot) cz</emphasis> 2005/02/23
		</para>
		<para>
round-robin algorithm is not usable for squid.
Some servers (banks etc.) check clients ip address and terminates it's 
connection if it changes.
When you use the source-hashing algorithm, 
IPVS checks the client against its 
local table and forwards connection always to same squid real server, 
so the client always accesses the web through same squid.
source-hashing can become unbalanced when you have few clients 
and one of them use squid more frequently than others. 
With more clients, it's statistically balanced.
		</para>
		</section>
		<section id="dh_persistence">
		<title>DH persistence</title>
		<para>
Just as you can use the <xref linkend="SH-scheduler"/> to achieve persistence (affinity), 
you can also use the DH.
We couldn't work out why this LVS wasn't scheduling the way it was expected, but
the DH scheduler fixed it.
		</para>
		<para>
Steve Haneman <emphasis>stevehaneman (at) yahoo (dot) com</emphasis> 22 Oct 2008 
		</para>
		<blockquote>
			<para>
I'm using ipvsadm to load balance 2 security web servers, so I'm using 3 boxes.
The web servers have 100 IPs each in the 192.168.253.x and 192.168.252.x ranges.
			</para>
			<para>
I'm running a load test through the lb to the web servers from 20 unique IPs.
I'm finding that 4% of the time the sessions are not sticky.  
A user/password web POST goes to one server and a followup POST ends up at the other server.
There is less than 1 second between the POSTs.  
Each transaction (login POST, data POST, logout) is completed with the IP it started with.
			</para>
		</blockquote>
		<para>
Jeff Tchang <emphasis>jeff (dot) tchang (at) gmail (dot) com</emphasis>
		</para>
		<para>
Not sure if this might help but have you tried using different
scheduling algorithms? In particular maybe destination hashing?
		</para>
		<para>
Steve
		</para>
		<blockquote>
That fixed it.  I changed from rr to dh and I'm seeing all goodness. 
		</blockquote>
		</section>
	</section>
	<section id="Henrik">
	<title>LVS with mark tracking: fwmark patches for multiple firewalls/gateways</title>
	<para>
If the LVS is protected by multiple firewall boxes and each
firewall is doing connection tracking, then packets arriving
and leaving the LVS from the same connection will need
to pass through the same firewall box or else they won't be
seen to be part of the same connection and will be dropped.
An initial attempt to handle the firewall problem was
sent in by Henrik Nordstrom, who is involved with developing
<ulink url="http://squid.sourceforge.net/hno/">web caches (squids)</ulink>.
	</para>
	<para>
This code isn't a scheduler, but it's in here awaiting further developements of code
from Julian because it addresses similar problems to the <link linkend="SH-scheduler">
SH scheduler</link> in the next section.
	</para>
	<para>
Julian 13 Jan 2002
	</para>
	<blockquote>
	Unfortunately Henrik's patch breaks the LVS fwmark code.
Multiple gateway setups can be solved with routing and a solution is planned for LVS.
Until then it would be best to contact
Henrick, <emphasis>hno (at) marasystems (dot) com</emphasis> for his patch.
	</blockquote>
	<para>
Here's Henrick's 
<ulink url="files/ipvs-0.2.3-mark-track-v2.patch">patch</ulink> and here's some history.
	</para>
	<para>
Henrik Nordstrom <emphasis>hno (at) marasystems (dot) com</emphasis> 13 Jan 2002
	</para>
	<blockquote>
	<para>
My use of the MARK is for routing purposes of return traffic only, not at
all related to the scheduling onto the farm.
This to solve complex routing problems arising in borders between networks
where it is impractical to know full routing of all clients.
One example of what I do is like this:
	</para>
	<para>
I have a box connected to three networks (firewall, including LVS-NAT load
balancing capabilities for published services)
	</para>
	<itemizedlist>
		<listitem>
a - Internet
		</listitem>
		<listitem>
b - DMZ, where the farm members are
		</listitem>
		<listitem>
c - Large intranet
		</listitem>
	</itemizedlist>
	<para>
For simplicity both Internet and intranet users connect to the same
LVS IP addresses.
Both networks 'a' and 'c' is complex, and maintaining a complete and
correct routing table covering one of the networks (i.e. the 'c' network
in the above) is on the border to impossible and error prone as the use of
addresses change over time.
	</para>
	<para>
To simplify routing decisions I simply simply want return traffic to be
routed back the same way as from where the request was received. This
covers 99.99% of all routing needed in such situation regardless of the
complexity of the networks on the two (or more) sides without the need of
any explicit routing entries. To do this I MARK the session when received
using netfilter, giving it a routing mark indicating which path the
session was received from. My small patch modifies LVS to memorize this
mark in the LVS session, and then restore it on return traffic received
FROM the realservers. This allows me to route the return traffic from the
farm members to the correct client connection using iproute fwmark based
routing rules.
	</para>
	<para>
As farm distribution algorithms I use different ones depending on the type
of application. The MARK I only use for routing of return traffic.
I also have a similar patch for Netfilter connection tracking (and NAT),
for the same purpose of routing return traffic. If interested search for
CONNMARK in the netfilter-devel archives.
The two combined allows me to make multihomed boxes who do not need to
know the networks on any of the sides in detail, besides it's own IP
addresses and suitable gateways to reach further into the networks.
	</para>
	<para>
Another use of the connection MARK memory feature is a device connected to
multiple customer networks with overlapping IP addresses, for example two
customers both using 192.168.1.X addresses. In such case making a standard
routing table becomes impossible as the customers are not uniquely
identified by their IP addresses. The MARK memory however deals with such
routing at ease since it do not care about the detailed addressing as long
as it possible to identify the two customer paths somehow. i.e. interface
originally received on, source MAC of the router who sent us the request,
or anything uniquely identifying the request as coming from a specific
path.
	</para>
	<para>
The two problems above (not wanting to known the IP routing, or not being
able to IP route) are not mutually exclusive. If you have one then the
other is quite likely to occur.
	</para>
	</blockquote>
	<para>
Here's Henrik's announcement and the replies.
	</para>
	<para>
Henrik Nordstrom 14 Feb 2001
	</para>
	<blockquote>
		<para>
Here is a small patch to make LVS keep the MARK,
and have return traffic inherit the mark.
		</para>
		<para>
We use this for routing purposes on a multihomed LVS server, to have
return traffic routed back the same way as from where it was received.
What we do is that we set the mark in the iptables mangle chain
depending on source interface, and in the routing table use this mark to
have return traffic routed back in the same (opposite) direction.
		</para>
		<para>
The patch also moves the priority of LVS INPUT hook back to infront of
iptables filter hook, this to be able to filter the traffic not picked
up by LVS but matchin it's service definitions. We are not
(yet) interested of filtering traffic to the virtual servers, but very
interested in filtering what traffic reaches the Linux LVS-box itself.
		</para>
	</blockquote>
	<para>
Julian - who uses NFC_ALTERED ?
	</para>
	<blockquote>
Netfilter. The packet is accepted by the hook but altered (mark changed).
	</blockquote>
	<para>
Julian -
Give us an example (with dummy addresses) for setup that require
such fwmark assignments.
	</para>
	<blockquote>
		<para>
For a start you need a LVS setup with more than one real interface receiving
client traffic for this to be of any use. Some clients (due to routing
outside the LVS server) comes in on one interface, other clients on another
interface. In this setup you might not want to have a equally complex routing
table on the actual LVS server itself.
		</para>
		<para>
Regarding iptables/ipvs I currently "only" have three main issues.
		</para>
		<itemizedlist>
			<listitem>
As the "INPUT" traffic bypasses most normal routes, the iptables conntrack
will get quite confused by return traffic..
			</listitem>
			<listitem>
	Sessions will be tracked twice. Both by iptables conntrack and by IPVS.
			</listitem>
			<listitem>
There is no obvious choice if IPVS LOCAL_IN sould be placed before or after
iptables filter hook. Having it after enables the use of many fancy iptables
options, but instead requires one to have rules in iptables for allowing ipvs
traffic, and any mismatches (either in rulesets or IPVS operation) will cause the
packets to actually hit the IP interface of the LVS server which in most cases is
not what was intended.
			</listitem>
		</itemizedlist>
	</blockquote>
	</section>
	<section id="SH-scheduler" xreflabel="SH scheduler">
	<title>SH scheduler</title>
	<para>
Using the SH (source hash) scheduler, 
the realserver is selected using a hash of the CIP.
Thus all connect requests from a particular client will go to the same realserver.
Scheduling based on the client IP, 
should solve some of the problems that currently require persistence 
(<emphasis>i.e.</emphasis> having a client always go to the same realserver).
	</para>
	<para> 
Other than the few comments here, no-one has used the -sh scheduler.
The SH scheduler was originally intended for directors with multiple firewalls,
with the balancing based on hashes of the MAC address of the firewall
and this is how it was written up.
Since no-one was balancing on the MAC address of the firewall,
the SH scheduler lay dormant for many years, 
till someone on the mailing list figured out that it could do other things too. 
	</para>
	<para>
It turns out that address hashing is a standard method 
of keeping the client on the same
server in a load balanced server setup.
Willy Tarreau (in 
<ulink url="http://1wt.eu/articles/2006_lb/">
http://1wt.eu/articles/2006_lb/ Making applications scalable with Load Balancing</ulink>)
discusses address hashing (in the section "selecting the best server")
to prevent loss of session data with SSL connections in loadbalanced servers,
by keeping the client on the same server.
	</para>
	<para>
Here's Wensong's announcement:
	</para>
	<para>
Wensong Zhang <emphasis>wensong (at) gnuchina (dot) org</emphasis> 16 Feb 2001
	</para>
	<para>
Please see "man ipvsadm" for short description of DH and SH
schedulers. I think some examples to use those two schedulers.
Example: Firewall Load Balancing
	</para>
<programlisting><![CDATA[
                      |-- FW1 --|
  Internet ----- SH --|         |-- DH -- Protected Network
                      |-- FW2 --|
]]></programlisting>
	<para>
Make sure that the firewall boxes are added in the load balancers in the
same order. Then, request packets of a session are sent to a firewall,
<emphasis>e.g.</emphasis> FW1, the DH can forward the response packets 
from protected network to the FW1 too. 
However, I don't have enough hardware to test this setup myself. 
Please let me know if any of you make it work for you. :)
	</para>
	<para>
For initial discussions on the -dh and -sh scheduler see on the mailing list
under "some info for DH and SH schedulers" and "LVS with mark tracking".
	</para>
		<section id="testing_sh">
		<title>Testing the SH scheduler</title>
		<para>
The SH scheduler schedules by client IP. 
Thus if you test from one client only, 
all connections will go to the first realserver 
in the <command>ipvsadm</command> table.
		</para>
		<para>
Rached Ben Mustapha <emphasis>rached (at) alinka (dot) com</emphasis> 15 May 2002
		</para>
		<blockquote>
			<para>
It seems there is a problem with the SH scheduler and local node feature.
I configured my LVS director (node-102) in direct routing mode on a 2.4.18 linux
kernel with ipvs 1.0.2. The realservers are set up accordingly.
			</para>
<programlisting><![CDATA[
root@node-102# ipvsadm --version
director:/etc/lvs# ipvsadm v1.20 2001/11/04 (compiled with popt and IPVS v1.0.2)
			
root@node-102# ipvsadm -Ln
IP Virtual Server version 1.0.2 (size=65536)
Prot LocalAddress:Port Scheduler Flags
  -> RemoteAddress:Port           Forward Weight ActiveConn InActConn
TCP  10.0.0.50:23 sh
  -> 192.168.32.103:23            Route   1      0          0
  -> 192.168.32.101:23            Route   1      0          0
]]></programlisting>
			<para>
With this configuration, it's ok. Connections from different clients are
load-balanced on both servers.
Now I add the director:
			</para>
<programlisting><![CDATA[
root@node-102# ipvsadm -Ln
IP Virtual Server version 1.0.2 (size=65536)
Prot LocalAddress:Port Scheduler Flags
  -> RemoteAddress:Port           Forward Weight ActiveConn InActConn
TCP  10.0.0.50:23 sh
  -> 127.0.0.1                    Route   1      0          0
  -> 192.168.32.103:23            Route   1      0          0
  -> 192.168.32.101:23            Route   1      0          0
]]></programlisting>
			<para>
All new connections whatever the client's IP goes to the director.
And with this config:
			</para>
<programlisting><![CDATA[
root@node-102# ipvsadm -Ln
IP Virtual Server version 1.0.2 (size=65536)
Prot LocalAddress:Port Scheduler Flags
  -> RemoteAddress:Port           Forward Weight ActiveConn InActConn
TCP  10.0.0.50:23 sh
  -> 192.168.32.103:23            Route   1      0          0
  -> 192.168.32.101:23            Route   1      0          0
  -> 127.0.0.1
]]></programlisting>
			<para>
Now all new connections whatever the client's IP goes to node-103.
So it seems that with localnode feature, the scheduler always choose the
first entry in the redirection rules.
			</para>
		</blockquote>
		<para>
Wensong
		</para>
		<para>
There is no problem in SH scheduler and localnode feature.
		</para>
		<para>
I reproduced your setup. I issued the
requests from two difficult clients, all the requests were sent to the
localnode. Then, issues the requests from the third client, the requests
were sent to the other server. Please see the result.
		</para>
<programlisting><![CDATA[
[root@dolphin /root]# <command>ipvsadm</command> -ln
IP Virtual Server version 1.0.2 (size=4096)
Prot LocalAddress:Port Scheduler Flags
  -> RemoteAddress:Port           Forward Weight ActiveConn InActConn
TCP  172.26.20.118:80 sh
  -> 172.26.20.72:80              Route   1      2          0
  -> 127.0.0.1:80                 Local   1      0          858
]]></programlisting>
		<para>
I don't know how many clients are used in your test. You know that the SH
scheduler is statically mapping algorithm (based on the source IP address
of clients). It is quite possible that two or more client IP addresses are
mapped to the same server.
		</para>
		</section>
		<section id="sh_weight">
		<title>"weight" is really the number of connections for the SH scheduler</title>
		<para>
Con Tassios <emphasis>ct (at) swin (dot) edu (dot) au</emphasis> 7 Jun 2006 
		</para>
		<para>
source hashing with a weight of 1 (the default value for the other schedulers) 
will result in the service being overloaded when the
number of connections is greater than 2, as the output of ipvsadm shows.  
You should increase the weight.
The weight when used with SH and DH has a different meaning than most, if not
all, the other standard LVS scheduling methods.  Although this doesn't appear
to be mentioned in the man page for ipvsadm.
		</para>
<programlisting><![CDATA[
From ip_vs_sh.c

The sh algorithm is to select server by the hash key of source IP
address. The pseudo code is as follows:

      n <- servernode[src_ip];
      if (n is dead) OR
         (n is overloaded, such as n.conns>2*n.weight) then
                return NULL;

      return n;
]]></programlisting>
		<note>
Joe: if weight is 1, then return NULL if number of connections > 2.
If number of connections is twice the weight, don't allow anymore connections. 
		</note>
		<para>
Martijn Grendelman <emphasis>martijn (at) grendelman (dot) net</emphasis> 09 Jun 2006 
		</para> 
		<para>
That would explain the things I saw.
In the meantime, I went back to a configuration using the SH scheduler 
now with a weight for both real servers of 200, instead of 1, 
and things seem to run fine.
		</para>
<programlisting><![CDATA[
martijn@tweety:~> rr ipvsadm -L
IP Virtual Server version 1.0.10 (size=4096)
Prot LocalAddress:Port Scheduler Flags
  -> RemoteAddress:Port           Forward Weight ActiveConn InActConn
TCP  212.204.230.98:www sh
  -> tweety.sipo.nl:www           Local   200    25         44
  -> daffy.sipo.nl:www            Route   200    12         27
TCP  212.204.230.98:https sh persistent 360
  -> tweety.sipo.nl:https         Local   100    0          0
  -> daffy.sipo.nl:https          Route   100    0          0
]]></programlisting>
		<blockquote>
Joe: Since the SH scheduler sends a client's packets to the same realserver, 
I had thought that it should completely replace persistence. 
However you're using persistence with SH, 
so apparently SH doesn't handle keeping the client on the realserver as I expect. 
So why are you using persistence?
		</blockquote>
		<para>
Ehr.. no reason, I guess. 
It's still there from when I used RR scheduling and I guess I forgot to remove it. 
I don't think it is actually useful.
		</para>
		</section>
		<section id="SH-failout">
		<title>SH failout</title>
		<para>
Shutting down an SH realserver by changing the weight to 0 
(as is done for the other schedulers),
still allows in connection requests to be sent to that realserver 
(you'll get a failed connection if the realserver is down).
This seems to be a result of the different meaning of weight for the SH scheduler.
No new sources will be allowed to initiate connections, 
but all connections from known sources will still be forwarded,
and all known sources will be allowed to initiate connections.
To stop connection requests being forwarded to a realserver,
you have to remove the realserver from the ipvsadm table.
You may have to break current connections to do this :-( 
		</para>
		<para>
Thomas Pedoussaut <emphasis>thomas (at) pedoussaut (dot) com</emphasis> 16 Oct 2008
		</para>
		<para>
Weight to 0 means no more new connections, but existing ones (in the SH 
way) will still hit the real server
You need to have it properly removed.
		</para>
		</section>
	</section>
	<section id="ActiveConn" xreflabel="ActConn">
	<title>What is an ActiveConn/InActConn (Active/Inactive) connnection?</title>
	<para>
The output of ipsvadm lists connections, either as
	</para>
	<itemizedlist>
		<listitem>
ActiveConn - in ESTABLISHED state
		</listitem>
		<listitem>
InActConn - any other state
		</listitem>
	</itemizedlist>
	<para>
With LVS-NAT,
the director sees all the packets between the client and the realserver,
so always knows the state of tcp connections and the listing from
<command>ipvsadm</command> is accurate.
However for LVS-DR, LVS-Tun, the director does not see the packets
from the realserver to the client.
Termination of the tcp connection occurs by one of the ends sending a FIN
(see W. Richard Stevens, TCP/IP Illustrated Vol 1, ch 18, 1994,
pub Addison Wesley) followed by reply ACK from the other end.
Then the other end sends its FIN, followed by an ACK from the first machine.
If the realserver initiates termination of the connection,
the director will only be able to infer that this has
happened from seeing the ACK from the client.
In either case the director has to infer that the connection
has closed from partial information and uses its own
table of timeouts to declare that the connection has terminated.
Thus the count in the InActConn column for LVS-DR, LVS-Tun is
inferred rather than real.
	</para>
	<para>
Entries in the ActiveConn column come from
	</para>
	<itemizedlist>
		<listitem>
service with an established connection.
Examples of services which hold connections in the ESTABLISHED state
for long enough to see with <command>ipvsadm</command> are telnet and ftp (port 21).
		</listitem>
	</itemizedlist>
	<para>
Entries in the InActConn column come from
	</para>
	<itemizedlist>
		<listitem>
		<para>
Normal operation
		</para>
		<itemizedlist>
			<listitem>
Services like http (in non-persistent <emphasis>i.e.</emphasis> HTTP /1.0 mode)
or ftp-data(port 20)
which close the connections as soon as the hit/data (html page, or gif etc)
has been retrieved (&lt;1sec).
You're unlikely to see anything
in the ActiveConn column with these LVS'ed services.
You'll see an entry in the InActConn
column untill the connection times out.
If you're getting 1000connections/sec and
it takes 60secs for the connection to time out (the normal timeout),
then you'll have 60,000 InActConns.
This number of InActConn is quite normal.
If you are running an e-commerce site with 300secs of persistence,
you'll have 300,000 InActConn entries.
Each entry takes 128bytes (300,000 entries is about 40M of memory,
make sure you have enough RAM for your application).
The number of ActiveConn might be very small.
			</listitem>
		</itemizedlist>
		</listitem>
		<listitem>
		<para>
Pathological Conditions (<emphasis>i.e.</emphasis> your LVS is not setup properly)
		</para>
		<itemizedlist>
			<listitem>
			<para>
identd delayed connections:
The 3 way handshake to establish a connection takes
only 3 exchanges of packets (<emphasis>i.e.</emphasis> it's quick on any
normal network) and you won't be quick enough with ipvsadm
to see the connection in the states before it becomes ESTABLISHED.
However if the service on the realserver is under
<xref linkend="LVS-HOWTO.authd"/>, you'll see an InActConn entry
during the delay period.
			</para>
			</listitem>
			<listitem>
			<para>
Incorrect routing
(usually the wrong default gw for the realservers):
			</para>
			<para>
In this case the 3 way handshake will never complete, the connection will hang,
and there'll be an entry in the InActConn column.
			</para>
			</listitem>
		</itemizedlist>
		</listitem>
	</itemizedlist>
	<para>
Usually the number of InActConn will be larger or very much larger than the number
of ActiveConn.
	</para>
	<para>
Here's a LVS-DR LVS, setup for ftp, telnet and http,
after telnetting from the client
(the client command line is at the telnet prompt).
	</para>
<programlisting><![CDATA[
director:# ipvsadm
IP Virtual Server version 0.2.8 (size=4096)
Prot LocalAddress:Port Scheduler Flags
-> RemoteAddress:Port               Forward Weight ActiveConn InActConn
TCP  lvs2.mack.net:www rr
-> RS2.mack.net:www                 Route   1      0          0
-> RS1.mack.net:www                 Route   1      0          0
TCP  lvs2.mack.net:0 rr persistent 360
-> RS1.mack.net:0                   Route   1      0          0
TCP  lvs2.mack.net:telnet rr
-> RS2.mack.net:telnet              Route   1      1          0
-> RS1.mack.net:telnet              Route   1      0          0
]]></programlisting>
	<para>
showing the ESTABLISHED telnet connection (here to realserver RS2).
	</para>
	<para>
Here's the output of netstat -an | grep (appropriate IP) for the client and the
realserver, showing that the connection is in the ESTABLISHED state.
	</para>
<programlisting><![CDATA[
client:# netstat -an | grep VIP
tcp        0      0 client:1229      VIP:23           ESTABLISHED
			</para><para>
realserver:# netstat -an | grep CIP
tcp        0      0 VIP:23           client:1229      ESTABLISHED
<programlisting><![CDATA[
	<para>
Here's immediately after the client logs out from the telnet session.
	</para>
<programlisting><![CDATA[
director# ipvsadm
IP Virtual Server version 0.2.8 (size=4096)
Prot LocalAddress:Port Scheduler Flags
-> RemoteAddress:Port               Forward Weight ActiveConn InActConn
TCP  lvs2.mack.net:www rr
-> RS2.mack.net:www                 Route   1      0          0
-> RS1.mack.net:www                 Route   1      0          0
TCP  lvs2.mack.net:0 rr persistent 360
-> RS1.mack.net:0                   Route   1      0          0
TCP  lvs2.mack.net:telnet rr
-> RS2.mack.net:telnet              Route   1      0          0
-> RS1.mack.net:telnet              Route   1      0          0

client:# netstat -an | grep VIP
#ie nothing, the client has closed the connection

#the realserver has closed the session in response
#to the client's request to close out the session.
#The telnet server has entered the TIME_WAIT state.
realserver:/home/ftp/pub# netstat -an | grep 254
tcp        0      0 VIP:23        CIP:1236      TIME_WAIT

#a minute later, the entry for the connection at the realserver is gone.
]]></programlisting>
	<para>
Here's the output after ftp'ing from the client and logging in,
but before running any commands (like `dir` or `get filename`).
	</para>
<programlisting><![CDATA[
director:# ipvsadm
IP Virtual Server version 0.2.8 (size=4096)
Prot LocalAddress:Port Scheduler Flags
-> RemoteAddress:Port               Forward Weight ActiveConn InActConn
TCP  lvs2.mack.net:www rr
-> RS2.mack.net:www                 Route   1      0          0
-> RS1.mack.net:www                 Route   1      0          0
TCP  lvs2.mack.net:0 rr persistent 360
-> RS1.mack.net:0                   Route   1      1          1
TCP  lvs2.mack.net:telnet rr
-> RS2.mack.net:telnet              Route   1      0          0
-> RS1.mack.net:telnet              Route   1      0          0

client:# netstat -an | grep VIP
tcp        0      0 CIP:1230      VIP:21        TIME_WAIT
tcp        0      0 CIP:1233      VIP:21        ESTABLISHED

realserver:# netstat -an | grep 254
tcp        0      0 VIP:21        CIP:1233      ESTABLISHED
]]></programlisting>
	<para>
The client opens 2 connections to the ftpd and leaves one open (the ftp prompt).
The other connection, used to transfer the user/passwd information,
is closed down after the login.
The entry in the <command>ipvsadm</command> table corresponding to the TIME_WAIT state
at the realserver is listed as InActConn.
If nothing else is done at the client's ftp prompt, the connection will
expire in 900 secs. Here's the realserver during this 900 secs.
	</para>
<programlisting><![CDATA[
realserver:# netstat -an | grep CIP
tcp        0      0 VIP:21        CIP:1233      ESTABLISHED
realserver:# netstat -an | grep CIP
tcp        0     57 VIP:21        CIP:1233      FIN_WAIT1
realserver:# netstat -an | grep CIP
#ie nothing, the connection has dropped

#if you then go to the client, you'll find it has timed out.
ftp> dir
421 Timeout (900 seconds): closing control connection.
]]></programlisting>
	<para>
http 1.0 connections are closed immediately after retrieving the URL
(<emphasis>i.e.</emphasis> you won't see any ActiveConn in the <command>ipvsadm</command> table immediately
after the URL has been fetched).
Here's the outputs after retreiving a webpage from the LVS.
	</para>
<programlisting><![CDATA[
director:# ipvsadm
IP Virtual Server version 0.2.8 (size=4096)
Prot LocalAddress:Port Scheduler Flags
-> RemoteAddress:Port               Forward Weight ActiveConn InActConn
TCP  lvs2.mack.net:www rr
-> RS2.mack.net:www                 Route   1      0          1
-> RS1.mack.net:www                 Route   1      0          0

client:~# netstat -an | grep VIP

RS2:/home/ftp/pub# netstat -an | grep CIP
tcp        0      0 VIP:80        CIP:1238      TIME_WAIT
]]></programlisting>
		<section id="programmatically_accessing_activeconn">
		<title>Programmatically access ActiveConn, InActConn</title>
		<blockquote>
I want to get the active and inactive connections of one virtual
service in my program.
		</blockquote>
		<para>
Jeremy Kerr <emphasis>jeremy (at) redfishsoftware (dot) com (dot) au</emphasis> 12 Feb 2003
		</para>
		<para>
You have two options here:
		</para>
		<itemizedlist>
			<listitem>
Read <filename>/proc/net/ip_vs file</filename> and parse it for the required numbers
			</listitem>
			<listitem>
Use <filename>libipvs</filename> (distributed with ipvsadm) to read the tables directly.
Take a look in ipvsadm.c for how this is done.
			</listitem>
		</itemizedlist>
		</section>
		<section>
		<title>ActiveConn/InActConn different for 2.4.x/2.6.x kernels</title>
		<para>
Ratz 15 Oct 2006 
		</para>
		<para>
IPVS between 2.4 and 2.6 have has change significantly 
with regards to the ratio of active/inactive connections. 
We've seen that in our rrdtool/MRTG graphs as well.
In the 2.6.x kernels, at least for the (w)LC scheduler the RS calculation is done differently. 
On top of that, the TCP stack has changed tunables and you hardware also behaves differently. 
The LVS state transition timeouts are different between 2.4.x and 2.6.x kernels, IIRC and so, 
for example if you're using LVS-DR, 
the active connection to passive connection transition takes more time, 
thus yielding a potentially higher amount of sessions in state ActiveConn.
		</para>
		</section>
		<section>
		<title>from the mailing list</title>
		<para>
Ty Beede wrote:
		</para>
		<blockquote>
I am curious about the implementation of the inactconns and
activeconns variables in the lvs source code.
		</blockquote>
		<para>
Julian
		</para>
<programlisting><![CDATA[
        Info about LVS <= 0.9.7
TCP
        active:         all connections in ESTABLISHED state
        inactive:       all connections not in ESTABLISHED state
UDP
        active:         0 (none) (LVS <= 0.9.7)
        inactive:       all (LVS <= 0.9.7)

        active + inactive = all
]]></programlisting>
		<para>
        Look in this table for the used timeouts for each
protocol/state:
		</para>
		<para>
/usr/src/linux/net/ipv4/ip_masq.c, masq_timeout_table
		</para>
		<para>
        For LVS-Tun and LVS-DR the TCP states are changed checking only
the TCP flags from the incoming packets. For these methods UDP entries can
expire (5 minutes?) if only the realservers sends packets and there are
no packets from the client.
		</para>
		<para>
        For info about the TCP states: <filename>/usr/src/linux/net/ipv4/tcp.c</filename>,
<filename>rfc793.txt</filename>
		</para>
		<para>
Jean-francois Nadeau <emphasis>jf (dot) nadeau (at) videotron (dot) ca</emphasis>
		</para>
		<blockquote>
		<para>
Done some testing (netmon) on this and here's my observations :
		</para>
		<para>
1. A connection becomes active when LVS sees the ACK flag in the TCP header
incoming in the cluster : i.e when the socket gets established on the real
server.
		</para>
		<para>
2. A connection becomes inactive when LVS sees the ACK-FIN flag in the TCP
header incoming in the cluster. This does NOT corespond to the socket
closing on the realserver.
		</para>
		<para>
Example with my Apache Web server.
		</para>
<programlisting><![CDATA[
Client  	<---> Server

A client request an object on the web server on port 80 :

SYN REQUEST     ---->
SYN ACK 	<----
ACK             ----> *** ActiveConn=1 and 1 ESTABLISHED socket on realserver.
HTTP get        ----> *** The client request the object
HTTP response   <---- *** The server sends the object
APACHE closes the socket : *** ActiveConn=1 and 0 ESTABLISHED socket on realserver
The CLIENT receives the object. (took 15 seconds in my test)
ACK-FIN         ----> *** ActiveConn=0 and 0 ESTABLISHED socket on realserver
]]></programlisting>
		<para>
Conclusion : ActiveConn is the active number of CLIENT connections.....
not on the server in the case of short transmissions (like objects on a web page).
Its hard to calculate a server's capacity based on this
because slower clients makes ActiveConn greater than
what the server is really processing.
You wont be able to reproduce that effect on a LAN,
because the client receives the segment too fast.
		</para>
		<para>
In the LVS mailing list, many people explained that the correct way
to balance the connections is to use monitoring software.
The weights must be evaluated using values from the realserver.
In LVS-DR and LVS-Tun, the Director can be easily fooled
with invalid packets for some period
and this can be enough to inbalance the cluster when using "*lc" schedulers.
		</para>
		<para>
I reproduce the effect connecting at 9600 bps
and getting a 100k gif from Apache,
while monitoring established sockets on port 80
on the realserver and <command>ipvsadm</command> on the cluster.
		</para>
		</blockquote>
		<para>
Julian
		</para>
		<para>
You are probably using LVS-DR or LVS-Tun in your test.
Right?
Using these methods, the LVS is changing the TCP state
based on the incoming packets, <emphasis>i.e.</emphasis> from the clients.
This is the reason that the Director can't see the FIN packet
from the realserver.
This is the reason that LVS can be easily SYN flooded,
even flooded with ACK following the SYN packet.
The LVS can't change the TCP state according
to the state in the realserver.
This is possible only for VS/NAT mode.
So, in some situations you can have invalid entries
in ESTABLISHED state which do not correspond to the connections
in the realserver, which effectively ignores these SYN packets using cookies.
The VS/NAT looks the better solution against the SYN flood attacks.
Of course, the ESTABLISHED timeout can be changed to 5 minutes for example.
Currently, the max timeout interval
(excluding the ESTABLISHED state) is 2 minutes.
If you think that you can serve the clients using a
smaller timeout for the ESTABLISHED state,
when under "ACK after SYN" attack, you can change it with ipchains.
You don't need to change it under 2 minutes in LVS 0.9.7.
In the last LVS version SYN+FIN switches the state to TIME_WAIT,
which can't be controlled using ipchains.
In other cases,
you can change the timeout for the ESTABLISHED and FIN-WAIT states.
But you can change it only down to 1 minute.
If this doesn't help, buy 2GB RAM or more for the Director.
		</para>
		<para>
One thing that can be done, but this is may be paranoia:
		</para>
		<para>
change the INPUT_ONLY table:
		</para>
<programlisting><![CDATA[
from:
           FIN
        SR ---> TW
to:
           FIN
        SR ---> FW
]]></programlisting>
		<para>
        OK, this is incorrect interpretation of the TCP states
but this is a hack which allows the min state timeout to be
1 minute. Now using ipchains we can set the timeout to all
TCP states to 1 minute.
		</para>
		<para>
        If this is changed you can now set ESTABLISHED and
FIN-WAIT timeouts down to 1 minute. In current LVS version
the min effective timeout for ESTABLISHED and FINWAIT state
is 2 minutes.
		</para>
		<para>
Jean-Francois Nadeau <emphasis>jf (dot) nadeau (at) videotron (dot) ca</emphasis>
		</para>
		<blockquote>
		<para>
I'm using DR on the cluster with 2 realservers.  I'm trying to control the
number of connections to acheive this :
		</para><para>
The cluster in normal mode balances requests on the 2 realservers.
If the realservers reaches a point where they can't serve clients fast
enough, a new entry with a weight of 10000 is entered in LVS to send the
overflow locally on a web server with a static web page saying "we're too busy".
It's a cgi that intercept 'deep links' in our site and return a predefined page.
A 600 seconds persistency ensure that already connected clients stays on the
server they began to browse.  The client only have to hit refresh until the
number of AciveConns (I hoped) on the realservers gets lower and the overflow
entry gets deleted.
		</para><para>
Got the idea... Load balancing with overflow control.
		</para>
		</blockquote>
		<para>
Julian
		</para>
		<para>
        Good idea. But LVS can't help you. When the clients are
	redirected to the Director they stay there for 600 seconds.
		</para>
		<blockquote>
		<para>
But when we activate the local redirection of requests due to overflow,
ActiveConn continues to grow in LVS, while Inactconn decreases as expected.
So the load on the realserver gets OK... but LVS doesnt sees it and doesnt let
new clients in. (it takes 12 minutes before ActiveConns decreases enough to
reopen the site)
		</para><para>
I need a way, a value to check at that says the server is
overloaded, begin redirecing locally and the opposite.
		</para><para>
I know that seems a little complicated....
		</para>
		</blockquote>
		<para>
Julian
		</para>
		<para>
       What about trying to:
		</para>
		<itemizedlist>
			<listitem>
			<para>
use persistent timeout 1 second for the virtual service.
			</para>
			<para>
        If you have one entry for this client you have all entries
from this client to the same realserver. I didn't tested it but
may be a client will load the whole web page. If the server is
overloaded the next web page will be "we're too busy".
			</para>
			</listitem>
			<listitem>
			<para>
switch the weight for the Director between 0 and 10000. Don't
delete the Director as realserver.
			</para>
			<para>
        Weight 0 means "No new connections to the server". You
have to play with the weight for the Director, for example:
			</para>
			</listitem>
			<listitem>
			<para>
if your realservers are loaded near 99% set the weight to 10000
			</para>
			</listitem>
			<listitem>
			<para>
if your realservers are loaded before 95% set the weight to 0
			</para>
			</listitem>
		</itemizedlist>
		<para>
Jean-Francois Nadeau <emphasis>jf (dot) nadeau (at) videotron (dot) ca</emphasis>
		</para>
		<blockquote>
		<para>
Will a weight of 0 redirect traffic to the other realservers
(persistency remains ?)
		</para>
		</blockquote>
		<para>
Julian
		</para>
		<para>
If the persistent timeout is small, I think.
		</para>
		<blockquote>
			<para>
I can't get rid of the 600 seconds persistency 
because we run a transactionnal engine. 
<emphasis>i.e.</emphasis> if a client begins on a realserver, 
he must complete the transaction on that server or get an error 
(transactionnal contexts are stored locally).
			</para>
		</blockquote>
		<para>
Such timeout can't help to redirect the clients back to the
realservers.
		</para>
		<para>
You can check the free ram or the cpu idle time for the
realservers. By this way you can correctly set the weights for
the realservers and to switch the weight for the Director.
		</para>
		<para>
These recommendations can be completely wrong. I've never
tested them. If they can't help try to set httpd.conf:MaxClients
to some reasonable value. Why not to put the Director as real
server permanently. With 3 realservers is better.
		</para>
		<para>
Jean
		</para>
		<blockquote>
			<para>
	Those are already optimized,  bottleneck is  when 1500 clients tries our site
	in less than 5 minutes.....
			</para>
			<para>
	One of ours has suggested that the realservers check their own state (via
	TCP in use given by sockstat) and command the director to redirect traffic
	when needed.
			</para>
			<para>
	Can you explain more in details why the number of ActiveConn on realserver
	continue to grow while redirecting traffic locally with a weight of 10000 (and
	Inactonn on that realserver decreasing normally).
			</para>
		</blockquote>
		<para>
Julian
		</para>
		<para>
Only the new clients are redirected to the Director at this
moment. Where the active connections continue to grow, in the real
servers or in the Director (weight=10000)?
		</para>
		</section>
		<section id="calculating_activeconn">
		<title>How is ActiveConn/InActConn calculated?</title>
		<para>
<blockquote><para>
Joe, 14 May 2001
			</para><para>
according to the <command>ipvsadm</command> man page, for "lc" scheduling, the
new connections are assigned according to the number of
"active connections". Is this the same as "ActiveConn" in the
output of ipvsadm?
If the number of "active connections" used to determine the
scheduling is "ActiveConn", then for services which don't
maintain connections (<emphasis>e.g.</emphasis> http or UDP services),
the scheduler won't have much information,
just "0" for all realservers?
</para></blockquote>
			</para><para>
Julian, 14 May and 23 May
			</para><para>
It is a counter and it is incremented when new connection is
created. The formula is:
			</para><para>
<programlisting><![CDATA[
active connections = ActConn * K + InActConn
]]></programlisting>
			</para><para>
where K can be 32 to 50 (I don't remember the last used value),
so it is not only the active conns (which would break UDP).
			</para><para>
<blockquote><para>
Is "active connections" incremented if the client re-uses a port?
</para></blockquote>
			</para><para>
No, the reused connections are not counted.
		</para>
		</section>
		<section id="ActiveConn_netstat_not_matching">
		<title>ActiveConn is a guess for LVS-DR</title>
		<para>
For LVS-DR, the director doesn't see the return packets 
and uses tables of timeouts to guess a likely state of the service at the realserver.
For the same reason you can't do stateful filtering on the director for LVS-DR controlled
packets.
		</para>
		<para>
barrywong <emphasis>barrywong (at) sina (dot) com</emphasis> 30 Aug 2008
		</para>
		<blockquote>
			<para>
I'm using  DR wlc persistent 120 
			</para>
<programlisting><![CDATA[
# ipvsadm -Ln
IP Virtual Server version 1.2.0 (size=4096)
Prot LocalAddress:Port Scheduler Flags
  -> RemoteAddress:Port           Forward Weight ActiveConn InActConn

TCP  xx.xx.xx.xx:80 wlc persistent 120
  -> xx.xx.xx.x1:80             Route   1      6459       7057
  -> xx.xx.xx.x2:80            Route   1      6446       4766

# netstat -n
realserver ESTABLISHED
xx.xx.xx.x1:80 4210 ESTABLISHED
xx.xx.xx.x2:80 4483 ESTABLISHED
]]></programlisting>
			<para>
The realserver ESTABLISHED status connect numberis less than the lvs ActiveConn connect number.
Why is this?
			</para>
		</blockquote>
		<para>
Thomas Pedoussaut <emphasis>thomas (at) pedoussaut (dot) com</emphasis>
		</para>
		<para>   
I guess your issue is that the persistance is low compared to your usage.
I've had similar numbers with a mysql setup. Basically, there was
hundreds of very-long-lasting connections, but that weren't doing much
of traffic, with sometimes pausing for hours. They would disappear from
the LVS status but still be visible on the client and the server as
CONNECTED.
		</para>
		<para>
It's not really a big issue. Usually server affinity make the resuming
packets being directed to the same server so the connection can still be
used. If it wasn't the case, there is enough code on the client side to
re-establish a new connection if that one was to fail. You'll still have
to face a problem with the server side connections that will be
lingering in a limbo state. I would consider setting some sort of
timeout on that side. I'm not 100% sure, but you're real server are
running squid on port 80 correct.
If so, please have a look there
http://www.squid-cache.org/Versions/v3/3.0/cfgman/read_timeout.html and
probably shorten it (or extend your LVS persistance to that value with
ipvsadm --set )

		</para>
		</section>
	</section>
	<section id="faq_entries_in_inactconn">
	<title>FAQ: ipvsadm shows entries in InActConn, but none in ActiveConn, connection hangs. What's wrong?</title>
	<para>
The usual mistake is to have the default gw for the realservers set incorrectly.
	</para>
	<itemizedlist>
		<listitem>
		LVS-NAT: the default gw <emphasis>must</emphasis> be the director.
There <emphasis>cannot</emphasis> be any other path from the realservers to the client,
except through the director.
		</listitem>
		<listitem>
LVS-DR, LVS-Tun: the default gw <emphasis>cannot</emphasis> be the director -
use some local router.
		</listitem>
	</itemizedlist>
	<para>
Setting up an LVS by hand is tedious.
You can use the configure script
which will trap most errors in setup.
	</para>
	</section>
	<section id="faq_initial_connection_delayed">
	<title>FAQ: initial connection is delayed, but once connected everything is fine. What's wrong?</title>
	<para>
Usually you have problems with <xref linkend="LVS-HOWTO.authd"/>.
Simplest thing is to stop your service from calling the identd server
on the client (<emphasis>i.e.</emphasis>disconnect your service from identd).
	</para></section>
	<section id="reusing_ports">
	<title>unbalanced realservers: does rr and lc weighting equally distribute the load? - clients reusing ports</title>
	<para>
(also see <xref linkend="polygraph"/> in the performance section.)
	</para>
	<para>
I ran the <ulink url="http://www.polygraph.org/">polygraph</ulink> simple.pg
test on a LVS-NAT LVS with 4 realservers using rr scheduling.
Since the responses from the realservers should average out
I would have expected the number of connection and load average on the
realservers to be equally distributed over the realservers.
	</para>
	<para>
Here's the output of <command>ipvsadm</command> shortly after the number of connections
had reached steady state (about 5 mins).
	</para>
<programlisting><![CDATA[
IP Virtual Server version 0.2.12 (size=16384)
Prot LocalAddress:Port Scheduler Flags
  -> RemoteAddress:Port             Forward Weight ActiveConn InActConn
TCP  lvs2.mack.net:polygraph rr
  -> RS4.mack.net:polygraph         Masq    1      0          883
  -> RS3.mack.net:polygraph         Masq    1      0          924
  -> RS2.mack.net:polygraph         Masq    1      0          1186
  -> RS1.mack.net:polygraph         Masq    1      0          982
]]></programlisting>
	<para>
The servers were identical hardware. I expect (but am not sure)
that the utils/software on the machines is identical (I set up
RS3,RS4 about 6 months after RS1,RS2).
RS2 was running 2.2.19,
while the other 3 machine were running 2.4.3 kernels.
The number of connections (all in TIME_WAIT) at the realservers
was different for each (otherwise apparently identical) realserver
and was in the range 450-500 for the 2.4.3 machines and 1000 for the
2.2.19 machine (measured with netstat -an | grep $polygraph_port |wc )
and varied about 10&percnt; over a long period.
	</para>
	<para>
This run had been done immediately after another run and InActConn
had not been allowed to drop to 0.
Here I repeated this run, after first waiting for InActConn to drop to 0
	</para>
<programlisting><![CDATA[
IP Virtual Server version 0.2.12 (size=16384)
Prot LocalAddress:Port Scheduler Flags
  -> RemoteAddress:Port             Forward Weight ActiveConn InActConn
TCP  lvs2.mack.net:polygraph rr
  -> RS4.mack.net:polygraph         Masq    1      0          994
  -> RS3.mack.net:polygraph         Masq    1      0          994
  -> RS2.mack.net:polygraph         Masq    1      0          994
  -> RS1.mack.net:polygraph         Masq    1      1          992
TCP  lvs2.mack.net:netpipe rr
]]></programlisting>
	<para>
RS2 (the 2.2.19 machine) had 900 connections in TIME_WAIT while
the other (2.4.3) machines were 400-600. RS2 was also delivering
about 50&percnt; more hits to the client.
	</para>
	<para>
Repeating the run using &quot;lc&quot; scheduling, the InActConn remains
constant.
	</para>
<programlisting><![CDATA[
IP Virtual Server version 0.2.12 (size=16384)
Prot LocalAddress:Port Scheduler Flags
  -> RemoteAddress:Port             Forward Weight ActiveConn InActConn
TCP  lvs2.mack.net:polygraph lc
  -> RS4.mack.net:polygraph         Masq    1      0          994
  -> RS3.mack.net:polygraph         Masq    1      0          994
  -> RS2.mack.net:polygraph         Masq    1      0          994
  -> RS1.mack.net:polygraph         Masq    1      0          993
]]></programlisting>
	<para>
The number of connections (all in TIME_WAIT)
at the realservers did not change.
	</para>
	<para>
I've been running the polygraph simple.pg test over the weekend
using rr scheduling on what (AFAIK) are 4 identical realservers
in a LVS-NAT LVS. There are no ActiveConn and a large number of
InActConn. Presumably the client makes a new connection for each
request.
	</para>
	<para>
Julian (I think)
	</para>
	<blockquote>
The implicit persistence of TCP connection reuse can cause
such side effects even for RR.
When the setup includes small number of hosts and the used rate is
big enough to reuse the client's port, the LVS detects existing
connections and new connections are not created. This is the reason
you can see some of the rs not to be used at all, even for such method
as RR.
	</blockquote>
	<para>
the client is using ports from 1025-4999 (has about 2000 open
at one time) and it's not going above the 4999 barrier. ipvsadm
shows a constant InActConn of 990-995 for all realservers,
but the number of connections on each of the realservers (netstat -an)
ranges from 400-900.
	</para>
	<para>
So if the client is reusing ports (I thought you always incremented
the port by 1 till you got to 64k and then it rolled over again),
LVS won't create a new entry in the hash table if the old one
hasn't expired?
	</para>
	<blockquote>
	Yes, it seems you have (5000-1024) connections that never expire
in LVS.
	</blockquote>
	<para>
Presumably because the director doesn't know the number of connections
at the realservers (it only has the number of entries in its tables),
and because even apparently identical realservers aren't identical
(the hardware here is the same, but I set them up at different times,
presumably not all the files and time outs are the same), the throughput
of different realservers may not be the same.
	</para>
	<para>
The apparent unbalance in the number of InActConn then is a combination
of some clients reusing ports and the director's method of estimating
the number of connections, which makes assumptions about TIME_WAIT on
the realserver.
A better estimate of the number of connections at the realservers would
have been to look at the number of ESTABLISHED and TIME_WAIT connections
on the realservers, but I didn't think of this at the time when I did
the above tests.
	</para>
	<para>
The unbalance then isn't anything that we're regarding as a big enough
problem to find a fix for.
	</para>
	</section>
	<section id="changing_weights">
	<title>Changing weights with ipvsadm</title>
	<para>
When setting up a service, you set the weight with a command like
(default weight is 1).
			</para><para>
<programlisting><![CDATA[
director:/etc/lvs# ipvsadm -a -t $VIP:$SERVICE -r $REALSERVER_NAME:$SERVICE $FORWARDING -w 1
]]></programlisting>
			</para><para>
If you set the weight for the service to &quot;0&quot;, then no new
connections will be made to that service 
(see also man ipvsadm, about the -w option).
			</para><para>
<blockquote><para>
Lars Marowsky-Bree <emphasis>lmb (at) suse (dot) de</emphasis> 11 May 2001
			</para><para>
Setting weight = 0 means that no further connections will be assigned to the
machine, but current ones remain established. This allows to smoothly take a
realserver out of service, <emphasis>i.e.</emphasis> for maintenance.
			</para><para>
Removing the server hard cuts all active connections. This is the correct
response to a monitoring failure, so that clients receive immediate notice
that the server they are connected to died so they can reconnect.
</para></blockquote>
			</para><para>
<blockquote><para>
Laurent Lefoll <emphasis>Laurent (dot) Lefoll (at) mobileway (dot) com</emphasis> 11 May 2001
			</para><para>
Is there a way to clear some entries in the ipvs tables ?
If a server reboots or crashes, the connection
entries remains in the <command>ipvsadm</command> table.
Is there a way to remove manually some entries? I have tried to remove
the realserver from the service (with <command>ipvsadm</command> -d .... ),
but the entries are still there.
			</para><para>
			</para><para>
<blockquote><para>
Joe
			</para><para>
After a service (or realserver) failure, some agent external to LVS
will run <command>ipvsadm</command> to delete the entry for the
service. Once this is done no new connections can
be made to that service, but the entries are kept in
the table till they timeout.
(If the service is still up, you can delete the entries
and then re-add the service and the client will not
have been disconnected). You can't &quot;remove&quot; those
entries, you can only change the timeout values.
			</para><para>
Any clients connected through
those entries to the failed service(s) will find their
connection hung or deranged in some way. We can't do
anything about that. The client will have to
disconnect and make a new connection.
For http where the client makes
a new connection almost every page fetch, this is not
a problem. Someone connected to a database may find their
screen has frozen.
	</para></blockquote>
</para></blockquote>
			</para><para>
If you are going to set the weight of a connection, you need
to first know the state of the LVS.
If the service is not already in the <command>ipvsadm</command> table, you add (-a) it.
If the service is already in the <command>ipvsadm</command> table, you edit (-a) it.
There is no command to just set the weight no matter what the state.
A patch exists to do this (from Horms) but Wensong doesn't want to
include it.
Scripts which dynamically add, delete or change weights on services
will have to know the state of the LVS before making any changes,
or else trap errors from running the wrong command.
	</para>
	</section>
	<section id="setting_initial_weights">
	<title>Setting initial weights</title>
	<para>
If your hardware is all the same, you set then all to the same weight (1:1:1.., or 1000:1000:1000, it's the
ratio that's important, not the value).
What if you have a bunch of different hardware and you don't know what weight to set for each?
	</para>
	<para>
Malcolm Turnbull <emphasis>malcolm (at) loadbalancer (dot) org</emphasis> 13 Nov 2008 
	</para>
	<para>
Run them all on the same weight for a while and see how they get
loaded, then decide if you need to play with the weights or just add
more servers.
In a layer 4 balanced cluster I normally recommend no greater than 40%
utilisation as a rule of thumb to cope with peaks in demand.
	</para>
	<para>
Graeme
	</para>
	<para>
Ensure you start with (for example) 100/100/100, or 1000/1000/1000. It's
easier to juggle the weights with those values than 1/1/1 !
	</para>
	</section>
	<section id="dynamically_changing_weights">
	<title>Dynamically changing realserver weights</title>
	<para>
Some law of averaging large numbers predicts that realservers with large
numbers of clients should have nearly the same load.
In practice, realservers can have widely different loads or numbers of connections.
Presumably this is for services where a small number of clients can saturate a realserver.
LVS's serving static html pages should have even loads on the realservers.
	</para>
	<para>
Leonard Soetedjo <emphasis>Leonard (at) axs (dot) com (dot) sg</emphasis>
	</para>
	<blockquote>
From reading the howto,
mon doesn't handle dynamically changing the realserver weights.
Is it advisable to create a monitoring program that changes the
weightage of the realserver?
The program will check the worker's load,
memory etc and reduce or increase the weight
in the director based on those information.
	</blockquote>
	<para>
Malcolm Turnbull <emphasis>Malcolm.Turnbull (at) crocus (dot) co (dot) uki </emphasis>
09 Dec 2002
	</para>
	<para>
Personaly I think it adds complication you shouldn't require...
As your servers are running the same app they should respond in roughly
the same way to traffic..
If you have a very fast server reduce its weight.
If you have some very slow pages.. i.e. Global Search...
Then why not set up another VIP to make sure that all requests to
search.mydomain.com are evenly distributed... or restricted to a couple
of servers (so they don't imapact everyone else..)
	</para>
	<para>
But obviously it all depends on how your app works,
with mine its database performance that is the problem...
Time to look at loadbalancing the DB !,
Does anyone have any experience of doing this with MS SQL server and or PostGreSQL ?
I'm thinking about running the session / sales stuff of the MS SQL box,
and all the readonly content from several readonly PostGreSQL DBs...
Due to licencing costs... :-(.
	</para>
	<para>
OTOH, someone recently spoke
on the list about a monitoring tool which could use plugins to monitor
the realservers.
(Joe - see <link linkend="feedbackd">feedbackd</link>.)
	</para>
	<para>
Lars Marowsky-Bree <emphasis>lmb (at) suse (dot) de</emphasis> 17 Mar 2003
	</para>
	<para>
keep in mind that loadavg is a poor indication of real resource
utilization, but it might be enough.
loadavg needs to be at least normalized via the number of CPUs.
	</para>
	<para>
Andres Tello <emphasis>criptos (at) aullox (dot) com</emphasis> 17 Mar 2003
	</para>
	<para>
I use: ram*speed/1000 to calculate the weight
	</para>

	<para>
Joe
	</para>
	<para>
dsh (http://www.netfort.gr.jp/~dancer/software/dsh.html", machine gone Sep 2004)
is good for running commands (via rsh, ssh) on multiple machines
(machines listed in a file).
I'm using it here to monitor temperatures on multiple machines.
	</para>
	<para>
also see
<xref linkend="procstatd"/>
	</para>
	<para>
Bruno Bonfils
	</para>
	<para>
The loads can become unbalanced even if the realservers are indentical.
Customers can read different pages.
Some of them may have heavy php/sql usage,
which implies a higher load average than a simple static html file.
	</para>
	<para>
Rylan W. Hazelton <emphasis>rylan (at) curiouslabs (dot) com</emphasis> 17 Mar 2003
	</para>
	<para>
I still find large differences in loadaverage of the realservers.
WLC has no idea what else (non httpd) that might be happening on a
server.
Maybe I am compiling something for some reason, or I have a large cron.
It would be nice if LVS could redirect load accordingly.
	</para>
	</section>
	<section id="feedbackd">
	<title>feedbackd</title>
	<para>
Joe, Mar 2003
	</para>
	<para>
Jeremy's
<ulink url="http://www.redfishsoftware.com.au/projects/feedbackd/">feedbackd code and HOWTO</ulink>
(<ulink url="http://www.redfishsoftware.com.au/projects/feedbackd/">feedbackd</ulink>)
is now released.
	</para>
	<para>
Jeremy Kerr <emphasis>jeremy (at) redfishsoftware (dot) com (dot) au</emphasis> 09 Dec 2002:
	</para>
	<para>
As I've said earlier (check out the thead starting at
http://www.in-addr.de/pipermail/lvs-users/2002-November/007264.html ), 
the software sends server load information to the director to be inserted in to
the ipvs weighting tables.
	</para>
	<para>
I'm busy writing up the benchmarking results at the moment, and I'll post a
link to the paper (and software) soon. In summary: when the simulation
cluster is (intentionally) unbalanced, the feedback software sucessfully
evens the load between all servers.
	</para>
	<para>
Jeremy at one stage had plans to merge his code with Alexandre's code, but
(Aug 2004) he's not doing anything about it at the moment (he has a real job now).
	</para>
	<para>
Jeremy Kerr <emphasis>jeremy (at) redfishsoftware (dot) com (dot) au</emphasis> 04 Feb 2005
	</para>
	<para>
Everything's available at 
<ulink url="http://ozlabs.org/~jk/projects/feedbackd/">feedbackd</ulink>
(http://ozlabs.org/~jk/projects/feedbackd/).
	</para>

	<para>
Michal Kurowski <emphasis>mkur (at) gazeta (dot) pl</emphasis> 19 Jan 2007
	</para>
	<para>
I want to distribute the load based on criteria such as:
	</para>
	<itemizedlist>
		<listitem>
disk usage
		</listitem>
		<listitem>
OS load average
		</listitem>
		<listitem>
CPU usage
		</listitem>
		<listitem>
custom hooks into my own software
		</listitem>
		<listitem>
You Name It (TM)
		</listitem>
	</itemizedlist>
	<para>
<command>feedbackd</command> has got CPU-monitoring only by default.
It also has a perl plugin that's supposed to let you code something revelant to you quickly. 
That's a perfect idea except the original perl plugin is not fully functional, 
because it breaks some rules regarding linking to C-based modules.
	</para>
	<para>
I wrote <ulink url="files/feedbackd-agent.patch">feedbackd-agent.patch</ulink>
that's solves the problem (it's against the latest release - 0.4, and I've sent Jeremy a copy). 
	</para>
	</section>
	<section id="lvs-kiss">
	<title>lvs-kiss</title>
	<para>
Per Andreas Buer <emphasis>perbu (at) @linpro (dot) .no </emphasis> 14 Dec 2002
	</para>
	<para>
I ran into the same problem this summer. I was setting up a loadbalanced
SMTP cluster - and I wanted to distribute the incomming connections
based on number of e-mails in the mail-servers queues.
We ended up making our own program to do this. Later, I made the thing a
bit more generic and released it. You might want to check it out
	</para>
	<para>
http://www.linpro.no/projects/lvs-kiss/
	</para>
	<para>
lvs-kiss distributes incomming connections based on some numerical value
- as long as you are able to quantify it - it can be used. It can also
time certain test in order to acquire the load of the realservers.
	</para>
	</section>
	<section id="threshold" xreflabel="connection threshold">
	<title>connection threshold</title>
	<note>
according to my dictionary, the spelling is <emphasis role="bold">threshold</emphasis>
and not the more logical <filename>threshhold</filename> as found in many 
webpages (see google: "threshhold dictionary"). 
	</note>
	<para>
If the realservers are limited in the number of connections they can support,
you can use the connection threshold in <command>ipvsadm</command>
(in ip_vs 1.1.0). See the Changelog and man ipvsadm. This
functionality is derived from Ratz's original patches.
	</para>
	<para>
Matt Burleigh
	</para>
	<blockquote>
Is there a stock Red Hat kernel with a new enough version of ip_vs to
include connection thresholds?
	</blockquote>
	<para>Ratz 19 Dec 2002:
I've done the original patch for 2.2.x kernels but I've never ported
it to 2.4.x kernels. I don't know if RH has done so.
In the newest LVS release for 2.5.x kernels the same concept is there,
so with a bit of coding (maybe even luck) you could use that.
	</para>
	<para>
ratz <emphasis>ratz (at) tac (dot) ch</emphasis> 2001-01-29
	</para>
	<para>
This patch on top of ipvs-1.0.3-2.2.18 adds support for threshold
settings per realserver for all schedulers that have the -w option.
	</para>
	<note>
As of Jun 2003, patches are available for 2.4 kernels. All patches are on
<ulink url="http://www.drugphish.ch/patches/ratz/LVS/">Ratz's LVS page</ulink>.
Patches are in active development (<emphasis>i.e.</emphasis> you'll be helping
with the debugging), look at the mailing list for updates.
	</note>
	<para>
Horms 30 Aug 2004
	</para>
	<para>
LVS in 2.6 has its own connection limiting code.
There isn't a whole lot too it. Just get <command>ipvadm</command> for 2.6 and take a look
in the man page. It has details on how the connection thresholds can be
set. Its pretty straight forward as I recall.
	</para>
	<para>
Anon
	</para>
	<para>
Is there any way to
limit connections per IP through IPVS, to mimic the netfilter connection
limit module ipt_connlimit?
I see ipvsadm's threshold option, but it does totals per server.
	</para>
	<para>
Ratz 15 Feb 2007
	</para>
	<para>
how exactly is the threshold option (per RS)
different to the ipt_connlimit regarding the service -> RS pool mapping? If
you need source IP limiting you're better off using QoS anyway.
	</para>
		<section>
		<title>Description/Purpose</title>
		<para>
I was always thinking of how a kernel based implementation of
connection limitation per realserver would work and how it could
be implemented so while waiting in the hospital for the x-ray I
had enough time to write up some little dirty hack to show a
proof of concept. It works like follows. I added three new entries
to the ip_vs_dest() struct, u_thresh and l_thresh in ip_vs.* and
I modified the <command>ipvsadm</command> to add the two new options x and y.
A typical setup would be:
		</para>
<programlisting><![CDATA[
director:/etc/lvs# ipvsadm -A -t 192.168.100.100:80 -s wlc
director:/etc/lvs# ipvsadm -a -t 192.168.100.100:80 -r 192.168.100.3:80 -w 3 -x 1145 -y 923
director:/etc/lvs# ipvsadm -a -t 192.168.100.100:80 -r 192.168.100.3:80 -w 2 -x 982 -y 677
director:/etc/lvs# ipvsadm -a -t 192.168.100.100:80 -r 127.0.0.1:80 -w 1 -x 100 -y 50
]]></programlisting>
		<para>
So, this means, as soon as (dest->inactconns + dest->activeconns)
exceed the x value the weight of this server is set to zero. As
soon as the connections drop below the lower threshold (y) the
weight is set back to the initial value.
What is it good for? Yeah well, I don't know exactly, imagine yourself,
but first of all this is proposal and I wanted to ask for a discussion
about a possible inclusion of such a feature or even a derived one into
the main code (of course after fixing the race conditions and bugs and
cleaning up the code) and second, I found out with tons of talks with
customers that such a feature is needed, because also commercial lb
have this and managers always like to have a nice comparision of all
features to decide which product they take. Doing all this in user-
space is unfortunately just not atomic enough.
		</para>
		<para>
Anyway, if anybody else thinks that such a feature might be vital
for inclusion we can talk about it. If you look at the code, it
wouldn't break anything and just add two lousy CPU cycles for checking
if u_thresh is &lt;0. This feature can easily be disabled by just
setting u_thresh to zero or not even initialize it.
		</para>
		<para>
Well, I'm open for discussion and flames. I have it running in
production :) but with a special SLA. I implemented the last
server of resort which works like this: If all RS of a service
are down (healthcheck took it out or treshhold check set weight
to zero), my userspace tool automagically invokes the last
server of resort, a tiny httpd with a static page saying that
the service is currently unavailable. This is also useful if you
want to do maintainance of the realservers.
		</para>
		<para>
I already implemented a dozen of such setups and they work all
pretty well.
		</para>
		<para>
How we will defend against DDoS (distributed DoS)?
		</para>
		<blockquote>
I'm using a packetfilter and in special zones a firewall after the
packetfilter ;) No seriously, I personally don't think the LVS should
take too much part on securing the realservers It's just another part
of the firewall setup.
		</blockquote>
		<para>
        The problem is that LVS has another view for the realserver
load. The director sees one number of connections the realserver
sees another one. And under attack we observe big gap between the
active/inactive counters and the used threshold values. In this case
we just exclude all realservers. This is the reason I prefer the
more informed approach of using agents.
		</para><para>
Using the number of active
or inactive connections to assign a new weight is _very_ dangerous.
		</para>
		<blockquote>
			<para>
I know, but OTOH, if you set a threshold and my code takes the
server out, because of a well formated DDoS attack, I think it
is even better than if you would allow the DDoS and maybe kill the
realservers http-listener.
			</para>
			<blockquote>
				<para>
        No, we have two choices:
				</para><para>
- use SYN cookies and much memory for open requests, accept more
valid requests
				</para><para>
- don't use SYN cookies, drop the requests exceeding the backlog length,
drop many valid requests but the realservers are not overloaded
				</para><para>
In both cases the listeners don't see requests until the handshake is
completed (Linux).
				</para>
			</blockquote>
			<para>
BTW, what if you enable the defense
strategies of the loadbalancer? I've done some tests and I was
able to flood the realservers by sending forged SYNs and timeshifted
SYN-ACKs with the expected seq-nr. It was impossible to work on
the realservers unless of course I enabled the TCP_SYNCOOKIES.
			</para>
		</blockquote>
		<para>
        Yes, nobody claims the defense strategies guard the real
servers. This is not their goal. They keep the director with more
free memory and nothing more :) Only drop_packet can control the
request rate but only for the new requests.
		</para>
		<blockquote>
I then enabled my patch and after the connections exceeded the
threshold, the kernel took the server out temporarily by setting
the weight to 0. In that way the server was usable and I could
work on the server.
		</blockquote>
		<para>
        Yes but the clients can't work, you exclude all servers
in this case because the LVS spreads the requests to all servers
and the rain becomes deluge :)
		</para><para>
In theory, the number of connections is related to the load but
this is true when the world is ideal. The inactive counter can
be set with very high values when we are under attack. Even the WLC
method loads proportionatly the realservers but they are never
excluded from operation.
		</para>
		<blockquote>
			<para>
True, but as I already said. I think LVS shouldn't replace a fw.
I normally have a router configured properly, then a packetfilter,
then a firewall or even another but stateful packetfilter. See,
the patch itself is not even mandatory. I normal setup, my code
is not even touched (except the ``if'':).
			</para>
			<blockquote>
        I have some thoughts about limiting the traffic per
connection but this idea must be analyzed.
			</blockquote>
			<para>
Hmm, I just want to limit the amount of concurrent connections
per realserver and in the future maybe per service. This saved
me quite some lines of code in my userspace healthchecking
daemon.
			</para>
		</blockquote>
		<para>
        Yes, you vote for moving some features from user to the
kernel space. We must find the right balance: what can be done in
LVS and what must be implemented in the user space tools.
		</para><para>
The other alternatives
are to use the Netfilter's "limit" target or QoS to limit the
traffic to the realservers.
		</para>
		<blockquote>
But then you have to add quite some code. The limit target has
no idea about LVS tables. How should this work, f.e. if you
would like to rate limit the amount of connections to a realserver?
		</blockquote>
		<para>
        May be we can limit the SYN rate. Of course, that not covers
all cases, so my thought was to limit the packet rate for all states
or per connection, not sure, this is an open topic. It is easy to open
a connection through the director (especially in LVS-DR) and then
to flood with packets this connection. This is one of the cases where
LVS can really guard the realservers from packet floods. If we
combine this with the other kind of attacks, the distributed ones,
we have better control. Of course, some QoS implementations can
cover such problems, not sure. And this can be a simple implementation,
of course, nobody wants to invent the wheel :)
		</para><para>
        Let's analyze the problem. If we move new connections from
"overloaded" realserver and redirect them to the other realservers we
will overload them too.
		</para>
		<blockquote>
No, unless you use a old machine. This is maybe a requirement of
an e-commerce application. They have some servers and if the servers
are overloaded (taken out by my user-space healthchecking daemon
because the response time it to high or the application daemon is
not listening anymore on the port) they will be taken out. Now I
have found out that by setting thresholds I could reduce the down-
time of flooded server significantly. In case all servers were
taken out or their weights were set to 0 the userspace application
sets up a temporarily (either local route or another server) new
realserver that has nothing else to do then pushing a static webpage
saying that the service is currently unavailable due to high
server load or DDoS attack or whatever. Put this page behind a
TUX 2.0 and try to overflow it. If you can, apply the zero-copy
patches of DaveM. No way you will find such a fast (88MBit/s
requests!!) Link to saturate the server.
		</blockquote>
		<para>
        Yes, I know that this is a working solution. But see, you
exclude all realservers :) You are giving up. My idea is we to find
a state when we can drop some of the requests and to keep the
realservers busy but responsive. This can be a difficult task but
not when we have the help from our agents. We expect that many
valid requests can be dropped but if we keep the realserver in
good health we can handle some valid requests because nobody knows
when the flood will stop. The link is busy but it contains valid
requests. And the service does not see the invalid ones.
		</para>
		<para>
IMO, the problem is that there are
more connection requests than the cluster can handle. The solutions
to try to move the traffic between the realservers can only cause
more problems. If at the same time we set the weights to 0 this
leads to more delay in the processing. May be more useful is to
start to reduce the weights first but this again returns us to
the theory for the smart cluster software.
		</para>
		<para>
        So, we can't exit from this situation without dropping
requests. There is more traffic that can't be served from the cluster.
		</para>
		<para>
        The requests are not meaningful, we care how much load they
introduce and we report this load to the director. It can look, for
example, as one value (weight) for the real host that can be set
for all real services running on this host. We don't need to generate
10 weights for the 10 real services running in our real host. And
we change the weight on each 2 seconds for example. We need two
syscalls (lseek and read) to get most of the values from /proc fs.
But may be from 2-3 files. This is in Linux, of course. Not sure
how this behaves under attack. We will see it :)
		</para>
		<blockquote>
Obviously yes, but if you also include the practical problem of
SLA with customers and guaranteed downtime per month I still have
to say that for my deploition (is this the correct noun?) I go
better with my patch in case of a DDoS and enabled LVS defense
strategies then without.
		</blockquote>
		<para>
If there is no cluster software to keep the realservers equally
loaded, some of them can go offline too early.
		</para>
		<blockquote>
The scheduler should keep them equally loaded IMO even in case
of let's say 70% forged packets. Again, if you don't like to
set a threshold, leave it. The patch is open enough. If you like
to set it, set it, maybe set it very high. It's up to you.
		</blockquote>
		<para>
        The only problem we have with this scheme is the ipvsadm
binary. It must be changed (the user structure in the kernel :))
The last change is dated from 0.9.10 and this is a big period :)
But you know what means a change in the user structures :)
		</para>
		<para>
        The cluster software can take the role to monitor the load
instead of relying on the connection counters. I agree, changing the
weights and deciding how much traffic to drop can be explained
with a complex formula. But I can see it only as a complete solution:
to balance the load and to drop the exceeding requests, serve as many
requests as possible. Even the drop_packet strategy can help here,
we can explicitly enable it specifying the proper drop rate. We don't
need to use it only to defend the LVS box but to drop the exceeding
traffic. But someone have to control the drop rate :) If there is no
exceeding traffic what problems we can expect? Only from the bad load
balancing :)
		</para>
		<para>
        The easiest way to control the LVS is
from user space and to leave in LVS only the basic needed support.
This allows us to have more ways to control LVS.
		</para>
		</section>
	</section>
	<section id="flushing_connection_table">
	<title>Flushing connection table</title>
	<para>
Shinichi Kido <emphasis>shin (at) kidohome (dot) ddo (dot) jp</emphasis>
 	</para>
	<blockquote>
I want to reset all the connection
table (the output list by <command>ipvsadm -lc</command> command) 
immediately without waiting for the expire time for all the connection. 
	</blockquote>
	<para> 
Stefan Schlosser <emphasis>castla (at) grmmbl (dot) org</emphasis> 04 Jun 2004
	</para>
	<para>
you may want to try these patches:
	</para>
<programlisting><![CDATA[
http://grmmbl.org/code/ipvs-flushconn.diff
http://grmmbl.org/code/ipvsadm-flushconn.diff
]]></programlisting>
	<para>
and use <command>ipvsadm -F</command>
	</para>
	<para>
Horms <emphasis>horms (at) verge (dot) net (dot) au</emphasis> 04 Jun 2004 
	</para>
	<para>
Another alternative, if you have lvs compiled as a module is
to reload it. This will clear everything.
	</para>
<programlisting><![CDATA[
ipvsadm -C
# remove the ipvs scheduler and other modules
# rmmod ip_vs_wlc
# ...
rmmod ip_vs 
modprobe ip_vs
]]></programlisting>
	<para>
Then again, Shinichi-san, why do you want to clear the connection table?
It might be useful for testing. But I am not sure what it would
be useful for in production.
	</para>
	<para>
Joe
	</para>
	<para>
In general it's not good for a server to accept a connection and then unilaterally
break it. You should let the connections expire. If you don't want any new
connections, just set weight=0.
	</para>
	</section>
	<section id="thundering_herd" xreflabel="thundering herd problem">
	<title>Thundering herd problem, Slow start code for realserver(s) coming on line</title>
	<para>
Despite what you may have read in the mailing list 
and possibly in earlier versions of this HOWTO, 
there is no slow start for realservers coming on line
(I thought it was in the code from the very early days).
If you bring a new realserver on-line with *lc scheduling,
the new machine, having less connections (<emphasis>i.e.</emphasis> none) 
will get all the new connections.
This will likely stress the new realserver.
	</para>
	<para>
As Jan Klopper points out (11 Mar 2006), you don't get the thundering herd
problem with round robin scheduling. 
In this case the number of connections will even out when the old
connections expire (for http this may only be a few minutes).
It would be simple enough to bring up a new realserver with all rules being rr,
then after 5mins change over to lc (if you want lc).
	</para>
	<para>
Horms says (off-line Dec 2006) that it's simple enough to use the 
in-kernel timers to handle this problem; he just hasn't done it.
Some early patches to handle the problem received zero response,
so he dropped it.
	</para>
	<para>
Christopher Seawood <emphasis>cls (at) aureate (dot) com</emphasis>
	</para>
	<para>
LVS seems to work great until a server goes down (this is where
<command>mon</command> comes in). Here's a couple of things to keep in mind.  If
you're using the Weighted Round-Robin scheduler, then LVS will
still attempt to hit the server once it goes down. If you're
using the Least Connections scheduler, then all new connections
will be directed to the down server because it has 0 connections.
You'd think using mon would fix these problem but not in all
cases.
	</para>
	<para>
Adding mon to the LC setup didn't help matters much. I took one
of three servers out of the loop and waited for mon to drop the
entry.  That worked great.  When I started the server back up,
mon added the entry.  During that time, the 2 running servers had
gathered about 1000 connections apiece.  When the third server
came back up, it immediately received all of the new connections.
It kept receiving all of the connections until it had an equal
number of connections with the other servers (which by this
time...a minute or so later...had fallen to ~700). By this time,
the 3rd server had been restarted after due to triggering a high
load sensor also monitoring the machine (a necessary evil or so
I'm told).  At this point, I dropped back to using WRR as I could
envision the cycle repeating itself indefinitely.
	</para>
	<para>
Horms has fixed this problem with a patch to <command>ipvsadm</command>.
	</para>
	<para>
Horms <emphasis>horms (at) verge (dot) net (dot) au</emphasis> 23 Feb 2004
	</para>
	<para>
Here is a 
<ulink url="files/thundering_herd.diff">patch</ulink>
(http://www.austintek.com/LVS/LVS-HOWTO/HOWTO/files/thundering_herd.diff)
that implements slow start for the WLC scheduler.
This is designed to address the problem where a realserver is added
to the pool and soon inundated with connections. This is sometimes
refered to as the thundering herd problem and was recently
the topic of a thread on this list "Easing a Server into Rotation".
http://marc.theaimsgroup.com/?l=linux-virtual-server&amp;m=107591805721441&amp;w=2
	</para>
	<para>
The patch has two basic parts.
	</para>
	<itemizedlist>
		<listitem>
		<para>
ip_vs_ctl.c:
		</para>
		<para>
When the weight of a realserver is modified (or a realserver is added),
set the IP_VS_DEST_F_WEIGHT_INC or IP_VS_DEST_F_WEIGHT_DEC flag
as appropriate and put the size of the change in dest.slow_start_data.
		</para>
		<para>
This information is intended to act as hints for scheduler
modules to implement slow start. The scheduler modules may
completely ignore this information without any side effects.
		</para>
		</listitem>
		<listitem>
		<para>
ip_vs_wlc.c:
		</para>
		<para>
If IP_VS_DEST_F_WEIGHT_DEC is set then the flag is zeroed -
slow start does not come into effect for weight defects.
		</para>
		<para>
If IP_VS_DEST_F_WEIGHT_INC is set then a handicap is calculated.
The flag is then zeroed.
		</para>
		<para>
The handicap is stored in dest.slow_start_data, along with a scaling
factor to allow gradual decay which is stored in dest.slow_start_data2.
The handicap effectively makes the realserver appear to have
more connections than it does, thus decreasing the number of connections
that the wlc scheduler will allocate to it. This handicap is decayed
over time.
		</para>
		</listitem>
	</itemizedlist>
	<para>
Limited debugging information is available by setting
	</para>
<programlisting><![CDATA[
/proc/sys/net/ipv4/vs/debug_level to 1 (or greater).
]]></programlisting>
	<para>
This will show the size of the handicap when it is calculated
and show a message when the handicap is fully decayed.
	</para>
	</section>
	<section id="files_kernel_version_dependant">
	<title>Handling kernel version dependant files <emphasis>e.g.</emphasis> System.map and ipvsadm</title>
	<para>
If you boot with several different versions of the kernel
(particularly switching between 2.2.x and 2.4.x), and
you have executables or directories with contents that
need to match the kernel version
(<emphasis>e.g.</emphasis> System.map, ipvsadm, /usr/src/linux, /usr/src/ipvs),
then you need some
mechanism for making sure that the appropriate executable
or directory is brought into scope.
	</para>
	<para>
Note:klogd is supposed to read files like /boot/System.map-&lt;kernel_version&gt;
allowing you to have several kernels in / (or /boot). However this doesn't
solve the problem for general executables like ipvsadm.
	</para>
	<para>
If you have the wrong version of System.map you'll get
errors when running some commands
(<emphasis>e.g.</emphasis> `ps` or `top`)
	</para>
<programlisting><![CDATA[
Warning: /usr/src/linux/System.map has an incorrect kernel version.
]]></programlisting>
	<para>
If you the ip_vs and <command>ipvsadm</command> don't match, then
<command>ipvsadm</command> will give invalid numbers for IPs and ports
or it will tell you that you don't have <filename>ip_vs</filename> installed.
	</para>
	<para>
As with most problems in computing, this can
be solved with an extra layer of indirection.
I name my kernel versions in /usr/src like
	</para>
<programlisting><![CDATA[
director:/etc/lvs# ls -alF /usr/src | grep 2.19
lrwxrwxrwx   1 root     root           25 Sep 18  2001 linux-1.0.7-2.2.19 -> linux-1.0.7-2.2.19-module/
drwxr-xr-x  15 root     root         4096 Jun 21  2001 linux-1.0.7-2.2.19-kernel/
drwxr-xr-x  15 root     root         4096 Aug  8  2001 linux-1.0.7-2.2.19-module/
lrwxrwxrwx   1 root     root           18 Oct 21  2001 linux -> linux-1.0.7-2.2.19
]]></programlisting>
	<para>
Here I have two versions of ip_vs-1.0.7 for the 2.2.19 kernel,
one built as a kernel module and the other built into the kernel
(you will probably only have one version of ip_vs for any kernel).
I select the one I want to use by making a link from linux-1.0.7-2.2.19
(I do this by hand).
If you do this for each kernel version, then the
/usr/src directory will have several links
	</para>
<programlisting><![CDATA[
director:/etc/lvs# ls -alFrt /usr/src | grep lrw
lrwxrwxrwx   1 root     root           25 Sep 18  2001 linux-1.0.7-2.2.19 -> linux-1.0.7-2.2.19-module/
lrwxrwxrwx   1 root     root           38 Sep 18  2001 linux-0.9.2-2.4.7 -> linux-0.9.2-2.4.7-module-hidden-shared/
lrwxrwxrwx   1 root     root           39 Sep 18  2001 linux-0.9.3-2.4.9 -> linux-0.9.3-2.4.9-module-forward-shared/
lrwxrwxrwx   1 root     root           17 Sep 19  2001 linux-2.4.9 -> linux-0.9.3-2.4.9/
lrwxrwxrwx   1 root     root           40 Oct 11  2001 linux-0.9.4-2.4.12 -> linux-0.9.4-2.4.12-module-forward-shared/
lrwxrwxrwx   1 root     root           18 Oct 21  2001 linux -> linux-0.9.4-2.4.12/
]]></programlisting>
	<para id="rc.system_map">
The last entry, the link from <filename>linux</filename> is
made by 
<ulink url="files/rc.system_map">rc.system_map</ulink>
(http://www.austintek.com/LVS/LVS-HOWTO/HOWTO/files/rc.system_map).
At boot time <filename>rc.system_map</filename> checks the
kernel version (here booted with 2.4.12) and links <filename>linux</filename>
to <filename>linux-0.9.4-2.4.12</filename>.
If you lable ipvsadm, /usr/src/ip_vs and System.map
in a similar way, then <filename>rc.system_map</filename>
will link the correct versions for you.
	</para>
	<para>
<filename>ipvsadm</filename>
versions match ipvs versions and not kernel versions,
but kernel versions are close enough that this scheme works.
	</para>
	</section>
	<section id="limiting_clients" xreflabel="limiting client">
	<title>Limiting number of clients connecting to LVS</title>
	<para>
This comes up occasionally, and Ratz has developed scheduler code that
will handle overloads for realservers
(see <xref linkend="writing_a_scheduler"/> and discussion of schedulers with
memthresh in <xref linkend="hash_table"/>).
	</para>
	<para>
The idea is that after a certain
number of connections, the client is sent to an overload machine with
a page saying "hold on, we'll be back in a sec".
This is useful if you have an SLA saying that no client connect request
will be refused, but you have to handle 100,000 people trying to buy
Rolling Stones concert tickets from your site, who all connect within
30secs of the opening time.
Ratz' code may even be in the LVS code sometime.
Until it is, ask Ratz about it.
	</para>
	<para>
NewsFlash: Ratz' code is out
	</para>
	<para>
Roberto Nibali <emphasis>ratz (at) tac (dot) ch</emphasis> 23 Oct 2003
	</para>
	<para>
http://marc.theaimsgroup.com/?l=linux-virtual-server&amp;m=105914647925320&amp;w=2
	</para>
	<para>
Horms
	</para>
	<para>
The LVS 1.1.x code for the 2.6 kernel allows you to set connection
limits using ipvsadm. This is documented in the ipvsadm man
page that comes with the 1.1.x code.
The limits are currently not available in the 1.0.x code
for the 2.4 kernel. However I suspect that a backport
would not be that difficult.
	</para>
	<para>
Diego Woitasen, Oct 22, 2003
	</para>
	<blockquote>
but what set the IP_VS_DEST_F_OVERLOAD in struct ip_vs_dst?
	</blockquote>
	<para>
Horms 23 Oct 2003
	</para>
	<para>
This relates to LVS's internal handling
of connection thresholds for realservers which is available
in the 1.1.x tree for the 2.6.x kernel (also see 
<xref linkend="threshold"/>).
	</para>
	<para>
IP_VS_DEST_F_OVERLOAD is set and unset by the core LVS code when
the high and low thresholds are passed for a realserver.
If a scheduler honours this flag then it should not allocate
new connections to realservers with this flag set. As far as
I can see all the supplied schedulers honour this flag. But if
a scheduler did not then it would just be ignored. That is real
servers would have new connections allocated regardless of
if IP_VS_DEST_F_OVERLOAD is set or not. It would be as if
no connection thresholds had been set.
	</para>
	<para>
Note that if persistancy is in use then subsequent connections
to the same realserver for a given client within the persistancy
timeout are not scheduled as such. Thus additional connections
of this nature can be allocated to a realserver even if
it has been marked IP_VS_DEST_F_OVERLOAD. This, IMHO, is
a desirable behaviour.
	</para>
	<blockquote>
ok, I saw that IP_VS_DEST_F_OVERLOAD is set and unset by the core LVS,
but I can't find where the thresholds are set. As can I see, this
thresholds are always set to Zero in userpace.
Is this right?
	</blockquote>
	<para>
No.
In the kernel the threshoulds are set by code in ip_vs_ctl.c
(I guess, as that is where all other configuration from user-space
is handled). If you get the version of ipvsadm that comes with
LVS source that supports IP_VS_DEST_F_OVERLOAD then
it has command line options to set the thresholds.
	</para>

	<para>
Steve Hill
	</para>
	<blockquote>
A number of the schedulers seem to use an is_overloaded() function that 
limits the number of connections to twice the server's weight.
	</blockquote>
	<para>
Ratz 03 Aug 2004
	</para>
	<para>
For the sake of discussion I'll be referring to the 2.4.x kernel. We 
would be talking about this piece of jewelry:
	</para>
<programlisting><![CDATA[
static inline int is_overloaded(struct ip_vs_dest *dest)
{
         if (atomic_read(&dest->activeconns) > 
atomic_read(&dest->weight)*2) {
                 return 1;
         }
         return 0;
}
]]></programlisting>
	<para>
I'm a bit unsure about the semantics of this is_overloaded 
regarding it's mathematical background. Wensong, what was the reason to 
arbitraly us twice the amount of activeconns for the overoad criteria?
	</para>
	<itemizedlist>
		<listitem>
<filename>dest->activeconns</filename> has such a short life span, 
it hardly represents nor reflects the current RS load in any way I could imagine.
		</listitem>
		<listitem>
2.4.x and 2.6.x differ in what they consider a destination to be
overloaded. IP_VS_DEST_F_OVERLOAD is set when ip_vs_dest_totalconns
exceeds the upper threshold limit and totalconns means currently
active + inactive connections which is also kind of unfortunate. And
yes, there is some more code I haven't mentioned yet.
		</listitem>
	</itemizedlist>
	<blockquote>
I'm using 
the dh scheduler to balance across 3 machines - once the connections 
exceed twice the weight, it refuses new connections from IP addresses that 
aren't currently persistent.
	</blockquote>
	<para>
Which kernel?
And 2.4.x and 2.6.x contain 
similar (although not sync'd ... sigh) code regarding this feature:
	</para>
	<blockquote>
2.4.24 sorry
	</blockquote>
<programlisting><![CDATA[
ratz@webphish:/usr/src/linux-2.6.8-rc2> grep -r is_overloaded *
net/ipv4/ipvs/ip_vs_sh.c:static inline int is_overloaded(struct ip_vs_dest *dest)
net/ipv4/ipvs/ip_vs_sh.c:           || is_overloaded(dest)) {
net/ipv4/ipvs/ip_vs_lblcr.c:is_overloaded(struct ip_vs_dest *dest, struct ip_vs_service *svc)
net/ipv4/ipvs/ip_vs_lblcr.c:            if (!dest || is_overloaded(dest, svc)) {
net/ipv4/ipvs/ip_vs_dh.c:static inline int is_overloaded(struct ip_vs_dest *dest)
net/ipv4/ipvs/ip_vs_dh.c:           || is_overloaded(dest)) {
net/ipv4/ipvs/ip_vs_lblc.c:is_overloaded(struct ip_vs_dest *dest, struct ip_vs_service *svc)
net/ipv4/ipvs/ip_vs_lblc.c:                 || is_overloaded(dest, svc)) { ratz@webphish:/usr/src/linux-2.6.8-rc2>


ratz@webphish:/usr/src/linux-2.4.27-rc4> grep -r is_overloaded *
net/ipv4/ipvs/ip_vs_sh.c:static inline int is_overloaded(struct ip_vs_dest *dest)
net/ipv4/ipvs/ip_vs_sh.c:           || is_overloaded(dest)) {
net/ipv4/ipvs/ip_vs_lblcr.c:is_overloaded(struct ip_vs_dest *dest, struct ip_vs_service *svc)
net/ipv4/ipvs/ip_vs_lblcr.c:            if (!dest || is_overloaded(dest, svc)) {
net/ipv4/ipvs/ip_vs_lblc.c:is_overloaded(struct ip_vs_dest *dest, struct ip_vs_service *svc)
net/ipv4/ipvs/ip_vs_lblc.c:                 || is_overloaded(dest, svc)) {
net/ipv4/ipvs/ip_vs_dh.c:static inline int is_overloaded(struct ip_vs_dest *dest)
net/ipv4/ipvs/ip_vs_dh.c:           || is_overloaded(dest)) {
]]></programlisting>
	<para>
Assymetric coding :-)
	</para>
	<blockquote>
This in itself isn't really a problem, but I can't find this behaviour 
actually documented anywhere - all the documentation refers to the 
weights as being "relative to the other hosts" which means there should 
be no difference between me setting the weights on all hosts to 5 or 
setting them all to 500.
Multiplying the 
weight by 2 seems very arbitrary, although in itself there is no real 
problem (as far as I can tell) with limiting the connections like that so 
long as it's documented.
	</blockquote>
	<para>
This is correct. I'm a bit unsure as to what your exact problem is, but 
a kernel version would already help, although I believe you're using a 
2.4.x kernel. Normally the is_overloaded() function was designed to be 
used by the threshold limitation feature only which is only present as a 
shacky backport from 2.6.x. I don't quite understand the is_overloaded() 
function in the ip_vs_dh scheduler, OTOH, I really haven't been using it 
so far.
	</para>
	<blockquote>
		<para>
I have 3 squid servers and had set them all to a weight of 5 (since they 
are all identical machines and the docs said that the weights are 
relative to eachother).  What I found was that once there were >10 
concurrent connections any new hosts that tried to make a connection (i.e. 
any host that isn't "persisting") would have it's connection rejected 
outright.  After some reading through the code I discovered the 
is_overloaded condition, which was failing in the case of > 10 connections 
and so I have increased all the weights to 5000 (to all intents and 
purposes unlimited) which has solved the problem.
		</para>
		<para>
Oddly there is another LVS server with a similar configuration which isn't 
showing this behaviour, but I cannot find any significant difference in 
the configuration to account for it.
		</para>
		<para>
The primary use for LVS in this case is failover in the event of one of 
the servers failing, although load balancing is a good side effect.  I'm 
using ldirectord to monitor the realservers and adjusting the LVS 
settings in response to an outage.  At the moment, for some reason it 
doesn't seem to be doing any load balancing at the moment (something I am 
looking into) - it is just using a single server, although if that server 
is taken down it does fail over correctly to one of the other servers.
		</para>
		<para>
Sorry, I've just realised I've been exceptionally stupid about this bit - 
I should be using the SH scheduler instead of DH.
		</para>
	</blockquote>
	<para>
One problem is that activeconns doesn't define connections and
the implementations for 2.4 and 2.6 differ significantly.
Also <filename>is_overloaded</filename> should be reserved
for another purpose, the threshhold limitation feature.
	</para>
	<para>
Joe: now back into prehistory -
	</para>
	<para>
Milind Patil <emphasis>mpatil (at) iqs (dot) co (dot) in</emphasis> 24 Sep 2001
	</para>
	<blockquote>
I want to limit number of users accessing the LVS services at any given
time. How can I do it.
	</blockquote>
	<para>
Julian
	</para>
	<itemizedlist>
		<listitem>
		<para>
for non-NAT cluster (maybe stupid but interesting)
		</para>
		<para>
	May be an array from policers, for example, 1024 policers or
an user-defined value, power of 2. Each client hits one of the policers
based on their IP/Port. This is mostly a job for QoS ingress, even the
distributed attack but may be something can be done for LVS? May be we
better to develop a QoS Ingress module? The key could be derived
from CIP and CPORT, may be something similar to SFQ but without queueing.
It can be implemented may be as a patch to the normal policer but with
one argument: the real number of policers. Then this extended policer
can look into the TCP/UDP packets to redirect each packet to one of the
real policers.
		</para>
		</listitem>
		<listitem>
			<para>
	for NAT only
			</para>
			<para>
	Run SFQ qdisc on your external interface(s). It seems this is
not a solution for DR method. Of course, one can run SFQ on its uplink
router.
			</para>
		</listitem>
		<listitem>
			<para>
Linux 2.4 only
			</para>
			<para>
	iptables has support to limit the traffic but I'm not sure
whether it is useful for your requirements. I assume you want to set
limit to each one of these 1024 aggregated flows.
			</para>
		</listitem>
	</itemizedlist>
	<para>
Wenzhuo Zhang
	</para>
	<para>
Is anybody actually using the ingress policer for anti-DoS? 
I tried it several days ago using the script in the iproute2
package: iproute2/examples/SYN-DoS.rate.limit.
I've tested it against different 2.2 kernels (2.2.19-7.0.8 - redhat
kernel), 2.2.19, 2.2.20preX, with all QoS related functions either
compiled into the kernel or as modules) and different versions of
iproute2. In all cases, tc fails to install the ingress qdisc policer:
	</para>
<programlisting><![CDATA[
root@panda:~# tc qdisc add dev eth0 handle ffff: ingress
RTNETLINK answers: No such file or directory
root@panda:~# /tmp/tc qdisc add dev eth0 handle ffff: ingress
RTNETLINK answers: No such file or directory
]]></programlisting>
	<para>
Julian
	</para>
	<para>
	For 2.2, you need the ds-8 package, at
<ulink url="http://diffserv.sourceforge.net/">
Package for Differentiated Services on Linux</ulink>.
Compile tc by setting TC_CONFIG_DIFFSERV=y in Config.
The right command is:
	</para>
<programlisting><![CDATA[
	tc qdisc add dev eth0 ingress
]]></programlisting>
	<para>
Ratz
	</para>
	<para>
		The 2.2.x version is not supported anymore. The
advanced routing documentation says to only use 2.4.
	For 2.4, ingress is in the kernel but it is still unusable for
more than one device (look in linux-netdev for reference).
	</para>
	<para>
James Bourne <emphasis>james (at) sublime (dot) com (dot) au</emphasis>
25 Jul 2003
	</para>
	<blockquote>
		<para>
I was after some samples or practical suggestion in regard to Rate Limiting
and Dynamically Denying Services to abusers on a per VIP basis.
I have had a look at the sections in the HOWTO on
"Limiting number of clients connecting to LVS"
and
		</para>
		<para>
<ulink url="http://www.linuxvirtualserver.org/docs/defense.html">
http://www.linuxvirtualserver.org/docs/defense.html</ulink>.
		</para>
	</blockquote>
	<para>
Ratz
	</para>
	<para>
This is a defense mechanism which is always unfair. You don't want that
from what I can read.
	</para>
	<blockquote>
		<para>
Specifically, we are running web based competition entries (<emphasis>e.g.</emphasis>
type in your three bar codes) out of our LVS cluster and want to limit those who might
construct "bots" to auto-enter. The application is structured so that you have
to click through multiple pages and enter a value that is represented in a
dynamically generated PNG.
		</para>
		<para>
I would like to:
		</para>
		<orderedlist>
			<listitem>
rate limit on each VIP (we can potentially do this at the firewall)
			</listitem>
			<listitem>
ban a source ip if it goes beyond a certain number "requests-per-time-interval"
			</listitem>
			<listitem>
dynamically take a vip offline if it goes beyond a certain number of
"requests-per-time-interval"
			</listitem>
			<listitem>
toss all "illegal requests" - eg. codered, nimda etc.
			</listitem>
		</orderedlist>
		<para>
Perhaps a combination of iptables, QoS, SNORT etc. would do the job??
		</para>
	</blockquote>
	<para>
Roberto Nibali 25 Jul 2003
	</para>
	<blockquote>
1. rate limit on each VIP (we can potentially do this at the firewall)
	</blockquote>
	<para>
Hmm, you might need to use QoS or probably better would be to write a
scheduler which uses the rate estimator in IPVS.
	</para>
	<blockquote>
2. ban a source ip if it goes beyond a certain number "requests-per-time-interval"
	</blockquote>
	<para>
A scheduler could do that for you, although I do not think this is a
good idea.
	</para>
	<blockquote>
3. dynamically take a vip offline if it goes beyond a certain number of
"requests-per-time-interval"
	</blockquote>
	<para>
Quiescing the service should be enough, you don't want to put on a
penalty on other people, you simple want to keep your maximum request
-per-time rate.
	</para>
	<blockquote>
4. toss all "illegal requests" - eg. codered, nimda etc.
	</blockquote>
	<para>
This has nothing to do with LVS ;).
	</para>
	<para>
QoS is certainly suitable for 1). For 2) and 3) I think you would need
to write a scheduler.
	</para>

	<para>
Max Sturtz
	</para>
	<blockquote>
I know that iptables can block connections if they exceed a specified
number of connections per second (from anywhere).
The question is, is
anybody doing this on a per-client basis, so that if any particular IP is
sending us more than a specified number of connections per second, they
get blocked but all other clients can keep going?
	</blockquote>
	<para>
ratz 01 Dec 2003
	</para>
	<para>
Using <filename>iptables</filename> is a very bad practice approach to handle such problems.
You have no information if the IP which is making those request attempts
at a high rate is malicious or friendly. If it's malicious (IP spoofing)
you will block an existing friendly IP.
	</para>
	<blockquote>
several times per week we experience
a traffic storm.  LVS handles it just fine,
but the web-servers get loaded up really bad, and pretty soon our site is
all but un-usable.
We're looking for tools we could use to analyze this
(we use Webalizer for our web-logs-- but it can't tell us who's talking to
us in any given time-frame...)
	</blockquote>
	<para>
Could you describe your overloaded system with some metrics or could you
determine the upper connection threshold where your RS are still working
fine?
You could dump the LVS masquerading table from time to time and grep for
connection templates.
	</para>
	<para>
I see 4 approaches (in no particular order) to this problem:
	</para>
	<itemizedlist>
		<listitem>
LVS tcp defense mechanism, best described in
http://www.linux-vs.org/docs/defense.html
		</listitem>
		<listitem>
L7 load balancer which inspects HTTP content, best described in
http://www.linux-vs.org/software/ktcpvs/ktcpvs.html
    or in the package Readme.
		</listitem>
		<listitem>
Use of the per RS threshold limitation patch I wrote (see <xref linkend="limiting_clients"/>).
		</listitem>
		<listitem>
Use the 
<ulink url="http://www.redfishsoftware.com.au/projects/feedbackd/">feedbackd</ulink>
(http://www.redfishsoftware.com.au/projects/feedbackd/)
architecture to signal the director of network
anomalies based on certain metrics gained on the RSs.
		</listitem>
	</itemizedlist>
	</section>
	<section id="who_is_connecting">
	<title>Who is connecting to my LVS?</title>
	<para>
On the realservers you can look with `netstatn -an`. With LVS, the
director also has information.
			</para><para>
<blockquote><para>
<emphasis>malalon (at) poczta (dot) onet (dot) pl</emphasis> 18 Oct 2001
			</para><para>
How do I know who is connecting to my LVS?
</para></blockquote>
			</para><para>
Julian
			</para><para>
<itemizedlist>
<listitem><para>Linux 2.2: netstat -Mn (or /proc/net/ip_masquerade)
</para></listitem><listitem><para>Linux 2.4: ipvsadm -Lcn (or /proc/net/ip_vs_conn)
</para></listitem></itemizedlist>
	</para>
	</section>
	<section id="experimental_schedulers">
	<title>experimental scheduling code</title><para>
This section is a bit out of date now. See the
<xref linkend="LVS-HOWTO.ipvsadm"/> new schedulers by Thomas Prouell for web caches
and by Henrik Norstrom for firewalls. Ratz <emphasis>ratz (at) tac (dot) ch</emphasis> has produced
a scheduler which will keep activity on a particular realserver
below a fixed level.
			</para><para>
For this next code write to Ty or grab the code off the list server
			</para><para>
<blockquote><para>
Ty Beede <emphasis>tybeede (at) metrolist (dot) net</emphasis> 23 Feb 2000
			</para><para>
     This is a hack to the ip_vs_wlc.c schedualing algorithm.  It is
 curently implemnted in a quick, ad hoc fashion. It's purpose is to
 support limiting the total number of connections to a realserver.
 Currently it is implmented using the weigh value as the upper limit
 on the number of activeconns(connections in an established TCP state).
 This is a very simple implementation and only took a few minutes after
 reading through the source. I would like, however, to develop it further.
			</para><para>
     Due to it's simple nature it will not function in several types of
 enviroments, those based on connectionless protocals (UDP, this uses
 the inactconns variable to keep track of things, simply change the
 activeconns varible-in the weigh check- to inactconns for UDP) and it may
 impose complecations when persistance is implemented.  The current
 algorimthm simply checks that weight > activeconns before including
 a server in the standard wlc scheduling. This works for my enviroment,
 but could be changed to perhaps (weight * 50) > (activeconns * 50) + inactconns to
 include the inactconns but make the activeconns more important in the decison.
			</para><para>
     Currently the greatest weight value a user may specify is approimalty
 65000, independant of this modification. As long as the user keeps most
 importanly the weight values correct for the total number of connections
 and in porportion to one another the things should function as expected.
			</para><para>
     In the event that the cluster is full, all real severs have maxed out,
 then it might be neccessary for overflow control, or the client's end will
 hang. I haven't tested this idea but it could simply be implemented by
 specifing the over flow server last, after the real severs using
 the <command>ipvsadm</command> tool. This will work because as each realserver is added
 using <command>ipvsadm</command> it is put on a list, with the last one added being last
 on the list. The scheduling algorithm traverses this list linearly from
 start to finish and if it finds that all severs are maxed out, then the
 last one will be the overflow and that will be the only one to send traffic to.
			</para><para>
     Anyway this is just a little hack, read the code and it should make sense.
 It has been included as an attachment. If you would like to test this
 simply replace the old ip_vs_wlc.c scheduling file in /usr/src/linux/net/ipv4
 with this one. Compile it in and set the weight on the real severs to the max
 number of connections in an established TCP state or modifiy the source to
 your liking.
			</para><para>
 From: Ty Beede <emphasis>tybeede (at) metrolist (dot) net</emphasis> 28 Feb 2000
			</para><para>
 I wrote a little patch and posted it a few days ago... I indicated that
 overflow might be accomplished by adding the overflow server to the lvs last.
 This statement is completely off the wall wrong. I'm not really sure why I
 thought that would work but it won't, first of all the linked list adds
 each new instance of a real sever to the start of the realservers list,
 not the end like I though.  Also it would be impossible do distingish
 the overflow server from the realservers in the case that not all the
 realservers were busy. I don't know where I got that idea from but I'm
 going to blame it on my "bushy eyed youth".  In responce to needing
 overflow support I'm thinking about implementing "prority groups" into
 the lvs code. This would logically group the real severs into different
 groups, though with a higher priority group would fillup before those
 with a lower grouping.  If anybody could comment on this it would be
 nice to hear what the rest of you think about overflow code.
</para></blockquote>
			</para>
		<section id="developing_schedulers">
		<title>Theoretical issues in developing better scheduling algorithms</title>
		<para>
Julian
			</para><para>
It seems to me it would be useful in some cases to use the total number
of connections to a realserver in the load balancing calculation, in
the case where the realserver participates in servicing a number of
different VIPs.
			</para><para>
<blockquote><para>
Wensong
			</para><para>
Yeah, it is true. Sometimes, we need tradeoff between
simplicity/performance and functionality. Let me think more about
this, and probably maximum connection scheduling together together
too. For a rather big server cluster, there may be a dedicated load
balancer for web traffic and another load balancer for mail traffic,
then the two load balancers may need exchange status periodically, it
is rather complicated.
</para></blockquote>
 Yes, if a realserver is used from two or more directors
 the "lc" method is useless.
<blockquote><para>
 Actually, I just thought that dynamic weight adaption according to
 periodical load feedback of each server might solve all the above
 problems.
</para></blockquote>
			</para><para>
Joe - this is part of a greater problem with LVS, we don't have
 good monitoring tools and we don't have a lot of information on
 the varying loads that realservers have, in order to develope
 strategies for informed load regulation.
See <link linkend="agent">load and failure monitoring</link>.
<blockquote><para>
Julian
			</para><para>
From my experience with realservers for web, the only
 useful parameters for the realserver load are:
			</para><para>
<itemizedlist>
<listitem><para>cpu idle time
			</para><para>
                 If you use realservers with equal CPUs (MHz)
                 the cpu idle time in percents can be used.
                 In other cases the MHz must be included in
                 a expression for the weight.
			</para><para>
</para></listitem><listitem><para>free ram
			</para><para>
                 According to the web load the right expression
                 must be used including the cpu idle time
                 and the free ram.
			</para><para>
</para></listitem><listitem><para>free swap
			</para><para>
                 Very bad if the web is swapping.
			</para><para>
</para></listitem></itemizedlist>
			</para><para>
 The easiest parameter to get, the Load Average is
 always &lt;5. So, it can't be used for weights in this case.
 May be for SMTP ? The sendmail guys use only the load average
 in sendmail when evaluating the load :)
			</para><para>
			</para><para>
 So, the monitoring software must send these parameters
 to all directors. But even now each of the directors use
 these weights to create connections proportionally. So,
 it is useful these parameters for the load to be updated
 in short intervals and they must be averaged for this
 period. It is very bad to use current value for a parameter
 to evaluate the weight in the director. For example, it
 is very useful to use something like "Average value for
 the cpu idle time for the last 10 seconds" and to broadcast
 this value to the director on each 10 seconds. If the
 cpu idle time is 0, the free ram must be used. It depends
 on which resource zeroed first: the cpu idle time or the
 free ram. The weight must be changed slightly :)
			</para><para>
 The "*lc" algorithms help for simple setups, eg.
 with one director and for some of the services, eg http,
 https. It is difficult even for ftp and smtp to use these
 schedulers. When the requests are very different, the
 only valid information is the load in the realserver.
			</para><para>
 Other useful parameter is the network traffic (ftp).
 But again, all these parameters must be used from the director
 to build the weight using a complex expression.
			</para><para>
 I think the complex weight for the realserver
 based on connection number (lc) is not useful due to the
 different load from each of the services. May be for
 the "wlc" scheduling method ? I know that the users
 want LVS to do everything but the load balancing is
 very complex job. If you handle web traffic you can be happy
 with any of the current scheduling methods. I didn't tried
 to balance ftp traffic but I don't expect much help from *lc
 methods. The realserver can be loaded, for example, if you
 build new Linux kernel while the server is in the cluster :)
 Very easy way to switch to swap mode if your load is near 100%.
</para></blockquote>
		</para></section>
	</section>
	<section id="writing_a_scheduler" xreflabel="writing a scheduler">
	<title>Ratz's primer on writing your own scheduler</title>
	<para>
Roberto Nibali <emphasis>ratz (at) tac (dot) ch</emphasis> 10 Jul 2003
	</para>

	<para>
the whole setup roughly works as follows:
	</para>
<programlisting><![CDATA[
struct ip_vs_scheduler {
	struct list_head        n_list;   /* d-linked list head */
	char			*name;    /* scheduler name */
	atomic_t                refcnt;   /* reference counter */
 	struct module		*module;  /* THIS_MODULE/NULL */

	/* scheduler initializing service */
	int (*init_service)(struct ip_vs_service *svc);
	/* scheduling service finish */
	int (*done_service)(struct ip_vs_service *svc);
	/* scheduler updating service */
	int (*update_service)(struct ip_vs_service *svc);

	/* selecting a server from the given service */
	struct ip_vs_dest* (*schedule)(struct ip_vs_service *svc,
				       struct iphdr *iph);
};
]]></programlisting>

	<para>
Each scheduler {rr,lc,...} will have to register itself by initialisation of the
ip_vs_scheduler struct object. As you can see it contains above other data types
4 function pointers:
	</para>
<programlisting><![CDATA[
int (*init_service)(struct ip_vs_service *svc)
int (*done_service)(struct ip_vs_service *svc)
int (*update_service)(struct ip_vs_service *svc)
struct ip_vs_dest* (*schedule)(struct ip_vs_service *svc,struct iphdr *iph)
]]></programlisting>
	<para>
Each scheduler will need to provide a callback function for those prototypes
with his own specific implementation.
	</para>
	<para>
Let's have a look at ip_vs_wrr.c:
	</para>
	<para>
We start with the __init function which is kernel specific. It defines
ip_vs_wrr_init() which in turn calls the required
register_ip_vs_scheduler(&amp;ip_vs_wrr_scheduler). You can see the
ip_vs_wrr_scheduler structure definition just above the __init function. There
you will note following:
	</para>
<programlisting><![CDATA[
static struct ip_vs_scheduler ip_vs_wrr_scheduler = {
         {0},                    /* n_list */
         "wrr",                  /* name */
         ATOMIC_INIT(0),         /* refcnt */
         THIS_MODULE,            /* this module */
         ip_vs_wrr_init_svc,     /* service initializer */
         ip_vs_wrr_done_svc,     /* service done */
         ip_vs_wrr_update_svc,   /* service updater */
         ip_vs_wrr_schedule,     /* select a server from the destination list */
};
]]></programlisting>
	<para>
This now is exactly the scheduler specific object instantiation of the struct
ip_vs_scheduler prototype defined in ip_vs.h. Reading this you can see that the
last for "names" map the function names to be called accordingly.
	</para>
	<para>
So in case of the wrr scheduler, what does the init_service (mapped to the
ip_vs_wrr_init_svc function) do?
	</para>
	<para>
It generates a mark object (used for list chain traversal and mark point) which
gets filled up with initial values, such as the maximum weight and the gcd
weight. This is a very intelligent thing to do, because if you do not do this,
you will need to compute those values every time the scheduler needs to schedule
a new incoming request.
	</para>
	<para>
The latter also requires a second callback. Why? Imagine someone decides to
update the weights of one or more server from user space. This would mean that
the initially computed weights are not valid anymore.
	</para>
	<para>
What can be done against it? We could compute those values every time the
scheduler needs to schedule a destination but that's exactly what we don't want.
So in play comes the update_service protoype (mapped to the ip_vs_wrr_update_svc
function).
	</para>
	<para>
As you can easily see the ip_vs_wrr_update_svc function will do part of what we
did for the init_service: it will compute the new max weight and the new gcd
weight, so the world is saved again. The update_service callback will be called
upon a user space ioctl call (you can read about this in the previous chapter of
this marvellous developer guide :)).
	</para>
	<para>
The ip_vs_wrr_schedule function provides us with the core functionality of
finding an appropriate destination (realserver) when a new incoming connection
is hitting our cluster. Here you could write your own algorithm. You only need
to either return NULL (if no realserver can be found) or a destination which is
of type: struct ip_vs_dest.
	</para>
	<para>
The last function callback is the ip_vs_wrr_done_svc function which kfree()'s
the initially kmalloc()'d mark variable.
	</para>
	<para>
This short tour-de-scheduler show give you enough information to write your own
scheduler, at least in theory :).
	</para>

	<para>
unknown
	</para>
	<blockquote>
I'd like to write a user defined scheduler
to guide the load dispatching
	</blockquote>
	<para>
Ratz 12 Aug 2004
	</para>
	<para>
Check out <filename>feedbackd</filename> 
<link linkend="feedbackd">feedbackd</link>
and see if you miss something there. 
I know that 
this is not what you wanted to hear but to provide a generic API for 
user space deamons to interact directly with a generic scheduler is 
definitely out of scope. One problem is that the process of balancing 
incoming network load is not an atomic operation. It can take minutes, 
hours, days, weeks until you get an equalised load on your servers. 
Having a user space doing premature scheduler updates in a short time 
interval only asks for trouble regarding peak load bouncing.
	</para>
	</section>
	<section id="sysctl" xreflabel="sysctl">
	<title>changing ip_vs behaviour with sysctl flags in /proc</title>
	<para>
You can change the behaviour of ip_vs by pushing bits in the /proc filesystem.
This gives finer control of ip_vs than is available with <command>ipvsadm</command>.
For ordinary use, you don't need to worry about the <filename>sysctl</filename>,
since sensible defaults have been installed.
	</para>
	<para>
Here's a
<ulink url="http://www.linuxvirtualserver.org/docs/sysctl.html">
list of the current sysctls at
http://www.linuxvirtualserver.org/docs/sysctl.html
</ulink>.
Note that older kernels will not have all of these sysctls
(test for the existance of the appropriate file in /proc first).
These sysctls are mainly used for
<xref linkend="bringing_down_persistent_services"/>.
	</para>
	<para>
Some, but not all, of the sysctls are documented in ipvsadm(8)
	</para>
	<para>
(Thanks to Kit Gerrits Dec 2008). There's info on <filename>ip_vs()</filename> sysctls at
<ulink url="http://www.mjmwired.net/kernel/Documentation/networking/ipvs-sysctl.txt">ipvs-sysctl.txt</ulink>
(http://www.mjmwired.net/kernel/Documentation/networking/ipvs-sysctl.txt).
	</para>
	<para>
Horms <emphasis>horms (at ) verge (dot) net (dot) au</emphasis> 11 Dec 2003
	</para>
	<para>
I am still strongly of the opinion that the sysctl variables should
be documented in the ipvsadm man page 
as they are strongly tied to its behaviour.
At the moment we are in a situation where
some are documented in ipvsadm(8), 
while all documented in <filename>sysctl.html</filename>
Yet there is no reference to sysctl.html in ipvsadm(8).
My preference is to merge all the information in sysctl.html into
ipvsadm(8) or perhaps a separate man page. If this is not acceptable
then I would advocate removing all of the sysctl infromation from
ipvsadm(8) and replacing it with a reference to sysctl.html.
Though to be honest, why half the information on configuring LVS
should be in ipvsadm(8) and the other half in sysctl.html
is beyond me.
	</para>
	</section>
	<section id="ipvsadm_counters">
	<title>Counters in ipvsadm</title>
	<para>
Rutger van Oosten <emphasis>r (dot) v (dot) oosten (at) benq-eu (dot) com</emphasis> 09 Oct 2003
	</para>
	<blockquote>
		<para>
When I run
		</para>
<programlisting><![CDATA[
ipvsadm -l --stats
]]></programlisting>
		<para>
it shows connections, packets and bytes in and
out for the virtual services and for the realservers. One would expect that
the traffic for the service is the sum of the traffic to the servers - but
it is not, the numbers don't add up at all, whereas in
		</para>
<programlisting><![CDATA[
ipvsadm -l --rate
]]></programlisting>
		<para>
they do (approximately, not exactly for the bytes per second ones).
For example (LVS-NAT, two realservers, one http virtual service):
		</para>
<programlisting><![CDATA[
# ipvsadm --version
ipvsadm v1.21 2002/11/12 (compiled with popt and IPVS v1.0.10)

# ipvsadm -l --stats
IP Virtual Server version 1.0.10 (size=4096)
Prot LocalAddress:Port               Conns   InPkts  OutPkts  InBytes OutBytes
  -> RemoteAddress:Port
TCP  vip:http                      4239091 31977546 29470876    3692M 26647M
  -> www02:http                    3911835 29405279 26900679    3407M 24292M
  -> www01:http                    3395953 25407180 23257431    2931M 20957M

# ipvsadm -l --rate
IP Virtual Server version 1.0.10 (size=4096)
Prot LocalAddress:Port                 CPS    InPPS   OutPPS    InBPS OutBPS
  -> RemoteAddress:Port
TCP  vip:http                           45      348      314    41739 285599
  -> www02:http                         35      252      216    30416 197101
  -> www01:http                         10       96       98    11323 88497
]]></programlisting>
		<para>
Is this a bug, or am I just missing something?
		</para>
	</blockquote>
	<para>
Wensong 12 Oct 2003
	</para>
	<para>
It's quite possible that the conns/bytes/packets statistics of virtual
service is not the sum of the conns/bytes/packets counters of its realservers,
because some realservers may be removed permanetly. The
connection rate of virtual service is the sum of connection rate of its
realservers, because it is an instant metric at a time.
	</para>
	<para>
In the output of your <command>ipvsadm --l --stats</command>, the counters of virtual
service is less than the sum of the counters of its realservers. I guess
that your virtual service must have been removed after it run for a while,
and then must be created later. In current implementation, if realservers
are to be deleted, they will not be removed permanently, but be put in the
trash, because established connections still refer to them; a server can
be looked up in the trash when it is added back to a service. When a
virtual service is created, it always has counters set to zero, but the
realservers can be picked up from the trash, they have the past counters.
We probably need zero the counters of realservers if the service is a new
one. Anyway, you can do <command>cat /proc/net/ip_vs_stats</command>.
The counters of all
IPVS services is larger than or equal to the sum of realservers.
	</para>
	<blockquote>
You are right - after the weekly reboot last night the numbers do add up.
The realservers have been removed and added in the mean time, but the
virtual services have stayed in place and the numbers are still correct. So
that must be it.
Mystery solved, thank you :-)
	</blockquote>
	</section>
	<section id="exact_counters">
	<title>Exact Counters</title>
	<para>
Guy Waugh <emphasis>gwaugh (at) scu (dot) edu (dot) au</emphasis> 
2005/20/05 
	</para>
	<para>
The 
<ulink url="http://www.austintek.com/LVS/LVS-HOWTO/HOWTO/files/ipvsadm_exact.patch">
ipvsadm_exact.patch 
</ulink>
(http://www.austintek.com/LVS/LVS-HOWTO/HOWTO/files/ipvsadm_exact.patch)
contains a diff for the addition of an <filename>'-x'</filename> or 
<filename>'--exact'</filename> command-line switch to 
<command>ipvsadm</command> (version 1.19.2.2).
The idea behind the new option is to allow users to specify that large 
numbers printed with the <filename>'--stats'</filename> or <filename>'--rate'</filename> 
options are in machine readable bytes, 
rather than in 'human-readable' form (<emphasis>e.g.</emphasis> kilobytes, megabytes).
I needed this to get stats from LVS readable by 
<ulink url="http:/www.nagios.org/">nagios</ulink>
(http:/www.nagios.org/).
	</para>
	</section>
	<section id="TCP_UDP_scheduling" xreflabel="TCP UDP scheduling">
	<title>Scheduling TCP/UDP/SCTP/TCP splicing/</title>
	<note>
		<para>
LVS does not schedule SCTP 
(although people ask about it occasionally).
		</para>
		<para>
SCTP is a connection oriented protocol (like TCP, but not like UDP).
Delivery is reliable (like TCP), but packets are not neccessarily delivered in order.
The Linux-2.6 kernel supports SCTP 
(see <ulink url="http://lksctp.sourceforge.net/">The Linux Kernel sctp project</ulink>
http://lksctp.sourceforge.net/).
For an article on SCTP see
<ulink url="http://www-128.ibm.com/developernetworks/linux/library/l-sctp/?ca=dgr-lnwx01SCTP">Better networking with SCTP</ulink>
(http://www-128.ibm.com/developernetworks/linux/library/l-sctp/?ca=dgr-lnwx01SCTP).
One of the features of SCTP is multistreaming: 
control and data streams are separate streams within an association. 
With tcp to do the same thing, 
you need separate ports (<emphasis>e.g.</emphasis> ftp uses 20 for data, 21 for command) 
or you put both into one connection (<emphasis>e.g.</emphasis> http).
If you use one port then a command will be blocked till queued data is serviced.
If multiple (redundant) routes are available, failover is transparent to the application.
(Thus the requirement that packets not neccessarily be delivered in order.)
<xref linkend="SIP"/> is can use SCTP (I only know about SIP using UDP).
		</para>
	</note>
        <note>
		<para>
Ratz 20 Feb 2006
		</para>
		<para>
There is a remotely similar approach in the 
<ulink url="http://www.linuxvirtualserver.org/software/tcpsp/">TCP splicing code for LVS</ulink>.
(http://www.linuxvirtualserver.org/software/tcpsp/).
It's only a small subset of SCTP.
		</para>
	</note>
	<para>
With TCP, scheduling needs to know the number of current connections to each realserver,
before assigning a realserver for the next connection. 
The length of time for a connection can be short 
(retrieving a page by http) or long (an extended telnet session).
	</para>
	<para>
For UDP there is no "connection". LVS uses a timeout (for 2.4.x kernels
is about 3mins) and any UDP packets from a client within the timeout
period will be rescheduled to the same realserver.
On a short time scale (<emphasis>ca.</emphasis> timeout), 
there will be no load balancing of UDP services
(<emphasis>e.g.</emphasis> as was found for <link linkend="ntp">ntp</link>).
All requests will go to the same realserver. On a long time scale
(&gt;&gt;timeout) loadbalancing will occur.
	</para>
	<para>
Here's the official LVS definition of a UDP "connection"
	</para>
	<para>
Wensong Zhang <emphasis>wensong (at) iinchina (dot) net</emphasis> 2000-04-26
	</para>
	<blockquote>
For UDP datagrams, we create entries for state with the timeout of
IP_MASQ_S_UDP (5*60*HZ) by default.
Consequently all UDP datagrams from the same
source to the same destination will be sent to the same realserver.
Therefore, we call data communication
between a client's socket and a server's socket a "connection",
for both no TCP and UDP.
	</blockquote>
	<para>
Julian Anastasov 2000-07-28
	</para>
	<blockquote>
For UDP we can in principle remove the implicit
persistence for the UDP connections and thus select different real
server for each packet.
My thought was to implement a new feature:
schedule each UDP packet to new realserver.
<emphasis>i.e.</emphasis>something like timeout=~0 for UDP as service flag.
	</blockquote>
	<para>
LVS has been tested with the following UDP services,
	</para>
	<itemizedlist>
		<listitem>
<link linkend="DNS">DNS</link>
		</listitem>
		<listitem>
<link linkend="ntp">ntp</link>
		</listitem>
		<listitem>
<link linkend="xdmcp">xdmcp</link>
		</listitem>
		<listitem>
<link linkend="radius">radius</link>
		</listitem>
	</itemizedlist>
	<para>
So far only DNS has worked well
(but then DNS already fine in a cluster setup without LVS).
ntpd is already self loadbalancing and doesn't need to be run under LVS.
xdmcp dies if left idle for long periods (several hours).
UDP services are not commonly used with LVS and we don't yet know
whether the problems are with LVS or with the service running under LVS.
	</para>
	<para>
Han Bing <emphasis>hb (at) quickhot (dot) com</emphasis> 29 Dec 2002
	</para>
	<blockquote>
	<para>
I am developing several game servers using UDP which I would like
to use with LVS.
LVS supports UDP "connection" persistence.
Does persistence work for UDP too?
	</para>
	<para>
	For example, I have 3 games, every games has 3 servers( 9 servers in 3
groups totally). All game1 servers listen on udp port 10000, game2
servers listen on 10001 udp port, and game3 servers listen on 10002 udp
port. when the client send a udp datagram to game1( to VIP:10000 ), can
the lvs director auto-select one server from the 3 game1 servers and
forward it to the server, AND keep the persistence of this "UDP
connection" when she receives the following datagram from the same CIP?
	</para>
	</blockquote>
Joe: not sure what may happen here. people have had problems with LVS/udp
(<emphasis>e.g.</emphasis> with <xref linkend="ntp"/>).
These problems should go away with persistent udp, but
no-one has tried it and it didn't even occur to me.
The behaviour of LVS with persistent udp may be undefined
for all I know. I would make sure that the setup worked with
ntp before trying a game setup.
	</section>
	<section id="Padraig">
	<title>patch: machine readable error codes from ipvsadm</title>
	<para>
Computers can talk to each other
and read from and write to other programs.
You shouldn't have to get a person to sit at the console
to parse the output of a program.
Here's a patch to make the output of <command>ipvsadm</command> machine readable
	</para>
	<para>
Padraig Brady <emphasis>padraig (at) antefacto (dot) com</emphasis> 07 Nov 2001
	</para>
	<para>
This 1 line patch is useful for me and I don't think it will break anything.
It's against ipvsadm-0.8.2 and returns a specific error code.
	</para>
<programlisting><![CDATA[
--Boundary_(ID_nuebet+LsBGYFsmRPljqqA)
Content-type: text/plain;>ipvsadm-0.8.2-returncode.diff"
Content-disposition: inline; filename="ipvsadm-0.8.2-returncode.diff"
Content-transfer-encoding: 7bit

--- //ipvs-0.8.2/ipvs/ipvsadm/ipvsadm.c	Fri Jun 22 16:03:08 2001
+++ ipvsadm.c	Wed Nov  7 16:29:11 2001
@@ -938,6 +938,7 @@
         result = setsockopt(sockfd, IPPROTO_IP, op,
                             (char *)&urule, sizeof(urule));
         if (result) {
+                result = errno; /* return to caller */
                 perror("setsockopt failed");

                 /*

--Boundary_(ID_nuebet+LsBGYFsmRPljqqA)--
]]></programlisting>
	</section>
	<section id="stateless_ipvsadm">
	<title>patch: stateless ipsvadm - add/edit patch</title>
	<para>
Commands like <command>ifconfig</command> are idempotent,
<emphasis>i.e.</emphasis> they tell the machine to assume a certain state
without reference to the previous state.
You can repeat the same command without errors 
(<emphasis>e.g.</emphasis> put IP=xxx onto eth0).
Not all commands are idempotent - some require you to know the state
of the machine first.
<filename>ipvsadm</filename> is not idempotent:
if a VIP:port entry already exists,
then you will get an error on attempting to enter it.
Whether you make a command idempotent or not, will depend on the 
nature of the command. 
	</para>
	<para>
The problem with <filename>ipvsadm</filename> is that it isn't scriptable
and hence can't be used for automated control of an LVS:
	</para>
	<itemizedlist>
		<listitem>
			<para>
If no entry exists:
			</para>
			<para>
you must <filename>add</filename> the entry with the <filename>-a</filename> option
			</para>
		</listitem>
		<listitem>
			<para>
if the entry exists;
			</para>
			<para>
you must <filename>edit</filename> the entry with the <filename>-e</filename> option.
			</para>
		</listitem>
	</itemizedlist>
	<para>
You will get an error if you use the wrong command. 
Two solutions are:
	</para>
	<itemizedlist>
		<listitem>
parse the output of <command>ipvsadm</command> to see if the entry you are about to
make already is present
		</listitem>
		<listitem>
try both commands and see which one runs
and then have the script figure out if both the error and
the non-error was valid.
		</listitem>
	</itemizedlist>
	<para>
This is a pain and is quite unneccesary.
What is needed is a version of ipvs that accepts valid entries without giving an error.
Here's the 
<ulink url="files/ipvs-0.9.0_add_edit.patch">ipvs-0.9.0_add_edit.patch</ulink>
(http://www.austintek.com/LVS/LVS-HOWTO/HOWTO/files/ipvs-0.9.0_add_edit.patch)
patch by Horms against ipvs-0.9.0. It modifies
several ipvs files, including ipvsadm.
	</para>
	</section>
	<section id="fwmark_nametable">
	<title>patch: fwmark name-number translation table</title>
	<para>
<command>ipvsadm</command> allows entry of fwmark only as numbers.
In some cases, it would be more convenient
to enter/display the fwmark as a name;
<emphasis>e.g.</emphasis> an e-commerce site, serving multiple
customers (<emphasis>i.e.</emphasis> VIPs) and which is linking http and https by a fwmark.
The output of <command>ipvsadm</command> then would list the fwmark as "bills_business", "fred_inc"
rather than "14","15"...
	</para>
	<para>
Horms has written a 
<ulink url="files/ipvs-0.9.5.fwmarks-file.patch">
ipvs-0.9.5.fwmarks-file.patch</ulink>
(http://www.austintek.com/LVS/LVS-HOWTO/HOWTO/files/ipvs-0.9.5.fwmarks-file.patch)
which allows the use of a string fwmark 
as well as the default method of an integer fwmark,
using a table in <filename>/etc</filename> 
that looks like the <filename>/etc/hosts</filename> table.
	</para>
	<para>
Horms <emphasis>horms (at) vergenet (dot) net</emphasis> Nov 14 2001
	</para>
	<blockquote>
		<para>
while we were at OLS in June, Joe suggested that we have a file to
associate names with firewall marks. I have attached a patch that enables
<filename>ipvsadm</filename> to read names for firewall marks from 
<filename>/etc/fwmarks</filename>. This file is
intended to be analogous to <filename>/etc/hosts</filename> 
(or files in <filename>/etc/iproute2/</filename>).
		</para>
		<para>
The patch to the man page explains the format more fully, but briefly the
format is "fwmark name..." newline delimited
		</para>
<programlisting><![CDATA[
e.g.

1 a_name
2 another_name yet_another_name

Which leads to

director:/etc/lvs# ipvsadm -A -f a_name
]]></programlisting>
	</blockquote>
	</section>
	<section>
	<title>ip_vs_conn.pl</title>
	<note>
you can also run <command>`ipvsadm -lcn`</command> to do the same thing)
	</note>
<programlisting><![CDATA[
#!/usr/bin/perl
#-----------------------------------------------
#Date: Wed, 07 Aug 2002 20:14:25 -0300
#From: Jeff Warnica <noc (at) mediadial (dot) com>

#Here is an /proc/net/ip_vs_conn hex mode to integer script.
#If its given an ipaddress as an argument on the commandline,
#it will show only lines with that ipaddress in it.
#-------------------------------------------------

if (@ARGV) {
        $mask = $ARGV[0];
}
open(DATA, "/proc/net/ip_vs_conn");

$format = "%8s %-17s %-5s %-17s %-5s %-17s %-5s %-17s %-20s\n";
printf $format, "Protocol", "From IP", "FPort", "To IP", "TPort", "Dest
IP", "DPort", "State", "Expires";
while(<DATA>){
        chop;
        ($proto, $fromip, $fromport, $toip, $toport, $destip, $destport,
$state, $expiry) = split();
        next unless $fromip;
        next if ($proto =~ /Pro/);

        $fromip = hex2ip($fromip);
        $toip   = hex2ip($toip);
        $destip = hex2ip($destip);

        $fromport = hex($fromport);
        $toport   = hex($toport);
        $destport = hex($destport);

        if ( ($fromip =~ /$mask/) || ($toip =~ /$mask/) || ($destip =~
/$mask/) || (!($mask))) {
                printf $format, $proto, $fromip, $fromport, $toip,
$toport, $destip, $destport, $state, $expiry;
        }
}


sub hex2ip($input) {
        my $input = shift;

        $first  = substr($input,0,2);
        $second = substr($input,2,2);
        $third  = substr($input,4,2);
        $fourth = substr($input,6,2);

        $first  = hex($first);
        $second = hex($second);
        $third  = hex($third);
        $fourth = hex($fourth);

        return "$first.$second.$third.$fourth";
}

#---------------------------------------------------------------
]]></programlisting>
	</section>
	<section id="lucas_script">
	<title>Luca's php monitoring script</title>
	<para>
Luca Maranzano <emphasis>liuk001 (at) gmail (dot) com</emphasis> 12 Oct 2005
	</para>
	<para>
I've written a simple php script 
<filename>luca.php</filename>
to monitor the status of an LVS server.
To use it, configure sudo in order to make the Apache user to run
<command>/sbin/ipvsadm</command> as root without password prompt.
The CSS is derived from phpinfo() page.
	</para>
	<note>
I had this as a link to the file on my machine, 
so you could just download it if you wanted it.
However the file has a <command>sudo</command> in it,
which caused havoc with my security tests of files.
I've deleted the file and instead have it as text here in the HOWTO.
Hopefully no-one will try to execute the HOWTO  
	</note>
<programlisting><![CDATA[
<?
// Simple script to monitor LVS
// --liuk -at- linux.it
//
// extract vars...
$p1=$_GET['resolve_dns'];
$p2=$_GET['refresh_int'];
if($p2=="" || $p2<9) { $p2="10"; };
?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN"
"DTD/xhtml1-transitional.dtd">
<html><head>
<meta http-equiv="refresh" content="<? echo $p2; ?>">
<style type="text/css"><!--
body {background-color: #ffffff; color: #000000;}
body, td, th, h1, h2 {font-family: sans-serif;}
pre {margin: 0px; font-family: courier;}
a:link {color: #000099; text-decoration: none; background-color: #ffffff;}
a:hover {text-decoration: underline;}
table {border-collapse: collapse;}
.center {text-align: center;}
.center table { margin-left: auto; margin-right: auto; text-align: left;}
.center th { text-align: center !important; }
td, th { border: 1px solid #000000; font-size: 75%; vertical-align: baseline;}
h1 {font-size: 150%;}
h2 {font-size: 125%;}
.p {text-align: left;}
.e {background-color: #ccccff; font-weight: bold; color: #000000;}
.h {background-color: #9999cc; font-weight: bold; color: #000000;}
.v {background-color: #cccccc; color: #000000;}
.vv {background-color: #cccccc; color: #000000; font-family: courier; }
i {color: #666666; background-color: #cccccc;}
img {float: right; border: 0px;}
hr {width: 600px; background-color: #cccccc; border: 0px; height: 1px;
color: #000000;}
//--></style>
<title>Local Director Monitor</title></head>
<body><div class="center">
<table border="0" cellpadding="3" width="600">
<tr class="h"><td>
<h1 class="p">Local Director Monitor v. 1.0</h1>
</td></tr>
</table><br />
<table border="0" cellpadding="3" width="800">

<tr><td class="e">Monitor Options: </td>
<td class="v">
<form method="GET" action="">
<? if(isset($resolve_dns)) { $curr_dns="$p1"; } else { $curr_dns="1"; }; ?>
<input type="checkbox" name="resolve_dns" value="<?echo $curr_dns;?>"
<? if($p1) { echo "checked=\"checked\""; } else { $dns_flag=" -n "; }; ?>
> Resolve DNS Names - Refresh every
<input type="text" name="refresh_int" size="2" value="<? echo $p2; ?>">
seconds -
<input type="submit" value="Update">
</form>
</td></tr>

<tr><td class="e">Active node: </td>
<td class="vv"><? passthru("hostname"); ?></td></tr>

<tr><td class="e">Status: </td>
<td class="vv"><pre><? $cmd="sudo /sbin/ipvsadm -L ".$dns_flag;
passthru($cmd); ?></pre></td></tr>

<tr><td class="e">Statistics: </td>
<td class="vv"><pre><? $cmd="sudo /sbin/ipvsadm -L --stats
".$dns_flag; passthru($cmd); ?></pre></td></tr>

<tr><td class="e">Active<br>connections: </td>
<td class="vv"><pre><? $cmd="sudo /sbin/ipvsadm -L -c ".$dns_flag;
passthru($cmd); ?></pre></td></tr>

<tr><td class="e">Rate<br>statistics: </td>
<td class="vv"><pre><? $cmd="sudo /sbin/ipvsadm -L --rate ".$dns_flag;
passthru($cmd); ?></pre></td></tr>

<tr><td class="e">Sync<br>daemon: </td>
<td class="vv"><pre><? passthru("sudo /sbin/ipvsadm -L --daemon");
?></pre></td></tr>

</table><br />

</div></body></html>
]]></programlisting>
	<para>
Jeremy Kerr <emphasis>jk (at) ozlabs (dot) org</emphasis> 12 Oct 2005
	</para>
<programlisting><![CDATA[
<? $cmd="sudo /sbin/ipvsadm -L ". $dns_flag; passthru($cmd); ?>
]]></programlisting>
	<para>
Whoa.
	</para>
	<para>
If you use this script with register_globals set (and assuming you've
set it up so that the sudo works), you've got a remote *root*
vunerability right there.
<emphasis>e.g.</emphasis>
http://example.com/script.php?resolve_dns=1&amp;dns_flag=;sudo+rm+-rf+/, 
which will do <command>`rm -rf /`</command> as root.
	</para>
	<para>
you may want to ensure your variables are clean beforehand, and avoid
the sudo completely (maybe use a helper process?)
	</para>
	<para>
<emphasis>malcolm (at) loadbalancer (dot) org</emphasis> Oct 12 2005
	</para>
	<para>
That's why PHP no longer has register globals defaulted!
And also why you lock down your admin ip address by source ip.
My code has this vulnerability, but I'm not sure a helper app would be 
any more secure (sudo is a helper app.)
	</para>

	<para>
<emphasis>liuk001 (at) gmail (dot) com</emphasis>Oct 12 2005
	</para>
	<para>
Jeremy, this is a good point. I wrote it as a quick and dirty hack
without security in mind. It is used on the internal net from trusted
users who indeed have root access to the servers ;-)
However, sudo is configured to run only /sbin/ipvsadm from www-data
user, so I think that /bin/rm could not be executed.
	</para>
	<para>
Graeme Fowler <emphasis>graeme (at) graemef (dot) net</emphasis> 12 Oct 2005 
	</para>
	<para>
...as all the relevant values are produced in 
<filename>/proc/net/ip_vs[_app,_conn,_stats]</filename>, 
then why not just write something to 
process those values instead? They're globally readable and don't need 
any helper apps to view them at all.
	</para>
	<para>
Yes, you'd be re-inventing a small part of ipvsadm's functionality. The 
security improvements alone are worth it; the fact that the overhead of 
running <command>sudo</command> and then <command>ipvsadm</command> 
is removed by just doing an <filename>open()</filename> on a 
<filename>/proc</filename> file might be worth it in situations where you may have many 
users running your web app.
	</para>
	<para>
Sure, you need to decode the hex values to make them "nice". Unless you 
have the sort of users who read hex encoding all the time :)
	</para>
	</section>
	<section id="ipvsadm_set">
	<title>ipvsadm set option</title>
	<para>anon</para>
	<blockquote>
what <filename>/proc</filename> values does <command>ipvsadm --set</command>
modify? Something in <filename>/proc/sys/net/ipv4/vs</filename>?
	</blockquote>
	<para>Ratz</para>
	<para>
the current proc-fs entries are a read-only representation of what 
could be set regarding state timeouts. <command>ipvsadm --set</command> will set
for IPVS related connection entries
	</para>
<itemizedlist>
	<listitem>	
The time we spend in TCP ESTABLISHED before transition
	</listitem>
	<listitem>
The time we spend in TCP FIN_WAIT before transition
	</listitem>
	<listitem>
The time we spend for UDP in general
	</listitem>
</itemizedlist>
	<para>
Andreas 05 Feb 2006
	</para>
	<blockquote>
Where can I get the currently set values of <command>ipvsadm --set foo bar baz</command>?
	</blockquote>
	<para>
Ratz
	</para>
	<para>
You can't :) IP_VS_SO_GET_TIMEOUTS is not implemented in <command>ipvsadm</command>
or I'm blind.
Also the <filename>proc-fs</filename> related entries for this are not exported. 
I've written a patch to re-instate the proper settings in <filename>proc-fs</filename>, 
however this is only in 2.4.x kernels. 
Julian has recently proposed a very granular timeout framework, 
however none of us has had the time nor impulse to implement it. 
For our (work) customers I needed the ability to instrument all 
the IPVS related timeout values in DoS and non-DoS mode. 
The <command>ipvsadm --set</command> option should be obsoleted, 
since it only covers the timeout settings partially 
and there is no <command>--get</command> method.
	</para>
	<blockquote>
I did not find a way to read them out, I grep through the /proc/sys/foo
and /proc/net foo and was not able to see the numbers I set before. This
was on kernel 2.4.30 at least.
	</blockquote>
	<para>
Correct. The standard 2.4.x kernel only exports the DoS timers for some 
(to me at least) unknown reason. I suggest that we re-instate (I'll send 
a patch or a link to the patch tomorrow) these timer settings until we 
can come up with Julian's framework. It's imperative that we can set 
those transition timers, since their default values are dangerous 
regarding >L4 DoS. One example is HTTP/1.1 slow start if the web servers 
are mis-configured (wrong MaxKeepAlive and its timeout settings).
	</para>
	<blockquote>
This brings me further to the question if the changes of lvs in recent
2.6 development are being backported to 2.4?
	</blockquote>
	<para>
Currently I would consider it the other way 'round. 2.6.x has mostly 
stalled feature wise and 2.4.x is missing the crucial per RS threshold 
limitation feature. I've backported it and also improved it quite a bit 
(service pool) and so we're currently completely out of sync :). I'll 
try to put some more effort into working on the 2.6.x kernel, however 
since it's still too unstable of us, our main focus remains on the 2.4.x 
kernel.
	</para>
	<para>
[And before you ask: No, we don't have the time (money wise) to invest 
into bug-hunting and reporting problems regarding 2.6.x kernels on 
high-end server machines. And in private environment 2.6.x works really 
well on my laptops and other machines, so there's really not much to 
report ;).]
	</para>
        <para>
On top of that LVS 
does not use the classic TCP timers from the stack since it only 
forwards TCP connections. The IPVS timers are needed so we can maintain 
the LVS state table regarding expirations in various modes, mostly LVS_DR.
	</para>
	<para>
Browsing through the code recently I realised that the state transition 
code in <filename>ip_vs_conn:vs_tcp_state()</filename> is very simple, probably too simple. 
If we use Julian's <filename>forward_shared patch</filename> 
(which I consider a great invention, BTW) 
one would assume that IPVS timeouts are more closely 
timed to the actually TCP flow. 
However, this is not the case because, 
from what I've read and understood the IPVS state transitions are done 
without memory, so it's wild guessing :). I might have a closer look at 
this because it just seems sub-optimal. Also the notion of active versus 
inactive connections stemming from this simple view of TCP flow is 
questionable, especially the dependence and weighting of some schedulers.
	</para>
	<blockquote>
So, if I set a
lvs tcp timeout about 2h 12 min, lvs would never drop a tcp connection
unless a client is really "unreachable":
	</blockquote>
	<para>
The timeout is more bound to the connection entry in the IPVS lookup 
table, so we know where to forward incoming packets regarding a specific 
TCP flow. A TCP connection is never drop or not dropped by LVS, only 
specific packets pertaining to a TCP connection.
	</para>
	<blockquote>
After 2h Linux sends tcp
keepalive probes serveral times, so there are some byte send through the
connection.
	</blockquote>
	<para>
Nope, IPVS does not work as a proxy regarding TCP connections. It's a 
TCP flow redirector.
	</para>
	<blockquote> 
lvs will (re)set the internal timer for this connection to
the keepalive time I set with <command>--set</command>.
	</blockquote>
	<para>
Kind of ... only the bits of the state transition table which are 
affected by the three settings. It might not be enough to keep 
persistency for your TCP connection.
	</para>
	<blockquote>
Or does it recognize that the
bytes send are only probes without a vaild answer and thus drop the
connection?
	</blockquote>
	<para>
There is no sending keepalive probes from the director.
	</para>
	<blockquote>
will we eventually get timeput parameters _per service_ instead of global ones? 
	</blockquote>
	<para>
Julian proposed following framework: 
http://www.ssi.bg/~ja/tmp/tt.txt
	</para>
	<para>
So if you want to test, the only thing you have to do is fire up your 
editor of choice :). Ok, honestly, I don't know when this will be done 
because it's quite some work and most us developers here are a pretty 
busy with other daily activities. So unless there is a glaring issue 
regarding timers implemented as-is, chances are slim that this gets 
implemented. Of course I could fly down to Julian's place over the 
week-end and we could implement it together; want to sponsor it? ;).
	</para>
	<para>
There's a lot of TCP timers in the Linux kernel and they all have 
different semantical meanings. There is the TCP timout timer for sockets 
related to locally initiated connections, then there is a TCP timeout 
for the connection tracking table, which on my desktop system for 
example has following settings:
	</para>
<programlisting><![CDATA[
/proc/sys/net/ipv4/netfilter/ip_conntrack_tcp_timeout_close:10
/proc/sys/net/ipv4/netfilter/ip_conntrack_tcp_timeout_close_wait:60
/proc/sys/net/ipv4/netfilter/ip_conntrack_tcp_timeout_established:432000
/proc/sys/net/ipv4/netfilter/ip_conntrack_tcp_timeout_fin_wait:120
/proc/sys/net/ipv4/netfilter/ip_conntrack_tcp_timeout_last_ack:30
/proc/sys/net/ipv4/netfilter/ip_conntrack_tcp_timeout_syn_recv:60
/proc/sys/net/ipv4/netfilter/ip_conntrack_tcp_timeout_syn_sent:120
/proc/sys/net/ipv4/netfilter/ip_conntrack_tcp_timeout_time_wait:120
]]></programlisting>
	<para>
And of course we have the IPVS TCP settings, which look as follows (if 
they weren't disabled in the core :)):
	</para>
<programlisting><![CDATA[
/proc/sys/net/ipv4/vs/tcp_timeout_established:900
/proc/sys/net/ipv4/vs/tcp_timeout_syn_sent:120
/proc/sys/net/ipv4/vs/tcp_timeout_syn_recv:60
/proc/sys/net/ipv4/vs/tcp_timeout_:900
[...]
]]></programlisting>
	<para>
unless you enabled tcp_defense, which changes those timers again. And 
then of course we have other in-kernel timers, which influence those 
timers mentioned above.
	</para>
	<para>
However, the beforementioned timers regarding packet filtering, NAPT and 
load balancing and are meant as a means to map expected real TCP flow 
timeouts. Since there is no socket (as in an endpoint) involved when 
doing either netfilter or IPVS, you have to guess what the TCP flow 
in-between (where you machine is "standing") is doing, so you can 
continue to forward, rewrite, mangle, whatever, the flow, _without_ 
disturbing it. The timers are used for table mapping timeouts of TCP 
states. If we didn't have them, mappings would stay in the kernel 
forever and eventually we'd run out of memory. If we have them wrong, it 
might occur that a connection is aborted prematurely by our host, for 
example yielding those infamous ssh hangs when connecting through a 
packet filter.
	</para>
	<para>
The tcp keepalive timer setting you've mentioned, on the other hand, is 
per socket. And as such only has an influence on locally created or 
terminated sockets. A quick socket(2) and socket(7) skimming reveil:
	</para>
<programlisting><![CDATA[
   [socket(2) excerpt]
        The communications protocols which implement a SOCK_STREAM
        ensure that data is not lost or duplicated.  If a piece of
        data  for  which the peer protocol has buffer space cannot
        be successfully transmitted within a reasonable length  of
        time,  then the connection is considered to be dead.  When
        SO_KEEPALIVE is enabled on the socket the protocol  checks
        in  a  protocol-specific  manner if the other end is still
        alive.

   [socket(7) excerpt]
        These socket options can be set by using setsockopt(2) and
        read with getsockopt(2)  with  the  socket  level  set  to
        SOL_SOCKET for all sockets:

        SO_KEEPALIVE
        Enable sending of keep-alive messages on connection-oriented 
        sockets. Expects a integer boolean flag.
]]></programlisting>
	</section>
	<section id="ipvsadm_error_messages">
	<title>ipvsadm error messages</title>
	<para>
<command>ipvsadm</command>'s error messages are low level and give the
user little indication of what they've done wrong. 
These error messages were written in the early days of LVS
when getting <command>ipvsadm</command> to work was a feat in itself.
Unfortunately the messages have not been updated and enough use of 
<command>ipvsadm</command> is now scripted and so we don't run into 
the messages anymore. 
As people post error messages and what they mean, I'll put them here
	</para>
	<para>
Brian Sheets <emphasis>bsheets (at) singlefin (dot) net</emphasis> 7 Jan 2007 
	</para>
	<blockquote>
<programlisting><![CDATA[
ipvsadm -d -t 10.200.8.1:25 -r 10.200.8.100
Service not defined
]]></programlisting>
	<para>
What am I doing wrong? The syntax looks correct to me.
	</para>
	</blockquote>
	<para>
Graeme Fowler <emphasis>graeme (at) graemef (dot) net</emphasis> 07 Jan 2007
	</para>
	<para>
do you have a service defined on VIP 10.200.8.1 port 25? Make
sure you're not getting your real and virtual servers mixed up.
	</para>
	<para>
Brian
	</para>
	<blockquote>
Yup, I had the real and virtuals reversed..
	</blockquote>
	<para>
Joe
	</para>
	<para>
You should be able to delete a realserver for a service that isn't declared,
with only a notice rather than an error, at least in my thinking. However
that battle was lost back in the early days.
	</para>
	</section>
	<section id="ipvsadm_smp_bug">
	<title>ipvsadm fast update bug with smp</title>
	<para>
Kees Hoekzema <emphasis>kees (at) tweakers (dot) net</emphasis> 11 Jul 2007 
	</para>
	<para>
I'm applying weight changes to a 64bit 2-way SMP director quite rapidly (not
quite twice a second, but close) and getting a frozen director, which 
needs a cold reset.
	</para>
	<para>
I have found a bit more information from my debugging, 
and it seems that Horms already knows about it:
(http://marc.info/?l=linux-netdev&amp;m=118040107213444&amp;w=2)
I recompiled the 
<filename>ip_vs()</filename> modules with a bit more debug and everytime my system
crashed I had the same debug output:
	</para>
<programlisting><![CDATA[
Jul 12 15:43:15 atropos kernel: Enter: ip_vs_edit_dest,
net/ipv4/ipvs/ip_vs_ctl.c line 885
Jul 12 15:43:15 atropos kernel: DEBUG: ip_vs_edit_dest,
net/ipv4/ipvs/ip_vs_ctl.c line 886
Jul 12 15:43:15 atropos kernel: DEBUG: ip_vs_edit_dest,
net/ipv4/ipvs/ip_vs_ctl.c line 891
Jul 12 15:43:15 atropos kernel: DEBUG: ip_vs_edit_dest,
net/ipv4/ipvs/ip_vs_ctl.c line 897
Jul 12 15:43:15 atropos kernel: DEBUG: ip_vs_edit_dest,
net/ipv4/ipvs/ip_vs_ctl.c line 906
Jul 12 15:43:15 atropos kernel: DEBUG: ip_vs_edit_dest,
net/ipv4/ipvs/ip_vs_ctl.c line 908
Jul 12 15:43:15 atropos kernel: DEBUG: ip_vs_edit_dest,
net/ipv4/ipvs/ip_vs_ctl.c line 910
Jul 12 15:43:15 atropos kernel: DEBUG: ip_vs_edit_dest,
net/ipv4/ipvs/ip_vs_ctl.c line 913
Jul 12 15:43:15 atropos kernel: DEBUG: ip_vs_edit_dest,
net/ipv4/ipvs/ip_vs_ctl.c line 916
Jul 12 15:43:15 atropos kernel: DEBUG: ip_vs_edit_dest,
net/ipv4/ipvs/ip_vs_ctl.c line 918
Jul 12 15:43:15 atropos kernel: Leave: ip_vs_edit_dest,
net/ipv4/ipvs/ip_vs_ctl.c line 919
Jul 12 15:43:15 atropos kernel: Enter: ip_vs_edit_dest,
net/ipv4/ipvs/ip_vs_ctl.c line 885
Jul 12 15:43:15 atropos kernel: DEBUG: ip_vs_edit_dest,
net/ipv4/ipvs/ip_vs_ctl.c line 886
Jul 12 15:43:15 atropos kernel: DEBUG: ip_vs_edit_dest,
net/ipv4/ipvs/ip_vs_ctl.c line 891
Jul 12 15:43:15 atropos kernel: DEBUG: ip_vs_edit_dest,
net/ipv4/ipvs/ip_vs_ctl.c line 897
Jul 12 15:43:15 atropos kernel: DEBUG: ip_vs_edit_dest,
net/ipv4/ipvs/ip_vs_ctl.c line 906
Jul 12 15:43:15 atropos kernel: DEBUG: ip_vs_edit_dest,
net/ipv4/ipvs/ip_vs_ctl.c line 908
Jul 12 15:43:15 atropos kernel: DEBUG: ip_vs_edit_dest,
net/ipv4/ipvs/ip_vs_ctl.c line 910
]]></programlisting>
	<para>
The code after line 910 reads:
	</para>
<programlisting><![CDATA[
while (atomic_read(&svc->usecnt) > 1) {};
]]></programlisting>
	<para>
Every other busy lock in the code reads:
	</para>
<programlisting><![CDATA[
IP_VS_WAIT_WHILE(atomic_read(&svc->usecnt) > 1);
]]></programlisting>
	<para>
Which basicly is the same except a cpu_relax();
At the moment I am testing my server with cpu_relax() code in the
ip_vs_edit_dest function, and so far it has not crashed yet and is directing
the traffic quite a bit longer than previously was possible.
The only differences between this server and the old server (which didn't
have any problems) are:
	</para>
	<itemizedlist>
		<listitem>
- SMP (4 cores) vs Single core
		</listitem>
		<listitem>
- 64 bits vs 32 bits
		</listitem>
		<listitem>
- 2.6.21.5 vs 2.6.20.4 (but I do not see any changes in ip_vs_ctl.c)
		</listitem>
	</itemizedlist>
	<para>
In my first mail I accused the 64/32 bits difference, but right now I'm more
thinking of a SMP issue, but unfortunatly I lack the kernel hacking skills
to say why, or why that cpu_relax() helps so much in the while loop.
Hopefully Horms understands it better than I do ;)
	</para>

<programlisting><![CDATA[
--- linux-2.6.22.1/net/ipv4/ipvs/ip_vs_ctl.c    2007-07-12
19:41:27.000000000 +0200
+++ old/net/ipv4/ipvs/ip_vs_ctl.c       2007-07-10 20:56:30.000000000 +0200
@@ -909,8 +909,8 @@
        write_lock_bh(&__ip_vs_svc_lock);

        /* Wait until all other svc users go away */
-       IP_VS_WAIT_WHILE(atomic_read(&svc->usecnt) > 1);
-
+       while (atomic_read(&svc->usecnt) > 1) {};
+
        /* call the update_service, because server weight may be changed */
        svc->scheduler->update_service(svc);
]]></programlisting>

	<para>
Joe
	</para>
	<para>
I know this is separate from the problem, but according to 
feedback and control theory you should be making adjustments 
on a timescale that damps the transients. What a transient 
is here is not obvious - the timescale of a tcpip 
connection, the time is takes to change the load by 10%?, 
50%? I don't know, but every couple of seconds would seem to 
be a lot shorter than either of these two time scales.
Do you find your setup has problems when you do adjustments 
on a longer timescale?
	</para>
	</section>
	<section id="no_scheduler">
	<title>Problems when no scheduler</title>
	<note>
What happens if you have the service entered with <command>ipvsadm -A</command>, 
but have no realservers (no <command>ipvsadm -a</command>) to accept the forwarded packets?
We haven't quite figured out what to do about this yet.
Till we can get a better idea about what's going on,
we're not going to do anything.
	</note>
	<para>
Siim Poder <emphasis>windo (at) p6drad-teel (dot) net</emphasis> 07 May 2008
	</para>
	<blockquote>
		<para>
We've had LVS machines dying a couple of times when the service is using
the wrr scheduler and keepalived pulls all real servers from behind the
service IP.
		</para>
		<para>
The symptoms are that there are a lot of (thousands, apparently for
every packet?) messages in syslog:
ip_vs_wrr_schedule(): no available servers
		</para>
		<para>
After which the machine hangs. I don't recall if i've had to boot it
manually or if it boots by itself.
		</para>
		<para>
Also, I'm not sure if it is that message that is killing the machine,
but the problem hasn't occured with other schedulers (that don't print
such a message). We use wrr the most though.
		</para>
		<para>
I think we should either remove the message or ratelimit it (unless the
bug is somewhere else). I tested the patch and it seems to be ok, but as
I'm unable to reproduce the hanging/crashing in test environment, I
can't verify wether it actually helps.
		</para>
		<para>
Something close to this was added to mainline by someone already. But
the problem seems to persist (just without the messages). It seems to
appear with any scheduler (at least wrr, wlc and rr). However I have
been unable to reproduce this neither by connection nor packet rate in
test environment. It's probably not just the missing real servers, but
something relatively infrequent that gets triggered only after there are
no real servers. The LVS goes down in about 5-15 minutes of missing real
servers IIRC.
		</para>
		<para>
I tried generating many connections (and played with ttl/fragmentation a
little), but couldn't trigger the bug. Maybe it has to do with clients
sending some ICMP messages (which would probably be rare enough)?
		</para>
		<para>
This still gets triggered in our live env for high connection rate
services (if the servers fail for any reason and keepalived kicks them
out). We have put sorry servers into keepalived configuration to avoid
the whole LVS going down for now (sorry_server 127.0.0.1:666), so there
is a workaround for us.
		</para>
<programlisting><![CDATA[
--- linux-2.6.24/net/ipv4/ipvs/ip_vs_wrr.c      2008-01-24 22:58:37.000000000 +0000
+++ linux-2.6.24-ipvs_patches/net/ipv4/ipvs/ip_vs_wrr.c 2008-05-06 16:17:17.790662800 +0000
@@ -169,7 +169,7 @@
                                 */
                                if (mark->cw == 0) {
                                        mark->cl = &svc->destinations;
-                                       IP_VS_INFO("ip_vs_wrr_schedule(): "
+                                       IP_VS_DBG_RL("ip_vs_wrr_schedule(): "
                                                   "no available servers\n");
                                        dest = NULL;
                                        goto out;
]]></programlisting>
	</blockquote>
	<para>
Horm 29 Dec 2008
	</para>
	<para>
We're doing nothing till we figure out what's really going on
The important problem seems to be that LVS dies sometimes. 
But unfortunately that can't be fixed right now, 
because nobody knows how to do so, 
despite Siim's efforts to find the cause of the problem.
	</para>
	<para>
With regards to making wrr like the other schedulers, I'd actually
be much more inclined to do the reverse - make all the other schedulers
display a rate-limited warning when they don't have any real servers
available. Perhaps something like the patch against 2.6.28 below.
	</para>
	<para>
In any case, I think that the warning message and the LVS dying issues
are separate, except that it seems likely that the warning message
will help to lead us to the cause of the "LVS dies" bug.
	</para>
	<note>
Joe: The patches to make all schedulers display a warning will be in kernel 2.6.29. 
	</note>
	</section>
</section>
<section id="LVS-HOWTO.LVS-NAT" xreflabel="LVS-NAT">
<title>LVS: LVS-NAT</title>
	<section id="lvs_nat_intro">
	<title>Introduction</title>
	<para>
		<note>
see also <ulink url="http://www.ssi.bg/~ja/L4-NAT-HOWTO.txt">
Julian's layer 4 LVS-NAT setup</ulink>
(http://www.ssi.bg/~ja/L4-NAT-HOWTO.txt).
		</note>
	</para>
	<para>
LVS-NAT is based on cisco's LocalDirector.
	</para>
	<para>
This method was used for the first LVS. If you want to set up
a test LVS, this requires no modification of the realservers
and is still probably the simplest setup.
	</para>
	<para>
In a commercial environment, the owners of servers are
loath to change the configuration of a tested machine.
When they want load balancing, they will clone their
server and tell you to put your load balancer infront of their
rack of servers. 
You will not be allowed near any of their servers, thank you very much.
In this case you use LVS-NAT. 
	</para>
	<blockquote>
		<para>
Ratz Wed, 15 Nov 2006
		</para>
		<para>
Most commercial load balancers are not set up anymore 
using the triangulation mode (Joe: triangulation == LVS-DR)
(at least in the projects I've been involved).
The load balancer is becoming more and more a router,
using well-understood key technologies like VRRP and content processing. 
		</para>
	</blockquote>
	<para>
With LVS-NAT, the incoming packets are rewritten by the director
changing the dst_addr from the VIP to the address of one of the realservers 
and then forwarded to the realserver.
The replies from the realserver are sent to the director where they
are rewritten and returned to the client with the source address 
changed from the RIP to the VIP.
	</para>
	<para>
Unlike the other two methods of forwarding used in an LVS (LVS-DR and LVS-Tun)
the realserver only needs a functioning tcpip stack (eg a networked printer),
<emphasis>i.e.</emphasis> the realserver can have any operating system and no modifications are
made to the configuration of the realservers (except setting their route tables).
	</para>
	</section>
	<section id="lvs_nat_problems">
	<title>LVS-NAT bugs</title>
	<para>
Sep 2006:
Various problems have surfaced in the 2.6.x LVS-NAT code
all relating to routing (netfilter)
on the side of the director facing the internet.
People using LVS-NAT on a director which isn't a firewall
and which only has a single default gw, aren't having any problems.
	</para>
	<para>
It seems the 2.4.x code was working correctly: 
Farid Sarwari had it working for IPSec at least.
The source routing problem has been identified by three people, 
who've all submitted functionally equivalent patches.
While we're delighted to have contributions from so many people,
we regret that we weren't fast enough to recognise the problem
and save the last two people all their work.
One of the problems (we think) is that not
many people are using LVS-NAT and when a weird problem
is reported on the mailing list we say "well 1000's of people
have been using LVS-NAT for years without this problem, 
this guy must not know what he's talking about".
We're now taking the approach that maybe not too many people
are using LVS-NAT.
	</para>
	<para>
Here are the problems which have surfaced so far with LVS-NAT.
They either have been solved or will be in a future release of LVS.
	</para>
	<itemizedlist>
		<listitem>
Firewall incompatibility: You couldn't run a netfilter firewall on the outside of the director. 
This was solved by Ben North with the <xref linkend="antefacto_patches"/>.
These patches were taken over by Vinnie, 
and are now being maintained by Julian as part of the <xref linkend="ipvs_nfct"/>.
Since the NFCT patches are benign when not being used, 
we hope that they will be incorporated into the ip_vs code for the kernel
(when Horms gets time).
		</listitem>
		<listitem>
Source routing: Outbound packets originating at the VIP are not injected
into the routing table but are sent straight out the default gw.
As a result the packets were not affected by <command>iproute2</command> commands.
This problem was found by Ken Brownfield who submitted a patch for his relatively
old kernel, then Farid Sarwari who couldn't get routing to work for his IPSec LVS submitted another,
then David Black realised that Julian's NFCT patches handled the problem from the start.
(see <xref linkend="brownfield"/>). 
Horm's is working on getting Julian's NFCT code into ip_vs.
		</listitem>
		<listitem>
LVS-NAT ftp helper modules for active/passive ftp:
We seem to get a disproportionate number of problems with
ftp on LVS. This seems to be a combination of the small number
of users, real bugs and inadequate documentation.
(see <xref linkend="LVS-NAT_ftp_bug"/>).
		</listitem>
	</itemizedlist>
	</section>
	<section id="lvs_nat_one_network_two_nic">
	<title>Example 1-NIC, 2 Network LVS-NAT (VIP and RIPs on different network)</title>
	<note>
If the VIP and the RIPs are on the same network you need the <xref linkend="one_network"/>
	</note>
	<para>
Here the client is on the same network as the VIP
(in a production LVS, the client will be coming in from an
external network via a router).
(The director can have 1 or 2 NICs -
two NICs will allow higher throughput of packets, since
the traffic on the realserver network will be separated
from the traffic on the client network).
	</para>
<programlisting><![CDATA[
Machine                      IP
client                       CIP=192.168.1.254
director VIP                 VIP=192.168.1.110 (the IP for the LVS)
director internal interface  DIP=10.1.1.1
realserver1                  RIP1=10.1.1.2
realserver2                  RIP2=10.1.1.3
realserver3                  RIP3=10.1.1.4
.
.
realserverN                  RIPn=10.1.1.n+1
dip                          DIP=10.1.1.9 (director interface on the LVS-NAT network)
]]></programlisting>
	<para>
	</para>
<programlisting><![CDATA[
                        ________
                       |        |
                       | client |
                       |________|
                       CIP=192.168.1.254
                           |
                        (router)
                           |
             __________    |
            |          |   |   VIP=192.168.1.110 (eth0:110)
            | director |---|
            |__________|   |   DIP=10.1.1.9 (eth0:9)
                           |
                           |
          -----------------------------------
          |                |                |
          |                |                |
   RIP1=10.1.1.2      RIP2=10.1.1.3   RIP3=10.1.1.4 (all eth0)
   _____________     _____________    _____________
  |             |   |             |  |             |
  | realserver  |   | realserver  |  | realserver  |
  |_____________|   |_____________|  |_____________|
]]></programlisting>
	<para>
here's the <filename>lvs.conf</filename> for this setup
	</para>
<programlisting><![CDATA[
LVS_TYPE=VS_NAT
INITIAL_STATE=on
VIP=eth0:110 lvs 255.255.255.0 192.168.1.255
DIP=eth0 dip 192.168.1.0 255.255.255.0 192.168.1.255
DIRECTOR_DEFAULT_GW=client
SERVICE=t telnet rr realserver1:telnet realserver2:telnet realserver3:telnet
SERVER_NET_DEVICE=eth0
SERVER_DEFAULT_GW=dip
#----------end lvs_nat.conf------------------------------------
]]></programlisting>
	<para>
The VIP is the only IP known to the client. The RIPs here are on
a different network to the VIP (although with only 1 NIC on
the director, the VIP and the RIPs are on the same wire).
	</para>
	<para>
In normal NAT, masquerading is the rewriting of packets
originating behind the NAT box.
With LVS-NAT, the incoming packet (src=CIP,dst=VIP, abbreviated to CIP->VIP)
is rewritten by the director (becoming CIP->RIP).
The action of the LVS director is called demasquerading.
The demasqueraded packet is forwarded to the realserver.
The reply packet (RIP->CIP) is generated by the realserver.
	</para>
	</section>
	<section id="NAT_default_gw">
	<title>All packets sent from the LVS-NAT realserver to the client must go through the LVS-NAT director</title>
	<para>
For LVS-NAT to work
	</para>
	<itemizedlist>
		<listitem>
<emphasis>all packets from the realservers to the client must go through the director.</emphasis>
		</listitem>
	</itemizedlist>
	<para>
Forgetting to set this up is the single most common cause of failure
when setting up a LVS-NAT LVS.
	</para>
	<para>
The original (and the simplest from the point of view of setup)
way is to make the DIP
(on the director) the default gw for the packets from the realserver.
The documentation here all assumes you'll be using this method.
(Any IP on the director will do, but in the case where you
have two directors in active/backup failover, you have an
IP that is moved to the active director and this is called the DIP).
Any method of making the return packets go through the
director will do.
With the arrival of the <xref linkend="LVS-HOWTO.policy_routing"/> tools,
you can route packets according to any parameter in the packet header
(<emphasis>e.g.</emphasis> src_addr, src_port, dest_addr..)
Here's an example of ip rules on the realserver to
route packets from the RIP to an IP on the director.
This avoids having to route these packets via a default gw.
	</para>
	<para>
Neil Prockter <emphasis>prockter (at) lse (dot) ac (dot) uk</emphasis> 30 Mar 2004
	</para>
	<blockquote>
		<para>
you can avoid using the director as the default gw by
		</para>
<programlisting><![CDATA[
realserver# echo 80 lvs >> /etc/iproute2/rt_tables
realserver# ip route add default <address on director, eg DIP> table lvs
realserver# ip rule add from <RIP> table lvs
]]></programlisting>
		<para>
For the IPs in <ulink url="http://www.linuxvirtualserver.org/VS-NAT.html">
Virtual Server via NAT</ulink>
(http://www.linuxvirtualserver.org/VS-NAT.html).
		</para>
<programlisting><![CDATA[
echo 80 lvs >> /etc/iproute2/rt_tables
ip route add default 172.16.0.1 table lvs
ip rule add from 172.16.0.2 table lvs
]]></programlisting>
		<para>
I do this with lvs and with cisco css units
		</para>
	</blockquote>
	<para>
Here Neil is routing packets from RIP to 0/0 via DIP.
You can be more restrictive and route packets from RIP:port
(where port is the LVS'ed service) to 0/0 via DIP.
Packets from RIP:other_ports can be routed via other rules.
	</para>
	<para>
For a 2 NIC director (with different physical networks for the realservers and the
clients), it is enough for the default gw of the realservers to be the director.
For a 1 NIC, two network setup (where the two networks are using the
same link layer), in addition, the realservers must only have
routes to the director. For a 1 NIC, 1 network setup, ICMP redirects
must be turned off on the director (see <xref linkend="one_network"/>)
(the configure script does this for you).
	</para>
	<para>
In a normal server farm, the default gw of the realserver
would be the router to the internet and the packet RIP->CIP would
be sent directly to the client.
In a LVS-NAT LVS, the default gw of the realservers must be the director.
The director masquerades the packet from the
realserver (rewrites it to VIP->CIP) and the client
receives a rewritten packet with the expected source IP of the VIP.
	</para>
	<para>
		<note>
the packet must be routed via the director,
there must be no other path to the client.
A packet arriving at the client directly from the
realserver, rather than going through the director,
will not be seen as a reply to the client's
request and the connection will hang.
If the director is not the default gw for the realservers,
then if you use tcpdump on the director to watch an attempt
to telnet from the client to the VIP
(run tcpdump with `tcpdump port telnet`),
you will see the request packet (CIP->VIP),
the rewritten packet (CIP->RIP) and the reply packet (RIP->CIP).
You will not see the rewritten reply packet (VIP->CIP).
(Remember if you have a switch on the
realserver's network, rather than a hub, then each node
only sees the packets to/from it. tcpdump won't see
packets to between other nodes on the same network.)
		</note>
	</para>
	<para>
Part of the setup of LVS-NAT then is to make sure
that the reply packet goes via the director,
where it will be rewritten to have the addresses (VIP->CIP).
In some cases (<emphasis>e.g.</emphasis> <link linkend="one_network">1 net NS-NAT</link>)
icmp redirects have to be turned off
on the director so that the realserver doesn't get a redirect to forward
packets directly to the client.
	</para>
	<para>
In a production system, a router would prevent
a machine on the outside exchanging packets with machines on the RIP network.
As well, the realservers
will be on a private network (eg 192.168.x.x/24) and replies will not be routable.
	</para>
	<para>
In a test setup (no router), these safeguards don't exist.
All machines (client, director, realservers) are on the same piece of wire and
if routing information is added to the hosts,
the client can connect to the realservers independantly of the LVS.
This will stop LVS-NAT from working (your connection will hang),
or it may appear to work (you'll be connecting directly to the realserver).
	</para>
	<para>
In a test setup, traceroute from the realserver to the client
should go through the director (2 hops in the above diagram).
The configure script
will test that the director's gw is 2 hops from
the realserver and that the route to the director's gw is via
the director, preventing this error.
	</para>
	<para>
(Thanks to James Treleaven <emphasis>jametrel (at) enoreo (dot) on (dot) ca</emphasis> 28 Feb 2002, for
clarifying the write up on the ping tests here.)
	</para>
	<para>
In a test setup with the client connected directly to the director
(in the setup above with 1 or 2 NICs, or the
<link linkend="one_network">one NIC, one network LVS-NAT</link> setup), you can ping
between the client and realservers.
However in production, with the client out on internet land,
and the realservers with unroutable IPs,
you should not be able to ping between the realservers and the client.
The realservers should not know
about any other network than their own (here 10.1.1.0). The
connection from the realservers to the client is through
ipchains (for 2.2.x kernels) and LVS-NAT tables setup by the director.
	</para>
	<para>
In my first attempt at LVS-NAT setup, I had all machines on a
192.168.1.0 network and added a 10.1.1.0 private network for the
realservers/director, without removing the 192.168.1.0 network on
the realservers. All replies from the servers were routed onto
the 192.168.1.0 network rather than back through LVS-NAT and the
client didn't get any packets back.
	</para>
	<para>
Here's the general setup I use for testing.
The client (192.168.2.254) connects to the VIP on the director.
(The VIP on the realserver is present only for LVS-DR and LVS-Tun.)
For LVS-DR, the default gw for the realservers is 192.168.1.254.
For LVS-NAT, the default gw for the realservers is 192.168.1.9.
	</para>
<programlisting><![CDATA[
        ____________
       |            |192.168.1.254 (eth1)
       |  client    |----------------------
       |____________|                     |
     CIP=192.168.2.254 (eth0)             |
              |                           |
              |                           |
     VIP=192.168.2.110 (eth0)             |
        ____________                      |
       |            |                     |
       |  director  |                     |
       |____________|                     |
     DIP=192.168.1.9 (eth1, arps)         |
              |                           |
           (switch)------------------------
              |
     RIP=192.168.1.2 (eth0)
     VIP=192.168.2.110 (for LVS-DR, lo:0, no_arp)
        _____________
       |             |
       | realserver  |
       |_____________|
]]></programlisting>
	<para>
This setup works for both LVS-NAT and LVS-DR.
	</para>
	<para>
Here's the routing table for one of the realservers as in the LVS-NAT
setup.
	</para>
<programlisting><![CDATA[
realserver:# netstat -rn
Kernel IP routing table
Destination     Gateway         Genmask         Flags   MSS Window  irtt Iface
192.168.1.0     0.0.0.0         255.255.255.0   U        40 0          0 eth0
127.0.0.0       0.0.0.0         255.0.0.0       U        40 0          0 lo
0.0.0.0         192.168.1.9     0.0.0.0         UG       40 0          0 eth0
]]></programlisting>
	<para>
Here's a traceroute from the realserver to the client showing 2 hops.
	</para>
<programlisting><![CDATA[
traceroute to client2.mack.net (192.168.2.254), 30 hops max, 40 byte packets
 1  director.mack.net (192.168.1.9)  1.089 ms  1.046 ms  0.799 ms
 2  client2.mack.net (192.168.2.254)  1.019 ms  1.16 ms  1.135 ms
]]></programlisting>
	<para>
Note the traceroute from the client box to the realserver only has one hop.
	</para>
	<para>
director icmp redirects are on, but the director doesn't issue
a redirect (see <xref linkend="icmp_redirects"/>)
because the packet RIP->CIP from the realserver emerges from a different
NIC on the director than it arrived on (and with different source IP).
The client machine doesn't send a redirect since it is not forwarding packets,
it's the endpoint of the connection.
	</para>
	</section>
	<section id="lvs_nat_configure_script">
	<title>Run the configure script</title>
	<para>
Use lvs_nat.conf as a template (sample here will setup LVS-NAT in the
diagram above assuming the realservers are already on the network and using
the DIP as the default gw).
			</para><para>
<programlisting><![CDATA[
#--------------lvs_nat.conf----------------------
LVS_TYPE=VS_NAT
INITIAL_STATE=on

#director setup:
VIP=eth0:110 192.168.1.110 255.255.255.0 192.168.1.255
DIP=eth0:10 10.1.1.10 10.1.1.0 255.255.255.0 10.1.1.255

#Services on realservers:
#telnet to 10.1.1.2
SERVICE=t telnet wlc 10.1.1.2:telnet
#http to a 10.1.1.2 (with weight 2) and to high port on 10.1.1.3
SERVICE=t 80 wlc 10.1.1.2:http,2 10.1.1.3:8080 10.1.1.4

#realserver setup (nothing to be done for LVS-NAT)

#----------end lvs_nat.conf------------------------------------
]]></programlisting>
			</para><para>
The output is a commented rc.lvs_nat file.
Run the rc.lvs_nat file on the director and then the realservers
(the script knows whether it is running on a director or realserver).
			</para><para>
The configure script
will setup up masquerading, forwarding on
the director and the default gw for the realservers.
	</para>
	</section>
	<section id="lvs_nat_demasquerading">
	<title>Setting up demasquerading on the director; 2.4.x and 2.2.x</title>
	<para>
The packets coming in from the client are being demasqueraded by the director.
	</para><para>
In 2.2.x you need to masquerade the replies.
Here's the masquerading code in rc.lvs_nat, that runs on the
director (produced by the configure script).
			</para><para>
<programlisting><![CDATA[
        echo "turning on masquerading "
        #setup masquerading
        echo "1" >/proc/sys/net/ipv4/ip_forward
        echo "installing ipchain rules"
        /sbin/ipchains -A forward -j MASQ -s 10.1.1.2 http -d 0.0.0.0/0
	#repeated for each realserver and service
	..
	..
        echo "ipchain rules "
        /sbin/ipchains -L
]]></programlisting>
			</para><para>
In this example, http is being masqueraded by the director, allowing
the realserver to reply to the telnet requests from the director
being demasqueraded by the director as part of the 2.2.x LVS code.
			</para><para>
In 2.4.x masquerading of LVS'ed services is done explicitely
by the LVS code and no extra masquerading (by iptables)
commands need be run.
	</para>
	</section>
	<section id="re-mapping_ports_lvs_nat" xreflabel="Re-mapping ports with LVS-NAT">
	<title>rewriting, re-mapping, translating ports with LVS-NAT</title>
	<para>
One of the features of LVS-NAT is that you can rewrite/re-map the
ports. Thus the client can connect to VIP:http, while the realserver can
be listening on some other port (!http). You set this up with <command>ipvsadm</command>
	</para>
	<para>
Here the client connects to VIP:http, the director rewrites the packet header so that
dst_addr=RIP:9999 and forwards the packet to the realserver,
where the httpd is listening on RIP:9999.
	</para>
<programlisting><![CDATA[
director:/# /sbin/ipvsadm -a -t VIP:http -r RIP:9999 -m -w 1
]]></programlisting>
	<para>
For each realserver (<emphasis>i.e.</emphasis> each RIP) you can
rewrite the ports differently: each realserver could have the httpd
listening on it's own particular port (<emphasis>e.g.</emphasis> RIP1:9999, RIP2:80,
RIP3:xxxx).
	</para>
	<para>
Although port re-mapping is not possible with LVS-DR or LVS-Tun, it's
possible to use <command>iptables</command> to do
<xref linkend="re-mapping_ports_lvs_dr"/> (and LVS-Tun) on the realserver,
producing the same result.
	</para>
	</section>
	<section id="masquerade_timeouts">
	<title>masquerade timeouts</title>
	<para>
For the earlier versions of LVS-NAT (with 2.0.36 kernels) the
timeouts were set by linux/include/net/ip_masq.h, the default
values of masquerading timeouts are:
	</para><para>
<programlisting><![CDATA[
        #define MASQUERADE_EXPIRE_TCP 15*16*Hz
        #define MASQUERADE_EXPIRE_TCP_FIN 2*16*Hz
        #define MASQUERADE_EXPIRE_UDP 5*16*Hz
]]></programlisting>
	</para>
	</section>
	<section id="lvs_nat_julians_setup">
	<title>Julian's step-by-step check of a L4 LVS-NAT setup</title>
	<para>
Julian has his latest fool-proof setup doc at
<ulink url="http://www.ssi.bg/~ja/L4-NAT-HOWTO.txt">
Julian's software page</ulink>.
Here's the version, at the time I wrote this entry.
			</para><para>
<programlisting><![CDATA[
Q.1 Can the realserver ping client?

	rs# ping -n client

A.1 Yes => good
A.2 No => bad

	Some settings for the director:

	Linux 2.2/2.4:
	ipchains -A forward -s RIP -j MASQ

	Linux 2.4:
	iptables -t nat -A POSTROUTING -s RIP -j MASQUERADE

Q.2 Traceroute to client goes through LVS box and reaches the client?

	traceroute -n -s RIP CLIENT_IP

A.1 Yes => good
A.2 No => bad

	same ipchains command as in Q.1

	For client and server on same physical media use these
	in the director:

	echo 0 > /proc/sys/net/ipv4/conf/all/send_redirects
	echo 0 > /proc/sys/net/ipv4/conf/<DEV>/send_redirects


Q.3 Is the traffic forwarded from the LVS box, in both directions?

	For all interfaces on director:
	tcpdump -ln host CLIENT_IP

	The right sequence, i.e. the IP addresses and ports on each
	step (the reversed for the in->out direction are not shown):

	CLIENT
	   | CIP:CPORT -> VIP:VPORT
	   |		||
	   |		\/
 out	   | CIP:CPORT -> VIP:VPORT
 ||	LVS box
 \/	   | CIP:CPORT -> RIP:RPORT
 in	   |		||
	   |		\/
	   | CIP:CPORT -> RIP:RPORT
	   +
	REAL SERVER

A.1 Yes, in both directions => good (for Layer 4, probably not for L7)
A.2 The packets from the realserver are dropped => bad:

	- rp_filter protection on the incoming interface, probably
	hit from local client (for more info on rp_filter, see
the section on <xref linkend="proc_filesystem"/>
	- firewall rules drop the replies

A.3 The packets from the realservers leave the director unchanged

	- missing -j MASQ ipchains rule in the LVS box

	For client and server on same physical media:

	The packets simply does not reach the director. The real
	server is ICMP redirected to the client. In director:

	echo 0 > /proc/sys/net/ipv4/conf/all/send_redirects
	echo 0 > /proc/sys/net/ipv4/conf/<DEV>/send_redirects

A.4 All packets from the client are dropped

	- the requests are received on wrong interface with rp_filter
	protection
	- firewall rules drop the requests

A.5 The client connections are refused or are served from service
in the LVS box

	- client and LVS are on same host => not valid
	- the packets are not marked from the firewall and don't hit
	firewall mark based virtual service

Q.4 Is the traffic replied from the realserver?

	For the outgoing interface on realserver:

	tcpdump -ln host CLIENT_IP

A.1 Yes, SYN+ACK => good
A.2 TCP RST => bad, No listening real service
A.3 ICMP message => bad, Blocked from Firewall/No listening service
A.4 The same request packet leaves the realserver => missing accept
	rules or RIP is not defined
A.5 No reply => realserver problem:

	- the rp_filter protection drops the packets
	- the firewall drops the request packets
	- the firewall drops the replies

A.6 Replies goes through another device or don't go to the LVS
box =? bad

	- the route to the client is direct and so don't pass the LVS
	box, for example:

		- client on the LAN
		- client and realserver on same host

	- wrong route to the LVS box is used => use another

	Check the route:

	rs# ip route get CLIENT_IP from RIP


The result: start the following tests

rs# tcpdump -ln host CIP
rs# traceroute -n -s RIP CIP
lvs# tcpdump -ln host CIP
client# tcpdump -ln host CIP


For more deep problems use tcpdump -len, i.e. sometimes the link layer
addresses help a bit.


For FTP:

	VS-NAT in Linux 2.2 requires:

	- modprobe ip_masq_ftp (before 2.2.19)
	- modprobe ip_masq_ftp in_ports=21 (2.2.19+)

	VS-NAT in Linux 2.4 requires:

	- ip_vs_ftp

	VS-DR/TUN require persistent flag


	FTP reports with debug mode enabled are useful:

	# ftp
	ftp> debug
	ftp> open my.virtual.ftp.service
	ftp> ...
	ftp> dir
	ftp> passive
	ftp> dir

	There are reports that sometimes the status strings reported
	from the FTP realservers are not matched with the string
	constants encoded in the kernel FTP support. For example,
	Linux 2.2.19 matches
	"227 Entering Passive Mode (xxx,xxx,xxx,xxx,ppp,ppp)"


Julian Anastasov
]]></programlisting>

	</para>
	</section>
	<section id="lvs_nat_how_it_works">
	<title>How LVS-NAT works</title>
	<para>
director:/etc/lvs# ipvsadm does the following
	</para>
<programlisting><![CDATA[
#setup connection for telnet, using round robin
director:/etc/lvs# /sbin/ipvsadm -A -t 192.168.1.110:23 -s rr
#connections to x.x.x.110:telnet are sent to
#                 realserver 10.1.1.2:telnet
#using LVS-NAT (the -m) with weight 1
director:/etc/lvs# /sbin/ipvsadm -a -t 192.168.1.110:23 -r 10.1.1.2:23 -m -w 1
#and to realserver 10.1.1.3
#using LVS-NAT with weight 2
director:/etc/lvs# /sbin/ipvsadm -a -t 192.168.1.110:23 -r 10.1.1.3:23 -m -w 2
]]></programlisting>
	<para>
(if the service was http instead of telnet,
the webserver on the realserver could be listening on port 8000 instead of 80)
	</para>
	<para>
Turn on ip_forwarding (so that the packets can be forwarded to the realservers)
	</para>
<programlisting><![CDATA[
director:/etc/lvs# echo "1" > /proc/sys/net/ipv4/ip_forward
]]></programlisting>
	<para>
Example: client requests a connection to 192.168.1.110:23
	</para>
	<para>
director chooses realserver 10.1.1.2:23, updates connection tables, then
	</para>
<programlisting><![CDATA[
packet                source                        dest
incoming              CIP:3456                      VIP:23
inbound rewriting     CIP:3456                      RIP1:23
reply (routed to DIP) RIP1:23                       CIP:3456
outbound rewriting    VIP:23                        CIP:3456
]]></programlisting>

	<para>
The client gets back a packet with the source_address = VIP.
	</para>
	<para>
For the verbally oriented...
	</para>
	<para>
The request packet is sent to the VIP. The director looks up its
tables and sends the connection to realserver1. The packet is
rewritten with a new destination (in this case with the same
port, but the port could be changed too) and sent to RIP1. The
realserver replies, sending back a packet to the client. The
default gw for the realserver is the director. The director
accepts the packet and rewrites the packet to have source=VIP and
sends the rewritten packet to the client.
	</para>
	<para>
Why isn't the source of the incoming packet rewritten to be the
DIP or VIP?
	</para>
	<para>
Wensong
	</para>
	<blockquote>
		<para>
...changing the source of the packet to the VIP sounds good too,
it doesn't require that default route rule, but requires additional
code to handle it.
		</para>
	</blockquote>
	</section>
	<section id="lvs_nat_src_addr_reply">
	<title>
In LVS-NAT, how do packets get back to the client, or how does the
director choose the VIP as the source_address for the outgoing packets?
	</title>
	<note>
	<para>
This was written for 2.0.x and 2.2.x kernel LVSs which was based on
the masquerading code.
With 2.4.x, LVS is based on netfilter and there were initially some problems
getting LVS-NAT to work with 2.4.x.
What happens here for 2.4.x, I don't know.
	</para>
	</note>
	<para>
Joe
	</para>
	<para>
In normal NAT, where a bunch of machines are sitting
behind a NAT box, all outward going packets are given
the IP on the outside of the NAT box.
What if there are several IPs facing the outside world?
For NAT it doesn't really matter as long as the
same IP is used for all packets.
The default value is usually the first interface address (eg eth0).
With LVS-NAT you want the outgoing packets to have the
source of the VIP (probably on eth0:1) rather than the
IP on the main device on the director (eth0).
	</para>
	<para>
With a single realserver LVS-NAT LVS serving telnet,
the incoming packet does this,
	</para>
<programlisting><![CDATA[
CIP:high_port -> VIP:telnet     #client sends a packet
CIP:high_port -> RIP:telnet     #director demasquerades packet, forwards to realserver
RIP:telnet    -> CIP:high_port  #realserver replies
]]></programlisting>
	<para>
The reply arrives on the director (being sent
there because the director is the default
gw for the realserver).
To get the packet from the director to the
client, you have to reverse the masquerading
done by the LVS. To do this (in 2.2 kernels),
on the director
you add an ipchains rule
	</para>
<programlisting><![CDATA[
director:# ipchains -A forward -p tcp -j MASQ -s realserver1 telnet -d 0.0.0.0/0
]]></programlisting>
	<para>
If the director has multiple IPs facing the outside
world (eg eth0=192.168.2.1 the regular IP for the director
and eth0:1=192.168.2.110 the VIP), the masquerading code
has to choose the correct IP for the outgoing packet.
Only the packet with src_addr=VIP will be accepted by
the client. A packet with any other scr_addr will be
dropped. The normal default for masquerading (eth0)
should not be used in this case. The required m_addr
(masquerade address) is the VIP.
	</para>
	<para>
Does LVS fiddle with the ipchains tables to do this?
	</para>
	<para>
Julian Anastasov <emphasis>ja (at) ssi (dot) bg</emphasis> 01 May 2001
	</para>
	<blockquote>
		<para>
        No, ipchains only delivers packets to the masquerading code.
It doesn't matter how the packets are selected in the ipchains
rule.
		</para>
		<para>
The m_addr (masqueraded_address)
is assigned when the first packet is seen (the connect
request from the client to the VIP).
LVS sees the first packet in the LOCAL_IN chain when it comes from
the client. LVS assigns the VIP as maddr.
		</para>
		<para>
The MASQ code sees the first packet in the FORWARD chain when
there is a -j MASQ target in the ipchains rule. The routing selects
the m_addr. If the connection already exists the packets are masqueraded.
		</para>
		<para>
The LVS can see packets in the FORWARD chain but they are for already
created connections, so no m_addr is assigned and the packets are
masqueraded with the address saved in the connections structure (the
VIP) when it was created.
		</para>
		<para>
There are 3 common cases:
		</para>
		<orderedlist>
			<listitem>
The connection is created as response to packet.
			</listitem>
			<listitem>
The connection is created as response to packet to another connection.
			</listitem>
			<listitem>
The connection is already created
			</listitem>
		</orderedlist>
		<para>
Case (1) can happen in the plain masquerading case where the in->out
packets hit the masquerading rule. In this case when nobody recommends
the s_addr for the packets going to the external side of the MASQ, the
masq code uses the routing to select the m_addr for this new connection.
This address is not always the DIP, it can be the preferred source
address for the used route, for example, address from another device.
		</para>
		<para>
Case (1) happens also for LVS but in this case we know:
		</para>
		<itemizedlist>
			<listitem>
the client address/port (from the received datagram)
			</listitem>
			<listitem>
the virtual server address/port (from the received datagram)
			</listitem>
			<listitem>
the realserver address/port (from the LVS scheduler)
			</listitem>
		</itemizedlist>
		<para>
But this is on out->in packet and we are talking about in->out packets
		</para>
		<para>
Case (2) happens for related connections where the new connection can
be created when all addresses and ports are known or when the protocol
requires some wildcard address/port matching, for example, ftp. In
this case we expect the first packet for the connection after some
period of time.
		</para>
		<para>
It seems you are interested how case (3) works. The answer is that the
NAT code remembers all these addresses and ports in a connection
structure with these components
		</para>
		<itemizedlist>
			<listitem>
external address/port (LVS: client)
			</listitem>
			<listitem>
masquerading address/port (LVS: virtual server)
			</listitem>
			<listitem>
internal address/port (LVS: realserver)
			</listitem>
			<listitem>
protocol
			</listitem>
			<listitem>
etc
			</listitem>
		</itemizedlist>
		<para>
LVS and the masquerading code simply hook in the packet path
and they perform the header/data mangling. In this process they use the
information from the connection table(s). The rule is simple: when a
packet is already for established connection we must remember all
addresses and ports and always to use same values when mangling the
packet header. If we select each time different addresses or ports
we simply break the connection. After the packet is mangled the routing
is called to select the next hop. Of course, you can expect problems
if there are fatal route changes.
		</para>
		<para>
	So, the short answer is: the LVS knows what m_addr to use when
a packet from the realserver is received because the connection is
already created and we know what addresses to use. Only in the
masquerading case (where LVS os not involved) connections can be
created and a masquerading address to be selected without using rule
for this. In all other cases there is a rule that recommends what
addresses to be used at creation time. After creation the same values
are used.
		</para>
	</blockquote>
		<section id="VIP_is_primary_IP">
		<title>So make the VIP the primary IP on the outside of the director</title>
		<blockquote>
			<para>
Wayne <emphasis>wayne (at) compute-aid (dot) com</emphasis>
26 Apr 2000
			</para>
			<para>
Any web server behind the LVS box use LVS-NAT can
initiate communication to the Internet.  However, it is not
using the farm IP address,  rather it is using the
masquerading IP address -- the actual IP address of the
interface.  Is there easy way to let the server in NAT mode
to go out as the farm IP address?
			</para>
		</blockquote>
		<para>
Lars
		</para>
		<para>
No. This is a limitation in the 2.2 masquerading code. It will always use the
first address on the interface.
		</para>
		<blockquote>
We tried and it works!  We put VIP on eth0, and RIP on eth0:1 in
NAT mode and it works fine.  Just need to figure out how to do it
during reboot, since this is done by playing with ifconfigure command.
Once we swap them around, the going out IP address is the VIP
address.  But if LVS box reboot, you just have to redo it again.
		</blockquote>

		<para>
Joe:
		</para>
		<para>
! :-)
I didn't realise you were in VS-NAT mode, therefore not having the
VIP on the realservers. I thought you must be in VS-DR.
		</para>
		</section>
	</section>
	<section id="one_network" xreflabel="One Network LVS-NAT">
	<title>One Network LVS-NAT</title>
	<note>
According to Malcolm Turnbull, this is called "One Arm NAT" in the commercial world
(<emphasis>i.e.</emphasis> one nic and one network)
	</note>
	<para>
The disadvantage of the 2 network LVS-NAT is that the realservers
are not able to connect to machines in the network of the VIP.
You couldn't make a LVS-NAT setup out of machines already on
your LAN, which were also required for other purposes to stay
on the LAN network.
	</para>
	<para>
Here's a one network LVS-NAT LVS.
	</para>
<programlisting><![CDATA[
                        ________
                       |        |
                       | client |
                       |________|
                       CIP=192.168.1.254
                           |
                           |
             __________    |
            |          |   |   VIP=192.168.1.110 (eth0:110)
            | director |---|
            |__________|   |   DIP=192.168.1.9 (eth0:9)
                           |
                           |
          ------------------------------------
          |                |                 |
          |                |                 |
   RIP1=192.168.1.2   RIP2=192.168.1.3  RIP3=192.168.1.4 (all eth0)
    _____________      _____________     _____________
   |             |    |             |   |             |
   | realserver  |    | realserver  |   | realserver  |
   |_____________|    |_____________|   |_____________|
]]></programlisting>
	<para>
The problem:
	</para>
	<para>
A return packet from the realserver (with address RIP->CIP)
will be sent to the realserver's default gw (the director).
What you want is for the director to accept the packet and
to demasquerade it, sending it on to the client as
a packet with address (VIP->CIP).
With ICMP redirects on, the director will realise that
there is a better route for this packet,
<emphasis>i.e.</emphasis> directly from the realserver
to the client and will send an ICMP redirect to the realserver,
informing it of the better route.
As a result, the realserver will send subsequent packets directly to the
client and the reply packet will not be demasqueraded by the director.
The client will get a reply from the RIP rather than the VIP
and the connection will hang.
	</para>
	<para>
The cure:
	</para>
	<para>
Thanks to
<emphasis>michael_e_brown (at) dell (dot) com</emphasis>
and Julian <emphasis>ja (at) ssi (dot) bg</emphasis>
for help sorting this out.
	</para>
	<para>
To get a LVS-NAT LVS to work on one network -
	</para>
	<orderedlist>
		<listitem>
		<para>
On the director, turn off icmp redirects on the NIC
that is the default gw for the realservers.
(Note: eth0 may be eth1 etc, on your machine).
		</para>
<programlisting><![CDATA[
director:/etc/lvs# echo 0 > /proc/sys/net/ipv4/conf/all/send_redirects
director:/etc/lvs# echo 0 > /proc/sys/net/ipv4/conf/default/send_redirects
director:/etc/lvs# echo 0 > /proc/sys/net/ipv4/conf/eth0/send_redirects
]]></programlisting>
		</listitem>
		<listitem>
		<para>
Make the director the default and only route for outgoing packets.
		</para>
		<para>
You will probably have set the routing on the realserver up like this
		</para>
<programlisting><![CDATA[
realserver:/etc/lvs# netstat -r
Kernel IP routing table
Destination     Gateway         Genmask         Flags   MSS Window  irtt Iface
192.168.1.0     0.0.0.0         255.255.255.0   U         0 0          0 eth0
127.0.0.0       0.0.0.0         255.0.0.0       U         0 0          0 lo
0.0.0.0         director        0.0.0.0         UG        0 0          0 eth0
]]></programlisting>
		<para>
Note the route to 192.168.1.0/24.
This route allows the realserver to send packets
to the client by just putting them out on eth0,
where the client will pick them up directly
(without being demasqueraded) and the LVS will not work.
This route also allows the realservers to talk to each
other directly <emphasis>i.e.</emphasis> without routing packets
through the director.
(As the admin, you might want to telnet
from one realserver to another, or you might have
ntp running, sending ntp packets between realservers.)
		</para>
		<para>
Remove the route to 192.168.1.0/24.
		</para>
<programlisting><![CDATA[
realserver:/etc/lvs#route del -net 192.168.1.0 netmask 255.255.255.0 dev eth0
]]></programlisting>
		<para>
This will leave you with
		</para>
<programlisting><![CDATA[
realserver:/etc/lvs# netstat -r
Kernel IP routing table
Destination     Gateway         Genmask         Flags   MSS Window  irtt Iface
127.0.0.0       0.0.0.0         255.0.0.0       U         0 0          0 lo
0.0.0.0         director        0.0.0.0         UG        0 0          0 eth0
]]></programlisting>
		</listitem>
	</orderedlist>
	<para>
Now packets RIP->CIP have to go via the director and will be demasqueraded.
The LVS-NAT LVS now works.
If LVS is forwarding telnet,
you can telnet from the client to the VIP and connect to the realserver.
As a side effect,
packets between the realservers are also routed via the director,
rather than going directly (note: all packets now go via the director).
(You can live with that.)
	</para>
	<para>
You can ping from the client to the realserver.
	</para>
	<para>
You can also connect _directly_ to services on the realserver _NOT_
being forwarded by LVS (in this case <emphasis>e.g.</emphasis> ftp).
	</para>
	<para>
You can no longer connect directly to the realserver for services
being forwarded by the LVS. (In the example here, telnet ports are
not being rewritten by the LVS, <emphasis>i.e.</emphasis> telnet->telnet).
	</para>
<programlisting><![CDATA[
client:~# telnet realserver
Trying 192.168.1.11...
^C
(i.e. connection hangs)
]]></programlisting>
	<para>
Here's tcpdump on the director. Since the network is switched
the director can't see packets between the client and realserver.
The client initiates telnet. `netstat -a` on the client
shows a SYN_SENT from port 4121.
	</para>
<programlisting><![CDATA[
director:/etc/lvs# tcpdump
tcpdump: listening on eth0
16:37:04.655036 realserver.telnet > client.4121: S 354934654:354934654(0) ack 1183118745 win 32120 <mss 1460,sackOK,timestamp 111425176[|tcp]> (DF)
16:37:04.655284 director > realserver: icmp: client tcp port 4 121 unreachable [tos 0xc0]
]]></programlisting>
	<para>
(repeats every second until I kill telnet on client)
	</para>
	<para>
The director doesn't see the connect request from client->realserver.
The first packet seen is the <command>ack</command> from the realserver,
which will be forwarded via the director.
The director will rewrite the <command>ack</command> to be from the director.
The client will not accept an <command>ack</command> to port 4121 from director:telnet.
	</para>
	<para>
Julian 2001-01-12
	</para>
	<para>
	The redirects are handled in net/ipv4/route.c:ip_route_input_slow(),
<emphasis>i.e.</emphasis> from the routing and before reaching LVS (in LOCAL_IN):
	</para>
<programlisting><![CDATA[
        if (out_dev == in_dev && err && !(flags&(RTCF_NAT|RTCF_MASQ)) &&
            (IN_DEV_SHARED_MEDIA(out_dev)
             || inet_addr_onlink(out_dev, saddr, FIB_RES_GW(res))))
                flags |= RTCF_DOREDIRECT;
]]></programlisting>
	<para>
	Here RTCF_NAT &amp;&amp; RTCF_MASQ are flags used from the dumb nat code
but the masquerading defined with ipchains -j MASQ does not set such
or some of these flags. The result: the redirect is sent according to
the conf/{all,&lt;device&gt;}/send_redirects from ip_rt_send_redirect() and
ip_forward() from net/ipv4/ip_forward.c. So, the meaning is: if we are
going to forward packet and the in_dev is same as out_dev we redirect
the sender to the directly connected destination which is on the same
shared media. The ipchains code in the FORWARD chain is reached too late
to avoid sending these redirects. They are already sent when the -j MASQ
is detected.
	</para>
	<para>
	If all/send_redirects is 1 every &lt;device&gt;/send_redirects
is ignored. So, if we leave it 1 redirects are sent. To stop them we
need all=0 &amp;&amp; &lt;device&gt;=0. default/send_redirects is the value that will
be inherited from each new interface that is created.
	</para>
	<para>
	The logical operation between conf/all/&lt;var&gt; and
conf/&lt;device&gt;/&lt;var&gt; is different for each var. The used operation is
specified in <filename>/usr/src/linux/include/linux/inetdevice.h</filename>
	</para>
	<para>
	For send_redirects it is '||'. For others, for example for
conf/{all,&lt;device&gt;}/hidden), it is '&amp;&amp;'
	</para>
	<para>
So, for the two logical operations we have:
	</para>
<programlisting><![CDATA[
For &&:

all	<dev>	result
------------------------------
0	0	0
0	1	0
1	0	0
1	1	1

For ||:

all	<dev>	result
------------------------------
0	0	0
0	1	1
1	0	1
1	1	1
]]></programlisting>
	<para>
	When a new interface is created we have two choices:
	</para>
	<para>
1. to set conf/default/&lt;var&gt; to the value that we want each new
created interface to inherit
	</para>
	<para>
2. to create the interface in this way:
	</para>
<programlisting><![CDATA[
ifconfig eth0 0.0.0.0 up
]]></programlisting>
	<para>
and then to set the value before assigning the address:
	</para>
<programlisting><![CDATA[
echo <val> > conf/eth0/<var>
ifconfig eth0 192.168.0.1 up
]]></programlisting>
	<para>
but this is risky especially for the tunnel devices, for example, if
you want to play with var rp_filter.
	</para>
	<para>
	For the other devices this is a safe method if there is no
problem with the default value before assigning the IP address. The
first method can be the safest one but you have to be very careful.
	</para>
		<section id="stump">
		<title>One Network LVS from Joe Stump</title>

		<para>
		Joe Stump <emphasis>joe (at) joestump (dot) net</emphasis> 2002-09-04
		</para>

			<section><title>Problem</title>
			<para>
The problem is you have one network that has your realservers, directors, and
clients all together on the same class C. For this example we will say they all
sit on 192.168.1.*. Here is a simple layout.
			</para>
<programlisting><![CDATA[
                         ~~~~~~~~~~~~~
                         {  Internet }------------------------+
                         ~~~~~~~~~~~~~                        |
                              |                               | IP: 192.168.1.1
                              | External IP: 166.23.3.4       |
                              |                               |
                       +---------------+                   +---------+
                       |   Director    |-------------------| Gateway |
                       +---------------+                   +---------+
                              |                                  |
                              | Internal IP: 192.168.1.25        |
                              |                                  |
                   +----------+                                  |
                   |                                             |
                   | IP: 192.168.1.200                     +--------+
                   |                                       | Client |
           +---------------+                               +--------+
           |  Real Server  |                            IP: 192.168.1.34
           +---------------+
]]></programlisting>
			<para>
Everything looks like it should work just fine right? Wrong. The problem is
that in reality all of these machines are able to talk to one another because
they all reside on the same physical network. So here is the problem: clients
outside of the internal network get expected output from the load balancer, but
clients on the internal network hang when connecting to the load balancers.
			</para>
			</section>
			<section>
			<title>Cause</title>
			<para>
So what is causing this problem? The routing tables on the directors and the
realservers are causing your client to become confused and hang the connection.
If you look at your routing tables on your realserver you will notice that
the default gatway for your internal network is 0.0.0.0. Your director will
have a similar route. These routes tell your directors and realservers that
requests coming from machines on that network should be routed directly back
to that machine. So when a request comes to the director the director routes
it to the realserver, but the realserver sends the response directly back to
the client instead of routing it back through the director as it should. The
same thing happens when you try to connect via the director's outside IP from
an internal client IP, only this time the director mistakenly sends directly
to the internal client IP. The internal client IP is expecting the return
packets from the director's external IP, not the director's internal IP.
			</para>
			</section>
			<section>
			<title>Solution</title>
			<para>
The solution is simple. Delete the default routes on your directors and real
servers to the internal network.
			</para>
<programlisting><![CDATA[
route del -net 192.168.1.0 netmask 255.255.255.0 dev eth0
]]></programlisting>
			<para>
The above line should do the trick. One thing to note is that you will not
be able to connect to these machines once you have deleted these routes. Y0u
might just want to use the director as a terminal server since you can connect
from there to the realservers.
			</para><para>

Also, if you have your realservers connect to DB's and NFS servers on the
internal network you will have to add direct routes to those hosts. You do
this by typing this:
			</para>

<programlisting><![CDATA[
route add -host $SERVER dev eth0
]]></programlisting>
			<para>

I added these routes to a startup script so it kills my internal routes and
adds the needed direct routes to my NFS and DB server during startup.
			</para>
			</section>
		</section>
		<section id="one_network_nat_with_windows_realservers">
		<title>One Network LVS-NAT with windows realservers</title>
		<para>
Malcolm Turnbull <emphasis>malcolm (at) loadbalancer (dot) org</emphasis> 1 Aug 2008 
		</para>
		<para>
Route configuration for Windows Server with one arm NAT mode:
		</para>
		<para>
When a client on the same subnet as the real server tries to access
the virtual server on the load balancer the request will fail. The
real server will try to use the local network to get back to the
client rather than going through the load balancer and getting the
correct network translation for the connection.
		</para>
		<para>
To rectify this issue we need to add a route to the the load balancer
that takes priority over Windows default routing rules.
This is a simple case of adding a permanent route:
		</para>
<programlisting><![CDATA[
route add -p 192.168.1.0 mask 255.255.255.0 metric 1
]]></programlisting>
		<para>
(NB. Replace 192.168.1.0 with your local subnet address.)
The default route to the local network has a metric of 10, so this new
route overrides all local traffic and forces it to go through the load
balancer as required.
Any local traffic (same subnet) is handled by this route and any
external traffic is handled by the default route (which also points at
the load balancer).
		</para>
		</section>
		<section id="lvs_nat_one_network_malcolm">
		<title>Malcolm's modification of the One Network LVS-NAT</title>
		<para>
Malcolm Turnbull <emphasis>malcolm (at) loadbalancer (dot) org</emphasis> 1 Aug 2008 
		</para>
		<para>
Forgot to add that this method (<emphasis>i.e.</emphasis> the windows realserver method above)
works for Linux as well avoiding the
need to add a route for each host
		</para>
		<para>
Route configuration for Linux with one arm NAT mode:
When a client on the same subnet as the real server tries to access
the virtual server on the load balancer the request will fail. The
real server will try to use the local network to get back to the
client rather than going through the load balancer and getting the
correct network translation for the connection.
To rectify this issue we need to modify the local network route to a
higher metric:
		</para>
<programlisting><![CDATA[
route del -net 192.168.1.0 netmask 255.255.255.0 dev eth0
route add -net 192.168.1.0 netmask 255.255.255.0 metric 2000 dev eth0
]]></programlisting>
		<para>
NB. Replace 192.168.1.0 with your local subnet address.
Then we need to make sure that local network access uses the load
balancer as its default route:
		</para>
<programlisting><![CDATA[
route add -net 192.168.1.0 netmask 255.255.255.0 gateway 192.168.1.21 metric 0 dev eth0
]]></programlisting>
		<para>
NB. Replace 192.168.1.21 with your load balancer gateway
Any local traffic (same subnet) is handled by this manual route and
any external traffic is handled by the default route (which also
points at the load balancer).
		</para>
		<note>
FIXME 
Joe: here's what I think Malcolm is saying.
Malcolm's clients are on 0/0 and not on the same logical network as the realservers.
(In the setup above needing the icmp redirects turned off, all machines, client, director, realservers
are on the same network).
		<itemizedlist>
			<listitem>
metric 0 is high priority. anything to 0/0 goes to default gw
			</listitem>
			<listitem>
metric 2000 is low priority. anything to 192.168.1.0/24 goes to eth0.
			</listitem>
			<listitem>	
you don't need to turn off icmp redirects
			</listitem>
		</itemizedlist>
However
		<itemizedlist>
			<listitem>
the linux kernel ignores the metric 
			</listitem>
			<listitem>
only dynamic routing protocols (RIP, GATED) use metric,
and then only to decide between duplicate routes.
			</listitem>
			<listitem>
routes with (metric&gt;16) are ignored by dynamic routing protocols.
Presumably Linux ignoring the metric, treats a route with metric=2000
the same as a route with metric=0.
			</listitem>
		</itemizedlist>
So although Malcolm's method works, we don't understand why at the moment.
		</note>
		</section>
		<section id="lvs_nat_one_network_eric_robinson">
		<title>One net LVS-NAT with static routes, with small number of fixed clients, from Eric Robinson</title>
		<para>
From: "Robinson, Eric" <emphasis>eric (dot) robinson (at) psmnv (dot) com</emphasis> 21 Mar 2009
		</para>
		<para>
The section on One Network LVS-NAT solution which relies on disabling
redirects at the load balancer and removing the local LAN routes from
the RealServers causes all network traffic between RealServers to
pass through the director (as is required). 
This is undesirable in environments where
inter-RS traffic is high, as with clustering and data replication.
		</para>
		<para>
If someone only has a few clients that need to
access RealServers on their own subnet through a director, 
then static routes on each client and RS seems to be a better approach.
I just added explicit routes from each RS to
my client machine through the director and did the same on the client. I
figured I could live with some redirect traffic. It worked fine, and as
a side effect I noticed that no redirects were being sent by the
director machine anyway. Running sniffers simultaneously on the client,
the director, and the server, I observed no ICMP redirects being sent or
received. The traces also showed that requests and responses were in
fact passing through the director and being properly NATed.
		</para>
		</section>
		<section id="lvs_nat_one_network_mailing_list">
		<title>One net LVS-NAT from the mailing list</title>
		<para>
Here's an untested solution from Julian for a one network LVS-NAT
(I assume this is old, maybe 1999, because I don't have a date on it).
		</para><para>
put the client in the external logical network. By this way the
client, the director and the realserver(s) are on same physical network
but the client can't be on the masqueraded logical network. So, change the
client from 192.168.1.80 to 166.84.192.80 (or something else). Don't add
through DIP (I don't see such IP for the Director). Why in your setup
DIP==VIP ? If you add DIP (166.84.192.33 for example) in the director you
can later add path for 192.168.1.0/24 through 166.84.192.33. There is no
need to use masquerading with 2 NICs. Just remove the client from the
internal logical network used by the LVS cluster.
		</para><para>
A different working solution from Ray Bellis <emphasis>rpb (at) community (dot) net (dot) uk</emphasis>
		</para><para>
the same *logical* subnet.
I still have a dual-ethernet box acting as a director, and the VIP is
installed as an alias interface on the external side of the director, even
though the IP address it has is in fact assigned from the same subnet as the
		</para><para>
Ray Bellis <emphasis>rpb (at) community (dot) net (dot) uk</emphasis> has used a 2 NIC director
to have the RIPs on the same logical network as the VIP
(ie RIP and VIP numbers are from the same subnet), although
they are in different physical networks.
		</para>
		</section>
	</section>
	<section id="lvs_nat_rewriting_slow">
	<title>re-mapping ports, rewriting is slow for 2.0, 2.2 kernels</title>
	<para>
	For LVS-NAT, the packet headers are re-written
(from the VIP to the RIP and back again).
At no extra overhead, anything else in the header can
be rewritten at the same time. LVS-NAT can rewrite the ports
Thus a request to port VIP:80 received on the director
can be sent to RIP:8000 on the realserver.
	</para>
	<para>
In the 2.0.x and 2.2.x series of IPVS, rewriting the packet
headers is slow on machines from that era
(60usec/packet on a pentium classic)
and limits the throughput of LVS-NAT (for 536byte packets, this is
72Mbit/sec or about 100BaseT). While LVS-NAT throughput does not
scale well with the packet rate (after you run out of CPU), the advantage of
LVS-NAT is that realservers can have any OS, no modifications are
needed to the realserver to run it in an LVS, and the realserver
can have services not found on Linux boxes.
	</para>
	<note>
	<para>
For <xref linkend="LVS-HOWTO.localnode"/>,
headers are <emphasis>not</emphasis> rewritten.
	</para>
	</note>
	<para>
The LVS-NAT code for 2.4 is rewritten as a Netfilter modules
and is not detectably slower than LVS-DR or LVS-Tun.
(The IPVS code for the early 2.4.x kernels in 2001 was buggy
during the changeover, but that is all fixed now.)
	</para>
	</section>
	<section id="two_instances_on_realserver">
	<title>Two instances of demon running on realserver</title>
	<para>
from Horms, Jul 2005
	</para>
	<para>
With LVS-DR or LVS-Tun, the packet arrives on the realserver with
dst_addr=VIP:port. 
Thus even if you set up two RIPs on the realserver you cannot have
two instances of the service demon, because they would both have
to be listening for VIP:port.
With LVS-NAT, you could 
	</para>
	<itemizedlist>
		<listitem>
have two RIPs (RIP1 and RIP2) on one realserver (both IPs could be on one NIC),
<command>ipvsadm</command> forwarding to both RIPs,  
with an instance of the demon listening to RIP1 
and another instance of the demon listening to RIP2.
		</listitem>
		<listitem>
one RIP on the realserver, but have <command>ipvsadm</command> 
forward requests to two different ports. 
Thus one instance of the demon would listen to RIP:port1 
and another would listen to RIP:port2.
		</listitem>
	</itemizedlist>
	</section>
	<section id="lvs_nat_performance">
	<title>Performance of LVS-NAT</title>
	<para>
Horms
	</para>
	<para>
All things are relative. LVS-NAT is actually pretty fast.
I have seen it do well over 600Mbit/s. But in theory LVS-DR
is always going to be faster because it does less work.
If you only have 100Mbit/s on your LAN then either will be fine.
If you have gigabit then LVS-NAT will still probably be fine.
Beyond that... I am not sure if anyone has tested that to see
what will happen.
In terms of number of connections, there is a limit
with LVS-NAT that relates to the number of ports.
But in practice you probably won't reach that limit anyway.
	</para>
		<section id="lvs_nat_performance_2.0_2.2">
		<title>Performance of LVS-NAT, 2.0 and 2.2 kernels</title>
		<para>
With the slower machines around in the early days of LVS,
the throughput of LVS-NAT was limited by the time taken by the
director to rewrite a packet.
The limit for a pentium classic 75MHz is about 80Mbit/sec (100baseT).
Since the director is the limiting step,
increasing the number of realservers does not increase the throughput.
		</para>
		<para>
The
<ulink
url="http://www.linuxvirtualserver.org/Joseph.Mack/performance/single_realserver_performance.html">
performance page
</ulink>
shows a slightly higher latency with LVS-NAT compared to LVS-DR or LVS-Tun,
but the same maximum throughput. The load average on the director is high (>5)
at maximum throughput, and the keyboard and mouse are quite sluggish.
The same director box operating at the same throughput under LVS-DR or
LVS-Tun has no perceptable load as measured by <command>top</command>
or by mouse/keyboard responsiveness.
		</para>
		</section>
		<section id="2.4_NAT">
		<title>Performance of LVS-NAT, 2.4 kernels</title>
		<para>
Wayne
		</para>
		<blockquote>
NAT taks some CPU and memory copying. With a slower CPU, it will
be slower.
		</blockquote>
		<para>
<ulink url="http://marc.theaimsgroup.com/?l=linux-virtual-server&amp;m=99554689108488&amp;w=2">
the origial posting</ulink>
		</para>
		<para>
Julian Anastasov <emphasis>ja (at) ssi (dot) bg</emphasis> 19 Jul 2001
		</para>
		<para>
	This is a myth from the 2.2 age. In 2.2 there are 2 input
route calls for the out->in traffic and this reduces the performance.
By default, in 2.2 (and 2.4 too) the data is not copied when the IP
header is changed. Updating the checksum in the IP header does not
cost too much time compared to the total packet handling time.
		</para>
		<para>
	To check the difference between the NAT and DR forwarding
method in out->in direction you can use <link linkend="testlvs">testlvs</link> from
http://www.ssi.bg/~ja/ and to flood a 2.4 director in 2 setups: DR and NAT.
My tests show that I can't see a visible difference.
We are talking about 110,000 SYN packets/sec with 10 pseudo clients and
same cpu idle during the tests (there is not enough client power in my
setup for full test), 2 CPUx 866MHz, 2 100mbit internal i82557/i82558
NICs, switched hub:
		</para><para>
3 testlvs client hosts -> NIC1-LVS-NIC2 -> packets/sec.
		</para><para>
	I use small number of clients because I don't want to spend time
in routing cache or LVS table lookups.
		</para><para>
	Of course, the NAT involves in->out traffic and this can reduce
twice the performance if the CPU or the PCI power is not enough to handle
the traffic in both directions. This is the real reason the NAT method
to look so slow in 2.4. IMO, the overhead from the TUN encapsulation
or from the NAT process is negliable.
		</para><para>
	Here come the surprises:
		</para><para>
The basic setup: 1 CPU PIII 866MHz, 2 NICs (1 IN and 1 OUT), LVS-NAT,
SYN flood using testlvs with 10 pseudo clients, no ipchains rules.
Kernels: 2.2.19 and 2.4.7pre7.
		</para>
		<itemizedlist>
			<listitem>
				<para>
Linux 2.2 (with ipchains support, with modified demasq path to use
one input routing call, something like LVS uses in 2.4 but without dst
cache usage):
				</para>
<programlisting><![CDATA[
In 80,000 SYNs/sec, Out 80,000 SYNs/sec, CPU idle: 99% (strange)
In 110,000 SYNs/sec, Out 88,000 SYNs/sec, CPU idle: 0%
]]></programlisting>
			</listitem>
			<listitem>
				<para>
Linux 2.4 (with ipchains support): with 3-4 ipchains rules:
				</para>
<programlisting><![CDATA[
In 80,000 SYNs/sec, Out 55,000 SYNs/sec, CPU idle: 0%
In 80,000 SYNs/sec, Out 80,000 SYNs/sec, CPU idle: 0%
In 110,000 SYNs/sec, Out 63,000 SYNs/sec (strange), CPU idle: 0%
]]></programlisting>
			</listitem>
			<listitem>
				<para>
Linux 2.4 (without ipchains support):
				</para>
<programlisting><![CDATA[
In 80,000 SYNs/sec, Out 80,000 SYNs/sec, CPU idle: 20%
In 110,000 SYNs/sec, Out 96,000 SYNs/sec, CPU idle: 2%
]]></programlisting>
			</listitem>
			<listitem>
				<para>
Linux 2.4, 2 CPU (with ipchains support):
				</para>
<programlisting><![CDATA[
In 80,000 SYNs/sec, Out 80,000 SYNs/sec, CPU idle: 30%
In 110,000 SYNs/sec, Out 96,000 SYNs/sec, CPU idle: 0%
]]></programlisting>
			</listitem>
			<listitem>
				<para>
Linux 2.4, 2 CPU (without ipchains support):
				</para>
<programlisting><![CDATA[
In 80,000 SYNs/sec, Out 80,000 SYNs/sec, CPU idle: 45%
In 110,000 SYNs/sec, Out 96,000 SYNs/sec, CPU idle: 15%, 30000 ctxswitches/sec
]]></programlisting>
			</listitem>
		</itemizedlist>
			<para>
What I see is that:
			</para>
		<itemizedlist>
			<listitem>
				<para>
modified 2.2 and 2.4 UP look equal on 80,000P/s
				</para><para>
limits: 2.2=88,000P/s, 2.4=96,000P/s, i.e. 8% difference
				</para>
			</listitem>
			<listitem>
				<para>
1 and 2 CPU in 2.4 look equal 110,000->96,000 (100mbit or PCI bottleneck?),
may be we can't send more that 96,000P/s through 100mbit NIC?
				</para>
			</listitem>
			<listitem>
the ipchains rules can dramatically reduce the performance - from
88,000 to 55,000 P/s
			</listitem>
			<listitem>
2.4.7pre7 SMP shows too many context switches
			</listitem>
			<listitem>
DR and NAT show equal results for 2.4 UP
110,000->96,000P/s, 2-3% idle,
so I can't claim that there is a NAT-specific overhead.
			</listitem>
		</itemizedlist>
		<para>
I performed other tests, testlvs with UDP flood. The packet rate
is lower, the cpu idle time in the LVS box was increased dramatically
but the client hosts show 0% cpu idle, may be more testlvs client
hosts are needed.
		</para>
		<para>
Julian Anastasov <emphasis>ja (at) ssi (dot) bg</emphasis> 16 Jan 2002
		</para><para>
Many people think that the packet mangling is evil
in the NAT processing. The picture is different: the NAT processing in
2.2 uses 2 input routing calls instead of 1 and this totally kills
the forwarding of packets from/to many destinations. Such problems
are mostly caused from the bad hash function used in the routing code
and because the routing cache has hard limit for entries.
Of course, the NAT setups handle more traffic than the other forwarding
methods (both the forward and reply directions),
a good reason to avoid LVS-NAT with a low power director.
In 2.4 the difference
between the DR and NAT processing in out->in direction can not be
noticed (at least in my tests) because only one route call is used,
for all methods.
		</para>
		<para>
Matthew S. Crocker Jul 26, 2001
		</para><para>
DR is faster, less resource intensive but has issues with configuration
because of the age old 'arp problem'
		</para>
		<para>
Horms <emphasis>horms (at) vergenet (dot) net</emphasis>
		</para>
		<para>
LVS-NAT is still fast enough for many aplications and
is IMHO considerably easier to set up. While I think LVS-DR is great
I don't think people should be under the impresion that LVS-NAT
will intrisicly be a limiting factor to them.
		</para>
		<para>
Don Hinshaw <emphasis>dwh (at) openrecording (dot) com</emphasis> 04 Aug 2001
		</para>
		<para>
Cisco, Alteon and F5 solutions are all NAT based. The real limiting
factor as I understand it is the capacity of the netcard, which these three
deal with by using gigabit interfaces.
		</para>
		<para>
Julian Anastasov <emphasis>ja (at) ssi (dot) bg</emphasis> 05 Mar 2002 in discussion with Michael McConnell
		</para>
		<para>
	Note that I used a modified demasq path which uses
one input route for NAT but it is wrong. It only proves that
2.2 can reach the same speed as 2.4 if there was use_dst
analog in 2.2. Without such feature the difference is 8%.
OTOH, there is a right way to implement one input route call
as in 2.4 but it includes rewriting of the 2.2 input processing.
		</para>
		<para>
Michael McConnell
		</para>
		<blockquote>
From what I see here, it looks as though the 2.2 kernel handles a higher
numberof SYN's better than the 2.4 kernel. Am I to asume, that the for the
110,000SYNs/sec in the 2.4 kernel, only 63,000 SYNs/sec were answers? The
rest failed?
		</blockquote>
		<para>
	In this test 2.4 has firewall rules, while 2.2 has only
ipchains enabled.
		</para>
		<blockquote>
Is the 2.2 kernel better at answer a higher number of requests?
		</blockquote>
		<para>
	No. Note also that the testlvs test was only in one
direction, no replies, only client->director->realserver
		</para>
		<blockquote>
has anyone compared iptables/ipchains, via 2.2/2.4?
		</blockquote>
		<para>
here are my
<ulink url="http://marc.theaimsgroup.com/?l=linux-virtual-server&amp;m=100903333532449&amp;w=2">
results</ulink>
There is some magic in these tests, I don't know at one place
why netfilter shows such bad results. Maybe someone can point to me
to the problem.
		</para>
		</section>
	</section>
	<section id="debugging_routes">
	<title>Various debugging techniques for routes</title>
	<para>
This originally described how I debugged setting up a one-net LVS-NAT LVS
using the output of route. Since it is more about networking tools
than LVS-NAT it has been moved to the section on
<xref linkend="LVS-HOWTO.policy_routing"/>.
	</para>
	</section>
	<section id="lvs_nat_connecting_to_realserver">
	<title>Connecting directly from the client to a service:port on an LVS-NAT realserver</title>
	<para>
If you connect directly to the realserver in a LVS-NAT LVS, the reply
packet will be routed through the director, which will attempt to
masquerade it. This packet will not be part of an established connection
and will be dropped by the director, which will issue an ICMP error.
	</para>
	<para>
Paul Wouters <emphasis>paul (at) xtdnet (dot) nl</emphasis> 30 Nov 2001
	</para>
	<blockquote>
		<para>
It would like to reach all LVS'ed services on the realservers directly,
<emphasis>i.e.</emphasis> without going through the LVS-NAT director, say from
a local client not on the internet.
		</para>
		<para>
Connecting from client to a RIP
should just completely bypass all the lvs code, but it seems that the lvs
code is confused, and thinks a RIP->client answer should be part of its
NAT structure.
		</para>
		<para>
tcpdump running on internal interface of the director shows
a packet from the client received on the RIP;
the RIP replies (never reaches the client, the director drops it).
The director then sends out a port unreachable:
		</para>
	</blockquote>
	<para>
Julian
	</para>
	<para>
	The code that replies with an ICMP error can be removed but then
you still have the problem of reusing connections.
The local_client can select a port for direct connection
with the RIP but if that port was used
some seconds before for a CIP->VIP connection,
it is possible that LVS to catch these replies as part
of the previous connection.
LVS does not inspect the TCP headers and does not accurately keep the TCP state.
So, it is possible that LVS will not to detect that the local_client
and the realserver have established a new connection with
the same addresses and ports that are still known as NAT connection.
Even stateful conntracking can't notice
it because the local_clientIP->RIP packets are not subject to NAT processing. When
LVS sees the replies from RIP to local_clientIP it will SNAT them and this will
be fatal because the new connection is between the local_clientIP and RIP directly,
not from CIP->VIP->RIP. The other thing is that CIP even does not know
that it connects from same port to same server. It thinks there
are 2 connections from same CPORT: to VIP and to RIP, so they can live
even at the same time.
	</para>
	<blockquote>
But a proper TCP/IP stack on a client will not re-use the same port
that quickly, unless it is REALLY loaded with connections right?
And a client won't (can't?) use the same source port to different
destinations (VIP and RIP) right?
So, the problem becomes almost theoretical?
	</blockquote>
	<para>
	This setup is dangerous. As for the ICMP replies, they
are only for anti-DoS purposes but may be are going to die soon.
There is still no enough reason to remove that code (it was not
first priority).
	</para>
	<blockquote>
Or make it switachable as #ifdef or /proc sysctl?
	</blockquote>
	<para>
Wensong
	</para>
	<para>
Just comment out the whole block, for example,
	</para>
<programlisting><![CDATA[
#if 0
                if (ip_vs_lookup_real_service(iph->protocol,
                                              iph->saddr, h.portp[0])) {
                        /*
                         * Notify the realserver: there is no existing
                         * entry if it is not RST packet or not TCP packet.
                         */
                        if (!h.th->rst || iph->protocol != IPPROTO_TCP) {
                                icmp_send(skb, ICMP_DEST_UNREACH,
                                          ICMP_PORT_UNREACH, 0);
                                kfree_skb(skb);
                                return NF_STOLEN;
                        }
                }
#endif
]]></programlisting>
	<blockquote>
This works fine. Thanks
	</blockquote>
	<para>
The topic came up again. Here's another similar reply.
	</para>
	<blockquote>
I've set up a small LVS_NAT-based http load
balancer but can't seem to connect to the realservers
behind them via IP on port 80.
Trying to connect directly to the realservers
on port 80, though, translates everything correctly,
but generates an ICMP port unreach.
	</blockquote>
	<para>
Ben North <emphasis>ben (at) antefacto (dot) com</emphasis> 06 Dec 2001
	</para>
	<para>
The problem is that LVS takes an interest in all packets with a
source IP:port of a Real Service's IP:port, as they're passing
through the FORWARD block.  This is of course necessary ---
normally such packets would exist because of a connection
between some client and the Virtual Service, mapped by LVS to
some Real Service.  The packets then have their source address
altered so that they're addressed VIP:VPort -> CIP:CPort.
	</para>
	<para>
However, if some route exists for a client to make connections
directly to the Real Service, then the packets from the Real
Service to the client will not be matched with any existing LVS
connection (because there isn't one).  At this point, the LVS
NAT code will steal the packet and send the "Port unreachable"
message you've observed back to the Real Server.  A fix to the
problem is to #ifdef out this code --- it's in ip_vs_out() in
the file ip_vs_core.c.
	</para>
	</section>
	<section id="lvs_nat_has_no_connections">
	<title>A NAT router has no connections</title>
	<para>
A NAT router rewrites source IP (and possibly the port)
of packets coming from machines on the inside network.
With an LVS-NAT director, the connection originates on
the internet and terminates on the realserver (de-masquerading).
The replies (from the realserver to the the lvs client) are
masqueraded. In both cases (NAT router, LVS-NAT director),
to the machine on the internet, the connection appears
to be coming from the box doing the NAT'ing. However
the NAT box has no connection (<emphasis>e.g.</emphasis>
with <command>netstat -an</command>) to the box on the
internet. It is just routing packets (and rewriting them). 
	</para>
	<para>
Horms 17 May 2004
	</para>
	<para>
There is no connection as such. Or more specifically,
the connection is routed, not terminated by the kernel. 
However, there is a proc entry, that you can inspect, 
to see the natted connections.
	</para>
	</section>
	<section id="lvs_net_extending">
	<title>Thoughts on extending NAT</title>
	<para>
<blockquote><para>Tao Zhao <emphasis>taozhao (at) cs (dot) nyu (dot) edu</emphasis> 01 May 2002
LVS-NAT assumes that all servers are behind the
director, so the director only need to change the destination IP when a
request comes in and forward that to the scheduled realserver. When the
reply packets go through the director it will change the source IP. This
limits the deployment of LVS using NAT: the director must be the outgoing
gateway for all servers.
			</para><para>
I am wondering if I can change the code so that both source and
destinamtion IPs are changed in both ways. For example,
CIP: client IP;
DIP: director IP;
SIP: server IP (public IPs);
			</para><para>
<programlisting><![CDATA[
Client->Director->Server: address pair (CIP, DIP) is changed to (DIP, SIP)
Server->Director->Client: address pair (SIP, DIP) is changed to (DIP, CIP).
]]></programlisting>
</para></blockquote>
			</para><para>
Lars
			</para><para>
Not very efficient; but this can actually already be done by using the
port-forwarding feature AFAIK, or by a userspace application level gateway. I
doubt its efficiency, since the director would _still_ need to be in between
all servers and the client both ways.
Direct routing and/or tunneling make more sense.
As well clients do not
know where the connection originally came from; making the logs on them nearly
useless, also filtering by client IP and establishing a session back to the
client (ie, ftp or some multimedia protocols) is also very difficult.
			</para><para>
Wayne <emphasis>wayne (at) compute-aid (dot) com</emphasis> 01 May 2002
			</para><para>
Client IP address is very important for analyzing the traffic for
marketing people.  Get rid of the CIP will make web server
has no way to log where the traffic coming from, thus totally
blind the marketing people, that is very undesirable for many
use.
Do you have to allocate a table for tracking these changes, too?
That will further slow down the director.
			</para><para>
<blockquote><para>
Of course, the director need to allocate a new port number and change the
source port number to it when it forwards the packet to the server. Thus
this local port number should be enough for the director to distinguish
different connections.
This way, there will be no limitation where the servers are (the tunneling
solution needs the change of server: setup tunneling)
</para></blockquote>
			</para><para>
Joe
			</para><para>
I talked to Wensong about this in the early days of LVS, but I remember
thinking that keeping track of the CIP would have been a lot of work.
I think I mentioned it in the HOWTO for a while.
However I'd be happy to use the code if someone else wrote it :-)
			</para><para>
Some commercial load balancers seem to have some NAT-like scheme where
the packets can return directly to the CIP without going through the director.
Does anyone know how it works? (Actually I don't know whether it's NAT-like
or not, I think there's some scheme out there that isn't VS-DR which
returns packets directly from the realservers to the clients - this
is called "direct server return" in the commercial world).
			</para><para>
Wayne <emphasis>wayne (at) compute-aid (dot) com</emphasis>
			</para><para>
I think those are switch-like load balancers.  They don't take any IP
addresses, But I think it could be done even with NAT, as long as
the server has two NIC, one talk to the load balancer, the other
talk to the switch/hub before the load balancer.  The load balancer
has to change the packet not have its own IP in it, so there is no
need to NAT back to the public packet.  Server set its default
gateway using the other NIC to send the packets out.
	</para>
	</section>
	<section id="lvs_nat_mailing_list">
	<title>Postings from the mailing list</title>
	<para>
<emphasis>frederic (dot) defferrard (at) ansf (dot) alcatel (dot) fr</emphasis>
	</para>
	<blockquote>
		<para>
 would be possible to use LVS-NAT to load-balance virtual-IPs to
 ssh-forwarded real-IPs?
 Ssh can also be used to create a local access that is forwarded to a
 remote access throught the ssh protocol. For example you can use ssh to
 securely map a local acces to a remote POP server:
		</para>
<programlisting><![CDATA[
 local:localport ==> local:ssh ~~~~~ ssh port forwarding ~~~~~ remote:ssh ==> remote:pop
]]></programlisting>
		<para>
 And when you connect to local:localip you are transparently/securely
 connected to remote:pop
 The main idea is to allow RS in differents LANs
 with RS that are non-Linux (precluding LVS-Tun).
 Example:
		</para>
<programlisting><![CDATA[
                                - VS:81 ---- ssh ---- RS:80
                               /
INTERNET - - - - > VS:80 (NAT)-- VS:82 ---- ssh ---- RS:80
                               \
                                - VS:83 ---- ssh ---- RS:80
]]></programlisting>
	</blockquote>
	<para>
Wensong
	</para>
	<para>
 you can use VPN (or CIPE) to map some external realservers into
 your private cluster network. If you use LVS-NAT, make sure the
 routing on the realserver must be configuration properly so that the
 response packets will go through the load balancer to the clients.
	</para>
	<blockquote>
 I think that it isn't necessery to have the default router to the load
 balancer when using ssh because when the RS address is the same that the
 VS address (differents ports)
	</blockquote>
	<para>
 With the NAT method, your example won't work because the LVS/NAT
 treats packets as local ones and forward to the upper layers without
 any change.
	</para>
	<para>
 However, your example give me an idea that we can dynamically redirect
 the port 80 to port 81, 82 and 83 respectively for different
 connections, then your example can work. However, the performance
 won't be good, because lots of works are done in the application
 level, and the overhead of copying from kernel to user-space is high.
	</para>
	<para>
 Another thought is that we might be able to setup LVS/DR with real
 server in different LANs by using of CIPE/VPN stuff. For example, we
 use CIPE to establish tunnels from the load balancer to realservers
 like
	</para>
<programlisting><![CDATA[
                     10.0.0.1================10.0.1.1 realserer1
                     10.0.0.2================10.0.1.2 realserer2
   --- Load Balancer 10.0.0.3================10.0.1.3 realserer3
                     10.0.0.4================10.0.1.4 realserer4
                     10.0.0.5================10.0.1.5 realserer5
]]></programlisting>
	<para>
 Then, you can add LVS-DR configuration commands as:
	</para>
<programlisting><![CDATA[
         ipvsadm -A -t VIP:www
         ipvsadm -a -t VIP:www -r 10.0.1.1 -g
         ipvsadm -a -t VIP:www -r 10.0.1.2 -g
         ipvsadm -a -t VIP:www -r 10.0.1.3 -g
         ipvsadm -a -t VIP:www -r 10.0.1.4 -g
         ipvsadm -a -t VIP:www -r 10.0.1.5 -g
 ]]></programlisting>
	<para>
I haven't tested it. Please let me know the result if anyone tests
this configuration.
	</para>
	<para>
Lucas 23 Apr 2004
	</para>
	<blockquote>
 Is it possible use the cluster as a NAT Router?
 What I'm saying is: I got a private LAN and I want to share my internet
 connection, doing NAT and Firewall and QoS. The realservers are actually
 routers and dont serve any service. Is there a way to use the VIP as the
 private LAN gateway or to pass the traffic through the director to the "real
 servers (real routers)" even when is not destined to a specific port in the
 server?
	</blockquote>
	<para>
Horms 21 May 2004
	</para>
	<para>
I think that should work, as long as you are only wanting to route IPv4
TCP, UDP and related ICMP.  You probably want to use a fwmark virtual
service so that you can forward all ports to the realservers (routers).
That said I haven't tried it, so I can't be sure.
	</para>
	</section>
	<section id="brownfield" xreflabel="source routing patches">
	<title>LVS-NAT source routing patch (Brownfield, Sawari and Black)</title>
	<note>
Mar 2006: This will be in the next release of LVS.
	</note>
	<para>
Ken Brownfield found that ipvs changes the routing of packets from the director to 0/0
(<emphasis>i.e.</emphasis> LVS-NAT or LVS-DR with the forward-shared patch).
The packets from ipvs should use the routing table, but they don't.
Ken had a director with two external NICS. He wanted 
the packets to return via the NIC they arrived. When he tried LVS-NAT, 
with his own installed routing table (which works when tested 
with traceroute), the reply packets from ip_vs are sent to the default gw, 
apparently ignoring his routing table. 
It should be none of ip_vs's business where the packets are routed.
	</para>
        <para>
Here's Ken's 
<ulink url="http:files/ip_vs_source_route.patch.gz">
ip_vs_source_route.patch.gz</ulink> patch.
	</para>
	<para>
Here's Ken's take on the matter
	</para>
	<para>
I need to support VIPs on the director that live on two  
separate external subnets:
	</para>
<programlisting><![CDATA[
       |        |
  eth0 |   eth1 |         eth0 = ISP1_IP on ISP1_SUBNET
----------------------    eth1 = ISP2_IP on ISP2_SUBNET
|      Director      |
----------------------
   internal |
            |
]]></programlisting>
	<para>
The default gateway is on ISP1_SUBNET/eth0, and I have source routes  
set up as follows for eth1:
	</para>
<programlisting><![CDATA[
# cat /etc/SuSE-release
SuSE Linux 9.0 (i586)
VERSION = 9.0

# uname -a
Linux lvs0 2.4.21-303-smp4G #1 SMP Tue Dec 6 12:33:10 UTC 2005 i686  
i686 i386 GNU/Linux

# ip -V
ip utility, iproute2-ss020116

# ip rule list
0:      from all lookup local
32765:  from ISP2_SUBNET lookup 136
32766:  from all lookup main
32767:  from all lookup default

# ip route show table 136
ISP2_SUBNET dev eth1  scope link  src ISP2_IP default via ISP2_GW dev eth1
]]></programlisting>
	<para>
If I perform an mtr/traceroute on the director bind()ed to the  
ISP2_IP interface, outgoing traceroutes traverse the proper ISP2_GW,  
and the same for the ISP1_IP interface.  I'm pretty sure the source- 
route behavior is correct, since I can revert from the proper  
behavior by dropping table 136.
	</para>
	<para>
For a single web service, I'm defining identical VIPs but for each of  
the ISPs:
	</para>
<programlisting><![CDATA[
  -A -t ISP1_VIP:80 -s wlc
  -a -t ISP1_VIP:80 -r 10.10.10.10:80 -m -w 1000
  -a -t ISP1_VIP:80 -r 10.10.10.11:80 -m -w 800
  -A -t ISP2_VIP:80 -s wlc
  -a -t ISP2_VIP:80 -r 10.10.10.10:80 -m -w 1000
  -a -t ISP2_VIP:80 -r 10.10.10.11:80 -m -w 800
]]></programlisting>
	<para>
Incoming packets come in via the proper gateway, but LVS always emits  
response packets through the default gateway, seemingly ignoring the  
source-route rules.  
	</para>
	<para>
I've seen Henrick's general fwmark state tracking described.  
Reading this, it seems like  
this patch isn't exactly approved or even obviously available.  And  
the article is from 2002. :)
	</para>
	<para>
I'm also not sure why this seems like such a difficult problem.  If  
LVS honored routes, there would be no complicated hacks required.   
Unless LVS overrides routes, in which case it might be nice to have a  
switch to turn off that optimization.
	</para>
	<para>
I understand that routes are a subset of the problem fixed by the  
patch, and I can see the value of the patch.  But for the basic route  
case it seems odd for LVS to just dump all outgoing packets to the  
default gw.  I mean, it could cache the routing table instead of just  
a single gw?
	</para>
	<para>
From what I can tell, the SH scheduler decides which realserver will receive an  
incoming request based on the external source IP in the request.  I  
can see four problems with this.
	</para>
	<itemizedlist>
		<listitem>
The first is that I can't see how this will change the return route  
of the packet.  I can see mapping incoming source routes to specific  
real servers with distinct gateways, but I can't see how it could  
effect an LVS-NAT setup.
		</listitem>
		<listitem>
The second is that a single client IP could go through either  
incoming VIP.  Assuming SH was somehow changing outbound routing, it  
would distribute the outbound gateway randomly vs. correctly.  I  
suppose this helps distribute traffic but I'm not really interested  
in perpetuating asymmetric routes.
		</listitem>
		<listitem>
The third is that I'd really like to use LVS as a load-balancer, not  
as a simple load splitter.  wlc is pretty key.
		</listitem>
		<listitem>
The fourth is that using sh doesn't change outbound routes, I just  
tried it. :-)
		</listitem>
	</itemizedlist>
	<para>
The docs state "Multiple gateway setups can be solved with routing  
and a solution is planned for LVS."  Which seems to imply that source  
routing is a fix but sort of not... :(
	</para>
	<para>
Scanning the NFCT patch and looking at the icmp handling, I'm pretty  
sure the problem is that ip_vs_out() is sending out the packet with a  
route calculated from the real server's IP.  Since ip_vs_out() is  
reputedly only called for masq return traffic, I think this is just  
plain incorrect behavior.
	</para>
	<para>
I pulled out the route_me_harder() mod and created the attached  
patch.  My only concern would be performance, but it seems  
netfilter's NAT uses this.
	</para>
	<para>
First, I need to correct the stated provenance of this patch.  It is  
a small tweaked subset of an antefacto patch posted to integrate  
netfilter's connection tracking into LVS, not the NFCT patches as I  
said.  Lots of Googling, not enough brain cells.  This patch applies  
to v1.0.10, but appears to be portable to 2.6.
	</para>
	<para>
During a maintenance window this morning, I had the opportunity to  
test the patch.
	</para>
	<para>
The first time I ever loaded the patched module, and shockingly it  
worked perfectly -- outbound traffic from masq VIPs now follows  
source-routes and choses the correct outbound gateway.  No side  
effects so far, no obvious increased load.
	</para>
	<para>
I also poked around the 2.6 LVS source a bit to see if this issue had  
been resolved in later versions, and noticed uses of  
ip_route_output_key, but the source address was always set to 0  
instead of something more specific.  I'd say it might be worth a  
review of the LVS code to make sure source addresses are set  
usefully, and routes are recalculated where necessary.
	</para>
	<para>
In any case, if anyone has a similar problem with VIPs spanning  
multiple external IP spaces and gateways, this has been working like  
a charm for me in significant production load.  So far.   
*knock*on*wood*  I'll update if it crashes and/or burns.
	</para>
	<para>
Joe
	</para>
	<blockquote>
 	any idea what would happen if there were multiple 
VIPs or the packets coming into the director from the 
outside world were arriving at the LVS code via a fwmark?
	</blockquote>
	<para>
To my understanding, Henrick's fwmark patch allows LVS to route traffic  
based on fwmarks set by an admin in iptables/iproute2.  I can imagine  
certain complex situations where this functionality could be useful  
and even crucial, but setup and maintenance of fwmarks requires  
specifically coded fwmark behavior in each of netfilter, iproute2,  
and ip_vs.
	</para>
	<para>
Source routes are essentially a standard feature these days, and are  
critical for proper routing on gateways and routers (which is  
essentially what a director is in Masq mode).  Having LVS properly  
observe the routing table is a "missing feature", I believe.  The  
patch I created requires no changes for an admin to make (no fwmarks  
to set up in ip_vs, netfilter, *and* iproute2), basically just  
properly and transparently observing routes set by iproute2 (which  
the rest of the director's traffic already obeys).
	</para>
	<para>
So short answer: Henrick's patch allows VIP routing based on fwmarks  
specifically created/handled by an admin for that purpose, whereas  
mine is a minor correction to existing code to properly recalculate  
the routes of outbound VS/NAT VIP traffic after mangling/masquerading  
of the source IP.  A little end-result crossover, but really quite  
different.  My (borrowed :) patch is essentially a one-liner, so the  
code complexity is very small and the behavior easily confirmable at  
a glance.  The fwmark code is more invasive, seemingly.
	</para>
	<para>
Technically, I could have used fwmarks, but until someone needs that  
specific functionality, I suspect proper source-routing covers 90% of  
the alternate use cases.  And it's the cleaner, more specific  
solution to my problem.  But that's just me. :)
	</para>
	<para>
Your summary of SH matches my understanding -- it's hash-based  
persistence calculated from the client's source IP (vs destination in  
DH).  It probably generates a good random, persistent distribution,  
which I can see being useful in a cluster environment where  
persistence is rewarded by caching/sessions/etc.  WLC with  
persistence is probably a better bet for a load-balancer config,  
since it actually balances load.  Without something like wackamole on  
the real servers, rr/sh/dh are happy to send traffic to dead servers,  
AFAICT.
	</para>
	<para>
Ken Brownfield <emphasis>krb (at) irridia (dot) com</emphasis> 22 Mar 2006
	</para>
	<para>
I'm attaching <filename>ip_vs_source_route.patch.gz</filename>, which is the patch itself.
It patches <filename>ip_vs_core.c</filename>, adding a function call at the end of  
<filename>ip_vs_out()</filename> that recalculates the route for an outgoing packet after  
mangling/masquerading has occurred.
	</para>
	<para>
<filename>ip_vs_out()</filename>, according to the comments in the source (and my brief  
perusal of the code) is "used only for VS/NAT."  There should be no  
effect on DR/TUN functionality as far as I can tell.  This type of  
route recalc might be correct behavior in some TUN or DR  
circumstances, but I have no experience in a DR/TUN setup.
So yes, I believe this patch is orthogonal to DR/TUN functionality  
and should be silent with regard to DR/TUN.
	</para>
	<para>
The only concern a user should have after applying this patch is that  
they make sure they are aware of existing source routes before using  
the patch.  Users may be unknowingly relying on the fact that LVS  
always routes traffic based on the real server's source IP instead of  
the VIP IP, and applying the patch could change the behavior of their  
system.  I suspect that will be a very rare concern.
	</para>
	<para>
As long as the source routes on the system are correct, where the  
source IP == the VIP IP, packets from LVS will be routed as the  
system itself routes packets.  Routes confirmed with a traceroute  
(bound to a specific IP on the director) will no longer be ignored  
for traffic outbound from a NAT VIP.
	</para>
	<para>
Joe: next Farid Sarwari stepped in
	</para>
	<para id="sarwari" xreflabel="IPSec">
Farid Sarwari <emphasis>fsarwari (at) exchangesolutions (dot) com</emphasis> 25 Jul 2006 
	</para>
	<para>
I'm having some issues with IPVS and IPSec. When a HTTP client requests
a page, I can see the traffic come all the way to the webserver
(ws1,ws2). However, the return traffic gets to the load balancer but
does not make it through the ipsec tunnel. When doing a tcpdump I can
see that the packets get SNATed by ipvs. I know there is a problem with
ipsec2.6 and SNAT, and I've upgraded my kernel and iptables so now SNAT
with iptables works. But it looks like ipvs is doing its own SNAT which
doesn't pass through the ipsec tunnel.  
	</para>
<programlisting><![CDATA[
My setup:


                      HTTP Clients
                       -------
                         |
                          \ -- Ipsec tunnel
                          /
                         |            
                  +------------+
                  |LoadBalancer|
                  |  ipsec2.6  |  
                  |   ipvs     |
                  +------------+
                         |
                        /\
                       /  \
                      /    \
                 +-----+  +-----+
                 | ws1 |  | ws2 |
                 +-----+  +-----+


Ldirector.conf:
virtual=x.x.x.x:80 #<public ip>
        real=y.y.y.1:80 masq
        real=y.y.y.2:80 masq
        checktype=negotiate
        fallback=127.0.0.1:80 masq
        service=http
        request="/"
        receive=" "
        scheduler=wlc
        protocol=tcp

------------------

ipvsadm -ln output:
P Virtual Server version 1.2.1 (size=4096)
Prot LocalAddress:Port Scheduler Flags
  -> RemoteAddress:Port           Forward Weight ActiveConn InActConn
TCP  x.x.x.x:80 wlc
  -> y.y.y.1:80            Masq    1      0          0
  -> y.y.y.1:80            Masq    1      0          0

------------------

Software Version #s:
ipvsadm v1.24 2003/06/07 (compiled with popt and IPVS v1.2.0)
Linux Kernel 2.6.16
iptables v1.3.5
ldirectord  version 1.131
]]></programlisting>

	<para>
The Brownfield patch is for an older version of ipvs. When I was applying the
patch, Hunk#3 failed. I was able to apply the third hunk manually. When
I compile it give errors for the code from the first hunk of the patch.
	</para>
	<para>
Finally got it to work! I can access load balanced pages through ipsec.
Ken Brownfield's patch seemed to have been for an older version of
kernel/ipvs. 
If you look in the patch, there is function called ip_vs_route_me_harder
with is an exact copy of ip_route_me_harder from netfilter.c. 
I'm not sure what version of ipvs/kernel Brownfield's patch is for. I
couldn't get ipvs to compile with his patch, so I just used his idea and
copied the new code from the netfilter source code.
I've modified his patch by copying new the ip_route_me_harder function
from net/ipv4/netfiter.c (2.6.16).
Below is the patch for kernel 2.6.16 (kernel sources from FC4)
	</para>
<programlisting><![CDATA[
IPVS Version:     $Id: ip_vs_core.c,v 1.34 2003/05/10 03:05:23 wensong
Exp



------snip--------
--- ip_vs_core.c.orig   2006-03-20 00:53:29.000000000 -0500
+++ ip_vs_core.c        2006-07-27 14:31:14.000000000 -0400
@@ -43,6 +43,7 @@

 #include <net/ip_vs.h>

+#include <net/xfrm.h>

 EXPORT_SYMBOL(register_ip_vs_scheduler);
 EXPORT_SYMBOL(unregister_ip_vs_scheduler);
@@ -516,6 +517,76 @@
        return NF_DROP;
 }

+/* This code stolen from net/ipv4/netfilter.c */
+
+int ip_vs_route_me_harder(struct sk_buff **pskb)
+{
+        struct iphdr *iph = (*pskb)->nh.iph;
+        struct rtable *rt;
+        struct flowi fl = {};
+        struct dst_entry *odst;
+        unsigned int hh_len;
+
+        /* some non-standard hacks like ipt_REJECT.c:send_reset() can
cause
+         * packets with foreign saddr to appear on the NF_IP_LOCAL_OUT
hook.
+         */
+        if (inet_addr_type(iph->saddr) == RTN_LOCAL) {
+                fl.nl_u.ip4_u.daddr = iph->daddr;
+                fl.nl_u.ip4_u.saddr = iph->saddr;
+                fl.nl_u.ip4_u.tos = RT_TOS(iph->tos);
+                fl.oif = (*pskb)->sk ? (*pskb)->sk->sk_bound_dev_if :
0;
+#ifdef CONFIG_IP_ROUTE_FWMARK
+                fl.nl_u.ip4_u.fwmark = (*pskb)->nfmark;
+#endif
+                if (ip_route_output_key(&rt, &fl) != 0)
+                        return -1;
+
+                /* Drop old route. */
+                dst_release((*pskb)->dst);
+                (*pskb)->dst = &rt->u.dst;
+        } else {
+                /* non-local src, find valid iif to satisfy
+                 * rp-filter when calling ip_route_input. */
+                fl.nl_u.ip4_u.daddr = iph->saddr;
+                if (ip_route_output_key(&rt, &fl) != 0)
+                        return -1;
+
+                odst = (*pskb)->dst;
+                if (ip_route_input(*pskb, iph->daddr, iph->saddr,
+                                   RT_TOS(iph->tos), rt->u.dst.dev) !=
0) {
+                        dst_release(&rt->u.dst);
+                        return -1;
+                }
+                dst_release(&rt->u.dst);
+                dst_release(odst);
+        }
+
+        if ((*pskb)->dst->error)
+                return -1;
+
+#ifdef CONFIG_XFRM
+        if (!(IPCB(*pskb)->flags & IPSKB_XFRM_TRANSFORMED) &&
+            xfrm_decode_session(*pskb, &fl, AF_INET) == 0)
+                if (xfrm_lookup(&(*pskb)->dst, &fl, (*pskb)->sk, 0))
+                        return -1;
+#endif
+
+        /* Change in oif may mean change in hh_len. */
+        hh_len = (*pskb)->dst->dev->hard_header_len;
+        if (skb_headroom(*pskb) < hh_len) {
+                struct sk_buff *nskb;
+
+                nskb = skb_realloc_headroom(*pskb, hh_len);
+                if (!nskb)
+                        return -1;
+                if ((*pskb)->sk)
+                        skb_set_owner_w(nskb, (*pskb)->sk);
+                kfree_skb(*pskb);
+                *pskb = nskb;
+        }
+
+        return 0;
+}

 /*
  *      It is hooked before NF_IP_PRI_NAT_SRC at the NF_IP_POST_ROUTING
@@ -734,6 +805,7 @@
        struct ip_vs_protocol *pp;
        struct ip_vs_conn *cp;
        int ihl;
+       int retval;

        EnterFunction(11);

@@ -821,8 +893,20 @@

        skb->ipvs_property = 1;

-       LeaveFunction(11);
-       return NF_ACCEPT;
+       /* For policy routing, packets originating from this
+        * machine itself may be routed differently to packets
+        * passing through.  We want this packet to be routed as
+        * if it came from this machine itself.  So re-compute
+        * the routing information.
+        */
+       if (ip_vs_route_me_harder(pskb) == 0)
+               retval = NF_ACCEPT;
+       else
+               /* No route available; what can we do? */
+               retval = NF_DROP;
+
+       LeaveFunction(11);
+       return retval;

   drop:
        ip_vs_conn_put(cp);
------snip--------
]]></programlisting>

	<para>
Joe
	</para>
	<blockquote>
Can you do IPSec with LVS-DR? (the director would only decrypt and the
realservers encrypt)
	</blockquote>
	<para>
I haven't tried it, but I don't see why it shouldn't work. It's probably
easier to get work than LVS-NAT with IPSec :)
You can think of Ipsec as just another interface except that with kernel
2.6 there is more ipsec0 interface. So as long as routing is setup
correctly LVS-DR should work with IPSec.
	</para>
	<blockquote>
so you have an ipsec0 interface and you can put an IP on it and route
to/from it just like with eth0? Can you use iproute2 tools on ipsec0?
	</blockquote>
	<para>
With Kernel 2.6 there is no more ipsec0 interface, but you can use
iproute2 to alter the routing table. You wouldn't want to modify the
routes to the tunnel because ipsec takes care of that, but you can
modify routes for traffic that is coming through the tunnel destined for
LVS-DR.
	</para>
	<para>
Ken Brownfield <emphasis>krb (at) irridia (dot) com</emphasis> 28 Jul 2006 
	</para>
	<para>
At first glance, that's exactly what had to be ported, and I'm glad someone
with enough 2.6 fu did it.
Now, if someone could have it conditional on a proc/sysctl, it would seem
like more of a no-brainer for inclusion. ;)
	</para>
	<para>
Joe: next David Black stepped in
	</para>
	<para>
David Black <emphasis>dave (at) jamsoft (dot) com</emphasis> 28 Jul 2006
	</para>
	<para>
I applied the following patch to a stock 2.6.17.7 kernel, and enabled
the source routing hook via /proc/sys/net/ipv4/vs/snat_reroute:
http://www.ssi.bg/~ja/nfct/ipvs-nfct-2.6.16-1.diff
LVS-NAT connections now appear to obey policy routing - yay!
	</para>
	<para>
Referring to an older version of the NFCT patch, Ken Brownfield says in
the LVS HOWTO: "I pulled out the route_me_harder() mod and created the
attached patch."  So the Brownfield patch is a derivative of the NFCT
patch in the first place.
	</para>
	<para>
And here's a comment from the NFCT patch I used:
	</para>
<programlisting><![CDATA[
/* For policy routing, packets originating from this
 * machine itself may be routed differently to packets
 * passing through.  We want this packet to be routed as
 * if it came from this machine itself.  So re-compute
 * the routing information.
]]></programlisting>
	<para>
For a patched kernel, that functionality is enabled by
	</para>
<programlisting><![CDATA[
echo 1 > /proc/sys/net/ipv4/vs/snat_reroute
]]></programlisting>
	<para>
Farid Sarwari <emphasis>fsarwari (at) exchangesolutions (dot) com</emphasis> 31 Jul 2006 
	</para>
	<para>
The problem I was having with ipvs was that I couldn't access it through
ipsec kernel 2.6. I remember accessing ipvs through ipsec 2.4 a few
years ago and I don't remember running into this problem.
Correct me if I'm wrong, prior to kernel 2.6.16 SNAT (netfilter) didn't
work properly with ipsec. When troubleshooting my problem it looked like
the natting was happening after the routing decision had been made. This
is why I was under the assumption that only code from kernel 2.6.16+
would fix my problem. 
If the NFCT patch works with ipsec, I would much rather us that.
	</para>
	<para>
Joe
	</para>
	<blockquote>
If Julian's patch had been part of the kernel ipvs code,
would anyone have had source routing/iproute2 problems with LVS-NAT?
	</blockquote>
	<para>
Ken 9 Aug 2006
	</para>
	<para>
I don't believe so -- the source-routing behavior appears to be a (happy)
side-effect of working NFCT functionality.  I think the NFCT and
source-routing patches' intentions are to supply a feature and a bug-fix,
respectively, but NFCT is an "accidental" superset.
	</para>
	</section>
	<section id="lvs_nat_ftp">
	<title>LVS-NAT FTP Recipe</title>
	<para>
Stephen Milton <emphasis>smmilton (at) gmail (dot) com</emphasis> 12/17/05
	</para>
	<para>
This may be old hat to many of you on this list, but I had a lot of 
problems deciphering all the issues around FTP in load balanced NAT.  So I 
wrote up the howto on how I got my configuration to work.  I was 
specifically trying to setup for high availability, load balanced, FTP and 
HTTP with failover and firewalling on the load balancer nodes.  Here is a 
permanent link to the article: 
<ulink url="http://sacrifunk.milton.com/b2evolution/blogs/index.php/2005/12/17/load_balanced_ftp_server">
load_balanced_ftp_server</ulink>
(http://sacrifunk.milton.com/b2evolution/blogs/index.php/2005/12/17/load_balanced_ftp_server)
	</para>
	</section>
	<section id="lvs_nat_vhosts">
	<title>LVS-NAT vhosts with apache</title>
	<para>Michael Green <emphasis>mishagreen (at) gmail (dot) com</emphasis>
	</para>
	<blockquote>
Is it possible to make Apache's IP based vhosts work under LVS-NAT?
	</blockquote>
	<para>
Graeme Fowler <emphasis>graeme (at) graemef (dot) net</emphasis>
14 Dec 2005
	</para>
	<para>
If, by that, you mean Apache vhosts whereby a single vhost lives on a 
single IP then the answer is definitely "yes", although it may seem 
counter-intuitive at first.
	</para>
	<para>
If you're using IP based virtual hosting, you have a single IP address 
for *each and every* virtual host. In the 'classic' sense this means 
your server has one, two, a hundred, a thousand IP addresses configured 
(as aliases) on its' interface which faces the internet and a different 
vhost listens to each interface.
	</para>
	<para>
In the clearest case of LVS-NAT, you'd have your public interface on 
the director handle the one, two, a hundred, a thousand _public_ IP 
addresses and present those to the internet (or your clients, be those 
as they are).
Assuming you have N realservers, you then require N*(one, two, a 
hundred, a thousand) private IP addresses and you configure up (one, 
two, a hundred, a thousand) aliases per virtual server. You then setup 
LVS-NAT to take each specific public IP and NAT it inbound to N private 
IPs on the realservers.
	</para>
	<para>
Still with me? Good.
	</para>
	<para>
This is a network management nightmare. Imagine you had 256 Virtual 
IPs, each with 32 servers in a pool. You immediately need to manage an 
entire /19 worth of space behind your director. That's a lot of address 
space (8192 addresses to be precise) for you to be keeping up with, and 
it's a *lot* of entries in your ipvsadm table.
	</para>
	<para>
There is, however, a trick you can use to massively simplify your addressing:
	</para>
	<para>
Put all your IP based vhosts on the same IP but a *different port* on 
each realserver. Suddenly you go from 8192 realserver address (aliases) 
to, well, 32 address (aliases) with 256 ports in use on each one. Much 
easier to manage.
	</para>
	<para>
For even more trickery you could probably make use of some of 
keepalived's config tricks to "pool" your realservers and make your 
configuration even more simple, but if you only have a small 
environment you may want to get used to using ipvsadm by hand first 
until you're happy with it.
	</para>
	</section>
	<section id="LVS-NAT_timeout_problem">
	<title>LVS-NAT timeout problem</title>
	<para>
Joe: here's a posting that hasn't been solved. It occured with LVS-NAT,
but we don't know if it occurs with the other forwarding methods.
	</para>
	<para>
Dmitri Skachkov <emphasis>dmitri (at) nominet (dot) org (dot) uk</emphasis> 21 Feb 2007
	</para>
	<para>
I should probably say in the beginning that the issue I'm going to describe
is not directly related to the problem discussed on this list
a while ago (http syn/ack not translated when ftp loadbalancing also enabled).
We have several LVS/NAT installations which are managed by Keepalived.
All of them are pretty much identical and exhibit the same issue.
The setup is looking like this (a backup load balancer and a backup
router are omitted) and is LVS/NAT standard:
	</para>
<programlisting><![CDATA[

        !-----------------!
        !                 !
        !     Internet    !
        !                 !
        !-----------------!
                 !
                 !
        !-----------------!
        !                 !
        !     Router      !
        !                 !
        !-----------------!
                 !
                 !
        !-----------------!
        !      eth0       !
        !                 !
        !  LoadBalancer   !
        !                 !
        !      eth1       !
        !-----------------!
                 !
                 !192.168.1.0/24
    ------------------------
    !       !       !      !
  !---!                  !---!
  !RS1!     .........    !RSN!
  !---!                  !---!
]]></programlisting>
	<para>
This setup is working fine most of the time except when a client sends a TCP SYN
packet and then forgets about this connection. In this case a RealServer starts to
send SYN/ACK packets until this connection on the server times out and it sends RST/ACK.
The issue is that two last packets don't get translated because ipvs on the
LoadBalancer already timed out this connection. Below is a tcpdump on LoadBalancer/eth0:
	</para>

<programlisting><![CDATA[
10:58:20.655059 IP 213.248.204.8.2113 > 213.248.224.116.43: S 1402601529:1402601529(0) win 512
10:58:20.655335 IP 213.248.224.116.43 > 213.248.204.8.2113: S 443218720:443218720(0) ack 1402601530 win 49312 <mss 1460>
10:58:24.031708 IP 213.248.224.116.43 > 213.248.204.8.2113: S 443218720:443218720(0) ack 1402601530 win 49312 <mss 1460>
10:58:30.792336 IP 213.248.224.116.43 > 213.248.204.8.2113: S 443218720:443218720(0) ack 1402601530 win 49312 <mss 1460>
10:58:44.303557 IP 213.248.224.116.43 > 213.248.204.8.2113: S 443218720:443218720(0) ack 1402601530 win 49312 <mss 1460>
10:59:11.316010 IP 213.248.224.116.43 > 213.248.204.8.2113: S 443218720:443218720(0) ack 1402601530 win 49312 <mss 1460>
11:00:05.330972 IP 213.248.224.116.43 > 213.248.204.8.2113: S 443218720:443218720(0) ack 1402601530 win 49312 <mss 1460>
11:01:05.346329 IP 192.168.1.32.43 > 213.248.204.8.2113: S 443218720:443218720(0) ack 1402601530 win 49312 <mss 1460>
11:02:05.362233 IP 192.168.1.32.43 > 213.248.204.8.2113: R 1:1(0) ack 1 win 49312
]]></programlisting>
	<para>
In this example I simulated the situation with sending SYN packet from my PC
to the server and dropping all further packets.
While the SYN/ACK packets were still being translated
	</para>
<programlisting><![CDATA[
director# ipvsadm -lnc
TCP 28:12  NONE        213.248.204.8:0    213.248.224.116:43 192.168.1.32:43
TCP 00:57  SYN_RECV    213.248.204.8:2113 213.248.224.116:43 192.168.1.32:43
]]></programlisting>
	<para>
But once I see only this:
	</para>
<programlisting><![CDATA[
TCP 27:02  NONE        213.248.204.8:0    213.248.224.116:43 192.168.1.32:43
]]></programlisting>
	<para>
Yes, I played with 'ipvsadm --set tcp tcpfin udp' and it doesn't
have any effect on this issue.
	</para>
	<para>
packets from RealServer belonging to this connection (from RealServer 
point of view) stop getting translated.

This is not a real problem but rather a nuisance for me. I just don't want 
packets with private IP's leaving LoadBalancer. 
I can't block this packets with iptables since I believe ipvs does SNATing
somewhere in POSTROUTING chain and there is no way to put any other rules beyond this chain.
I also can't modify SYN_RECV timeout since there is no tcp_timeout_syn_recv entry
in <filename>/proc/sys/net/ipv4/vs/</filename> (this is a stock CentOS 4.3 kernel).
My question is: Is it possible to block not translated packets from 
leaving the LoadBalancer without touching RealServers and the Router?
	</para>
	<para>
If it can help, here is additional info:
	</para>
<programlisting><![CDATA[
# uname -a
Linux lb1 2.6.9-34.ELsmp #1 SMP Thu Mar 9 06:23:23 GMT 2006 x86_64 x86_64 x86_64 GNU/Linux
# ipvsadm --help
ipvsadm v1.24 2003/06/07 (compiled with getopt_long and IPVS v1.2.0)
]]></programlisting>
	<para>
later...
	</para>
	<para>
Graeme Fowler <emphasis>graeme (at) graemef (dot) net</emphasis> 25 Jun 2007
	</para>
	<para>
One of my "standard" (I use the term advisedly) configuration settings
for LVS-NAT is to ensure that I have an SNAT rule for packets exiting
the director towards clients.
I make sure that if I have RS1 with VIP 1.2.3.4 and two realservers
192.0.0.1 and 192.0.0.2 that I have rules of the form:
	</para>
<programlisting><![CDATA[
-t nat -A POSTROUTING -o eth0 -s 192.0.0.1 -j SNAT --to-source $VIP
-t nat -A POSTROUTING -o eth0 -s 192.0.0.2 -j SNAT --to-source $VIP 
]]></programlisting>
	<para>
This means any packets escaping the LVS - for example where the LVS
connection entry has timed out, but the realserver application session
hasn't, will be SNATted to the right IP.
	</para>
	<para>
It also means that any sessions originating from the realserver - CGI
calls to other websites, PHP database connections to offboard servers,
SSI includes, RSS inclusion, whatever - appear to come from the right
source. It can help to track down abuse in the case of mass virtual
hosting, and it prevents information leakage of the form you're seeing.
	</para>
	<para>
Longer term, it looks like you need to make sure that the IP stack
timeouts on the realservers match the LVS connection table timeouts on
the director. Have a look at the "--set" option to ipvsadm, and check
the corresponding sysctls in <filename>/proc/sys/net/ipv4/</filename> - you may have to do a
bit of deduction regarding backoff algorithms and retries to get the total
time for (for example) a TCP three-way handshake timeout, like you're
seeing.
	</para>
	<para>
<emphasis>dmitri (at) nominet (dot) org (dot) uk</emphasis> 25 Jun 2007
	</para>
	<para>
If I remember correctly, the POSTROUTING solution didn't work for me as it seemed
LVS stuff in kernel just ignored any postrouting tables for any ip packets under LVS control. 
Neither <command>ipvsadm --set</command> had any effect on this issue. 
Sorry for a short explanation but this is what I remember of top of my head and since in all other 
respects LVS is just working fine for us and so I have not looked often into it lately.
	</para>
	</section>
</section>
<section id="LVS-HOWTO.arp_problem" xreflabel="The Arp Problem">
<title>LVS: The ARP Problem</title>
	<section id="the_problem">
	<title>The problem</title>
	<para>
If you follow the instructions and setup the examples
in the <link linkend="mini-HOWTO">LVS-mini-HOWTO</link>,
then you don't need to know about the arp problem.
If you're going to setup grander LVS's, 
then you'll need to understand the arp problem.
	</para>
	<para>
Although this section comes early in the HOWTO, it has lots of pitfalls.
You shouldn't be reading this unless you've at least setup a working
LVS-NAT and LVS-DR LVS using the canned instructions in the
<link linkend="mini-HOWTO">LVS-mini-HOWTO</link>.
	</para>
	<para>
The LVS allows several machines to function as one machine.
For LVS-DR and LVS-Tun, some trickery
was needed to split the various handshakes 
involved in establishing and maintaining a tcpip connection,
so that some parts of the handshake come from one
machine and other parts from another machine.
The worst problem, which ironically only
happens with realservers running Linux (2.2 and later kernels),
is the "arp problem".
It's just as well we have the source code :-(.
	</para>
	<para>
With LVS-DR and LVS-Tun, all the machines (director, realservers)
in the LVS have an extra IP, the VIP. Here's a LVS-DR in a test setup where
all machines and IPs are on the same physical network
(<emphasis>i.e.</emphasis> are using the same link layer
and can hear each other's broadcasts).
	</para>
<programlisting><![CDATA[

                      ________
                     |        |
                     | client |
                     |________|
 	                 |
                         |
                      (router)
                         |
                         |
                         |       __________
                         |  DIP |          |
                         |------| director |
                         |  VIP |__________|
                         |
                         |
                         |
       ------------------------------------
       |                 |                |
       |                 |                |
   RIP1, VIP         RIP2, VIP        RIP3, VIP
 ______________    ______________    ______________
|              |  |              |  |              |
| realserver1  |  | realserver2  |  | realserver3  |
|______________|  |______________|  |______________|


]]></programlisting>
	<para>
When the client requests a connection to the VIP, it must connect
to the VIP on the director and not to the VIP on the realservers.
	</para>
	<para>
The director acts as a layer-4 IP router,
accepting packets destined for the VIP and then sending them on to a realserver
(where the real work is done and a reply is generated).
For the LVS to function, when the client (or if present, the router)
puts out the arp request "who has VIP, tell client",
the client/router must receive the MAC address
of the director (and not the MAC address of one of the realservers).
After receiving the arp reply,
the client will send the connect request to the director.
(The director will update its <command>ipvsadm</command> tables
to keep track of the connections that it's in charge of and
then forward the connect request packet to the chosen realserver).
	</para>
	<para>
If instead, the client gets the MAC address of one of the realservers,
then the packets will be sent directly to that realserver,
bypassing the LVS action of the director.
If nothing is done to direct arp requests, by the router for the VIP,
to the director (<xref linkend="arp_bouncing"/>), then in some setups,
one particular realserver's MAC address will be in the client/router's
arp table for the VIP and the client will only see one realserver.
If the client's packets are consistently sent to the same realserver,
then the client will have a normal session connected to that realserver.
You can't count on this happening: in the middle of a tcpip sesssion,
the client/router might get the MAC address of another realserver
as a result of an arp request, and the client will start getting
packets for connections it knows nothing about
(and the realserver will send tcp resets).
(In my setup, the machine with the fastest CPU is
in the client's arp table, suggesting that it's the first machine to reply
that gets in. Horms and Steven WIlliams have written that they think
it's the last machine to reply whose entry in in the client's arp table.)
In other setups where the realservers are identical,
the client will connect to different realservers each time the
arp cache times out (see comment by Steven WIlliams elsewhere).
If the director always gets its MAC address in the router arp table,
then the LVS will work without any changes to the realservers
(as happened in my case with a director with the fastest CPU in the LVS),
although this is not a reliable solution for production.
	</para>
	<para>
Getting the MAC address of the VIP on the director
(instead of the MAC address of the VIP on the realservers) to the
client when the client/router does an arp request
is the key to solving the "arp problem".
	</para>
	<para>
The traditional ways of handling the arp problem (as explained here)
all require fiddling with the settings of the VIP on the realservers.
The assumption in the early days of LVS was that you wouldn't
have access to the router (this being under the control
of the IT department or your ISP and you would have to go through
a lot of bureaucracy to changed the settings on the router).
However if you're paying good money to an ISP to house your
LVS, or your inhouse LVS is doing something useful for your
establishment, then you should have no trouble in having the
router setup the way you want.
	</para>
	<para>
If you have access to the router (or can put one in front of your
LVS - a low power linux box is just fine) and you can set it
to route packets for the VIP only to the director(s) and not
to the realservers, or you can use the arp filtering tools
of <filename>iptables</filename>, and you understand what's been said above,
then you've handled the arp problem and need read no futher.
	</para>
	<para>
For those who don't have access to the router, or who want
to setup an LVS on one network, then read on...
	</para>
	<para>
The arp problem is handled in Linux 2.0.x kernels,
as dummy0, tunl0, lo:0,  are available on the realserver 
which don't reply to arp requests.
For other OS's, the NOARP flag for ifconfig stops the VIP
on the realservers from replying to arp requests.
	</para><para>
However with 2.2.x (and later) kernels,
the devices which didn't reply to arp requests in 2.0.x,
now reply to arp requests.
There is a "-arp" (NOARP) option for ifconfig which (according
to the man pages) turns off replies to arp requests for that
device, and an "arp" option which turns them back on again.
Linux does not always honour this flag. You couldn't turn on replies
to arp requests for the dummy0 devices in 2.0.36 kernels and
you can't turn it off for tunl0 in 2.2.x kernels. eth0 behaves
properly in 2.0.36 but in 2.2.x kernels it arps even when you
tell it not to arp. This behaviour of not honouring the NOARP
flag in the Linux 2.2.x kernels
<link linkend="first_inklings">is not regarded as a &quot;problem&quot;</link>
by those writing the Linux TCPIP code and is not going to be &quot;fixed&quot;.
	</para>
	<para>
Julian 22 May 2001
	</para>
	<blockquote>
		<para>
The flag is used to allow arp requests for the specified device.
Although "lo" doesn't reply to arp requests, the requests for the
VIP go through eth*, and so the NOARP flag is of no help to us.
We can't drop the flag for eth.
		</para>
	</blockquote>
	<para id="julian_alias">
Another wrinkle is that in 2.0.36 kernels, aliased devices
(eg eth0:1) could be setup independantly of the options on
the primary (eth0) device. Thus eth0:1 behaved as if it were
on a separate NIC and its arp'ing behaviour could be set
independantly of the primary interface. The settings of
an aliased device belonged to the IP. With the 2.2.x
kernels, the aliased devices are now just alternate names for each
other: you change an option (eg -arp) or up/down of one
alias (or primary) the other aliases follow. With 2.2.x
kernels, the settings of the aliased device belong to the
primary device (there is only one device with several
IPs).
	</para>
	<para>
When LVS was running on 2.0.36 machines, the VIP was usually
configured as an alias (eg lo:0, tunl0) on the main ethernet
device (eth0), allowing the nodes in an LVS to have only one
NIC.
	</para>
	<para>
With 2.2.x kernels,
care is needed when only one NIC is used
on the realserver (the usual case).
On a realserver with eth0 carrying the RIP,
and the realserver having only one NIC, eth0 must reply to
arp requests (to receive packets), then eth0:1 carrying the
VIP will reply to arp requests too, even if you ifconfig it
with -noarp. Thus if a realserver is running a 2.2.x kernel
and has the VIP on an ip_alias, then the VIP on the realserver
will reply to arp requests received from the router.
	</para>
	<para>
The use of ip_aliases is still allowed,
but requires a "label" to be recognised by
the new <xref linkend="LVS-HOWTO.policy_routing"/>
tools (iproute2 and ip_tables).
The "label"ed IPs are now secondary IPs.
	</para>
	<para>
For 2.2.x kernels and beyond the commands <command>ifconfig</command>
and <command>route</command> should only be used with single NIC leaf nodes. 
You can still use them to set up a simple LVS,
but for anything more complicated you will need to start using 
the iproute2 commands.
	</para>
	</section>
	<section id="vip_lo">
	<title>Put the VIP on the realservers lo device</title>
	<para>
In the early days (2.0.x, 2.2.x) I seemed to be able to put
the VIP on any device I liked. I don't know whether this
is still possible with the newer kernels, but people
have not been able to get their LVSes to work unless with
arp_filter and arp_ignore unless they put the VIP on the
realserver's lo device. 
	</para>
	</section>
	<section id="the_cure">
	<title>The Cure(s)</title>
	<para>
Several cures have been produced in an attempt to solve the arp problem. They involve either
	</para>
	<itemizedlist>
		<listitem>
stopping the realservers from replying to arp requests for
the VIP.
		</listitem>
		<listitem>
hiding the VIP on the realservers so that they don't see
the arp requests.
		</listitem>
		<listitem>
priming the client/router in front of the director with the
correct MAC address for the VIP.
		</listitem>
		<listitem>
allowing the realserver to accept a packet with dst=VIP even
though the realserver does not have a device with this IP
(<emphasis>i.e.</emphasis> the host has nothing to reply to an arp request).
This is implemented by 
<xref linkend="LVS-HOWTO.transparent_proxy"/> or 
<xref linkend="LVS-HOWTO.fwmark"/>fwmark.
For transparent proxy on the realserver, the director forwards
the packets to the realserver's MAC address, 
so you don't need to route the packets yourself.
For fwmark, you need to understand 
<xref linkend="LVS-HOWTO.routing_to_VIP-less_director"/>.
There may be performance problems with transparent proxy 
<xref linkend="TP_performance"/> at high packet rates.
Noone has tested <xref linkend="2_6_arp_announce"/> 
against transparent proxy at high throughput.
		</listitem>
		<listitem>
stopping arp requests for the VIP getting to the realservers.
		</listitem>
	</itemizedlist>
	<para>
Note: For the 2.2 and 2.4 kernels, 
most of these cures involve applying a kernel patch to the realserver.
The realserver patch is unrelated to the ipvs patch applied to the director.
	</para>
	<para>
horms 4 Aug 2005
	</para>
	<para>
For the record, the ARP problem is not about honoring the 
<filename>-arp</filename> flag or not.
The problem lies in whether or not the OS regards the IP address
as belonging to the interface, or as belonging to the host.
Both are valid. 
Linux adopts the latter, which turns out to work really well in most situations. 
LVS is a rare case where it doesn't. 
This has been painful in the past, 
but since <filename>arp_ignore</filename> and <filename>arp_announce</filename> were added, 
its quite easy now.
	</para>
	<para>
The following list of cures is a little confusing. 
If you're not using routing to stop packets for the VIP arriving at the realservers,
then you'll have to stop the realservers replying to arp requests for the VIP.
In this case you'll do one of the following on the realservers
(Mar 2005, with help from Horms)
	</para>
	<itemizedlist>
		<listitem>
			<para>
the original method: 
use Julian's <filename>hidden</filename> patch on the realserver. 
You set the VIP on lo and then "hide" it. 
This method has been around since the arp problem first arose
and has been well tested.
For more on the <link linkend="hidden">hidden patch</link> see <ulink url="http://www.ssi.bg/~ja/hidden.txt">julian's page</ulink>.
This code is still being maintained, so if your setup scripts
are for the hidden patch, you can continue to use it. 
Otherwise for new installations, you should use the arp_announce.
			</para>
		</listitem>
		<listitem>
			<para>
the next method: Maurizio's <link linkend="sartori">noarp module</link>. 
This has the advantage that it does not require any patching of the realserver's kernel, 
is simple to setup and is the preferred method for many people. 
It has another advantage that you control the arp behaviour for the IP 
and not for the device.
			</para>
		</listitem>
		<listitem>
			<para>
the new way <link linkend="2_4_arp_announce">arp_announce</link>: see
<ulink url="http://www.ssi.bg/~ja/#arp_announce">arp_announce</ulink>
(http://www.ssi.bg/~ja/#arp_announce) 
which sets <filename>arp_ignore</filename> and <filename>arp_announce</filename> 
on the arping interfaces.
This typically means eth0, but if you have eth1 as well, you need to set it there too.
(If you have multiple NICs; eth0..ethn, you only need fix the NIC that hears the arp requests.)
Setting these parameters on <filename>lo</filename> 
has no effect as far as I understand from testing, 
reading the code and reading correspondance from Jullian,
<emphasis>i.e.</emphasis> you <emphasis role="bold">aren't</emphasis> 
interested in these settings. 
			</para>
			<note>
Make sure you don't bring up the ethernet device (say at bootup) 
before arp_ignore/arp_announce have been setup, 
or you will get a round of arp broadcasts from the NIC.
			</note>
<programlisting><![CDATA[
# ipvs settings for realservers:
net.ipv4.conf.lo.arp_ignore = 1
net.ipv4.conf.lo.arp_announce = 2
]]></programlisting>
			<para>
Horms
			</para>
			<para>
If the VIP is on eth0, and you don't want it advertised over ARP on
eth1, then set:
			</para>
<programlisting><![CDATA[
net.ipv4.conf.eth1.arp_ignore = 1
net.ipv4.conf.eth1.arp_announce = 2
]]></programlisting>
			<para>
This is different to the hidden approach where you put the VIP on lo 
and then hide lo.
			</para>
			<para>
The <filename>arp_ignore</filename> approach has 
<link linkend="ratz_arp_announce">theoretical and aesthetic advantages</link>.
			</para>
		</listitem>
	</itemizedlist>
	</section>
	<section id="2.0_arp">
	<title>The Cure: 2.0 kernels - nothing needed</title>
	<para>
	There is no arp problem with 2.0 kernels on the realservers.
On the realservers, configure the VIP on the lo device
with the <command>-noarp</command> option as you would with any other Unix.
	</para>
	</section>
	<section id="2.2_arp">
	<title>The Cure: 2.2.x kernels - many options</title>
	<para>
The preferred method is "hidden"
	</para>
		<section id="hidden" xreflabel="hidden">
		<title>The hidden patches</title>
		<para>
The &quot;hidden&quot; patches for kernel &gt;=2.2.14
are now in the standard linux distribution
(<emphasis>i.e.</emphasis> you can use the &quot;hidden&quot;
feature with a standard kernel and
don't have to patch the kernel on the realserver).
The arp patches allow you to hide a device from arp requests,
allowing the realserver to function in an LVS.
		</para>
		<note>
The hidden patch hides the device (here the lo) (and any IPs that are on it).
The <command>-noarp</command> flag in 2.0 kernels
affects only the ip_alias (and not other IPs on the same device).
These are different methods, but both stop the
router/client from getting arp replies from the realserver
for the VIP.
		</note>
		<para>
To hide devices from arp calls, on the realservers do
		</para>
<programlisting><![CDATA[
       #to activate the hidden feature
       echo 1 > /proc/sys/net/ipv4/conf/all/hidden
       #to make lo:0 not arp, put lo here
       echo 1 > /proc/sys/net/ipv4/conf/<interface_name>/hidden
]]></programlisting>
		<para>
then test that you've hidden the VIP (<xref linkend="testing_for_arp"/>).
		</para>
		<para>
There is a possible race condition in hiding the VIP -
		</para>
		<para>
Kyle Sparger, 15 Feb 2001
		</para>
		<blockquote>
			<para>
I've found an interesting, but not totally unexpected race condition
under DR in 2.2.x that I've managed to create when installing VIP's on a
machine in DR mode.
Basically, the cause is this:
			</para>
<programlisting><![CDATA[
ifconfig dummy0 10.0.1.15
echo 1 > /proc/sys/net/ipv4/conf/dummy0/hidden
]]></programlisting>
			<para>
You'll notice that there's going to be a small gap between the two which
allows an ARP request to come in, and for the server to reply.  And yes,
it is big enough to be bitten by -- I've been bitten twice by it so far :)
			</para>
		</blockquote>
		<para>
Julian
		</para>
		<para>
On boot:
		</para>
<programlisting><![CDATA[
echo 1 > /proc/sys/net/ipv4/conf/all/hidden
# For each hidden interface (dummy, lo, tunl):
modprobe dummy0
ifconfig dummy0 0.0.0.0 up
echo 1 > /proc/sys/net/ipv4/conf/dummy0/hidden
# Now set any other IP address
]]></programlisting>

		<para>
Kyle's suggestion
		</para>
		<blockquote>
<programlisting><![CDATA[
echo 1 > /proc/sys/net/ipv4/conf/default/hidden
ifconfig dummy0 10.0.1.15
echo 0 > /proc/sys/net/ipv4/conf/default/hidden
]]></programlisting>
		<para>
The echo 0 command is incase I want to configure other
interfaces later that I _do_ want responding to ARP requests.
Technically, it's not necessary, I just find it useful in my particular setup.
		</para>
		</blockquote>

		</section>
		<section id="older_2.2">
		<title>The Cure: Older 2.2 kernels (&lt;2.2.12)</title>
		<para>
These are old and it would better to upgrade (you won't get much
help on the mailing list for these).
However if you have them,
you apply the arp patches to the kernel code of the 2.2.x realservers.
These patches are separate from the ipvs patch applied to the kernel on
the director.
		</para>
		<para>
For kernels &lt;2.2.12, Julian's patch is on the lvs website.
		</para>
		<para>
http://www.linuxvirtualserver.org/arp_invisible-2213-2.diff
		</para>
		<para>
The patch by Stephen WIllIams is at
		</para>
		<para>
http://www.linuxvirtualserver.org/sdw_fullarpfix.patch
		</para>
		<para>
This patch is against a 2.2.5 kernel but can be applied to later kernels
(tested to 2.2.13). The file appears to have DOS carriage control.
Depending what you get on your disk, you may have to convert the file
to unix carriage control (with `tr -d '\015'`) (the unix line extension
of '\' doesn't work in combination with DOS carriage control).
		</para>
		<para>
The whitespace may not match your file so do
		</para>
<programlisting><![CDATA[
$ cd /usr/src/linux
$ patch -p1 -l < sdw_fullarpfix.patch
]]></programlisting>
		<para>
If you are using <xref linkend="martian_modification"/> you will
need the forward_shared-hidden patch as well (needed only on the director,
but can be applied to both director and realservers).
		</para>
		</section>
		<section id="extra_nic">
		<title>Put an extra NIC (eth1) on the realserver to carry the VIP</title>
		<para>
Possible cards would be a discarded ISA card (WD80x3), or a cheap 100Mbit PCI
card (eg Netgear FA310TX, $16 in USA in Nov 99) There is no traffic going
through this NIC and it doesn't matter that it's an old slow card. The extra
card is only required so that the realserver can have the VIP on the machine.
With 2.2.x kernels you can't stop this device (eth1) from replying to arp
requests, but if you don't connect the cable to it or don't put a route to
it in the realserver's routing table, then the client won't be able to send
it an arp request.
		</para>
		<para>
To set this up with the configure script,
enter eth1 as the device for the VIP on the realserver.
		</para>
		<note>
			<para>
Apparently, the 2nd NIC doesn't handle arp problem for 2.4 kernels.
			</para>
			<para>
I tested the 2 NIC method of handling the arp problem with kernel 2.2.13.
I haven't tried it with 2.4 kernels, but apparently it doesn't work.
Julian and Ratz think it shouldn't work with 2.2.x kernels, but I haven't
revisited the matter to see why we have come to different conclusions.
			</para>
		</note>
		</section>
	</section>
	<section id="2.4_arp">
	<title>The Cure: 2.4.x kernels - arp_ignore/arp_announce</title>
	<para>
The current (kernels starting 2.4.26) accepted method is 
<link linkend="2_4_arp_announce">arp_ignore/arp_announce</link>.
	</para>
	<para>
There are several ways of handling the arp problem for 2.4.x kernels.
They all work, but some of them have been around longer and so have
been used more and people on the mailing list are more familiar with
them.
	</para>
		<section id="2.4_hidden">
		<title>2.4 Hidden Patch</title>
		<para>
Julian's hidden patch has been around the longest and is well tested.
Although included in the standard 2.2.x kernel, it is not being included in
the 2.4.x kernels. You'll have to patch the kernel on the realservers.
The preferred method for new installations is 
<link linkend="2_4_arp_announce">arp_ignore/arp_announce</link>.
		</para>
		<para>
For early 2.4.x kernels (eg x=0), the patch is available at
http://www.linuxvirtualserver.org/hidden-2.3.41-1.diff.
(This patches a part of the kernel that isn't being actively fiddled with,
so hopefully the patch will work against later 2.4.x kernels too.)
		</para>
		<para>
The 2.4.x &quot;hidden&quot; patch is 
included in ipvs-x.x.x/contrib/patches/hidden-x.x.x.diff
		</para>
		<para>
Assuming you are patching 2.4.2 with the ipvs-0.2.5 files
		</para>
<programlisting><![CDATA[
cd /usr/src/linux
patch -p1 <../ipvs-0.2.5/contrib/patches/hidden-2.4.2-1.diff
]]></programlisting>
		<para>
Then build the kernel (can use same options as for the 2.4 director kernel build).
		</para>
		<para>
You activate the hidden feature as for 2.2 (see <link linkend="hidden">hidden</link>).
		</para>
		<para>
As to why the hidden patch is in the 2.2 kernels but not the 2.4 kernels see
the <ulink url="http://marc.theaimsgroup.com/?l=linux-kernel&amp;m=98032243112274&amp;w=2">
the mailing list archives</ulink> or for
<ulink url="http://marc.theaimsgroup.com/?t=98019795800013&amp;w=2&amp;r=1">the thread</ulink>
		</para>
		</section>
		<section id="2_4_arp_announce">
		<title>2.4 arp_announce</title>
		<para>
The 2.6.x <link linkend="2_6_arp_announce">arp_announce, arp_ignore</link>
code has been back ported to 2.4.26 (and later) kernels.
		</para>
		</section>
		<section id="arp_filtering">
		<title>arp filtering</title>
		<para>
Julian has written an extension to the iproute2 tools,
which filters arp packets.
You can use this to handle the arp problem.
See
<ulink url="http://www.ssi.bg/~ja/iparp.txt">Julian's software page</ulink>
for more details.
This method does not require patching of the 2.4 kernel on the realserver.
		</para>
		<note>
Julian's arp filtering is not <xref linkend="arptables"/>.
		</note>
		<para>
Joe
		</para>
		<blockquote>
Is <filename>arptables</filename> the extension to <filename>iptables</filename> 
that you wrote a while ago?
<filename>arptables</filename> seems pretty simple. 
What are the problems with <filename>arptables</filename> 
that you've written arp_ignore and keep maintaining the hidden patch?
		</blockquote>
		<para>
Julian 11 Jul 2004 
		</para>
		<para>
	Almost true, I'm not the <filename>arptables</filename> author.
You're referring to the arprules/iparp functionality which is
based on <command>ip</command>, not on <filename>iptables</filename>. 
Similar names.
		</para>
		<para>
At that time there was no user space tool for the arptables
changes in kernel (done by David Miller), now there is such tool (I didn't
tried it), so the list of options to hide addresses in clusters is
extended.
		</para>
		<para>
	arp_ignore was born day(s) after arp_announce. Both flags are
easy to set default policy for playing with ARP requests and replies
which was needed for years for stuff like interoperability with
other ARP stacks (mostly for controlling the source address selection
in ARP requests with arp_announce) or for hiding of addresses for
cluster setups.
		</para>
		</section>
		<section id="sartori">
		<title>Maurizio Sartori's noarp module</title>
		<para>
Maurizio Sartori <emphasis>masar (at) masarlabs (dot) com</emphasis> 28 Nov 2002
		</para>
		<para>
On <ulink url="http://www.masarlabs.com">my site</ulink>
is a simple kernel module for Linux 2.4.x to solve the ARP Problem.
You don't have to patch the kernel but only to
compile, install and configure the 'noarp' module,
to use your loopback interface filtering its arp
reply.
I've tested it on Debian 'Sarge' and RedHat 8.
		</para>
		<note>
Maurizio later produced a patch for 2.6.
		</note>
		<para>
Sebastien Bonnet <emphasis>Sebastien (dot) Bonnet (at) experian (dot) fr</emphasis>
04 Jun 2003
		</para>
		<para>
Nobody seems to recall what a smart Italian guy named Maurizio Sartori did.
Instead of the hidden patch, which requires a full kernel build,
he's written a *module* called noarp, way more handy, as
		</para>
		<orderedlist>
			<listitem>
it requires only a one module build, doesn't require a kernel
build, takes about 1 minute to install and get working.
			</listitem>
			<listitem>
it allows hidding IPs, not interfaces.
			</listitem>
		</orderedlist>
		<para>
I'm using it in production and it works perfectly.
		</para>
		<para>
Joe
		</para>
		<blockquote>
Can you hide the VIP on eth0:x and not hide the RIP on eth0?
(I should know this, but I don't)
		</blockquote>
		<para>
Jan Abraham <emphasis>jan_abraham (at) gmx (dot) net</emphasis>
31 Oct 2003
		</para>
		<para>
Yes, you can :)
I used Maurizio Sartori's noarp module, suggested in your HOWTO in
chapter 4.5.3. It can be controlled by IP, not by interface.
		</para>
		<para id="ratz_arp_announce">
Ratz 17 Dec 2004
		</para>
		<para>
Julian's arp_ignore is the way to go, portable and ready for upgrades ;). 
Nothing against Maurizio by all means, but after years of fighting with the netdev's Julian 
finally convinced the high priest of Linux networking to solve the arp Problem 
once and for eternity. If you read the accompagning documentation on arp_* 
sysctrl you can pretty much figure out that nothing is impossible anymore ;).
		</para>
		<para>
Joe - I would have been happy if they'd left the arp behaviour as it was originally
and as it is in all the other unices (except HPUX).
		</para>
		<para>
Todd Lyons <emphasis>tlyons (at) ivenue (dot) com</emphasis> 03 Feb 2005 
		</para>
		<blockquote>
			<para>
Hi guys (and masar), I am trying to use your noarp module, but am
hitting the limit of 16 entries.  I need it to work for (at the moment)
an additional 10 entries. I see in <filename>noarp.h</filename>:
			</para>
<programlisting><![CDATA[
#define NOARP_MAX_IP            (16)
]]></programlisting>
			<para>
Is it going to create problems to pick this number up to 32 or 64?  
I've already done it and it seems to handle the problem. I
don't want to create any memory leaks or overruns.  Your code looks like
it allocates memory based on that NOARP_MAX_IP, but my c is not good
enough to know for sure if that will be a problem.  Here's what happens
on my system (RH 7.3 with 2.4.20-28.7smp kernel).  You can see that it's
failing on the 10 additional IP's after the initial 16.  Please let me
know if I can safely raise that number.
			</para>
<programlisting><![CDATA[
[root@rproxy1a init.d]# /etc/init.d/noarp start
/usr/local/sbin/noarpctl: ioctl error: No space left on device
/usr/local/sbin/noarpctl: ioctl error: No space left on device
/usr/local/sbin/noarpctl: ioctl error: No space left on device
/usr/local/sbin/noarpctl: ioctl error: No space left on device
/usr/local/sbin/noarpctl: ioctl error: No space left on device
/usr/local/sbin/noarpctl: ioctl error: No space left on device
/usr/local/sbin/noarpctl: ioctl error: No space left on device
/usr/local/sbin/noarpctl: ioctl error: No space left on device
/usr/local/sbin/noarpctl: ioctl error: No space left on device
/usr/local/sbin/noarpctl: ioctl error: No space left on device
[root@rproxy1a init.d]# /etc/init.d/noarp status
64.14.201.41 10.10.10.160 0 0 0
64.14.201.151 10.10.10.160 0 0 0
64.14.201.161 10.10.10.160 0 0 0
64.14.201.162 10.10.10.160 0 0 0
64.14.201.163 10.10.10.160 0 0 0
64.14.201.164 10.10.10.160 0 0 0
64.14.201.165 10.10.10.160 0 0 0
64.14.201.166 10.10.10.160 0 0 0
64.14.201.167 10.10.10.160 0 0 0
64.14.201.168 10.10.10.160 0 0 0
64.14.201.169 10.10.10.160 0 0 0
64.14.201.175 10.10.10.160 0 0 0
64.14.201.153 10.10.10.160 0 0 0
64.14.201.178 10.10.10.160 0 0 0
64.14.201.170 10.10.10.160 0 0 0
64.14.201.171 10.10.10.160 0 0 0

[root@rproxy1a network-scripts]# ls ifcfg-lo:*
ifcfg-lo:0   ifcfg-lo:13  ifcfg-lo:18  ifcfg-lo:22  ifcfg-lo:4 ifcfg-lo:9
ifcfg-lo:1   ifcfg-lo:14  ifcfg-lo:19  ifcfg-lo:23  ifcfg-lo:5
ifcfg-lo:10  ifcfg-lo:15  ifcfg-lo:2   ifcfg-lo:24  ifcfg-lo:6
ifcfg-lo:11  ifcfg-lo:16  ifcfg-lo:20  ifcfg-lo:25  ifcfg-lo:7
ifcfg-lo:12  ifcfg-lo:17  ifcfg-lo:21  ifcfg-lo:3   ifcfg-lo:8
]]></programlisting>
			<para>
I have a question about the man page 
			</para>
<programlisting><![CDATA[
NOARPCTL COMMANDS
       add    Adds a new Virtual IP to  the  list.  Requires  two
              arguments: the VIP is the address to hide, the Real
              IP (RIP) is a real address of this host to use when
              ARP query are made that would use VIP.
]]></programlisting>
			<para>
I must be misunderstanding something very basic.  I thought you didn't
want real servers to arp at all for VIPs, no matter what interface the
arp comes in on and no matter what interface is defined with the
matching address.  The only acceptable arp answer is for the RIP
(implying local traffic or traffic that is not desired to be load
balanced).  But the above man page contradicts my ideas.  So I'm a bit
confused as to how exactly noarp is working.
			</para>
		</blockquote>
		<para>
Maurizio Sartori <emphasis>masar (at) MasarLabs (dot) com</emphasis> 04 Feb 2005
		</para>
		<para>
there should be no problem to incremente NOARP_MAX_IP,
all memory is allocated statically.
The RIP in the 'add' command of noarpctl is
used to suppress the selection of the VIP as the sender 
IP address in arp requests. 
If not suppressed the back-end host request updates all arp
cache entries on the local net for the VIP with the mac of
the back-end host.
		</para>
		<para>
A way to generate a request of this type is, from a real server:
		</para>
<programlisting><![CDATA[
#> nc -s $VIP somehost 80
]]></programlisting>
		</section>
		<section id="2.4_2NIC">
		<title>extra NIC doesn't solve arp problem for 2.4 kernel realservers</title>
		<para>
Jean Paul Piccato <emphasis>j (dot) piccato (at) studenti (dot) to (dot) it</emphasis>
		</para>
		<blockquote>
I'm setting up a DR_LVS with a director and two servers...
I've to handle the ARP problem so I've put two NIC on the two
realservers...
		</blockquote>
		<para>
Julian Anastasov <emphasis>ja (at) ssi (dot) bg</emphasis> 16 Jan 2002
		</para>
		<para>
This works maybe only with Linux 2.0.
(Joe: see <link linkend="extra_nic">2.2 kernels with extra NIC</link>).
For 2.2+ you need <ulink url="http://www.ssi.bg/~ja/#hidden">
a specific kind of ARP control</ulink>.
In Linux 2.2+ the operation of adding IP address involves
the following 2 steps:
		</para>
		<orderedlist>
			<listitem>
Define a local IP address as a host property - remote hosts can
talk to it through any device
			</listitem>
			<listitem>
Define network link route on the specified device - you can talk
with other hosts from this local network only through this device
			</listitem>
		</orderedlist>
		<para>
(1) allows the Linux 2.2+ box to send ARP replies
through any device that received the reply. Additionally,
the user can provide some filtering by setting some device
specific values:
		</para>

<programlisting><![CDATA[
/proc/sys/net/ipv4/conf/*/<FLAG>
]]></programlisting>
		<para>
These are explained in /usr/src/linux/Documentation/networking/ip-sysctl.txt
		</para>
		<para>
The LVS setups depend mostly on the FLAGs rp_filter, hidden, arp_filter,
send_redirects.
(for more info on kernel flags see the section on
<xref linkend="proc_filesystem"/>).
On problems, check them after learning what they
mean and how they can kill your setup.
		</para>
		<para>
By setting rp_filter or arp_filter on some device you can
ignore the ARP requests (and the traffic if rp_filter is set)
coming from addresses if we don't have a route to these addresses
through the mentioned above device.
		</para>
		<para>
The send_redirects values must be checked for setups playing
with NAT on one physical medium.
		</para>
		<para>
Information on using the hidden patch is in hidden.txt
		</para>
		<blockquote>
It seems that eth0 reply to the server instead of eth1
		</blockquote>
		<para>
Any device can reply if the ARP probe is not filtered.
See hidden.txt from the above URL
		</para>
		<para>
Michael McConnell <emphasis>michaelm (at) eyeball (dot) com</emphasis> 10 Jun 2002
		</para>
		<blockquote>
			<para>
I currently have a system which has a Tyan 2515 Motherboard. This
motherboard features a Dual Intel 82559 NIC.
			</para>
			<para>
The problem I am face is that which using both ports of this dual
interface network card (plugged into the same switch) I find that the
second interface is answering arp requests (on rare occasions) that the
first interface should be answering.
I have used tcpdump and clearly seen eth1 answering arps requests that
eth0 should be answering... how odd.... It's rare, but when it happens
of course that address is offline. (Note: this only seems to happen on
alias IP address, it has never happened on the primary interface)
			</para>
			<para>
I am using the open source drivers provided with the 2.2.19 kernel, I'm
wondering if the drivers provided by Intel would help this problem?
			</para>
		</blockquote>
		<para>
Roberto Nibali <emphasis>ratz (at) tac (dot) ch</emphasis> 11 Jun 2002
		</para>
		<para>
The drivers indeed can't make the difference but not because they are the same, 
but because the driver doesn't have anything to do with the arp/routing issue.
		</para>
		<para>
Julian
		</para>
		<para>
Classic problem of attaching multiple Linux interfaces to
shared medium. You can set arp_filter on all your ARP devices or
why not to restrict even the IP protocol by setting rp_filter.
		</para>
		<para>
	Such answering (of arp requests) can not be never a problem. If the Linux box
answers via many interfaces then it is willing to accept traffic
through these ifaces. Of course, the achieved failover when attaching
two interfaces to same hub is not perfect because the remote LAN boxes
will use the alive Linux interface but Linux routing still uses the first
interface (even if it is failed on Layer 2) for the used subnet.
If your goal is to restrict the talks for each subnet through one
interface then you have to use arp_filter=1 but still to use rp_filter=0
to allow cross-subnet talks. One day rp_filter will be aware of the
medium_id values for each interface and will allow the Linux box
to interconnect multiple hubs securely (and still to use many interfaces
to these hubs).
		</para>
		<para>
	By default Linux replies to ARP probes for any local
IP address configured on any device no matter on what device the
probe is received. Such probes look like "who-has TARGET tell SENDER".
If the probe is answered later we can receive IP traffic from
SENDER to TARGET destined to the TARGET's MAC address.
		</para>
		<para>
	When we have different subnets (network routes) configured
on multiple interfaces attached to same hub sometimes we prefer (may
be the reader can find good reason for this) the traffic to/from one
subnet always to use one interface. In such cases replying through
many interfaces is not desired. We have 2 options:
		</para>
		<para>
arp_filter:
		</para>
		<blockquote>
			<para>
when
			</para>
<programlisting><![CDATA[
/proc/sys/net/ipv4/conf/DEV/arp_filter is set to 1
or
/proc/sys/net/ipv4/conf/all/arp_filter is set to 1
]]></programlisting>
			<para>
then the flag will cause any probe received on interface
        DEV to be dropped if the route from TARGET to SENDER points
        to different interface. With the usual local networks in
        table main in the form "from 0/0 to local_net lookup main"
        we see that the TARGET is ignored. As result, we drop
        probes received from SENDER that comes from wrong
        interface. As result, if the route from TARGET to
        SENDER1 is via DEV1 and from TARGET to SENDER2 is
        via DEV2, then we will reply only through one device
        for each of the senders. Of course, the arp_filter
        relies on the routing and as result the bahavior
        depends on the used ip rules and routes. The above
        is a simple example for normal local networks. The
        arp_filter simply checks the route for the reversed
        addresses. It should point to the input device.
			</para>
		</blockquote>
		<para>
rp_filter:
		</para>
		<blockquote>
	The rp_filter flag (DEV/rp_filter or all/rp_filter)
	set to 1 has similar semantic. It has nearly the same
	function as arp_filter and can control the ARP for
	the same purposes: symmetric talks (in and out using
	same device) but it covers the IP traffic too. It is
	assumed that where ARP is received (replied more
	exactly) there the IP traffic will be accepted too.
	It has mostly security function and can defend
	against IP spoofing. It controls the reverse path
	protection: we accept traffic from SENDER to TARGET
	received on DEV only when the reverse path (from
	TARGET to SENDER) points to the input interface
	DEV. It is used usually for "external" interfaces.
		</blockquote>
		<para>
	How you can use it:
		</para>
<programlisting><![CDATA[
ifconfig eth0 192.168.1.2
ifconfig eth1 192.168.2.2

echo 1 > /proc/sys/net/ipv4/conf/eth0/arp_filter
echo 1 > /proc/sys/net/ipv4/conf/eth1/arp_filter
]]></programlisting>
		</section>
		<section id="different_network">
		<title>Put the realservers on a different network to the VIP</title>
		<para>
Setup routing tables so that the client cannot route
to the realserver network <link linkend="Lars_method">(Lars' method)</link>.
This method requires the director to not forward
packets for the VIP (easy to implement if 2 NICS on the director).
The reply packets from the realservers return to the client
via a different router to the one attached to the director.
Thus the director's router cannot send arp requests to the
realservers.
		</para>
		</section>
		<section id="ethers">
		<title>
On the client(router), route packets with dst_addr=VIP to the director
		</title>
		<para>
You can hardwire the MAC address of the director
as the MAC address of the VIP. You can do this with
		</para>
<programlisting><![CDATA[
#arp -s lvs.mack.net 00:80:C8:CA:A7:E4

or

arp -f /etc/ethers.
]]></programlisting>
		<para>
Here is my /etc/ethers file (on the client)
		</para>
<programlisting><![CDATA[
lvs.mack.net 00:80:C8:CA:A7:E4
]]></programlisting>
		<para>
This requires no extra NICs or patching of realservers. However in a production
environment, redundant directors with heartbeat/failover may be required and
some method (eg running send-arp) will be needed to change the static arp entry
as the failover occurs. If multiple NICs are involved, it is possible that
the above instruction will result in a route through the wrong NIC. In this
case bring up the NIC of interest first and then run the above command.
		</para>
		<para>
Alternately if the router has several NICs, use one for the director and
another for the realservers. Route the VIP to the director.
		</para>
		</section>
		<section id="horms_method" xreflabel="Horms method">
		<title>Use transparent proxy allow the incoming packet to be accepted locally - Horms method.</title>
		<para>
see the sections on <xref linkend="LVS-HOWTO.transparent_proxy"/>,
and its setup for LVS-DR and LVS-Tun.
The configure script will set this up for you.
		</para>
		</section>
	</section>
	<section id="2.6_arp">
	<title>The Cure: 2.6.x kernels - arp_ignore/arp_announce</title>
		<section id="2_6_arp_announce" xreflabel="2.6 arp announce">
		<title>2.6 arp_announce</title>
	        <para>
Julian Anastasov <emphasis>ja (at) ssi (dot) bg</emphasis> 25 Feb 2004
       		</para>
		<blockquote>
2.4.26 and 2.6.4 come with 2 new device flags for tuning the ARP stack:
<filename>arp_announce</filename> and <filename>arp_ignore</filename>.
All IPVS-like setups can use arp_announce=2 and arp_ignore=1/2/3 
to solve the "ARP problem" on realservers with DR/TUN setups. 
These flags are going to replace the "hidden"
functionality which does not work well when directors are
changing role between master/slave for a particular VIP.
The risk is that other hosts can probe for VIP using unicast packets
for which the hidden flag always replies. I'll continue to support the
hidden flag for 2.4 and 2.6 to help existing setups but switching
to the new device flags (or other solutions) is recommended.
		</blockquote>
		<para>
Documentation is in the
<ulink url="file:/usr/src/linux/Documentation/networking/ip-sysctl.txt">
2.6 kernel docs</ulink>
(linux/Documentation/networking/ip-sysctl.txt) (here from the 2.6.17 kernel).
		</para>
<programlisting><![CDATA[
arp_announce - INTEGER
	Define different restriction levels for announcing the local
	source IP address from IP packets in ARP requests sent on
	interface:
	0 - (default) Use any local address, configured on any interface
	1 - Try to avoid local addresses that are not in the target's
	subnet for this interface. This mode is useful when target
	hosts reachable via this interface require the source IP
	address in ARP requests to be part of their logical network
	configured on the receiving interface. When we generate the
	request we will check all our subnets that include the
	target IP and will preserve the source address if it is from
	such subnet. If there is no such subnet we select source
	address according to the rules for level 2.
	2 - Always use the best local address for this target.
	In this mode we ignore the source address in the IP packet
	and try to select local address that we prefer for talks with
	the target host. Such local address is selected by looking
	for primary IP addresses on all our subnets on the outgoing
	interface that include the target IP address. If no suitable
	local address is found we select the first local address
	we have on the outgoing interface or on all other interfaces,
	with the hope we will receive reply for our request and
	even sometimes no matter the source IP address we announce.

	The max value from conf/{all,interface}/arp_announce is used.

	Increasing the restriction level gives more chance for
	receiving answer from the resolved target while decreasing
	the level announces more valid sender's information.

arp_ignore - INTEGER
	Define different modes for sending replies in response to
	received ARP requests that resolve local target IP addresses:
	0 - (default): reply for any local target IP address, configured
	on any interface
	1 - reply only if the target IP address is local address
	configured on the incoming interface
	2 - reply only if the target IP address is local address
	configured on the incoming interface and both with the
	sender's IP address are part from same subnet on this interface
	3 - do not reply for local addresses configured with scope host,
	only resolutions for global and link addresses are replied
	4-7 - reserved
	8 - do not reply for all local addresses

	The max value from conf/{all,interface}/arp_ignore is used
	when ARP request is received on the {interface}
]]></programlisting>
		<para>
On the realservers the VIP will still be on <filename>lo</filename> (as for the hidden method).
If the reply packets to the client are routed through <filename>eth0</filename>, 
then the arp announcements/requests are made through <filename>eth0</filename> and you
will apply the <filename>arp_ignore</filename>/<filename>arp_announce</filename> sysctls to 
<filename>eth0</filename>, 
not to <filename>lo</filename> 
(you cannot use <filename>arp_ignore</filename>/<filename>arp_announce</filename> on <filename>lo</filename>).
		</para>
<programlisting><![CDATA[
/etc/sysctl.conf
net.ipv4.conf.eth0.arp_ignore = 1
net.ipv4.conf.eth0.arp_announce = 2
net.ipv4.conf.all.arp_ignore = 1
net.ipv4.conf.all.arp_announce = 2
]]></programlisting>
		<para>
As with all devices that reply to arp requests, 
you should stop the arp behaviour before bringing up the VIP,
or else flush the arp tables on the router before using the LVS.
		</para>
		<para>
Mag2589 Walla Feb 21, 2007
		</para>
		<blockquote>
			<para>
On my realservers I have them set up to listen to the virtual address
on eth0:0 I need them to respond to arp on eth0 but I need them to
ignore it on eth0:0 To do this would I enter the following line in my
<filename>/etc/sysctl.conf</filename> file?
			</para>
<programlisting><![CDATA[
net.ipv4.conf.eth0:0.arp_ignore = 8
]]></programlisting>
			</blockquote>
		<para>
Horms
		</para>
		<para>
In a word: No
		</para>
		<para>
<filename>arp_ignore</filename> works only on physical interfaces. 
The old <filename>eth0:0</filename> notation is
a hang-over from the days of ip aliases, where in a round-about way you
could establish virtual interfaces (sort of). These days an interface
can have 0 or more addresses.  The <filename>arp_ignore</filename> 
semantics apply to such addresses.
		</para>
		<para>
If you really
need fine-grained arp control, take a look at <xref linkend="arptables"/>, 
which is kind of like iptables for arp.
		</para>
		</section>
		<section id="noarp_2.6">
		<title>noarp v2.6</title>
		<para>
Masar <emphasis>masar (at) MasarLabs (dot) com</emphasis> 04 Mar 2004
		</para>
		<para>
<ulink url="http://www.masarlabs.com/">noarp 2.0.0</ulink>
(http://www.masarlabs.com) is now available.
This is the port of <filename>noarp</filename> to the Linux 2.6.x kernel.
For the 2.4.x kernel use <filename>noarp 1.x.x</filename>.
I'm making separate packages of <filename>noarp</filename>
for the two kernels,
because the method for producing a module is different.
If there is sufficient interest,
I may produce a single package for both kernel versions.
		</para>
		</section>
		<section id="arp_ignore_ubuntu">
		<title>arp ignore with Ubuntu</title>
		<para>
Julien Cornuwel <emphasis>cornuwel (at) gmail (dot) com</emphasis> 29 Sep 2008 
		</para>
		<blockquote>
			<para>
I'm trying to set up load balancing with IPVS on two Apache webservers.
The loadbalancer and both apache servers are virtual machines running Ubuntu
8.04 server on VMware ESX 3.5.
			</para>
			<para>
If the platform has been idle for some time (like when I came back to work
this morning), I can point a browser to http://VIP and get pages from
server1 or server2 alternatively (I'm using rr during setup). But after
about 5 seconds, I get nothing and the browser times out.
			</para>
			<para>
Here is my configuration on the load balancer :
			</para>
<programlisting><![CDATA[
ipvsadm -A -t $VIP:80 -s rr
ipvsadm -a -t $VIP:80 -r $RIP1:80 -g
ipvsadm -a -t $VIP:80 -r $RIP2:80 -g
]]></programlisting>
			<para>
On webservers, I added the following to /etc/sysctl.conf (as suggested on
http://www.linuxvirtualserver.org/VS-DRouting.html) :
			</para>
<programlisting><![CDATA[
net.ipv4.conf.all.hidden = 1
net.ipv4.conf.lo.hidden = 1
]]></programlisting>
			<para>
I rebooted them and then :
			</para>
<programlisting><![CDATA[
ifconfig lo:0 $VIP netmask 255.255.255.255 up
]]></programlisting>
			<para>
Unless I did something stupid (if so, please tell me), it should work. 
			</para>
<programlisting><![CDATA[
echo 1 > /proc/sys/net/ipv4/conf/lo/arp_ignore
echo 2 > /proc/sys/net/ipv4/conf/lo/arp_announce
echo 1 > /proc/sys/net/ipv4/conf/all/arp_ignore
echo 2 > /proc/sys/net/ipv4/conf/all/arp_announce
]]></programlisting>
			<para>
I'm quite sure my problem is not on the loadbalancer but on webservers.
			</para>
			<para>
I have one interface and tried the following with no more luck :
			</para>
<programlisting><![CDATA[
net.ipv4.conf.all.arp_ignore=1
net.ipv4.conf.eth0.arp_ignore=1
net.ipv4.conf.all.arp_announce=2
net.ipv4.conf.eth0.arp_announce=2
]]></programlisting>
			<para>
On the first request, that works, I have an ESTABLISHED line.
But after a few seconds, I get dozens of SYN_RECV.
OK, so I definitely have an ARP problem, with the above configuration.
Any idea why the above commands doesn't work on Ubuntu?
			</para>
			<para>
I did a TCP dump on all 3 servers and here is what I see :
			</para>
			<itemizedlist>
				<listitem>
On webservers, when it works, I see outgoing IP packets with the LB's
address as origin. When it doesn't, I just see nothing. About once per
second, the LB sends ARP requests trying to find both webservers (on their
real addresses), I never saw an ARP reply.
				</listitem>
				<listitem>
On the load balancer, I see incomming requests from clients, and some
"ICMP host lb" not reachable sent to the client when it doesn't work.
				</listitem>
			</itemizedlist>
			<para>
Webservers should reply to ARP requests on their primary addresses, but they
don't :(
			</para>
		</blockquote>
		<para> 
Laurentiu C. Badea (L.C.) <emphasis>lc (at) waat (dot) com</emphasis> 07 Oct 2008
		</para>
		<para>
Well I think it's either that you applied "hidden" to eth0 on the 
webservers, or the LB has the VIP as a primary address. See if the ARPs 
were going out with VIP as source and if that's the case, try giving the 
LB a different primary address and make VIP an alias.
		</para>
		<para>
Julien
		</para>
		<blockquote>
Great ! That was it. Now that I have the VIP as an alias on LB, it works.
Note to the documentation team : on Ubuntu 8.04, there is a trap with real servers.
If you set arp_ignore/arp_announce configuration in /etc/sysctl.conf AND set
the VIP on lo:0 in /etc/interfaces. It seems that the interface is brought
up  *before* the sysctl commands are passed. You have to set the VIP
manually at the end of the boot process.
		</blockquote>
		</section>
	</section>
	<section id="arptables" xreflabel="arptables">
	<title>arptables</title>
        <para>
Kjetil Torgrim Homme <emphasis>kjetilho (at) ifi (dot) uio (dot) no</emphasis>
11 Jul 2004
        </para>
        <blockquote>
                <para>
arptables is a method supported by Red Hat.
The package, <filename>arptables_jf</filename>,
is part of Advanced Server, but the src.rpm can be downloaded,
rebuilt and used on Workstation since it has the same kernel support.
The configuration is pretty straightforward:
                </para>
<programlisting><![CDATA[
# arptables -A IN -d $VIP -j DROP
# arptables -A OUT -s $VIP -j mangle --mangle-ip-s $RIP
# service arptables_jf save
# chkconfig --add arptables_jf
# chkconfig --levels 12345 arptables_jf on
]]></programlisting>
                <para>
This service will start before the network is brought up.  Note that you
have to specify an explicit runlevel, since it stupidly won't start in
single user by default.
                </para>
        </blockquote>
	<para>
Bandit Lazuli <emphasis>banditlazuli (at) yahoo (dot) com</emphasis> 13 Apr 2006 
	</para>
	<para>
Our cluster of web frontends periodically exhibited a kind of Fatal
Attraction behavior, where one host would suddenly be the recipient of
all hits. Attempting to add new hosts to the existing cluster
triggered this behavior in a consistent way. With something clear to
fix, we installed the latest version of keepalived on the latest RHEL4
kernel.
 	</para>
	<para>
And lo, nothing changed. 
Add a new host, it became a Fatal Attractor within 6 minutes of operation 
(note that this is NOT the <xref linkend="thundering_herd"/>; 
things were relatively well balanced for a minute or 6).
	</para>
	<para> 
Stranger yet, ipvsadm on the director revealed that the Attractor was
getting NO hits. So it wasn't that the LVS was sending all hits to one
machine. You guessed it. The new machine was arping for the shared ip,
and connections were coming directly to it.
We had arptables set up as follows:
 	</para>
<programlisting><![CDATA[
*filter
:IN ACCEPT [0:0]
:OUT ACCEPT [0:0]
-A IN -d 192.168.0.12 -j DROP
COMMIT
]]></programlisting>
	<para> 
And in desperation, started arptables at runlevel 1. This didn't help,
because it wasn't responding to an inbound arp request, but was
instead generating it's OWN arp request, and broadcasting the response
it made to itself.
This could be seen with:
	</para> 
<programlisting><![CDATA[
tcpdump -i any arp > file
]]></programlisting>
	<para> 
And then pawing through the file for the shared ip (name). So there
lies the smoking gun. Arptables was NOT working as advertised. So we
added:
	</para>

<programlisting><![CDATA[
-A OUT -d 192.168.0.12 -j mangle --mangle-ip-s 192.168.0.104
]]></programlisting>

	<para> 
This still did not do the trick; apparently arptables implicitly
operates on the interface owing the ip (lo:1, in our case), if no
interface is specified. That left eth0 leaking arps.
Specifying the interface did the trick:
	</para>

<programlisting><![CDATA[
-A OUT -s 192.168.0.12 -o eth0 -j mangle --mangle-ip-s 192.168.0.104
]]></programlisting>
	<para>
And here is the whole filter:
 	</para>
<programlisting><![CDATA[
*filter
:IN ACCEPT [0:0]
:OUT ACCEPT [0:0]
-A IN -d 192.168.0.12 -j DROP
-A OUT -s 192.168.0.12 -o eth0 -j mangle --mangle-ip-s 192.168.0.104
COMMIT
]]></programlisting>
	<para>
arps are now properly squelched, and fatal attractor behavior has vanished. I'm posting this because I longed for google to return such a message in response to many searches.
	</para>
	</section>
	<section id="vip_not_rip" xreflabel="vip not rip">
	<title>The arp problem is on the realserver's VIP not the RIP</title>
	<para>
Cali Federico
	</para>
	<blockquote>
		<para>
I've configured an http service on director as below:
		</para>
<programlisting><![CDATA[
Prot LocalAddress:Port Scheduler Flags
  -> RemoteAddress:Port             Forward Weight ActiveConn InActConn
TCP  194.153.172.249:80 wlc
  -> 194.153.172.222:80             Route   1      0          0
]]></programlisting>
		<para>
and I've installed the noarp module on the realserver as below:
		</para>
<programlisting><![CDATA[
[root@cautha2 root]# noarpctl list
194.153.172.249 194.153.172.222 12 0 3
]]></programlisting>
		<para>
The problem I can see is that invoking the http://VIP/index.html from my 
PC (outside the LVS network) I can see the page provided by realserver 2 
or 3 times after that I receive a "Page Cannot Displayed".
The page remains unreachable for several minutes after I have the same 
behaviour again.
Looking at the director's arp table, the HWaddress related 
to the realserver is "(incomplete)".
After that I set (using arp -s) the correct realserver MacAddress the LVS 
works properly.
		</para>
	</blockquote>
	<para>
Malcolm Turnbull <emphasis>malcolm (at) loadbalancer (dot) org</emphasis> 2005/19/05 
	</para>
	<para>
You are no arp'ing your RIP which is not a good idea. It's just the VIP 
that needs NOARP on the realserver.
	</para>
	</section>
	<section id="testing_for_arp" xreflabel="testing for arp">
	<title>Testing an interface for replies to arp requests</title>
	<para>
To test that the VIP on the realservers
(here lo:0) is hidden from arp requests:
You test from a client machine on the same network segment as
the NICs on the realservers.
For your sanity, you could try this with one realserver at a time.
You do _NOT_ have the director (with its pingable VIP) connected to the network
(unplug it).
	</para>
	<itemizedlist>
		<listitem>
			<para>
Optional: on each realserver, to accumulate a list of the MAC addresses
for each NIC.
			</para>
<programlisting><![CDATA[
realserver: # ping VIP
realserver: # arp -a	# look for the MAC address of the VIP
realserver: # ifconfig	# should show the same MAC address
]]></programlisting>
		</listitem>
		<listitem>
			<para>
find the MAC address for the realserver's VIP from the test client.
			</para>
<programlisting><![CDATA[
client: # ping VIP
or ping the broadcast address
client: # ping 192.168.1.255	#for a VIP in the 192.169.1.0/24 network
then
client: # arp -a	# look for the MAC address of the VIP on the realserver.
			# if you have several realservers on-line,
			# it could be the MAC address of the NIC on any of the realservers
]]></programlisting>
		</listitem>
		<listitem>
			<para>
Hide the lo interface on the realserver (<xref linkend="hidden"/>).
Before the arp tables expire (15secs - 2mins depending
on the OS), ping the VIP again from the test client.
The realserver will still reply to the ping,
since the MAC address for the VIP will still be in the arp table of the test client.
			</para>
<programlisting><![CDATA[
client: # ping VIP
]]></programlisting>
		</listitem>
		<listitem>
			<para>
let the arp cache expire (wait 15sec - 2mins) or clear the arp cache of the test client.
			</para>
<programlisting><![CDATA[
client: # sleep 120
or
client: # arp -d VIP	# delete/flush/clear the entry for the VIP
then
client: # arp -a	# show that the arp entry for the VIP is gone
]]></programlisting>
		</listitem>
		<listitem>
			<para>
ping the VIP. You should get no reply.
			</para>
<programlisting><![CDATA[
client: # ping VIP
]]></programlisting>
		</listitem>
		<listitem>
			<para>
Do for all realservers, making sure you get no ping replies for the VIP.
			</para>
		</listitem>
		<listitem>
			<para>
On the director (don't connect it to the network yet)
find the MAC address of the VIP
			</para>
<programlisting><![CDATA[
director: # ping VIP		#VIP can be an IP or a resolvable name
and/or
director: # ifconfig		#look for MAC address of NIC with VIP
then
director: cat /proc/net/arp	#shows list of IP-MAC address pairs
or
director: arp -a 		#shows FQDN as well
]]></programlisting>
		</listitem>
		<listitem>
			<para>
Connect the director to the network.
Just to be sure, clear the arp entry for the VIP on the test client
(<command>arp -d VIP</command>) and ping the VIP again.
You should get ping replies.
The test client's arp cache should have the MAC address of the director's NIC
for the VIP.
			</para>
		</listitem>
	</itemizedlist>
	</section>
	<section id="normal_realservers">
	<title>Normal machines, Solaris, Novell Server</title>
	<para>
The arp problem only occurs on Linux with kernels 2.2 and later. 
All other OS's honor the arp flag 
(Joe HPUX does something wierd with <filename>noarp</filename>, but I've forgotten what).
	</para>
	<para>
Mark de Vries
	</para>
	<blockquote>
I need to do some DR to a Solaris 8 box... Anyone know how to set it to
ignore arp requests? So far I have only done DR to linux and windows
boxen...
	</blockquote>
	<para>
Lasse Karstensen <emphasis>lkarsten (at) hyse (dot) org</emphasis>21 Apr 2006
	</para>
	<para>
At least for Solaris 9, you can just create the file
<filename>/etc/hostname.lo0:14</filename> (14=some number)
	</para>
	<para>
Inside of it you write
	</para>
<programlisting><![CDATA[
"""
plumb 1.2.3.4 -arp netmask 255.255.255.255 up
"""
]]></programlisting>
	<para>
where 1.2.3.4 is your vip-address.
I'm pretty sure this also works in Solaris 8. 
The Solaris-people here also mention that you can just use
addif in <filename>/etc/hostname.lo0</filename>, 
if you rather fancy having everything in one file.
	</para>
	<para>
Mark de Vries <emphasis>markdv (dot) lvsuser (at) asphyx (dot) net</emphasis>21 Apr 2006 
	</para>
	<blockquote>
		<para>
Ah yes, the -arp option... Yeah works! Not that it matters because half
way throught the exersize I suddenly realized that the service has always
used NAT for a reason; the real servers have the service on different
ports then on the VIP... so DR is a no-go... sigh...
		</para>
		<para>
And the whole reason we wanted to use dr in this first, or actually
second, case was because half way through the first attempt at configuring
it as NAT I suddenly realized that wouldn't work because in this case the
realserver has an interface in the same network as the VIP is in (so there
is a direct route to the client and packets won't get de-natted)... So
short of someone pointing me to a source-based-routing-HOWTO-on-Solaris
it's just not gonna work out...
		</para>
	</blockquote>
	<para>
Malcolm Turnbull <emphasis>malcolm (at) loadbalancer (dot) org</emphasis> 17 Dec 2008
	</para>
	<para>
We recently had a customer using that funny thing called Novell Server....
I couldn't find anything in the LVS manual about Novell Server in DR
mode but eventually figured out the following which works great:
	</para>
<programlisting><![CDATA[
add secondary ipaddress <ipaddress> noarp
]]></programlisting>
	</section>
	<section id="switches_that_bight">
	<title>problems with switches</title>
	<para>
There are other places in the network with arp caches,
like "smart" switches.
These will bight you if you don't know about them.
	</para>
	<para>
<emphasis>frederic (dot) buche (at) equant (dot) com</emphasis> 29 Oct 2003
	</para>
	<blockquote>
		<para>
OK Julian, you are right.
The problem came from my network-switch,
which keeps in memory the MAC address of all machines.
So it just relays the arp request to the concerned server,
by using a unicast arp request.
		</para>
		<para>
Just for a test, I have deleted the MAC entry on my switch. Then reproduce
the same test than before ... and the hidden patch works well!
		</para>
	</blockquote>
	<para>
Carlos J. Ramos <emphasis>cjramos (at) genasys (dot) com</emphasis> 15 Dec 2003
	</para>
	<para>
We are using an HP Procurve Switch 2124 in a
cluster using Heartbeat and Ldirectord as HA and Balancing mechanisms.
Previously we have similar working setups with a hub in the
same location.
Eerything works fine, till we make a takeover on directors. As
the switch documentation saids, the switch automatically learn MAC
address and associate it to its ports, so that although heartbeat
changes IP address, the switch try to use the same switch port.
The  situation remains for at least 1 hour... for this time the forwarding in
the cluster does not works... and realservers are unable to be reached
from outside... We are assuming this is an arp caching problem,
although we haven't eliminated other possible causes yet.
	</para>
	<para>
Is there any way to force the switch to refresh MAC Address Table?, is
there any Linux tool that sent any kind of packet over the net forcing
the ARP Table to be updated?
	</para>
	</section>
	<section id="first_inklings">
	<title>The ARP problem, the first inklings</title>
	<para>
History: The ARP behaviour changed between 2.0.x and 2.2.x kernels.
Here's the original posting by Wensong
and a reply from Alexy Kuznet (2.2 tcpip author)
	</para>
	<para>
Wensong Zhang <emphasis>wensong (at) iinchina (dot) net</emphasis>  24 Mar 1999
	</para>
	<para>
Today I upgraded the kernel to 2.2.3 with tunneling support on
one of a realserver, and found a problem that the Linux 2.2.3
tunnel device answers ARP requests.  Even if I used the NOARP
options as follows:
	</para>
<programlisting><![CDATA[
realserver:# ifconfig tunl0 172.26.20.110 -arp netmask 255.255.255.255 broadcast 172.26.20.110
]]></programlisting>
	<para>
It still answers the ARP requests. This will greatly affect the
virtual server via tunneling work properly.  In fact, the tunnel
device shouldn't answer the ARP requests from the ethernet. I
think it is a bug of linux/net/ipv4/ipip.c, which is now a clone
of ip_gre.c not the original tunneling code.
	</para>
	<para>
If you are interested, you can test yourself on kernel 2.2.3,
choose a free IP address of your ethernet and configure it on the
tunl0 device, then telnet to that IP address from other host, I
guess you can. Finally, have a look at the ipip.c, maybe you can
debug it. :-) --
	</para>
	<para>
But, what is the IFF_NOARP flag of the tunnel device for?
	</para>
	<para>
<emphasis>kuznet (at) ms2 (dot) inr (dot) ac (dot) ru</emphasis>
	</para>
	<blockquote>
		<para>
IFF_NOARP means that ARP is not used by THIS device.
On normal IPIP tunnels it does not make much of sense, but may be
used for example to turn on/off endpoint reachability detection.
		</para>
		<para>
I do not see any reasons to disable answering ARP in such
curcumstances. Isolation of VPNs on adjacent segments is impossible
at routing/arp level, it is just not well-defined behaviour.
		</para>
		<para>
If the isolation is made with firewall policy rules, then
it is clear that arp policy must be handled at this level too.
		</para>
	</blockquote>
	<para>
In kernel 2.0.x, the tunnel device doesn't answer ARP requests.
	</para>
	<blockquote>
Yes.
	</blockquote>
	<para>
Yeah, we can have link-local addresses that doesn't answer ARP requests in
kernel 2.2.x. For example, we can configure all the hosts in a network
with the following command:
	</para>
<programlisting><![CDATA[
ifconfig lo:0 192.168.0.10 up
]]></programlisting>
	<para>
There will no collision. The lookback alias interfaces don't answer ARP
requests.
	</para>
	<blockquote>
		<para>
Are you sure? I am not. Please, test.
		</para>
		<para>
BTW you risk adding non-loopback addresses on loopback device.
They have the HIGHEST preference to be used as router identifier.
so that VPN addresses cannot be added to loopback at all.
		</para>
	</blockquote>
	<para>
No, it doesn't fail. I tested it with kernel 2.0.36, it worked.
	</para>
	<blockquote>
It does not work under 2.2. To be honest, I am about to stop to understand
you. You talk about 2.2, but all your tests are made for 2.0. 8)
	</blockquote>
	</section>
	<section id="Kese">
	<title>A posting to the mailinglist by Peter Kese explaining the "arp problem"</title>
	<para>
(saved for posterity by Ted Pavlic, minor editing by Joe)
	</para>
	<para>
<emphasis>peter (dot) kese (at) ijs (dot) si</emphasis>
	</para>
	<para>
Before we start, let's assume we have following network
configuration for an LVS running LVS-DR.
	</para>
<programlisting><![CDATA[
client		10.10.10.10

gw		192.168.1.1

director	192.168.1.10 	IP for admin (director IP)
        	192.168.1.110 	VIP (responds to arp requests)

realserver	192.168.1.11 	IP to which each service is listening (realserver IP)
		192.168.1.110 	VIP (DOES NOT respond to arp requests)
]]></programlisting>
	<para>
The virtualserver is the combination of the director and
the realserver running LVS.
	</para>
	<para>
Or goal is:
	</para>
	<orderedlist>
		<listitem>
Virtual server should respond to arp requests for both
the VIP and the director IP.
		</listitem>
		<listitem>
		The realserver should respond to arp requests for the
realserver IP but NOT the VIP.
		</listitem>
		<listitem>
Gateway sends packets for the VIP to the director IP
load balancer no matter what.
		</listitem>
	</orderedlist>
	<para>
Problem 1: Interface aliases
	</para>
	<para>
Realserver and director need to have an interface with the VIP in
order to respond to packets for virtual server. A real interface
is not needed, an IP alias will do just fine and this interface
alias could be either eth0:0 or lo:0.
	</para>
	<para>
On the 2.0 kernels, the ARP responding ability of an interface
alias (eg eth0:0) could either be enabled or disabled
independantly of the main (eth0) interface.  If you wanted eth0:0
not to respond to ARP requests, you could simply say:
	</para>
<programlisting><![CDATA[
        ifconfig eth0:0 192.168.1.2 -arp up
]]></programlisting>
	<para>
Thus in the 2.0 kernels it is possible, on a realserver, to have
the realserver IP (on eth0) respond to arp requests and for the
VIP (on eth0:0) to not respond.
	</para>
	<para>
In the 2.2 kernels this doesn't work any more. Whether the an
interface alias responds to ARP requests or not, depends only on
the way the real interface is configured.  So if eth0 responds to
ARP requests (which it normally will), eth0:0 carrying the VIP
will also respond to ARP requests no matter what.
	</para>
	<para>
This means an ethernet alias (eth0:0) is not permitted on real
servers, because realservers should not respond ARP requests.
	</para>
	<para>
On the other hand, loopback aliases never respond ARP requests,
which means that the loopback alias (lo:0) must not be used on
the director for the VIP.
	</para>
	<para>
Problem 2: Loopback aliases
	</para>
	<para>
I haven't done much checking on loopback interface problem, but
it seems that if an alias is used on a loopback interface (as is
required for LVS-DR) on a realserver running kernel 2.2.x, the
whole ARP gets screwed.
	</para>
	<para>
It appears that loopback interfaces get special ARP treatment in
the kernel, so I suggest avoiding the loopback aliases as whole.
	</para>
	<para>
The question now is: What kind of an interface can I use on real
servers?
	</para>
	<para>
As I already noted, eth0:0 alias can not be used, because such
aliases respond to ARP requests. lo:0 aliases can not be used,
because they make ARP problems too.
	</para>
	<para>
In case of tunneling VS configuration, the answer is trivial:
tunl0. But to be honest, tunl0 interface can also be used for
direct routing.
	</para>
	<para>
(Joe: the dummy device is OK too, at least for the 2.0.x kernels)
	</para>
	<para>
With direct routing, the only thing we need an interface for is
to let kernel know we posses an additional IP address. This
means, we can set up any kind of an interface, as long as it
doesn't respond ARP requests. Instead of tunl0, you could also
set up a ppp0, slip0, eth1 or whatever. I suggest setting up a
tunl0:
	</para>
<programlisting><![CDATA[
        ifconfig tunl0 192.168.1.2 -arp up
]]></programlisting>
	<para>
Problem 3: Real server ARP requests.
	</para>
	<para>
Suppose we have set up a virtual server as described at the
beginning. All computers are running, but no requests have been
made.
	</para>
	<para>
Then the client sends a request to the VIP.
	</para>
	<para>
When the packet arrives to gateway, the gateway makes an ARP
query for the VIP and the director responds. Gateway remembers
the director's MAC address and sends the packet to the director.
Director receives the packet, looks up its ipvsadm/LVS tables and
chooses the realserver and forwards the packet to the real
server by direct routing or tunneling method.
	</para>
	<para>
Real server receives the packet and generates a response packet
with destination=client, source=VIP.
	</para>
	<para>
(until now everything works correctly)
	</para>
	<para>
When realserver wants to send the response packet to the
gateway, it finds out, that it does not know the gateway's MAC
address.
	</para>
	<para>
It sends an ARP request to the local network and asks for the
gateway MAC address. This should look like:
	</para>
	<para>
        ARP, who has 192.168.1.1 (gw), tell 192.168.1.11 (realserver IP)
	</para>
	<para>
But in reality, realserver asks something like:
	</para>
	<para>
        ARP, who has 192.168.1.1 (gw), tell 192.168.1.110 (VIP),
	</para>
	<para>
because it takes the source address from the packet it wants to
send.
	</para>
	<para>
Here the problems come in.
	</para>
	<para>
Gateway receives the packet and responds to it, which is correct.
But at the same time, gatweay does a little optimization. It
finds out, that the realserver's MAC address is not listed in its
ARP tables and adds the entry into the table, just in case it
might need that address in the near future.
	</para>
	<para>
The ARP request contained the VIP address and the realserver's
MAC address, so from now on, the gateway will send all packets
destined for the VIP to the realserver instead (due to MAC
address). This means all packets that follow will avoid the
virtual server as whole and get responded by the realserver.
	</para>
	<para>
If the realserver's ARP request would be:
	</para>
	<para>
        ARP, who has 192.168.1.1 (gw), tell 192.168.1.11 (realserver IP)
	</para>
	<para>
all this would not have happened. Therefore I have patched the
2.2 VS kernel in such a way, that it composes ARP requests based
on the address of the interface selected by the routing tables
instead of the address taken from the packet itself.
	</para>
	<para>
In order for virtual server to work correctly, the realservers
should have patched kernels as well, or at least copy the patched
/usr/src/linux/net/ipv4/arp.c file to the realservers before
compiling the kernels.
	</para>
	<para>
Conclusion
	</para>
	<para>
Those were my experience with ARP problems, and the 2.2 kernel
virtual server.
	</para>
	<para>
I think it would be wise to add this letter to the web site and
notify the network developers about our findings at some point in
time.
	</para>
	<para>
Here are some golden rules I stick to, when I do virtual server
configuration:
	</para>
<programlisting><![CDATA[
Rule 1:
        Do not use lo:0 alias on the director.
        Use eth0:0 alias instead.

Rule 2:
        Avoid using lo:0 alias, not even on realservers.
        Use tunl0 or some other simulated interface
        on realservers instead. (Joe: use dummy0)


Rule 3:
        Apply the VS patch to kernels on realservers.
]]></programlisting>
	</section>
	<section id="arp_bouncing" xreflabel="arp bouncing">
	<title>arp bouncing</title>
	<para>
symptoms of realservers arp'ing - arp bouncing
	</para>
	<para>
Stephen WIlliams <emphasis>sdw (at) lig (dot) net</emphasis> (Stephen wrote one of
the patches that stop devices in 2.2.x kernels from replying
to arp requests)
	</para>
	<para>
If you don't use the patch you'll find that the 'active' box will
bounce from machine to machine as each one sends an ARP reply
that is heard last. Additionally you will get TCP Reset's as
connections that were on one box suddenly start going to others.
Very nasty and unusable.
	</para>
	</section>
	<section id="lars_method">
	<title>Lar's Method</title>
	<para>
(This is called <link linkend="Lars_method">Lars' method</link>)
	</para>
	<para>
Lars
	</para>
	<para>
I have thought about how the ARP problem can occur at all with
direct routing, because I never noticed it. Then it occured to me
that your VIP comes from the same subnet as the RIP of
the LVS and also all the realservers share this media.
	</para>
	<para>
To avoid the "ARP problem" in this case without adding a kernel
patch or anything else, you can just add a direct route for the
VIP using the RIP of the LVS as a gateway address on the
router in front of the LVS. ("ip route VIP 255.255.255.255
real_ip" on a Cisco, or "route add -host VIP gw RIP" on Linux)
	</para>
	<para>
Since I just used 2 ethernet cards and had the LVS act as
gateway/firewall anyway, I never noticed the ARP problem. (We
have 2 LVS in a standby configuration to eliminate the SPOF)
	</para>
	</section>
	<section id="static_routing">
	<title>Static Routing to Director</title>
	<para>
The arp problem is handled if the router in front of the director
has a static route for the VIP to the director (<emphasis>i.e.</emphasis>
packets for the VIP from the outside world are sent to the director
and cannot get to the realservers).
	</para>
	<para>
Wensong
	</para>
	<para>
For the clients who reach the virtual server through the router,
there is no problem if a static route for VIP is added.
	</para>
	<para>
However, for the clients who are in the network of virtual
server, the "ARP problem" will arise. There is fight in ARP
response, and the clients don't know send the packets to the load
balancer or the realserver.
	</para>
	<para>
In my point of view, the VIP address is shared by the director
and realservers in LVS-Tun or LVS-DR, only the director
does ARP response for VIP to accept request packets, and
the realservers has the VIP but don't, so that they can process
packets destined for VIP.
	</para>
	</section>
	<section id="iproute2_NOARP">
	<title>iproute2 arp on|off flag</title>
	<para>
Joe, 21 May 2001
	</para>
	<blockquote>
		<para>
Was looking at the ip (<emphasis>i.e.</emphasis>iproute2) notes and it says
		</para>
<programlisting><![CDATA[
ip arp on|off

--change NOARP flad on the device

1cm NB. This operation is not allowed if the device is in state UP.
Though neither ip utility nor kernel check for this condition, you can
get unpredictable results changing the flag while the device is running.
]]></programlisting>
		<para>
Is this like the old -noarp flag for ifconfig?
		</para>
	</blockquote>
	<para>
Julian Anastasov <emphasis>ja (at) ssi (dot) bg</emphasis> 21 May 2001
	</para>
	<para>
	This is the device ARP flag, same as ifconfig [-]arp.
The flag is used to allow ARP packets for the specified device.
It is correct that "lo" does not talk ARP, but you connect to
the VIPs on "lo" through eth*, so the flag is of no help for LVS.
We can't drop the flag for eth device.
	</para>
	<para>
Andreas J. Koenig, 02 Jun 2001
	</para>
	<blockquote>
kernel 2.4.5 has arp_filter
	</blockquote>
	<para>
Julian Anastasov <emphasis>ja (at) ssi (dot) bg</emphasis>
	</para>
	<para>
arp_filter does not solve the ARP problem for LVS
	</para>
	<para>
	This is a new proposal to control the ARP probes and replies
based on route flag "noarp". It will be discussed on the netdev mailing
list and may be something like this is going to be included in 2.4,
may be in 2.2 too, not sure. All you know that the hidden feature is
not considered to 2.4. The net developers have the final word. I'll
try to maintain the hidden flag in all next kernels while this flag is
more usable than the new feature and because the hidden flag has other
semantic. And because may be there are some user space tools that rely
on this.
	</para>
	</section>
	<section id="arp_2.2">
	<title>Is the arp behaviour of 2.2.x kernel a bug?</title>
	<note>
		<para>
Julian Anastasov is replying to correct an
error in a previous version of the HOWTO
where I state that the dummy0 device in
2.2.x kernels does not arp. Julian wrote
one of the realserver patches which
fix the "arp problem".
		</para>
	</note>
	<para>
Julian
	</para>
	<para>
         In fact, the documentation is incorrect. There is no difference,
 all devices are reported in the ARP replies: lo, tunl and dummy. So, only
 the ARP patch can solve the problem. This can be tested using this
 configuration with any device (before the patch applied):
	</para>
<programlisting><![CDATA[
Host A:
         eth:x 192.168.0.1

Host B:
         eth:x 192.168.0.2
         lo, dummy, tunl: 192.168.0.3
]]></programlisting>
	<para>
On host A try: ping 192.168.0.3
	</para>
	<para>
Host B replies for 192.168.0.3 through 192.168.0.2 device
	</para>
	<para>
         So, the ARP problem means: "All local interfaces are reported"
until the ARP patch is used. In fact, all ARP patches which use IFF_NOARP
to hide the interface are incorrect. I don't expect them in the kernel.
	</para>
	<para>
Stephen WIlliams (who wrote another of the patches to
fix the arp problem).
	</para>
	<blockquote>
		<para>
Of course the ARP code in the kernel needs to be fixed so my filter code isn't
needed.  Still, I'm confused by this statement.  The IFF_NOARP flag determines
whether a device arp replies or not.  What's wrong with honoring that?
		</para>
		<para>
If you mean that arp replies should never be sent on another interface, that is
what I currently believe to be correct.
		</para>
	</blockquote>
	<para>
Julian
	</para>
	<para>
         My understanding is that 2.2.x ARP code is not buggy and
 there is no need to be "fixed". I must say that your patch is
 working for the LVS folks but not for all linux users.
	</para>
	<para>
         IFF_NOARP means "Don't talk ARP on this device",
 from the 'man ifconfig':
	</para>
	<para>
 [-]arp  Enable or disable the use of the ARP protocol on
 this interface.
	</para>
	<para>
         So, where is the bug ? The ARP code never talks through
 lo, dummy and tunl devices when they are set NOARP. It uses
 eth (ARP) device.
 If You hide all NOARP interfaces from the ARP protocol
 this is a bug. One example:
	</para>
<programlisting><![CDATA[
 +--------+ppp0                          +------+
 | Host A |------------ppp link----------|ROUTER|------ The World
 +--------+A.B.C.1 (www.domain.com)      +------+
   |eth0
   |A.B.C.2
   |
   |A.B.C.3
 +--------+
 | Host B |
 +--------+
]]></programlisting>
	<para>
 Is it possible after your patch Host B to access www.domain.com ?
 How ? Host A doesn't send replies for A.B.C.1 through eth0 after
 your patch. OK, may be this is not fatal. Tell it to all kernel
 users. You hide all their NOARP interfaces. May be there are other
 examples where this is a problem too. Or may be there is something
 wrong in this configuration?
	</para>
	<para>
         I want to say that this patch hurts all users if present
 in the kernel. On Nov 6 I posted one patch proposal to the
 linux-kernel list which adds the ability to hide interfaces
 from the ARP queries and replies. But the difference is that
 only specified interfaces are not replied, not all NOARP
 interfaces. Its arp_invisible sysctl can be used by LVS
 folks to hide lo, tunl or dummy interfaces but this feature
 doesn't hurt all kernel users. I think, this patch is more
 acceptable and can be included in the 2.2 kernel, may be after
 some tunning. And I'm still expecting comments from the net
 folks and from all LVS users.
	</para>
	</section>
	<section id="arp" xreflabel="the kernel replies to arp requests">
	<title>The device doesn't reply to arp requests, the kernel does.</title>
	<para>
ARP requests/replies are thought of as coming from a device
and people make statements like
	</para>
	<para>
"the dummy device in 2.0.x kernels does not reply to arp
requests while the same device in 2.2.x kernels does reply".
	</para>
	<para>
It is the kernel that handles arp requests according to a
set of rules and not the device. The code for the dummy
device is the same in 2.0.x and 2.2.x kernels and is
not responsible for the change in arp behaviour.
	</para>
	<para>
(The RPC for ARP is at ftp://ftp.isi.edu/in-notes/std/std37.txt.
- also see rfc826 and rfc1122. The model system used there is 2
machines on a single ethernet. It doesn't shed any light on the
implementation of ARP on multi-interface systems like LVS.)
	</para>
	</section>
	<section id="vip_devices" xreflabel="vip devices">
	<title>Properties of devices for the VIP</title>
	<para>
In a previous version of the HOWTO I stated that the dummy0
device did not arp in 2.2.x kernels and therefore could be
used as the device for the VIP on an unpatched 2.2.13 realserver.
Julian Anastasov replied that they did arp (see below
for his posting and the ensuing discussions).
	</para>
	<para>
I hadn't actually tested whether the dummy0 device arp'ed
but had concluded that it wasn't arp'ing because I had a
working LVS using the dummy0 interface for the VIP on
unpatched 2.2.x realservers and because as everyone
knows ;-) an LVS needs to have a non-arp'ing device on
the VIP of the realservers.
	</para>
	<para>
I had a LVS-DR LVS which worked with dummy0, lo:0 and tunl0
as the VIP device and which on further testing, I found
also worked with eth0:1 or eth1 as the VIP device on
2.2.13 realservers. Whatever the arp'ing status of dummy0,
lo:0 or tunl0, clearly eth1 replies to arp requests,
so despite the conventional wisdom, it is possible
to build an LVS with arp'ing VIP's on the realservers.
	</para>
	<para>
On investigating why this LVS worked, I found that the
MAC address for the VIP in the client's arp cache (# arp -a)
was always the director. I assume this was
because the director is 3-4x the speed of the other
machines in the LVS and it replies to arp requests first
for the VIP (another posting from Stephen WIlliams
says that the address which replies last is stored in the
arp cache - we'll figure out what's really going on here
eventually). On another LVS where the realservers were all
identical hardware with 2.2.13 unpatched kernels, one
particular realserver always was the machine in the client's
arp cache for the VIP (to check, delete entry for VIP
with arp -d, then ping again, then look in arp cache).
	</para>
	<para>
	I found that I could get a working LVS using almost
anything to hold the VIP on the realservers, including eth0:1
and eth1 (another NIC in the realserver). These devices carrying
the VIP were pingable from the client and I could get the
corresponding MAC addresses in the arp table of the client
if the director was not setup with a VIP. When I setup a
working LVS this way, I found each time that the MAC
address for the VIP in the client's arp cache was the
director's MAC address. For some reason, that I don't know,
whenever the client does an arp request for the VIP, it gets
the director's MAC address.
	</para>
	<para>
Possible reasons for the MAC address of the director always
being associated with the VIP in my LVS -
	</para>
	<orderedlist>
		<listitem>
1. I configure the director first and then the realservers.
I don't make requests for a service till the realservers
are setup. (Still I can't imagine the client
asking for the MAC address of the VIP until it makes a connect
request.)
		</listitem>
		<listitem>
2. The director is 3 times faster (CPU speed) than the next
machine in the LVS and it always replies to arp request first.
		</listitem>
		<listitem>
3. I was lucky.
		</listitem>
	</orderedlist>
	<para>
Since you can make a working LVS-DR LVS with the realserver VIP
on an arp'ing eth0:1 device I decided that the relevent piece
of information about arp'ing was (ta da!)
	</para>
	<para>
* <emphasis>an LVS will work if the client always gets the MAC address
of the director when it asks for the MAC address of the VIP</emphasis> *
	</para>
	<para>
This provides an easy solution - you tell the client (or the router) the
MAC address of the VIP with <command>arp -s</command> or <command>arp -f</command>.
	</para>
	<para>
here's my <filename>/etc/ethers</filename>
	</para>
<programlisting><![CDATA[
lvs.mack.net 00:A0:CC:55:7D:47
]]></programlisting>
	<para>
After installing the MAC address of the DIP (director) as
the MAC address of the VIP (lvs) in the arp table
(<command>arp -f /etc/ethers</command>) I get
	</para>
<programlisting><![CDATA[
client:/usr/src/temp/lvs# arp -a
realserver1.mack.net (192.168.1.1) at 00:90:27:66:CE:EB [ether] on eth0
lvs.mack.net (192.168.1.110) at 00:A0:CC:55:7D:47 [ether] PERM on eth0
director.mack.net (192.168.1.10) at 00:A0:CC:55:7D:47 [ether] on eth0
]]></programlisting>
	<para>
notice the "PERM" in the VIP entry on the client.
	</para>
	<para>
removing the permanent entry
	</para>
<programlisting><![CDATA[
client:/usr/src/temp/lvs# arp -d lvs.mack.net
client:/usr/src/temp/lvs# arp -a
realserver1.mack.net (192.168.1.1) at 00:90:27:66:CE:EB [ether] on eth0
lvs.mack.net (192.168.1.110) at <incomplete> on eth0
director.mack.net (192.168.1.10) at 00:A0:CC:55:7D:47 [ether] on eth0
]]></programlisting>
	<para>
If I edited <filename>/etc/ethers</filename> changing the MAC address of lvs to
anything else, the LVS did not work anymore. So the arp
information is coming from <filename>/etc/ethers</filename> rather than some
uncontrolled variable I'm not aware of.
	</para>
	<para>
I had thought that in an LVS with the VIP on realservers
on an arping device that the VIP would hop from one machine
to another (see the postings in the MISC section). Since
naturally occuring LVS's with arping VIP's on realservers
existed and worked well (mine), I set up an LVS
by making a permanent entry for the VIP of the director
in the arp cache of the client (router). This can be done by
	</para>
<programlisting><![CDATA[
$ arp -f /etc/ethers
]]></programlisting>
or
<programlisting><![CDATA[
$ arp -s 192.168.1.110 MAC_ADDRESS
]]></programlisting>
	<para>
There are 2 results of this
	</para>
	<orderedlist>
		<listitem>
the realservers can have the VIP on an
an <filename>arp</filename>'ing device (eg eth0:1, eth1)
- you don't need lo or dummy0, tunl0
for realservers with 2.0.36 and 2.2.x kernels.
		</listitem>
		<listitem>
If two (or more) directors are setup in failover mode, the
mechanism by for changing the VIP from one to another is
broken by making a permanent entry for VIP on the director
in the arp cache of the router. This is not a problem for a test
setup to demonstrate an LVS but may be a problem in a high
availability environment (a solution may be found n the meantime
too).
		</listitem>
	</orderedlist>
	<para>
The normal method for changing directors
(<emphasis>e.g.</emphasis> with heartbeat) includes
a gratuitous arp. To force a gratuitous arp
	</para>
	<para>
Julian
	</para>
	<blockquote>
		<para>
You can use Yuri Volobuev's send_arp.c from the 'fake' package or
Alexey Kuznetsov's arping from its iputils package:
		</para>
		<itemizedlist>
			<listitem>
fake - http://vergenet.net/linux/fake/
			</listitem>
			<listitem>
iputils - ftp://ftp.inr.ac.ru/ip-routing/iputils-ss991024.tar.gz
iputils is also used for IPAT, IP address takeover
			</listitem>
		</itemizedlist>
	</blockquote>
	<para>
If you're not sure if the network knows that the VIP has moved, try this.
	</para>
	<para>
Graeme Fowler <emphasis>graeme (at) graemef (dot) net</emphasis> 13 Mar 2006
	</para>
	<para>
At failover, make the new live director run something along the lines of:
	</para>
<programlisting><![CDATA[
/sbin/ping -c5 -I $VIP $GW_IP
]]></programlisting>
	<para>
Where $GW_IP is the IP address of your upstream router. It's not exactly 
gratuitous ARP but it does, in my experience, help to rapdily converge 
the systems which currently don't talk to each other.
	</para>
	<para>
Also make absolutely sure that the VIP is being torn down on the 
failed director. If it isn't, and it still ARPs for it, you'll end up in 
all sorts of problems.
	</para>
	<para>
To monitor this you could feasibly run <command>arpwatch</command> 
on both the directors' upstream interfaces. 
You should see the VIP flip-flop on failover. If 
you see it repeatedly flip-flop at regular intervals, you're not tearing 
down properly.
	</para>
	<para>
Joe Dec 2003
	</para>
	<para>
There is also <ulink url="http://www.vergenet.net/~acassen/software/garp-0.1.1.tar.gz">
http://www.vergenet.net/~acassen/software/garp-0.1.1.tar.gz</ulink>
which has been available for over a year, without me even knowing about it.
	</para>
	<para>
Here's some tests I did
	</para>
<programlisting><![CDATA[
LVS equipment: 2.2.13 client, and 0.9.4/2.2.13 director.
2 realservers
a) 2.0.36 kernel, libc5, gcc-2.7.2.3, net-tools 1.42.
b) 2.2.13 kernel, glibc, gcc-2.95,    net-tools 1.52
]]></programlisting>
	<para>
Experiment 1: Result - arp'ing is independant of [-]arp
	</para>
	<para>
Summary: the -arp/+arp option for ifconfig had no effect
on any devices back to 2.0.36 kernels with net-tools 1.42.
If it normally arps then -arp had no effect, if it normally
doesn't arp, than "arp" doesn't turn it on (data below).
	</para>
	<para>
Method:
IP=192.168.1.1/24 with VIP=192.168.1.110/32. The VIP was on
dummy0. The test was to see if the VIP was pingable from
another (external) machine on the 192.168.1.0/24 network
or pingable from the machine itself (ie internally from
the console). (I assume I had a route add -host for the
VIP although I didn't record this). The test was done with
ifconfig using arp or -arp (the output of ifconfig -a
didn't change)
	</para>
<programlisting><![CDATA[
                 -----2.0.36------- -----2.2.13------
ping from        internal  external internal external
VIP device
dummy	ARP        +         -	      +        +
        NOARP      +         -        +        +
        down       -         -        -        - (control)
]]></programlisting>
	<para>
Experiment2: Can the VIP be on a separate NIC?
	</para>
	<para>
Summary: yes, as long as the NIC doesn't have a cable
plugged into it.
	</para>
	<para>
Method:
same as above except VIP on eth1 (another NIC).
	</para>
<programlisting><![CDATA[
                 -----2.0.36-------
ping from        internal  external
VIP device
eth1 has cable connected to 192.168.1.0 network
eth1    ARP        +         +
        NOARP      +         +

eth1 cable to network removed
eth1    ARP        +         -
        NOARP      +         -
        works as realserver in LVS - yes
]]></programlisting>
	<para>
One of the reasons an no_arp interface is used on the
realserver is that it is not visible to the rest of the
network. Does the LVS work if the eth1 VIP on the realserver
is not visible to the rest of the network?
	</para>
	<para>
Conclusion: for 2.0.36 dummy0 doesn't arp, and eth1 does arp.
the arp/-arp option to ifconfig has no effect on arp behaviour.
LVS works with both dummy0 and eth1, I assume since VIP need
only be resolved as local on the realserver and does not
need to be visible to the network.
	</para>
	<para>
Experiment 3: What devices and netmasks are neccessary for
a working LVS?
	</para>
	<para>
Using the /etc/ethers approach for setting the MAC address of the
VIP I then set up an LVS with pair of realservers serving telnet.
All IPs are 192.168.1.x, all machines have a route to 192.168.1.0
via eth0. There is no default route.
	</para>
<programlisting><![CDATA[
1. 2.0.36, libc5, gcc 2.7.2.3, net-tools 1.42
2. 2.2.13, glibc-2.1.2, gcc-2.95, net-tools 1.52
]]></programlisting>
	<para>
with the following devices holding the VIP, tunl0, eth0:1, lo:0, dummy0,
eth1. In each case there was no route entry for the VIP device and
there was no cable connected to eth1 when it was used for the VIP.
The table below shows whether the LVS worked. The VIP is installed with
	</para>
<programlisting><![CDATA[
ifconfig $DEVICE 192.168.1.110 netmask $NETMASK broadcast $BROADCAST
with $NETMASK="255.255.255.255" $BROADCAST="192.168.1.110"
or   $NETMASK="255.255.255.0"   $BROADCAST="192.168.1.255"
]]></programlisting>
	<para>
the result belong to 1 of 3 groups
	</para>
<programlisting><![CDATA[
+ works fine
- doesn't work
  (at $ prompt on client get
  "unable to connect to remote host.  Protocol not available"
  then client returns to regular unix $ prompt)
hang - client hangs, realserver cannot access network anymore,
  have to run rc.inet1 from console prompt on realserver to
  start network again.
]]></programlisting>
	<para>
netmask of VIP=255.255.255.255 (normal LVS setup)
	</para>
<programlisting><![CDATA[
LVS type  -----VS-Tun------     ----VS-DR------
kernel    2.0.36     2.2.13     2.0.36   2.2.13

VIP on
tunl0      +           +         +         +
eth0:1     +           -         +         +
lo:0       +           -         +         +
dummy0     +           -         +         +
eth1       +           -         +         +
]]></programlisting>
	<para>
netmask of VIP=255.255.255.0 (not normally used for LVS)
	</para>
<programlisting><![CDATA[
VIP on
tunl0      +           +         +         +
eth0:1     +           -         +         +
lo:0       +           hangs     +         hangs
dummy0     +           -         +         +
eth1       +           -         +         +
]]></programlisting>
	<para>
It would seem that any device and any netmask can be used
for the VIP on a 2.0.36 realserver for both LVS-Tun and LVS-DR.
	</para>
	<para>
For 2.2.13 realserver,
LVS-Tun, VIP on a tunl0 device only, any netmask
(ie you need tunl0 on LVS-Tun with 2.2.x kernels)
	</para>
<programlisting><![CDATA[
LVS-DR,  lo:0 device netmask /32 only
       all other devices any netmask
]]></programlisting>
	<para>
For LVS-DR then on Solaris/DEC/HP/NT...
LVS can probably use a regular eth0 device rather than
an lo:0 device (more work for Ratz to do :-).
	</para>
	<para>
Does anyone know why the lo:0 device has to be /32
for LVS-DR on kernel 2.2.13 while the other devices
can be /24?
	</para>
	<para>
Jean-Francois Nadeau <emphasis>jna (at) microflex (dot) ca</emphasis> 6 Dec 99
	</para>
	<para>
In kernel 2.2.1x with a virtual interface on lo:0
and netmask of 255.255.255.0 that the interface no longer
arps.
	</para>
	<para>
Horms 29 Oct 2003 (4yrs later, presumably referring to the 2.4 kernels)
	</para>
<programlisting><![CDATA[
/sbin/ifconfig lo:110 192.168.1.110 broadcast 192.168.1.110 netmask 255.255.255.255
]]></programlisting>
	<para>
brings up lo:110 (a virtual interface on the loopback device)
for 192.168.1.110 with the broadcast and netmask as specified.
If you are using LVS-DR then the packets that arrive
on the realservers have the destination IP address set
to the VIP. So the realservers need some way of accepting
this traffic as local. One way is to add an interface on
the loopback device and hide it so it won't answer ARP requests.
The netmask has to be 255.255.255.255 because
the loopback interface will answer packets for
_all_ hosts on any configured interface.
So 192.168.1.110 with netmask of 255.255.255.0
will cause the machine to accept packets for
_all_ addresses in the range 192.168.1.0 - 192.168.1.255,
which is probably not what you want.
	</para>
	<para>
Does anyone know why only the tunl0 device works for
LVS-Tun on 2.2.x kernels?
	</para>
	<para>
Experiment 4: Effect of route entry for VIP and connection to
VIP. The VIP normally has an entry in the routing table eg
	</para>
<programlisting><![CDATA[
route add -host 192.168.1.110 $DEVICE
]]></programlisting>
	<para>
I found in Experiment 2 that a route entry was not neccessary
for the LVS to work when the realserver had the VIP on eth0:1.
Since I had always used a route entry for the VIP I wanted to
find out when it was needed. The same LVS was used as for
Experiment 3. The variables were
	</para>
<programlisting><![CDATA[
1) a route entry/no route entry for VIP/32
2) for eth1 whether the NIC was connected to the network by a cable.

kernel            ------2.0.36-------     -------2.2.13-------
VIP               eth1 eth1_nc eth0:1     eth1  eth1_nc eth0:1

no route
   LVS             +     +      +          +      +       +
   ping internal   -     -      -          +      +       +
   ping external   +     -      +          +      +       +

route
   LVS             +     +      +          +      +       +
   ping internal   +     +      +          +      +       +
   ping external   +     -      +          +      +       +
]]></programlisting>
	<para>
Conclusion 1: LVS works when for both cases of route/no_route
for the VIP for eth0:1 and eth1 (ie you don't need a route entry
for the VIP on the realservers).
	</para>
	<para>
Conclusion 2:  having a network cable/no network cable
does not affect whether the LVS works.
	</para>
	<para>
Conclusion 3: for 2.0.36 kernels you can choose to have
the VIP pingable from the outside world but not pingable
by the local host by having it on eth1 with a cable
connection (this seems weird and I can't think
of any use for it just yet) or the reverse - pingable
from the localhost but not by the external world
by not have a cable connection.
	</para>
	<note>
	using a host's routable IP as the target - the IP on eth0
say - you can make a host unpingable from the console if you down
the lo. The host is still pingable from elsewhere on the net.
	</note>
	</section>
	<section id="topology">
	<title>Topologies for LVS-DR and LVS-Tun LVS's</title>
		<section id="traditional">
		<title>Traditional</title>
		<para>
The conventional LVS-DR/VS-Tun topology which allows maximum
scalability has each realserver with its own default
gateway (to a router). (In a routerless test setup, the
client would be the default gateway for the realservers.
In a setup which is not network bound, <emphasis>i.e.</emphasis>
is disk- or compute-bound, only one router
may be needed. The changes in topology/routing are made
by changing the IP of the default gw for the realservers)
		</para>
		<para>
Some method of handling the arp problem is needed here.
		</para>
		<para>
The packets sent to the realservers from the director,
generate replies which go directly to the client.
Failure messages (eg if a realservers is not available)
do not get returned to the director, who cannot
tell if a realserver has failed
(see discussion of <link linkend="agent">monitoring agents</link>).
		</para>
<programlisting><![CDATA[
                       -------------clients-----------------------
                       |                         |       |       |
                    (router)                  (router)(router)(router)
                       |                         |       |       |
          _________    |                         |       |       |
        |          |   |    VIP                  |       |       |
        | director |---     DIP                  |       |       |
        |__________|   |                         |       |       |
                       |                         |       |       |
                       |                         |       |       |
        ---------------------------------        |       |       |
        |              |                |        |       |       |
        |              |                |        |       |       |
       RIP1           RIP2             RIP3      |       |       |
       VIP            VIP              VIP       |       |       |
 _____________   _____________   _____________   |       |       |
|             | |             | |             |  |       |       |
| realserver  | | realserver  | | realserver  |  |       |       |
|_____________| |_____________| |_____________|  |       |       |
        |              |                |        |       |       |
        |              |                ----------       |       |
        |              -----------------------------------       |
        ----------------------------------------------------------
]]></programlisting>
		</section>
		<section id="director_sees_replies">
		<title>Director sees replies</title>
		<para>
(from Julian Anastasov)
		</para>
		<note>
This discussion led to Julian's <xref linkend="martian_modification"/>.
		</note>
		<para>
If the default gw for each realserver is changed to the DIP
(see the Martian modification section) then
		</para>
		<itemizedlist>
			<listitem>
The director has to handle the reply packets as well
as in the incoming packets, doubling the network load.
			</listitem>
			<listitem>
The director sees all the reply packets. Connection failure
can be detected (in principle).
			</listitem>
		</itemizedlist>
<programlisting><![CDATA[
                        clients
                           |
                         router
                           |
             __________    |
            |          |   |    VIP
            | director |---     DIP
            |__________|   |
                           |
                           |
          ------------------------------------
          |                |                 |
          |                |                 |
         RIP1             RIP2              RIP3
         VIP              VIP               VIP
   _____________     _____________     _____________
  |             |   |             |   |             |
  | realserver  |   | realserver  |   | realserver  |
  |_____________|   |_____________|   |_____________|
]]></programlisting>
		<para>
Here's the original posting by Horms <emphasis>horms (at) vergenet (dot) net</emphasis>
		</para>
		<para>
Hi, I have been setting up a test network to benchmark IPVS,
the topology is as follows.
		</para>
<programlisting><![CDATA[
       node-1      node-6     node-7
       (client)   (client)   (client)
           |         |          |        client-net
  ---------+---------+----------+------ 192.168.2.0/24
                     |
                   node-3 (router)
                     |                   server-net
      ------+--------+----------+---     192.168.1.0/24
            |        |          |
         node-2    node-4     node-5
         (IPVS)   (server)   (server)
]]></programlisting>
		<para>
The question that I have is that the network I would really like
to be testing is;
		</para>
<programlisting><![CDATA[
       node-1       node-6     node-7
       (client)   (client)   (client)
           |         |          |        client-net
  ---------+---------+----------+------ 192.168.2.0/24
                     |
                   node-2 (IPVS)
                     |                   server-net
      ---------+-----+----+---------     192.168.1.0/24
               |          |
             node-4     node-5
            (server)   (server)
]]></programlisting>
		<para>
..  other than using NAT, which has
 performance problems, is this possible? I tried this topology
 with direct routing and packets from the clients were multiplexed
 to the servers fine, but return packets from the servers to the
 client were not routed by the IPVS box.
		</para>
		<para>
Lars
		</para>
		<para>
Yes. The LVS box silently drops the return packets, since they have a src ip
which is also bound as a local interface on the LVS. This is meant to be a
simple anti-spoofing protection.
		</para>
		<para>
from Joe:
		</para>
		<note>
The return packet from the realserver has src=VIP,
dest=CIP. If this packet is routed via the director, which also has
the VIP, the director will be receiving a packet from another machine
with the the src being an one of its own IPs and the director will
drop the packet).
		</note>
		<para>
You can enable logging these packets via
		</para>
<programlisting><![CDATA[
echo 1 >/proc/sys/net/ipv4/conf/all/log_martians
]]></programlisting>
		<para>
The only way around this with current Linux kernels is to disable the check in
the kernel source or to use a separate box as the outward gateway. (Which is
how DR is meant to be used for full performance)
This is not a problem as such as it probably makes a lot of sense
on not to use an IPVS box as your gateway router,
Actually it makes a lot of sense to do just that IMHO. Less points of failure,
less hard- and software to duplicate in a failover configuration.
		</para>
		<para>
Ray Bellis <emphasis>rpb (at) community (dot) net (dot) uk</emphasis>
		</para>
		<blockquote>
It needs to be made more explicit in the documentation that LVS-DR will
<emphasis>only</emphasis> work if you have a different return path.
		</blockquote>
		<para>
Lars Marowsky-Bree <emphasis>lmb (at) teuto (dot) net</emphasis>
		</para>
		<para>
... or if you have a suitably patched kernel.
		</para>
		<blockquote>
 We spent several man days trying to get this to work before figuring out why
the packets were being dropped, at which point we had no alternative but to
use LVS-NAT instead.
		</blockquote>
		<para>
I agree. We still assume too much knowledge on the network admin side.
		</para>
		<blockquote>
FYI, we have our LVS system working now, with LVS redundancy achieved by
running OSPF routing (gated) on the LVS-NAT servers and having the VIP
within the same IP subnet as the RIPs so that IGP routing policies
automatically determine which LVS router the packets arrive on.
		</blockquote>
		<para>
Yes, thats one option. Even better than heartbeat and IPAT, if all your
systems support running a routing protocol.
(IPAT = IP address takeover, part of heartbeat)
In essence, heartbeat and IPAT is nothing but reinventing a subset of the
functionality of a hardened routing protocol like OSPF/RIPv2/EIGRP.
		</para>
		</section>
		<section id="promote">
		<title>On other schemes for director/realservers to exchange roles</title>
		<para>
Julian Anastasov <emphasis>uli (at) linux (dot) tu-varna (dot) acad (dot) bg</emphasis>
has pointed out on the mailing list that the prototype LVS can be redrawn as
		</para>
<programlisting><![CDATA[
                        ________
                       |        |
                       | client |
                       |________|
			   |
                           |
                        (router)
                           |
			   |
         ------------------------------------
         |                 |                |
         |                 |                |
      DIP, VIP         RIP1, VIP        RIP2, VIP
    ____________    ______________    ______________
   |            |  |              |  |              |
   |  director  |  | realserver1  |  | realserver2  |
   |____________|  |______________|  |______________|
]]></programlisting>
		<para>
and that any realserver is in a position to replace a failed
director.  No-one has bothered to write the code for this.
It seems it's easier do have extra boxes in the director role
(ready for failover) and others in realserver role.
It's easier to wheel in another box for a spare director
than to configure realservers to do two jobs reliably.
		</para>
		<para>
Julian
		</para>
		<para>
The director and the backup are in a shared
network for incoming traffic, the backup sniff packets and change its
connection state the same as the director (because the director is just on
half client-to-server connection in LVS/TUN and LVS/DR), then drop
packets.
It needs some investigation and probably lots of additional code too. ;-)
		</para>
		<para>
Wensong Zhang <emphasis>wensong (at) iinchina (dot) net</emphasis>
		</para>
		<para>
I don't even think so - the main trick is getting the kernel to sniff the
packets, which is probably quite easy with a little messing around. Not
sending the packets out again (which would confuse the realservers) is easy
with a ipchains output rule which silently drops them.
		</para>
		<para>
This doesn't work with a switch though, you need a shared network like a
hub.
		</para>
		<para>
However, I have been talking with Rusty about this. The problem is more
general - HA shared-state firewalls are asked for all the time, so we want to
do a generic thing for everything which builds upon Netfilter's state machine.
This would not only cover LVS, but also masquerading and packet filtering in
general. We intend to discuss this in greater detail at the Ottawa Linux
Symposium latest.
		</para>
		<para>
Julian
		</para>
		<para>
You can see,the connections depend on the initalize status and realsevers
realtime status. So another method is that when Director is down, backup-sever
setup the ipvs with the connections,but it seems too late. How do you think
about this?
		</para>
		<para>
Wensong
		</para>
		<para>
TCP/IP should be able to cope with a few seconds delay and lost packets. You
want to heartbeat once per second and take over after 3-4s though - this
usually means takeover is complete in &lt;10s, which TCP/IP should swallow.
		</para>
		</section>
	</section>
	<section id="broadcast_arp_replies" xreflabel="broadcast_arp_replies">
	<title>Why do all devices broadcast the arp replies</title>
	<para>
John Reuning (10 Apr 2003)
	</para>
	<blockquote>
Why are arp replies sent for all interfaces,
regardless of which interface receives the arp request?
	</blockquote>
	<para>
Julian
	</para>
	<para>
	Because Linux routing agrees that all these senders have access
to this IP, so we give them access to valid link layer address.
This behavior is usually observed on routers configured without
source address validation enabled. As this is the default behavior
specified in RFC1812 (rp_filter=0), Linux simply allows access to
this IP on any interface.
	</para>
	<blockquote>
arp is part of the transition from network layer to link layer, right?
So why should an alias on lo, an interface that doesn't really generate
network frames, trigger an arp reply.  Do other unix tcp/ip
	</blockquote>
	<para>
	Note that these packets are not passed via the lo interface,
also, we do not send ARP replies via lo, why we should care about
the lo's NOARP flag?
	</para>
	<blockquote>
I can't seem to make a Solaris 7 system generate arp replies for an lo alias.
	</blockquote>
	<para>
	The different systems have different policy for IP addresses
configured on loopback device. Note that in Linux, this behavior
has nothing to do with the lo interface, you can configure IP
on eth1 and then again to see our ARP reply for it on eth0.
	</para>
	</section>
	<section id="arp_discussion">
	<title>A discussion about the arp problem</title>
	<para>
			</para><para>
(Joe and Julian)
			</para><para>
Julian Anastasov <emphasis>uli (at) linux (dot) tu-varna (dot) acad (dot) bg</emphasis>
There is no difference between devices in 2.2.x, all devices
are reported in the ARP replies: lo, tunl and dummy.
This can be tested using this configuration with any device:
<programlisting><![CDATA[

Host A:
        eth:x 192.168.0.1

Host B:
        eth:x 192.168.0.2
        lo, dummy, tunl: 192.168.0.3
]]></programlisting>
			</para><para>
On host A try: ping 192.168.0.3
			</para><para>
Host B replies for 192.168.0.3 through 192.168.0.2 device
			</para><para>
			</para><para>
The ARP problem means: "All local interfaces are reported"
until the ARP patch is used. In fact, all ARP patches which use IFF_NOARP
to hide the interface are incorrect. I don't expect them in the kernel.
			</para><para>
ARP problem, some rules:
			</para><para>
ARP responses
<itemizedlist>
<listitem> all local IP addresses are replied: lo, eth,
        tunl*, dummy* but with some exceptions (see the next rules)

</listitem><listitem> 127.0.0.0/8(LOOPBACK) and 224.0.0.0/4(MULTICAST) are
        not replied

</listitem><listitem> there is one exception for the "lo" interface:
it is possible the kernel to ignore the ARP request if the
        source IP is from the same net as the net used to
        configure "lo" alias. The specified network is treated
        as local.
</listitem></itemizedlist>
			</para><para>
For example:
			</para><para>
realserver# ifconfig lo:0 192.168.1.1 netmask 255.255.255.0
                broadcast 192.168.1.255 up
			</para><para>
        "real" treats all packets with source addr from
        192.168.1.0/24 which come from the other devices (eth0)
        as invalid, i.e. source address validation works in
        this case and the ARP request are not replied. The kernel
        thinks: "The incoming packet arrived with
        saddr=local_IP1 and daddr=local_IP2(VIP), so it is invalid".
        By this way the host from the LAN can't talk to the
        realserver if its lo alias is configured with
        netmask != 255.255.255.255
			</para><para>
<programlisting><![CDATA[
        ifconfig dummy0 192.168.1.1 netmask 255.255.255.255
]]></programlisting>
			</para><para>
        registers only 192.168.1.1 as local ip but:
			</para><para>
<programlisting><![CDATA[
        ifconfig lo:0 192.168.1.1 netmask 255.255.255.0
]]></programlisting>
			</para><para>
	all 256 IPs are local. All IFF_LOOPBACK devices treat
	all IPs as local according to the used netmask.
			</para><para>
<blockquote><para>
Joe
			</para><para>
I assume IFF_LOOPBACK devices are lo, lo:0..n?
</para></blockquote>
			</para><para>
        Yes, currently only lo is marked as loopback. It is used to mark
whole subnets as local.
			</para><para>
<blockquote><para>lo:0 is not marked as loopback?</para></blockquote>
			</para><para>
        lo:0 is just attached IP address to the same device "lo".
You can try "ifconfig lo:0 192.168.0.1 netmask 255.255.255.255" and
display the interfaces using "ifconfig". There is LOOPBACK flag for
lo:0 which is inherited from the device "lo". In Linux 2.2 all aliases
inherit the device flags. Only the IFF_UP flag is used to add/delete
the aliases.
			</para><para>
<blockquote><para>
Joe
			</para><para>
 Assume LVS-DR with VIP, RIPs all on the same /24 network on eth0 devices,
 realservers all have lo:0 with VIP/24 and have the standard 2.2.x kernel
 (no patches to hide interfaces). Router says "who has VIP", the arp
 request arrives at the realservers via eth0. Device lo:0 finds arp request
 which arrived on eth0 from router is on the same subnet as lo:0 and does
 not reply to the arp request.
</para></blockquote>
			</para><para>
        Before checking if to answer the ARP the routing tables are
checked, i.e. the source validation of the packet is performed. If
192.168.0.2 asks "who-has 192.168.1.1 tell 192.168.1.2" the realservers
assumes that this is invalid packet, i.e. from one local IP to another
local IP (from me to me => drop).
			</para><para>
<blockquote><para>
Joe
			</para><para>
 I notice that with the 2.2.x kernel, that lo:0 has to have
 netmask=255.255.255.255 to work, whereas with the 2.0.x kernels (where
 lo:0 doesn't reply to arp requests), that lo:0 can have the VIP on a
 255.255.255.0 netmask and still work.
</para></blockquote>
			</para><para>
        The rule is to use netmask 255.255.255.255 and to hide lo. The ARP
works in different way in 2.2. It looks the "local" table to validate the
source of the ARP request and after that it lookups the same table to
check if daddr of the ARP request is local ip.
			</para><para>
			</para><para>
ARP requests: - all local addresses can be used by the kernel to
        announce them as the source for the ARP request.
			</para><para>
<blockquote><para>
 is it OK to say
			</para><para>
 the kernel can (does?) use all local addresses as the source
 of ARP requests
</para></blockquote>
			</para><para>
        It can and does. The realserver thinks that it can use any local
ip address as saddr in the ARP request and the answer will be returned
back if this ip is uniq in the LAN.
			</para><para>
<blockquote><para>
Joe
			</para><para>
do you mean "the realserver will receive a reply if the s_addr is
 unique in the LAN"?
</para></blockquote>
			</para><para>
        The realserver will receive answer if it uses RIP as saddr in the
ARP request because the VIP(HIP) is hidden or when using transparent proxy
because it is not local (the VIP). Real server must know how to ask (using
uniq IP) or the trafic for the asked IP (ROUTER) will be blocked.
			</para><para>
But the hidden addresses are not used
because they are not uniq (2.2.14) and the answer will be returned to the
Director.
			</para><para>
<blockquote><para>
Joe
			</para><para>
do you mean "the non-hidden VIP on the director"?
</para></blockquote>
			</para><para>
        Yes, when the realserver ask "who-has ROUTER tell VIP" the ARP
reply is received in the Director and the transmission in the realservers
is stopped. The ROUTER sends everything destined to VIP to the Director.
This is true for all clients on the LAN too if they are not in this
cluster (if they don't handle packets for VIP).
			</para><para>
<blockquote><para>
Joe
			</para><para>
I would have thought that the main device on each NIC, eg eth0, eth1
would have been used as the source address.
</para></blockquote>
			</para><para>
        No, it is extracted from the outgoing datagram and if saddr is
local ip it is used. But if this is not local ip, i.e. when using
transparent proxy or the address is marked as hidden the main device ip
is used.
			</para><para>
<blockquote><para>
Joe
			</para><para>
how is arping part of transparent proxy?
</para></blockquote>
			</para><para>
        It is not. When VIP is not local IP address in the realserver
this IP is not used from the ARP code. It is not in the "local" table. But
TCP, UDP and ICMP use it via transparent proxy support.
			</para><para>
	They are extracted from the outgoing packet.
			</para><para>
<blockquote><para>
Joe
			</para><para>
what is "They"? the source addresses? When you say "extracted", do you
 mean "removed from packet" or "looked at/detected"
</para></blockquote>
			</para><para>
        The saddr from the data packet is used to build the ARP request.
			</para><para>
We tell the kernel
that these addresses are not uniq by setting
&lt;interface&gt;/hidden=1 (starting with kernel 2.2.14).
By this way the kernel select the devices primary IP
 as the source of the ARP request.
			</para><para>
<blockquote><para>
Joe
			</para><para>
the kernel can use any local address as s_addr but the
code for hiding IPs from arp requests prevents the
kernel from using hidden addresses as
s_addr in an arp request?
</para></blockquote>
			</para><para>
        Yes, the code to hide the addresses is already part of
the source address autoselection (saddr in the ARP request in
our case). We never autoselect hidden addresses, i.e. if the
source address is not specified from the higher level. The code
to hide interface:
			</para><para>
<programlisting><![CDATA[
- ignores ARP replies for hidden local addresses
- doesn't select hidden local addresses as source of the ARP request
- doesn't autoselect hidden local addresses for the IP level
]]></programlisting>
			</para><para>
<blockquote><para>
Joe
			</para><para>
When you say
&quot;We expect it is uniq in the LAN&quot;
do you mean -
we expect you've set up your network properly and that
you don't have the same RIP on 2 realservers? :-)
</para></blockquote>
			</para><para>
			</para><para>
			</para><para>
        The LVS administrator must ensure that the RIPs are
uniq, only the VIP is shared.
We tell the kernel that the VIP addresses are not uniq by setting
<emphasis>interface</emphasis>hidden=1 (2.2.14). By this way the kernel
select the devices primary IP as the source of the ARP
request. We expect it is uniq in the LAN.
			</para><para>
			</para><para>
So, the recommendation for using the "lo" interface in the real
servers is:
			</para><para>
- use netmask 255.255.255.255 when configuring lo alias. By this
way source validation doesn't drop the incoming packets to
this IP. LVS users usually define the net route through the eth
interface, so we can talk to other hosts from this network,
for example to send the packets to the client through the
default gateway. It is not needed to configure the alias with
mask != 255.255.255.255
			</para><para>
So, the interfaces which can be used in the realservers to
listen for VIP are:
			</para><para>
<programlisting><![CDATA[
- lo aliases with netmask 255.255.255.255
- tunl*
- dummy*
]]></programlisting>
			</para><para>
All these devices must be marked as hidden to solve the ARP
problem when using Linux 2.2.
			</para><para>
In the Director: there is no problem to configure the VIP
even on lo alias or dummy interface. If the interface is
not marked as hidden this VIP is visible for all hosts on
the LAN.
			</para><para>
	</para></section>
	<section id="ATM"><title>ATM/ethernet and router problems</title><para>
			</para><para>
LVS has only been tested on ethernet. One person had
an ATM setup which didn't work with LVS-DR as the ATM router
expects packets from the VIP to have the same MAC address
(in LVS-DR packets coming from the VIP could have the MAC
address of any of the realservers).
Apparently this is not easily fixable in the ATM world.
It should be possible to use Julian's
<xref linkend="martian_modification"/>
to make LVS-DR work on ATM, but the person with the ATM setup
disappeared off the mailing list without us convincing him
of the joy in having the first ATM LVS.
			</para><para>
Other people have found similar problems with ethernet -
			</para><para>
<blockquote><para>Kyle Sparger <emphasis>ksparger (at) dialtoneinternet (dot) net</emphasis>
			</para><para>
I don't know if someone has gone over this, but here's a consideration
I've come across when setting up LVS in DR mode:
			</para><para>
When the realservers reply, cisco routers (ours do, at least) will
pick up on the fact that it's replying from a different MAC address, and
will start arping soon thereafter.  This is sub-optimal, as it causes a
constant flood of arp requests on the network.  Our solution has been to
hardcode the MAC address into the router, but this can cause other issues,
for example during failover.  That can be worked around, as you can set
the MAC address on most cards, but that in itself may cause other issues.
			</para><para>
Has anyone else experienced this?  Has anyone else come up with a better
solution than hardcoding it into the router?
</para></blockquote>
			</para><para>
It should be possible to have the reply packets from the VIP come from
a virtual MAC address (such as created by <link linkend="keepalived_vrrpd">vrrpd</link>),
in which case all replies coming to the same port in a router from the VIP
will have the same MAC address. No-one seems to be interested in writing
the code to do this.
			</para><para>
	</para>
	</section>
	<section id="same_ip_on_multiple_nics">
	<title>Same IP on multiple NICs</title>
	<para>
			</para><para>
<blockquote><para>Bonnet <emphasis>Sebastien (dot) Bonnet (at) experian (dot) fr</emphasis> 2002-04-16
			</para><para>
I'm setting up with LVS-DR.
To allow a node to be both a
realserver and a backup director,
I have eth0:2 being the VIP, because at this point,
"backup-and-node" is the director. But when it's not, I still need VIP to be
setup on lo:1 to use "backup-and-node" as a realserver.
I end up with the following config :
			</para><para>
<programlisting><![CDATA[
[root@backup-and-node root]# cat /proc/sys/net/ipv4/conf/all/hidden 1
[root@backup-and-node root]# cat /proc/sys/net/ipv4/conf/lo/hidden 1
[root@backup-and-node root]# cat /proc/sys/net/ipv4/conf/eth0/hidden 0

[root@backup-and-node root]# ifconfig
eth0    Link encap:Ethernet  HWaddr 00:40:05:5C:C2:04
        inet addr:172.22.48.208  Bcast:172.22.63.255  Mask:255.255.240.0
        UP BROADCAST RUNNING MULTICAST  MTU:1500  Metric:1

eth0:2  Link encap:Ethernet  HWaddr 00:40:05:5C:C2:04
        inet addr:172.22.48.212  Bcast:172.22.63.255  Mask:255.255.240.0
        UP BROADCAST RUNNING MULTICAST  MTU:1500  Metric:1

lo      Link encap:Local Loopback
        inet addr:127.0.0.1  Mask:255.0.0.0
        UP LOOPBACK RUNNING  MTU:16436  Metric:1

lo:1    Link encap:Local Loopback
        inet addr:172.22.48.212  Mask:255.255.255.255
        UP LOOPBACK RUNNING  MTU:16436  Metric:1
]]></programlisting>
The problem is that when VIP is setup on both lo:1 and eth0:2,
"backup-and-node" will not answer *any* ARP request for VIP, whereas it
should via eth0 (as far as I understand the purpose of the hidden feature).
			</para><para>
</para></blockquote>
Julian
			</para><para>
        The problem is that this setup is ambigous. The kernel doesn't
know what device you are using for primary and for secondary IPs.
Device lo is a valid device for primary IPs. It is not allowed to
define one IP both as primary and secondary one.
        Yes, lo is first in the device list and we search for hidden
IP in _any_ device. We don't have a preferred device to start from.
        Yes, this is limitation that nobody wants to fix. Someone
will have to persuade me with a clear fix for this.
			</para><para>
			</para><para>
Joe
<blockquote><para>
I'm surprised you're allowed to have the same IP on two different devices.
Is there a reason why you'd want to do this or is it just not
forbidden and therefore allowed (I beleive this is called the American
philosophy).
</para></blockquote>
			</para><para>
Horms
			</para><para>
It is actually something you may want to do.
Imagine you have a dialup server, 192.168.0.1, which sits on the
192.168.0.0/24 network.  Now each dialup user is going to get their own ip
address, but 192.168.0.0/24 is your server network, so these ip addresses
are on a different network, lets say 10.0.7.0/24. Now when the dailup users
come in, there is no need for the dialup-server to have an address on the
10.0.7.0/24 network, it is just a point to point link, so you can have for
instance.
			</para><para>
<programlisting><![CDATA[
[client]<-------->[dialup-server]
10.0.7.7          192.168.0.1
ppp0              ppp0
]]></programlisting>
			</para><para>
But the dialup-server already has 192.168.0.1 on eth0. Thus you have the
same IP address on multiple interfaces. In fact it would have the same IP
address on eth0 and each of the ppp interfaces.
	</para>
	</section>
</section>
<section id="LVS-HOWTO.LVS-DR" xreflabel="LVS-DR">
<title>LVS: LVS-DR</title>
<para>
LVS-DR is based on IBM's NetDispatcher. The NetDispatcher sits in
front of a set of webservers, which appear as one webserver to
the clients. The NetDispatcher served http for the Atlanta and the Sydney
Olympic games and for the chess match between Kasparov and Deep
Blue.
</para>
<para>
When the packet CIP->VIP arrives at the director it is put into the
OUTPUT chain as a layer 2 packet with dest = MAC address of the realserver.
This bypasses the routing problem of a packet with dest = VIP, where
the VIP is local to the director.
When the packet arrives at the realserver, which finds the packet
addressed to an IP local to the realserver (the VIP).
</para>
	<section id="lvs_dr_example" xreflabel="LVS-DR example">
	<title>LVS-DR example</title>
	<para>
Here's an example set of IPs for a LVS-DR setup. 
In this example, the RIPs are on the same network as the VIP
(a one network LVS-DR). 
In this example, for (my) convenience, the servers are
on the same network as the router connecting to the client 
and you have to handle the arp problem 
(I used the <command>arp -f /etc/ethers</command> approach).
	</para>
<programlisting><![CDATA[
Host                         IP
client                       CIP=192.168.1.254
director                     DIP=192.168.1.1
virtual IP (VIP)             VIP=192.168.1.110 (arpable, IP clients connect to)
realserver1                  RIP1=192.168.1.2, VIP=192.168.1.110 (lo:0, not arpable)
realserver2                  RIP2=192.168.1.3, VIP=192.168.1.110 (lo:0, not arpable)
realserver3                  RIP3=192.168.1.4, VIP=192.168.1.110 (lo:0, not arpable)
.
.
realserver-n                 192.168.1.n+1
]]></programlisting>
	<para>
	</para>
<programlisting><![CDATA[
#lvs_dr.conf
LVS_TYPE=VS_DR
INITIAL_STATE=on
VIP=eth0:110 lvs 255.255.255.255 192.168.1.110
DIP=eth0 dip 192.168.1.0 255.255.255.0 192.168.1.255
DIRECTOR_DEFAULT_GW=client
SERVICE=t telnet rr realserver1 realserver2 realserver3
SERVER_VIP_DEVICE=lo:0
SERVER_NET_DEVICE=eth0
SERVER_DEFAULT_GW=client
#----------end lvs_dr.conf------------------------------------
]]></programlisting>
	<para>
	</para>
<programlisting><![CDATA[
                           ________
                          |        |
                          | client |
                          |________|
                          CIP=192.168.1.254
                              |
                   CIP->VIP | |
                            v |
                              |
                           ________
                          |        |
                          | router | advertises route to VIP
                          |________|
                              |
                __________    |
               |          |   |    VIP=192.168.1.110 (eth0:1, arps)
               | director |---     DIP=192.168.1.1 (eth0)
               |__________|   |
                              |  ^
MAC_DIP->MAC_RIP1(CIP->VIP) | |  |  VIP->CIP
                            v |
                              |
             -------------------------------------
             |                |                  |
             |                |                  |
      RIP1=192.168.1.2  RIP2=192.168.1.3  RIP3=192.168.1.4 (eth0)
      VIP=192.168.1.110 VIP=192.168.1.110 VIP=192.168.1.110 (all lo:0, non-arping)
      _____________     _____________      _____________
     |             |   |             |    |             |
     |   CIP->VIP  |   |             |    |             |
     |   VIP->CIP  |   |             |    |             |
     | realserver  |   | realserver  |    | realserver  |
     |_____________|   |_____________|    |_____________|
]]></programlisting>
	<para>
Here's the lvs_dr.conf file
	</para>
<programlisting><![CDATA[
#--------------------lvs_dr.conf
LVS_TYPE=VS_DR
INITIAL_STATE=on

#director setup
VIP=eth0:12 192.168.1.110 255.255.255.255 192.168.1.110
DIP=eth0 192.168.1.10 192.168.1.0 255.255.255.0 192.168.1.255
#service setup, one service at a time
SERVICE=t telnet rr 192.168.1.1 192.168.1.8 127.0.0.1

#realserver setup
SERVER_LVS_DEVICE=lo0:1
SERVER_NET_DEVICE=eth0

#----------end lvs_dr.conf------------------------------------
]]></programlisting>
	<para>
Here's how you'd set up a two-network LVS-DR.
Note that the router receives packets on port R from both the RIP and VIP, 
which are in different networks.
Once you've solved the arp problem, 
the router will send packets to the VIP only on port D.
	</para>
<programlisting><![CDATA[
                           ________
                          |        |
                          | client |
                          |________|
                          CIP=192.168.1.254
                              |
                   CIP->VIP | |
                            v |
                              |
                           ________
                          |        | R
                          | router |------------- 
                          |________|             | 
                              | D                |
                              |                  |
                 VIP=192.168.1.110 (eth0:1, arps)|
                          __________             |
                         |          |            |
                         | director |            |
                         |__________|            |
                        DIP=10.0.1.1 (eth1)      | 
                              |                  |  ^             
MAC_DIP->MAC_RIP1(CIP->VIP) | |                  |  |  VIP->CIP 
                            v |                  |
                              |                  |
             -------------------------------------
             |                |                  |
             |                |                  |
      RIP1=10.0.1.2     RIP2=10.0.1.3     RIP3=10.0.1.4 (eth0)
      VIP=192.168.1.110 VIP=192.168.1.110 VIP=192.168.1.110 (all lo:0, non-arping)
     ______________     _____________      _____________
    |              |   |             |    |             |
    |lo:  CIP->VIP |   |             |    |             |
    |eth0:VIP->CIP |   |             |    |             |
    | realserver   |   | realserver  |    | realserver  |
    |______________|   |_____________|    |_____________|
]]></programlisting>
	<para>
LVS-DR setup and testing is the same as LVS-Tun except
that all machines within the LVS-DR (ie the director and
realservers) must be on the same segment (be able to arp each other). 
This means that there must be no forwarding devices between them
<emphasis>i.e.</emphasis> they are using the same piece of
transport layer hardware ("wire"), eg RJ-45, coax, fibre
(there can be hub(s) or switch(es) in this mix). 
Communication within the LVS is by link-layer, 
using MAC addresses rather than IP's. 
All machines in the LVS have the VIP:
only the VIP on the director replies to arp requests, 
the VIP on the realservers must be on a non-arping device (eg lo:0, dummy).
	</para>
	<para>
The restrictions for LVS-DR are
	</para>
	<itemizedlist>
		<listitem>
The client must be able to connect to the VIP on the director
		</listitem>
		<listitem>
Realservers and the director must be on the same segment (piece of wire)
(they must be able to arp each other) as packets are sent by
link-layer from the director to the realservers.
		</listitem>
		<listitem>
The route from the realservers to the client _cannot_ go
through the director, <emphasis>i.e.</emphasis> 
the director cannot be the default gw for the realservers. 
(Note: the client does not 
connect directly to the the realservers for the LVS to function. The
realservers could be behind a firewall, but the realservers
must be able to send packets to the client). 
The return packets, from the realservers to the client, go directly from the
realservers to the client and _do_not_ go back through the
director. For high throughput, each realserver can have its own
router/connection to the client/internet and return packets need
not go through the router feeding the director.
		</listitem>
	</itemizedlist>
	<para>
For more info
see e-mail postings about LVS-DR topologies in the section
<link linkend="topology">More on the arp problem and topologies of LVS-DR and LVS-Tun LVS's</link>.
	</para>
	<para>
To allow the director to be the default gw for the
realservers (<emphasis>e.g.</emphasis> when the director is the firewall), see
<xref linkend="martian_modification"/>.
	</para>
	<para>
Note for LVS-DR (and LVS-Tun), the services on the realservers
are listening to the VIP. You can have the service listening
to the RIP as well, but the LVS needs the service to be
listening to the VIP. This is not an issue with services
like telnet which listen to all local IPs (ie 0.0.0.0), but httpd is set
up to listen to only the IPs that you tell it.
	</para>
	<para>
Normally for LVS-DR, the client is on a different network to the
director/server(s), and each realserver has its own route to the
outside world. In the simple test case below, where all machines
are on the 192.168.1.0 network, no routers are required, and the
return packets, instead of going out (the router(s)) at the bottom
of the diagram, would return to the client via the network device
on 192.168.1.0 (presumably eth0).
	</para>
	</section>
	<section id="lvs_dr_how_it_works" xreflabel="LVS-DR how it works">
	<title>How LVS-DR works</title>
	<para>
Here's part of the rc.lvs_dr script which configures the realserver
with RIP=192.168.1.8
	</para>
<programlisting><![CDATA[
#setup servers for telnet, LVS-DR
director:/etc/lvs# /sbin/ipvsadm -A -t 192.168.1.110:23 -s rr
director:/etc/lvs# echo "adding service 23 to realserver 192.168.1.6 "
director:/etc/lvs# /sbin/ipvsadm -a -t 192.168.1.110:23 -R 192.168.1.6 -g -w 1
]]></programlisting>
	<para>
There's no forwarding in the conventional sense for LVS-DR
(ip_vs does the forwarding on the director of the LVS packets).
You can have <filename>ip_forward</filename> set to ON if you
need it for something else, but LVS_DR doesn't need in ON.
If you don't have a good reason to have it ON, then for security turn it OFF.
For more explanation see <xref linkend="ipvs_for_netfilter"/>
	</para>
<programlisting><![CDATA[
#set ip_forward OFF for lvs-dr director (1 on, 0 off)
cat       /proc/sys/net/ipv4/ip_forward
echo "0" >/proc/sys/net/ipv4/ip_forward
]]></programlisting>
	<para>
With LVS-DR, the target port numbers of incoming packets cannot be remapped (unlike LVS-NAT). 
A request to port 23 (telnet) on the VIP will be forwarded to port 23 on a realserver, 
thus the RIP entry for the realserver in <command>ipvsadm</command> has no accompanying port.
You can however re-map ports with <command>iptables</command> (see <xref linkend="re-mapping_ports_lvs_dr"/>).
	</para>
	<para>
Here's the packet headers as the request is processed by the LVS.
	</para>
<programlisting><![CDATA[
packet                  source        dest         data
1. request from client  CIP:3456      VIP:23       -
2. ipvsadm table:
   director chooses server=RIP1, creates link-layer packet
                        MAC of DIP    MAC of RIP1  IP datagram
                                                   source=CIP:3456,
                                                   dest=VIP:23,
                                                   data= -
3. realserver recovers IP datagram
                        CIP:3456      VIP:23       -
4. realserver looks up routing table, finds VIP is local,
   processes request locally, generates reply
                        VIP:23        CIP:3456     "login:"

5. packet leaves realserver via its default gw, not via DIP.
]]></programlisting>
	<para>
For the verbally oriented...
	</para><para>
A packet arrives from the client for the VIP (CIP:3456->VIP:23).
The director looks up its tables and decides to send the connection
to realserver_1. The director arps for the MAC address of RIP1 and
sends a link-layer packet to that MAC containing an IP datagram with
CIP:3456->VIP:23. This is the same src:dst as the incoming packet
and the tcpip layer see this as a forwarded packet. To allow this
packet to be sent to the realserver, it is not neccessary for
forwarding must be on in the director
(it is turned off by default in 2.2.x, 2.4.x kernels - turning it
on is handled by the configure script).
	</para><para>
The packet arrives at realserver_1. The realserver
recovers the IP datagram, looks up its routing table, finds that
the VIP (on an otherwise unused, non-arping and nonfunctional
device) is local.
	</para><para>
I'm not sure what exactly happens next, but I believe the Linux
tcpip stack then delivers the packet to the socket listeners,
rather than to the device with the VIP,
but I'm out of my depth now.
	</para><para>
The realserver now has a packet CIP:3456->VIP:23,
processes it locally, constructs a reply, VIP:23->CIP:3456.
The realserver looks up its routing table and
sends the reply out its default gw to the internet (or client). The
reply does not go through the director.
	</para><para>
The role of LVS-DR is to allow the director to deliver a packet
with dst=VIP (the only arp'ing VIP being on the
director), not to itself, but to some machine that (as far as the
director knows) doesn't have the VIP address at all. The only
difference between LVS-DR and LVS-Tun is that instead of putting
the IP datagram inside a link-layer packet with dst=MAC
of the RIP, for LVS-Tun the IPdatagram from the client CIP->VIP
is put inside another IPdatagram DIP->RIP.
	</para><para>
The use of the non-arping lo:0 and tunl0 to hold the VIP for
LVS-DR and LVS-Tun (respectively) is to
allow the realserver's routing table to have an entry for a local
device with IP=VIP _AND_ that so that other machines can't see
this IP (ie it doesn't reply to arp requests). There is nothing
particularly loopback about the lo:0 device that is required to
make LVS-DR work anymore than there is anything tunnelling about a
tunl0 device. For 2.0.x kernels, a tunnel packet is de-capsulated
because it is marked type=IPIP, and will be decapsulated if delivered
to an lo device just as well as if delivered to a tunl device.
The 2.2.x kernels are more particular and need a tunl device (see
"Properties of devices for VIP").
	</para>
	</section>
	<section id="lvs_dr_arp_problem">
	<title>Handling the arp problem for LVS-DR</title>
		<section id="lvs_dr_vip_on_lo:0"><title>VIP on lo:0</title><para>
The VIP on the realservers must not reply to arp requests from
the client (or from the router between the client and the director).
			</para>
			<section id="lvs_dr_2.2_realservers">
			<title>Realservers with Linux 2.2.x kernels</title><para>
The loopback device does not arp by default for all OS's except
Linux 2.2.x,2.4.x kernels (even when you use -noarp with ifconfig). You
may need to do something if you are running a realserver with a
2.2.x or 2.4.x kernel (see the <xref linkend="LVS-HOWTO.arp_problem"/>).
			</para></section>
		</section>
		<section id="Lars_method" xreflabel="Lars' method">
		<title>Lars' method</title>
		<para>
This requires hiding the VIP on the realservers,
by putting them on a separate network.
			</para><para>
Lars set this up first on LVS-Tun. Here it is for LVS-DR. The director
has 2 NICs and the realservers are on a different network
(10.1.1.0/24) to the VIP (192.168.1.0/24). All IPs reply to arps.
The router/client cannot route to the realserver network and the
RIPs do not need to be internet routable. Since the director
has 2 NICs, in the lvs_dr.conf file, set the DIP to eth1.
			</para><para>
<programlisting><![CDATA[
                        ________
                       |        |
                       | client |
                       |________|
                       CIP=192.168.1.254
                           |
                        (router)
                           |
                 VIP=192.168.1.110 (eth0, arps)
                      __________
                     |          |
                     | director |
                     |__________|
                     DIP=10.1.1.1 (eth1, arps)
                           |
                           |
          -------------------------------------
          |                |                  |
          |                |                  |
   RIP1=10.1.1.2     RIP2=10.1.1.3     RIP3=10.1.1.4 (eth0)
   VIP=192.168.1.110 VIP=192.168.1.110 VIP=192.168.1.110 (all lo:0, can arp)
   _____________     _____________      _____________
  |             |   |             |    |             |
  | realserver  |   | realserver  |    | realserver  |
  |_____________|   |_____________|    |_____________|
          |                |                  |
      (router)          (router)           (router)
          |                |                  |
          ----------------------------------------------> to client
]]></programlisting>
		</para></section>
		<section id="lvs_dr_TP">
		<title>Transparent Proxy (TP or Horms' method) - not having the VIP on the realserver at all.</title>
		<para>
The subject of <xref linkend="LVS-HOWTO.transparent_proxy"/> has it's own section.
		</para>
		</section>
	</section>
	<section id="lvs_dr_scales_well">
	<title>LVS-DR scales well</title>
	<para>
Performance tests (75MHz pentium classics, on 100Mbps network) 
with LVS-DR on the
<ulink url="http://www.linuxvirtualserver.org/Joseph.Mack/performance/single_realserver_performance.html">
performance page</ulink>
(http://www.linuxvirtualserver.org/Joseph.Mack/performance/single_realserver_performance.html)
showed the rate limiting step for LVS-DR director forwarding packets to the realservers.
LVS doesn't add any detectable latency or change the throughput of forwarding.
There is little load on the director operating at high throughput
in LVS-DR mode. Apparently little computation is involved in forwarding.
	</para>
	<para>
In the early days of LVS, we expected the director in LVS-DR to be lightly
loaded because it was receiving only small packets from the client 
(<emphasis>e.g.</emphasis> <command>get index.html</command> 
or <command>get largefile.tar.gz</command>) 
while the realservers were delivering the large files to the client
via their router. 
We expected that the fan-out (number of realservers handled
by a director) would be in the ratio of the filesize
sent to the client compared to the requestsize from the client.
It is true that the measured bandwidth coming in to the director
is smaller than the output from the realservers.
	</para>
	<para>
Francois JEANMOUGIN <emphasis>Francois (dot) JEANMOUGIN (at) 123multimedia (dot) com</emphasis> 
06/06/2005
	</para>
	<blockquote>
		<para>
I have 38 realservers behind my director, incoming traffic (to director) goes up to 20Mb/s, 
outgoing (from realservers LVS-DR setup) up to 60Mb/s. 
I have about 1200 sites hosted. 
36 virtual_server entries in keepalived.conf, 30 VIPs.
There's no noticable load on the poor PIII/700 director that's handling the traffic.
		</para>
	</blockquote>
	<para>
However we have since realised that network hardware 
is specified in packets/sec and not Mbps
(see <xref linkend="8000pps"/>) and that every outgoing packet from a realserver
is matched by an incoming packet to the director (possibly just an &lt;ack&gt;).
The director then is passing the same number of network packets as
all the realservers together.
Once the incoming network traffic to the director reaches 8000pps 
(for 100Mbps FE), the director is saturated.
LVS-DR does get good fan-out 
(one director supporting many realservers)
but the reason is not the one we originally thought.
The good fan-out is because the director only has to handle network traffic, 
while a realserver may have to go to disk or to compute
before it can produce its packets.
The fan-out then is the ratio of time that the realservers
need to produce the packet payload,
compared to the time it takes to transmit them.
	</para>
	</section>
	<section id="LVS-DR_director_default_gw" xreflabel="julians_martian_modification">
	<title>LVS-DR director as default gw for realservers, transparent proxy and Julian's martian and forward_shared patches</title>
	<para>
In the case where the director is the firewall for the realserver
network, the director has to be the default gw for the realservers.
The reply packet from the realserver to the client
(VIP->CIP) then goes through the director
(which has a device with IP=VIP).
The director then is being asked to route a packet
from outside, that has a src address that is on the director.
Normally this is not allowed and such illegal
packets are called martians.
	</para>
	<para>
Here's from <ulink url="http://www.arin.net/library/rfc/rfc1812.txt">rfc1812</ulink>
from Ken Chase <emphasis>math (at) velocet (dot) ca</emphasis> 14 May 2003,
posting to the beowulf mailing list.
	</para>
<programlisting><![CDATA[
1609 martian_source:
1610
1611         rt_cache_stat[smp_processor_id()].in_martian_src++;
1612 #ifdef CONFIG_IP_ROUTE_VERBOSE
1613         if (IN_DEV_LOG_MARTIANS(in_dev) && net_ratelimit()) {
1614                 /*
1615                  *      RFC1812 recommendation, if source is martian,
1616                  *      the only hint is MAC header.
1617                  */
1618                 printk(KERN_WARNING "martian source %u.%u.%u.%u from "
1619                         "%u.%u.%u.%u, on dev %s\n",
1620                         NIPQUAD(daddr), NIPQUAD(saddr), dev->name);
1621                 if (dev->hard_header_len) {
1622                         int i;
1623                         unsigned char *p = skb->mac.raw;
1624                         printk(KERN_WARNING "ll header: ");
1625                         for (i = 0; i < dev->hard_header_len; i++, p++) {
1626                                 printk("%02x", *p);
1627                                 if (i < (dev->hard_header_len - 1))
1628                                         printk(":");
1629                         }
1630                         printk("\n");
1631                 }
1632         }
1633 #endif
1634         goto e_inval;
1635 }
1636


5.3.7 Martian Address Filtering

   An IP source address is invalid if it is a special IP address, as
   defined in 4.2.2.11 or 5.3.7, or is not a unicast address.

   An IP destination address is invalid if it is among those defined as
   illegal destinations in 4.2.3.1, or is a Class E address (except
   255.255.255.255).

   A router SHOULD NOT forward any packet that has an invalid IP source
   address or a source address on network 0.  A router SHOULD NOT
   forward, except over a loopback interface, any packet that has a
   source address on network 127.  A router MAY have a switch that
   allows the network manager to disable these checks.  If such a switch
   is provided, it MUST default to performing the checks.

   A router SHOULD NOT forward any packet that has an invalid IP
   destination address or a destination address on network 0.  A router
   SHOULD NOT forward, except over a loopback interface, any packet that
   has a destination address on network 127.  A router MAY have a switch
   that allows the network manager to disable these checks.  If such a
   switch is provided, it MUST default to performing the checks.

   If a router discards a packet because of these rules, it SHOULD log
   at least the IP source address, the IP destination address, and, if
   the problem was with the source address, the physical interface on
   which the packet was received and the Link Layer address of the host
   or router from which the packet was received.

  Martian Filtering
        A packet that contains an invalid source or destination address
        is considered to be martian and discarded.
]]></programlisting>
	<para>
Horms <emphasis>horms (at) vergenet (dot) net</emphasis>>
	</para>
	<blockquote>
The problem is that with Direct routing the reply from the real
server has the vip as the source address. As this is an address
of one of the interfaces on the director it will drop it if you
try and forward it through the director. It appears from
experimentation with /proc/sys/net/ipv4/conf/*/rp_filter
that at least on 2.2.14, there is no way to turn this behaviour
off. (for more info on rp_filter see the
<xref linkend="proc_filesystem"/>.)
	</blockquote>
	<para>
This type of packet is called a "source martian" and is dropped by
the director. martians can be logged with
	</para>
<programlisting><![CDATA[
# echo 1 >/proc/sys/net/ipv4/conf/all/log_martians
]]></programlisting>
	<para>
There are 3 solutions to this; 2 by Julian and 1 by Horms.
	</para>
		<section id="lvs_dr_director_1_nic_TP">
		<title>Director has 1 NIC, accepts packets via transparent proxy.</title>
		<para>
If the director accepts packets for the VIP via transparent proxy,
then the director doesn't have the VIP and the return packets are
processed normally. (Note: transparent proxy only works on the director
for 2.2.x kernels - update early 2003, patches are now available for
2.4.x kernels).
		</para>
		<para>
Here's Julian's posting
		</para>
<programlisting><![CDATA[
                Clients
                   |
                  ISP
                   |eth0/ppp0/...
                Router/Firewall/Director (LVS box)
                   |eth1
        +----------+------------+
        |eth0                   |eth0
        Real 1                  Real2
]]></programlisting>
		<para>
Router: transparent proxy for VIP (or all served VIPs).
The ISP must feed your Director with packets for your subnet 199.199.199.0/24
LVS-DR mode (Yes, LVS-DR, this is not a mistake).
eth1: 199.199.199.2.
default gw is ISP.
		</para>
		<para>
Real server(s): nothing special.
VIP on hidden device or via transparent proxy.
eth0: 199.199.199.3.
default gateway is 199.199.199.2 (the Director)
		</para>
		<para>
        This is a minimum required config. You can add internal subnets
yourself using the same physical network (one NIC) or by adding additional
NICs, etc. They are not needed for this test.
		</para><para>
        Packets from the realservers with saddr=VIP will be forwarded
from the director because VIP is not configured in the Director. We expect
that this setup is faster than VS/NAT.
		</para>
		</section>
		<section id="martian_modification" xreflabel="martian modification">
		<title>Julian's martian modification (forward_shared)</title>
		<para>
In normal LVS-DR, the packets returning from the realservers 
(which have a src_addr=VIP) are routed to anywhere but the director.
Normally packets with scr_addr=VIP are rejected as source martians on the
director, because the director has the VIP as a local IP.
The martian modification patch allows the director to be the default gw
for packets from the realservers.
Since packets with src_addr are now allowed from the realserver, 
spoofed packets from the outside, with src_addr=VIP, must be disallowed
(you can use filter rules in combination with the name of the NIC connecting to the router
- assuming it's a different NIC to the one connecting to the realservers).
		</para>
		<para>
The original name I gave this patch is "martian modification". 
Julian's name for it is "forward_shared". Both names are used
in the HOWTO.
		</para>
		<para>
To download the patches and to read Julian's notes
on using the director as a gateway for realserver in 
LVS-DR/Tun, see <ulink url="http://www.ssi.bg/~ja/#lvsgw">
LVS director as gateway in Direct Routing and Tunnel Setups</ulink>.
(The dates on the files are the creation dates, not the last modified.
Thus the file for the 2.4.26 kernel, current in May 2004, has a date
in 2001.)
		</para>
		<note>
(see <link linkend="LVS-DR_director_default_gw">
earlier for an explanation of &quot;source martians&quot;
</link>.)
		</note>
		<para>
Also see <xref linkend="LVS-HOWTO.transparent_bridging"/> for an alternate
solution to the martian problem.
		</para>
		<para>
The martian modification is currently (since Aug 2001) implemented with the
<ulink url="http://www.ssi.bg/~ja/">
hidden-forward_shared-xxx.diff patch</ulink>.
This patch has the hidden (for realservers) and forward_shared (for directors)
patch and can be applied to both realservers and directors.
(Remember for the director you need the ipvs patch too).
The forward_shared patch will not be going into the kernel code
(you'll always have to apply the patch) as some kernel people
don't like the idea of allowing source martin packets.
		</para>
		<para>
This is a kernel patch, director has 2 NICs
(doesn't work with one NIC), VIP is on outside NIC.
		</para>
		<para>
        After applying the patch, for a test, use the default
values for */rp_filter(=0). This allows realservers to send
packets with saddr=VIP and daddr=client through the Director.
		</para>
		<para>
        If the patch is applied and external_eth/rp_filter is
0 (which is the default) the realservers can receive packets
with saddr=any_director_ip and dst=any_RIP_or_VIP which is not
very good. On the external net, set rp_filter=1 for better
security.
		</para>
		<para>
Here's the test setup
		</para>
<programlisting><![CDATA[
             ____________
            |            |
            |  client    |
            |____________|
                  |
                  |  192.168.2.0/24
             _____|______
            |            |
            |  director  | LVS-DR director has 2 NICs
            |____________|
                  | eth0    192.168.1.9
                  | eth0:12 192.168.1.1
                  |
                  |  192.168.1.0/24
             _____|____________________
            |
            |
       _____|__________
      |                |
      | realserver(s)  | default gw=192.168.1.1
      |________________|
]]></programlisting>
		<para>
192.168.1.1 is the normal router. For the test it was put on the
director instead (as an alias). The director has 2 NICs, with forwarding=on
(client and realservers can ping each other).
		</para>
		<para>
Director runs linux-0.9.8-2.2.15pre9 unpatched or with Julian's patch.
LVS is setup using the configure script,
redirecting telnet, with rr scheduling to 3 realservers.
The realservers were running 2.0.36 (1) or 2.2.14 (2).
The arp problem was handled for the 2.2.14 realservers by permanently
installing in the client's arp table,
the MAC address of the NIC on the outside of the director,
using the command <command>arp -f /etc/ethers</command>.
		</para>
		<para>
The director was booted 4 times, into unpatched, patched, unpatched and
patched. After each reboot the lvs scripts were run on the director and
the realservers, then the functioning of the LVS tested by telnet'ing
multiple times from the client to the VIP.
		</para>
		<para>
For the unpatched kernel, the client connection hung and inactive connections
acccumulated for each realserver. For the patched kernel, the client
telnet'ed to the VIP connecting with each realserver in turn.
		</para>
		<para>
The configure script
will set up the modified LVS-DR
(and will warn you that you need the patch for this to work).
Setup details are in
<ulink url="http://www.linuxvirtualserver.org/Joseph.Mack/performance/single_realserver_performance.html">performance page</ulink>
		</para>
			<section id="lvs_dr_martian_modification">
			<title>Martian modification performance</title>
			<para>
Performance has similar latency to LVS-NAT but the load is low on the director
at high throughput of LVS-DR (see the
<ulink url="http://www.linuxvirtualserver.org/Joseph.Mack/performance/single_realserver_performance.html">performance page</ulink>).
			</para>
			</section>
			<section id="lvs_dr_martian_modification_questions">
			<title>questions</title>
			<para>
<emphasis>mstockda (at) logicworks (dot) net</emphasis>
			</para>
			<blockquote>
Which interfaces need forward_shared?
the interface on the realserver lan _and_ the external side?
			</blockquote>
			<para>
Julian Anastasov <emphasis>ja (at) ssi (dot) bg</emphasis> 15 Mar 2002
			</para>
			<para>
	No, you just enabled the feature which works only for the
already selected interfaces. Check it with
			</para>
<programlisting><![CDATA[
ip route get from VIP to 1.2.3.4 iif CHECK_ALL_INTERFACES_HERE
]]></programlisting>
			<para>
	You should enable forward_shared only for interfaces
attached to internal mediums (hubs) and of course, only where
is needed.
			</para>
<programlisting><![CDATA[
#define IN_DEV_FORWARD_SHARED(in_dev)   ((in_dev)->cnf.forward_shared && ipv4_devconf.forward_shared)
]]></programlisting>
			</section>
		</section>
		<section id="TP_Bridging">
		<title>LVS-DR director as default gw by bridging: the difference between "transparent proxy" and "proxy arp"</title>
		<para>
proxy arp and bridging were discussed in the early days of LVS
as a way of allowing the director to be the default gw for LVS-DR.
The subject came up again in a thread on another topic.
Also see <xref linkend="LVS-HOWTO.transparent_bridging"/>.
		</para>
		<para>
Nicolas Chiappero <emphasis>Nicolas (dot) Chiappero (at) estat (dot) com</emphasis> 28 Jan 2003
		</para>
		<blockquote>
Is "proxy arp" and "transparent proxy" the same thing?
		</blockquote>
		<para>
Joe
		</para>
		<para>
Both allow routing of packets in ways not allowed by the normal routing tables.
TP allows a machine to accept (rather than forward) packets
for which it is not the destination. This originally was written
so that a local squid would accept packets destined for a remote
httpd server.
		</para>
		<para>
proxy arp, allows a host to reply to arp requests, telling the requestor
that it has an IP locally, when in fact the IP is on another machine.
This is useful to alter routing (eg for transparent bridging).
		</para>

		<para>
Julian
		</para>
		<para>
- proxy ARP is used when the traffic should be routed at Layer 3
with the help from ARP. The packets reach the routing after the
box answers ARP probes asking for foreign addresses.
		</para>
		<para>
- transparent proxy has mostly Layer 5-7 semantic, it is used
to intercept traffic destined to foreign addresses and to deliver
it to sockets.
		</para>
		<blockquote>
 - If so, I found a document (http://www.sjdjweis.com/linux/proxyarp/)
 explaining how to do proxy arp on a 2.4 kernel. Will this method
 be compatible with LVS as long as director would also be the default
 GW for realservers?
		</blockquote>
		<para>
	No. The spoofing checks performed from routing will drop
the traffic.
		</para>
		<itemizedlist>
			<listitem>
			<para>
		<emphasis role="bold">Linux Bridging</emphasis>
			</para>
			<para>
Here, the traffic from realservers to the ROUTER passes only Layer 2,
<emphasis>i.e.</emphasis> the routing
is not reached and you avoid the spoofing checks.
			</para>
			</listitem>
			<listitem>
			<para>
		<emphasis role="bold">forward shared</emphasis>
			</para>
			<para>
If you don't
want Bridging or the link to the ROUTER is not ARP aware, then
you can use solutions that avoid the spoofing checks for this
traffic. One of them is the forward_shared flag (Solution 2).
			</para>
			<para>
	With the forward_shared patch applied and with eth1
as the private interface, in the forward_shared directory of
the /proc filesystem you set
<programlisting><![CDATA[
all/forward_shared = 1
eth1/forward_shared = 1
]]></programlisting>
			</para>
			</listitem>
		</itemizedlist>
		</section>
		<section id="why_forward_shared_not_in_kernel">
		<title>Why the forward_shared patch is not in the kernel</title>
		<para>
Julian 16 Nov 2006
		</para>
		<para>
Pros:
		</para>
		<itemizedlist>
			<listitem>
saves one extra patching
			</listitem>
		</itemizedlist>
		<para>
Cons:
		</para>
		<itemizedlist>
			<listitem>
useful only for setups which share IPs
			</listitem>
			<listitem>
very dangerous!!! That was the first concern by Alexey Kuznetsov.
I see people blindly use <command>echo 1 > all/VAR_NAME</command> 
without considering
what is the relation between <filename>all/VAR_NAME</filename> and 
<filename>DEV_NAME/VAR_NAME</filename>.
I saw this many times. 
<filename>forward_shared</filename> should be applied only on trusted interfaces and setting 
<filename>1</filename> to <filename>all/</filename> opens the door for spoofing/loop attacks.
			</listitem>
			<listitem>
it is another hack in routing. 
Not sure if all changes are entirely correct.
			</listitem>
		</itemizedlist>
		<para>
So, my opinion is 30% (below 50%) for inclusion. May be it is a good idea 
to have one diff with all IPVS patches not included in mainline. Then the 
IPVS users will have to patch only once. Now we even don't have this 
option linked to visible place in web.
		</para>
		</section>
	</section>
	<section id="lvs_dr_fwmarks">
	<title>Accepting packets on LVS-DR director by fwmarks</title>
	<para>
Horms <xref linkend="LVS-HOWTO.fwmark"/> allows the director
to accept packets by fwmark.
There is no VIP required on the director.
	</para>
	</section>
	<section id="Pearthree" xreflabel="default gw for director with LVS-DR/LVS-Tun">
	<title>security concerns: default gw(s) and routing with LVS-DR/LVS-Tun</title>
	<para>
The material here came from a talk by Herbie Pearthree
of IBM (posting 2000-10-10) and from a posting by TC Lewis (which I've lost).
	</para>
	<para>
In normal IP communication between two hosts, the routing is symmetrical:
each end of the link has an ethernet device with an IP and
a route to the other machine. Packets are transmitted in pairs
(an outgoing packet and a reply, often just an ACK).
	</para>
	<para>
In LVS-DR or LVS-Tun the roles of the two machines are split
between 3 machines. Here is a two network test setup, with
the client in the position normally occupied by the router.
In production, the client will have a public IP and connect
via a router.
(This is my test setup.
A big trap in this setup is that services which make calls from the RIP,
<emphasis>e.g.</emphasis> <xref linkend="LVS-HOWTO.authd"/> and <link linkend="rshd">rshd</link>
will work,
but will fail in production, where the RIP will not be routable).
	</para>
<programlisting><![CDATA[
        ____________
       |            |192.168.1.254 (eth0)
       |  client    |----------------------
       |____________|          <-         |
     CIP=192.168.2.254 (eth1)             |
|             |                           |
V             |                           |
     VIP=192.168.2.110 (eth0)             |
        ____________                      |
       |            |                     |
       |  director  |                     |
       |____________|                     |
     DIP=192.168.1.1 (eth1, arps)         |
|             |                           |
V             |----------------------------
              |		        ->
     RIP=192.168.1.2 (eth0)
     VIP=192.168.2.110 (lo:0, no_arp)
        _____________
       |             |
       | realserver  |
       |_____________|
]]></programlisting>
		<section id="lvs_dr_director_default_gw">
		<title>Director's default gw</title>
		<para>
The client sends a packet to the VIP on the director.
In a normal exchange of packets between a pair of machines,
the director would send a reply packet back to the client.
With an LVS, the director's response instead is a packet
to the MAC address of the RIP.
Except for ICMP packets (which are only sent in error conditions),
the VIP on the director never sends packets back to the client,
it only sends packets to the realservers.
A default gw for the director is not needed for the functioning of the LVS.
Having a default gw would only allow the VIP director to reply
to packets from the internet, such as port scans, creating a security hazard.
The director doesn't need and shouldn't have a default gw.
		</para>
		<para>
There are pathological conditions when the VIP needs to reply to the client.
If the realserver goes down, the director will issue ICMP "host unreachable"
packets, till a new realserver is switched in by mon or ldirectord.
(If you have a long lived tcp connection,
eg with telnet or https, the new realserver will be
getting packets for a connection which it doesn't know about, and it will issue
a tcp reset. This reset will go out the default gw for the realserver and
the client's session will hang or drop.)
		</para>
		<para>
If you're using the director for other functions (DNS, firewall...), then
packets will need to return to the internet.
If you wanted security, you could use the <link linkend="iproute2">iproute2 tools</link>
to allow only the DNS replies to use the default route.
An example of doing this is the routing used for
<xref linkend="3-Tier_lvs"/> realservers.
		</para>
		<para>
Julian Anastasov <emphasis>ja (at) ssi (dot) bg</emphasis>> 30 Aug 2001
		</para>
		<blockquote>
			<para>
	It may be these ICMPs are not fatal if they are not sent.
This is true when LVS is used in transparent proxy setups and
particulary in 2.4 where there is no real transparent proxy support.
There icmp_send() does not send any packets when there is no running
squid.
			</para>
			<para>
	But may be the original email sender wanted to use the LocalNode
feature together with a DR setup, IIRC. I see that the configure script
does not have configs for such setups with mixed forwarding methods.
So, as you said, the users with more knowledge can select another
way to build their setup. And they will know when they need a default
gateway :)
			</para>
			<para>
If the mtu is not matched between the router and the director, the
director will need to send ICMP "fragmentation needed" packets back
to the router. This is a bad setup.
			</para>
		</blockquote>
		<para>
You could enable default routing for icmp, but not tcp or udp from
the VIP back to the router, by using iproute2.
		</para>
		</section>
		<section id="route_to_realserver">
		<title>Realserver's default gw, route to realserver from router</title>
		<para>
The realserver doesn't reply to the director, instead it sends
its reply to the client. The realserver requires a default gw (here
192.168.1.154), but the client/router never replies to the realserver,
the client/router sends its replies to the director. So the client/router
doesn't need a route to the realserver network. To have one would
be a security hazard. The realserver now can't ping its default gw
(since there's no route for the reply packet), but the LVS still works.
		</para>
		<para>
The flow of packets around the LVS-DR LVS is shown by the ascii arrows.
		</para>
		<para>
When an attacker tries to access the nodes on the LVS, it can only
connect to the LVS services on the director. It can't
connect to the realserver network, as there is no routing to the
realservers (even if they get access to the router).
Presumably the realservers are not accessable from the outside
as they'll be on private networks anyhow.
		</para>
		<para>
Note that for Julian's <xref linkend="martian_modification"/>,
the director will need a default gw.
		</para>
		</section>
	</section>
	<section id="route_on_non_ip_interface">
	<title>routing to realserver from director</title>
	<note>
you don't need routing from the server_gw to the realservers either,
see <link linkend="route_to_realserver">route to realserver</link>.
	</note>
	<para>
If you are only using the link between the director and realserver for
LVS-DR packets (<emphasis>i.e.</emphasis> you aren't
<command>telnet</command> or <command>ssh</command>'ing from the realserver
to the director for your admin, and you aren't copying logs from one machine to
another), then you don't need an IP on the interface on the director
which connects to the realserver(s).
	</para>
	<para>
tc lewis <emphasis>tcl (at) bunzy (dot) net</emphasis> 12 Jul 2000 (paraphrased)
	</para>
	<blockquote>
		<para>
I would like to send packets from the LVS-DR director to the realservers
by a separate interface (eth2), but not assign an IP to this interface.
Normally I put a 192.168.100.x ip on eth2, but without it, route add -net
192.168.100.0 netmask 255.255.255.0 dev eth2 just gives me an error about
eth2 not existing. I just want to save an extra IP.
		</para>
		<para>
What i'm asking is: does the director's eth2 need an ip on
192.168.100.0/24, or can i just somehow add that route to that interface
to tell the machine to send packets that way? With lvs, the
realservers are never going to care about the director's interface ip,
since there's no direct tcp/ip connections or anything there, but
it looks like it still needs an ip anyway.
		</para>
		<para>
If all that that interface is doing is forwarding outgoing
packets from the director via the dr method, then i don't see why it
needs an ip address.
		</para>
	</blockquote>
	<para>
Ted Pavlic <emphasis>tpavlic (at) netwalk (dot) com</emphasis>
	</para>
	<para>
You basically want to do device routing. There's nothing special about
this -- many routers do it... NT even does it. So does Linux.
Your original route command should work
	</para>
<programlisting><![CDATA[
route add -net 192.168.100.0 netmask 255.255.255.0 dev eth2
]]></programlisting>
	<para>
as long as you've brought up eth2. Now tricking Linux into bringing up eth2
without an address might be the hard part.  Try this:
	</para>
<programlisting><![CDATA[
ifconfig eth2 0.0.0.0 up

or

ifconfig eth2 0 up
]]></programlisting>
	<para>
tc lewis <emphasis>tcl (at) bunzy (dot) net</emphasis>
	</para>
	<blockquote>
<programlisting><![CDATA[
ifconfig eth0 0.0.0.0 up
]]></programlisting>
		<para>
then the route did work.  I tried that before with a netmask but it didn't work.
		</para>
	</blockquote>
	<para>
Ted Pavlic <emphasis>tpavlic (at) netwalk (dot) com</emphasis>
	</para>
	<para>
Remember that IP=0 actually is IP=0.0.0.0, which is another name for the
default route.
	</para>
	<para>
The reason why IP=0 is 0.0.0.0 ... Remember that each IP address is simply a
4-byte unsigned integer, right? Well... the easiest way to envision this is
to imagine that an IP is just like a base-256 number. For example:
	</para>
<programlisting><![CDATA[
216.69.192.12 (my mail server) would be:

12 +
192 * 256 +
69  * 256 * 256 +
216 * 256 * 256 * 256
]]></programlisting>
	<para>
Which is equal to 3628449804. So...
	</para><para>
telnet 216.69.192.12 25
	</para><para>
is the same as:
	</para><para>
telnet 3628449804 25
	</para>
	<para>
0.0.0.0 is just a special system address which is the same as the default
route. Making a route from 0.0.0.0 to some gateway will set your default
route equal to that gateway. That's all "route add default gw ..." does.
Don't believe me? Do a route -n.
	</para><para>
So when I told TC to put 0 on his IP-less NIC, I was just choosing a system
IP that I knew would not ever need to be transmitted on. Linux wanted an IP
to create the interface... so I gave it one -- the IP of the default
gateway. Packets would never need to leave the system going to 0.0.0.0, and
Linux has to listen to this address ANYWAY, so you might as well explicitly
put it on an interface.
	</para><para>
What would have also worked (and might have been a better idea) would be to
put 127.0.0.1 on that interface. That is another system address that Linux
will listen to anyway if loopback has been turned on... and it should never
transmit anything away from itself with that as the destination address, so
it's safe to put it on more than one interface.
	</para><para>
The only reason I chose 0 over 127.0.0.1 is because 0 is easy... It's
small... It's quick. Whenever I want to telnet to my localhost's port blah I
just do a:
	</para>
<programlisting><![CDATA[
telnet 0 blah
]]></programlisting>
	<para>
because I'm lazy.. (Linux sees 0, interprets 0.0.0.0, sees an address it
listens to, and basically treats 0 like a loopback)
	</para><para>
Also you'll notice that if you give an interface 0.0.0.0 as an IP address
and do an ifconfig to get stats on that interface, it will still retain no
IP address. Another perquesite of using 0.0.0.0 in TC's particular situation.
It may actually cause less confusion in the end.
	</para>
	</section>
	<section id="set_rp_filter" xreflabel="turn off rp_filter">
	<title>LVS-DR, LVS-Tun need rp_filter=0</title>
	<note>
This applies <emphasis>on the director</emphasis> for both LVS-DR and LVS-Tun
	</note>
	<para>
Brandon Yap <emphasis>byap (at) xss (dot) com (dot) au</emphasis> 21 Feb 2004
	</para>
	<para>
I found the problem.  <filename>rp_filter</filename> needed to be turned off on tunl0.
	</para>
<programlisting><![CDATA[
echo 0 >/proc/sys/net/ipv4/conf/tunl0/rp_filter
]]></programlisting>
	<note>
Joe - 0 is the default value for <filename>rp_filter</filename>,
as specified in RFC1812 
(for more on RFC1812 see 
<xref linkend="broadcast_arp_replies"/> and 
<xref linkend="LVS-DR_director_default_gw"/>). 
From postings on the LVS mailing list,
it seems that some of the market enhanced kernels (<emphasis>e.g.</emphasis> Debian)
have changed the default.
(They wouldn't make any money if their kernels behaved in the expected way ;-\ .)
You need to file a bug report with the supplier of your kernel.
	</note>
	<para>
Ratz 13 Nov 2006
	</para>
<programlisting><![CDATA[
for i in /proc/sys/net/ipv4/conf/*/rp_filter
do
   echo "setting $i to 0"
   echo 0 > $i
done
]]></programlisting>
	<para>
Ratz 21 Jan 2006 
	</para>
	<para>
You would be referring to following snippet in the RFC, right?
	</para>
	<para>
5.3.8 Source Address Validation
	</para>
	<blockquote>
		<para>
    A router SHOULD IMPLEMENT the ability to filter traffic based on a
    comparison of the source address of a packet and the forwarding table
    for a logical interface on which the packet was received.  If this
    filtering is enabled, the router MUST silently discard a packet if
    the interface on which the packet was received is not the interface
    on which a packet would be forwarded to reach the address contained
    in the source address.  In simpler terms, if a router wouldn't route
    a packet containing this address through a particular interface, it
    shouldn't believe the address if it appears as a source address in a
    packet read from this interface.
		</para>
		<para>
    If this feature is implemented, it MUST be disabled by default.
		</para>
	</blockquote>
	<para>
So if I read this correctly, <filename>/proc/../conf/{all,default}/rp_filter</filename> 
must be off on a freshly booted kernel without any explicit user changes in 
any of the rc boot scripts.
	</para>
	<para>
I've checked on a Debian 
installation of one of our customers:
	</para>
<programlisting><![CDATA[
sf-lb:~ # cat /etc/network/options
ip_forward=yes
spoofprotect=yes
syncookies=no
sf-lb:~ # uname -a
Linux sf-lb 2.4.27 #1 Sat Oct 16 17:14:21 CEST 2004 sparc64 GNU/Linux
sf-lb:~ # cat /etc/debian_version
testing/unstable
sf-lb:~ #
]]></programlisting>
	<para>
I have to assume these are the default settings, which then in 
<filename>/etc/init.d/networking</filename> get set over <filename>doopt()</filename> 
(completely brain-dead redundant information).
	</para>
	<para>	
Reading <filename>spoofprotect_rp_filter()</filename> in 
<filename>/etc/init.d/networking</filename> I have to 
assume that the person maintaining this piece of software has not 
understood the network related settings (besides showing horrible 
programming practice) in <filename>proc-fs</filename> under Linux:
	</para>
<programlisting><![CDATA[
spoofprotect_rp_filter () {
     # This is the best method: turn on Source Address Verification and get
     # spoof protection on all current and future interfaces.

     if [ -e /proc/sys/net/ipv4/conf/all/rp_filter ]; then
         for f in /proc/sys/net/ipv4/conf/*/rp_filter; do

--> This should be s/*/default/ to match at least the wrong comment

             echo 1 > $f
         done
         return 0
     else
         return 1
     fi
}
]]></programlisting>

	<para>
On top, good programming practice would be to explicitly set the other 
values you take for granted to 0, since an operator could have 
accidentally set some <filename>proc-fs</filename> values to test something and did not make 
it reboot-safe.
	</para>
	<para>
Debian is and will remain a system for people with a lot of spare time. 
Folks: <filename>rp_filter</filename> has almost nothing to do with proper network security! 
If source validation has to be done, make sure you route properly.
	</para>
	<para>
It's funny, Debian people would only need to have a look at SuSE or Red 
Hat to see how one can do the networking setup a tad bit better.
	</para>
	<para>
Jacob Coby <emphasis>jcoby (at) listingbook (dot) com</emphasis> 20 Feb 2004
	</para>
	<para>
Could you do me a favor, and turn <filename>rp_filter</filename> ON,
and ping the VIP with both normal sized ping packets, and very large (&gt;MTU).
And then, turn <filename>rp_filter</filename> OFF and try it again?
I'm thinking this is the reason I was having trouble getting lvs-tun to work
with packets of size &gt;MTU (see <xref linkend="MTU"/>).
<filename>rp_filter</filename> is about the only <filename>/proc</filename>
entry I didn't lookup and try fiddling with.
	</para>
	<para>
from the
<ulink url="http://www.ibiblio.org/pub/Linux/docs/HOWTO/Adv-Routing-HOWTO">
adv-routing HOWTO</ulink>
(http://www.ibiblio.org/pub/Linux/docs/HOWTO/Adv-Routing-HOWTO)
	</para>
	<blockquote>
".. if a packet arrived on the Linux router on eth1
claiming to come from the Office+ISP subnet, it would be dropped. Similarly,
if a packet came from the Office subnet, claiming to be from somewhere
outside your firewall, it would be dropped also."
	</blockquote>
	<para>
I think LVS-TUN packets claim to be from the outside world, but come from
the subnet, don't they?
	</para>
	<para>
Joe: in test situations where both the director and realservers are on
the same bench, tunnelled packets from the director to the realservers
are from the same netmask.
However in real life, the director and realservers can be on different
continents and will be in different networks.
The decapsulated packet is from the client.
	</para>
	<para>
Guy Coates <emphasis>gmpc (at) sanger (dot) ac (dot) uk</emphasis> 03 Nov 2004 
	</para>
	<blockquote>
		<para>
I'm running into problems using LVS-DR when using a private network to
route traffic from the director to the realservers.
		</para>
<programlisting><![CDATA[
director
Public   IP :   172.17.22.215   (eth0)
Public VIP  :   172.17.22.216 (eth0:0)
Private IP  :   10.4.1.2 (eth1)

realserver

Public  IP: 172.17.22.214 (eth0)
Private IP:	10.4.1.1   (eth1)
VIP       :     172.17.22.216 (lo:0)
]]></programlisting>
		<para>
eth0 on both machines are on the same segment, and eth1 on both machines
are connected via a crossover cable. All client traffic comes in and out
via the public network.
		</para>
		<para>
If I route director->realserver traffic over eth0, everything works as it
should.
		</para>
<programlisting><![CDATA[
ipvsadm -A -t 172.17.22.216:80
ipvsadm -a -t 172.17.22.216:80 -r 172.17.22.214 -g

director:~# ipvsadm -L -c
IPVS connection entries
pro expire state       source           virtual         destination
TCP 14:49  ESTABLISHED 172.25.1.32:37143  172.17.22.216:80  172.17.22.214:80
]]></programlisting>
		<para>
If I route director->realserver traffic via the private network, things
don't. The director routes the incoming traffic correctly, but the
realserver drops the packets on the floor.
		</para>
<programlisting><![CDATA[
ipvsadm -A -t 172.17.22.216:80
ipvsadm -a -t 172.17.22.216:80  -r 10.4.1.1 -g

director:~# ipvsadm -L  -c -n
IPVS connection entries
pro expire state       source             virtual            destination
TCP 00:36  SYN_RECV    172.25.1.32:37154  172.17.22.216:80   10.4.1.1:80
]]></programlisting>
		<para>
tcpdump on the realserver confirms that the director is correctly passing
the packets to the realserver:
		</para>
<programlisting><![CDATA[
realserver:~# tcpdump -i eth1 port 80 -p -n

12:25:30.922232 IP 172.25.1.32.37159 > 172.17.22.216.80:
S 2236244704:2236244704(0) win 5840
<mss 1460,sackOK,timestamp 172541305 0,nop,wscale 0>
]]></programlisting>
		<para>
However,  the realserver does not pick up the packet.
I'm using kernel 2.4.27+hidden arp patches on both realserver and
director.
		</para>
	</blockquote>
	<para>
Unknown
	</para>
	<para>
You're not running with one of the anti-spoofing controls switched on
re you? For the life of me I can't remember which sysctl this is (rp_filter?)
but that would exhibit this type of behaviour if set.
	</para>
	<blockquote>
Ahh yes, it looks as if debian handily sets
<filename>/proc/sys/net/ipv4/conf/default/rp_filter</filename> 
to 1 by default.
Setting that to zero on the realserver make everything spring into life.
	</blockquote>
	<para>
Simon Detheridge <emphasis>simon (at) widgit (dot) com</emphasis> 30 Oct 2006
	</para>
	<para>
I had two LVS-Tun directors. One worked, one didnt.
Yeah. I did a "cp -r /proc/sys ~/" on each machine, 
then a recursive diff on the results. 
Looks like somehow during the upgrading and ensuing tinkering, 
<filename>rp_filter</filename> got set to "1" on the backup director.
Setting it to "0" seems to have made the bad behaviour go away. 
I thought I'd checked this, but must have only done it on the realservers.
	</para>
	</section>
	<section id="director_as_client_in_LVS-DR">
	<title>Director as client in LVS-DR</title>
	<para>
The 
<ulink url="http://www.austintek.com/LVS/LVS-HOWTO/mini-HOWTO/LVS-mini-HOWTO.html#gotchas">
LVS-mini-HOWTO</ulink> states that the lvs client cannot be on the director or 
any of the realservers, <emphasis>i.e.</emphasis> that you need an outside client.
This restriction can be relaxed under some conditions.
	</para>
	<para>
Joshua Goodall <emphasis>joshua (at) myinternet (dot) com (dot) au</emphasis> 11 May 2004
	</para>
	<para>
I want to setup the situation where the director is one of the clients.
It appears that LVS does not intercept the outbound packet when it 
originates on the director itself. This is with both fwmark and a 
configured VIP:port. I've also tried adding -j REDIRECT in the OUTPUT 
chain, to no avail.
If I bring up the VIP on the director, I see the packet when tcpdumping 
localhost, but LVS doesn't grab it. Oddly, the packet is still on 
localhost even when the VIP is on eth0.
It seems that <filename>ip_vs_in</filename> ignores the packet if the
device is <filename>loopback_dev</filename>.
	</para>
	<para>
Questions then:
	</para>
	<itemizedlist>
		<listitem>
Why test for <filename>loopback_dev</filename> at all? Is this important, or is
it just supposed to be an optimisation?
		</listitem>
		<listitem>
Can we fool ip_vs to fill <filename>skb->dev</filename> with something other than
<filename>&amp;loopback_dev</filename> if the director is the client?
		</listitem>
	</itemizedlist>
	<para>
I tried this patch (2.4.26)
	</para>
<programlisting><![CDATA[
diff -u -p -r1.1.1.1 ip_vs_core.c
--- ip_vs_core.c	19 Apr 2004 04:54:41 -0000	1.1.1.1
+++ ip_vs_core.c	11 May 2004 13:03:34 -0000
@@ -1036,7 +1036,7 @@ static unsigned int ip_vs_in(unsigned in
 	 *	Big tappo: only PACKET_HOST (nor loopback neither mcasts)
 	 *	... don't know why 1st test DOES NOT include 2nd (?)
 	 */
-	if (skb->pkt_type != PACKET_HOST || skb->dev == &loopback_dev) {
+	if (skb->pkt_type != PACKET_HOST) {
 		IP_VS_DBG(12, "packet type=%d proto=%d daddr=%d.%d.%d.%d ignored\n",
 			  skb->pkt_type,
 			  iph->protocol,
]]></programlisting>
	<para>
then added
	</para>
<programlisting><![CDATA[
iptables -t mangle -A OUTPUT -p tcp -s 0/0 -d $VIP --dport $VIPP -j MARK --set-mark 2
]]></programlisting>
	<para>
to the existing
	</para>
<programlisting><![CDATA[
ip rule add prio 100 fwmark 2 table 100
ip route add local 0/0 dev lo table 100
]]></programlisting>
	<para>
and now my fwmark-based LVS-DR director does the job for clients and for
itself.  To make LVS-NAT work, we'd also need to be able to choose the
masqueraded source address, which would be a much longer diff.  I
didn't try LVS-Tun, but that would probably be workable like LVS-DR.
	</para>
	<para>
Julian 
	</para>
	<para>
	So, now you can send packets in form DIP->VIP to real
servers (LVS-DR method)? I'm wondering how your patched director accepts
reply packets for the LVS'ed service from the realserver in the form VIP->DIP. 
Linux has source
address validation and you can not disable it for packets with
<filename>saddr=local_ip</filename>.
	I see that you can remove the limitation when sending
packets but how do you accept the normal LVS replies from the realservers? 
Maybe you do not have
the VIP configured as IP address?
	</para>
	<para>
Joshua
	</para>
	<para>
There is no VIP. For regular (external) clients, I'm using fwmark + iproute2
to grab packets intended for the DIP; to capture locally sourced packets,
I just put a -j REDIRECT into the OUTPUT chain of the nat table.
	</para>
	<para>
Julian
	</para>
	<para>
	There can be another problem in 2.4 (2.6 seems to handle
this properly): <filename>ip_vs_skb_cow</filename> 
does not expect skbs to have valid <filename>skb->ski</filename>. 
Maybe the skb should be copied (skb_copy) instead
reallocating only its data. You can check for problems by using
<command>tcpdump -i lo</command>. Make sure there are no crashes or any kind of
memory leaks because I personally can not test such setup. For 2.6
you can remove also the <command>skb->sk</command> check.
	</para>
	</section>
	<section id="lvs_dr_mailing_list">
	<title>from the mailing list</title>
	<para>
tc lewis has NAT'ed out <xref linkend="NAT_client_ntp"/>.
	</para>
	</section>
	<section id="re-mapping_ports_lvs_dr" xreflabel="Re-mapping ports with LVS-DR">
	<title>rewriting, re-mapping, translating ports with LVS-DR</title>
	<para>
see <xref linkend="re-mapping_ports_with_iptables"/>
	</para>
	</section>
</section>
<section id="LVS-HOWTO.LVS-Tun" xreflabel="LVS-Tun">
<title>LVS: LVS-Tun</title>
	<section id="LVS-Tun-intro">
	<title>LVS-Tun Intro</title>
	<para>
LVS-Tun is an LVS original. It is based on LVS-DR.
The LVS code encapsulates the original packet (CIP-&gt;VIP)
inside an ipip packet of DIP-&gt;RIP, 
which is then put into the OUTPUT chain, 
where it is routed to the realserver.
(There is no tunl0 device on the director; ip_vs() does
its own encapsulation and doesn't use the standard kernel ipip code.
This possibly is the reason why PMTU on the director does not work
for LVS-Tun - see <xref linkend="MTU"/>.) 
The realserver receives the packet on a tunl0 device 
(see <link linkend="need_tun_device">need tunl0 device</link>)
and decapsulates the ipip packet,
revealing the original CIP->VIP packet.
	</para>
	<para>
Initially only Linux could decapsulate IPIP packets, 
but recently FreeBSD and w2k can now do it too 
(hmm 2005, Microsoft has dropped support for IPIP).
	</para>
	<para>
If you want to try a test LVS-Tun setup on the bench, 
take a standard LVS-DR setup <xref linkend="lvs_dr_example"/>,
change <filename>lo </filename> on the realservers to <filename>tunl0</filename> 
(and handle the ARP problem on <filename>tunl0</filename>)
and change the <command>ipvsadm</command> switch from <command>-g</command>
to <command>-i </command>.
If your clients are going to be sending large packets, 
you need to set the MTU (see <xref linkend="MTU"/> for the ipip packet DIP->RIP).
This can be done on the realserver with 
<command>iptables</command> (see <xref linkend="tunl_mtu_solved"/>) 
or <command>iproute2</command> (see <xref linkend="setting_mtu_by_route"/>).
	</para>

	<para>
As with LVS-DR, the director doesn't know about the VIP on the realserver
(it only knows about the RIP).
Health checking of a service listening on the VIP on the
realserver then must use a connection between the DIP and the RIP
(if the demon is listening on both the RIP and DIP,
the service listening on the RIP can be a proxy for the service
listening on the VIP).
	</para>
	<para>
LVS-Tun allows the realservers to be geographically remote from the director
(this is the main point of LVS-Tun).
If your realservers cannot do ipip decapsulation, 
you can still have geographically remote realservers using other techniques
(see <xref linkend="non_tunnelling_realservers"/>). 
	</para>
	<para>
(see also
<ulink url="http://www.ssi.bg/~ja/TUN-HOWTO.txt">
Julian's LVS-Tun write up</ulink> and
<ulink url="http://marc.theaimsgroup.com/?t=100272238300009&amp;w=2&amp;r=1">
postings to the mailing list</ulink>).
	</para>
	</section>
	<section id="lvs-tun_example">
	<title>LVS-Tun example setup</title>
	<para>
Here's an example set of IPs for a LVS-Tun setup. For (my)
convenience the servers are on the same network as the client.
The only restrictions for LVS-Tun with remote hosts are that the
client must be able to route to the director and that the
realservers must be able to route to the client (the return
packets to the client come directly from the realservers and do
not go back through the director).
	</para>
	<para>
Normally for LVS-Tun, the client is on a different network to the
director/server(s), and each server has its own route to the
outside world. In the simple test case below where all machines
are on the 192.168.1.0 network there would be no default route
for the servers, and routing for packets from the servers to the
client would use the device on the 192.168.1.0 network
(presumably eth0). In reallife, the realservers would have their
own router/connection to the internet and packets returning to
the client would go through this router. In any case reply
packets do not go back through the director.
	</para>
<programlisting><![CDATA[
Machine                      IP
client                       CIP=192.168.1.254
director                     DIP=192.168.1.1
                             VIP=192.168.1.110 (arps, IP clients connect to)
realserver-1                 RIP1=192.168.1.2, VIP (tunl0, non-arping, 192.168.1.110)
realserver-2                 RIP2=192.168.1.3, VIP (tunl0, non-arping, 192.168.1.110)
realserver-3                 RIP3=192.168.1.4, VIP (tunl0, non-arping, 192.168.1.110)
.
.
realserver-n                 RIPn=192.168.1.n+1, VIP (tunl0, non-arping, 192.168.1.110)
]]></programlisting>
<para>
</para>
<programlisting><![CDATA[
#lvs_tun.conf
LVS_TYPE=VS_TUN
INITIAL_STATE=on
VIP=eth0:110 192.168.1.110 255.255.255.255 192.168.1.110
DIP=eth0 192.168.1.9 192.168.1.0 255.255.255.0 192.168.1.255
DIRECTOR_DEFAULT_GW=client
SERVICE=t telnet rr realserver1 realserver2
SERVER_VIP_DEVICE=tunl0
SERVER_NET_DEVICE=eth0
SERVER_DEFAULT_GW=client
#----------end lvs_tun.conf------------------------------------
]]></programlisting>
	<para>
	</para>
<programlisting><![CDATA[
                        ________
                       |        |
                       | client |
                       |________|
                       CIP=192.168.1.254
                           |
             CIP->VIP |    |   ^  
                      v    |   | VIP->CIP
                           |
       VIP=192.168.1.110   |
       (eth0:1, arps)      |
         __________        |
        |          |       |
        | director |-------
        |__________|       |
       DIP=192.168.1.1     |
       (eth0)              |
                           |
   DIP->RIP(CIP->VIP) |    |
                      v    
          -------------------------------------
          |                |                  |
          |                |                  |
   RIP1=192.168.1.2  RIP2=192.168.1.3  RIP3=192.168.1.4 (eth0)
   VIP=192.168.1.110 VIP=192.168.1.110 VIP=192.168.1.110 (all tunl0,non-arping)
    _____________     _____________     _____________
   |             |   |             |   |             |
   | realserver  |   | realserver  |   | realserver  |
   |_____________|   |_____________|   |_____________|

]]></programlisting>
	<para>
Here's a likely production setup (I haven't done this one myself).
It assumes the realservers are on a different network to the DIP.
Here x.x.x.? and y.y.y.? are public IPs. 
The 176 and 10 addresses are for communication between
the different locations and will be assigned by the ISP.
	</para>
<programlisting><![CDATA[
                       ________
                      |        |
                      | client |
                      |________|
                      CIP=x.x.x.1
                          |
            CIP->VIP |    |---------------------------------
                     v    |                                 |
                      __________                            | 
                     |          |                           |
                     | D-router |                           |
                     |__________|                           |
                          |                                 |
            CIP->VIP |    |                                 |
                     v    |                                 |
                          |                                 |
                VIP=y.y.y.110(eth0, arps)                   |
                      __________                            |
                     |          |                           |
                     | director |                           |
                     |__________|                           |
                DIP=176.0.0.1 (eth1)                        |
                          |                              ^  |
  DIP->RIP1(CIP->VIP) |   |                     VIP->CIP |  |
                      v   |                                 |
                      __________                       __________
                     |          |                     |          | 
                     | R-router |  R,C-Router do not  | C-Router |
                     |__________|   advertise VIP     |__________|
                          |                                 |
                          |                              ^  |
  DIP->RIP1(CIP->VIP) |   |                     VIP->CIP |  |
                      v   |                                 |
                          |                                 |
         ----------------------------------------------------
         |                           |
         |                           |
  RIP1=10.0.0.1(eth0)       RIP2=10.0.0.2(eth0)
  VIP=y.y.y.110(tunl0)      VIP=y.y.y.110(tunl0)
         |                           |
  _________________         ___________________     
 |                 |       |                   | 
 | realserver      |       | realserver        |
 | tunl0: CIP->VIP |       |                   |
 | eth0:  VIP->CIP |       |                   | 
 |_________________|       |___________________|
]]></programlisting>
	</section>
	<section id="need_tun_device">
	<title>You need a tunl0 device</title>
	<note>
<filename>tunl0</filename> is a networking device like <filename>eth0</filename>, 
<filename>lo</filename>, and <filename>dummy0</filename>.
	</note>
	<para>
In LVS-Tun, the <filename>tunl0</filename> device holds the VIP, 
just as the <filename>lo</filename> device holds the device for LVS-DR.
You need to build the <filename>tunl0</filename> device into the Linux kernel
(in networking options - IP:tunneling) - it is turned off by default.
The tunnelling (ipip) can be built as a module, 
in which case you'll have to <command>insmod ipip</command> before you can use it, 
or you can build ipip directly into the kernel.
With a kernel enabled for ipip,
you should be able to see the unconfigured <filename>tunl0</filename> device with
<command>ifconfig</command> or with <command>ip addr show</command>
(Feb 2004 - my <command>ifconfig</command> used to see the unconfigured <filename>tunl0</filename>,
but it doesn't anymore.)
	</para>
	<para>
Then you configure the <filename>tunl0</filename> device 
(even if <command>ifconfig</command> can't see it).
	</para>
<programlisting><![CDATA[
ifconfig tunl0 192.168.1.110 netmask 255.255.255.255 broadcast 192.168.1.110
]]></programlisting>
	<para>
when the <filename>tunl0</filename> device becomes visible to <command>ifconfig</command>
	</para>
	<para>
or
	</para>
<programlisting><![CDATA[
ip addr add dev tunl0 192.168.1.110/32 brd 192.168.1.110
]]></programlisting>
	<note>
the VIP is a /32 addr, so the brd addr is the VIP, not x.x.x.255.
	</note>
	</section>
	<section id="arp_problem_lvs-tun">
	<title>the ARP problem with LVS-Tun</title>
	<para>
If the realservers and director are on a different network
(<emphasis>e.g.</emphasis> the realservers are geographically remote), 
then the router infront of the realservers will not be advertising routes to the VIP
and you won't need to handle the ARP problem on the realservers.
In effect you are using <xref linkend="Lars_method"/> without having to do anything special.
	</para>
	<para>
If the realservers are using the same router as the director
you need to handle the ARP problem for the realservers 
(set <filename>tunl0</filename> to not reply to arp queries).
This networking is the same as for LVS-DR 
and you'd only do this to test LVS-Tun.
(there's no other reason to use LVS-Tun with the LVS-DR network).
However all my LVS-Tun test cases used the same networking as for LVS-DR, 
<emphasis>i.e.</emphasis> the DIP and RIPs were on the same network
and only one router (actually none, the client with 1 or 2 NICs,
faced directly onto the director and realservers). 
In this case I had to handle the ARP problem for the realservers.
	</para>
	</section>
	<section id="reply_packets_appear_spoofed">
	<title>Reply packets appear to be spoofed</title>
	<para>
Unlike LVS-DR, with LVS-Tun the realservers can be in a different 
location (and on a network remote from the director), 
where the director and realservers will be on different networks
and the realservers will be on a network that does NOT contain the VIP.
If this is the case,
the realservers will be generating reply packets with VIP:port->CIP
(where <emphasis>port</emphasis> is the LVS'ed service).
Not being on the VIP network,
the routers for the realservers will have to be programmed to accept outgoing packets
with src_addr=VIP:port.
Routers normally drop these packets as an anti-spoofing measure.
If you aren't in control of the routers,
you'll just have to inform the people who are,
that packets from VIP:port are valid for your business.
If they don't want to help you with your business,
then you should find another provider who will.
	</para>
	<para>
Mark Wadham <emphasis>mark (dot) wadham (at) areti (dot) net</emphasis> 30 Mar 2007
	</para>
	<para>
I believe we have located the source of the problem.  
Our load balancer is located in Manchester and the mail servers
are located in London, and it appears that our upstream providers filter our
traffic to prevent ip spoofing.
	</para>
	</section>
	<section id="lvs_tun_how_it_works">
	<title>How LVS-Tun works</title>
	<para>
Here's part of the rc.lvs_tun script which configures the realserver with
RIP=192.168.1.8
	</para>
<programlisting><![CDATA[
#setup servers for telnet
/sbin/ipvsadm -A -t 192.168.1.110:23 -s rr
/sbin/ipvsadm -a -t 192.168.1.110:23 -R 192.168.1.1 -i -w 1
]]></programlisting>
	<para>
There's no forwarding in the conventional sense for LVS-Tun.
(You can have <filename>ip_forward</filename> set to ON if you
need it for something else, but LVS-Tun doesn't need in ON.
If you don't have a good reason to have it ON, then for
security turn it OFF).
For more explanation see <xref linkend="ipvs_for_netfilter"/>
	</para>
<programlisting><![CDATA[
#set ip_forward OFF for lvs-tun director (1 on, 0 off)
cat       /proc/sys/net/ipv4/ip_forward
echo "0" >/proc/sys/net/ipv4/ip_forward
]]></programlisting>
	<para>
As with LVS-DR, for LVS-Tun, the target port numbers of incoming
packets cannot be remapped. A request to port 23
on the VIP will be forwarded to port 23 on a realserver,
thus no port number is used for setting up the
IP of the realserver.
However you can still <xref linkend="re-mapping_ports_lvs_tun"/> 
external to LVS, using <command>iptables</command>
	</para>
	<para>
Here's the packet headers as the request is processed by LVS-Tun.
	</para>
<programlisting><![CDATA[
packet                  source        dest         data
1. request from client  CIP:3456      VIP:23       -
2. ipvsadm table:
   director chooses server=RIP1, encapsulates into IPIP packet
                        DIP           RIP1         IP datagram
                                                   source=CIP:3456,
                                                   dest=VIP:23,
                                                   data= -
3. realserver recovers IP datagram
                        CIP:3456      VIP:23       -
4. realserver looks up routing table, finds VIP is local,
   processes request locally, generates reply
                        VIP:23        CIP:3456     "login: "

5. packet leaves realserver via default gw, not via DIP.
]]></programlisting>
	<para>
For the verbally oriented...
	</para>
	<para>
A packet arrives at the director for the VIP. The director looks up its tables
and decides to send the connection to realserver_1. The director
encapsulates the request packet in an IPIP datagram with
header DIP->RIP_1. The packet arrives at realserver_1, the
realserver recovers the original IP datagram, looks up its
routing table, finds that the VIP (on the non-arping <filename>tunl0</filename>) 
is local and processes the packet locally. 
A reply packet is generated with VIP:23->CIP:3456.
The realserver looks up its routing table and
finds that a packet to CIP goes out its default gw (not to the DIP).
	</para>
	<para>
The <filename>tunl0</filename> device does not arp with 2.0.36 kernels, but does with
2.2.x (and later) kernels.
Go look up the section on the <xref linkend="LVS-HOWTO.arp_problem"/>
to see if you need to patch the kernel on the realserver.
(Joe: since kernel 2.6.4 and 2.4.26, <filename>arp_ignore/arg_annouce</filename>
are the preferred way of handling the arp problem.)
	</para>
	</section>
	<section id="tunl_device_doesnt_receive_packet">
	<title>The RIP (not the tunl device) receives the ipip packet</title>
	<para>
Joe
	</para>
	<blockquote>
How does a packet get to a <filename>tunl</filename> device,
which doesn't have a MAC address, from a remote machine?
	</blockquote>
	<para>
Julian
	</para>
	<para>
        <filename>tunl</filename>, <filename>lo</filename> and <filename>dummy</filename> 
are used just to configure the VIP. 
We don't send any packets through these devices. 
The requests are delivered to the realservers using their RIP. 
The director asks only about their RIP from <command>ipvsadm</command>. 
Only the router/gateway asks about VIP, but only the director must reply. 
When the packet is received in the realserver it is delivered locally 
(not forwarded or dropped) due to configured VIP. This is the only role
of these "dummy" interfaces: the kernel to treat the received packet
as it is destined to our host (the realserver). Nothing more. No IPIP
encapsulations (for <filename>tunl</filename>), no MAC address definitions, nothing more.
When we answer the request we use <filename>eth0</filename>. 
The <filename>tunl/lo/dummy</filename> is not selected as device for the outgoing packets. 
We have routes for <filename>eth0</filename> (default gateway) which we use for the outgoing traffic.
This is for DROUTE and TUNNEL mode.
	</para>
	<blockquote>
If two linux boxes (not in an LVS) are joined by an IPIP tunnel and
there is no MAC address associated with the tunl0 devices at each
end of the link, then how do the packets get from one machine to
the other?
	</blockquote>
	<para>
Julian
	</para>
	<para>
The packets are encapsulated via IPIP and sent to the tunnel ends
real IP where they are decapsulated again and appear on the <filename>tunl</filename> interface.
You don't need a MAC address for point-to-point links, or logical interfaces like tunnels.
	</para>
	</section>
	<section id="lvs_tun_configure">
	<title>Configure LVS-Tun</title>
	<para>
Edit the template <filename>lvs_tun.conf</filename> and run the configure script
<programlisting><![CDATA[
$ ./configure_lvs.pl lvs_tun.conf
]]></programlisting>
	</para><para>
Load the the parameters into the director and then the
realservers with the command
	</para>
<programlisting><![CDATA[
$ . ./etc/rc.d/rc.lvs_tun
]]></programlisting>
	<para>
(the script knows whether it is running on a realserver or the director).
	</para>
	<para>
(later put <filename>rc.lvs_tun</filename> in <filename>/etc/rc.d</filename> or 
<filename>/etc/init.d</filename> and put <filename>mon_xxx.cf</filename> 
in <filename> /etc/mon</filename>)
	</para>
	<para>
check the output from <command>ipvsadm</command>, 
<command>ifconfig -a</command> and <command>netstat -rn</command>, 
to check that the services/IP's are correct. 
	</para>
	</section>
	<section id="tunl0_device">
	<title>set rp_filter correctly</title>
	<para>
this is now in <xref linkend="set_rp_filter"/>
	</para>
	</section>
	<section id="lvs_tun_freebsd_realservers">
	<title>FreeBSD and Solaris realservers with LVS-Tun</title>

	<para>
maluyao <emphasis>ma(dot)luyao(at)gmail(at)com</emphasis> 4 Apr 2007
	</para>
	<para>
	see
<ulink url="http://kb.linuxvirtualserver.org/wiki/LVS/TUN_mode_with_FreeBSD_and_Solaris_realserver">
LVS-Tun on FreeBSD and Solaris realservers</ulink>
(http://kb.linuxvirtualserver.org/wiki/LVS/TUN_mode_with_FreeBSD_and_Solaris_realserver).
	</para>
	<para>
Here's how to setup ipip encapulation in FreeBSD.
	</para>
	<para>
carla quiblat <emphasis>carlaq (at) asti (dot) dost (dot) gov (dot) ph</emphasis> 20 Jun 2002
	</para>
	<blockquote>
	<para>
First, gifs must be supported in your kernel (enable "pseudo-device
gif" in your kernel config).
	</para>
	<para>
src_addr is the address of your NIC's interface while dest_addr is the
remote side or the other end of the tunnel IP address. For example, if pc1
is one end of your tunnel and pc2 is the other end, then:
	</para>
<programlisting><![CDATA[
if in pc1, you have:
	xl0: 1.1.1.1

	gif0:

if in pc2, you have:
	de0: 1.1.2.1

	gif0:

on pc1, do the following:

	pc1# ifconfig gif0 1.1.1.1 1.1.2.1

on pc2, do the following:

	pc2# ifconfig gif0 1.1.2.1 1.1.1.1
]]></programlisting>
	<para>
You can also man gifconfig .
	</para>
	<para>
I haven't tried using gif interfaces for IP-in-IP tunneling. I've
only used them for IPv6 in IPv4 tunneling, but you can test it.
	</para>
	</blockquote>
	<para>
carla quiblat <emphasis>carlaq (at) asti (dot) dost (dot) gov (dot) ph</emphasis> 30 Jun 2002
	</para>
	<blockquote>
	<para>
I'd just like to report that I got LVS-Tun working for a
Linux(as director)-OpenBSD(as realserver). I am currently testing LVS so
we could use it to loadbalance web service requests (http) over different
sites (different IPs/different blocks) therefore LVS-Tun is required.
	</para>
	<para>
I know FreeBSD implements tunneling but I've
only used it for IPv6-in-IPv4 tunneling and I didn't quite understand how
tunneling in Linux worked. For example, in linux to create a tunnel, you
did this:
	</para>
	<itemizedlist>
		<listitem>
		<para>
on the director: no tunnel is created because ipvs does the encapsulation
		</para>
		</listitem>
		<listitem>
		<para>
on the realserver:
		</para>
<programlisting><![CDATA[
	ifconfig tunl0 172.26.20.110 netmask 255.255.255.255 broadcast 172.26.20.110
	route add -host 172.26.20.110 dev tunl0
]]></programlisting>
		</listitem>
	</itemizedlist>
	<para>
Basically, I understand that the tunl0 is identified with the remote
tunnel end (VIP) but I don't understand the "route add" part since LVS-Tun
only implements a one-way tunnel. That is, from the director to the
realserver, tunneling from realserver-to-director is not required and
seems useless. The realserver routes following it's default router path
direct to the client. So that's where I got stuck. "How do you say
this in *BSD using the gif0 interface, the one I'm familiar with?" In the
end, this is the topology we'd like to implement:
	</para>
<programlisting><![CDATA[
               --------
              | client |
               --------
                  |
                  |
               Internet
                  |
                  |
              LVS director, Linux
                  |
                  |  ______________
              -------...tunnel.....-->(one-way-tunnel)realserver, *BSD
              |      --------------
              |
           realserver(local-NAT), *BSD
]]></programlisting>
	<para>
with the tunneled packet routed normally through its routers/gateways
(edge routers or other) down to the realserver.
	</para>
	<para>
My test setup looks like this:
	</para>
<programlisting><![CDATA[
[ client with a live IP ] -------gw------eth0(10.10.8.98, DIP) [director]
                                     |   eth0:110 (VIP)
                                     |
                                     |___fxp0(10.10.8.199,RIP)[realserver]
]]></programlisting>
	<para>
So what I did on the OpenBSD realserver is this,
	</para>
<programlisting><![CDATA[
	ifconfig fxp0 10.10.8.199 netmask 255.255.255.0 up
	route add default 10.10.8.1
	ifconfig gif0 tunnel 10.10.8.199 10.10.8.98
	ifconfig lo0 _VIP netmask 255.255.255.255
]]></programlisting>
	<para>
10.10.8.1 is the default gateway for the private network. Notice that the
tunnel endpoint is the DIP (not VIP like in Linux). This is because as I
understand, the packet that arrives at the realserver (encapsulated by
ipvs) has this format:
	</para>
<programlisting><![CDATA[
	[D|R|C|V|...payload....]
]]></programlisting>
	<para>
where, D - director address, R - realserver address, C - client address,
and V - VIP address. Decapsulation is done by the gif0 tunnel, after that
it sees that the packet is destined to itself (VIP defined at its lo0
interface) and processes it normally with source IP= client IP.
	</para>
	<para>
When I do "telnet VIP" from the client, I successfully enter
10.10.8.199 after the login.
	</para>
	</blockquote>
	</section>
	<section id="LVS-Tun-windows">
	<title>Windows realservers with LVS-Tun</title>
	<note>
support for ipip was removed from M$ after w2k. 
Paolo has a solution for <xref linkend="non_tunnelling_realservers"/> 
using a spanned layer2 network.
	</note>
	<para>
Johan Ronkainen <emphasis>jr (at) mpoli (dot) fi</emphasis> 10 Feb 2003
	</para>
	<para>
It's possible with w2k Server. You'll find necessary settings under
Routing and Remote Access snap-in. First create new IP Tunnel under "Routing
Interfaces", then select "New Interface" under IP Routing/General and put
necessary settings there.
	</para>
	<para>
You'll also need Loopback interface so w2k will handle packets itself
and won't try to route them. Open Control Panel, click Add New Hardware,
navigate thru dialogs and finally select Microsoft Loopback Adapter. If you
want /32 network for loopback adapter you need to change it with regedit
since GUI allows only /31. Network code itself is fine with /32 subnets.
	</para>
	<para>
It's been a while since I did this. We load-balanced w2k Terminal Server
clients to three servers. Two were on same building as clients and third one
was in different city on separate subnet. Clients connected to LVS that
forwarded 2/3 of connections to local servers using LVS/DR and 1/3 to remote
location using LVS/Tun via IP-tunnel. Replies were routed directly to
clients.
	</para>
	<para>
This never went to full production and servers have been re-installed since
so I can't check exact configs. It's not that hard. Just like LVS/Tun with
Linux on LVS end. w2k part required bit trial and error but it's doable.
	</para>
	<para>
Adam Hammouda <emphasis>AdamMH (at) aol (dot) com</emphasis>
02 September 2003
	</para>
	<blockquote>
		<para>
I'm wondering if anyone can help me with some lvs/ipvs configuration issues regarding
Windows' Real Server's and LVS-Tunneling.
I have been able to setup LVS-Tun when all realservers are Linux-based,
however when Windows is thrown into the equation things start to get
messy. I have
		</para>
		<itemizedlist>
			<listitem>
Created a new General IP Routing Tunnel (Interface) and set it's local and remote
addresses' to the VIP and Director IP, respectively.
			</listitem>
			<listitem>
configured the Microsoft Loopback Adapter to use the VIP, 
and set it's subnet mask to 255.0.0.0 as was recommended.
			</listitem>
		</itemizedlist>
	</blockquote>
	<para>
Chris <emphasis>Chris (at) baonline (dot) co (dot) uk</emphasis> 03 Sep 2003
	</para>
	<para>
We run lvs using tunneling (ipip) with 3 windows 2000 realservers.
The steps are something like:
	</para>
	<orderedlist>
		<listitem>
Install a loopback adapter on each realserver.  I think this is documented elsewhere
to solve the ARP problem.  But basically, go to add new hardware, network, microsoft,
loopback adapter.  Assign this adapter the IP address of the cluster, (VIP).
 - Sounds like you have already done this
		</listitem>
		<listitem>
Go to routing and remote access on each realserver.
Enable if needed.
Dont let it automatically configure = asking for trouble.
Under routing interfaces, add a new IPTunnel.
Now, under IP Routing - General, add a new interface,
selecting the IPTunnel that you have just created.
For the 'Local address', specify the RIP of that realserver.
For the Remote Address, specify the DIP.
Ok through all that and then reboot the realserver. - it is M$ after all.
 - Sounds like you have specified the wrong IP address
		</listitem>
	</orderedlist>
	<para>
Paolo Penzo <emphasis>paolo.penzo (at) bancatoscana (dot) it</emphasis> 26 Sep 2003
	</para>
	<blockquote>
I 'm using LVS on geographical basis (DR and TUN) with both Linux and Windows 2k as realservers.
Unfortunately we started to migrate Win 2k severs to Win 2003 and we
discovered that IP-IP encapsulation is not supported anymore by MS
servers (see http://support.microsoft.com/?id=280484) so LVS TUN
configurations don't work anymore if you use win 2k3 as realserver.
I'm thinking how to overcame this problem by manually configuring IPSec
tunnels or something similar...
Help is wellcomed.
	</blockquote>
	<para>
Joe: there was no answer
	</para>
	</section>
	<section id="non_tunnelling_realservers" xreflabel="non tunnelling realservers">
	<title>Realservers without ipip encapsulation</title>
	<para>
ipip encapsulation is used when the realservers are at a remote site.
Methods of tunneling other than ipip exist (<emphasis>e.g.</emphasis> a VPN)
if you need geographically remote realservers.
	</para>
	<para>
Richard Seabrook
	</para>
	<blockquote>
Since Windows 2003 doesn't support IP-in-IP like 2000 did, what other alternatives are people using
when real servers are remote from the directors?
	</blockquote>
	<para id="paolo">
Paolo Penzo <emphasis>paolo (dot) penzo (at) bancatoscana (dot) it</emphasis> 06 Dec 2006
	</para>
	<para>
We made a layer2 network spanned across geographical sites and moved to DR balancing: 
everthing is much more easy to manage!
	</para>
	</section>
	<section id="MTU" xreflabel="MTU">
	<title>LVS-Tun has smaller MTUu: PMTU is disabled - handling fragmentation</title>
	<note>
		<para>
Ratz 28 Feb 2007 
(after seeing a patch in the lkml regarding documentation for sysctls 
<filename>tcp_mtu_probing</filename> and <filename>tcp_base_mss</filename>.) 
		</para>
		<para>
I found this patch rather interesting, 
regarding the fact that obviously PMTU seems to be disabled by default on newly 2.6.x
(x>19?) kernels. We need to keep an eye on this.
		</para>
	</note>
	<para>
A ipip header is added when sending packets through a tunnel. 
Since the mtu is fixed (1500), the extra header reduces the allowed packet payload size.
This will require fragmenting of packets&gt;1480 sent from the director to the realserver in LVS-Tun.
LVS (and Linux) doesn't have any special code to handle ipip fragmentation, 
so we should have expected LVS-Tun to fail when the client sent packets 
large enough to require fragmentation in the DIP->RIP hop.
Either few people were using LVS-Tun in production, 
or clients were only sending small packets (<emphasis>e.g.</emphasis> HTTP GET)
and we didn't realise for a long time that we had a problem lurking.
Further below <link linkend="tunl_mtu_solved">is Casey Zacek's solution for both w2k and linux</link>. 
Here is Julian's description of the problem.
	</para>
	<para>
Julian Feb 12 2007
	</para>
	<para>
The client will (Joe: should?) see a "fragmentation required" icmp packet from
the director, if the packet is bigger than our PMTU to RS. 
	</para>
	<note>
this problem is still present and it is hard to fix (it's a bug):
	</note>
<programlisting><![CDATA[
http://marc.theaimsgroup.com/?l=linux-virtual-server&m=107757685230840&w=2
]]></programlisting>
	<para>
	Without handling ICMP errors for our IPIP packets, we will not
lower the PMTU just by generating IPIP traffic. 
But other (non ipip) protocols (packets to RS) can learn lower PMTU and update the cache.
Then we can see this lower value in the routing cache and generate reply ICMPs 
when large packets come from the client. 
At least that's what I remember from before;
I'm not sure if things have changed in 2.6 now.
	</para>
	<para>
	IPIP packets are between the DIP and RIP. 
These packets can hit the MTU limit in all hops between director and RS. 
The reply packets from RS to CLIENT are another path. 
If a big packet from the RS to CLIENT hits a MTU limit, 
then our director will receive ICMP/FRAG_NEEDED
from xxxHOP to VIP, which we tunnel in IPIP to RIP. 
Here is a simple picture showing the MTU for each hop:
	</para>
<programlisting><![CDATA[
				VIP<-CIP
                         ------------------------------
                        |                              |
       1500      1400   v      1300      1200    1100  ^   1000
CLIENT ---> DHOP ---> DIRECTOR ---> RHOP ---> RS ---> CHOP ---> same CLIENT
          CIP->VIP                DIP->RIP          VIP->CIP

CLIENT   - knows about DHOP and uses MTU=1500
DHOP     - hop/router to director, knows MTU=1400 to director
director - sees MTU=1300 to RS, knows (or doesn't know) about RS (MTU=1200)
RHOP     - hop/router to realserver, knows about RS and uses MTU=1200
RS       - connects to CHOP with MTU 1100
CHOP     - hop/router to CLIENT, uses MTU 1000
]]></programlisting>
	<para>
	The steps:
	</para>
	<orderedlist>
		<listitem>
Client sends 1500-byte TCP packet to DHOP (IP DF=1)
		</listitem>
		<listitem>
DHOP returns ICMP/FRAG_NEEDED
		</listitem>
		<listitem>
Client reduces the cached MTU and generates a new shorter 1400-byte packet
		</listitem>
		<listitem>
ipvs() in Director receives the packet and if PMTU for RS is not configured
to 1200, the packet still hits the 1300-byte limit. 
ICMP is replied (back to client).
As the kernel/IPVS does not update PMTU cache based on ICMP for our IPIP packets, 
the PMTU for DIP->RIP has to be configured manually in the director
(if it's going to be set at all there).
Director encapsulates the CIP->VIP packet inside an ipip packet DIP->RIP.
This packet has a header IPIP 
(there is no SYN, ACK, DATA, FIN) and is a one-off packet,
and not part of a two-way DIP-RIP tcp connection.
		</listitem>
		<listitem>
The decapsulated packet arriving at the RS (CIP->VIP)
can't result in any packets going back to the director.
Once decapsulated the RS forgets that DIP sent the packet,
and the RS now sees the original packet from client.
If the IPIP packet (DIP->RIP) is too big, the RS won't 
cause an icmp FRAG_NEEDED to be sent back to the DIP -
the RS is not a router, only the RHOP will send an ICMP packet.
		</listitem>
		<listitem>
CLIENT sends 1280-byte packet which IPVS tunnels into 20+1280 IPIP packet.
		</listitem>
		<listitem>
RHOP generates ICMP/FRAG_NEEDED (src_addr=RHOP dst_addr=DIP). 
We don't accept this icmp packet and the icmp information is lost (the problem mentioned in URL).
I don't remember if this is a problem with ip_vs() or the Linux kernel.
Maybe the kernel learns the PMTU from the first ICMP packet, 
but IPVS does not see the ICMP packet. 
I hope for the 2nd packet from CIP IPVS will detect the lower MTU limit
and will return ICMP immediately to CIP. 
Maybe IPVS looking for ICMP packets in LOCAL_IN can see this first error, 
but it is hard to forward similar message to the client.
		</listitem>
	</orderedlist>
	<para>
If instead the director knows about the 1200-byte limit, 
then any IPIP packet from director will reach RS without any ICMP replies.
One way of doing this would be by setting the mtu for the route DIP->RIP.
(This command sets a lower MTU for all packets, not just ipip packets.)
	</para>
<programlisting><![CDATA[
director# ip route add RIP via RHOP dev DEV src DIP mtu 1200
]]></programlisting>
	<para>
If the RS generates a 1500-byte TCP reply packet (VIP->CIP), 
then CHOP will generate ICMP reply to the VIP, 
that should come in director, if routed properly
(this packet will likely traverse the internet using a path
separate to the client-director-RS-client path). 
On arrival at the director, the director will use
<filename>icmp.c:icmp_unreach()</filename> to learn the PMTU.
<filename>ip_rt_frag_needed()</filename> will save the value in the routing cache.
Since the director doesn't send packets to CHOP, the problem then
is how this information is used.
The kernel's ICMP protocol receiver parses the information, 
updates PMTU in cache, but fails to deliver it to the upper
layers as happens when delivering errors to sockets. 
This time IPVS was the sender.
That is why the LOCAL_IN hook exists, 
where IPVS can listen for these errors, 
but as I said, it is difficult to generate ICMP error to send to the CIP.
	</para>
	<para>
Another problem problem is what MTU to use between RS and clients,
but IPVS should properly forward (tunnel) any ICMP errors from
hops between RS and (before) client to the RS (Joe: the director?). 
The client will never trigger an ICMP reply, which is generated only by routers.
CHOP replies to the packet VIP->CIP, so this ICMP packet comes to the VIP (director)
and IPVS will select the appropriate connection in the <command>ipvsadm</command> table,
and forward the ICMP information in an IPIP packet to the RIP
(as happens for the regular TCP packets from the CIP).
ip_vs() used to have forwarding of ICMP from the non-error class icmp packets
(<emphasis>e.g.</emphasis> ICMP ECHO), 
but someone dropped it from 2.6 as an unused feature.
	</para>
	<para>
	I hope that is how IPIP setups work.
	</para>
	</section>
	<section id="mtu_early_signs_of_problems">
	<title>MTU: early signs of problems</title>
	<para>
<emphasis>awysock (at) absoftware (dot) com</emphasis> 28 Nov 2003
	</para>
	<blockquote>
		<para>
I've set up two UM Load blancers running LVS 1.0.10 and have them up and running.  
I'm using LVS-Tun since I rent my servers and my IP addresses are all over the place.
My site deals with lots of photos, 
so my users are doing large POSTS along with large POSTS of Text data.
It seems when the ethernet packet goes over the 1460 byte mark
only some of the users fail others (my own machines) work just fine.
I have tried it on my windows machine and my MAC I have no problem,
but when somebody elsewhere on the net does the
same function they fail with a 404 or timeout error on their end.
Its only some of the people, others are not having the problems.
If they go directly to the server it works.
So I'm guessing it something between the LVS and the Real Servers.
		</para>
		<para>
I have changed the MTU value for eth0 on the director to 1400.
All that does for me is make more machines
(all that I have tested) suffer from the same problem.
Should the MTU value be changed at different places?
<emphasis>i.e.</emphasis> both ends of the tunnel?
I knew that our choice to use Windows 2000, would haunt me!
Does anyone know how to change the MTU for an IP tunnel in Windows 2000?
		</para>
	</blockquote>
	<para id="ratz_mtu">
Ratz, 1 Dec 2003
	</para>
	<para>
<ulink url="http://insight.zdnet.co.uk/communications/networks/0,39020427,2123537-2,00.htm">
Enable PMTUDiscovery in w2k</ulink>
(http://insight.zdnet.co.uk/communications/networks/0,39020427,2123537-2,00.htm)
and
<ulink url="http://www.dslreports.com/drtcp">DrTCP</ulink>
(http://www.dslreports.com/drtcp) 
(Joe: presumably you want <filename>DRTCP019.exe</filename>, support for MTU set in w2k).
	</para>
	<blockquote>
		<para>
The MTU was originally set to 1500 on all machines.
Most machines worked but some would not when posting large amounts of data.
		</para>
		<itemizedlist>
			<listitem>
When I set the MTU for all interfaces on the director to 1400
and leave the MTU for the tunnel untouched at 1500, all machines would fail.
			</listitem>
			<listitem>
When I set the MTU for all interfaces on the director to 1400 and set the MTU for
the tunnel at 1400, all machines would fail.
			</listitem>
			<listitem>
With the MTU for the tunnel set to 1400. I can set the MTU for the director
to anywhere between 1420 - 1500 before it fails with all machines.
			</listitem>
			<listitem>
The largest packet I can transmit on the ISP's network without it fragmenting is
1472 although they claim their MTU is 1500. (ping www.linux.org -l -f 1472 works
but anything bigger does not)
			</listitem>
		</itemizedlist>
		<para>
This makes no sense to me. The only way I can think this is correct is if:
Maximum packet size (without a tunnel) between director and realservers is 1500.
If the header for IPIP tunnel is about 20 bytes, 
then the maximum packet size for packets within the tunnel is 1480.
Therefore, the MTU for the director must be at least 20 more than the MTU for the tunnel.
So why does using 1400 everywhere make it all fail, 
but 1500 everywhere only fail on some machines?
		</para>
		<para>
What can I set the MTU values to in order to guarantee it working with all clients?
Most of our clients have no technical knowledge and this is becomming a nightmare!
		</para>
	</blockquote>
	<para>
Horms 30 Nov 2003
	</para>
	<para>
typically the MTU used is 1500 bytes. 
But when tunnels come into play then this becomes slightly smaller because of
the overhead for the tunnel. 
This should not be an issue but in practice it often makes sense to manually set
the MTU to the smaller value on applicable interfaces.
	</para>
	<para id="ratz_mtu_route">
ratz 01 Dec 2003
	</para>
	<para>
... or the mtu of the tunnel's routing entity for that matter. 
This is faster and less intrusive than adjusting down the whole physical interface's mtu. 
I use it for boxes where I have dozens of VPN tunnels over a physical interface, 
but also non-tunneled traffic. 
	</para>
	<para>
Joe
	</para>
	<note>
Ratz is saying to change the MTU not for the interface
(which will affect all routes through that interface), but only for the route.
Presumably the route is DIP->RIP 
(the packet on arrival at the RIP is decapsulated to the packet with dest_addr=VIP).
(Feb 2007 - Ratz posted that he got the idea from off-line discussions with Julian. 
But Ratz gets the credit for telling us about it.)
	</note>
	<para>
Roberto Nibali <emphasis>ratz (at) drugphish (dot) ch</emphasis> 01 Jun 2004 
	</para>
	<para>
You can set the mtu for a route to/from the VIP. 
You must of course pay attention to 
route selection which can be investigated with ip rule/ip route or the 
shell tools I've written to display routing tables.
So you might need to put the VIP route into a special routing table 
which gets parsed before the other routes. Also don't forget to flush 
the routing cache.
	</para>
	<para>
Joe: in principle this is easy to do, but no-one has done it yet.
The ipip packet from the director to the realserver is DIP->RIP.
Ideally you would only want to change the mtu for the ipip packets
to the RIP (or to the RIP network), so that other packets to the RIP
(<emphasis>e.g.</emphasis> logging, administration) have standard MTUs.
As well we aren't sure yet whether PMTU works, 
even if we do change the mtu for the DIP->RIP (someone could look in the code).
Here's how Ratz changes the MTU for the default route.
	</para>
	<para>
Ratz 05 Feb 2007
	</para>
	<para>
Here I add a default route to a new table and change the default mtu.
Basically you can use the "change" keyword in conjunction with the "mtu"
selector on the specific route.
	</para>
<programlisting><![CDATA[
root@laphish2:~# ip route help
Usage: ip route { list | flush } SELECTOR
       ip route get ADDRESS [ from ADDRESS iif STRING ]
                            [ oif STRING ]  [ tos TOS ]
       ip route { add | del | change | append | replace | monitor } ROUTE
SELECTOR := [ root PREFIX ] [ match PREFIX ] [ exact PREFIX ]
            [ table TABLE_ID ] [ proto RTPROTO ]
            [ type TYPE ] [ scope SCOPE ]
ROUTE := NODE_SPEC [ INFO_SPEC ]
NODE_SPEC := [ TYPE ] PREFIX [ tos TOS ]
             [ table TABLE_ID ] [ proto RTPROTO ]
             [ scope SCOPE ] [ metric METRIC ]
             [ mpath MP_ALGO ]
INFO_SPEC := NH OPTIONS FLAGS [ nexthop NH ]...
NH := [ via ADDRESS ] [ dev STRING ] [ weight NUMBER ] NHFLAGS
OPTIONS := FLAGS [ mtu NUMBER ] [ advmss NUMBER ]
           [ rtt NUMBER ] [ rttvar NUMBER ]
           [ window NUMBER] [ cwnd NUMBER ] [ ssthresh NUMBER ]
           [ realms REALM ]
TYPE := [ unicast | local | broadcast | multicast | throw |
          unreachable | prohibit | blackhole | nat ]
TABLE_ID := [ local | main | default | all | NUMBER ]
SCOPE := [ host | link | global | NUMBER ]
FLAGS := [ equalize ]
MP_ALGO := { rr | drr | random | wrandom }
NHFLAGS := [ onlink | pervasive ]
RTPROTO := [ kernel | boot | static | NUMBER ]

root@laphish2:~# ip route show
192.168.1.0/24 dev eth1  proto kernel  scope link  src 192.168.1.32
default via 192.168.1.1 dev eth1
root@laphish2:~# ip rule show
0:      from all lookup local
32766:  from all lookup main
32767:  from all lookup default
root@laphish2:~# ip rule add from 10.0.0.0/16 table 33 prio 100
root@laphish2:~# ip rule show
0:      from all lookup local
100:    from 10.0.0.0/16 lookup 33
32766:  from all lookup main
32767:  from all lookup default
root@laphish2:~# ip route add default via 192.168.1.1 dev eth1 table 33
root@laphish2:~# ip route show table 33
default via 192.168.1.1 dev eth1
root@laphish2:~# ip route change default via 192.168.1.1 mtu 1000 table 33
root@laphish2:~# ip route show table 33
default via 192.168.1.1 dev eth1  mtu 1000

Cleanup the stuff:

root@laphish2:~# ip route flush table 33
root@laphish2:~# ip rule del prio 100
root@laphish2:~# ip rule show
0:      from all lookup local
32766:  from all lookup main
32767:  from all lookup default
]]></programlisting>
	<para>
Jacob Coby <emphasis>jcoby (at) listingbook (dot) com</emphasis> 01 Dec 2003
	</para>
	<para>
Decreasing the MTU with this bug only causes more problems; it causes the
packets to fragment MORE often.
When I had the issue, I could decrease the MTU to 200 bytes, and the
connection would fail at a payload of ~160 (20b for the IP header, 20b for
the IPIP header), even with non-tcp data, like ping.
	</para>
	<para>
Julian 28 Nov 2003
	</para>
	<para>
try LVS with 2.4.23 as it contains a fix for packets longer than mtu.
	</para>
	<para>
(and later) Julian Anastasov 24 Feb 2004, 29 May 2004
	</para>
	<para>
	There is only one remaining problem related to LVS-TUN: there
is no handling of ICMP errors being received on a local IP after being
returned from somewhere in the path (DIP->RIP) coming back to the DIP
and containing the reply to tunneled packet
(<emphasis>e.g.</emphasis>
a frag_needed message and carrying the first few bytes of the packet).
We do not relay these messages, generated between the director and the
realserver, back to the client.
The correct target for the ICMP message depends: the director is
sending 20 bytes more (the ipip overhead), and if this is causing the
ICMP message, then the client need not receive the ICMP message
in all cases.
The client should only receive an ICMP message if the director
detects a lower PMTU.
While TCP and UDP handle ICMP errors, IPIP does not handle them well.
The LVS-DR and LVS-NAT forwarding preserve the sender's IP in which case
ICMP traffic from realservers (or hosts before realservers)
is always returned to the client.
But if LVS-Tun is used, the ICMP packets are not returned to the client.
	</para>
	<para>
If the only traffic from the director to the LVS-Tun realservers is IPVS traffic,
then the routing cache does not receive the PMTU info from ipip_err()
and we don't learn the correct path MTU to the realserver.
Then, on forwarding packets,
the IPVS code cannot detect that the path has lower PMTU.
But this is theory, not really tested.
Maybe we can update the PMTU
in the routing cache by listening to these ICMP errors in LOCAL_IN?
Needs experiments and time for fixing, patches are welcome.
	</para>
	<para>
There is no such thing as an MTU for ipip with IPVS. 
IPVS extends the packet with 20 bytes by prepending IPIP header and ignores the mtu. 
IPVS has its own encapsulation and uses the route to the RIP
(you do not need to configure a tunl0 device on the director).
	</para>
	<blockquote>
I would love to upgrade the Kernel (currently 2.4.20)
but that is not an option as a quick fix at the moment. -
Live environment and the like.
	</blockquote>
	<para>
This time the fix is not in the IPVS code:
(see <ulink url="http://linux.bkbits.net:8080/linux-2.4/hist/net/ipv4/ip_output.c?nav=index.html|src/.|src/net|src/net/ipv4">the kernel bug list</ulink>
http://linux.bkbits.net:8080/linux-2.4/hist/net/ipv4/ip_output.c?nav=index.html|src/.|src/net|src/net/ipv4). 
The problem is that <filename>skb->nfcache</filename>
is not copied on [re]fragmentation.
Here's a 
posting and patch by Julian to the linux-netdev mailing list
<ulink url="http://marc.theaimsgroup.com/?l=linux-netdev&amp;m=106589293316918&amp;w=2">
posting and patch by Julian to the linux-netdev mailing list
</ulink>
(http://marc.theaimsgroup.com/?l=linux-netdev&amp;m=106589293316918&amp;w=2).
	</para>
	<para>
	But we need to see your tcpdump output first
because the PMTUD (path MTU discovery) is usually enabled.
	</para>
	<para>
Joe
	</para>
	<blockquote>
IPIP is a one-way channel (packets don't come back?)
and PMTUD doesn't work?
	</blockquote>
	<para>
Julian
	</para>
	<para>
	The director still can receive ICMP errors with the source somewhere
between the LVS-Tun realserver and the director.
	</para>
	<para>
Chris Paul
	</para>
	<blockquote>
The problem is I can not reproduce the error. We only have a small number of non
technical customers who are having trouble, but I can only go so far when it
comes to asking them to debug our services.
	</blockquote>
	<para>
Julian 01 Dec 2003
	</para>
	<para>
	Then your problem is related to the client-director PMTU. 
I understand that it can be difficult to trace an unknown client,
but do you have some kind of ICMP filtering between clients and the director?
	</para>
	<para>
The problem came up again in May 2004 (when the current kernel is 2.4.26).
	</para>
	<para>
Casey Zacek <emphasis>cz (at) neospire (dot) net</emphasis> 26 May 2004
	</para>
	<blockquote>
		<para>
The problem, as described by one of my customers, 
is this (the customer is running phpBB on 3 Linux/Apache servers with an LVS-Tun setup):
		</para>
		<blockquote>
For very few users, when they post long posts (anything over a few
lines) and hit submit, the browser appears to hang and finally it
times out. Similar effects if they try and update their profiles. I
even experienced this on my home computer. I use a proxy server
sometimes and it showed the request being transmitted from my computer
but ultimately no response was received from the site. Now, in most
instances of this, we have found that the affected users are on
broadband using a router of some type. I myself use a cable modem
connected through a Linksys Router. When I experienced the issue, I
was able to post from work, but not from home. I fiddled with my
setup, thinking it was cookies or caching of some type and ultimately
performed a firmware upgrade on my router. Suddenly the problem went
away.
		</blockquote>
		<para>
At the time, I was running kernel 2.4.25 (IPVS 1.0.10), but since
upgraded to 2.4.26 (IPVS 1.0.11), then 2.6.6 (IPVS 1.2.0).  I have
asked the customer to retest it, but he'll have to talk to some of his
users, from the sound of things, since he upgraded his router
firmware.  I'd love to chalk it up to "client router problems," but
that probably won't be good enough for this customer. The customer's
setup worked using
a Riverstone smartswitch router running what equates to LVS-NAT, but
it does not work with this LVS-Tun setup.
		</para>
		<para>
With all three versions, I get a lot of these messages:
		</para>
<programlisting><![CDATA[
IPVS: ip_vs_tunnel_xmit(): frag needed
]]></programlisting>
	</blockquote>
	<para>
Julian 
	</para>
	<para>
	This message means that the IPVS director is generating
ICMP errors to request that the client reduce the packet size. 
Maybe these ICMP messages are filtered somewhere and do not reach the client.
	</para>
	<para>
        I have a step-by-step
howto for TUN setups: http://www.ssi.bg/~ja/TUN-HOWTO.txt
	</para>
	<note>
Joe: This URL doesn't directly address the mtu problem. 
It checks the capsulation and routing.
	</note>
	<para>
Joe
	</para>
	<blockquote>
Why is the default MTU for ipip packets 1480, rather than 1500+overhead_for_ipip=1520?
Is 1500 a hardware buffer size limit in the NICs? 
(<emphasis>i.e.</emphasis> hardware buffer=1500?)
	</blockquote>
	<para>
Julian
	</para>
	<para>
I don't know which the origin of the 1500 limit. 
Maybe it is a balance between link sharing and protocol header overhead.
	</para>
	<para>
There is a convention in IPv4 to reply with an ICMP error if a
packet with DF flag set reaches a smaller pipe 
(<emphasis>i.e.</emphasis> packet length > PMTU).
If the DF flag is not set, the packet is fragmented into MTU-sized fragments.
	</para>
	<note>
For an explanation of PMTU and the DF flag, see
<ulink url="http://www.netheaven.com/pmtu.html">PMTU - Path MTU Discovery</ulink>
(http://www.netheaven.com/pmtu.html).
	</note>
	<para>
        There can be many problems related to MTU:
	</para>
	<itemizedlist>
		<listitem>
no ICMP errors generated (from director or from other hosts
between director and realservers)
		</listitem>
		<listitem>
ICMP errors do not reach their destination (the client), 
<emphasis>e.g.</emphasis> filters dropping blindly any ICMP traffic
		</listitem>
		<listitem>
ICMP errors generated from realservers (or from hosts between
the director and realservers) 
not forwarded from director to client
		</listitem>
		<listitem>
PMTU not updated in routing cache due to IP TOS changes after routing
		</listitem>
	</itemizedlist>
	<para>
Chris Paul <emphasis>Chris (at) baonline (dot) co (dot) uk</emphasis> 27 May 2004
	</para>
	<para>
The problem is caused by the linux kernel not taking into account 
the size of the ipip tunnel headers when sending traffic over an ipip tunnel. 
	</para>	
	<para>
Basically, the MTU (the largest size packet than can be sent over a network) 
is normally 1500 bytes. 
With the IP header information this drops to 1492, 
so the largest size of packet that can be sent over an IP link, 
before the packet get split into multiple packets is 1492 bytes. 
When you use ipip tunneling, 
there is an additional header that takes the maximum transmition size 
through the link to somthing like 1480. 
Linux kernel 2.4.??? does not take into account this additional header 
and sets the mtu for the ipip tunnel to 1492. 
So if you send a packet that is between 1480 and 1492, 
it gets truncated rather than split into multiple packets. 
The ipip tunnel destination then waits to receive the rest of the packet, 
which it never arrives. The result is the server never responds. 
	</para>
	<para>
When I was having this problem, 
it was a nightmare because you can not guarantee it will fail. 
It only fails when the packet size is very specific 
and the size of the header is also large.
To fix this you can either.
	</para>
	<itemizedlist>
		<listitem>
Upgrade to kernel 2.6.???
		</listitem>
		<listitem>
Change the MTU values on the director.
		</listitem>
	</itemizedlist>
	<para>
I solved it by changing the MTU values, 
but it was nearly a year ago now I and can't remember exactly which ones I changed, 
<emphasis>i.e.</emphasis>, 
the RIP on the director, the tunnel from the director, or the tunnel from the realserver.
	</para>
	<para id="chris_paul">
Chris Paul <emphasis>Chris (at) baonline (dot) co (dot) uk</emphasis> 27 May 2004
	</para>
	<para>
You have to change the mtu value on the end of the IP tunnel 
that initiates the tunnel <emphasis>i.e.</emphasis> the realserver
(in this instance, a w2k box). 
This value should be close to the mtu value of the physical interface 
it is going through, 
but small enough to ensure there is enough space left for the ipip header. 
We use 1400 and have never had any reports of it failing.
To do this you goto registry 
and add a dword entry called MTU with the decimal value 1400 (safe) into
	</para>
<programlisting><![CDATA[
hklm\system\currentcontrolset\services\tcpip\parameters\interfaces\{guid of ip tunnel}
]]></programlisting>
	<para>
reboot
	</para>
	<note>
with w2k, XP, you can "Restart Networking"
	</note>
	<note>
Joe - see <xref linkend="tunl_mtu_solved"/> for Casey Zacek's modification of this method.
	</note>
	<para>
If the mtu is not set, you get lots of 
<filename>IPVS: ip_vs_tunnel_xmit(): frag needed</filename>
messages logged to the console and connections hang.
	</para>
	<para>
Joe
	</para>
	<blockquote>
I would have thought you'd set the mtu at the director end. Presumably
if any end of the segment has a reduced mtu, then both ends of the segment
should be notified about it.
	</blockquote>
	<para>
Julian
	</para>
	<para>
This message means "fragmentation needed but DF flag set".
<filename>ip_vs_tunnel_xmit()</filename> tries to prepend IPIP header, 
but notices that the resulting packet with DF flag set will exceed the
PMTU(director->RS) limit, so it generates an ICMP error
instead of xmit-ing the packet to the RS.
	</para>
	<para>
Joe
	</para>
	<blockquote>
What messages would you get if the icmp problem was about the link between
the tunnel realserver and the director?
	</blockquote>
	<para>
        Messages from the same type but we haven't handled this case yet.
In the meantime, setting the proper PMTU in the director for the route 
to the realserver is a good idea.
	</para>
	<para>
Jacob Coby <emphasis>jcoby (at) listingbook (dot) com</emphasis> 27 May 2004
	</para>
	<para>
I could test for the problem reliably by using ping with 
packet_size&gt;934 (934 and lower worked fine). 
Once I bumped it up over 934, I'd see 
Must Fragment (MF) ICMP messages being sent, 
and the ping request would have no response.  
As I lowered the MTU, the size of the ping that would 
cause the problem lowered in direct proportion.  
A 1500 MTU would cause a 935 byte ping to fail, 
a 1400 MTU would cause a 835 byte ping to fail, and so on.
Any HTTP GET or POST over that 934 byte payload 
would cause the site to not respond.
	</para>
	<para>
Chris Paul 
	</para>
	<blockquote>
Where are you setting your mtu of 1400?
You have to make sure that it is the mtu for data inside the tunnel.
When I changed the mtu values, the only way I could reliably get it
to change the size inside the tunnel rather than the whole tunnel
packets was from the realserver not the director.
	</blockquote>
	<para>
Jacob Coby 
	</para>
	<para>
I have no idea which MTU I was setting.  I could get the problem to go 
away for one or two times, and then it would come back.
It's been over a year since I messed with LVS-TUN, and I'm now running 
LVS-DR.
	</para>
	<para>
Peter Mueller <emphasis>pmueller (at) sidestep (dot) com</emphasis> 27 May 2004
	</para>
	<para>
I've heard people in poptop use this hack.  Maybe you can modify for
your use in this situation.  If it works I like this solution better
than a change to the MTU on the interface.
	</para>
<programlisting><![CDATA[
iptables -A FORWARD -p tcp --tcp-flags SYN,RST SYN -j TCPMSS --set-mss 1300
]]></programlisting>
	<note>
Joe: MSS is maximum segment size, <emphasis>i.e.</emphasis> the payload in the packet,
rather than the packet size (which is set by mtu).
	</note>
	<para>
Julian 3 Jun 2004
	</para>
	<para>
Ratz's work around should work, 
or you can hope that other traffic between director
and RS will update the PMTU in the routing cache.
	</para>
	<para>
Joe
	</para>
	<blockquote>
if you put a tunl0 device on the director, would it receive the PMTU
packets back from the realserver?
	</blockquote>
	<para>
	Yes, it can look into the ICMP errors that include IPIP
header but the current version of ipip.c does not update the
RIP's PMTU. Another option is IPVS to do it in LOCAL_IN.
The VIP does not play here. The forwarded traffic in the director is
routed to daddr=RIP (as for the other forwarding methods). Only the
clients need a route to VIP.
	</para>
	<para>
Joe
	</para>
	<blockquote>
I was thinking to reduce the MTU for the CIP-VIP segment, then
there would be no problem in the DIP-RIP segment. Is this a way
of handling it?
	</blockquote>
	<para>
This is another solution. Just keep
PMTU(CIP-&gt;VIP) &lt;= PMTU(DIP-&gt;RIP) + 20.
I'm not sure you can do it for every client. 
Maybe it can be in the default route :)
	</para>
	<para>
To use Ratz's work-around, you set the PMTU for packets going to the RIP 
(via eth0 on the director, there being no tunl0 devices on the director).
If it is set to 1500 then
you do not need such route as IPVS reports PMTU reduced with 20 
(here 1480) when generating ICMP error to client. 
So, if PMTU to RIP is X or RS sends ICMP error to director 
notifying for PMTU=X then IPVS will report PMTU=(X-20) to client.
	</para>
	<para>
	OTOH, may be it is not so difficult to check in LOCAL_IN
for any FRAG_NEEDED errors and if they reduce the PMTU for RIP
we can update the routing cache. Need to investigate whether
we can easily find that such error is for one of our TUN RIPs.
	</para>
	<para>
What you can do on the director when using LVS-TUN:
	</para>
	<itemizedlist>
		<listitem>
if PMTU to RIP is lower then outdev's MTU then you have to specify it
in special route to RIP. If the PMTU is 1500 you do not need such
route, IPVS automatically reports MTU 1480 to all clients that
send packets&gt;1480. There is no chance for PMTUD to work when
the ICMP errors are dropped between director and client. It will
happen for any used PMTU to RIP.
		</listitem>
		<listitem>
			<para>
run tcpdump and check for any received or generated ICMP errors
			</para>
			<para>
The PMTU is not updated in the routing cache
if director receives ICMP_FRAG_NEEDED. This is easy to detect
and to solve. The good news is that you can detect it from any client,
send large file, tcpdump for ICMP errors coming from realservers to 
director. If this is the case (PMTU to RIP is lower than outdev's MTU) 
than you can try to specify pmtu in special route to RIP. Once the 
director knows the right PMTU to RIP then it will report it to every 
client that violates it. There is no need IPVS to relay the ICMP error
coming from RIP to the client, we just know how to generate
it on each request from client. The only benefit can be if
ipip.c is patched to update the PMTU in the routing cache and
to avoid creating special route to RIP.
			</para>
		</listitem>
		<listitem>
	All other problems can be related to filtering of the
ICMP errors generated from director and sent to client. Such
places for filtering can be the netfilter in director or any
router used to reach the client. It is enough to check that
the ICMP errors generated in director reach the director's uplink
GW. Then you hope that the client does not filter ICMP.
		</listitem>
	</itemizedlist>
	<para>
Joe
	</para>
	<blockquote>
what is the MTU doing in the output of <command>ip addr show dev tunl0</command>
when you have a tunl device on a machine?
I can set it (can't I?). Is the mtu meaningless, ignored, what?
	</blockquote>
	<para>
It is ignored for IPVS traffic, IPVS has its own encapsulation
and uses the route to RIP (you do not need to configure tunl0
in director).
The tunl0 device is usually needed to receive IPIP packets, so
in normal cases you do not need such interface in director even
when using TUN realservers. The PMTU setting must be for the route
to RIP. Such setting (and special route to daddr=RIP) can be needed
only if PMTU to RIP is less than the outdev MTU.
	</para>
	<blockquote>
So with regular ipip tunneling (not ipvs) you only need the tunl0 device
on the receiving end? The only reason you need a tunl0 device on the transmitting
end is to handle the packets that reply?
	</blockquote>
	<para>
        For regular ipip purposes tunl0 can be used both for send and
for receive. IPVS simply knows how to create ipip packets without using
the ipip code.
	</para>
	</section>
	<section id="tunl_mtu_solved" xreflabel="tunl MTU solved">
	<title>tunl mtu solved: Setting the MTU by MSS with iptables on the realserver</title>
	<note>
Casey's solution is run on the realserver. 
Presumably a similar solution could be found for the director.
Ratz's <link linkend="ratz_mtu_route">
method of setting the mtu for the route rather than the interface</link> runs on the director.
	</note>
	<para>
Casey Zacek <emphasis>cz (at) neospire (dot) net</emphasis> 2005/03/11
	</para>
	<para>
I've emailed about this before, and nothing we ever came up which really worked.  
The real problem I've always had is that
I've never had a means for duplicating it (possibly because I didn't
fully understand the problem -- I can probably duplicate it at will
now), and my customers have eventually just either accepted it and
moved on or changed to an LVS-NAT environment.
I finally came across someone whose home network was setup in
such a way as to experience the "problem", so I decided to figure it
out once and for all and hopefully end all the confusion.
Attached is a piece of PHP (lvs-tun-test.php) that'll duplicate the problem.  
The "submit" query will timeout if you are experiencing the problem.
 	</para>
	<para>
Matthew Boehm <emphasis> matthew (at) matthewboehm (dot) com</emphasis> 6 Jan 2007
(and Casey).
	</para>
	<note>
		<para>
With IE6/7: When you submit the POST, the page just reloads (Matthew) 
or hangs/timesout with no data posted (Casey).
		</para>
		<para>
With Firefox/Netscape: You get a "Bad Request" page.
		</para>
	</note>
<programlisting><![CDATA[
Cut here --- lvs-tun-test.php --------------------------------------
<html>
<head>
	<title>big POST test</title>
</head>
<body>
<?php echo $HTTP_POST_VARS['test']; ?>
<form action="lvs-tun-test.php" method="POST">
<textarea name="test" cols="100" rows="10">
alskdjfdaslkfjdslkjadsflkdsjfalsdkjfdsalkfjasdlkfjasdflkjadsfkljadsfkljasdflkasdjflksdjf
alskdjfdaslkfjdslkjadsflkdsjfalsdkjfdsalkfjasdlkfjasdflkjadsfkljadsfkljasdflkasdjflksdjf
alskdjfdaslkfjdslkjadsflkdsjfalsdkjfdsalkfjasdlkfjasdflkjadsfkljadsfkljasdflkasdjflksdjf
alskdjfdaslkfjdslkjadsflkdsjfalsdkjfdsalkfjasdlkfjasdflkjadsfkljadsfkljasdflkasdjflksdjf
alskdjfdaslkfjdslkjadsflkdsjfalsdkjfdsalkfjasdlkfjasdflkjadsfkljadsfkljasdflkasdjflksdjf
alskdjfdaslkfjdslkjadsflkdsjfalsdkjfdsalkfjasdlkfjasdflkjadsfkljadsfkljasdflkasdjflksdjf
alskdjfdaslkfjdslkjadsflkdsjfalsdkjfdsalkfjasdlkfjasdflkjadsfkljadsfkljasdflkasdjflksdjf
alskdjfdaslkfjdslkjadsflkdsjfalsdkjfdsalkfjasdlkfjasdflkjadsfkljadsfkljasdflkasdjflksdjf
alskdjfdaslkfjdslkjadsflkdsjfalsdkjfdsalkfjasdlkfjasdflkjadsfkljadsfkljasdflkasdjflksdjf
alskdjfdaslkfjdslkjadsflkdsjfalsdkjfdsalkfjasdlkfjasdflkjadsfkljadsfkljasdflkasdjflksdjf
alskdjfdaslkfjdslkjadsflkdsjfalsdkjfdsalkfjasdlkfjasdflkjadsfkljadsfkljasdflkasdjflksdjf
alskdjfdaslkfjdslkjadsflkdsjfalsdkjfdsalkfjasdlkfjasdflkjadsfkljadsfkljasdflkasdjflksdjf
alskdjfdaslkfjdslkjadsflkdsjfalsdkjfdsalkfjasdlkfjasdflkjadsfkljadsfkljasdflkasdjflksdjf
alskdjfdaslkfjdslkjadsflkdsjfalsdkjfdsalkfjasdlkfjasdflkjadsfkljadsfkljasdflkasdjflksdjf
alskdjfdaslkfjdslkjadsflkdsjfalsdkjfdsalkfjasdlkfjasdflkjadsfkljadsfkljasdflkasdjflksdjf
alskdjfdaslkfjdslkjadsflkdsjfalsdkjfdsalkfjasdlkfjasdflkjadsfkljadsfkljasdflkasdjflksdjf
alskdjfdaslkfjdslkjadsflkdsjfalsdkjfdsalkfjasdlkfjasdflkjadsfkljadsfkljasdflkasdjflksdjf
alskdjfdaslkfjdslkjadsflkdsjfalsdkjfdsalkfjasdlkfjasdflkjadsfkljadsfkljasdflkasdjflksdjf
alskdjfdaslkfjdslkjadsflkdsjfalsdkjfdsalkfjasdlkfjasdflkjadsfkljadsfkljasdflkasdjflksdjf
alskdjfdaslkfjdslkjadsflkdsjfalsdkjfdsalkfjasdlkfjasdflkjadsfkljadsfkljasdflkasdjflksdjf
alskdjfdaslkfjdslkjadsflkdsjfalsdkjfdsalkfjasdlkfjasdflkjadsfkljadsfkljasdflkasdjflksdjf
alskdjfdaslkfjdslkjadsflkdsjfalsdkjfdsalkfjasdlkfjasdflkjadsfkljadsfkljasdflkasdjflksdjf
alskdjfdaslkfjdslkjadsflkdsjfalsdkjfdsalkfjasdlkfjasdflkjadsfkljadsfkljasdflkasdjflksdjf
alskdjfdaslkfjdslkjadsflkdsjfalsdkjfdsalkfjasdlkfjasdflkjadsfkljadsfkljasdflkasdjflksdjf
alskdjfdaslkfjdslkjadsflkdsjfalsdkjfdsalkfjasdlkfjasdflkjadsfkljadsfkljasdflkasdjflksdjf
alskdjfdaslkfjdslkjadsflkdsjfalsdkjfdsalkfjasdlkfjasdflkjadsfkljadsfkljasdflkasdjflksdjf
alskdjfdaslkfjdslkjadsflkdsjfalsdkjfdsalkfjasdlkfjasdflkjadsfkljadsfkljasdflkasdjflksdjf
alskdjfdaslkfjdslkjadsflkdsjfalsdkjfdsalkfjasdlkfjasdflkjadsfkljadsfkljasdflkasdjflksdjf
alskdjfdaslkfjdslkjadsflkdsjfalsdkjfdsalkfjasdlkfjasdflkjadsfkljadsfkljasdflkasdjflksdjf
alskdjfdaslkfjdslkjadsflkdsjfalsdkjfdsalkfjasdlkfjasdflkjadsfkljadsfkljasdflkasdjflksdjf
alskdjfdaslkfjdslkjadsflkdsjfalsdkjfdsalkfjasdlkfjasdflkjadsfkljadsfkljasdflkasdjflksdjf
alskdjfdaslkfjdslkjadsflkdsjfalsdkjfdsalkfjasdlkfjasdflkjadsfkljadsfkljasdflkasdjflksdjf
alskdjfdaslkfjdslkjadsflkdsjfalsdkjfdsalkfjasdlkfjasdflkjadsfkljadsfkljasdflkasdjflksdjf
alskdjfdaslkfjdslkjadsflkdsjfalsdkjfdsalkfjasdlkfjasdflkjadsfkljadsfkljasdflkasdjflksdjf
alskdjfdaslkfjdslkjadsflkdsjfalsdkjfdsalkfjasdlkfjasdflkjadsfkljadsfkljasdflkasdjflksdjf
alskdjfdaslkfjdslkjadsflkdsjfalsdkjfdsalkfjasdlkfjasdflkjadsfkljadsfkljasdflkasdjflksdjf
alskdjfdaslkfjdslkjadsflkdsjfalsdkjfdsalkfjasdlkfjasdflkjadsfkljadsfkljasdflkasdjflksdjf
alskdjfdaslkfjdslkjadsflkdsjfalsdkjfdsalkfjasdlkfjasdflkjadsfkljadsfkljasdflkasdjflksdjf
alskdjfdaslkfjdslkjadsflkdsjfalsdkjfdsalkfjasdlkfjasdflkjadsfkljadsfkljasdflkasdjflksdjf
alskdjfdaslkfjdslkjadsflkdsjfalsdkjfdsalkfjasdlkfjasdflkjadsfkljadsfkljasdflkasdjflksdjf
</textarea>
<input type="submit">
</form>
</body>
</html>
Cut here -----------------------------------------------------------
]]></programlisting>
	<para>
In order to force yourself to experience the problem, you need to
forcefully ignore icmp fragmentation-needed packets.  I am able to do
that on my home network with a simple iptables rule on my firewall:
	</para>
<programlisting><![CDATA[
iptables -I FORWARD -p icmp --icmp-type fragmentation-needed -j DROP
]]></programlisting>
	<para>
Now, I browse the <filename>lvs-tun-test.php</filename> through LVS-Tun, and click submit,
and it just hangs and times out.  
<command>tcpdump</command> shows the expected results.
Then I change the MTU on the loopback interface on the realserver
(It's a w2k box) using <command>regedit</command>, then disable and re-enable the
loopback adapter via the network properties, then click submit again.
Poof, it works.
	</para>
	<para>
<command>tcpdump</command> is my friend.  I started out running <command>tcpdump</command> on the director:
	</para>
<programlisting><![CDATA[
23:13:52.804610 IP (tos 0x0,  ttl 116, id 26413, offset 0, flags [DF],   length: 48)   CIP.60964 > VIP.80: S [tcp sum ok] 3288780265:3288780265(0) win 65535 <mss 1452,nop,nop,sackOK>
23:13:52.810423 IP (tos 0x0,  ttl 116, id 26415, offset 0, flags [DF],   length: 40)   CIP.60964 > VIP.80: . [tcp sum ok] 3288780266:3288780266(0) ack 2303765635 win 65535
23:13:52.813943 IP (tos 0x0,  ttl 116, id 26416, offset 0, flags [DF],   length: 602)  CIP.60964 > VIP.80: P [tcp sum ok] 0:562(562) ack 1 win 65535
23:13:52.820802 IP (tos 0x0,  ttl 116, id 26417, offset 0, flags [DF],   length: 1492) CIP.60964 > VIP.80: . [tcp sum ok] 562:2014(1452) ack 1 win 65535
23:13:52.820887 IP (tos 0xc0, ttl  64, id 25185, offset 0, flags [none], length: 576)  VIP >       CIP: icmp 556: VIP unreachable - need to frag (mtu 1480) for IP (tos 0x0, ttl 116, id 26417, offset 0, flags [DF], length: 1492) CIP.60964 > VIP.80: . 562:2014(1452) ack 1 win 65535
23:13:52.827175 IP (tos 0x0,  ttl 116, id 26419, offset 0, flags [DF],   length: 1492) CIP.60964 > VIP.80: . [tcp sum ok] 2014:3466(1452) ack 90 win 65446
23:13:52.827251 IP (tos 0xc0, ttl  64, id 25186, offset 0, flags [none], length: 576)  VIP >       CIP: icmp 556: VIP unreachable - need to frag (mtu 1480) for IP (tos 0x0, ttl 116, id 26419, offset 0, flags [DF], length: 1492) CIP.60964 > VIP.80: . 2014:3466(1452) ack 90 win 65446
23:13:52.833420 IP (tos 0x0,  ttl 116, id 26420, offset 0, flags [DF],   length: 1492) CIP.60964 > VIP.80: . [tcp sum ok] 3466:4918(1452) ack 90 win 65446
]]></programlisting>
	<para>
The tcp [DF] CIP->VIP (packet length 1492 -- too big), then
IPVS's ICMP response continues until the request eventually times out.
This message is generated every time one of the ICMP responses are
sent:
	</para>
<programlisting><![CDATA[
IPVS: ip_vs_tunnel_xmit(): frag needed
]]></programlisting>
	<para>
The problem comes when the ICMP host-unreachable (change MTU) packets
are ignored/dropped and not acted-upon by the client.  This is a more
common situation than I thought would be the case.
	</para>
	<para>
A few hours of debugging later, I realized that the SYN+ACK packet,
the response from the real server to continue the connection
handshake, is missing.  Duh.  I moved my tcpdumping to a tap in the
network that I knew would get all of the traffic.  The SYN+ACK
packet establishes the MSS (max segment size -- the data segment
size for the packets for this connection) to 1452, just as the
client machine requests (the first packet in the earlier trace).
	</para>
	<para>
Duh!  I had read all the stuff on the URL above, and the
posting by <link linkend="chris_paul">Chris Paul</link>
comes closest to describing the solution:
	</para>
	<para>
In reality, it's not "the end of the IP tunnel that initiates the
tunnel" because the tunnel interface on the w2k box doesn't initiate
anything -- it only receives forwarded traffic from the director.
What he really means is "the interface on the real server that is
handshaking the TCP connection with the client."  The goal is to get
the client to send smaller packets so that they'll make it on to the
realserver.
	</para>
<programlisting><![CDATA[
CLIENT sends SYN to DIRECTOR
DIRECTOR encapsulates SYN packet in IPIP tunnel; sends to REALSERVER
REALSERVER receives SYN packet on LOOPBACK interface
REALSERVER sends SYNACK to CLIENT from LOOPBACK interface w/ MSS=1452
CLIENT sends ACK to DIRECTOR, on to REALSERVER
REALSERVER responds to CLIENT from LOOPBACK
repeat until dead
]]></programlisting>
	<para>
So, we have to change that MSS that gets sent back from realserver to client.  
That is, set the MTU on the loopback interface on the w2k box.
The solution is to do exactly what Chris Paul Chris said, except change from:
	</para>
<programlisting><![CDATA[
hklm\system\currentcontrolset\services\tcpip\parameters\interfaces\{guid of ip tunnel}
]]></programlisting>
	<para>
to:
	</para>
<programlisting><![CDATA[
hklm\system\currentcontrolset\services\tcpip\parameters\interfaces\{guid of MS Loopback Adapter}
]]></programlisting>
	<para>
After all, if you set an MTU in the IP tunnel interface this way, it
won't be there after you reboot, I've found.
Oh, and 1480 is the magic number. 1400 is safe, but 1480 works.
Any higher than that, and it doesn't work as desired.
	</para>
	<para>
So I went to investigate how to do the same thing on my Linux real
servers, only to find that the tunl0 interface, which is the
connection endpoint for Linux realservers, already has an MTU of 1480.
I don't know when that got fixed, but I guess I won't worry about it.
	</para>
	<para>
(later) I was wrong; here's the fix for Linux realservers:
	</para>
<programlisting><![CDATA[
iptables -A OUTPUT -s VIRTUAL-IP -p tcp -m tcp --tcp-flags SYN,RST,ACK SYN,ACK -j TCPMSS --set-mss 1440
]]></programlisting>
	<para>
Tested, tcpdumped, works.  Now I have no more 'IPVS:
ip_vs_tunnel_xmit(): frag needed' messages.  
(At least for now.  We'll see if I'm wrong tomorrow.)
	</para>
	<para>
Chris Paul, 11 Mar 2005
	</para>
	<blockquote>
Isn't this fixed in Kernel 2.6 anyway
	</blockquote>
	<para>
Casey Zacek <emphasis>cz (at) neospire (dot) net</emphasis>
        </para>
	<para>
I really don't think it's possible to fix this on the director (and my
directors are running 2.6.11 anyway -- and it's not fixed there).  The closest
way I could think of was to ignore the DF flag in the incoming TCP
packets and just fragment them anyway.
	</para>
	<para>
Casey Zacek <emphasis>cz (at) neospire (dot) net</emphasis> 2005/04/12
	</para>
	<para>
It's not fixed in 2.6; I still need the iptables rule to set the mss 
	</para>
<programlisting><![CDATA[
# iptables -A OUTPUT -s VIRTUAL-IP -p tcp -m tcp --tcp-flags SYN,RST,ACK SYN,ACK -j TCPMSS --set-mss 1440
]]></programlisting>
	<note>
Joe: we don't know why this works
	</note>
	<para>
Julian Feb 2007
	</para>
	<para>
	Huh, I don't know why, may be because there is such limit
somewhere in the path from RS to client. Path from RS to client is not
different between real servers in DR or TUN mode, they both send
normal reply from VIP to CIP, no IPIP is involved there. May be
problem with a CHOP that can not route ICMP to VIP properly.
	</para>
	<para>
jarol1@seznam.cz <emphasis>J (dot) Libak (at) sh (dot) cvut (dot) cz</emphasis> 07 Dec 2006 
	</para>
	<para>
Today I ran into an MTU problem with LVS-Tun.
Small packets were forwarded to real servers without problems, 
but the bigger ones weren't and TCP retransmissions occurred. 
I noticed the problem dissapeared when I switched to LVS/DR so this gave me
hint to where the problem might be. 
MTU 1480 had to be set on the outgoing interface of realservers
with tunl0 having standard 1500. 
Directors have 1500 on all interfaces. 
This way TCP syn ack contained correct MTU 
and the client didn't send big packets that were discarded on director anymore. 
IP header is 20 bytes long so 1480 is the maximum value that works.
	</para>
	<para>
Casey Zacek <emphasis>cz (at) neospire (dot) net</emphasis> 31 Aug 2007
	</para>
	<para>
For some reason that I cannot remember, 
I have switched off of
this iptables method in favor of using some advanced routing to take
care of the MSS setting.  
	<blockquote>
(Joe: Ratz says that the MTU should be set for the route and not for the device, 
since not all routes/packet types to/from a device need an altered MTU.)
	</blockquote>
I wish I would have shared with the group
when I started it, because I can't remember why I'm doing it this way now.
Still on the real servers, I use routing like so:
	</para>
	<para>
This assumes the VIP is in a class C network
	</para>
<programlisting><![CDATA[
 ip route flush table 42
 ip route add table 42 to VIP_NETWORK/24 dev eth0 advmss 1440
 ip route add table 42 to default via VIP_NETWORK_GATEWAY advmss 1440
 ip rule add from VIP table 42 priority 42
 ip route flush cache
]]></programlisting>
	<para>
So, for example, say VIP is 10.2.2.38
VIP_NETWORK is 10.2.2.0
VIP_NETWORK_GATEWAY is 10.2.2.1 (probably)
	</para>
<programlisting><![CDATA[
 ip route flush table 42
 ip route add table 42 to 10.2.2.0/24 dev eth0 advmss 1440
 ip route add table 42 to default via 10.2.2.1 advmss 1440
 ip rule add from VIP table 42 priority 42
 ip route flush cache
]]></programlisting>
	<para>
The number 42 is just a number I chose when I started this.
	</para>
	<para>
Sameer Garg <emphasis>sameer (dot) garg (at) gmail (dot) com</emphasis> 6 Sep 2007 
	</para>
	<para>
By trial and error I was able to find a work around this:
	</para>
<programlisting><![CDATA[
On the director I did the following
# ip route add REAL_SERVER_IP via DIRECTOR_GATEWAY dev eth0 advmss 1400

On the Real Server
# ip route change default via REAL_SERVER_GATEWAY dev eth0 advmss 1400
]]></programlisting>
	<para>
I am still not sure why I need to make the change on the director
because technically during the three way handshake, the real server
should tell the client about MSS being 1400.I have tried it without
making the changes on the director but it doesn't work.
	</para>
	</section>
	<section id="setting_mtu_by_route" xreflabel="setting the MTU by route">
	<title>Setting the MTU by route</title>
	<note>
This works on the realserver, but not on the director.
We don't know why it doesn't work on the director and
we're not really sure why it works on the realserver either.
	</note>
	<para>
With Casey having a suitable test setup, 
we asked him to test setting the MTU by route
using Julian's suggestion of
	</para>
<programlisting><![CDATA[
director# ip route add RIP via RHOP dev DEV src DIP mtu 1440
]]></programlisting>
	<para>
Casey Zacek <emphasis>cz (at) neospire (dot) net</emphasis> 14 Feb 2007 
	</para>
	<para>
Nope. Doesn't work.
Here's <command>tcpdump</command> running on the realserver showing the first
packet back to the client, which negotiates the MSS for the connection.
	</para>
<programlisting><![CDATA[
21:52:37.819770 IP (tos 0x0, ttl  64, id 0, offset 0, flags [DF], length: 48) \
   VIP.80 > ENDUSER.1276: S [tcp sum ok] 2051800163:2051800163(0) \
   ack 1809535240 win 5840 <mss 1460,nop,nop,sackOK>
]]></programlisting>
	<para>
That "mss 1460" needs to be "mss 1440".  That's the secret magic key
to the universe.
	</para>
	<para>
I got some of these when I blocked icmp-type fragmentation-needed to
my workstation, with logging:
	</para>
<programlisting><![CDATA[
IN=eth0 OUT= MAC=00:18:8b:74:d1:98:00:06:5b:3a:9f:0b:08:00 \
   SRC=66.111.105.216 DST=10.3.3.10 LEN=576 TOS=0x00 PREC=0x00 TTL=62 ID=32755 \
   PROTO=ICMP TYPE=3 CODE=4 [SRC=10.3.3.10 DST=66.111.105.216 LEN=1500 TOS=0x00 \
   PREC=0x00 TTL=62 ID=42460 DF PROTO=TCP SPT=45445 DPT=80 WINDOW=114 RES=0x00 ACK URGP=0 ] MTU=1420
]]></programlisting>
	<para>
And my page request just waited and waited (Firefox 2.0).
When I flushed the icmp-type fragmentation-needed DROP rules, and I
submit the page again, it goes through instantly.
I also tried with 
	</para>
<programlisting><![CDATA[
director# ip route add RIP via RHOP dev DEV src DIP mtu lock 1440
                                                        ^^^^
]]></programlisting>
	<para>
This also did not work.
	</para>
	<para>
Julian
	</para>
	<blockquote>
To tell if this is a PMTU problem 
(rather than we haven't figured out the correct <command>ip route</command> command),
one should check all steps with tcpdump in all boxes, icmp, tcp.
	</blockquote>
	<para>
Now, I can make it work if I do this on the real server:
	</para>
<programlisting><![CDATA[
]]></programlisting>
RS# ip route add table 42 to default via DEFAULTGW advmss 1440
RS# ip rule add from VIP to default table 42 priority 42
	<para>
So, at least it doesn't require iptables.
Also, this doesn't cover any client machine that is not reached via
the default route.  Instead you'd need something more like this:
	</para>
<programlisting><![CDATA[
RS# ip route add table 42 to LOCALNET/xx dev LOCALDEV advmss 1440
RS# ip route add table 42 to default via DEFAULTGW advmss 1440
 .. more entries for any static or other routes ..
RS# ip rule add from VIP table 42 priority 42
]]></programlisting>
	<para>
In most cases, though, these two routes and one rule will cover it.
I think I prefer using iproute to using iptables, as iptables tends to
be more volatile in my environments.
	</para>
	</section>
	<section id="re-mapping_ports_lvs_tun" xreflabel="Re-mapping ports with LVS-Tun">
	<title>rewriting, re-mapping, translating ports with LVS-Tun</title>
	<para>
see <xref linkend="re-mapping_ports_with_iptables"/>
	</para>
	</section>
</section>
<section id="LVS-HOWTO.localnode" xreflabel="LocalNode">
<title>LVS: LocalNode</title>
<para>
We rarely hear of anyone using this to make a director function as
a normal realserver. 
However more specialised roles have been found for localnode.
</para>
<note>
2008: plenty of people are using it now, particularly the <xref linkend="two_box_lvs"/>.
</note>
<itemizedlist>
	<listitem>
<xref linkend="https_on_localnode"/>
	</listitem>
	<listitem>
using the director as a "sorry server"
(<emphasis>e.g.</emphasis> when all realservers are overloaded and
you want to display a "please come back later message"). 
	</listitem>
</itemizedlist>
<para>
With localnode, the director machine can be a realserver too. 
This is convenient when only a small number of machines are available as servers.
</para>
<para>
To use localnode, with <command>ipvsadm</command>
you add a realserver with IP 127.0.0.1 (or any local IP on your director).
You then setup the service to listen to the VIP on the director, 
so that when the service replies to the client, 
the src_addr of the reply packets are from the VIP.
The client is <emphasis role="bold">not</emphasis> 
connecting to a service on 127.0.0.1 (or a local IP on the director),
despite <command>ipvsadm</command> installing a service with RIP=127.0.0.1.
</para>
<para>
Some services, <emphasis>e.g.</emphasis> telnet listen on all IP's on the
machine and you won't have to do anything special for them,
they will already be listening on the VIP.
Other services, <emphasis>e.g.</emphasis> http, sshd, have to be 
specifically configured to listen to each IP. 
</para>
<para>
	<note>
Configuring the service to listen to an IP which is <emphasis role="bold">
not</emphasis> the VIP, is the most common mistake of people reporting
problems with setting up LocalNode.
	</note>
</para>
<para>
LocalNode operates independantly of NAT,TUN or DR modules
(<emphasis>i.e.</emphasis> you have have LocalNode running
on a director that is forwarding packets to realservers
by any of the forwarding methods).
</para>
<blockquote>
	<para>
Horms 04 Mar 2003
	</para>
	<para>
from memory, this is what is going to happen:
The connection will come in for VIP.
LVS will pick this up and send it to the realserver
(which happens to be a local address on the director
<emphasis>e.g.</emphasis>192.168.0.1).
As this address is a local IP address, the packet
will be sent directly to the local port without any modification.
That is, the destination IP address will still be
the VIP, not 192.168.0.1. So I am guessing
that an application that is only bound to 192.168.0.1 will
not get this connection.
	</para>
</blockquote>
	<section id="two_node_localnode">
	<title>Two LocalNode Servers</title>
	<para>
We've only had the ability to have one service in LocalNode, till Horms made this proposal.
Let us know if it works.
	</para>
	<para>
Horms 5 Jun 2007 
	</para>
	<para>
If you want to use LVS to have two local services on the director, 
wouldn't an easy way be
to bind the processes to 127.0.0.1 and 127.0.0.2 respectively
and set them up as the real-servers in LVS?
	</para>
	</section>
	<section id="two_box_lvs" xreflabel="two box lvs">
	<title>Two Box LVS</title>
	<para>
It's possible to have a fully failover LVS with just two boxes.
The machine which is acting as director, also is acting as
a realserver using localnode. The second box is a normal realserver.
The two boxes run failover
code to allow them to swap roles as directors.
The two box machine is the minimal setup for an
LVS with both director and realserver
functions protected by failover.
	</para>
	<para>
An example two box LVS setup can be found at
<ulink url="http://www.ultramonkey.org/2.0.1/topologies/sl-ha-lb-eg.html">
http://www.ultramonkey.org/2.0.1/topologies/sl-ha-lb-eg.html</ulink>.
UltraMonkey uses LVS so this setup should be applicable to anyone else using LVS.
	</para>
	<blockquote>
 	       <para>
Salvatore D. Tepedino <emphasis>sal (at) tepedino (dot) org</emphasis> 21 Jan 2004
		</para>
	        <para>
I've set one up before and it works well.
Here's a page
<ulink url="http://www.ultramonkey.org/2.0.1/topologies/sl-ha-lb-overview.html">
http://www.ultramonkey.org/2.0.1/topologies/sl-ha-lb-overview.html</ulink>
that explains how it's done.
You do not have to use the ultramonkey packages if you don't want to.
I didn't and it worked fine.
		</para>
	</blockquote>
	<para>
In practice, having the director also function as a realserver, complicates failover.
The realserver, which had a connection on VIP:port will
have to release it before it can function as the director,
which only forwards connections on VIP:port (but doesn't accept them).
If after failover, the new active director is still listening on the LVS'ed
port, it won't be able to forward connections.
	</para>
	<blockquote>
		<para>
Karl Kopper <emphasis>karl (at) gardengrown (dot) org</emphasis> 22 Jan 2004
		</para>
		<para>
At failover time, the open sockets on the backup Director may survive when
the backup Director acquires the (now arp-able) VIP
(of course the localnode connections to
the primary director are dropped anyway), but that's not going to happen at
failback time automatically. You may be able to rig something up with
ipvsadm using the <filename>--start-daemon master/backup</filename>,
but it is not supported
"out-of-the-box" with Heartbeat+ldirectord. (I think this might be easier on
the 2.6 kernel btw). Perhaps what you want to achieve is only possible with
dedicated Directors not using LocalNode mode.
		</para>
	</blockquote>
	<para>
The "Two Box LVS" is only suitable for low loads and is more difficult to
manage than a standard (non localnode) LVS.
	</para>
	<blockquote>
		<para>
Horms <emphasis> horms (at) verge (dot) net (dot) au</emphasis> 23 Jan 2004
		</para>
		<para>
The only thing that you really need to consider is capacity.
If you have 2 nodes and one goes down, then will that be sufficient
untill you can bring the failed node back up again? If so go for it.
Obviously the more nodes you have the more capacity you have -
though this also depends on the capacity of each node.
		</para>
		<para>
My thinking is that for smallish sites having the linux director
as a machine which is also a realserver is fine. The overhead
in being a linux director is typically much smaller than that
of a realserver. But once you start pushing a lot of traffic
you really want a dedicated pair of linux directors.
		</para>
		<para>
Also once you have a bunch of nodes it is probably easier to manage
things if you you know that these servers are realservers and
those ones are linux directors, and spec out the hardware as appropriate
for each task -
<emphasis>e.g.</emphasis> linux-directors don't need much in the way of
storgage, just CPU and memory.
		</para>
		<para>
Horms <emphasis>horms (at) verge (dot) net (dot) au</emphasis> 26 Aug 2003
		</para>
		<para>
The discussion revolves around using LVS where Linux Directors are also
realservers. To complicate  matters more there are usually two such
Linux Directors that may be active or standby at any point in time, but
will be Real Servers as long as they are available.
		</para>
		<para>
The key problem that I think you have is that unless you are using a
fwmark virtual service then the VIP on the _active_ Linux Director must
be on an interface that will answer ARP requests.
		</para>
		<para>
To complicate things, this setup really requires the use of LVS-DR and
thus, unless you use an iptables redirect of some sort, the VIP needs to
be on an interface that will not answer ARP on all the realservers.  In
this setup that means the stand-by Linux Director.
		</para>
		<para>
Thus when using this type of setup with the constraints outlined above,
when a Linux Director goes from strand-by to active then the VIP must go
from being on an interface that does not answer ARP to an interface that
does answer ARP. The opposite is true if a Linux Director goes from
being active to stand-by.
		</para>
		<para>
In the example on ultramonkey.org the fail-over is controlled by heartbeat
(as opposed to Keepalived which I believe you are using). As part of the
fail-over process heartbeat can move an interface from lo:0 to ethX:Y and
reverse this change as need be. This fits the requirement above.
Unfortunately I don't think that Keepalived does this, though I would
imagine that it would be trivial to implement.
		</para>
		<para>
Another option would be to change the hidden status of lo as fail-over
occurs. This should be easily scriptable.
		</para>
		<para>
There are some more options too: Use a fwmark service and be rid of your
VIP on an interface all together. Unfortunately this probably won't
solve your problem though, as you really need one VIP in there
somewhere. Or instead of using hidden interfaces just use an iptables
redirect rule. I have heard good reports of people getting this to work
on redhat kernels. I still haven't had time to chase up whether this
works on stock kernels or not (sorry, I know it has been a while).
		</para>
		<para>
(For other postings on this thread see the
<ulink url="http://marc.theaimsgroup.com/?l=linux-virtual-server&amp;m=103612116901768&amp;w=2">
mailing list archive http://marc.theaimsgroup.com/?l=linux-virtual-server&amp;m=103612116901768&amp;w=2</ulink>.)
        	</para>
	</blockquote>
	</section>
	<section id="two_box_lvs_active_active">
	<title>Two Box LVS: both directors have active ipvsadm entries</title>
	<note>
The normal way to run the Two Box LVS 
is with no ipvsadm entries on the backup director. 
However keepalived does have ipvsadm entries, and a non-arp'ing VIP.
If the backup director has ipvsadm entries 
then even though it's not receiving packets directly from the internet,
a connection request can be forwarded from the active director.
The backup director will attempt to loadbalance this request, 
which could be sent back to the active director.
You are now in a loop. 
Here's the story of the discovery of the problem and the fix by Graeme.
	</note>
	<para>
Martijn Grendelman <emphasis>martijn (at) pocos (dot) nl</emphasis> 19 Dec 2007
	</para>
	<blockquote>
		<para>
I have a quite straightforward LVS-DR setup: two machines, both running
a webserver on port 80, one of them directing traffic to either the
local node or the other machine. I am using the 'sh' scheduler, as I
have been for ages.
		</para>
		<para>
Since a while, directing traffic to the other machine (not the director)
doesn't work anymore, BUT ONLY on a specific VIP:PORT combination.
During my tests, the LVS setup is as follows:
		</para>
<programlisting><![CDATA[
martijn@whisky:~> rr ipvsadm -L -n
IP Virtual Server version 1.2.1 (size=4096)
Prot LocalAddress:Port Scheduler Flags
  -> RemoteAddress:Port           Forward Weight ActiveConn InActConn
TCP  213.207.104.20:80 sh
  -> 213.207.104.11:80            Route   500    0          0
TCP  213.207.104.20:81 sh
  -> 213.207.104.11:81            Route   500    0          0
TCP  213.207.104.50:80 sh
  -> 213.207.104.11:80            Route   500    0          0
]]></programlisting>
		<para>
Note that all references to the local node have been temporarily
removed. Now, the service defined second (port 81) works. The third one,
port 80, but a different VIP, works too. The first one, the one that I
need, does not.
		</para>
		<para>
When I connect to 213.207.104.20:80, I see some kind of SYN storm on
both the director and the real server on 213.207.104.11:
Mostly identical lines (and nothing else) keep appearing at a high rate,
even after I kill the connection on the client. Only after I remove the
service from LVS, this stops.
		</para>
	</blockquote>
	<para>
Graeme
	</para>
	<para>
You likely have a pair of "battling" directors. Consider this
Client sends SYN to director1. Director1 sends it on to director2, being
the other realserver - so far this is your scenario.
	</para>
	<para>
(Joe: now only if director2 is active):
Director2's LVS catches the packet and sends it back to director1 for
service, but director1 already sent that connection to director2, so
sends the packet back.
	</para>
	<para>
What happens now is that second paragraph happens ad nauseum, until your
ethernet between the machines is full up of the same SYN packet,
performance degrades, and the directors fall over under the load
(eventually).
	</para>
	<para>
Martin
	</para>
	<blockquote>
		<para>
Indeed, the other realserver, being the backup director, had its LVS
rules loaded. After clearing the LVS table on this machine, everything
worked like ever before.
		</para>
		<para>
In the past, the machines only had LVS active if they were actually the
active director, but at some point in time, I figured I could just leave
it active, because the stand-by director didn't get any requests anyway.
But of course, in this DR fashion, that is not true.
		</para>
	</blockquote>
	<para>
Graeme
	</para>
	<para>
I found it eventually, on the keepalived-devel@lists.sourceforge.net
list - I'll post it verbatim below.
	</para>
	<para>
This *should* allow you, with some modifications, to sort out your
problem and keep an active/active master/backup (by this I mean with
IPVS loaded and configured on both directors).
	</para>
	<blockquote>
		<para>
Client sends packet to VIP. Director1 (Master) has VIP on external
interface, and has LVS to catch packets and load balance them. Director1
uses LVS-DR to route packet either to itself (which is fine), or to
Director2 (Backup).
		</para>

		<para>
There's the problem... In the case of keepalived, Director2 *also* has a VIP, 
and has ipvsadm rules configured to forward packets
regardless of the VRRP mode (MASTER, BACKUP or FAULT).
This makes for faster failover but leads directly to this problem/solution.
In the backup director
keepalived moves the VIP from the VRRP interface to the lo which
is configured to not reply to arp requests.
In the basic case, 50% of the packets being forwarded by
Director1 to Director2 *will now get sent back to Director1* by the
LVS-DR configuration.
Because Director1 LVS has already sent traffic for that connection to
Director2, so it forwards the traffic to Director2.
		</para>
		<para>
Time passes, friend.
		</para>
		<para>
Your servers collapse under the weight of the amplifying traffic on
their intermediate or backend (or frontend, if you're on a one-net
setup) network.
		</para>
		<para>
The solution? A real nice easy one - use iptables to set a MARK on the
incoming traffic - something like:
		</para>
<programlisting><![CDATA[
iptables -t mangle -I PREROUTING -i eth0 -p tcp -m tcp \
                  -s 0/0 -d $VIP --dport $VIP_PORT \
                  -j MARK --set-mark 0x1
]]></programlisting>
		<para>
Then configure keepalived to match traffic on the MARK value instead of
the VIP/PORT combination, like so:
		</para>
<programlisting><![CDATA[
virtual_server fwmark 1 {
     delay_loop 10
     lb_algo rr
     lb_kind DR
     protocol TCP

     real_server x.x.x.72 25 {
         TCP_CHECK {
             connect_timeout 5
         }
     }
     real_server x.x.x.73 25 {
         TCP_CHECK {
             connect_timeout 5
         }
     }
}
]]></programlisting>
		<para>
...and so on for the other MARK values you define in your iptables setup.
		</para>
	</blockquote>
	<para>
This works perfectly where you have more than one interface and are
routing inter-director traffic via a "backend". In the case of a single
NIC on each box, you need a modified rule to NOT apply the mark value to
packets sourced from the "other" director:
	</para>
	<orderedlist>
		<listitem>
			<para>
On node1 create an iptables rule of the form:
			</para>
-t mangle -I PREROUTING -d $VIP -p tcp -m tcp --dport $VPORT -m mac \
  ! --mac-source $MAC_NODE2 -j MARK --set-mark 0x6
			<para>
where $MAC_NODE2 is node2's MAC address as seen by node1. Do a similar
trick on node2:
			</para>
-t mangle -I PREROUTING -d $VIP -p tcp -m tcp --dport $VPORT -m mac \
  ! --mac-source $MAC_NODE1 -j MARK --set-mark 0x7
			<para>
where $MAC_NODE1 is node1's MAC address as seen by node2.
			</para>
		</listitem>
		<listitem>
			<para>
Change your keepalived.conf so that it uses fwmarks.
			</para>
node1:
virtual_server fwmark 6 {

node2:
virtual_server fwmark 7 {
		</listitem>
	</orderedlist>	
	<note>
The problem came up again, before the solution went into the HOWTO.
Graeme directed Thomas to the original posting in the archive
	</note>
	<para>
Thomas Pedoussaut <emphasis>thomas (at) pedoussaut (dot) com</emphasis> 15 Apr 2008
	</para>
	<blockquote>
		<para>
I have a very light infrastructure, with 2 servers acting as directors 
AND real servers.
		</para>
		<para>
I came across the packet storm problem where when the MASTER forwards a 
connection to the real server on the BACKUP (via DR), the BACKUP treats 
it as a VIP connection to be loadbalanced rather than a real server 
connection to process. And decides to load balance it back to the MASTER 
		</para>
		<para>
I'm sure there is a way to do it, maybe with iptables. I'm looking for a 
schema explaining how a packet coming on an interface traverses the 
various layers (ipvs, netfilter, routing) so I could figure out how to 
do it.
		</para>
		<para>
My chance is that I have 2 physical interfaces, one public and one 
private, so if a packet arrives on the private interface for the VIP, 
it's a DR from the MASTER, and if it comes on the public, it's 
pre-loadbalance traffic.
		</para>
		<para>
Another option would be to be sure that the tables are in sync between 
the 2 machines so the BACKUP know that the connection has to be directed 
locally. I have tried to setup that feature, but it doesn't seems to 
sync really.
		</para>
	</blockquote>
	<para>
Joe: Here's my explanation of Graeme's problem, in case you haven't got it yet.
The problem only occurs if ipvsadm rules are loaded on the backup director
(having the rules loaded makes failover simpler).
Here's the two NIC version of the problem
	</para>
<programlisting><![CDATA[
     ipvsadm balances on VIP:port

          CIP
    CIP    |
     v     |----------------
    VIP    |                |
       eth0 VIP         eth0 VIP 
        _______          _______
       |       |        |       |
active |       |        |       | backup
       |_______|        |_______|
         
       eth1 RIP1        eth1 RIP2        
           |                |
            ----------------
            CIP->MAC of RIP2    normal packet
            MAC of RIP1<-CIP   spurious packet
]]></programlisting>
	<itemizedlist>
		<listitem>
client sends a connect request to VIP:port.
		</listitem>
		<listitem>
the active director picks the realserver to forward the request and having two choices,
delivers it either to the localnode or to the MAC address of eth1 on the other realserver (with RIP2).
In a normal LVS, the packet would be accepted by the demon listing on the VIP.
		</listitem>
		<listitem>
if the packet is delivered to eth1/RIP2, 
it will not be delivered to the demon listening on the VIP,
but will first be processed by ip_vs().
		</listitem>
		<listitem>
There's a 50% chance the packet will be forwarded to the localnode, 
which will generate a normal reply to the client. 
Although the client gets the expected response, 
we don't want the packet to go through ip_vs(). 
We want it delivered directly to the demon.
		</listitem>
		<listitem>
There's a 50% chance that the packet will be returned by ip_vs() to the active director at eth1/RIP1.
(wrinse, lather, repeat).
		</listitem>
		<listitem>
We don't want packets to the VIP coming in on eth1 to be processed by ip_vs()
on the backup director (here acting as a realserver). We want the packets to be delived to the demon.
		</listitem>
		<listitem>
We do want packets to the VIP coming in on eth0 to be processed by ip_vs().
		</listitem>
	</itemizedlist>
	<para>
Solution: fwmark packets coming in on eth0, to VIP:80. Load balance on the fwmark.
Packets for the VIP coming from 0/0 to eth0 will be load balanced.
Packets for the VIP coming in on eth1 will not be load balanced and will be delivered to the demon.
	</para>
	<para>
Here's the 1 NIC version of the problem
	</para>
<programlisting><![CDATA[
     ip_vs() balances on VIP:port

          CIP
    CIP    |
     v     | CIP->MAC of eth0 on backup  normal packet
    VIP    | MAC of eth0 on active<-CIP  spurious packet
           |----------------
           |                |
       eth0 VIP         eth0 VIP 
        _______          _______
       |       |        |       |
active |       |        |       | backup
       |_______|        |_______|
         
]]></programlisting>
	<itemizedlist>
		<listitem>
client sends a connect request to VIP:port.
		</listitem>
		<listitem>
the active director picks the realserver to forward the request and having two choices,
delivers it either to the localnode or to the MAC address of eth0 on the backup director
(functioning as a realserver).
In a normal LVS, the packet would be accepted by the demon listing on the VIP.
		</listitem>
		<listitem>
if the packet is delivered to eth0 on the backup director, 
it will not be delivered to the demon listening on the VIP,
but will first be processed by ip_vs().
		</listitem>
		<listitem>
There's a 50% chance the packet will be forwarded to the localnode, 
which will generate a normal reply to the client.
Although to the client, the LVS is functioning correctly,
we want the packet delivered directly to the demon and not to go through ip_vs(). 
		</listitem>
		<listitem>
There's a 50% chance that the packet will be returned to the MAC of the active director at eth0/VIP.
		</listitem>
		<listitem>
We don't want packets to the VIP on the backup director (realserver) 
coming from the MAC of eth0 on the active director to be processed by ip_vs().
		</listitem>
		<listitem>
We do want packets to the VIP coming in on eth0, 
from anywhere else but the MAC of the other director, 
to be processed by ip_vs().
		</listitem>
	</itemizedlist>
	<para>
Solution: fwmark packets coming in on eth0, to VIP:80 but not those coming from MAC of the other director. 
Load balance on the fwmark. 
Packets to VIP:port from 0/0 will be loadbalanced.
Packets to VIP:port from the other MAC address, 
will not be loadbalanced and will be delivered directly to the demon.
	</para>
	<para>
Joe: It occurs to me that <command>ipvsadm</command> doesn't have the -i eth0, or -o eth0 options, 
that the other netfilter commands have.
Does a packet arriving on LOCAL_IN, know which NIC it came in on?
	</para>
	<para>
Horms 29 Dec 2008
	</para>
	<para>
It would be possible, and I believe that the information is available
in LOCAL_IN. But there are a lot of different filters taht can be
applied through netfitler. And rather than adding them all to ipvsadm,
I think it makes a lot more sense to just make use of fwmark.
	</para>
	</section>
	<section id="localnode_testing">
	<title>Testing LocalNode</title>
	<para>
If you want to explore installing localnode by hand, try this.
First make sure scheduling is turned on at the director (this
command adds round robin scheduling and direct routing)
	</para>
<programlisting><![CDATA[
#ipvsadm -A -t 192.168.1.110:23 -s rr
]]></programlisting>
	<para>
With an httpd listening on the VIP (192.168.1.110:80) of the
director (192.168.1.1) AND with _no_ entries in the ipvsadm
table, the director appears as a normal non-LVS node and you can
connect to this service at 192.168.1.110:80 from an outside
client. If you then add an external realserver to the ipvsadm
table in the normal manner with
	</para>
<programlisting><![CDATA[
#/sbin/ipvsadm -a -t 192.168.1.110:80 -r 192.168.1.2
]]></programlisting>
	<para>
then connecting to 192.168.1.110:80 will display the webpage at
the realserver 192.168.1.2:80 and not the director. This is
easier to see if the pages are different (eg put the real IP of
each machine at the top of the webpage).
	</para>
	<para>
Now comes the LocalNode part -
	</para>
	<para>
You can now add the director back into the <command>ipvsadm</command> table with
	</para>
<programlisting><![CDATA[
/sbin/ipvsadm -a -t 192.168.1.110:80 -r 127.0.0.1
]]></programlisting>
	<para>
(or replace 127.0.0.1 by another IP on the director)
	</para>
	<para>
Note, the port is the same for LocalNode. LocalNode is
independant of the LVS mode (LVS-NAT/Tun/DR) that you are using
for the other IP:ports.
	</para>
	<para>
Shift-reloading the webpage at 192.168.1.110:80 will alternately
display the wepages at the server 192.168.1.2 and the director at
192.168.1.1 (if the scheduling is unweighted round robin). If you
remove the (external) server with
	</para>
<programlisting><![CDATA[
/sbin/ipvsadm -d -t 192.168.1.110:80 -r 192.168.1.2
]]></programlisting>
	<para>
you will connect to the LVS only at the directors port.
The director:/etc/lvs# ipvsadm table will then look like
	</para>
<programlisting><![CDATA[
Protocol Local Addr:Port ==>
                        Remote Addr           Weight ActiveConns TotalConns
                        ...
TCP      192.168.1.110:80 ==>
                        127.0.0.1             2      3           3
]]></programlisting>
	<para>
From the client, you cannot tell whether you are connecting
directly to the 192.168.1.110:80 socket or through the LVS code.
	</para>
	</section>
	<section id="localnode_on_backup_director">
	<title>Localnode on the backup director</title>
	<para>
With dual directors in active/backup mode, 
some people are interested in running services in localnode,
so that the backup director can function as a normal realserver 
rather than just sit idle. 
This should be do-able. 
There will be extra complexity in setting up the scripts to
do this, so make sure that robustness is not compromised.
The cost of another server is small compared to the penalties
for downtime if you have tight SLAs.
	</para>
	<para>
Jan Klopper <emphasis>janklopper (at) gmail (dot) com</emphasis> 2005/03/02 
	</para>	
	<para>	
I have 2 directors running hearthbeat 
and 3 realservers to process the requests.
I use LVS-DR and want the balancers to also be realservers.
Both directors are setup with localnode to serve requests
when they are the active director, 
but when they are the inactive director, it is idle.
	</para>
	<para>
If I add the VIP with noarp to the director, hearthbeat would not 
be able to setup the VIP when it becomes the active director.
Is there any way to tell hearthbeat to toggle the noarp switch on the 
load balancers instead of adding/removing the VIP?
	</para>
	<para>
Ideal sollution would be like this:
secondary loadbalancer carries the VIP with noarp (trough 
noarp2.0/noarpctl) and can thus be used to process querys like any 
realserver.
If the primary loadbalancer fails, the secondary loadbalancer would 
disable the noarp program, and thus start arping for the VIP, becoming 
the load balancer, using the local node feature to continue processing 
requests.
If the primary load balancer comes back up, it either takes the role as 
secondary server (and adds the VIP with noarp to become a realserver), 
or becomes the primary load balancer agian, which would trigger the 
secondary load balancer to add the noarp patch again, (which would make 
it behave like a realserver again)
	</para>
	<para>
I figured we could just do the following:
	</para>
	<itemizedlist>
		<listitem>
replace the line that says, ifconfig eth0 add VIP netmask ...
with: noarpctl del VIP RIP.
		</listitem>
		<listitem>
And the other way around:
replace the line: ifconfig eth0:0 del VIP netmask ...
with noarpctl add VIP RIP
		</listitem>
	</itemizedlist>
	<para>
the only point I don't know for sure is:
will the new server begin replying to arp requests 
as soon as noarp has been deleted?
	</para>
	<para>
Joe
	</para>
	<para>
yes. 
However the arp caches for the other nodes will still have the old MAC address 
for the VIP and these take about 90secs to expire. 
Until the arp cache expires and the node makes another arp request,
the node will have the wrong MAC address. 
Heartbeat handles this situation by sending 5 gratuitous arps (arp broadcasts) 
using <filename>send_arp</filename>
just to make sure everyone on the net knows the new MAC address for the VIP.
	</para>
	<para>
Graeme Fowler <emphasis>graeme (at) graemef (dot) net</emphasis> 
(addressing the issue that complexity is not a problem in practice)
	</para>
	<para>
I've got a 3-node DNS system using LVS-DR, 
where all 3 nodes are directors and realservers simultaneously. 
I'm using keepalived to manage it all and do the failover, 
with a single script running when keepalived transitions from 
MASTER - BACKUP or FAULT and back again.
It uses iptables to add an fwmark on the incoming requests, 
then uses the fwmark check for the LVS. Basic configuration is as follows:
	</para>
<programlisting><![CDATA[
global_defs {
<snipped notifications>
lvs_id DNS02
}

static_routes {
# backend managment LAN
1.2.0.0/16 via 1.2.0.126 dev eth0
}

!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
!!!!!
! VRRP synchronisation
!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
!!!!!
vrrp_sync_group SYNC1 {
group {
DNS_OUT
GW_IN
}
}
vrrp_instance DNS_1 {
state MASTER
interface eth0
track_interface {
eth1
}
lvs_sync_daemon_interface eth0
virtual_router_id 111
priority 100
advert_int 5
smtp_alert
virtual_ipaddress {
5.6.7.1 dev eth1
5.6.7.2 dev eth1
}
virtual_ipaddress_excluded {
5.6.7.8 dev eth1
5.6.7.9 dev eth1
}
virtual_routes {
}
notify_master "/usr/local/bin/transitions MASTER"
notify_backup "/usr/local/bin/transitions BACKUP"
notify_fault  "/usr/local/bin/transitions FAULT"
}
vrrp_instance GW_IN {
state MASTER
garp_master_delay 10
interface eth0
track_interface {
eth0
}
lvs_sync_interface eth0
virtual_router_id 11
priority 100
advert_int 5
smtp_alert
virtual_ipaddress {
1.2.0.125 dev eth0
}
virtual_routes {
}
}
!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
!!!!!
! DNS TCP
!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
!!!!!
virtual_server fwmark 5 {
smtp_alert
delay_loop 30
lb_algo wlc
lb_kind DR
persistence_timeout 0
protocol TCP
real_server 1.2.0.2 53 {
weight 10
inhibit_on_failure
TCP_CHECK {
connect_timeout 10
connect_port 53
}
MISC_CHECK {
misc_path "/usr/bin/dig @1.2.0.2 -p 53 known_zone soa"
misc_timeout 10
}
}
<snip other realservers>
<snip UDP realservers>
]]></programlisting>

<para>
...Where /usr/local/bin/transitions is:
</para>

<programlisting><![CDATA[
#!/bin/bash

IPLIST="/etc/resolver_ips"
IPCMD="/sbin/ip addr"

if [ ! -f $IPLIST ]
then
echo "No resolver list found, exiting"
exit 127
fi

if [ $1 ]
then
SWITCH=$1
else
# No command, quit
echo "No command given, exiting"
exit 126
fi


if [ $SWITCH = "MASTER" ]
then
DO="del"
elif [ $SWITCH = "BACKUP" -o $SWITCH = "FAULT" ]
then
DO="add"
else
# No command, quit
echo "Invalid command given, exiting"
exit 126
fi

if [ $DO = "add" ]
then
# we cycle through and make the IPs in /etc/resolver_ips loopback live
# We're in BACKUP or FAULT here
for addr in `cat $IPLIST`
do
$IPCMD $DO $addr dev lo
done
/sbin/route del -net 5.6.7.0 netmask 255.255.255.0 dev eth1
/usr/bin/killall -HUP named
elif [ $DO = "del" ]
then
# we do the reverse
# We're in MASTER here
for addr in `cat $IPLIST`
do
echo $IPCMD $DO $addr dev lo
done
/sbin/route add -net 5.6.7.0 netmask 255.255.255.0 dev eth1
/usr/bin/killall -HUP named
else
echo "Something is wrong, exiting"
exit 125
fi

### EOF /usr/local/bin/transitions
]]></programlisting>
<para>
...and /etc/resolver_ips contains:
</para>
<programlisting><![CDATA[
5.6.7.1/32
5.6.7.2/32
5.6.7.3/32
5.6.7.4/32
]]></programlisting>
<para>
...and in /etc/sysctl.conf we have (amongst other things):
</para>
<programlisting><![CDATA[
# Don't hide mac addresses from arping out of each interface
net.ipv4.conf.all.arp_filter = 0
# Enable configuration of hidden devices
net.ipv4.conf.all.hidden = 1
# Make the loopback device hidden
net.ipv4.conf.lo.hidden = 1
]]></programlisting>
	<para>
So we have a single MASTER and two BACKUP directors in normal operation, 
where the MASTER has "resolver" IP addresses on its' "external" NIC, 
and the BACKUP directors have them on the loopback adapter. 
Upon failover, the transitions script moves them from loopback 
to NIC or vice-versa.
The DNS server processes themselves are serving in excess of 880000 zones
using the DLZ patch to BIND so startup times for the cluster as a whole are
really very short (it can be cold-started in a matter of minutes).
In practice the system can cope with many thousands of queries per minute
without breaking a sweat, and fails over from server to server without a
problem.
You might think that this is an unmanageable methodology and is impossible 
to understand, but I think it works rather well :)
	</para>
	</section>
	<section id="re-mapping_ports_local_node" xreflabel="Re-mapping ports with Localnode">
	<title>rewriting, re-mapping, translating ports with Localnode</title>
	<para>
see <xref linkend="re-mapping_ports_with_iptables"/>
	</para>
	<para>
For an alternate take on mapping ports for LocalNode 
see <xref linkend="LVS-HOWTO.one_box_lvs"/>.
	</para>
	</section>
</section>
<section id="LVS-HOWTO.rewrite_ports" xreflabel="rewrite ports">
<title>LVS: You can't map (or rewrite) ports with LVS-DR, LVS-Tun or localnode (but you can with iptables)</title>
	<para>
The LVS-NAT director rewrites the dst_addr in the header of the packet 
coming from the client from the VIP to the RIP.
The reply packet from the realserver has the src_addr in the header rewritten
restoring the RIP src_addr to the VIP.
Once you've incurred the cost of disassembling the packet, it is trivial
to rewrite the dst_port at the same time. 
So LVS-NAT can rewrite (or map) the ports.
Thus the client could send a packet to VIP:80 but when it arrives at
the realserver, the packet will be going to RIP:1080.
	</para>
	<para>
On the other hand LVS-DR, LVS-Tun and Localnode just forward the packet to 
the target, with no disassembly of the packet header. 
Thus you cannot remap (rewrite) the destination port in LVS. 
However you can use <filename>iptables</filename> to rewrite the ports.
The examples below can be used for any of LVS-DR, LVS-Tun and Localnode.
	</para>
	<section id="localnode_cant_rewrite_ports">
	<title>You can't rewrite ports with localnode (but you can with iptables)</title>
	<para>
Paul Monaghan wrote:
	</para>
	<para>
Okay, perhaps what I am trying to do can't work for what ever reason but
here it is.  I've setup ipvs rules as follows:
	</para>
<programlisting><![CDATA[
TCP 209.226.95.146:8080 wlc
       -> 10.0.0.1:8001         Local   1      1          0
       -> 10.0.0.1:8000         Local   1      0          0
]]></programlisting>
	<para>
Wensong
	</para>
	<blockquote>
For the LocalNode feature, the load balancer just lets the
packets pass to the upper layer (up to service daemon) to process
the request. So, the port number of the local service must be
equal to that of the virtual service, otherwise it won't work.
Maybe I should add some code to check whether the port number of
local service is equal to that of virtual service, if not, reject
it to avoid such an error.
	</blockquote>
	<para>
<emphasis>i.e.</emphasis> you can't use localnode with LVS-NAT and have it
rewrite ports. You can't have a request coming to port VIP:80
and have it serviced by a demon listening on 127.0.0.1:81.
	</para>
	<para>
If you want to do this, you could try instead
	</para>
<programlisting><![CDATA[
$ipchains -A input -j REDIRECT 81 -d 192.168.1.12 80 -p tcp
]]></programlisting>
	<para>
Requests to 192.168.1.12:80 will go to 192.168.1.12:81
(more <link linkend="redirect_81">info is available</link>).
	</para>
	<para>
Pablo Ares <emphasis>paresd (at) airtel (dot) net</emphasis> 19 Jul 2004 
	</para>
	<blockquote>
		<para>
I have a configuration with only two machines 
that act both as directors and realservers (Localnode).
With a Localnode configuration you can't do port redirection/rewrite 
independently of the forwarding method (DR, TUN or NAT).
I need port redirection because I want to offer a Virtual HTTP Service on port 80,
and map this service to two realservers running Tomcat 
on port 8080 with an unprivileged account.
I tried this iptables DNAT rule in the PREROUTING CHAIN.
		</para>
<programlisting><![CDATA[
iptables -t nat -A PREROUTING -p tcp -d VIP --dport 80 -j DNAT --to VIP:8080
]]></programlisting>
		<para>
This rule functions well for the traffic that is mapped to the local realserver,
but the traffic that goes to the other realserver returns 
with source port 8080 to client 
(which causes a Reset of TCP connection by client).
I probed this configuration with LVS/NAT 
and LVS/DR with forward_shared (source martians) patch.
Is it possible to do port redirection in a Localnode environment?
		</para>
	</blockquote>
	<para>
ratz
	</para>
	<para>
If I understand you correctly, the other RS is a physically different 
machine, right?
You need someone to do a port mapping for you on your back-path.
First idea:
	</para>
<programlisting><![CDATA[
[Internet] ----> eth0[director/node1]eth1 -----> eth0[node2]

Two DNAT rules:

iptables -t nat -A PREROUTING -i eth0 -p tcp -d $VIP --dport 80 \
                 -j DNAT --to $VIP:8080
iptables -t nat -A POSTROUTING -i eth0 -p tcp -d $CIP -s $RIP \
                  --sport 8080 -j SNAT --to-source $IP_of_eth0:80
]]></programlisting>
	<para>
The "problem" is that netfilter maintains a template table which is used 
to lookup the n-tuple corresponding to your initial connection attempt 
which was port-redirected. Of course the source port of the outgoing 
packet is then not known which gives you little to know option of back 
mapping the port.
What you could do is have a tcp forwarding tool on a local socket on 
node2 which redirects traffic to the local socket on port 8080. There 
are other possibilities, however I'm not sure if I understand your 
current setup correctly.
	</para>
	<blockquote>
		<para>
The problem is solved. I applied NFCT patch http://www.ssi.bg/~ja/nfct/
and I add a second iptables rule in the POSTROUTING chain.
		</para>
<programlisting><![CDATA[
iptables -t nat -A POSTROUTING -p tcp -s $VIP--sport 8080 -j SNAT --to-source $VIP:80
]]></programlisting>
	</blockquote>
	<para>
Mikel Ruiz Echeverria Jun 07, 2005
	</para>
	<blockquote>
		<para>
I would like to balance the service over two real instances running all 
on the same machine. I have tried <filename>ldirectord.cf</filename>
		</para>

<programlisting><![CDATA[
virtual=158.227.82.39:8090
        real=158.227.82.39:8091
        real=158.227.82.39:8092
]]></programlisting>
		<para>
And I also have tried:
		</para>
<programlisting><![CDATA[
virtual=158.227.82.39:8090
        real=127.0.0.1:8091
        real=127.0.0.1:8092
]]></programlisting>
		<para>
but when I start <command>ldirectord</command>, I get:
		</para>
<programlisting><![CDATA[
Starting ldirectord Error [] reading file /etc/ha.d/conf/ldirectord.cf 
at line 14: invalid address for real server (wrong format).
]]></programlisting>
		<para> 
It seems like IPs of realservers could not be the same as the Director
Server's one.
Must Director and realservers run on different machines to work 
properly with LVS?
		</para>
	</blockquote>
	<para>
Horms
	</para>
	<para>
Unfortunately, what you are trying to do is not possible, and
here is why:
	</para>
	<para>
When you set up a real server that is on the same machine
as LVS, it uses a special forwarding mechanism called Local.
It uses this regardless of weather you asked for Masq, Route or
Tun. You can't ask for it, it just knows if the address is
local and sets it. You can however observe it using <command>ipvsadm -L</command>.
	</para>
	<para>
The reason for this is running packages that are going to
be delivered to a local process through Masq, Route or Tun
has overhead and in most cases makes very little sense.
	</para>
	<para>
However, the downside is that the Local forwarding
mechanism (like Route and Tun, but) unlike Masq
does not allow port-mapping. That is, your port 8090
packets will stay as port 8090 packets. So in a nutshell
IPVS translates your configuration to.
	</para>
<programlisting><![CDATA[
virtual=158.227.82.39:8090
         real=158.227.82.39:8090
         real=158.227.82.39:8090
]]></programlisting>
	<para>
Which obiously isn't going to work because you have a duplicate
entry, and that is what the error message you are getting
is trying to say. Well, thats what it should be trying to say,
looks like there might be a bit of a bug in ldirectord somewhere,
but that doesn't change the fact that IPVS can't do what
you want to do.
	</para>
	<para>
I believe an easy solution to this problem would
be to deliver the packets to different addresses
rather than different ports. Something like the
following might just work.
	</para>
<programlisting><![CDATA[
virtual=158.227.82.39:8090
         real=127.0.0.1:8090
         real=127.0.0.2:8090
]]></programlisting>
	<para>
A longer term solution would be to fix up the way the
Local delivery mechanism works. But this would
likely be quite tricky, and certainly increase
its current complexity - its basically a NULL opp
at the moment.
	</para>
	</section>
	<section id="re-mapping_ports_with_iptables" xreflabel="Re-mapping ports in LVS-DR with iptables">
	<title>rewriting, re-mapping, translating ports with iptables in LVS-DR</title>
	<para>
With LVS-NAT you can rewrite ports
(see <xref linkend="re-mapping_ports_lvs_nat"/>).
However, LVS-DR and LVS-Tun just forward the packets to the realserver
without rewriting the ports. 
	</para>
	<note>
You could write code to rewrite the ports before the packet left the director, 
if you wanted to.
However, the replies from the realserver go directly to the client
and do not return through the director.
For the client to receive a reply from the correct source port,
then the realserver would have to rewrite the ports for the reply.
There doesn't seem to be enough demand for rewritten ports with LVS-DR or LVS-Tun,
that anyone has bothered to write the code.
	</note>
	<para>
You can still enter a port for 
the realserver with <command>ipvsadm -r</command> 
in the same way that you can for LVS-NAT. 
However with LVS-DR and LVS-Tun, the port is silently ignored. 
This leads people to mistakenly think that they can rewrite the
ports with LVS-DR.
It would be better if <command>ipvsadm</command>
disallowed a port with the <filename>-r</filename> option,
or at least gave a warning and exited with a non-zero error code.
	</para>
	<para>
Horms will have a fix out for the next releases of ipvsadm.
	</para>
	<blockquote>
		<para>
Horms <emphasis>horms (at) verge (dot) net (dot) au</emphasis> 21 May 2004
		</para>
		<para>
<command>ipvsadm</command>
has code to change the port if it doesn't match. 
Below the service on the realserver is entered as 10.0.0.3:200
but is added to the ipvsadm table as 10.0.0.3:100.
However no warning is generated. 
		</para>
<programlisting><![CDATA[
# ipvsadm -C
# ipvsadm -A -t 10.0.0.1:100
# ipvsadm -a -t 10.0.0.1:100 -r 10.0.0.1
# ipvsadm -a -t 10.0.0.1:100 -r 10.0.0.2:100
# ipvsadm -a -t 10.0.0.1:100 -r 10.0.0.3:200
# ipvsadm -L -n
IP Virtual Server version 1.0.10 (size=65536)
Prot LocalAddress:Port Scheduler Flags
  -> RemoteAddress:Port           Forward Weight ActiveConn InActConn
TCP  10.0.0.1:100 wlc
  -> 10.0.0.3:100                 Route   1      0          0         
  -> 10.0.0.2:100                 Route   1      0          0         
  -> 10.0.0.1:100                 Route   1      0          0      
]]></programlisting>
		<para>
I don't think it is a good idea to disallow specifying
the port. It may break some peoples scripts, and seems uneccessary.
Here's a possible patch.
		</para>
<programlisting><![CDATA[
--- ipvsadm-1.21/ipvsadm.c.dist	2004-05-21 11:13:53.000000000 +0900
+++ ipvsadm-1.21/ipvsadm.c	2004-05-21 11:37:53.000000000 +0900
@@ -904,10 +904,18 @@
 		 * if the IP_VS_CONN_F_TUNNEL or IP_VS_CONN_F_DROUTE is set.
 		 * Don't worry about this if fwmark is used.
 		 */
-		if (!urule.vfwmark &&
+		if (!urule.vfwmark && urule.dport != urule.vport &&
 		    (urule.conn_flags == IP_VS_CONN_F_TUNNEL
-		     || urule.conn_flags == IP_VS_CONN_F_DROUTE))
+		     || urule.conn_flags == IP_VS_CONN_F_DROUTE)) {
+			fprintf(stderr, "Warning: "
+				"Real-Server port must be the same as the "
+				"virtual-service port for\n"
+				"         direct routing or tunnelling\n"
+				"         Real-Server port has been changed "
+				"from %u to %u\n", 
+				ntohs(urule.dport), ntohs(urule.vport));
 			urule.dport = urule.vport;
+		}
 
 		/* try to insmod the ip_vs_ftp module if service is for
 		 * port 21 if IP_VS_CONN_F_MASQ is used. */
]]></programlisting>
		<para>
Now when you enter a mismatched port 
(<emphasis>e.g.</emphasis> the same 10.0.0.3:200 service on the realserver)
you get a warning.
		</para>
<programlisting><![CDATA[
# ipvsadm -C
# ipvsadm -A -t 10.0.0.1:100
# ipvsadm -a -t 10.0.0.1:100 -r 10.0.0.1
# ipvsadm -a -t 10.0.0.1:100 -r 10.0.0.2:100
# ipvsadm -a -t 10.0.0.1:100 -r 10.0.0.3:200
Warning: Real-Server port must be the same as the virtual-service port for
         direct routing or tunnelling
         Real-Server port has been changed from 200 to 100
# ipvsadm -L -n
IP Virtual Server version 1.0.10 (size=65536)
Prot LocalAddress:Port Scheduler Flags
  -> RemoteAddress:Port           Forward Weight ActiveConn InActConn
TCP  10.0.0.1:100 wlc
  -> 10.0.0.3:100                 Route   1      0          0         
  -> 10.0.0.2:100                 Route   1      0          0         
  -> 10.0.0.1:100                 Route   1      0          0         
]]></programlisting>
		</blockquote>
	<para>
You can still rewrite the ports at the realserver with <command>iptables</command>
allowing the realserver to listen on another port.
	</para>
	<blockquote>
		<para>
Francois JEANMOUGIN <emphasis>Francois (dot) JEANMOUGIN (at) 123multimedia (dot) com</emphasis> 04 Mar 2004
		</para>
		<para>
if you need to rewrite ports for LVS-DR or LVS-Tun, just use
		</para>
<programlisting><![CDATA[
realserver:/# /sbin/iptables -t nat -A PREROUTING -d VIP -p tcp -m tcp --dport 80 -j DNAT --to-destination VIP:9999
]]></programlisting>
		<para>
Here the client connects to VIP:80 on the director, 
the realserver is listening on VIP:9999.
It works for me for tomcat standalone servers.
		</para>
	</blockquote>
	</section>
	<section id="http_port_mapping">
	<title>can't port map with LVS</title>
	<para>
Ryan P Linn Oct 01, 2003
	</para>
	<blockquote>
		<para>
I'm currently using a setup where I have individual webservers which are
using port based virtual hosts in apache. For instance, I have port 5678
and 5679 which map to ports 80 and 443 on a virtual host.  I'm currently
using a commercial solution to schedule these hosts and keep them
persistant together, however I'm hoping to switch these over to my LVS-DR
box.
		</para>
		<para>
It appears that the fwmark group is what I would want to do to keep
people going to both ports persistant, but from the documentation it
didn't appear that you could do port mapping while doing fwmarks.  I was
wondering if anyone had done this and if they could share how they made it
work if they had.  This would be for a shopping cart type application
where switching between port "80" and "443" were necessary for security,
but because the application uses php sessions it has to go back to the
same server each time.  It appears very easy to do if they were actually
listening on port 80 and 443 but since they're not I'm very confused about
the correct way to configure this.
		</para>
	</blockquote>
	<para>
Horms <emphasis>horms (at) verge (dot) net (dot) au</emphasis> 02 Oct 2003
	</para>
	<para>
The short answer is that you can't, using LVS.
But I wonder if it might be possible to change the destination
port using nefilter before or after the packets hit LVS.
Alternatively it would be possible to modify LVS to do this,
the main issue in my mind would be working out a sane
way to configure it.
	</para>
	</section>
</section>
<section id="LVS-HOWTO.non-lvs_clients_on_realservers" xreflabel="non-lvs clients on realservers">
<title>LVS: Non-LVS clients on Realservers</title>
<para>
	This HOWTO is a little disorganised here. 
Read the section on <xref linkend="LVS-HOWTO.lvs_clients_on_realservers"/> too.
</para>
	<section id="nat_through_vip" xreflabel="NAT through VIP">
	<title>always NAT out clients through VIP</title>
	<note>
This section (Jan 2007) is a collection of material that previously has been 
scattered thoughout the HOWTO, including in the old sections on 3-Tier LVS's
and authd.
	</note>
	<para>
In its simplest form, an LVS is a highly available server. 
Realservers are servers only: they reply directly to the client 
and don't need to connect to other machines to do so. 
This model serves well for telnet (used for testing) and the widely deployed http. 
With http as the most often deployed service, 
this model lasted a surprisingly long time.
	</para>
	<para>
It wasn't long before we found that realservers were required to do 
more than just serve: client processes on the realserver made calls,
often back to the LVS client (the CIP).
The first client we found was <xref linkend="LVS-HOWTO.authd"/>
which connects to the CIP.
We didn't know what to do with this client and since it wasn't needed 
and could be turned off, we did just that, solving the immediate problem.
We assumed we had a one-off problem that we wouldn't see again 
and we didn't see any bigger picture. 
The write-up on <xref linkend="LVS-HOWTO.authd"/> is long,
not because anyone needs to understand it in any depth, 
but because it was an big problem with LVS in the early days
and we put some effort into figuring it out. 
	</para>
	<para>
Next, for LVS's running a web based database, a client process 
on the realserver connects to the database machine (a 3-Tier setup).
The database was running on a machine under our control and 
the connection was local and was easily handled.
We thought we'd handled another special case. 
	</para>
	<para>
Now and again an administrator would want access to the outside
world from a realserver, or a script would need to pull from the internet
(sometimes requiring access by a DNS client running on the realserver). 
These cases were handled by NAT'ing
out the connection through some convenient machine (often the director).
Again these were treated as another special case 
and implemented slightly differently for LVS-NAT/DR/Tun. 
These connections came from the primary IP on the outside
of the director and not the VIP.
By the time we figured this out, 
no-one was running identd anymore and the identd case was not revisited.
	</para>
	<para>
	It took a while for the next step; 
Francois JEANMOUGIN (<xref linkend="client_on_realserver_snat_single_vip"/>)
realised that you could NAT out the connection through the VIP.
This solution wasn't often needed, 
since you could usually pull data or resolve hostnames, 
no matter what IP you used to make the call.
We forgot about this trick and Graeme Fowler had to reinvent it.
(We still hadn't "got it".)
	</para>	
	<para>
The <filename>ftp-data</filename> connection, in the standard
two port <xref linkend="ftp"/> service, requires similar
handling, but for LVS-NAT <command>ftp</command> has its own helper, 
while for LVS-DR/Tun <command>ftp</command> is handled by persistence. 
Again we regarded this as another special case.
	</para>
	<para>
However some server processes on the realserver also make calls to the internet,
<emphasis>e.g.</emphasis> an MTA which receives e-mail on the VIP, 
and which forwards the e-mail, must forward it from the VIP. 
When there are multiple VIPs, each with its instance of the server process, 
client calls, from each instance of the server process, must be NAT'ed 
out through the appropriate VIP.
	</para> 
	<para>	
David M was the first to describe a working multiple 
VIP/multiple client setup, <xref linkend="client_on_realserver_snat_multiple_vip"/>,
which showed the generalisation that we'd been missing: 
clients running on the realservers, which are calling on behalf
of a server process listening on the VIP (or RIP for LVS-NAT), 
have to call from the VIP.
	</para> 
	<para>	
Thus an MTA on the realservers listening on the VIP, 
when it connects to another MTA, has to connect from the VIP.
In an LVS'ed DNS, when <filename>named</filename> 
makes a connect to other machines, 
these calls must come from the VIP.
In contrast, the client call for name resolution for the MTA client, 
doesn't have to come from the VIP, since the name resolution is
not being LVS'ed.
The connect request from a database client running on the
realserver, which accesses a database on LAN, doesn't have to come from the VIP,
since the database call is not being LVS'ed.
	</para> 
	<para>	
If you're unsure as to whether the call needs to come from the VIP, 
think of the standalone server; 
which IP does the client call need to come from?
	</para> 
	<para>	
After seeing David's solution, 
I scanned for unsolved problems on the mailing list,
to find postings about server setups that worked 
on a standalone server, but which didn't work in an LVS.
These setups were behind a director using NAT rules, 
where the client process emerged with src_addr!=VIP, 
but which required src_addr=VIP. 
(No we didn't fix the problem, presumably the poster(s)
went to a commercial solution.) 
	</para>
	<para>
The lesson from this is to nat your realserver
client processes from the VIP, unless you're sure that it's not needed.
The rest of this section is just amplification of this statement.
If you understand David M's posting on 
<xref linkend="client_on_realserver_snat_multiple_vip"/> 
then you're done here.
	</para>
	</section>
	<section id="client_on_realserver" xreflabel="clients on realservers">
	<title>Masquerading clients on realservers to the outside world (SNAT)</title>
	<note>
also see <xref linkend="reinject_snat"/>
	</note>
	<para>
Sometimes you a client process on the realserver will need to contact
the outside world, <emphasis>e.g.</emphasis> 
	</para>
	<itemizedlist>
		<listitem>
the LVS'ed server process may need to run a client process to connect
to another computer <emphasis>e.g.</emphasis> to access
a database, or to initiate an smtp connection to the next MTA in the chain.
		</listitem>
		<listitem>
the LVS'ed process may make a callback to a process running on the LVS client 
(<emphasis>e.g.</emphasis> the ftp-data port with ftp)
		</listitem>
		<listitem>
A process independant of the LVS'ed service may need to periodically connect
to an outside computer <emphasis>e.g.</emphasis> ftp to upload logs, 
or DNS (the realserver knows the CIP already, so this won't be for the LVS'ed service).
		</listitem>
	</itemizedlist>
	<para>
Clients on realservers can call from the RIP or VIP. 
By default, clients will call from the RIP, since it is the primary IP on the realserver.
Often the client of the LVS or an outside machine will expect
the call to come from the VIP, which is handled by NAT'ing the call. 
If the LVS has multiple VIPs, then the call must come from the correct VIP.
	</para>
	<itemizedlist>
		<listitem>
			<para>
<emphasis role="bold">RIP</emphasis>
			</para>
			<para>
Clients like telnet call from the RIP
as so do the clients of some callbacks
<emphasis>e.g.</emphasis> 
<link linkend="rshd_multiport">rshd</link>.
Some services <emphasis>e.g.</emphasis> MTAs which
receive e-mail on the VIP will initiate sending e-mail from the RIP,
this being the primary IP on the NIC. 
			</para>
			<para>
Usually the RIP is a private IP and will not be routable.
If the resources needed by the client are local 
<emphasis>e.g.</emphasis> to a local nameserver with 
its own connection to the internet, or to a database server,
then a non-routable RIP is fine.
If you need to route packets from a routable IP, 
you could make the RIPs routable.
but from the security point of view, 
you don't want to make your realservers publically accessible, 
so making the RIP routable is not generally a good idea.
			</para>
		</listitem>
		<listitem>
			<para>
<emphasis role="bold">VIP</emphasis>
			</para>
			<para>
Clients which are associated with a service listening on the VIP and 
which make callbacks from the VIP to the LVS client.
The instances that we know about of this.
			</para>
			<itemizedlist>
				<listitem>
<xref linkend="LVS-HOWTO.authd"/>
				</listitem>
				<listitem>
<link linkend="passive_ftp">passive ftp</link>
				</listitem>
			</itemizedlist>
			<para>
The general solution for callbacks from the VIP 
is to write a helper module for the director.
If you don't have one, then you're stuck - 
in this case look at the section on 
<xref linkend="LVS-HOWTO.authd"/> for attempts at solutions.
A possible solution is to use persistence with port=0 as
can be done for ftp 
(port=0 forwards all ports, increasing security problems and should not
be used if at all possible).
			</para>
		</listitem>
	</itemizedlist>
	<para>
To handle calls from the RIP, you can NAT the connections out through any available box:
for LVS-NAT, the director is available; for LVS-DR/LVS-Tun 
both the director and the default gw box are possibilities
(although you may not have access to the default gw box).
In the case of LVS-NAT, the director is the already the
default gw for packets from the RIP (since you need to 
route the replies from the LVS'ed service through the director). 
In the case of LVS-DR/LVS-Tun, the default gw for packets
from the VIP is through a router that is not the director:
the default gw for packets from the RIP is not part of the
LVS setup, but will probably also be the same router box.
In this case, the packets from the RIP will need to be
routed instead to the director 
(you can use the iproute2 tools for this).
	</para>
	<para>
If you don't do anything special, 
the NAT'ed requests will come from the primary IP on the outside of the director 
(the VIP is usually a secondary IP, so that it can be moved on failover).
<link linkend="client_on_realserver_snat">Below</link> 
we show how to make the call from the director's VIP.
In the case of LVS-DR/LVS-Tun, the VIP on the outside of the director
doesn't send any packets, and doesn't need a route
(see <link linkend="Pearthree">routing for LVS-DR</link>).
If you NAT out through the VIP on an LVS-DR or LVS-Tun director, 
then you will need to put in a default gw for packets from the VIP
(you normally don't have a default route for packets from the VIP
for LVS-DR or LVS-Tun).
	</para>
	</section>
	<section id="NAT_clients_in_LVS-NAT">
	<title>Masquerading clients on LVS-NAT realservers</title>
	<para>
Here's the command to run on a 2.2.x director to allow
realserver1 to telnet to the outside world.
	</para>
<programlisting><![CDATA[
director:# ipchains -A forward -p tcp -j MASQ -s realserver1 telnet -d 0.0.0.0/0
]]></programlisting>
	<para>
With LVS-NAT and a single director, the VIP will be the primary IP on the outside
of the director and the packets will have src_addr=VIP.
Otherwise the packets will come from an IP which is not the VIP.
	</para>
	<para>
You may have to turn off icmp redirects,
if you have a <link linkend="one_network">one network LVS-NAT</link>.
	</para>
<programlisting><![CDATA[
director: #echo 0 > /proc/sys/net/ipv4/conf/all/send_redirects
director: #echo 0 > /proc/sys/net/ipv4/conf/eth0/send_redirects
]]></programlisting>
	<para>
After running this command you can telnet from the realservers.
You can do this even if telnet is an LVS'ed service,
since the telnet client and demon running on the realserver 
operate independantly of each other.
	</para>
	<para>
Here are the IP:port, seen by <command>`netstat -an`</command> on each machine
	</para>
	<itemizedlist>
		<listitem>
			<para>
client on the internet telnet'ing to an LVS forwarding by LVS-NAT
			</para>
<programlisting><![CDATA[
client                  director             realserver

connection from client to LVS
CIP:1041->VIP:23          -                  CIP:1041->RIP:23
]]></programlisting>
		</listitem>
		<listitem>
			<para>
the realserver connecting by masquerading
through the director to the telnetd on the LVS client.
			</para>
<programlisting><![CDATA[
client                  director             realserver

telnet connection from realserver to telnetd on LVS client
CIP:23<-DIP:61000         -                  CIP:23<-RIP:1030
]]></programlisting>
			<para>
The masqueraded connection to the LVS client comes from
the primary IP of the director (here the DIP) and not
from the VIP, which in this setup is an alias (secondary IP)
of the DIP.
			</para>
			<para>
The masqueraded ports can be seen on the director with
			</para>
<programlisting><![CDATA[
director:/etc/lvs# ipchains -M -L -n
IP masquerading entries
prot expire   source               destination          ports
TCP  14:53.91 RIP                  CIP                  1030 (61000) -> 23
]]></programlisting>
		</listitem>
	</itemizedlist>
	<para>
For both connections, 
the director doesn't have connections to any of its ports.
It the case of LVS, the director is just forwarding packets like a router.
In the masquerading case, the director is rewritten the headers before
forwarding the packets like a router.
	</para>
	<para>
Connections from clients start at high_port=1024.
The masqueraded ports start at port=61000 (not 1024) (at least for kernel 2.2.x).
The port number increments for each new connection in both cases.
In the case where a machine is both connecting
to the outside world (using ports starting at 1024) and
masquerading connections from other machines (using port
starting at 61000), there is
<link linkend="port_range">no port collision detection</link>.
This can be a problem if the machine is masquerading
a large number of connections and the port range has
been increased.
	</para>
	<note>
The masqueraded ports start at (64k-4k)=61440 for 2.2.x kernels.
2.4.x kernels can use all ports for masquerading.
	</note>
	<para>
Peter Klapprodt <emphasis>peter (dot) klapprodt (at) ewido (dot) net</emphasis> 
21 Jul 2005
	</para>
	<blockquote>
		<para>
Any ideas on how to get internet access working on the real servers
(<emphasis>i.e.</emphasis> clients unrelated to the LVS services)
using LVS-NAT? I've read something about virtual_routes in keepalived
but couldn't find any detailed instructions yet.
		</para>
	</blockquote>
	<para>
<emphasis>graeme (at) graemef (dot) net</emphasis>
	</para>
	<para>
..in exactly the same way you would for an ordinary masqueraded network:
	</para>
	<itemizedlist>
		<listitem>
realservers use active director as default gateway
		</listitem>
		<listitem>
			<para>
on director
			</para>
<programlisting><![CDATA[
echo "1" >> /proc/sys/net/ipv4/ip_forward
]]></programlisting>
		</listitem>
		<listitem>
			<para>
on director, set up masquerading:
			</para>
<programlisting><![CDATA[
iptables -t nat -A POSTROUTING -s <priv net>/<netmask> -d <privnet>/<netmask> -j ACCEPT
iptables -t nat -A POSTROUTING -s <priv net>/<netmask> -j MASQUERADE
]]></programlisting>
		</listitem>
	</itemizedlist>
	<para>
and that's it!
Any packet which returns to the director which is not hooked by LVS as 
part of an active connection will fall through to the nat POSTROUTING 
chain and get masqueraded.
	</para>
	<para>
<emphasis>PMilanese (at) nypl (dot) org</emphasis> 22 Jul 2005 
	</para>
	<note>
Do not use the static interface assignment for the gateway. 
Use the virtual (dynamic) interface (the DIP). 
If the directors fail over you need the gateway to move with the active director.
	</note>
	</section>
	<section id="NAT_clients_in_LVS-DR">
	<title>Masquerading clients on LVS-DR realservers</title>
	<para>
The realserver in LVS-DR has two IPs, the RIP and the VIP.
The LVS'ed services are running on the VIP.
Packets from LVS'ed services, returning from the realserver, have src_addr=VIP.
The RIP is not directly involved in the LVS.
Services may be running on the RIP too, 
<emphasis>e.g.</emphasis> telnetd which listens to 0.0.0.0,
but services running on the RIP are of no interest to a LVS-DR.
The director only needs the RIP to determine the target MAC address to forward packets
from the clients destined for the VIP.
Thus you are free to do whatever you like with the RIP without affecting the LVS.
Usually the RIP is on a private IP (eg 192.168.x.x) so as to not
require an extra IP, and to shield the realserver from the internet.
It would be unusual to run non-LVS'ed services on the realservers,
as the RIP would have to be a public IP and the realservers would have
to be firewalled.
However there it is reasonable to run clients on the realservers.
A client session (<emphasis> e.g.</emphasis> telnet) initiated from the
RIP would have to be NAT'ed out to the outside world.
The NAT box could be the router or the director.
Here's how to setup with the director doing the NAT'ing
(the router setup would be the same).
	</para>
		<section id="lvs_dr_nat_clients_on_realservers">
		<title>Send client packets (src_addr=RIP) to the director and LVS packets (src_addr=VIP) to the router</title>
		<para>
This is not possible with the standard destination-based route command.
You need the policy routing tools from <link linkend="iproute2">iproute2</link>.
		</para>
		<para>
Here's Julian's recipe (25 Sep 2000)
for setting up NAT for clients on realservers in a LVS-DR LVS.
		</para>
		<para>
For the realserver(s), send all packets from the RIP network (RIPN)
to the DIP (an IP on the director in the RIPN).
		</para>
<programlisting><![CDATA[
#create a rule with priority 100, which says that for any packet
#with src_addr in the RIP network, lookup the action to take in table 100.
realserver: #ip rule add prio 100 from RIPN/24 table 100

#route all packets in table 100 which go to 0/0
#(ie anywhere, the default route), via the DIP.
realserver: #ip route add table 100 0/0 via DIP dev eth0

#the result of this is that packets with src_addr=RIPnetwork
#and dst_addr=0/0 go via the DIP.
]]></programlisting>
		<para>
The director has to to listen on DIP (if it doesn't already),
and not send ICMP redirects from the DIP ethernet device and
has to masquerade (all) packets from the RIPN. 
		</para>
<programlisting><![CDATA[
director: #ifconfig eth0:1 DIP netmask 255.255.255.0
director: #echo 0 > /proc/sys/net/ipv4/conf/all/send_redirects
director: #echo 0 > /proc/sys/net/ipv4/conf/eth0/send_redirects
# for 2.2 kernels, all services
director: #ipchains -A forward -s RIPN/24 -j MASQ 
# for 2.2 kernels, telnet only
director: #ipchains -A forward -p tcp -j MASQ -s realserver1 telnet -d 0.0.0.0/0 
]]></programlisting>
		</section>
		<section id="lvs_dr_add_default_route">
		<title>add a default route for packets from the primary IP on the outside of the director</title>
		<para>
For <link linkend="Pearthree">LVS-DR, no default gw is needed</link>
for packets from the primary IP on the outside
of the director or from the VIP (which will be an alias/secondary IP).
For security reasons then none is installed.
To allow masquerading of clients on the realservers,
a default route will be needed for packets from the
primary IP on the outside of the director
(but not for packets from the VIP).
			</para><para>
If you want to test this out first,
just put in a default route for the director
using the route command.
If you like it you can add the more restrictive routes
with iproute2 later.
		</para>
		</section>
	</section>
	<section id="NAT_clients_in_LVS-Tun">
	<title>Masquerading clients on LVS-Tun realservers</title>
	<para>
The director is on a different network (possibly in a different location),
you don't have a two way ipip connection back to the director (although you
can add one), and you don't have a route from the RIP to the DIP (although
you can add this too). If you handle these problems,
then you can use the director to NAT out connections from the realservers.
However it would probably be simpler to NAT out through the local router.
	</para>
	</section>
	<section id="client_on_realserver_snat">
	<title>Masquerading clients through the VIP on the director</title>
	<para>
	The recipes above for masquerading clients, have the packets
coming out from the primary IP on the outside of the director.
This will not usually be the VIP, which is a secondary IP (so that it can
be moved easily on failover). 
Here we show how to masquerade out from the VIP.
	</para>
		<section id="client_on_realserver_snat_single_vip" xreflabel="masquerade the client out through the VIP">
		<title>Masquerading through a single VIP</title>
		<para>
Francois JEANMOUGIN <emphasis>Francois (dot) JEANMOUGIN (at) 123multimedia (dot) com</emphasis> 19 Aug 2004
		</para>
		<blockquote>
When masquerading clients on realservers out through the director,
how do I make the src_addr=VIP?
		</blockquote>
		<para>
"C. R. Oldham" <emphasis>cro (at) ncacasi (dot) org</emphasis> 25 Aug 2004
		</para>
		<para>
You can do this with policy-based routing in the 2.6 series of kernels.
On my Debian realservers I have this in <filename>/etc/networks/interfaces</filename>
		</para>
<programlisting><![CDATA[
auto eth0 eth1
iface eth0 inet dhcp

#Define an interface eth1 that uses inet protocols and has a static address
iface eth1 inet static

   #Give the interface the address of 192.168.0.2
   address 192.168.0.2

   #And a netmask of 255.255.255.0
   netmask 255.255.255.0

   #When the interface is brought up, execute 'ip route' adding an entry to
   #the routing table that causes packets with src address 192.168.0.2 to be
   #processed with the iptables table called 'lvs'
   up ip route add 192.168.0.0 dev eth1 src 192.168.0.2 table lvs

   #When the interface is brought up, set the default route for the table lvs 
   #to 192.168.0.1 (which is my lvs director).
   up ip route add default via 192.168.0.1 table lvs

   #Add another routing rule so packets going from 192.168.0.2 are also
   #processed by table lvs.
   up ip rule add from 192.168.0.2 table lvs

   #When the interface is brought down delete the routing rules.
   #these rules lie dormant till the interface is brought down.	
   down ip rule delete from 192.168.0.2 table lvs
   down ip route delete 192.168.0.0 dev eth1 src 192.168.0.2 table lvs
]]></programlisting>
		<para>
I have a table "lvs" in <filename>iproute2/rt_tables</filename>
		</para>
<programlisting><![CDATA[
#
# reserved values
#
255     local
254     main
253     default
0       unspec
#
# local
#
1       inr.ruhep
80      lvs
]]></programlisting>
		<para>
It took me a long time and lots of googling to figure this out but it
works great.
		</para>
		<para>
Francois JEANMOUGIN
		</para>
		<para>
Just use snat!
		</para>
<programlisting><![CDATA[
director:# /sbin/iptables -t nat -A POSTROUTING -o eth1 -j SNAT --to $VIP
]]></programlisting>
		<para>
It is pretty simple. The VIP does not have to be up on the system, the rule
stays there unemployed. In case of a director switch, even if vrrp add the
VIP as a secondary (or alias) interface, the outgoing packets will have the
VIP as the source address.
Using iptables with the SNAT method let you
use vrrp for director failover without any other configuration and scripts.
		</para>
		<para>
Tested and approved (my VIP is a secondary interface now again on the
directors). I think you can use several SNAT rules if you want to mix several
natted virtual_servers, using a -s (IIRC) option (that part I didn't test).
		</para>
		<para>
P.S.: Yes, I feel, the "--to" option confusing too.
		</para>
		<para>
Joe - It took a long time for someone to realise how to make the
packets come from the VIP, rather than the primary IP on the outside
of the director. 
The same problem came up again, but I'd forgotten that it had been
solved, so it was invented again.
		</para>
		<para>
Kristoffer Egefelt 
		</para>
		<blockquote>
If I send a mail from a realserver to my gmail account, 
the outgoing packets have the primary IP of the director as src_addr.
I would like the packets to come instead from the VIP.
		</blockquote>
		<para>
Graeme Fowler <emphasis>graeme (at) graemef (dot) net</emphasis> 22 May 2006
		</para>
		<para>
You want a machine (the realserver) behind a masquerading server (the 
director) to appear to have a fixed IP address when making outbound 
connections to the internet.
Simply have a SNAT rule on your director's external interface such that 
packets going out from the realserver get mapped to the VIP; assuming 
here that the external interface is eth0:
		</para>

<programlisting><![CDATA[
iptables -t nat -I POSTROUTING -o eth0 \
                 -s $REALSERVER_IP \
                 -d 0/0 \
                 -j SNAT --to-source $VIRTUAL_IP
]]></programlisting>
		<para>
I've used this many times to do a many-to-one mapping for realservers so 
that when they initiate external connections, they appear to come from 
the same IP.
		</para>
		<para>
Since this is outbound data from a high port on the VIP, and
not from a port controlled by <command>ipvsadm</command>,
the <filename>ip_vs</filename> code on the director will ignore these packets
and they will be reverse SNAT'ed and pass to the realserver.
This works is for outbound communication from the
realservers; it's extremely unlikely that they'll use a well-known (and
often priveleged) service port as the source for a new TCP session to
somewhere external.
		</para>
		<para>
In context, an example mail server cluster will generally have one or
more of ports 25, 465 and 587 bound to the VIP on the external side of
the director. No well-written MTA will initiate a connection to an
external host using those ports as source.
The same goes for webservers, DB servers and a whole host of others.
		</para>
		<para>
That means the LVS doesn't have to be considered, as the netfilter
conntrack code will work perfectly well.
		</para>
		<para>
There is, however, an exception - DNS servers can be configured to use
UDP/53 as a source port for queries; in my experience explicitly turning
this off means a tiny proportion of queries will fail. Leaving it turned
on behind a director means that, well, anything could happen... so
making use of a forwarder here is a good solution. Besides, in DNS
operation having a query come from a reversible IP which maps to a
forward name lookup is less important than it is for web or email
connections.
		</para>
		<para>
Brad Dameron <emphasis>brad (at) seatab (dot) com</emphasis> 19 May 2006
		</para>
		<para>
you can use iptables to push packets from certain realservers
out certain IP's. Here is my 
<ulink url="files/ipvs_firewall">/etc/init.d/ipvs_firewall</ulink> startup script. 
This script also allows your real servers to connect to the outsite world
through the LVS server. This is a SuSe start script so will need to be a
little modified to work with RedHat, etc.
		</para>
		<para>
Chris Newland <emphasis>chrisn (at) allipo (dot) com</emphasis> 11 Jul 2006
		</para>
		<para>
I use LVS-NAT and SNAT by using the following iptables rule:
		</para>
<programlisting><![CDATA[
iptables -t nat -A POSTROUTING -s 10.0.0.0/255.255.255.0 -o eth0 -j SNAT \
--to-source x.x.x.x <public IP of your director>
]]></programlisting>
		<para>
My realservers only have non-routable IP addresses (10.0.0.*)
The realservers can all connect to servers on the internet and when they do,
the IP source address is that of the director.
		</para>
		</section>
		<section id="client_on_realserver_snat_multiple_vip" xreflabel="masquerading clients on realservers through multiple VIPs">
		<title>Masquerading through multiple VIPs</title>
	        <para>
David M <emphasis>northridgeaustin (at) gmail (dot) com</emphasis> 14 Dec 2006
		</para>
		<para>
We have an LVS-NAT which works fine for other services (<emphasis>e.g.</emphasis> http).
We also LVS sendmail. The MTA listens for connections on the RIP (and works fine),
but when it initiates a connection (which is does from the RIP), 
this occurs independantly of the LVS.
Outgoing connections from RIPs get routed out the default gateway for LVS-NAT,
where they're NAT'ed by iptables rules on the director.
		</para>
		<para>
We have three sendmail realservers, each with 30 private (172.16.0.0/24) RIPs, 
each RIP with an instance of sendmail (30 instances/realserver; 90 private RIPs total). 
On the Director, there are 30 public VIPs which are balanced by the three realservers.  
On each realserver then, MTA connections can be initiated from 30 RIPs, and all
are sent to the same default gateway (the DIP). 
The director needs to know through which VIP the connection needs to NAT'ed out.
The director then needs 90 rules (one for each RIP).
		</para>
		<para>
We have three realservers (RS1, RS2, RS3), and we are
associating RIPs with VIPs. Here's the subset for VIP_01
		</para>
<programlisting><![CDATA[
#RIP on RS1 that services VIP_01, connections come out from VIP_01
$RIP_RS1_VIP_01 --> $VIP_01  
$RIP_RS2_VIP_01 --> $VIP_01
$RIP_RS3_VIP_01 --> $VIP_01

#iptables rules
$IPT -t nat -A POSTROUTING -s $RIP_RS1_VIP_01 -o $EXT_INTER -j SNAT --to-source $VIP_01
$IPT -t nat -A POSTROUTING -s $RIP_RS2_VIP_01 -o $EXT_INTER -j SNAT --to-source $VIP_01
$IPT -t nat -A POSTROUTING -s $RIP_RS3_VIP_01 -o $EXT_INTER -j SNAT --to-source $VIP_01
]]></programlisting>
		<para>
Rob <emphasis>ipvsuser (at) itsbeen (dot) sent (dot) com</emphasis> 15 Dec 2006
		</para>
		<para>
Well, the way I set up things up is different (possibly better) -
My goal is to make it easy to config/manage/troubleshoot, secure, fast and
low load on the director(s):
		</para>
		<itemizedlist>
			<listitem>
I use OpenBSD and pf to separate public and private IP spaces
			</listitem>
			<listitem>
Use LVS-DR for all the lvs work (not sure if you can do this or if you need
to use nat for some other reason)
			</listitem>
		</itemizedlist>
		<para>
By separating the NATing from the load balancing it seems to simplify the
configuration of both and I feel it is easier to write pf rules than iptables (YMMV).
In pf for each of the 30 email servers you need 2 rules:
		</para>
<programlisting><![CDATA[
Outgoing: nat pass on $ext_if inet proto tcp from 172.16.1.1 to port 25 -> px.py.pz.1
Incoming: rdr pass on $ext_if inet proto tcp from any to px.py.pz.1 port 25 -> 172.16.1.1 port 25
]]></programlisting>
		<para>
The above will send incoming connections to the correct VIP and keep the outgoing
connections/replies coming from the correct public IP.
		</para>
		<para>
For the LVS config:
		</para>
<programlisting><![CDATA[
-A -t 172.16.1.1:25 -s nq
-a -t 172.16.1.1:25 -r 172.16.1.101:25 -g -w 100
-a -t 172.16.1.1:25 -r 172.16.1.102:25 -g -w 100
-a -t 172.16.1.1:25 -r 172.16.1.103:25 -g -w 100
]]></programlisting>
		<para>
No special routing set up on the director or real servers, all machines have the
OpenBSD firewall as their gateway. Low load on the director since it is DR.
Then to cheat on the arp issue, I hardcode the MAC Address of the director into the
arp table on the OpenBSD firewall for each of the VIPs
(and run arpwatch and set the Linux machines arp sysconfig params)
One of the cool things you can do with a set up like this 
is use the excellent table handling in pf.
I have about 85,000 ips that I know are spammers 
and I don't want them using any resources on my
MTA boxes so I redirect all of them to OpenBSD's spamd 
which tarpits them at extremely low cost:
		</para>
<programlisting><![CDATA[
table <spammers> persist file "/etc/spammers.txt"  {}
rdr pass on $ext_if inet proto tcp from {<spammers>} to any port 25 -> 127.0.0.1 port 8027
]]></programlisting>
		<para>
This means that the MTA boxes can service real mail more quickly since slots are not
being used by spammers.
I do similar things for bogons http://www.cymru.com/Bogons/ and ssh brute force attackers.
I haven't found a reasonable way to work with any sizable tables in iptables.
		</para>
		</section>
	</section>
	<section id="3-Tier_lvs" xreflabel="3-Tier LVS">
	<title>3-Tier LVS</title>
	<para>
However some services need resources on other machines,
<emphasis>e.g</emphasis> DNS, databases. A squid realserver gets
its content from machines on the internet and to do
this, the squid demon will run a client process which
makes a connection from RIP to 0/0:80.
These client packets need to be routed
and to do so the RIP must first be on a public IP
(or at least routable locally).
	</para>
	<para>
Sorting out the routing requirements for setting up a 3-Tier LVS
was prompted by Jezz Palmer (Mar 2002)
who found that his squid didn't work when setup by the configure script,
but did when he put in a default route for the squid realserver.
Jezz ran the tcpdumps, ran and debugged the scripts for me.
	</para>
	</section>
	<section id="3-tier_routes">
	<title>Routes needed for 3-Tier LVS</title>
	<para>
Figuring out the iptables and iproute2 commands was helped
by Horms, Ratz, Julian and Peter Mueller.
			</para><para>
Here is the standard LVS-DR test setup with 2-NIC director
and only 1 realserver. The router for the realservers has
the LVS client.
The routes neccessary for a normal LVS are in lower case (<emphasis>e.g.</emphasis>
from 0/0 to VIP). Note (see discussion of <link linkend="Pearthree">routes for LVS-DR</link>)
that there is no route for packets from the VIP on the director (to anywhere)
and no routes for packets from the SERVER_GW to RIP,VIP on the realserver.
			</para><para>
<programlisting><![CDATA[
        ____________
       |            |
       |   client   |SERVER_GW-------------
       |____________|                     | ^
             CIP                          | |
              | from 0/0 (CIP) to VIP     | from VIP to 0/0 (CIP) via SERVER_GW
              |  |                        |
              |  v                        | ^
             VIP                          | |
        ____________                      | FROM RIP TO 0/0:PORT (CIP) VIA SERVER_GW
       |            |                     | FROM 0/0:PORT (CIP) TO RIP
       |  director  |                     | |
       |____________|                     | v
             DIP                          |
              |                           |
              |----------------------------
              |
           RIP,VIP
        _____________
       |             |
       | realserver  |
       |_____________|
]]></programlisting>
			</para><para>
In UPPER CASE are the routes which need to be added to turn the LVS into a 3-Tier LVS
(<emphasis>e.g.</emphasis> FROM 0/0:PORT to RIP) where "PORT" is the port for the
client running on the RIP.
Note that the gw for 0/0:PORT (here SERVER_GW) can be another router -
it does not have to be the SERVER_GW.
Note also that the dst_addr does not have to be 0/0 -
a more restrictive dst_addr could be used if the IPs of the 3rd tier machines
are known ahead of time (<emphasis>e.g.</emphasis> DNS servers, database servers).
			</para><para>
In the original LVS-DR setup (1999, or configure scripts upto version 0.8.x)
the routes for the realserver were
<programlisting><![CDATA[
from RIP to RIP_network via eth0
default gw via SERVER_GW
]]></programlisting>
			</para><para>
In LVSs setup by the configure script 0.9.x, packets from the VIP are sent
to the default gw. Packets from the RIP to 0/0 are sent via the DIP
(where they are filtered <emphasis>i.e.</emphasis> DROPed or REJECTed)
			</para><para>
<programlisting><![CDATA[
from RIP to RIP_network via eth0
from VIP to 0/0 via SERVER_GW
from RIP to 0/0 via DIP
]]></programlisting>
			</para><para>
In LVSs setup by the configure script v 0.10.x and later, selected
packets from the RIP are sent to the 3_TIER_GW (which may be the
same as the SERVER_GW).
			</para><para>
<programlisting><![CDATA[
from RIP to RIP_network via eth0
from VIP to 0/0 via SERVER_GW
from RIP to selected_IPs:selected_ports via 3_TIER_GW
from RIP to ! RIP_network prohibit
]]></programlisting>
			</para><para>
	</para>
	</section>
	<section id="3-tier_route_setup">
	<title>Setting up routes using iptables and iproute2</title>
	<para>
The problem then becomes one of routing packets from RIP to 0/0:80 (if the
realserver is a squid) while making sure that no other packets from RIP to
any other ports on 0/0 are DROP'ed or REJECT'ed. For 2.2 kernels running
ipchains there is no way of doing this, and all packets to 0/0 have to be
routed. For 2.4 kernels, iptables allows marking (fwmark) by dport (or sport).
After marking, packets can be routed by iproute2.
	</para>
	<para>
The configure script (v 0.10.x or later) will set this up for you.
(May 2002, it's being tested as we speak, coming Real Soon Now).
Here's a standalone version of the code in the configure script
that marks the packets.
	</para>
<programlisting><![CDATA[
#!/bin/bash

#**************************
#NOTE: ADD THE LINE
#201    3_TIER
#to /etc/iproute2/rt_tables
#**************************

#---------------------------
#user modify section
RIP="192.168.1.11"
VIP="192.168.2.110"
#realserver will be allowed to connect to 0/0:OUTSIDE_PORT
#The port can be a number (eg 80) or a name in /etc/services (eg http).
#for a squid the port is http/80
#OUTSIDE_PORT="telnet"
#OUTSIDE_PORTS="192.168.2.254:telnet 0:80 192.168.2.254:1024:65535 0:auth"

#gw for packets coming from clients on realserver to 0/0:OUTSIDE_PORT
#(probably will be same as SERVER_GW in lvs_xxx.conf)
OUTSIDE_PORT_GW="192.168.1.254"

#from lvs_xxx.conf file
DIP="192.168.1.9"

#device carrying RIP
RIP_DEV="eth0"

DEBUG=Y                 #Y||N

#end user modify.
#---------------------------

#don't modify this.
#note mangling can only be done on the OUTPUT and the PREROUTING chains.
#CHAIN=PREROUTING       #for packets coming in, not what we want here.
CHAIN=OUTPUT            #for altering locally-generated packets before routing
OUTSIDE_PORT_CHAIN="3-Tier_rules"

#original code was
#iptables -N $OUTSIDE_PORT_CHAIN
#following a set of posting by
#Justin Albstmeijer justin (at ) VLAMea (dot) nl in  Oct,Nov 2003
#pointing out problems he was having, Ratz said this line should be
iptables -t mangle -N $OUTSIDE_PORT_CHAIN
#the old code is in the configure-lvs script, which I guess I'll
#fix sometime.

iptables -F $OUTSIDE_PORT_CHAIN
iptables -A $OUTSIDE_PORT_CHAIN -j MARK --set-mark 1

#---------------------------

#now stuff happens
#iptables section
iptables -F -t mangle

#mark packets from RIP to outside service
#note: you need -p protocol if you are using --dport
#iptables -t mangle -A ${CHAIN} -p tcp -s ${RIP}/32 -d 0/0 --dport ${OUTSIDE_PORT} -j MARK --set-mark 1
#for each OUTSIDE_PORT
OUTSIDE_IP="192.168.2.254"
OUTSIDE_PORT="telnet"
iptables -t mangle -A ${CHAIN} -p tcp -s ${RIP}/32 -d $OUTSIDE_IP --dport ${OUTSIDE_PORT} -j $OUTSIDE_PORT_CHAIN
OUTSIDE_IP=0
OUTSIDE_PORT="auth"
iptables -t mangle -A ${CHAIN} -p tcp -s ${RIP}/32 -d $OUTSIDE_IP --dport ${OUTSIDE_PORT} -j $OUTSIDE_PORT_CHAIN

#my test setup requires passing auth packets for telnet, or else telnet is delayed
#iptables -t mangle -A ${CHAIN} -p tcp -s ${RIP}/32 -d 0/0 --sport auth -j MARK --set-mark 1
#you can't do an ip rule on fwmark ! 1, so mark the unwanted packets too.
#iptables -t mangle -A ${CHAIN} -p tcp -s ${RIP}/32 -d 0/0 --dport ! ${OUTSIDE_PORT} -j MARK --set-mark 2

if [ "$DEBUG" = "Y" ]
then
        rm /var/log/debug
        kill -HUP `cat /var/run/syslogd.pid`
        iptables -t mangle -A ${CHAIN} -m mark --mark 1 -j LOG --log-level DEBUG --log-prefix "fwmark 1:
 "
fi

#show iptables
iptables -L -t mangle

#-----------------------------
#ip section

#packets from $RIP with fwmark 1, lookup table 3_TIER
ip rule add prio 99 from ${RIP} fwmark 1 table 3_TIER
#in table 3_TIER, add entry that all packets go via $(OUTSIDE_PORT_GW)
ip route add default via ${OUTSIDE_PORT_GW} dev ${RIP_DEV} table 3_TIER
#stop disallowed packets.
ip rule add prio 101 from ${RIP} fwmark 2 prohibit

#This may not be needed if the -t mangle is included above
#when `iptables -t mangle -N $OUTSIDE_PORT_CHAIN` is run.
#I haven't checked it yet.
#
#not sure why I need this one.
#There are some theories, none of which I can say for sure is it.
#me - so there is a route for packets to 0/0 when the routing table needs
#to check if packets can get there (the routing table doesn't know about the fwmark)
#Julian - so the client can get its src_addr.
#apparently clients are bound to 0.0.0.0,
#in which case they get their src_addr from the routing table.
#However (hopefully) all packets from $RIP to 0/0 to outside
#will have been stopped by the prohibit rule.
ip route add default from ${RIP} via ${DIP} table main

#show everything
ip rule show
ip route show table 3_TIER
ip route show table main

#Here's the output

#realserver:/etc/rc.d# ip rule show
#0:     from all lookup local
#100:     from 192.168.2.110 lookup VIP
#99:     from 192.168.1.11 fwmark        1 lookup 3_TIER
#100:    from 192.168.1.11 to 192.168.1.0/24 lookup RIP
#100:    from 192.168.1.11 lookup RIP
#101:    from 192.168.1.11 lookup main prohibit
#32766:  from all lookup main

#realserver:/etc/rc.d# ip route show table 3_TIER
#default via 192.168.1.254 dev eth0

#realserver:/etc/rc.d# ip route show table main
#192.168.2.110 dev lo  scope link  src 192.168.2.110
#192.168.1.0/24 dev eth0  scope link
#192.168.1.0/24 dev eth0  proto kernel  scope link  src 192.168.1.11
#127.0.0.0/8 dev lo  scope link
#default via 192.168.1.9 dev eth0

#-------------------------------------------------
]]></programlisting>
	<para>
Francois<emphasis>flafolie (at) aic (dot) fr</emphasis> Apr 26 2007
	</para>
	<para>
It seems I need the following rules to make my setup work.
The iprules have to
have as ip source address the VIP and not the RIP.
	</para>
<programlisting><![CDATA[
ip rule add from 10.0.22.171 table ftp_table
ip rule add from 10.0.23.100 table http_table
]]></programlisting>
	<para>
Here's the original problem I posted.
I have installed and configured keepalived (v1.1.13).
	</para>
<programlisting><![CDATA[
IP Virtual Server version 1.2.1 (size=4096)
Prot LocalAddress:Port Scheduler Flags
  -> RemoteAddress:Port           Forward Weight ActiveConn InActConn
TCP  10.0.23.100:http wlc persistent 600
  -> 192.168.15.11:http           Masq    100    0          0
TCP  10.0.22.171:ftp wlc persistent 600
  -> 192.168.15.10:ftp            Masq    100    0          0
]]></programlisting>
	<para>
I'm trying to manage different services on different VLANs on my
loadbalancer.
	</para>
<programlisting><![CDATA[
eth0.26 : vlan 10.0.22.0/24 for ftp
eth0.28 : vlan 10.0.23.0/24 for http
]]></programlisting>
	<para>
The problem is I can configure only one default route on my loadbalancer.
For example, if my default route is 10.0.23.1, request and reply for http
(vlan 10.0.23.0) both going in the good vlan. But for ftp, request will be
on the good vlan (10.0.22.0) but reply on vlan 10.0.23.0 (my firewall
authorizes that for tests) and not 10.0.22.0.
	</para>
	<para>
I have tried to define some iprules on my loadbalancer to say if the source
ip address is 192.168.15.10, so forward packets to 10.0.22.0 network but it
seems doesn't work. LVS apparently don't let the routing decisions to the
operating system after its own operations...
Here are my iprules :
	</para>
<programlisting><![CDATA[
ip rule add from 192.168.15.10 table ftp_table
ip rule add from 192.168.15.11 table http_table

ip route add default via 10.0.22.1 dev eth0.26 table ftp_table
ip route add default via 10.0.23.1 dev eth0.28 table http_table
ip route flush cache
]]></programlisting>
	<para>
I also tried that but no more effect :
	</para>
<programlisting><![CDATA[
ip route add default scope global nexthop via 10.0.22.1 dev eth0.26 weight 1
nexthop via 10.0.23.1 dev eth0.28 weight 1
]]></programlisting>
	</section>
	<section id="3-tier_mailing_list">
	<title>from the mailing list</title>
	<para>
TC Lewis has <xref linkend="NAT_client_ntp"/> running on the realserver.
He is using NAT through the director rather than routing the packets directly as
is described here.
An LVS-DR director normally <link linkend="Pearthree">does not have a default route</link>
and this would have to be added to NAT packets through the director.
You may be able to NAT through the router instead.
	</para>
	</section>
</section>
<section id="LVS-HOWTO.lvs_clients_on_realservers" xreflabel="lvs clients on realservers">
<title>LVS: LVS clients on Realservers</title>
<para>
	This HOWTO is a little disorganised here. 
Read the section on <xref linkend="LVS-HOWTO.non-lvs_clients_on_realservers"/> too.
</para>
	<section id="do_you_need_lvs_clients_on_the_realserver">
	<title>Do you really need LVS clients on the realserver in a 3-Tier setup?</title>
	<para>
Thomas Champagne 10 Apr 2007
	</para>
	<blockquote>
There are two services on each servers : Apache and Mysql.
Each service have its IP and have a VIP address :
The problem : Accessing services from a remote client (outside the
cluster) to the VIP is ok. But when the client is the cluster, it always
connects on the local machine.
	</blockquote>
	<para>
people coming to this mailing list are always trying to balance the 3rd-tier
(in your case, mysql). If this was easy to do, that would be one thing, but
with the current design of LVS, it's next to impossible.
	</para>
	<para>
The first connection
(here to apache) is balanced, so that the connection to the 3rd-tier (here
to mysql) will be (at least reasonably) balanced. So you have the balanced
apache on your realserver connect to the local mysql.
	</para>
	<para>
To have a valid realserver, both apache and mysql have to be up. Maybe
people think then that, running two services, 
there's twice the chance of the realserver going down
and for the same hardware their 99% uptime realserver is now a 98% uptime
realserver. So they have to be prepared for apache_1 to connect to mysql_2.
That would be true if the only failures on the machine were the demons dying
and that they died independantly. I don't run a production internet site, so
I don't have any numbers on failures in those situations, but it's not often
that demons for no reason at all just die or stop answering. Most failures
seem to be disks and fans dying, memory chips going bad resulting in corrupt
files being written, loss of network connectivity to the outside world (the
backhoe problem) and surprisingly routers dying. Rarely does the demon die.
In which case requiring two demons to have a functioning realserver may not
change the downtime a whole lot. There's many other demons running on the
realserver which are part of unix, and which are required for a running
machine, so you actually need maybe 10-20 demons for a functioning
realserver, in which case an extra one (mysql) isn't going to make a whole
lot of difference.
	</para>
	<para>
But let's say a functional realserver will have twice the downtime because
it requires two functioning realservsers. Well that's high availability life
when you have a service that requires multiple demons. You have to fail out
the realserver when either service goes down. That's all.
	</para>
	<para>
Last exchange I had on this subject, the person didn't have any technical
reason why they needed to balance the 3rd-tier. They just wanted it. So I
haven't been convinced that you must have a balanced 3rd tier.
	</para>
	</section>
	<section id="lvs_clients_on_LVS-NAT_realserver_contacting_services_on_VIP"
	xreflabel="lvs clients on LVS-NAT realservers connecting to services on VIP">
	<title>Realserver as LVS client in LVS-NAT</title>
	<para>
The 
<ulink url="http://www.austintek.com/LVS/LVS-HOWTO/mini-HOWTO/LVS-mini-HOWTO.html#gotchas">
LVS-mini-HOWTO</ulink> states that the lvs client cannot be on the realservers, 
<emphasis>i.e.</emphasis> that you need an outside client.
This restriction can be relaxed under some conditions.
	</para>
	<para>
	</para>
		<section id="jacobs_solution" xreflabel="jacobs_solution">
		<title>Jacob Reif's solution</title>
		<para>
This came from a posting by
Jacob Reif <emphasis>Jacob (dot) Rief (at) Tiscover (dot) com</emphasis> 25 Apr 2003.
		</para>
		<para>
It is common to run multiple websites (Jacob has 100s) on the same IP,
using name based http to differentiate the websites.
Sometimes webdesigners use some kind of include-function to include
content from one website into another, by means of server-side-includes.
(see http://www.php.net/manual/en/function.require.php) using
http-subrequests.
The include requires a client process running on the webserver,
to make a request to a different website on the same IP.
If the website is running on an LVS, then the realservers
need to be able to make a request to the VIP.
For LVS-DR and LVS-Tun this is no problem: the realserver has the VIP
(and the services presented on that IP),
so requests by http clients running on the realserver to the VIP,
will be answered locally.
		</para>
		<para>
For LVS-NAT, the services are all running on the RIP
(remember, there is no IP with the VIP on realservers
for LVS-NAT).
Here's what happens when the client on the realserver
requests a page at VIP:80
		</para>
		<para>
realserver_1 makes a request to VIP:80, which goes
to the director.
The director demasquerades (rewrites) dst_addr from VIP to RIP_2.
realserver_2 then services the request and fires off a reply
packet with src_addr=RIP_2, dst_addr=RIP_1.
This goes to realserver_1 directly (rather than being
masqueraded through the director),
but realserver_1 refuses the
packet because it expected a reply from VIP and not
from RIP_2.
		</para>
<programlisting><![CDATA[
           +-------------+
           |     VIP     |
           |  director   |
           +-------------+
            ^           |
            |           |req
            |req        v
  +-------------+     +-------------+
  |   RIP_1     |<--- |   RIP_2     |
  |  Realserver | ans |  Realserver |
  |  = client   | wer |  = server   |
  +-------------+     +-------------+
]]></programlisting>
		<para>
Here are the current attempts at solutions to the problem,
or you can go straight to
<link linkend="jacobs_solution">Jacob's solution</link>
		</para>
		<itemizedlist>
			<listitem>
Using the <filename>/etc/hosts</filename> solution of Ted Pavlic
for <xref linkend="indexing"/>,
doesn't work as there are 100s of domain-names registered
(rather than just one)
onto the same IP-address.
			</listitem>
			<listitem>
			<para>
Julian's solution removes the local routing
(as done for <link linkend="one_network">one network LVS-NAT</link>)
and forces every packet to pass through the director.
The director therefore masquerades (rewrites) src_addr=RIP_2 to VIP and
realserver_1 accepts the request.
This puts extra netload onto the director.
			</para>
<programlisting><![CDATA[
           +-------------+
           |    <vip>    |
           |  director   |
           +-------------+
            |^         |^
         ans||      req||ans
            v|req      v|
  +-------------+     +-------------+
  |  <rip1>     |     |  <rip2>     |
  |  Realserver |     |  Realserver |
  |  = client   |     |  = server   |
  +-------------+     +-------------+
]]></programlisting>
			</listitem>
		</itemizedlist>
		<para>
Jacob's solution:
The solution proposed here does not put that extra load onto the director.
However each realserver always contacts itself (which isn't a problem).
Put the following entry into each realserver.
Now the realservers can access the httpd on RIP as if it were on VIP.
		</para>
<programlisting><![CDATA[
realserver#  iptables -t nat -A OUTPUT -p tcp -d $VIP --dport 80 -j DNAT --to ${RIP}:80
]]></programlisting>
		</section>
		<section id="carlos_solution" xreflabel="Carlos Lozano's ip_vs_core.c.diff">
		<title>Carlos Lozano's solution</title>
		<para>
Carlos Lozano <emphasis>clozano (at) andago (dot) com</emphasis> 02 Jul 2004
		</para>
		<para>
We have a machine that must be both a client and director.
The two problems to solve are
		</para>
		<itemizedlist>
			<listitem>
ipvs doesn't handle loopback packets
			</listitem>
			<listitem>
the return packets are handled by 
<filename>ip_vs_in</filename>, and not by <filename>ip_vs_out</filename>.
			</listitem>
		</itemizedlist>
		<para>
I have written a 
<ulink url="files/ip_vs_core.c.diff">ip_vs_core.c.diff</ulink> 
(http://www.austintek.com/LVS/LVS-HOWTO/HOWTO/files/ip_vs_core.c.diff)
patch for 2.4.26 using IPVS-NAT. 
It works correctly in my testcase.
The schema is:
		</para>
<programlisting><![CDATA[
External client ---> IPVS:443 --> Local:443 ---> IPVS:80 ---> RealServer
]]></programlisting>
		<para>
The problem happens when Local:443 goes to localIPVS:80, 
because the packet is discarded by the next lines in ip_vs_core.c:
		</para>
<programlisting><![CDATA[
if (skb->pkt_type != PACKET_HOST) || skb->dev == &loopback_dev) { 
        IP_VS_DBG(12, "packet type=%d proto=%d daddr=%d.%d.%d.%d ignored\n",
                       skb->pkt_type,
                       iph->protocol,
                       NIPQUAD(iph->daddr));
        return NF_ACCEPT;
}  
]]></programlisting>
		<para>
Ratz
		</para>
		<blockquote>
Why do you need this? Seems like a replication of mod_proxy/mod_rewrite.
Your patch obviously makes it work but I wonder if such a functionality 
is really needed.  
		</blockquote>
		<para>
We are using it like an ssl accelerator. The first ipvs (443) sends the
request to localhost:443 or to a different director, and the second
ipvs(80), distributes the traffic in the realservers. 
		</para>
<programlisting><![CDATA[
Ext. client --> IPVS:443 --> Local:443 --> IPVS:80 --> RealServer1
                         |-> Director2:443         |-> RealServer2
]]></programlisting>
		<para>
In the first case, it is a scheme "external machine client+director", 
but in the second case it is a "client+director in the same machine".
This part of the patch only solves the output packet, the return is  
handled by the second part of the patch. (what is really a bad hack)
		</para>
		<para>
For a mini-HOWTO on using this patch see 
<xref linkend="https_on_localnode"/>.	
Matt Venn has tested it, it works using
the local IP of the director, but not 127.0.0.1.
		</para>
		</section>
		<section id="graeme_fowler">
		<title>Graeme Fowler's proposals, Rob Wilson's help and Judd Bourgeois' modification</title>
		<note>
Graeme came up with the original idea, Rob Wilson proposed a solution that
didn't quite work, Graeme fixed it and then Judd saw an easier solution
for the case of only one VIP. I've somewhat mashed the history in my 
write-up (sorry).
		</note>
		<para>
Graeme Fowler is looking for a solution for realservers that can't use 
<filename>iptables</filename>
		</para>
		<para>
Graeme Fowler <emphasis>graeme (at) graemef (dot) net</emphasis> 11 Feb 2005 
		</para>
		<para>
After a long day spent tracing packets through the LVS and netfilter trail
whilst trying to do cleverness with policy routing using the iproute2 package,
I can condense quite a lot of reading (and trial, mainly followed by error!)
down as follows:	
		</para>
		<orderedlist>
			<listitem>
FastNAT, as provided by the iproute2 package, is incompatible with the 
netfilter conntrack module. As most LVS-NAT systems are also doing 
masquerading or SNAT for outbound connections from the realservers, the 
conntrack module is loaded automagically - thus FastNAT via policy routing 
simply won't work.
			</listitem>
			<listitem>
Try as you might to do SNAT, it has to be done in the 'nat POSTROUTING' 
chain - and the packets being processed via LVS don't traverse this chain, 
because they're hooked right out of the nat POSTROUTING table and are 
processed by ip_vs_port_routing instead, which then plonks them back on the 
wire magically without further processing. So SNAT won't work either.
			</listitem>
			<listitem>
Using fwmarks seems inconclusive, because ultimately (in my case at least) 
I want to SNAT the packets in some way, and point (2) above precludes that.
			</listitem>
			<listitem>
"Internal" VIPs.
This one just came to me so please feel free to try it, I'm away from my
development lab and it might prove to be a complete lemon anyway!
Here's the idea: on the director, for every "external" VIP configuration which
faces the clients (say VIP1) another VIP - iVIP1 - is also configured with
identical realservers but attached to the _internal_ interface. The principle
difference is that this VIP uses LVS-DR, because - for obvious reasons - the 
realservers can respond directly to each other.
The only complicated bit is setting up a netfilter rule to do DNAT as the 
packets arrive - trap all packets destined for VIP1 and DNAT them to iVIP1. 
Ensure VIP1 is a loopback alias on your realservers as per normal DR 
configuration, and in theory at least the realservers should then be able to 
talk to each other as clients of a VIP.
			</listitem>
		</orderedlist>
		<para>	
Conclusions: mixing policy routing and LVS sounds like a great idea, and 
probably is if you're using LVS-DR or LVS-TUN. Just with LVS-NAT, it's a no-go 
(for me at the moment, anyway).
		</para>
		<para>
Graeme Fowler <emphasis>graeme (at) graemef (dot) net</emphasis> 2005/03/11
		</para>
		<para>
Solved... was Re: LVS-NAT: realserver as client (new thread, same subject!)
		</para>
		<para>
I've solved it - in as far as a proof of concept goes in testing. 
It's yet to be used under load though; however I can't see any specific problems ahead once I move
it into production.
		</para>
		<para>
The solution of type "4" above involves a "classic" LVS-NAT cluster as follows.
Nomenclature after DIP/RIP/VIP classification is "e" for external (ie.
public address space), "i" for internal (ie. RFC1918 address space) and
numbers to delimit machines.
		</para>
<programlisting><![CDATA[
Director: External NIC eth0 - DIPe, VIP1e
          Internal NIC eth1 - DIPi

Realserver 1: Internal NIC eth1 - RIP1

Realserver 2: Internal NIC eth1 - RIP2
]]></programlisting>
		<para>
In normal (or "classic" as referred to above) LVS-NAT, the director has
a virtual server configured on VIP1e to NAT requests into RIP1 and RIP2.
Under these circumstances, as discussed in great length in several
threads in Jan/Feb (and many times before), a request from a realserver
to a VIP will not work, because:
		</para>
<programlisting><![CDATA[
src         dst
RIP1 SYN -> VIP1e
RIP1 SYN -> RIP2  (or RIP1, doesn't matter)
RIP2 ACK -> RIP1
]]></programlisting>
		<para>
at this point the connection never completes because the ACK comes from
an unexpected source (RIP2 rather than VIP1e), so RIP1 drops the packet
and continues sending SYN packets until the application times out.
We need a way to "catch" this part of the connection and make sure that
the packets don't get dropped.
As it turns out, the hypothesis I put forward a month ago works well
(rather to my surprise!), and involves both netfilter (iptables) to
mangle the "client" packets with an fwmark, and the use of LVS-DR to
process them.
		</para>
		<para>
What I now have (simplified somewhat, this assumes a single service is
being load balanced in a very small cluster):
		</para>
<programlisting><![CDATA[
Director: External NIC eth0 - DIPe, VIP1e
          Internal NIC eth1 - DIPi

Realserver 1: Internal NIC eth1 - RIP1
              Loopback adapter lo:0 - VIP1e

Realserver 2: Internal NIC eth1 - RIP2
              Loopback adapter lo:0 - VIP1e
]]></programlisting>
		<para>
The on the director:
		</para>
<programlisting><![CDATA[
/sbin/iptables -t mangle -I PREROUTING -p tcp -i eth1 \
   -s $RIP_NETWORK_PREFIX -d $VIP1e --dport $PORT \
   -j MARK --set-mark $MARKVALUE
]]></programlisting>
		<para>
and we need a corresponding entry in the LVS tables for this. I'm using
keepalived to manage it; yours may be different, but in a nutshell you
need a virtual server on $MARKVALUE rather than an IP, using LVS-DR,
pointing back to RIP1 and RIP2. Instead of me spamming configs, here's
the <command>ipvsadm -Ln</command> output:
		</para>
<programlisting><![CDATA[
director# ipvsadm -Ln
Prot LocalAddress:Port Scheduler Flags
  -> RemoteAddress:Port   Forward Weight ActiveConn InActConn

FWM  92 wlc
  -> $RIP1:$PORT           Route  100    0          0
  -> $RIP2:$PORT           Route  100    0          0

(empty connection table right now)
]]></programlisting>
		<para>
...and believe it or not, that's it. Obviously the more VIPs you have,
the more complex it gets but it's all about repeating the appropriate
config with different RIP/VIP/mark values.
		</para>
		<para>
For ease of use I make the hexadecimal mark value match the last octet
of the IP address on the VIP; it makes for easier reading when tracking
stats and so on.
		</para>
		<para>
I've not addressed any problems with random ARP problems yet because
they haven't yet occurred in testing; and one major bonus point is that
if a connection is attempted from (ooh, let's say, without giving too
much away) a server-side include on a virtual host on a realserver to
another virtualhost on the same VIP, then it'll get handled locally as
long as Apache (in my case) is configured appropriately.
		</para>
		<para>
An interesting, and useful, 
side-effect of this scheme
is that when a realserver wants to connect to a VIP which it is 
handling, it'll
connect to itself - which reduces greatly the amount of traffic traversing the
RS -> Director -> RS network and means that the amount of actual 
load-balancing
is reduced too.
		</para>
		<para>
Rob Wilson <emphasis>rewilson () gmail ! com</emphasis>
2005-08-09 
		</para>
		<para>
We have an LVS server for testing which is handling 2 VIPs through LVS-NAT 
(using keepalived). 
Each of the VIPs currently points to 1 real server - it's a one realserver
LVS - just in testing phase at the moment. Both 
real-servers are on the same internal network.
		</para>
<programlisting><![CDATA[
VIP1 -> Realserver1 
VIP2 -> Realserver2 
]]></programlisting>
		<para>
We'd now like Realserver2 to be able to connect to Realserver1 via VIP1.
I was able to accomplish this following the solution provided by Graeme 
Fowler:
http://www.in-addr.de/pipermail/lvs-users/2005-March/013517.html
However, external connections to VIP1 no longer work while that solution is 
in place. Dropping the lo:0 interface assigned to VIP1 on Realserver1 fixes 
this, but then breaks Realserver2 from connecting. 
		</para>
		<para>
Graeme Fowler <emphasis>graeme () graemef ! net</emphasis>
2005-08-10
		</para>
		<para>
Are you doing your testing from clients on the same LAN as the VIP, by 
any chance? Have you set the netmask on the lo:0 VIP address on the 
realservers to 255.255.255.255?
I can see that making it a /24 mask - 255.255.255.0 - might result in 
the realservers thinking that the client is actually local to them, 
thus dropping the packets.
		</para>

		<para>
Rob Wilson <emphasis>rewilson () gmail ! com</emphasis> 
2005-08-10
		</para>
		<para> 
That's exactly it. I was hoping it was something daft I misconfigured, so.. 
wish granted :)
It works perfectly now. Thanks for your help (and coming up with the idea in 
the first place!).
		</para>

		<para>
Judd Bourgeois <emphasis>simishag (at) gmail (dot) com</emphasis> 19 Jan 2006 
		</para>
		<para>
I am running LVS-NAT, where the director has two NICs (and two networks).
The VIP is on the inside of the director (in the RIP network)
(Joe - this functions as a two network LVS-NAT).
Some of my web sites proxy to "themselves" within a page
(proxy, PRPC, includes, etc.).
The symptom is that the proxy functionality
breaks.  The real server does a DNS lookup for the remote site, gets back
the VIP, and hangs waiting for a response.
		</para>
		<para>
Previously I solved this problem by putting the site names and 127.0.0.1 in
<filename>/etc/hosts</filename> (as mentioned in this section and in
<xref linkend="indexing"/>), but after reading the FAQ more
carefully tonight, I solved it by simply adding the VIP as a dummy interface
on all of the realservers.  This appears to be addressed in Graeme's solution, but
he runs an extra iptables command on the director.  Is this really
necessary?  Won't any packets originating on the real servers and destined
for the VIP be handled by the dummy interface on the real server, without
being put on the wire?
		</para>
		<para>
It all appears to work fine and has the added nice effect of forcing each
realserver to proxy to itself when necessary.
		</para>
		<para>
Graeme Fowler <emphasis>graeme (at) graemef (dot) net</emphasis> 1/20/06
		</para>
		<para>
What you've suggested is the "single VIP" case of the above idea. It
worked for me, it seems to have worked for Rob Wilson, so casting aside
the fact that you might have multiple VIPs frontending multiple
realserver clusters (as is my case) I can't see any reason why you
shouldn't just go for it.
		</para>
		<para>
Judd Bourgeois <emphasis>simishag (at) gmail (dot) com</emphasis>
20 Jan 2006 
		</para>
		<para>
Right.  In fact, after reading your solution again, I think your solution is
the more useful general case, where there may be an arbitrary number of
VIPs, RIPs, and groupings of real servers (which I don't need right now, but
I've realized I will need it down the road).  I have some Alteons that call
these real server groups, not sure what the LVS equivalent is, but here's a
short illustration.
		</para>
		<para>
Assume 1 director, 3 VIPs, 4 RIPs on 4 real servers.  Assume we have real
server groups (RG) RG1 (RIP1-2), RG2 (RIP3-4), RG3 (RIP1-4).  VIP1 goes to
RG1, VIP2 goes to RG2, VIP3 goes to RG3.
		</para>
		<para>
In my solution, servers in RG1 can simply put VIP1 and VIP3 on dummy
interfaces, but for proxy requests they will only be able to talk to
themselves.  They will not be able to talk to VIP2.  All servers should be
able to talk to VIP3.  Your solution solves this by using fwmark.
		</para>
		<para>
This is a fairly common problem with NAT in general that I have to deal with
a lot.  Basically, the NAT box will not apply NAT rules for traffic
originating and terminating on the NAT box.  I recall that one workaround
for this is to use the OUTPUT chain, I can't find the rules at present but
it seemed to work ok.
		</para>
		<para>
Ratz 21 Jan 2006
		</para>
		<para>
There is no LVS equivalent of "real server groups".
But I think Alteon (Nortel) only has this feature 
for adminstrative reasons, so you can assign a group by its identifier 
to a VIP. What I would love to see with LVS is the VSR approach and a 
proper and working imlementation of VRRP or CARP. I've just recently set 
up a 2208 switch using one VSRs and 2 VIRs, doing failover when either 
the link or the DGW is not reachable anymore. The sexy thing about this 
setup is that you don't need to fiddle around with arp problems and you 
don't need to have NAT, so balancing schedulers can get meaningful L7 
information.
Alteon's groups are just an administrative layer with an identifier. We could add such 
a layer in ipvsadm and the IPVS code, however what benefit do you see in 
such an approach?
		</para>
		<para>
One problem I see with the Alteon approach is that if you add a RS to a 
group, to my avail it can only pertain to one RG. This is a bit 
suboptimal if you want to use RS as spillover servers on top of their 
normal functionality. Regarding your example, I'd like to say, that RG1 
is a spillover group for RG3. You can specify (IIRC) a spare server of 
each RG in AltheOS, however not cross-RG wise. Correct me if I'm wrong, 
please.
		</para>
		<para>
Judd
		</para>
		<blockquote>
Graeme's solution solves this by using fwmark.
		</blockquote>
		<para>
Yes, fwmark solves almost all problems
		</para>
		<para>
Graeme Fowler <emphasis>graeme (at) graemef (dot) net</emphasis> 21 Jan 2006 
		</para>

		<para>
Judd doesn't need fwmark, because in a single VIP LVS-NAT, 
with that VIP assigned locally on the
realservers on a dummy interface (or loopback alias), the realservers
will always answer requests for the VIP locally.
		</para>
		<para>
In a two-VIP case (the simplest multiple), if you have two "groups" [0]
of realservers, then the director becomes involved by virtue of it being
the default gateway for the realservers.
At the point the director gets involved you need some way of determining
which interface your traffic is on, and segregation via fwmark seems the
most elegant way to achieve this (given the known and predictable
failure of realservers as clients in LVS-NAT). I know I struggled for
months before realising that I could, in effect, combine the use of NAT
via an external interface for my real clients, and DR via an internal
interface for my "realservers as clients".
		</para>
		<para>
[0] I use the word groups in quotes and advisedly, since it appears that
Alteon use that in their setup terminology from previous posts.
		</para>
		</section>
	</section>
	<section id="realserver_as_client_in_LVS-DR">
	<title>Realserver as LVS client in LVS-DR</title>
	<para>
The topic came up with a posting about an LVS of httpd which generated
mail (presumably a webmail LVS). The poster reasonably wanted the
e-mail to be balanced by the same director. The problem is that
the mail is being sent to the VIP (on the director) 
from a machine (the realserver) which also has the VIP.
The mail will be accepted locally on the realserver, 
rather than being sent to the director to be load balanced.
If you don't attempt to load balance the mail requests, 
then if there are enough requests, 
then statistically (over a long enough period) the http traffic will be balanced
and the mail coming from each realserver will be approximately balanced. 
This posting started an off-line discussion with
Horms and Ludo about ways to have clients on the director and on the realservers.
The outcome was 
<link linkend="ludo_lvs_dr-client_on_realserver"> an idea by Ludo</link>, 
which no-one has got to work yet (Horms tried something similar a while
ago and couldn't get it to work either) and a 
<link linkend="julian_lvs_dr-client_on_realserver"> 
proposal by Julian</link>, which seems likely to work.
	</para>
	<para>
Dan <emphasis>kasper37 (at) speakeasy (dot) net</emphasis> 1 Oct 2005
	</para>
	<blockquote>
		<para>
Is there a way to connect from one of the real servers
hosting web to the VIP:smtp service?  The problem is that
telnet to VIP:smtp from one of the web real servers is
going to try to connect to smtp locally.
I'm actually talking about any
virtual service in general.
Here's what we've got so far (brace yourself):
		</para>
<programlisting><![CDATA[
# ip route add x.x.x.70 dev eth1 table local tos 4 scope link src y.y.y.16
# iptables -A PREROUTING -t mangle -p tcp --dport 25 -j TOS --set-tos 4
# ip route ls table all| grep x.x.x.70
x.x.x.70 tos reliability via y.y.y.16 dev eth1  table local  scope link  src y.y.y.16
local x.x.x.70 dev lo  table local  proto kernel  scope host  src y.y.y.70
]]></programlisting>
		<para>
These commands are run on the real server (for the sake of brevity I only
included the commands for one real server, but imagine these being run on all
real servers with the correc RIPs substituted for y.y.y.16).  With these rules,
packets are being output to the network as hoped, but the problem is that the
/source/ address is x.x.x.70 instead of the real server's RIP.  If there was a
way to force the kernel to send the request from the real servers RIP, this may
actually work.  Any ideas?
		</para>
	</blockquote>
	<para>
Ludo Stellingwerff <emphasis>ludo (at) protactive (dot) nl</emphasis> Oct  2 2005
	</para>
	<para>
Dan, try it like this: (without your routing table hacks)
	</para>
<programlisting><![CDATA[

#iptables -A PREROUTING -t nat -i lo -p tcp -d <local_ip> --dport 25 - -j ROUTE --oif  eth0
]]></programlisting>
	<para>
I assume you have fixed the ARP problems. 
Therefore the above ROUTE target should work.
If it doesn't I'll have to think of a solution using the "ip rule"
command in combination with firewall marking.
	</para>
	<para>
Joe (off-list)
	</para>
	<blockquote>
Can either of you think of a situation where it would be useful to
have the director also be a client?
	</blockquote>
	<para>
Ludo
	</para>
	<para>
Besides testing purposes, I can only think of two reasons:
	</para>
	<itemizedlist>
		<listitem>
Flexibility - for all those situations we can't guess because of lack
of imagination
		</listitem>
		<listitem>
In my line of work: When you combine the LVS-director with  a proxy
server.
		</listitem>
	</itemizedlist>
	<para>
Most companies (including my own) seem to want to integrate all
difficult routing problems on the company's gateway/router/firewall.
(My job is making this possible in a user-friendly manner, interfaces:)
One of the things many firewalls do is providing proxy-services to the
internal users. If you integrate LVS-director services on this
firewall, proxyusers should be able to access these services too.
Thus the director functions as a client.
	</para>
	<para>
Joe
	</para>
	<blockquote>
The case of allowing the realserver to be a client seems more useful. The
posting today on lvs-users was of a 3-Tier site where the LVS'ed
httpd sends mail. The poster wants to LVS the smtp too, but the
realservers connect to the local VIP:smtp.
	</blockquote>
	<para>
Right, this seems even more common.
	</para>
	<blockquote>
Is there any routing that's done down in the depths of LOCAL_IN?
What happens to a packet desting for a local IP? Does it appear in
the routing diagram, or does it just never get out. Can you
fwmark a packet to dst=LOCAL_IP:smtp and get it out somehow?
	</blockquote>
	<para id="ludo_lvs_dr-client_on_realserver">
Ludo
	</para>
	<para>
For email this question completely depends on the way the
client-software presents it email:
There are generally two possibilities:
	</para>
	<itemizedlist>
		<listitem>
Using a smtp-client
		</listitem>
		<listitem>
Using a local postdrop (Presenting mail to the local MTA without
using network traffic)
		</listitem>
	</itemizedlist>
	<para>
Most localservices will use a local postdrop, these can't be pulled
out of the local machine easily.
But clientsoftware using the SMTP protocol will normally connect to:
localhost:25.
	</para>
	<para>
To answer your question: traffic to the localhost is always done via
the loopback network device (dev lo). This can be fwmarked and
rerouted without too much of a problem.
	</para>

<programlisting><![CDATA[
#iptables -A PREROUTING -t nat -i lo -p tcp -d <local_ip> --dport 25 - -j ROUTE --oif  eth0
]]></programlisting>
	<para>
local_ip is the VIP not the RIP. I'm using it as the -d (destination) of
the connection.
The part behind the -j might need some more thinking/testing, but this
should work.
If ROUTE doesn't work, I can think of some more complex solutions to
get the packet to the director, through fwmarking and using Policy
Routing. 
	</para>
	<para>
Let's follow a packet:
	</para>
	<itemizedlist>	
		<listitem>
SMTP-client (on Realserver) wants to send a email
		</listitem>
		<listitem>
			<para>
SMTP-client sends a SYN-packet to VIP:25.
			</para>
			<para>
The src_addr of this smtp-client should be the RIP of the realserver that
handled the original http request.
Maybe you'll need to enforce the fact that the src_addr of this realserver's
packet is the RIP:
			</para>
<programlisting><![CDATA[
#iptables -A POSTROUTING -o lo -d <VIP> -p tcp --dport 25 -j SNAT --to-source <RIP>
]]></programlisting>
		</listitem>
		<listitem>
This packet gets sent through the loopback device. (Because the VIP
is local to the realserver when using LVS/DR)
		</listitem>
		<listitem>
the PREROUTING nat rule above matches, stealing the packet from the normal routing.
		</listitem>
		<listitem>
The packet is send directly through the output function of dev eth0.
		</listitem>
	</itemizedlist>
	<para>
I'm not sure if this and the next step work correctly. 
If not, I'll have to go to the Policy Routing solution.
	</para>
	<itemizedlist>
		<listitem>
This output driver asks for the MAC address of the VIP through ARP
requests.
		</listitem>
		<listitem>
the realserver doesn't answer because the ARP problem is solved.
		</listitem>
		<listitem>
the Director does answer, so the packet is sent to the director, who
balances the packet.
		</listitem>
	</itemizedlist>
	<para>
The packets then are 
	</para>
	<itemizedlist>
		<listitem>
RIP -> VIP:smtp
		</listitem>
		<listitem>
The packet goes to the VIP on the director
 and then you'll get a reply packet from the MTA: VIP:smtp -> RIP
		</listitem>
	</itemizedlist>
	<para>
Normally you don't want RIP to be routable on the internet, but in this
example the VIP host(s) do know where this RIP is, because it is in the
same local network.
Lets make this a complete example:
	</para>
<programlisting><![CDATA[
                    Internet
                        |
                Gateway: 1.2.3.1
                        |
                        |
       /----------------+--------------------\
       |                |                    |
       |          Director (LVS/DR)          |
       |            VIP:1.2.3.4              |
       |           LAN1:192.168.1.1          |
       |                                     |
       |                                     |
Realserver1: 192.168.1.2       Realserver2: 192.168.1.3
]]></programlisting>
	<para>
To make this setup work the realservers use the loopback trick to prevent
arp problems: The VIP is on their loopback devices. The RIP is on device
eth0 of the realservers. Just a normal LVS/DR setup will do.
	</para>
	<para>
Now you want Realserver1 to connect to the balanced service smtp(port 25)
on the director.
Using the following two iptables rules should do the trick:
	</para>

<programlisting><![CDATA[
#iptables -A POSTROUTING -o lo -d 1.2.3.4 -p tcp --dport 25 -j SNAT --to-source 192.168.1.2
#iptables -A PREROUTING -i lo -d 1.2.3.4 -p tcp --dport 25 -j ROUTE --oif eth0
]]></programlisting>
	<para>
Or you might want to give a more generic solution to the Realservers
connection to the director:
	</para>
<programlisting><![CDATA[
#iptables -A POSTROUTING -o lo -d 1.2.3.4 -j SNAT --to-source 192.168.1.2
#iptables -A PREROUTING -i lo -s 192.168.1.2 -d 1.2.3.4 -j ROUTE --oif eth0
]]></programlisting>
	<para>
And for Realserver2:
	</para>
<programlisting><![CDATA[
#iptables -A POSTROUTING -o lo -d 1.2.3.4 -j SNAT --to-source 192.168.1.3
#iptables -A PREROUTING -i lo -s 192.168.1.3 -d 1.2.3.4 -j ROUTE --oif eth0
]]></programlisting>
	<para>
Any client on the realservers that wants to connect to the VIP's services
can work now.
	</para>
	<para>
To test you can try: "telnet 1.2.3.4 25" from one of the
realservers. The MTA should react with something like:
	</para>
<programlisting><![CDATA[
HELO example.com                           <--- command you give the MTA.
220 realserver1.example.com ESMTP Postfix  <--- MTA's answer
]]></programlisting>
	<blockquote>
		<para id="julian_lvs_dr-client_on_realserver">
Joe: Let's say there's no way to do it with iptables. Is
it possible to write a piece of code that does what
we want outside of iproute2/iptables?
		</para>
		<para>
Ratz: Basically, what you want is to trick a RS FIB to handle a mark'd packet
with scope local into thinking its realm is scope global and then route
t out on the interface to only wait that it comes back with src mac ==
mac of RIP, dest mac == mac of RIP, src IP = RIP, dest IP = VIP.
My 5 minutes of thinking on the problem suggest that it's unsolvable
with conventional methods without causing major breakage in the FIB of
the routing cache.
		</para>
	</blockquote>
	<para>
Julian Anastasov <emphasis>ja (at) ssi (dot) bg</emphasis> 3 Nov 2005
	</para>
	<para>
	One can try the "loop" flag (send-to-self) feature at
routing level: http://www.ssi.bg/~ja/#loop.
	There is a text file that explains its usage.
	</para>
	<para>
	This patch changes the way how packets to local IPs are
routed. The trick is that it is done only for outgoing routes.
If applied to RS it can establish connection from RIP to VIP with
the assumption the packets are looped via crossover cable or hub.
In our case they will pass director and will come back to RS with
daddr=VIP. At least, this is the theory, only for DR method. Not
tested. The incoming connection is served as usually, the loop patch
allows it to come with saddr=RIP. One can try it after making sure
the director will not drop the packet due to rp_filter checks
if packet from RIP comes from wrong interfaces. If the interface
in director is single then there is no problem. The RS can look
in this way (VIP and RIP on different eth devices):
	</para>
	<para>
eth0: VIP (for DR the ARP problem should be solved with solutions that
work for eth devices), for traffic from director to RS (RIP->VIP)
eth1: RIP: for outgoing traffic (RIP->VIP)
	</para>
	<para>
	Such RS boxes will have loop=1 on eth0 and eth1 and should be
protected by firewall because there is a risk they to accept
unwanted UDP packet from RIP to VIP from world. Should be easy if
reverse path checks are done only in border firewall and not in
director and RSs.
	</para>
	<para>
	I'm not pushing it for inclusion as it is one big hack but
Anton Blanchard is very active in this:
	</para>
<programlisting><![CDATA[
http://marc.theaimsgroup.com/?l=linux-netdev&m=106209315512638&w=2
http://marc.theaimsgroup.com/?l=linux-netdev&m=110109969803330&w=2
]]></programlisting>
	<para>
	and once DaveM said he will review it, so he knows about it
	</para>
	<blockquote>
Ratz: What about medium_id issues? Does it work with bonding interfaces?
	</blockquote>
	<para>
	May be it should work. medium_id does not play here, loop
works just after fib_lookup and accepts packets from local source IP,
for other traffic loop=1 does not modify behaviour.
	</para>
	</section>
</section>
<section id="LVS-HOWTO.non-linux_realservers" xreflabel="non-linux-realservers">
<title>LVS: Non Linux Realservers</title>
<para>
This list of realservers is from Ratz (Joe: from about 2003).
About the only thing he hasn't tried yet is Plan 9.
Remember to set netmask=/32 for the VIP on LVS-DR and LVS-Tun
(for LVS-NAT you can setup with any netmask you like).
If you are running non-Linux unix realservers,
you can usually handle the arp problem by configuring the device
carrying the VIP with the -arp switch.
</para>
	<itemizedlist>
		<listitem>
Solaris 2.5.1, 2.6, 2.7
		</listitem>
		<listitem>
Linux (of course): 2.0.36, 2.2.9, 2.2.10, 2.2.12
		</listitem>
		<listitem>
FreeBSD 3.1, 3.2, 3.3
		</listitem>
		<listitem>
NT (although Webserver would crash): 4.0 no SP
		</listitem>
		<listitem>
IRIX 6.5 (Indigo2)
		</listitem>
		<listitem>
HPUX 11
		<note>
HPUX arps even if you tell it not to.
You'll need to handle the
<ulink url="http://www.austintek.com/LVS/LVS-HOWTO/HOWTO/LVS-HOWTO.arp_problem.html">
arp problem</ulink> some other way.
		</note>
		</listitem>
	</itemizedlist>
<para>
Ratz's code to setup non-linux realservers is now in the
<ulink url="http://www.austintek.com/LVS/LVS-HOWTO/mini-HOWTO/LVS-mini-HOWTO.html#configure_script">configure script</ulink>
(http://www.austintek.com/LVS/LVS-HOWTO/mini-HOWTO/LVS-mini-HOWTO.html#configure_script)
This part of the script has not been well tested
(you might find that it doesn't setup your non-linux
unix box properly yet, please contact me - Joe).
	<note>
(In the 3yrs the configure script has been out,
I've not heard of anyone using this part of the code,
so there seems no point in maintaining it.)
	</note>
</para>
<para>
Here's the original info from Ratz for realservers with non-Linux OS's.
On some Unixes you have to plumb the interface before assigning an IP.
The plumb instruction is not included here.
</para>
<programlisting><![CDATA[
#uname      : FreeBSD
#uname -r   : 3.2-RELEASE
#<command>  : ifconfig lo0 alias <VIP> netmask 0xffffffff -arp up
#ifconfig -a: lo0: flags=80c9<UP,LOOPBACK,RUNNING,NOARP,MULTICAST>mtu 16837
#                  inet 127.0.0.1 netmask 0xff000000
#                  inet <VIP> netmask 0xffffffff

#uname      : IRIX
#uname -r   : 6.5
#<command>  : ifconfig lo0 alias <VIP> netmask 0xffffffff -arp up
#ifconfig -a: lo0: flags=18c9<UP,LOOPBACK,RUNNING,NOARP,MULTICAST,CKSUM>
#                  inet 127.0.0.1 netmask 0xff000000
#                  inet <VIP> netmask 0xffffffff

#uname      : SunOS
#uname -r   : 5.7
#<command>  : ifconfig lo0:1 <VIP> netmask 255.255.255.255 up
#ifconfig -a: lo0:  flags=849<UP,LOOPBACK,RUNNING,MULTICAST>mtu 8232
#                   inet 127.0.0.1 netmask ff000000
#             lo0:1 flags=849<UP,LOOPBACK,RUNNING,MULTICAST>mtu 8232
#                   inet <VIP> netmask ffffffff

#uname      : HP-UX
#uname -r   : B.11.00
#<command>  : ifconfig lan1:1 10.10.10.10 netmask 0xffffff00 -arp up
#ifconfig -a: lan0:   flags=842<BROADCAST,RUNNING,MULTICAST>
#                     inet <some IP> netmask ffffff00
#             lan0:1: flags=8c2<BROADCAST,RUNNING,NOARP,MULTICAST>
#                     inet <VIP> netmask ffffff00
#
]]></programlisting>
<para>
Ratz 16 Apr 2001
</para>
<blockquote>
in most cases (when using the NOARP option)
you need alias support.
Some Unices have no support for aliased interfaces or only
limited, such as QNX, Aegis or Amoeba for example. Others
have interface flag inheritance problems like HP-UX where
it is impossible to give an aliased interface a different
flag vector as for the underlying physical interface
(as happens with Linux 2.2 and 2.4 - Joe). So
for HP/UX you need a special setup because with the standard
depicted setup for DR it will NOT work.
I've done most
Unices as Realserver and was negatively astonished by all
the different implementation variations of the different
Unix flavours. This maybe resulted from unclear statements
from the RFC's.
</blockquote>
<para>
Gregory Boehnlein
</para>
<blockquote>
I'm going to be working with a bunch of Solaris 9 boxes in the
near future, and I would like to add them to my existing LVS cluster. Does
anyone have information on what/how Solaris 9 can be used as the Real
Servers in an LVS-DR cluster? On linux, I implement the hidden-arp patch.
How is this accomplished on Solaris boxen?
</blockquote>
<para>
Roberto Nibali <emphasis>ratz (at) drugphish (dot) ch</emphasis> 11 Aug 2003
</para>
<para>
Solaris doesn't have this issue ;).
</para>
<para>
Chris Kennedy <emphasis>ckennedy (at) iland (dot) net</emphasis>
</para>
<blockquote>
	<para>
   The thing I have found out is that on Solaris 2.6, and
probably other versions of Solaris, you have to to some magic to
get the loopback alias setup.  You must run the following
commands one at a time:
	</para>
<programlisting><![CDATA[
ifconfig lo0:1 <VIP>
ifconfig lo0:1 <VIP> <VIP>
ifconfig lo0:1 netmask 255.255.255.255
ifconfig lo0:1 up
]]></programlisting>
       <para>
Which works well and is actually a pointopoint link like ppp
which must be the way Solaris defines aliases to the lo
interface. It will not let you do this all at once, just each
step at a time or you have to start over from scratch on the
interface.
	</para>
</blockquote>
<para>
Ramon Kagan <emphasis>rkagan (at) YorkU (dot) ca</emphasis> 05 Jun 2002
</para>
<blockquote>
	<para>
Just in case anybody is interested.  You can do the following on lo0:1 or
for paranoid people like me hme1.
      	</para>
<programlisting><![CDATA[
ifconfig <intfc> plumb
ifconfig <intfc> <VIP>
ifconfig <intfc> <VIP> <VIP>
ifconfig <intfc> netmask 255.255.255.255
ifconfig <intfc> up
]]></programlisting>
         <para>
This is from the FAQ but I'm adding that this doesn't have to be on lo0.
	</para>
</blockquote>
<para>
For LVS-NAT, anything with a tcpip stack can be a realserver, even a printer.
</para>
<para>
For LVS-DR, you either must hide the realserver from arp requests, 
or have it not answer arp requests. 
HPUX and Linux (kernel &gt; 2.0) are the only Unices
that don't honour the <filename>-noarp</filename> flag.
</para>
<para>
For LVS-Tun, you need a realserver that decapsulates IPIP packets.
Windows used to do this but doesn't anymore.
</para>
	<section id="windows">
	<title>Loopback interface on Windows/Microsoft/NT/W2K</title>
	<para>
Windows is <emphasis>not</emphasis> handled by the
<ulink url="http://www.austintek.com/LVS/LVS-HOWTO/mini-HOWTO/LVS-mini-HOWTO.html#configure_script">configure script</ulink>
(http://www.austintek.com/LVS/LVS-HOWTO/mini-HOWTO/LVS-mini-HOWTO.html#configure_script).
	</para>
	<para>
According to Horms you don't need anything special to handle
the ARP problem; presumably Windows honours the noarp flag.
	</para>
	<para>
Instructions for setting up windows realservers is one
of the more common questions on the mailing list.
This must be a difficult part of the HOWTO to find ;-\.
There seem to be many ways of doing it.
Here are some of the answers.
Setting the metric to 254 seems to be critical.
	</para>
	<para>
Wensong's original recipe for setting up the lo device on a NT realserver.
	</para>
	<blockquote>
		<para>
If you don't have MS Lookback Adapter Driver installed on
your NT boxes, enter Network Control Panel, click the
Adapter section, click to add a new adapter, select the
MS Loopback Adapter. Your NT cdrom is needed here.
Then add your VIP (Virtual IP) address on the MS Loopback
Adapter, do not enter a gateway address on the Loopback
Adapter. Since the netmask 255.255.255.255 is considered
invalid in M$ NT, you just accept the default netmask,
then enter MS-DOS prompt, remove the extra routing entry.
		</para>
<programlisting>
<![CDATA[
c:route delete <VIP's network> <VIP's netmask>
]]>
</programlisting>
		<para>
This will make the packets destined for this network will
go through the other network interface, not this MS Loopback
interface.
As I remember, setting its netmask to 255.0.0.0 also works.
		</para>
	</blockquote>
	<para>	
Jerome Richard <emphasis>jrichard (at) virtual-net (dot) fr</emphasis>
	</para>
	<blockquote>
On Windows NT Server, you just have to install a network adapter
called "MS Loopback" (Provided on the Windows NT CDROM in new
network section) and then you setup the VIP on this interface.
	</blockquote>
	<para>
o1004g <emphasis>o1004g (at) nbuster (dot) com</emphasis>
	</para>
	<orderedlist>
		<listitem>Click Start, point to Settings, click Control Panel,
and then double-click Add/Remove Hardware.</listitem>
		<listitem>Click Add/Troubleshoot a device, and then click Next.</listitem>
		<listitem>Click Add a new device, and then click Next.</listitem>
		<listitem>Click No, I want to select the hardware from a list, and then click Next.</listitem>
		<listitem>Click Network adapters, and then click Next.</listitem>
		<listitem>In the Manufacturers box, click Microsoft.</listitem>
		<listitem>In the Network Adapter box, click Microsoft Loopback Adapter,
and then click Next.</listitem>
		<listitem>Click Finish.</listitem>
	</orderedlist>
	<para>
<emphasis>robert.gehr (at) web2cad (dot) de</emphasis>; 24 Oct 2001
	</para>
	<blockquote>
		<para>
The MS-Loopback adapter is a virtual device
under Windows that does not answer any arp requests.
It should be on a Server Edition CD of WinNT/2000.
Install and assign it the appropriate IP Address.
Because MS would not let you assign a "x.x.x.x/32" netmask to
the MS-Loopback adapter, you will
end up having two routes pointing into the same net.
Lets say your RIP is 10.10.10.10 and your MS-Loopback VIP is
10.10.10.11. You will have two routes in your routing table both
pointing to the 10.0.0.0 net. You delete the route that is bound to the
VIP on the MS-Loopback adapter with a command like
		</para>
<programlisting> <![CDATA[
route del 10.0.0.0 mask 255.0.0.0 10.10.10.11
]]> </programlisting>
	</blockquote>
	<para>
Johan Ronkainen <emphasis>jr (at) mpoli (dot) fi</emphasis>
	</para>
	<blockquote>
True with Windows NT4. However with Win2000 you can just configure high
metric value for loopback interface. I tried this about year ago with metric
value 254 without problems.
I think you could change netmask to /32 with regedit. Haven't tried that
with WinNT4/2000 though. I've used that trick with Win98SE and it worked.
	</blockquote>
	<para>
Brent Knotts <emphasis>brent (dot) knotts (at) mylocalgov (dot) com</emphasis> 28 Jan 2003
	</para>
	<blockquote>
		<para>
Concerning Windows 2000 realservers:
		</para>
		<para>
It is possible to change the subnet mask to 255.255.255.255 in the
registry, and it works fine for my DR setup.  This is easier than
deleting the extra route to the local interface after each boot.
		</para>
		<para>
In Windows 2000, the interfaces are found in:
		</para>
		<para>
HKEY_LOCAL_MACHINE\System\CurrentControlSet\Services\Tcpip\Parameters\Interfaces
		</para>
		<para>
Find the interface with the appropriate IP address and change the subnet
mask.  Rebooting is not necessary, but you should bring the interface
down and up.
		</para>
	</blockquote>
	<para>
<emphasis role="bold">Foreign Languages for MS</emphasis>
	</para>
	<para>
Sebastien <emphasis>Sebastien.Bonnet (at) experian (dot) fg</emphasis> 12 Apr 2002
	</para>
	<blockquote>
		The &quot;MS Lookback Adapter&quot; is called
&quot;carte de bouclage&quot;
	</blockquote>
	<para>
Malcolm Turnbull
	</para>
	<blockquote>
I've set up a simple LVS DR loadbalancer with 4 IIS web servers (win2K)
behind it.
I've setup a local loopback adapter on each 2K server and set the
priority to 254.
The loadbalancer works fine...
But seems to confuse Windows Networking, SMB Network Browsing no longer
seems to work. (Required by RoboCopy).
	</blockquote>
	<para>
Martijn Klingens <emphasis>mklingens (at) ism (dot) nl</emphasis>
10 Sep 2002. Subject: Re: LVS DR setup with NT2K servers
	</para>
	<blockquote>
		<para>		
We're using an almost similar setup, just that we're currently using a simple
xcopy and want to migrate to DFS. That doesn't change the basics though.
Things that I encountered:
		</para>
		<itemizedlist>
			<listitem>
Windows always adds a route to the subnet on the loopback adapter. If that
subnet is also available on the normal LAN your routing table will get
confused. In our case we migrated sites with existing IPs to LVS so we had to
pick an entire class C subnet as mask. Solution: manually delete the route to
the /24 on the loopback interface.
			</listitem>
			<listitem>
Disabling the file and print services on the loopback interface usually
also helps.
			</listitem>
			<listitem>
Check the default gateways and the DNS on the various interfaces. If they
are not identical you may find very strange behaviour (although there are
cases where it's useful to have them differ, this is not that common).
			</listitem>
		</itemizedlist>
		<para>
Hope this helps. If not, please specify a bit more about your setup. If you
have problems on the realservers, are they able to resolve another realserver
using dns and/or ping another realserver?
		</para>
		<para>
Oh, and you mentioned network browsing, which is not entirely the same as
opening a share on a computer with a well-known name. Do you really need the
browser? We usually have the computer browser service stopped anyway so an
intruder isn't instantly able to see all other w2k hosts on the net. A bit
moot, since DNS provides the same data, but it doesn't really hurt either.
		</para>
	</blockquote>
	<para>
<emphasis>lstep (at) banquise (dot) org</emphasis> 11 Aug 2004 
	</para>
	<blockquote>
I'm trying to understand why you set the metric of the localhost interface 
to 254 
(according to the doc found on 
<ulink url="http://wiki.linuxquestions.org/wiki/LVS_with_HA_for_Win2k_Terminal_Servers">
LVS with HA for Win2k Terminal Servers</ulink>
(http://wiki.linuxquestions.org/wiki/LVS_with_HA_for_Win2k_Terminal_Servers) 
when configuring a W2K realserver's loopback in a Direct Routing mode?
If I don't do this what problem(s) will I get?
	</blockquote>
	<para>
Malcolm Turnbull <emphasis>malcolm (at) loadbalancer (dot) org</emphasis>
	</para>
	<para>
NT can be a pain in the backside when its routing table gets confused :-)
In my experience setting the metric to 254 solves 95% of issues.
	</para>
	<para>
Ratz
	</para>
	<blockquote>
I'm sorry but this doesn't really convince me. Where can I read about 
this? What does NT really do when you set such a high metric?
	</blockquote>
	<para>
Using the registry to set the mask to 255.255.255.255 does the other 5%
Seems to happen more often in NT style domains or servers with multiple 
NICs.
Any NT realserver with a problem is easy to spot as it won't work in DR 
full stop, and the routing table will be incorrect.
	</para>
	<para>
Malcolm Turnbull <emphasis>malcolm (at) loadbalancer (dot) org</emphasis> 2005/04/15
	</para>
	<para>
We have a small .net based tool to setup
the loopback adpater for DR mode on windows 2000/2003 web servers.
The idea was to install the loopback and setup as many VIPs as required 
and then set the netmask to 255.255.255.255. 
But from testing we've found that windows will
sometimes stop responding to the load balancers RIP (for health checks), 
whereas if you use a netmask
of 255.0.0.0 Windows ignores this route because it looks for the 
smallest subnet in the routing table first <emphasis>i.e.</emphasis> 
you 255.255.255.0 (or whaterver your using for your RIP.)
	</para>
	<para>
The small utility requires the .net framework 1.1.
When you start iti, 
click on the red warning 'no adapter found' to install the loopback
Then add as many VIPs as you want and click save.
Slightly pointless for anyone who knows what they are doing, but someone 
may find it usefull.
	</para>
	<para>
You can 
<ulink url="http://www.loadbalancer.org/download/nt/">
download binary and source</ulink>
(http://www.loadbalancer.org/download/nt/).
NB. The one marked BETA will set the netmask to 255.255.255.255 (if 
thats what you want).
	</para>
	<para>
Graeme Fowler <emphasis>graeme (at) graemef (dot) net</emphasis> 06/11/2005
	</para>
	<para>
Adding a WIN NT machine to LVS setup:
If you go to "add new hardware" and "select from list", you should find
it listed under Network Adapters - Microsoft.
	</para>
	<para>
Install the "Microsoft Loopback Adapter" network device, and assign it
the relevant address(es). IIRC that it doesn't ARP at all, and I've used
it in production for a number of SLB setups - not behind LVS though,
these were Cisco IOS or ExtremeWare setups, either using NAT or DR.
	</para>
	<para>
Stuart walmsley wrote: 2007-05-16 
	</para>
	<para>
The fact that all the real servers are Windows based and will not take a
255.255.255.255 mask on the loopback stops this from working.
	</para>
	<para>
Graeme Fowler <emphasis>graeme (at) graemef (dot) net</emphasis>16 May 2007 
	</para>
	<para>
No it doesn't - set the realserver loopback interface address as per
normal, then edit the registry to change them from 255.255.255.0 to
255.255.255.255.
Unfortunately I forget exactly where the key is buried, but I suspect it
will be somewhere within:
	</para>
<programlisting><![CDATA[
HKLM\SYSTEM\CurrentControlSet\Tcpip\Parameters\Interfaces\{SID_VALUE}
]]></programlisting>
	<para>
An alternative is to set the netmask to 255.0.0.0, since a more specific
route for the local net will already exist and will be favoured over it;
this can however cause unexpected problems for inter-real-server
communication.
	</para>
	<para>
Graeme Fowler <emphasis>graeme (at) graemef (dot) net</emphasis> 16 May 2007 
	</para>
	<note>
when connecting from Windows LVS-NAT realservers to the VIP on the director using
http://www.austintek.com/LVS/LVS-HOWTO/HOWTO/LVS-HOWTO.LVS-NAT.html#clients_on_LVS-NAT_realserver_contacting_services_on_VIP
the realservers need a /32 netmask.
	</note>
	<para>
set the realserver loopback interface address as per
normal, then edit the registry to change them from 255.255.255.0 to
255.255.255.255.
Unfortunately I forget exactly where the key is buried, but I suspect it
will be somewhere within:
	</para>
<programlisting><![CDATA[
HKLM\SYSTEM\CurrentControlSet\Tcpip\Parameters\Interfaces\{SID_VALUE}
]]></programlisting>
	<para>
An alternative is to set the netmask to 255.0.0.0, since a more specific
route for the local net will already exist and will be favoured over it;
this can however cause unexpected problems for inter-real-server
communication.
	</para>
	</section>
	<section id="winserver_2008">
	<title>Windows Server 2008</title>
	<para>
Malcolm has figured this out
<ulink url="http://www.loadbalancer.org/blog/direct-server-return-on-windows-2008-using-loopback-adpter/">
Direct Server Return on Windows 2008 using loopback adapter</ulink>
(http://www.loadbalancer.org/blog/direct-server-return-on-windows-2008-using-loopback-adpter/)
	</para>
	<para>
Malcolm found you can't handle it by adding a 2nd NIC 
(as you could in the early days of Linux) 
as windows disables the NIC if there's no link.
	</para>
	</section>
	<section id="MacOS_X">
	<title>Mac OS X (and Solaris)</title>
	<para>
Malcolm Turnbull
	</para>
	<blockquote>
Has anyone used Mac OS X for a real server in LVS/DR ?
	</blockquote>
	<para>
Jerome RICHARD <emphasis>jrichard (at) virtual-net (dot) fr</emphasis> 20 Nov 2002
	</para>
	<para>
If you wish to configure multiple IP on Mac OS X, you should use the
following command :
	</para>
<programlisting> <![CDATA[
sudo ifconfig lo0 alias 10.0.0.80 netmask 255.255.0.0
]]> </programlisting>
	<para>
There is more information in the
<ulink url="http://docs.info.apple.com/article.html?artnum=106418">
AppleCare Documents</ulink>
	</para>
	<para>
Roberto Nibali <emphasis>ratz (at) drugphish (dot) ch</emphasis> 20 Nov 2002
	</para>
	<para>
Yes, I gave a presentation about a year ago and I remember that one of
the attendees had a new shiny G4 with Mac OS X. It worked flawlessly.
	</para>
	<blockquote>
Is it OK to use the loopback interface ?
	</blockquote>
	<para>
You can but you don't have to.
OS X is BSDish, so you need to use BSDish syntax:
	</para>
<programlisting> <![CDATA[
ifconfig lo0 alias VIP netmask 255.255.255.255 -arp up
]]> </programlisting>
	<para>
Malcolm Turnbull <emphasis>Malcolm.Turnbull (at) crocus (dot) co (dot) uk</emphasis> 22 Nov 2002
	</para>
	<blockquote>
		<para>
Got it working:
		</para>
		<itemizedlist>
			<listitem>
		Solaris:

<programlisting> <![CDATA[
ifconfig lo0:1 plumb
ifconfig lo0:1 <vip-addr> netmask 255.255.255.255 up
]]> </programlisting>
			</listitem>
			<listitem>
Mac OS X:
<programlisting> <![CDATA[
ifconfig lo0 alias VIP netmask 255.255.255.255 -arp up
]]> </programlisting>
			</listitem>
		</itemizedlist>
	</blockquote>
	</section>
	<section id="windows_domain">
	<title>Windows servers in Active Directory Domain</title>
	<note>
Joe: I'm not a windows guy, so I don't understand this. 
I've just spliced it out of the ml as best as I can.
Please send corrections.
	</note>
	<para>
David Dyer-Bennet <emphasis>dd-b (at) dd-b (dot) net</emphasis> 10 Oct 2008
	</para>
	<blockquote>
		<para>
We're running into a problem with windows boxes being on a private LAN
inside the LVS; they can't join the domain (apparently Active Directory
has to be able to initiate connections to the system), and now that's
starting to interfere with their deployment of what they call "tcp"
protocol since it authenticates service users (obviously they're not
talking about the real tcp proptocol; Microsoft must be working *really*
hard to obfucate things in this area!).
		</para>
		<para>
I'm not a Windows guy, but according to our Windows IT team, a computer
can't be part of a windows domain unless the domain controller can
initiate a connection to it.  So these hidden servers can't be in our
corporate domain.  It's not an issue with additional services, it's the
base domain membership.
		</para>
	</blockquote>
	<para>
Malcolm Turnbull <emphasis>malcolm (at) loadbalancer (dot) org</emphasis> 10 Oct 2008 
	</para>
	<para>
Normally you wouldn't want load balanced servers to be in an active directory domain...
but if it is a requirement then either use:
Direct Routing (but make sure DNS is set to manual in both active
directory and on the real servers) otherwise active directory stupidly
registers the loopback adpater address :-0.
	</para>
	<para>
Or you can try single network NAT and make sure that:
	</para>
	<note>
Joe: for more details see <xref linkend="one_network"/>
	</note>
	<para>
On the load balancer:
In order for one arm NAT to work correctly you must modify the
firewall script on the load
balancers to disable ICMP redirects:
	</para>
<programlisting><![CDATA[
# For single NIC NAT you will also need to disable re-directs
# director is gw for realservers so turn OFF icmp redirects (1 on, 0 off)
echo "0" >/proc/sys/net/ipv4/conf/all/send_redirects
echo "0" >/proc/sys/net/ipv4/conf/default/send_redirects
echo "0" >/proc/sys/net/ipv4/conf/eth0/send_redirects
echo "0" >/proc/sys/net/ipv4/conf/eth1/send_redirects
echo "0" >/proc/sys/net/ipv4/conf/eth2/send_redirects
]]></programlisting>
	<para>
Make sure that these lines are active by removing the # at the start
of each echo command.
	</para>
	<para>
Then configure the routing on the windows real servers:
	</para>
	<para>
Route configuration for Windows Server with one arm NAT mode
When a client on the same subnet as the real server tries to access
the virtual server on the load balancer
the request will fail. The real server will try to use the local
network to get back to the client rather than
going through the load balancer and getting the correct network
translation for the connection.
To rectify this issue we need to add a route to the the load balancer
that takes priority over Windows default
routing rules.
This is a simple case of adding a permanent route:
route add -p 192.168.1.0 mask 255.255.255.0 metric 1
NB. Replace 192.168.1.0 with your local subnet address.
The default route to the local network has a metric of 10, so this new
route overrides all local traffic and
forces it to go through the load balancer as required.
Any local traffic (same subnet) is handled by this route and any
external traffic is handled by the default
route (which also points at the load balancer).
	</para>
	<para>
I'm not sure what happens if the active directory is on a routed
network, but I think it will still work.
Please let me know.
	</para>
	<para>
Graeme 10 Oct 2008
	</para>
	<para>
Hrm... it depends on the management tools you're using as to whether
other domain member servers need to reach the realservers you're talking
about. I certainly haven't ever come across a situation where the domain
controllers initiate connections to member servers without being asked
to (like someone running a computer management application to control a
service on the realservers).
	</para>
	<para>
If this were me, I'd put a domain controller into the "private" LAN
which has firewall holes to the main AD domain controllers. That way
firewall restrictions should force the local systems use the local DC
(or DCs, for better resilience) which can then do all the fancy AD
replication back to the other DCs.
	</para>
	<para>
Not ideal, but it *might* work.
	</para>
	<para>
David Dyer-Bennet <emphasis>dd-b (at) dd-b (dot) net</emphasis>
	</para>
	<blockquote>
		<para>
The benefits I saw initially for load balancing windows boxes in an active directory domain are:
		</para>
		<itemizedlist>
			<listitem>
The people maintaining it can use their normal windows logons, meaning
I don't have to maintain a parallel set of accounts, and the Windows
software people don't have to remember yet more passwords.
			</listitem>
			<listitem>
Access to these systems can be controlled through the normal windows
active directory mechanisms.
			</listitem>
		</itemizedlist>
		<para>
In addition to that, apparently when users are connecting from in-house
applications on Windows boxes, it's easy for the windows people to extend
authentication through the Web Service connect to supply authentication
for the database and information services being accessed by the request. 
Or so they say.  I hadn't thought that would be an issue, and it may not
be in the end still.
		</para>
		<para>
My desktop system is part of the corporate domain.  So are the desktops of
the people doing Windows development.  Why would making a server part of
the domain be any more dangerous than that?  And that's standard anywhere
that does Windows development.
		</para>
	</blockquote>
	<para>
Graeme
	</para>
	<para>
You're personally fairly unlikely to run code as a system account,
especially when developing - you're more likely to run it as yourself.
Of course, many developers and sysadmins make themselves admins on their
own machines (makes installing software just *so* much more convenient
than doing "runas") so the security arguments in those cases are
slightly damaged anyway :)
	</para>
	<para>
Allowing arbitrary code (think of the mass of .NET examples out there)
to be executed under the IIS framework is a dangerous game, especially
(as is often the case) when it's being executed by a user with elevated
privileges (like the Network Service user which IIRC is the default user
for IIS code execution).
	</para>
	<para>
This is, of course, a massive Catch-22 for hosting operations, and is
the reason why app pools came along in IIS6 which allowed almost
complete segregation of execution environments which themselves ran as
non-privileged users. Much tidier than it used to be.
	</para>
	<para>
In your environment you might not be exposing the web servers to that
nasty Intertubes thingmy, which makes security all the easier to manage.
	</para>
	</section>
</section>
<section id="LVS-HOWTO.authd" xreflabel="authd/identd">
<title>LVS: identd/authd</title>
	<section id="authd_lvs" xreflabel="authd/identd">
	<title>What is authd/identd?</title>
	<note>
		<para>
Jun 2002: authd clients are invoked on the realserver by services
running under tcpwrappers and connect to a machine on the internet, in this case
the client, before the service can complete the request. Initially we thought
this was a problem unique to authd. However, we now see it as an example
of an often occuring situation.
See the <xref linkend="3-Tier_lvs"/> section for more details.)
		</para>
		<para>
If initial connection to your service (telnet, ftp, sendmail...) is delayed
by 10secs..5mins, but after you connect everything is fine, then you have
problems with identd.
		</para>
		<para>
You can avoid reading this section by turning off identd on your realservers.
		</para>
	</note>
	<para>
identd is a demon run under inetd.
Other services running on the server can use identd to ask the client
machine for the identity of the user making the request.
When a request arrives at a server for such a service (<emphasis>e.g.</emphasis> telnet, sendmail),
the auth client will connect from a high port to client:auth asking
"who is the owner of the process requesting this service".
If the client's authd replies with a <emphasis>username@nodename</emphasis>, the reply
will be optionally logged on the server (eg to syslog) and the
connection request will be handed back to telnetd (or whichever service).
If the reply is "<emphasis>root@nodename</emphasis>", or some null reply, or there is
no authd on the client, then the server's authd will wait till
a timeout before allowing connection. The delay is about 10secs for
Slackware and 2mins for RedHat7.0. There is no checking of the
validity of the reply and since the reply is under control of
the client machine, the reply <emphasis>username@nodename</emphasis> could be bogus.
	</para>
	<para>
The authd is a security feature. However it doesn't get the
server very much (you don't know who has made the connect request,
only what they told you), while clients that fail are delayed. This
may only be a nuisance for people telnet'ing in (provided they understand
what's happening), but will bring mail delivery to a crawl.
	</para>
	<para>
If you setup an LVS with realservers that have services running inside
identd, you will have to deal with identd.
Any service in inetd running under tcpwrappers
(probably just about every service, if tcpwrappers is installed)
and sendmail (see section on sendmail) use it.
	</para>
	<para>
Since problems with identd affect many aspects of an LVS, there are
references to identd in several places in this document.
	</para>
	</section>
	<section id="3-tier_clients">
	<title>authd/identd and other 3-Tier clients</title>
	<para>
A lot of time and effort was put into figuring out how to
handle <xref linkend="LVS-HOWTO.authd"/>
clients running on the realservers.
The best solution we came up with was to turn off authd on the realservers.
At the time the authd problem appeared to be a one-off problem and we dismissed
it as just one-of-those-things.
Later we realised that other demons running
on the realservers invoke client processes, <emphasis>e.g.</emphasis> <link linkend="rshd">rshd</link>,
<link linkend="passive_ftp">passive ftp</link>.
Still we didn't see the whole picture.
It now turns out that there is a
general class of services (demons)
running on the realservers which invoke client processes
as part of constructing a reply to the client.
These demons require you to run the LVS as a 3-Tier LVS.
If you allow packets from the RIP to be routable,
then it's easy for the client to connect to 0/0.
The problem before was that we did not allow
the RIP to be routable.
	</para>
	</section>
	<section id="identd_symptoms">
	<title>symptoms of the identd problem</title>
	<para>
There are two parts to identd on your realservers
	</para>
	<itemizedlist>
		<listitem>
		<para>
Identd runs on your realservers.
This isn't a problem for LVS.
Identd on the realservers is for clients on your realservers
connecting to services on remote machines.
These clients will be connecting from the RIP and not the VIP.
You aren't using this identd when setting up an LVS.
However if you telnet from your realservers for some other reason,
you'll need to think about what this identd is doing.
		</para>
		</listitem>
		<listitem>
		<para>
your LVS'ed services <emphasis>may</emphasis>
(<emphasis>e.g.</emphasis> sendmail
or services running inside tcpwrappers),
ask the identd client on your
server to connect to the identd on the client machine
and ask for the identity of the person
connecting to the service on the realserver.
You don't want this.
In general there is no way in an LVS, for the reply from the client
to return to the realserver.
		</para>
		</listitem>
	</itemizedlist>
	<para>
The problem is in the second part, <emphasis>i.e.</emphasis> if the LVS'ed service
on the realserver asks for the ident client to connect to the identd
on the client. (If this is confusing, remember machines can be clients
and servers at the same time.)
	</para>
	<para>
Here's a example telnet connection through a director to a realserver where
telnetd is running inside tcpwrappers.
tcpwrappers uses the ident client on the remote host (the
one with the telnetd) to connect to
the identd on the local (telnet client) host.
	</para>
<programlisting><![CDATA[
client:/director/usr/src/arch# telnet lvs2
Trying 192.168.2.110...
Connected to lvs2.mack.net.
Escape character is '^]'.

(delay)
Welcome to Linux 2.2.19.


RS2 login:
(successful login)
]]></programlisting>
	</section>
	<section id="identd_faq">
	<title>comp.os.linux.security FAQ on identd</title>
	<para>
<programlisting><![CDATA[
comp.os.linux.security FAQ
Daniel Swan <emphasis>swan_daniel (at) hotmail (dot) com</emphasis>
v0.1 - Last updated:  April 20, 2000
]]></programlisting>
			</para><para>
4.5)  What is Identd?  Can I disable it?
			</para><para>
Identd identifies the username of a process owning a specific TCP/IP connection.
It is usually run via inetd and listens on port 113.
Identd should not be used as a method of authentication -
anyone with root access can alter their identd response.
Indeed, on many systems (such as FreeBSD and Windows)
even a non-privledged user can specify whatever identd response they want.
The protocol is most useful on multiuser systems
as a method of tracking down problem users.
If one of your users is causing problems on another system,
that system's admin can inform you of the username of
the specific user causing problems, saving you a lot of legwork.
Should you run identd? That's really a judgement call.
On systems with many users, the benefits could be great,
but it doesn't serve any particular purpose on a single user box.
Not running identd may limit your ability to connect to certain servers -
many IRC and some FTP servers don't allow, or severly restrict,
non-identd'd connections, for example.
However, running it means leaving a service open to the outside world,
with all the security risks that entails.
Another thing to consider is that identd can allow
attackers to find out valuable information about your system,
such as whether a certain service is running as root,
the operating system you are running,
and the usernames of your users.
Consider running identd with the -n flag,
which sends userid numbers instead of usernames.
See the identd manpage and /etc/identd.conf for more
information about the available options.
You can block access to identd by shutting it off entirely
(usually done via inetd, see section on disabling services),
or by using tcpwrappers and/or firewalling software to disable/restrict access.
If you need identd enabled in order to connect to a certain server,
you might want to consider allowing access to it only from that server.
If you do choose to firewall the identd port,
strongly consider using a reject policy rather than deny.
Using deny may greatly increase the time it takes
you to connect to servers that utilize identd,
as they will wait for a response of some type before allowing you to connect.
	</para>
	</section>
	<section id="Rus_Nelson_on_identd">
	<title>Russ Nelson on identd</title>
	<para>
Russ Nelson (he
<ulink url="http://russnelson.com/bio.html">
wrote the Clarkson packet drivers for DOS</ulink>,
he was the 1980's version of Donald Becker)
says that
<ulink url="http://russnelson.com/ident.html">
the only possible role for identd is to keep track of client activity at the client end</ulink>.
He says that your firewall should reject, not drop identd requests.
	</para>
	<para>
Russ also has a some links to sites that don't allow links from other sites.
When you go to his site, please click on those links.
	</para>
	</section>
	<section id="identd_why_problem">
	<title>Why identd is a problem for LVS</title>
	<para>
The problem is that the identd/authd client makes a callback from the
RIP (for LVS-NAT) or the VIP (LVS-DR, LVS-Tun)
and LVS doesn't handle clients on realservers.
For the simple case where clients call from the RIP on NAT'ed realserver
see the section on
<link linkend="client_on_realserver">running clients on realservers</link>.
There the client is independant of the LVS.
			</para><para>
The case of clients on the realservers making call backs
triggered by an LVS client's requests to an LVS'ed service is
more difficult as the result has to get back to the LVS'ed service.
			</para><para>
Normally in an LVS,
the director in an LVS responds to connect requests by handing
them to an arbitrary realserver.
The corrollary of this is that replies to a client
request initiated on a realserver, to the outside world,
will not return to the realserver unless something is done to handle it.
(The only solutions we have are those in the section on
<link linkend="client_on_realserver">running clients on realservers</link>.)
			</para><para>
<itemizedlist>
<listitem><para>replies from the client which is connecting to the LVS,
arriving at the director are not connect requests,
and will not belong to an established connection.
They will be dropped.
</para></listitem><listitem><para>even if the director could forward these replies to a realserver,
they could go to any realserver, and not neccessarily to the realserver
which originated the request.
</para></listitem></itemizedlist>
			</para><para>
The result is that the client request will hang or timeout.
	</para>
	</section>
	<section id="identd_delay_tcpdump">
	<title>tcpdumps of connections delayed by identd</title>
	<para>
Here's the tcpdump of the client telnet'ing to a LVS-DR LVS.
Telnet on the realserver is running inside tcpwrappers,
client and realservers cannot connect directly
<emphasis>i.e.</emphasis> they have no routing to each other.
			</para><para>
seen from client:
			</para><para>
<programlisting><![CDATA[
telnet connect request

12:56:05.427252 client2.1038 > lvs.telnet: S 1170880662:1170880662(0) win 32120 <mss 1460,sackOK,timestamp 6539901[|tcp]> (DF) [tos 0x10]
12:56:05.427949 client2.1038 > lvs.telnet: . ack 416490630 win 32120 <nop,nop,timestamp 6539901 161874539> (DF) [tos 0x10]
12:56:05.431752 client2.1038 > lvs.telnet: P 0:27(27) ack 1 win 32120 <nop,nop,timestamp 6539902 161874539> (DF) [tos 0x10]

client replying to realserver's auth request

12:56:05.465152 client2.auth > lvs.1377: S 1159930752:1159930752(0) ack 417813448 win 32120 <mss 1460,sackOK,timestamp 6539905[|tcp]> (DF)
12:56:05.465405 lvs.1377 > client2.auth: R 417813448:417813448(0) win 0
12:56:08.464671 client2.auth > lvs.1377: S 1162930275:1162930275(0) ack 417813448 win 32120 <mss 1460,sackOK,timestamp 6540205[|tcp]> (DF)
12:56:08.464901 lvs.1377 > client2.auth: R 417813448:417813448(0) win 0

6 second delay then trying again

12:56:14.466048 client2.auth > lvs.1377: S 1168931649:1168931649(0) ack 417813448 win 32120 <mss 1460,sackOK,timestamp 6540805[|tcp]> (DF)
12:56:14.466275 lvs.1377 > client2.auth: R 417813448:417813448(0) win 0

client login to LVS

12:56:15.501272 client2.1038 > lvs.telnet: . ack 13 win 32120 <nop,nop,timestamp 6540908 161875546> (DF) [tos 0x10]
12:56:15.503946 client2.1038 > lvs.telnet: P 27:125(98) ack 52 win 32120 <nop,nop,timestamp 6540909 161875546> (DF) [tos 0x10]
12:56:15.509024 client2.1038 > lvs.telnet: P 125:128(3) ack 55 win 32120 <nop,nop,timestamp 6540909 161875547> (DF) [tos 0x10]
12:56:15.538816 client2.1038 > lvs.telnet: P 128:131(3) ack 88 win 32120 <nop,nop,timestamp 6540912 161875550> (DF) [tos 0x10]
12:56:15.551836 client2.1038 > lvs.telnet: . ack 90 win 32120 <nop,nop,timestamp 6540914 161875550> (DF) [tos 0x10]
12:56:15.571837 client2.1038 > lvs.telnet: . ack 106 win 32120 <nop,nop,timestamp 6540916 161875551> (DF) [tos 0x10]
]]></programlisting>
			</para><para>
Here's what it looks like on the realserver
(this is a different connection from the above sample, so the times are not the same).
			</para><para>
<programlisting><![CDATA[
realserver receives telnet request on VIP
12:50:58.049909 client2.1040 > lvs.telnet: S 1605709966:1605709966(0) win 32120 <mss 1460,sackOK,timestamp 6580274[|tcp]> (DF) [tos 0x10]
12:50:58.051263 lvs.telnet > client2.1040: S 862075007:862075007(0) ack 1605709967 win 32120 <mss 1460,sackOK,timestamp 161914907[|tcp]> (DF)
12:50:58.051661 client2.1040 > lvs.telnet: . ack 1 win 32120 <nop,nop,timestamp 6580274 161914907> (DF) [tos 0x10]
12:50:58.052819 client2.1040 > lvs.telnet: P 1:28(27) ack 1 win 32120 <nop,nop,timestamp 6580274 161914907> (DF) [tos 0x10]
12:50:58.053036 lvs.telnet > client2.1040: . ack 28 win 32120 <nop,nop,timestamp 161914907 6580274> (DF)

realserver initiates auth request from VIP to client:auth

12:50:58.088510 lvs.1379 > client2.auth: S 852509908:852509908(0) win 32120 <mss 1460,sackOK,timestamp 161914911[|tcp]> (DF)
12:51:01.083659 lvs.1379 > client2.auth: S 852509908:852509908(0) win 32120 <mss 1460,sackOK,timestamp 161915211[|tcp]> (DF)

realserver waits for timeout (about 8secs), sends final request to client:auth

12:51:07.083164 lvs.1379 > client2.auth: S 852509908:852509908(0) win 32120 <mss 1460,sackOK,timestamp 161915811[|tcp]> (DF)

telnet replies from realserver continue, login occurs

12:51:08.117727 lvs.telnet > client2.1040: P 1:13(12) ack 28 win 32120 <nop,nop,timestamp 161915914 6580274> (DF)
12:51:08.118142 client2.1040 > lvs.telnet: . ack 13 win 32120 <nop,nop,timestamp 6581281 161915914> (DF) [tos 0x10]
]]></programlisting>
	</para>
	</section>
	<section id="identd_solutions">
	<title>There are solutions to identd problem in some cases</title>
		<section id="identd_lvs_nat">
		<title>Director is LVS-NAT</title>
		<para>
In an LVS, authd on the realserver will be able to connect to the client if -
			</para><para>
LVS-NAT, the realservers are on public IPs (not likely, since you usually
hide the realservers from public view and they'll be on 192.168.x.x or
10.x.x.x networks)
			</para><para>
LVS-NAT, and high ports are nat'ed out with a command like
			</para><para>
<programlisting><![CDATA[
director:/etc/lvs# ipchains -A forward -j MASQ -s 192.168.1.0/24 -d 0.0.0.0/0
]]></programlisting>
			</para><para>
You usually don't want to blanket masquerade all ports. You really
only want to masquerade ports that are being LVS'ed (so you can still
get to the other services) in which case, for each service being
LVS'ed, you to use ipchains rules like
			</para><para>
<programlisting><![CDATA[
director:# ipchains -A forward -p tcp -j MASQ -s realserver1 telnet -d 0.0.0.0/0
]]></programlisting>
			</para><para>
Since the auth client (on your telnet server) is connecting from a high port
on the server, a better ipchains rule which will allow auth to work when the
realservers are on private IPs.
			</para><para>
<programlisting><![CDATA[
director:# ipchains -A forward -p tcp -j MASQ -s realserver1 1024:65535 -d 0.0.0.0/0
]]></programlisting>
		</para>
		</section>
		<section id="identd_lvs_dr">
		<title>LVS-DR, LVS-Tun, 2.2.x kernel directors</title>
		<para>
There is no solution for LVS-DR for 2.2.x directors.
The auth client on the realserver initiates the connection from the VIP.
There is no way for a packet from VIP:high port to get a
reply through the LVS because
		</para>
		<para>
<itemizedlist>
<listitem><para>
the incoming packet from the client on the internet is destined for a non-LVS'ed high port
			</para><para>
</para></listitem><listitem><para>
the incoming packet is not a connect request.
			</para><para>
</para></listitem><listitem><para>
the incoming packet is not associated with an established connection.
</para></listitem></itemizedlist>
			</para><para>
The reply from the LVS client will be dropped.
		</para>
		</section>
		<section id="identd_lvs_dr_2.4">
		<title>LVS-DR, LVS-Tun, 2.4.x kernel directors</title>
		<para>
Transparent proxy in 2.4 is different to 2.2
(see section on <link linkend="identd_with_2.4_TP">identd with 2.4 TP</link>).
You should be able to
<link linkend="identd_with_TP_realservers">
masquerade the identd client's request on the realserver</link>.
		</para>
		</section>
	</section>
	<section id="identd_turn_off_tcpwrappers">
	<title>Turn off tcpwrappers</title>
	<para>
One cure is to turn off tcpwrappers.
inetd.conf will have a line like
<programlisting><![CDATA[
telnet stream tcp nowait root /usr/sbin/tcpd in.telnetd
]]></programlisting>
change this to
<programlisting><![CDATA[
telnet stream tcp nowait root /usr/sbin/in.telnetd in.telnetd
]]></programlisting>
and re-HUP inetd.
	</para>
	</section>
	<section id="identd_iptables">
	<title>using iptables to handle identd</title>
	<para>
Graeme Fowler <emphasis>graeme (at) graemef (dot) net</emphasis> 19 Dec 2008
	</para>
	<para>
Make sure you REJECT rather than DROP ident lookups on the director, or
even better configure the realservers to REJECT them in the OUTPUT chain
on the outgoing interface.
If they get DROPped, then the calling process will exhibit the exact
hangup you're seeing. This is very, very common in SMTP systems using
ident lookups with badly configured firewalls.
	</para>
	<para>
David Merhar <emphasis>merhar (at) arlut (dot) utexas (dot) edu</emphasis> 19 Dec 2008
	</para>
	<para>
Nice.  This about does the trick on the realservers:
	</para>
<programlisting><![CDATA[
iptables - A OUTPUT -p tcp --dport 113 -j REJECT
]]></programlisting>
	<para>
This reduces the wait to 3 seconds as  
opposed to 30 seconds. However it also increases the delay of connecting 
to the RIP from 0 to 3 seconds.
	</para>
	</section>
	<section id="identd_and_sendmail">
	<title>Identd and smtp/pop/qmail</title>
	<para>
(This is from the early days of the mailing list when the problem first
came up)
			</para><para>
Problem: In the case of identd, the smtpd on a realserver says to
identd "give me the name of the owner of the process on IP:port
that is asking me to accept mail". If identd thinks it is running
on the RIP rather than the VIP and, as is most likely, RIP is not
routable from the outside world, mail on the realserver will
hang. If identd is running on the VIP, then replies will probably
return to another realserver and mail will still hang.
			</para><para>
The converse case, of sending mail from the LVS, has the smtp
server out in internetland asking the LVS for the name of the
owner of the process running on the VIP sending him mail.  If
identd is clustered, then the request will in all probability go
to another realserver. This seems equally intractable at the
moment.
			</para><para>
Originally the problem was raised by
<programlisting><![CDATA[
Chris Kennedy <emphasis>ckennedy (at) iland (dot) net</emphasis>
Subject: SMTP, POP3 using Qmail and Ident, also using Solaris as realservers
]]></programlisting>
			</para><para>
    I have setup a virtual server using the Linux 2.2 patch and 3
Sun Ultras as the actual servers. It has crashed twice, though
possibly from running bind on the Virtual Server, since it was
right when I started it up (bind) that the virtual server would
crash.
			</para><para>
    The major problem I am having is a timeout for Ident requests
on POP3 and SMTP ports which seem to be confused. When looking at
the problem with tcpdump on the virtual server and the real
servers the vserver seems to do the following:
			</para><para>
<programlisting><![CDATA[
13:41:48.635985 10.0.0.1.4658 > vserver.net.smtp: . ack 2764990963 win 8760
13:41:48.636030 10.0.0.1.4658 > vserver.net.smtp: . ack 1 win 8760
13:41:48.658875 10.0.0.1.auth > vserver.net.48981: R 0:0(0) ack 2765099549
win 0  <<<<<<
13:41:52.143790 10.0.0.1.auth > vserver.net.48981: R 0:0(0) ack 1 win 0
<<<<<<
13:41:58.144210 10.0.0.1.auth > vserver.net.48981: R 0:0(0) ack 1 win 0
<<<<<<
]]></programlisting>
			</para><para>
The Ident, or auth port on the client machine trying to connect
back to the vserver is where it will pause for about 10-15
seconds then connect just fine. I believe this may be qmail
specific since a server funning sendmail will not have this
problem and ident seems to be used by qmail more than it or
something.
			</para><para>
No-one answered, then months later...
<blockquote><para>
Ted
			</para><para>
I currently have HTTP loadbalanced just fine with the LinuxDirector.
I've setup SMTP in the same fashion, and I don't have as much luck.
</para></blockquote>
			</para><para>
Lars
			</para><para>
Check if your system (tcpwrapper or sendmail) is doing a NS
lookup before accepting the connection or trying to connect to
ident.
			</para><para>
<programlisting><![CDATA[
Chris Kennedy <emphasis>ckennedy (at) iland (dot) net</emphasis>
Subject: Re: SMTP -- very slow connection
]]></programlisting>
			</para><para>
I had the same problem with the Direct Routing and SMTP and POP3.
It looked like a problem with the Ident lookup to the server by
the client, it was what always was occurring during that time out
period.  I saw this while doing tcpdumps on the virtual server
where the client would just keep asking for Ident lookups to the
Virtual IP address which are from the client port 113 to a random
port above 1023 on the virtual server.  I can see how this is
tricky with the direct routing method since this traffic should
be sent on to the realserver but is not.  I sort of gave up on
Direct Routing for now since this looks pretty hard to fix if it
really is Ident and the client requirements getting in the way.
			</para><para>
<blockquote><para>
Ted
			</para><para>
 I'm connecting directly to the IP. But just to be sure, I'll add an entry to
 the nameserver for that particular IP -- in both forward and reverse
 lookups...........done.....
			</para><para>
 And it still does the same thing. :(
			</para><para>
 Understand that the thirty seconds are *AFTER* the connection... Telnet
 connects, gives me the escape character, and sits. If it was a nameservice
 thing, I'd imagine it'd sit before it connected.
 I'd actually be happier if it wasn't connecting. :) Then I'd know there
 was definitely something I needed to fix between me and the real machine.
 But when it connects and THEN has trouble... I'm lost. :(
</para></blockquote>
			</para><para>
Michael Baird <emphasis>mike (at) tc3net (dot) com</emphasis>
			</para><para>
 Sound's like an issue with ident lookup's, you probably aren't
 clustering IDENT, you can 1) cluster identd, or edit your sendmail.cf
 file and set the value
<programlisting><![CDATA[
0 Timeout.ident=0
]]></programlisting>
			</para><para>
<blockquote><para>
Ted
			</para><para>
Great idea. That was it. I turned off ident in sendmail and
things worked fine.
However, I don't want to turn of ident in sendmail, and I figure
other things might want ident too... so I want to cluster ident.
Clustering ident didn't help. I clustered tcp port 113 to both
servers. (I even tried "loadbalancing" 25 and 113 just to ONE
server -- that way it'd always hit the same server)... And that
didn't work. I got the same results -- telnet to port 25...
connect... thirty seconds... and then sendmail would enter
command mode.
			</para><para>
Any ideas? Do I have to loadbalance anything else besides tcp 113
for identd to work?
			</para><para>
Why is identd run with smtp (any other reason other than
wanting to know who is sending me the mail?)
Do you have to turn identd off in smtp to get LVS smtp to work?
Has anyone LVS'ed identd? (I'd imagine you wouldnt
neccessarily get the ident from the same machine running the process for
which you want the ident)
</para></blockquote>
	</para>
	</section>
</section>
<section id="LVS-HOWTO.one_box_lvs" xreflabel="one box lvs">
	<title>LVS: Variants on LVS: Local Nodes (One Box LVS)</title>
	<note>
		<para>
<emphasis role="bold">LVS Variants:</emphasis>
LVS was originally based on the masquerading code of Linux-2.0. 
The director had the VIP, to let the router know 
where to send packets for the virtual server. 
There was no port for the service listening on the director's
VIP, so <filename>ip_vs()</filename> forced acceptance of the
packet by hooking into LOCAL_IN.
The design of <filename>ip_vs()</filename> of
		</para>
	<itemizedlist>
		<listitem>
VIP
		</listitem>
		<listitem>
hook in LOCAL_IN
		</listitem>
	</itemizedlist>
		<para>
are historical rather than a technical restriction. 
If other clues can be given to the router, to route packets,
then the VIP is not needed on the director.
Current thinking is that <filename>ip_vs()</filename>
should be moved to the FORWARD chain to allow the
director to function more like a router.
		</para>
		<para>
This (and the following) section(s) show attempts at
alternate designs for LVS, <emphasis>e.g.</emphasis> to move
<filename>ip_vs()</filename> out of LOCAL_IN.
		</para>
	</note>
	<note>
This is <emphasis role="bold">NOT</emphasis> LocalNode. 
It's experimental code from Horms to allow running realservers on the director. 
This allows you to test LVS on one box.
	</note>
	<para>
Viktors Rotanovs 1 Sep 2006
	</para>
	<para>
Is it possible to do port redirection using iptables _after_ director on localnode?
I've changed NF_IP_LOCAL_IN to NF_IP_PRE_ROUTING at ip_vs_in_ops in
ip_vs_core.c, and now it bypasses NAT, but I'm not a kernel hacker and
I don't know which priority should  be set and if it's possible to
solve the problem that way.
	</para>
	<para>
Siim Poder <emphasis>windo (at) p6drad-teel (dot) net</emphasis> 01 Sep 2006 
	</para>
	<para>
If the LVS grabs a packet, you cant do any NAT on it any more. The
packet is as good as lost for those purposes (currently it seems so, at
least).
	</para>
	<para>
However, LVS does it's own NAT, is there a reason why you have to first
let LVS do its own nat and then have iptables nat again? couldn't you
just have the right LVS real servers (with right ports) in the first
place (using fwmarks, if that source address is important).
	</para>
	<para>
Joe
	</para>
	<para>
Although LVS has always hooked into LOCAL_IN, it could hook in anywhere and
perhaps it would be good to write this into the ip_vs code. Both Horms and
Ludo have fiddled around here with no apparent ill-effect.
	</para>
	<para>
Horms 2 Sep 2006
	</para>
	<para>
Here is my take on this problem
<ulink url="http://archive.linuxvirtualserver.org/html/lvs-users/2005-06/msg00102.html">Local Nodes, msg00102</ulink>
<ulink url="http://archive.linuxvirtualserver.org/html/lvs-users/2005-06/msg00113.html">Local Nodes, msg00113</ulink>.
Here's the <ulink url="files/local_nodes.patch">local_nodes.patch</ulink>.
If people tested it and gave feedback we could merge it into the kernel :)
	</para>
	<para>
Dave Whitla 20 Jun 2005
	</para>
	<blockquote>
		<para>
I am trying to load balance to two "real" servers which are actually 
listening on virtual IPs on the load-balancing host. 
Why would I want to do this?
To build a test environment for a web application which usually runs on 
an IPVS cluster.  The purpose of the test environment is to test for 
databasecache contention issues before we deploy to our production 
cluster. The catch is I must make the test environment (lvs director + 2 
x application server instances) run on one physical host (each 
developer's development machine).
		</para>
		<para>
The man page for <command>ipvsadm</command> makes specific mention of forwarding to 
realservers which are in fact running on local interfaces stating that the 
load balancing "forward" mechanism specified for a virtual service is 
completely ignored if the kernel detects that a real server's IP is 
actually a local interface.  The "Local Node" page describes a 
configuration in which I could load balance between a "real" server 
running on the director's virtual service IP and a real server running 
on another host. This does not solve my problem however as I must bind 
each instance of my application to a different IP address on the same 
physical box.
		</para>
		<para>
You may be thinking "Why not run the two instances on different ports on 
the same IP (the virtual service IP)?".  Sadly the application is not a 
simple web-site, and source code and deployment container dependencies 
on certain port numbers exist. eg RMI-IIOP listeners.
		</para>
		<para>
Does anyone know of some config or kernel hack, patch or whatever which 
might make my ipvs present forwarded packets to the virtual interfaces 
as though they had appeared on the wire so that my forward directives 
are not ignored and the packets are not simply presented to the TCP 
stack for the virtual service IP? I guess this is like NAT to local 
destination addresses (as opposed to NAT of locally originated 
connections which is supported in the kernel).
		</para>
	</blockquote>
	<para>
Horms
	</para>
	<para>
this is a pretty interesting problem that crops up all the time.
I have often wondered how hard it would be to make nat work locally
(not that LVS-Tun and LVS-DR don't/can't support portmaping anyway).
The patch linked above is for 2.6.12 that allows nat to work locally by:
	</para>
	<itemizedlist>
		<listitem>
Not marking local real-servers as local
		</listitem>
		<listitem>
Passing nat-mangled packets down to local processes 
   instead of passing them out onto the network
		</listitem>
		<listitem>
Reversing nat in the LOCAL_IN chain
		</listitem>
	</itemizedlist>
	<para>
Please note that this completely breaks NAT for non-Local hosts.
It could be cleaned up and made so it doesn't do that. But I 
thought I'd throw it onto the list before putting any more time
into it.
	</para>
	<para>
Horms 21 Jun 2005 
	</para>
	<para>
The patch is my second attempt.
This should automatically switch
local real-servers to Local unless the requested forwarding
method is Masq and the real port differs from the virtual port.
That is, if you want to do portmaping on a local service it will
use Masq, otherwise it will use Local.
It seems to work, but there are probably a few gotchas in there
and I haven't tested a whole lot.
	</para>
</section>
<section id="LVS-HOWTO.warasin" xreflabel="warasin">
<title>LVS: Variants on LVS: Peter Warasin's ip_vs() in PREROUTING</title>
<para>
Peter Warasin <emphasis>peter (at) endian (dot) com</emphasis> 11 Sep 2007
</para>
<para>
I made some modifications on the lvs specific kernel code, which now
leads into kernel oops. Could someone give me some pointers about how to
find the bug? I am not very familiar with the kernel code, so maybe I
missed some simple tricks which routined people know and me not.
Basically I altered the lvs code in order to make it catch packets
within the PREROUTING chain instead of the INPUT chain. My setup works,
but sometimes I have a kernel oops.
I think somewhere it lacks some sort of spinlock, but I not really know
where to begin in order to find where it must be inserted.
</para>
<para>
My setup:
</para>
<itemizedlist>
	<listitem>
Kernel is RHEL 2.6.55.0.2.EL.
	</listitem>
	<listitem>
I have 2 LVS directors (master, backup), which at the same time are real
servers running squid. They are configured as LVS-GW, the real servers
have ip addresses on a different subnet, than the VIP. The backup has
the correct route for both subnets and a default gateway pointing to the
master.
	</listitem>
	<listitem>
I use keepalived which configures LVS in order to have the correct rules
configured on the master and have no rules on the backup whenever the
master is up.
	</listitem>
	<listitem>
Connections to port 80 from behind the master going to "the outside"
should be transparently intercepted, balanced by lvs and passed to the
respective squid, which does the rest.
	</listitem>
	<listitem>
		<para>
With the standard LVS this setup is not possible, because of 2 causes:
		</para>
		<orderedlist>
			<listitem>
I must mark packets within the PREROUTING chain in the mangle table
in order to pass them to LVS, but LVS intercepts only packets coming in
into the INPUT chain, but which forwarded packets will never pass.
			</listitem>
			<listitem>
When I managed it to intercept the packets with LVS, both
realservers needs to DNAT the packets in order to redirect them to
squid, which runs on port 8080.
But packets which come in on Local cannot be NAT'ed because LVS sends
them directly to the wire.
			</listitem>
		</orderedlist>
		<para>
I solved those problems this way:
		</para>
		<orderedlist>
			<listitem>
<programlisting><![CDATA[
--- linux-2.6.9/net/ipv4/ipvs/ip_vs_core.c.orig 2007-07-30
20:40:31.000000000 +0200
+++ linux-2.6.9/net/ipv4/ipvs/ip_vs_core.c      2007-07-30
20:40:37.000000000 +0200
@@ -1095,7 +1095,7 @@
        .hook           = ip_vs_in,
        .owner          = THIS_MODULE,
        .pf             = PF_INET,
-       .hooknum        = NF_IP_LOCAL_IN,
+       .hooknum        = NF_IP_PRE_ROUTING,
        .priority       = 100,
 };

]]></programlisting>
			</listitem>
			<listitem>
<programlisting><![CDATA[
--- linux-2.6.9/include/net/ip.h.orig	2007-08-01 20:22:35.000000000 +0200
+++ linux-2.6.9/include/net/ip.h	2007-08-01 20:22:50.000000000 +0200
@@ -87,6 +87,7 @@
 					      struct ip_options *opt);
 extern int		ip_rcv(struct sk_buff *skb, struct net_device *dev,
 			       struct packet_type *pt);
+extern int		ip_rercv(struct sk_buff *skb);
 extern int		ip_local_deliver(struct sk_buff *skb);
 extern int		ip_mr_input(struct sk_buff *skb);
 extern int		ip_output(struct sk_buff **pskb);
--- linux-2.6.9/include/net/ip_vs.h.orig	2007-08-01 22:12:52.000000000 +0200
+++ linux-2.6.9/include/net/ip_vs.h	2007-08-01 22:13:10.000000000 +0200
@@ -925,6 +925,8 @@
  */
 extern int ip_vs_null_xmit
 (struct sk_buff *skb, struct ip_vs_conn *cp, struct ip_vs_protocol *pp);
+extern int ip_vs_loop_xmit
+(struct sk_buff *skb, struct ip_vs_conn *cp, struct ip_vs_protocol *pp);
 extern int ip_vs_bypass_xmit
 (struct sk_buff *skb, struct ip_vs_conn *cp, struct ip_vs_protocol *pp);
 extern int ip_vs_nat_xmit
--- linux-2.6.9/net/ipv4/ipvs/ip_vs_conn.c.orig	2007-08-01
21:52:32.000000000 +0200
+++ linux-2.6.9/net/ipv4/ipvs/ip_vs_conn.c	2007-08-01 21:52:51.000000000
+0200
@@ -322,7 +322,7 @@
 		break;

 	case IP_VS_CONN_F_LOCALNODE:
-		cp->packet_xmit = ip_vs_null_xmit;
+		cp->packet_xmit = ip_vs_loop_xmit;
 		break;

 	case IP_VS_CONN_F_BYPASS:
--- linux-2.6.9/net/ipv4/ipvs/ip_vs_xmit.c.orig	2007-08-01
19:28:52.000000000 +0200
+++ linux-2.6.9/net/ipv4/ipvs/ip_vs_xmit.c	2007-08-03 16:47:16.000000000
+0200
@@ -24,6 +24,8 @@
 #include <net/route.h>                  /* for ip_route_output */
 #include <linux/netfilter.h>
 #include <linux/netfilter_ipv4.h>
+#include <linux/netfilter_ipv4/ip_nat.h>
+#include <linux/netfilter_ipv4/ip_conntrack.h>

 #include <net/ip_vs.h>

@@ -141,12 +143,47 @@
 ip_vs_null_xmit(struct sk_buff *skb, struct ip_vs_conn *cp,
 		struct ip_vs_protocol *pp)
 {
+	IP_VS_DBG(10, "NULL transmitter called\n");
 	/* we do not touch skb and do not need pskb ptr */
 	return NF_ACCEPT;
 }


 /*
+ *      LOOP transmitter (reinject on NF_IP_PRE_ROUTING)
+ */
+int
+ip_vs_loop_xmit(struct sk_buff *skb, struct ip_vs_conn *cp,
+		struct ip_vs_protocol *pp)
+{
+
+	struct ip_conntrack *ct;
+	enum ip_conntrack_info ctinfo;
+	struct ip_nat_info *info;
+
+	IP_VS_DBG(5, "LOOP transmitter called\n");
+	if (skb->nfcache & NFC_IPVS_PROPERTY) {
+		IP_VS_DBG(10, "Already passed LVS. Receive it normally\n");
+		return NF_ACCEPT;
+	}
+
+	IP_VS_DBG(10, "Retransmit to IP_PRE_ROUTING hook starting with
priority NF_IP_PRI_MANGLE\n");
+	nf_reset_debug(skb);
+	skb->nfcache |= NFC_IPVS_PROPERTY;
+	skb->ip_summed = CHECKSUM_NONE;
+
+	ct = ip_conntrack_get(skb, &ctinfo);
+	if (ct && (ctinfo == IP_CT_NEW)) {
+		info = &ct->nat.info;
+		info->initialized = 0;
+	}
+	NF_HOOK_THRESH(PF_INET, NF_IP_PRE_ROUTING, skb, skb->dev,
+		       NULL, ip_rercv, NF_IP_PRI_MANGLE);
+	return NF_STOLEN;
+}
+
+
+/*
  *      Bypass transmitter
  *      Let packets bypass the destination when the destination is not
  *      available, it may be only used in transparent cache cluster.
--- linux-2.6.9/net/ipv4/ip_input.c.orig	2007-08-01 19:29:54.000000000 +0200
+++ linux-2.6.9/net/ipv4/ip_input.c	2007-08-01 19:32:42.000000000 +0200
@@ -355,6 +355,14 @@
 }

 /*
+ * 	Retransmit packet
+ */
+int ip_rercv(struct sk_buff *skb)
+{
+	return ip_rcv_finish(skb);
+}
+
+/*
  * 	Main IP Receive routine.
  */
 int ip_rcv(struct sk_buff *skb, struct net_device *dev, struct
packet_type *pt)
@@ -429,4 +437,5 @@
 }

 EXPORT_SYMBOL(ip_rcv);
+EXPORT_SYMBOL(ip_rercv);
 EXPORT_SYMBOL(ip_statistics);
]]></programlisting>
				<para>
the patch causes incoming packets which should go to Local to retransmit
through the netfilter hooks starting on NF_IP_PRI_MANGLE, instead of
transmit them directly with ip_vs_null_xmit.
This way I can remove the mark within the mangle table in order to pass
it through LVS twice and then simply DNAT it.
(please ask if you like to have the detailed iptables/ipvsadm rules.)
				</para>
			</listitem>
		</orderedlist>
	</listitem>
</itemizedlist>
<para>
The setup works.
But sometimes I have a kernel oops (fatal exception in interrupt,
<filename>ip_rcv</filename>, <filename>ip_rcv_finish</filename> is involved).
I tried to narrow down the problem, by removing patch nr 2, but the
problem still exists.
So the problem must be with the 1st patch. But what could cause this. I
simply let LVS catch packets within PREROUTING chain instead INPUT
chain. That seems not too different to me.
</para>
<para>
I think somewhere it lacks some sort of spinlock, but I not really know
where to begin in order to find where it must be inserted.
</para>
<para>
Horms 13 Sep 2007 
</para>
<para>
As Joe mentioned in a subsequent email, being able to move LVS from one
chain to another is something that we are interested in.  In particular
I am of the believe that the FORWARD chain would be a much more logical
home than LOCAL_IN as in some ways would allow LVS to act more like a
router than a proxy (not that it is a proxy, but it kind of behaves like
one in some ways because of its home on LOCAL_IN).
</para>
<para>
As I recall, I did try moving the code to the FORWARD chan a long time
ago. I believe that the change was very similar to the LOCAL_IN to
PRE_ROUTING snippet that you have below. I'm not sure that I ever posted
the change, as I never tested it thorougly. So perhaps it too broke
occasionally. In any case, this was a long time ago, and the kernel
has changed significantly then, so any testing done at that time
wouldn't really hold water now (incidently 2.6.9 is also pretty old,
though I'm not sure what patches RHEL include to modernise it).
</para>
<para>
As for debugging your problem. Providing the oops message - if any -
might help. Hopefully there is a stack trace in there and that should
start to point to where the problem is.
</para>
<para>
Some portions of the locking schemantics of LVS are non-trivial and
I have a deep suspicion that there are some races in there anyway.
By which I mean, don't be surprised if things get a bit hairy as you
are tracing through what is going on.
</para>
<para>
If your kernel is compiled with IP_VS_DEBUG then you can enable
and adjust the verbosity of debugging messages that LVS produced
by tweaking /proc/sys/net/ipv4/vs/debug_level as documented in
Documentation/networking/ipvs-sysctl.txt in the kernel source tree.
</para>
<para>
Also, if you are doing development work, I do recommend considering
using a more up to date kernel. Perhaps the latest rc kernel, currently
2.6.23-rc6. I'm not suggsting that you neccessarily drop this into
production. But for development work, it is much easier to work with
the kernel guys if you are on the same page as them.
</para>
</section>
<section id="LVS-HOWTO.ludos_reinject_forwarder" xreflabel="Ludo's reinJect forwarder">
<title>LVS-J: Ludo's reinJect Forwarder: using the director as a gateway to load balance connections to the internet</title>
	<section id="intro_reinject">
	<title>Introduction</title>
	<para>
We haven't had a new forwarder for quite a while 
(the last one was either Localnode or LVS-Tun, 
way back in the early days).
	</para>
	<para> 
An LVS director should be able to balance packets through 
multiple paths to the internet, 
except that it has to accept the replies as well. 
Ludo Stellingwerff <emphasis>ludo (at) protactive (dot) nl</emphasis> 
has hacked the ipvs code to do just that.
A writeup of the state of the art in routing multiple internet
connections over different paths is in <xref linkend="LVS-HOWTO.dynamic_routing"/>.
Handling failure in multipath routing is still difficult - 
see Julian's <xref linkend="dead_gateway"/> detection code.
As for all the forwarders, failover of the realservers
is handled externally to ip_vs.
Anyone who sets up this forwarder will at least need to
be aware of the problem of handling failure of any of the routes.
	</para>
        <para>
Ludo Stellingwerff <emphasis>ludo (at) protactive (dot) nl</emphasis> 29 Jul 2005
        </para>
	<para>
Here are the <ulink url="files/vs_reinject_patches.tar.bz2">
vs_reinject_patches.tar.bz2 against 2.6.11 </ulink>.
This is a minimum implementation to provide support for
using LVS as a loadbalancer for internet gateways. 
	</para>
	<para>
He're the physical layout with example IPs.
	</para>
<programlisting><![CDATA[
-
|                   LAN  192.168.1.0/24
private IPs         |
|                   eth0 192.168.1.254
-                   |
                 Director
-                |      |
|   200.200.10.1 eth1   eth2 200.200.20.1
|                |      |
public IPs       |      |
|                |      |
|           (modem, router, wan)
| 200.200.10.254 gw_1   gw_2 200.200.20.254
|                |      |
v                ISP1   ISP2
]]></programlisting>
	<para>
The director is the gateway for the private network.
The director load balances two separate internet connections (eth1, eth2)
through the realservers which are the real gateways. 
Any return traffic will pass through the director on the way back 
(side note: you'll need to switch off reverse path filter on the director)
	</para>
	<para>
The code consists of two parts: director code called "reinJect" and an iptables target called "LVS". 
I call my code "Multipath routing through LVS", 
because the kernel term for multiple internet connections is multipath routing.
Patches are included to allow <command>ipvsadm</command> to set up
the reinJect forwarding.
	</para>
	</section>
	<section id="reinject_ipvsadm">
	<title>reinJect setup with ipvsadm</title>
	<para>
Here's how you set it up. It's similar to the setup of the other
forwarders, but using the <filename>-j</filename> forwarder option.
There are a few extra wrinkles, as explained below.
	</para>
<programlisting><![CDATA[
iptables -A FORWARD -t mangle -s 192.168.1.0/24 -d 0.0.0.0/0 -m state - --state NEW -j MARK --set-mark 1
iptables -A FORWARD -t mangle -m mark --mark 1 -j LVS
ipvsadm -A -f 1 -p # for -p see below
ipvsadm -a -f 1 -r 200.200.10.254 -j
ipvsadm -a -f 1 -r 200.200.20.254 -j
iptables -A POSTROUTING -t nat -o eth1 -m mark --mark 1 -j SNAT - --to-source 200.200.10.1
iptables -A POSTROUTING -t nat -o eth2 -m mark --mark 1 -j SNAT - --to-source 200.200.20.1
]]></programlisting>
	</section>
	<section id="reinject_lvs_target">
	<title>The target LVS: sending packets with dst_addr=0/0 to ip_vs</title>
	<para>
Since the director is being asked to process packets with dst_addr=0/0,
some method of getting the director to process the packets is needed. 
Originally LVS was written to process single IP, single port
services (<emphasis>e.g.</emphasis> a website at VIP:80).
Since the packet was destined for an IP on the original server 
(that was replaced by an LVS), 
and this packet was routed to LOCAL_IN, LVS was written to hook into LOCAL_IN. 
In an LVS this IP became the VIP on the outside of the director and
a non-arping VIP on the realservers.
Later for 2.2.x kernels, transparent proxy 
<xref linkend="LVS-HOWTO.transparent_proxy"/> allowed LVS to be extended
so that it would accept packets to a wide range of IPs 
<emphasis>e.g.</emphasis> squids which process packets for 0:80.
With the arrival of the 2.4 series of kernels, transparent proxy
no longer worked for LVS (but still worked for squids) 
as the dst_addr of the packet was rewritten.
LVS was back to working on only individual IPs.
<xref linkend="LVS-HOWTO.fwmark"/> allowed grouping
of a small number of IPs to be seen as one service,
and was adapted to fwmark packets for 0.0.0.0.
Still methods outside LVS were required to allow 
the packets to be accepted locally,
which fwmark didn't do.
The problem was that LVS required the packets to traverse LOCAL_IN
and you couldn't put the IP=0.0.0.0 on
the director (or realservers) which would direct these packets to LOCAL_IN. 
These IPs were on machines out in internetland.
This was solved by Julian with two lines of <command>iproute2</command>
code (see <xref linkend="LVS-HOWTO.routing_to_VIP-less_director"/>).
Now everyone was happy again, but for LVS to work, the packets
must traverse LOCAL_IN.
	</para>
	<para>
There has been some talk of moving the LVS hooks from LOCAL_IN to another
part of the routing table
<emphasis>e.g.</emphasis> <xref linkend="hook_pre_routing"/>.
In fact you can hook LVS anywhere after PRE_ROUTING,
except that to make such a change would require much testing.
Hopefully not too much would break in the rest of the code,
but still you would have to allow time to fix it all.
No-one has wanted to take on the job.
	</para>
	<para>
Ludo solves the problem of LVS processing packets with dst_addr=0.0.0.0
by putting the hook for his forwarder into the FORWARD chain 
(which is traversed by packets to 0.0.0.0).
Conceivably LVS could be rewritten so that all forwarders 
for packets to 0.0.0.0 hook into the FORWARD chain.
Here's the instructions that send the packet to LVS. 
	</para>
<programlisting><![CDATA[
#mark new connections to 0/0 with fwmark=1
#after the SYN packet passes through, the routing cache will have an entry for that route.
#the kernel keeps a cache of used routes.
#subsequent packets in the connection will be forwarded by the routing cache table.
iptables -A FORWARD -t mangle -s 192.168.1.0/24 -d 0.0.0.0/0 -m state - --state NEW -j MARK --set-mark 1
#send all packets with fwmark==1 to the chain LVS
#the chain LVS is setup by the patches and sends the packet to the ip_vs code.
iptables -A FORWARD -t mangle -m mark --mark 1 -j LVS
]]></programlisting>
	<para>
The marked packets jump to the target LVS, which sends the packet
to the normal ip_vs code
	</para>
	</section>
	<section id="reinject_setup_forwarding">
	<title>setting up LVS-J forwarding</title>
	<para>
The setup of the <filename>-j</filename> forwarder is the same as for the other forwarders.
	</para>
<programlisting><![CDATA[
ipvsadm -A -f 1 -p  #standard persistence timeout
ipvsadm -a -f 1 -r 200.200.10.254 -j
ipvsadm -a -f 1 -r 200.200.20.254 -j
]]></programlisting>
	<para>
Normally you would like to use persistence: <emphasis>e.g.</emphasis>
accessing websites with cookies based on sourceip, using https, ssh. 
The problem is not in which gateway you would use, 
but which source address you seem to come from 
(here either 200.200.10.1 or 200.200.20.1).  
	</para>
	<para>
The ip_vs code does the normal things with the packet - if it's a
new connection, sets up the templates etc, and if it's a current
connection, figures out which realserver to send the packet to.
	</para>
	<para>
The reinject code puts the packet to the mangle chain,
doing a form of direct routing,
returning the packet to the place where target LVS was
called, but with a new mac-address and destination device
(here eth1 or eth2 on the director).
	</para>
	<note>
		<para>
The packet with have the source MAC address of the public interface on the outside of the
director and destination MAC address of the gateway/realserver.
The ip_vs code doesn't set destination MAC addresses, 
but leaves that to the outgoing device driver. 
LVS/DR (and LVS/Reinject) changes a field in a kernel structure called SKB.
(skb->dst) This field is the next ipaddress the packet will go to. The
corresponding MAC address will be determined by the link-layer driver.
LVS only operates on network layer. (ip-addresses)
		</para>
	</note>
	<para>
Reinjection is only effective if <filename>ip_vs</filename> 
is called on the FORWARD path. 
If you try to reinject at
the LOCAL-IN path, it won't work.
The normal <filename>ip_vs</filename> function is called after the
choice between local delivery and forwarding. 
If I only change the skb->dst at this point, 
it will not redo this choice and continue to be locally delivered. 
That is the reason why LVS-DR calls the ethernet output function directly.
	</para>
	</section>
	<section id="reinject_snat" xreflabel="reinject snat">
	<title>SNAT'ing the output</title>
	<para>
Packets emerging from the director would have src_addr=CIP
(a private IP).
Ludo fixes this by SNAT'ing the src_addr.
	</para>
<programlisting><![CDATA[
iptables -A POSTROUTING -t nat -o eth1 -m mark --mark 1 -j SNAT - --to-source 200.200.10.1
iptables -A POSTROUTING -t nat -o eth2 -m mark --mark 1 -j SNAT - --to-source 200.200.20.1
]]></programlisting>
	<para>
SNAT'ing is only necessairy when the director is between a private and a public network. 
It will work when the director is between two public networks (with no SNAT required). 
In most cases SNAT is required.
	</para>
	</section>
	<section id="reinject_discussion">
	<title>LVS-J discussion by Ludo</title>
	<para>
The code could have achieved the same result using direct routing, 
but then couldn't SNAT the private addresses to public addresses. 
Therefore the code introduced the reinject director, 
which only changes the routing decision and then returns to normal 
routing with NF_ACCEPT on the hook. 
The packet will than go on normally, but with a new route.
	</para>
	<para>
This effect is similar to the iptables ROUTE target, but with the
added features of LVS (caching, persistence).
	</para>
	<para>
The scheduler is non-intrusive: it only changes 1 field in the skb 
and then returns to the normal network stack, 
at the same point where "ip_vs_in()" was called.
The code provides a Netfilter Target called "LVS" 
which can be used in the mangle table on the FORWARD hook. 
When used, this target calls "ip_vs_in()" directly, 
providing the routing capability of lvs.
	</para>
	<itemizedlist>
		<listitem>
Packet coming in from LAN has non-local destination, normal Linux routing will call
ip_forward.
		</listitem>
		<listitem>
Netfilter Forwarding hook is called
		</listitem>
		<listitem>
			<para>
In the mangle table the following two targets will be called:
			</para>
<programlisting><![CDATA[
#iptables -A FORWARD -t mangle -s <lan-ip> -d 0.0.0.0/0 -m state - --state NEW -j MARK --set-mark 1
#iptables -A FORWARD -t mangle -m mark --mark 1 -j LVS
]]></programlisting>
		</listitem>
		<listitem>
			<para>
The LVS target will call ip_vs_in(), with a schedular on fwmark 1,
using the new "reinject" director:
			</para>
<programlisting><![CDATA[
#ipvsadm -A -f 1 -p
#ipvsadm -a -f 1 -j -r <gateway1>
#ipvsadm -a -f 1 -j -r <gateway2>
]]></programlisting>
		</listitem>
		<listitem>
The reinject director will make sure the packet will continue
transfering the mangle table, but with a new Nexthop (skb->dst).
		</listitem>
		<listitem>
The packet will continue through the normal network stack, through
POSTROUTING, etc.
		</listitem>
		<listitem>
The packet will be send towards the internet through the selected
gateway (specified as next hop).
		</listitem>
	</itemizedlist>
	<para>
The provided patches have three unfinished drawbacks:
	</para>
	<itemizedlist>
		<listitem>
I'm not sure if the kernelpatches compile correctly when used as
modules. Therefor I force the LVS subsystem to "inbuild/yes" when
selecting the iptables target.
		</listitem>
		<listitem>
I didn't check the usage of the iptables target for the FORWARDING
hook. It is still possible to select this target in PREROUTING, even
though this is ineffective, it will not work.
		</listitem>
		<listitem>
It's against 2.6.11 (which is old allready:)
Hopefully I'll find time to clean that up somewhere next week. Or
maybe someone else has time/energy to clean them up?
		</listitem>
	</itemizedlist>
	<para>	
Linux networking is very flexible when it comes to routing. It is
possible to use several internet connections through one router. The
process of selecting from these multiple defaultroutes is called
multipath routing.
One of the remaining problems for multipath routing under Linux is the
lack of flexibility on the scheduling of these multiple defaultroutes.
The normal multipath routing only provides a weight factor, but no
further setup parameters. It is a basic form of load-balancing, but
nothing fancy. Another problem is that multipath routing is only
supported on defaultroutes, not on any route with more than one
possible gateway.
	</para>
	<para>
The lvs_reinjection patches are designed to provide the full
effectiveness of the LVS schedulars for deciding which route a given
packet will take. Contrary to normal LVS setups it provides the
possibility to schedule any traffic through the router. With normal
LVS the scheduled service is a local service on the director which is
then transfered to one or more realservers. The solution provided
through these patches can select any traffic passing the director and
then force this traffic through a nexthop/gateway.
	</para>
	<para>
The fwmark can be anywhere in the networking stack, using iptables.
Then you'll need to tell the network stack to send the traffic through
the LVS subsystem. This is done through the use of a new iptables
target called LVS. The purpose of this target is to call the entry
function of LVS.
	</para>
	<para>
Basically you can then use any of the LVS functions, any director
available. But of the three standard forwarders, none is very
effective for the internet loadbalancing case. The LVS/NAT director
will mangle the headers of the packets, therefor loosing the final
destination information. The LVS/TUN director will try to setup a
tunnel to the realservers (in this case: the gateways), but most
gateway's don't provide such a tunnel capability. Only LVS-DR 
provides the required behaviour: it will send the packets
unmodified to the correct gateway. But the LVS/DR director does this
by bypassing all local routing on the router, and sends the packet
directly through the ethernet drivers output function. This means 
further services, like SNAT, Masquerading, etc. cannot be done on these
packets.
	</para>
	<para>
For this problem the patches introduce a new director, called
LVS/Reinject. This is a very simple director, similar to LVS/DR. But
instead of sending the packet directly out the ethernet device, this
director leaves that to the normal network stack. It just returns back
to where LVS was called in the first place. 
You can't use the LVS-J forwarder in normal LVS setups, 
where LVS hooks into LOCAL_IN. 
Returning the packet to LOCAL_IN 
would mean that the packet will try to be locally delivered. 
Here the code allows LVS
to hook into the FORWARD chain.
	</para>
	<para>
Normally LVS services require the traffic to the VIP to be delivered
locally on the director. Just before this traffic is delivered to a
local process the LVS subsystem will be called. If the LVS subsystem
accepts the traffic for one of its services, it will steal the traffic
from the local delivery-path and sent it through one of its directors
to the realservers (bypassing standard routing).
With the iptables target it is possible to call the LVS subsystem at
any time you like. This can be on the local-delivery path, but also on
the forwarding-path. If you call the "LVS" target and the traffic is
selected by one of the LVS services, it will be stolen from the normal
flow and delivered back there again.
	</para>
	<para>
Registering LVS with the FORWARD hook, fixes the problem 
of requiring the dst_addr to be a VIP local to the director. 
But I also wanted to prevent LVS from stealing the packet. 
I wanted the traffic to stay in the netwerk stack, 
and continue on its normal path.
The only service I needed from LVS was the ability to
select one of the available gateways.
These are the realservers in LVS terminology, 
but here they aren't the endpoint of the connection,
just the next hop to internet.
So I combined the ability to sent any traffic to LVS 
with the ability to reinject the packets in the network
flow at the same place where LVS stole it 
(basically returning from the LVS entry function with IPT_CONTINUE, 
i.s.o. NF_STOLEN)
	</para>
	<para>
Horms
	</para>
	<para>
I had a brief look over the patches and the seem ok to me. Except
that I am not clear on the motivation of the following hooks.
Doesn't this mean that <filename>ip_vs_in</filename> 
is registered in three separate places? Is this actually what you need?
	</para>
	<para>
Ludo Stellingwerff Aug 04, 2005
	</para>
	<blockquote>
		<para>
Yes, as I try to redirect forwarded traffic (with addresses not local
to the director), I need to hook into NF_FORWARD. 
Ideally this has to be a seperate <filename>ip_vs_forward_in function</filename>, 
but these patches are a concept proof.
This new <filename>ip_vs_forward_in function</filename> 
should be limited to matching fwmarks.
		</para>
		<para> 
The packet flow is:
incoming packet -> PRE_ROUTING -> FORWARD -> ip_vs_in (returning
NF_ACCEPT, after changing skb->dst) -> POSTROUTING -> outgoing packet.
		</para>
		<para>
I'm also looking at the possibility of using the iptables REDIRECT
target to get rid of the forwarding hook and use the normal ip_vs_in,
but I'm not yet sure this will not mangle the original packet (It
should not loose the original destination data). At least reinject
should than be changed to return NF_STOLEN on the INPUT hook, and call
<emphasis>ip_forward()</emphasis> to get the packet on it's way again.
		</para>
		<para>
The flow for the packet will then become:
incoming packet -> PRE_ROUTING (REDIRECT)-> INPUT -> ip_vs_in
(returning NF_STOLEN, sending packet to ip_forward()) -> FORWARD ->
POSTROUTING -> outgoing packet.
		</para>
	</blockquote>
	<para>
Horms 9 Aug 2005
	</para>
	<para>
IF you can get that working, that would be nice.
Though I have often wondered about just moving <filename>ip_vs_in()</filename>
to FORWARD and being done with it. I've tried it briefly
in the past to good effect.
	</para>
	</section>
</section>
<section id="LVS-HOWTO.services.general" xreflabel="services: general">
<title>LVS: Services: general, setup, debugging new services</title>
<para>
If you just want to find out about setting up a particular service that we already
have figured out (<emphasis>e.g.</emphasis> all single port read-only services,
some multiport services) then just go to that section.
This section is if you are having trouble setting up a service,
or want to know more about how services are setup.
</para>
	<section id="single_port">
	<title>Single port services are simple</title>
	<para>
Single port tcp services all use the same format:
	</para>
	<itemizedlist>
		<listitem>
		the realserver listens on a known port
(<emphasis>e.g.</emphasis> port 23 for telnet)
		</listitem>
		<listitem>
		the client initiates connection by sending a SYN from a high port
(port number &gt; 1024) to the VIP:known_port (<emphasis>e.g.</emphasis>VIP:23)
		</listitem>
		<listitem>
the director selects the next realserver to service the request from its
scheduling table, allocates a new entry in its hash (ipvsadm) table,
and forwards the SYN packet to the realserver.
		</listitem>
		<listitem>
the realserver replies to the client.
For LVS-DR and LVS-Tun, the default gw for the realserver
is <emphasis role="bold">not</emphasis> the director: the
reply packet goes directly to the client.
For LVS-NAT, the default gw for the realserver is the director:
the reply packet is sent to the director, where it is masqueraded
and then sent to the client.
		</listitem>
	</itemizedlist>

	<para>
A similar chain of events is involved in pulling down the tcp connection.
	</para>
	<para>
In principle, setting up a service on an LVS is simple - you run the service
on the realserver and forward the packets from the director.
A simple service to setup on LVS is telnet:
the client types a string of characters and the
server returns a string of characters, making it the choice of
services for debugging an LVS.
	</para><para>
In practice some services interact more with their environment.
<xref linkend="ftp"/> needs two ports.
With http, the server needs to know
its name (it will have the IP of realserver, but will need to proclaim
to the client that it has the name associated with the VIP).
https is not listening to an IP, but to requests to a nodename.
This section shows the steps needed to get the common single-port services working.
A section on <xref linkend="LVS-HOWTO.services.multi-port"/>
shows how to set up multi-port services like ftp or e-commerce sites.
	</para><para>
When trying something new on an LVS, always have telnet running as an LVS'ed service.
If something is not working with your service, check how telnet is doing.
Telnet has the advantages
	</para>
	<itemizedlist>
		<listitem>
telnetd listens on 0.0.0.0 on the realserver (at least under inetd)
		</listitem>
		<listitem>
the exchange between the client and server is simple, well documented,
		</listitem>
		<listitem>
the connection is non-persistence
(new sessions initiated from a client will make a new connection with the LVS)
unencrypted and in ascii (you can follow it with tcpdump)
		</listitem>
		<listitem>
the telnet client is available on most OS's
		</listitem>
	</itemizedlist>
	</section>
	<section id="new_services">
	<title>setting up a (new) service</title>
	<para>
When setting up your LVS, 
you should first test that your realservers are working correctly. 
Make sure that you can connect to each realserver from a test client, 
then put the realservers behind the director.
Putting the realservers into an LVS changes the networking.
For testing the realservers separately
	</para>
	<itemizedlist>
		<listitem>
<emphasis role="bold">LVS-DR, LVS-Tun</emphasis>: 
Have the VIP on lo:n or tunl0:n with the service listening to the VIP. 
You'll need some way of   
<xref linkend="LVS-HOWTO.routing_to_VIP-less_director"/> from the test client.
Alternately you can put the VIP on eth0 and move it back
to the local device afterwards.
		</listitem>
		<listitem>
<emphasis role="bold">LVS-NAT</emphasis>: 
The service will be listening on the RIP. 
In production the client will be connecting
to the VIP, so name resolution may be required mapping
the RIP to the name of the VIP.
If you need this see <xref linkend="indexing"/>.
		</listitem>
	</itemizedlist>
	<para>
The LVS director behaves as a router (with slightly different rules).
Thus when setting up an LVS on a new service,
the client-server semantics are maintained
	</para>
	<para>
	<itemizedlist>
		<listitem>
the client thinks it is connecting directly to a server
		</listitem>
		<listitem>
the realserver thinks it is being contacted directly by the client
		</listitem>
	</itemizedlist>
	</para>
	<para>
Example: nfs over LVS, realserver exports its disk,
client mounts a disk from LVS
(this example taken from
<ulink url="http://www.linuxvirtualserver.org/Joseph.Mack/performance/single_realserver_performance.html">
performance data for single realserver LVS</ulink>),
	</para>
	<para>
realserver:/etc/exportfs (realserver exports disk to client, here a host called client2)
	</para>
<programlisting><![CDATA[
/       client2(rw,insecure,link_absolute,no_root_squash)
]]></programlisting>
	<para>
The client mounts the disk from the VIP. Here's client2:/etc/fstab
(client mounts disk from machine with an /etc/hosts entry of VIP=lvs).
	</para>
<programlisting><![CDATA[
lvs:/   /mnt            nfs     rsize=8192,wsize=8192,timeo=14,intr 0 0
]]></programlisting>
	<para>
The client makes requests to VIP:nfs.
The director must forward these packets to the realservers.
Here's the conf file for the director.
	</para>
<programlisting><![CDATA[
#lvs_dr.conf for nfs on realserver1
.
.
VIP=eth1:110 lvs 255.255.255.255 192.168.1.110
DIP=eth0 dip 192.168.1.0 255.255.255.0 192.168.1.255
DIRECTOR_DEFAULT_GW=client2
SERVICE=t telnet rr realserver1 realserver2	#for sanity check on LVS
#to call NFS the name "nfs" put the following in /etc/services
#nfs             2049/udp
#note the 'u' for "udp" in the next line
SERVICE=u nfs rr realserver1			#the service of interest
SERVER_VIP_DEVICE=lo:0
SERVER_NET_DEVICE=eth0 Why do you need persistence?
SERVER_DEFAULT_GW=client
#----------end lvs_dr.conf------------------------------------
]]></programlisting>
	</section>
	<section id="setup_for_forwarding_type">
	<title>services must be setup for forwarding type</title>
	<para>
The services must be setup to listen on the correct IP.
With telnet, this is easy (telnetd listens on 0.0.0.0 under inetd),
but most other services need to be configured to listen to a particular IP.
	</para>
	<para>
For LVS-NAT, the packets will arrive with dst_addr=RIP, i.e.
the service will be listening to (and replying from) the RIP of the realserver.
When the realserver replies,
then name of the machine returned
will be that of the realserver (the RIP),
but the src_addr will be rewritten by the director to be the VIP.
If the name of the realserver is part of its service
(as with <link linkend="httpd">name based http</link>)
then the client will associate the VIP with this name.
The realserver then will need to associate the RIP with this name.
You could put an entry for the RIP into <filename>/etc/hosts</filename>
linking it to this name.
	</para>
	<para>
With LVS-DR and LVS-NAT the packets will arrive with dst_addr=VIP,
i.e. the service will be listening to (and replying from)
an IP which is <emphasis>NOT</emphasis> the IP of the realserver.
Configuring the httpd to listen to the RIP rather than the VIP
is a common cause of problems for people setting up http/https.
All realservers will need to think that they have the hostname
associated with the VIP.
	</para>
	<para>
In both cases, in production, you will need to make the name of the
machine given by the realserver to be the name associated with the VIP.
	</para>
	<para>
Note: if the realserver is Linux 2.4 and is
accepting packets by transparent proxy, then see the
section on <xref linkend="LVS-HOWTO.transparent_proxy"/> for the IP the service
should listen on.
	</para>
	</section>
	<section id="synchronising_content">
	<title>Realservers present the same content:
Synchronising (filesharing) content and config files, backing up realservers</title>
	<para>
Realservers should have indentical files/content for any particular
service (since the client can be connected to any of them).
This is not a problem for slowing changing sites (<emphasis>e.g.</emphasis>
ftp servers), where the changes can be made by hand,
but sites serving webpages have to be changed
daily or hourly.
Some semi-automated method is needed to
stage the content in a place where it is reviewed and then
moved to the realservers.
	</para>
	<para>
For a <link linkend="databases">database</link> LVS,
the changes have to be propagated in seconds.
In an e-commerce site you have to either keep the
client on the same machine when they transfer from
http to https (using persistence), which may
be difficult if they do some comparative shopping
or have lunch in the middle of filling their shopping cart,
or propagate the information
<link linkend="cookie"><emphasis>e.g.</emphasis> a cookie</link> to the
other realservers.
	</para>
	<para>
Here are comments from the mailing list.
	</para>
	<para>
Wensong
	</para>
	<blockquote>
		<para>
If you just have two servers, it might be easy to use rsync to
synchronize the backup server, and put the rsync job in the
crontab in the primary. See http://rsync.samba.org/ for rsync.
		</para>
		<para>
If you have a big cluster, you might be interested in Coda, a
fault-tolerant distributed filesystem.
See the
<ulink url="http://www.coda.cs.cmu.edu/">code website</ulink> for more information.
		</para>
	</blockquote>
	<para>
Joe
	</para>
	<blockquote>
		<para>
from comments on the mailing list, Coda now (Aug 2001) seems to be a
usable project. I don't know what has happened to the sister project
<ulink url="http://www.inter-mezzo.org">Intermezzo</ulink>.
		</para>
		<para>
May 2004. It appears that development has stopped on both Coda and Intermezzo.
I think the problem was too difficult.
		</para>
		<para>
Jan 2006. Coda appears to be back in development.
		</para>
	</blockquote>
	<para>
J Saunders 27 Sep 1999
	</para>
	<blockquote>
I plan to start a frequently updated web site (potentially every minute or so).
	</blockquote>
	<para>
Baeseman, Cliff <emphasis>Cliff (dot) Baeseman (at) greenheck (dot) com</emphasis>
	</para>
	<blockquote>
I use mirror to do this.  I created a ftp point on the director.
All nodes run against the director ftp directory and update the
local webs. It runs very fast and very solid.
upload to a single point and the web propagates across the nodes.
	</blockquote>
	<para>
Paul Baker <emphasis>pbaker (at) where2getit (dot) com</emphasis> 23 Jul 2001
(and another posting on 18 Jul 2002 announcing v0.9.2.2)
	</para>
	<blockquote>
		<para>
PFARS Project on SourceForge
		</para>
		<para>
I have just finished commiting the latest revisions to the PFARS project
CVS up on SourceForge. PFARS prounced 'farce' is the "PFARS For
Automatic Replication System."
		</para>
		<para>
PFARS is currently used to handle server replication for
Where2GetIt.com's LVS cluster. It has been in the production environment
for over 2 months so we are pretty confident with the code stability. We
decided to open source this program under the GPL to give back to the
community that provided us with so many other great FREE tools that we
could not run our business without (especially LVS). It is written in
Perl and uses rsync over SSH to replicate server file systems. It also
natively supports Debian Package replication.
		</para>
		<para>
Although the current version number is 0.8.1 it's not quite ready for
release yet. It is seriously lacking in documentation and there is no
installation procedure yet. Also in the future we would like add support
for RPM based linux distros, many more replication stages, and support
for restarting server processes when certain files are updated. If
anyone would like to contribute to this project in any way do not be
afraid to email me directly our join the development mailing list at
pfars-devel@lists.sourceforge.net.
		</para>
		<para>
Please visit the project page at <ulink url="http://sourceforge.net/projects/pfars/">
http://sourceforge.net/projects/pfars/</ulink>
and check it out. You will need to check it out from CVS as there are no
files released yet. Any feedback will be greatly appreciated.
		</para>
	</blockquote>
	<para>
	<note>
Joe (May 2004): the last code code entry for <filename>pfars</filename> was Sep 2002. 
The project appears to have stopped development.
	</note>
	</para>
	<para>
Zachariah Mully
	</para>
	<blockquote>
		<para>
         I am having a debate with one of my software developers about how to
 most efficiently sync content between realservers in an LVS system.
		</para>
		<para>
         The situation is this... Our content production software that we'll be
 putting into active use soon will enable our marketing folks to insert
 the advertising into our newsletters without the tech and launch teams
 getting involved (this isn't necessarily a good thing, but I'm willing
 to remain open minded ;). This will require that the images they put
 into newsletters be synced between all the webservers... The problem
 though is that the web/app servers running this software are
 load-balanced so I'll never know which server the images are being
 copied to.
		</para>
		<para>
         Obviously loading the images into the database backend and then out to
 the servers would be one method, but the software guys are convinced
 that there is a way to do it with rsync. I've looked over the
 documentation for rsync and I don't see anyway to set up cron jobs on
 the servers to run an rsync job that will look at the other servers
 content, compare it and then either upload or download content to that
 server. Perhaps I am missing an obvious way of doing this, so can anyone
 give me some advice as to the best way of pursuing this problem?
		</para>
	</blockquote>
	<para>
Bjoern Metzdorf <emphasis>bm (at) turtle-entertainment (dot) de</emphasis> 19 Jul 2001
	</para>
	<blockquote>
		<para>
You have at least 3 possibilities:
		</para>
		<itemizedlist>
			<listitem>
You let them upload to all RIPs (uploading to each realserver)
			</listitem>
			<listitem>
You let them upload to a testserver, and after some checks you use rsync
to put the images onto the RIPs.
			</listitem>
			<listitem>
You let them upload to one defined RIP instead of the VIP and rsync from
there (no need for a testserver)
			</listitem>
		</itemizedlist>
	</blockquote>
	<para>
Stuart Fox <emphasis>stuart (at) fotango (dot) com</emphasis> 19 Jul 2001
	</para>
	<blockquote>
		<para>
nfs mount one directory for upload and server the images from there.
		</para>
		<para>
Write a small perl/bash script to monitor both upload
directories remotely then rsync the differences when
detected.
		</para>
	</blockquote>
	<para>
Don Hinshaw <emphasis>dwh (at) openrecording (dot) com</emphasis> 19 Jul 2001
	</para>
	<blockquote>
		<para>
You can use rsync, rsync over ssh or scp.
		</para>
		<para>
You can also use partition syncing with a network/distributed filesystem such
as Coda or OpenAFS or DRBD (DRBD is still too experimental for me). Such a
setup creates partitions which are mirrored in real-time. I.e., changes to
one reflect on them all.
		</para>
		<para>
We use a common NFS share on a RAID array. In our particular setup, users
connect to a "staging" server and make changes to the content on the RAID. As
soon as they do this, the real-servers are immediately serving the changed
content. The staging server will accept FTP uploads from authenticated users,
but none of the real-servers will accept any FTP uploads. No content is kept
locally on the real-servers so they never need be synced, except for config
changes like adding a new vhost to Apache.
		</para>
		<para>
<emphasis>jik (at) foxinternet (dot) net</emphasis> 19 Jul 2001
		</para>
		<blockquote>
If you put the conf directory on the NFS mount along with htdocs then
you only need to edit one file, then ssh to each server and "apachectl
graceful"
		</blockquote>
		<para>
Don Hinshaw <emphasis>dwh (at) openrecording (dot) com</emphasis> 20 Jul 2001
		</para>
		<blockquote>
Um, no. We're serving a lot of:
&lt;VirtualHost x.x.x.x&gt;
and the IP is different for each machine. In fact the conf files for all the
real-servers are stored in an NFS mounted dir. We have a script that manages
the separate configs for each real-server.
		</blockquote>
		<para>
I'm currently building a cluster for a client that uses a pair of NFS servers
which will use OpenAFS to keep synced, then use linux-ha to make sure that
one of them is always available. One thing to note about such a system is
that the synced partitions are not "backups" of each other. This is really
a "meme" (way of thinking about something). The distinction is simply that
you cannot rollback changes made to a synced filesystem (because the change
is made to them both), whereby with a backup you can rollback. So, if a user
deletes a file, you must reload from backup. I mention this because many
people that I've talked to think that if you have a synced filesystem, then
you have backups.
		</para>
		<para>
What I'm wondering is why you would want to do this at all. From your
description, your marketing people are creating newsletters with embedded
advertising. If they are embedding a call for a banner (called a creative in
adspeak) then normally that call would grab the creative/clickthrough link
from the ad server not the web servers. For tracking the results of the
advertising, this is a superior solution. Any decent ad server will have an
interface that the marketing dept. can access without touching the servers at
all.
		</para>
	</blockquote>
	<para>
Marc Grimme <emphasis>grimme (at) comoonics (dot) atix (dot) de</emphasis> 20 Jul 2001
	</para>
	<blockquote>
		<para>
Depending on how much data you need to sync, you could think about using a
Cluster Filesystem. So that any node in the LVS-Cluster could concurrently
access the same physically data.
Have a look at <ulink url="http://www.redhat.com/software/rha/gfs/">GFS</ulink>.
We have a clustered webserver
with 3 to 5 nodes with GFS underneath and it works pretty stable.
		</para>
		<para>
If you are sure on what server has latest data is uploaded to, no problem
with rsync. If not, I would consider to use a Network - or Cluster Filesystem.
That should save a lot of scripting work and is more storage efficient.
		</para>
	</blockquote>
	<para>
<emphasis>jgomez (at) autocity (dot) com</emphasis>
	</para>
	<blockquote>
		<para>
We are using rsync as a server.
We are using a function that uploads the contents to the server and sync the
uploaded file to the other servers.The list of servers we have to sync
is in a file like:
		</para>
<programlisting><![CDATA[
192.168.0.X
192.168.0.X
192.168.0.X
]]></programlisting>
		<para>
When a file is uploaded,the server reads this file and make the sync to all
the other servers.
		</para>
	</blockquote>
	<para>
"Matthew S. Crocker" <emphasis>matthew (at) crocker (dot) com</emphasis> 14 May 2002
	</para>
	<blockquote>
Working machines have local disks for qmail queue and /etc /boot which are
EXT3. Working data (/home, /usr, /shared, /webspace) lives on a Network
Appliance Netfiler. I really can't say enough about the NetApps they are
simply awesome. You pay a chunk of money but it is money well spent.
	</blockquote>
	<para>
Andres Tello Abrego C.A.K." <emphasis>criptos (at) aullox (dot) com</emphasis> 06 Sep 2002
	</para>
	<blockquote>
		<para>
Using the KISS principle.
		</para><para>
The usernames and password collection, must be centralized, for control,
only one place, where, u update, change and remove passwords,then, a
little help of scp, and all the trick is done.
		</para><para>
Just, copy, over a secure coneccition, ur password collectios file.. and,
u are sync. We, even develop a "cluster" admin web based app, the
principle of functioning, was, one server, is the "fistone" then, using,
small programan triggered by a ssh execution command or attached to a port
using the inetd super server.. and u are done.
		</para>
	</blockquote>
	<para>
"Matthew S. Crocker" <emphasis>matthew (at) crocker (dot) com</emphasis> 07 Sep 2002
	</para>
	<blockquote>
		<para>
Instead of using NIS, or NIS+ I use LDAP for all my customer information
records.  I store, Radius, Qmail, DHCP, DNS, and Apache Virtual Host
information in my LDAP server.  We have a couple LDAP slaves and have all
servers query the LDAP servers for info.  Radius, Qmail are real time,
everything else is updated via a script.
		</para><para>
To replicate NIS functions in LDAP check out www.padl.com.  They have a
schema and migration tool set
		</para>
	</blockquote>
	<para>
Jerker Nyberg <emphasis>jerker (at) update (dot) uu (dot) se</emphasis> 08 Sep 2002
	</para>
	<blockquote>
		<para>
I used to take information from the customer database and store
shadow/passwd/groups/httpd.conf/aliases/virtusertable/etc in two
high-availability MySQL-databases (on the same machines that run LVS) then
every 30 minutes or apropriate generate the files on the realservers. The
"source of all information" for us whas the customer database (also
MySQL), that we can modify in our own customized python/GTK-clients or the
customers (indirect) via a webinterface.
		</para>
		<para>
One of the ideas with this was to move the focus from what is stored on
the servers to what is in the customer database. In that way it is easy to
inactivate accounts if customers doesn't pay their fees etc. If the
real-servers go down, they can all be reinstalled with a
kickstartinstallation including the scripts that generate the
configuration files. I found it easier with "pull" instead of a "push" for
the configuration files.
		</para>
		<para>
Local files (with databases "db" instead of linear files in
/etc/nsswitch.conf - this began to make a difference with more than 10k
users) in my experience always seemed to be faster than any networked
nameservices (LDAP, NIS etc) even if you use nscd to cache as much as you
can.
		</para>
	</blockquote>
	<para>
James Ogley <emphasis>james.ogley (at) pinnacle (dot) co (dot) uk</emphasis> 14 Aug 2002
	</para>
	<blockquote>
		<para>
We have an internal 'staging' server that our web designers upload
content to.  A shell script we run as a daemon then rsync's the content
across the cluster members.
		</para><para>
In addition, we have an externally facing FTP server that external
customers upload their content to.  The above mentioned shell script
rsyncs that content to itself as park of it's operation.
		</para>
	</blockquote>
	<para>
"Matthew S. Crocker" <emphasis>matthew (at) crocker (dot) com</emphasis> 14 Aug 2002
	</para>
	<blockquote>
		<para>
We use keepalived for the cluster/LVS monitoring/management.  We use SCP
to move the keepalived.conf file around to all the servers.
		</para>
		<para>
For content it is all stored on a Netfiler F720.  The next upgrade will
replace the F720 with a cluster of Netfilers (F85C ??).  The realservers
NFS mount the content (Webdirs, Maildir)
		</para>
		<para>
Put new content on the NFS server, every machine sees it
		</para>
		<para>
We run SMTP,POP3,IMAP.  We'll be adding HTTP, HTTPS and FTP in the next
few weeks.  Our LVS is LVS-NAT, 2 directors, 4 realservers, Cisco 3548
switch.
		</para>
	</blockquote>
	<para>
Do you know of any new technology or propriety solutions that need an
open source implementation?
	</para>
	<blockquote>
I would like to see a Netfiler type appliance open sourced.  I know I can
go with a linux box but I'm just not sure on the performance.  I want a
fiber channel based NFS server will complete journaling, 30 second
reboots, fail over, snapshots.  I think a linux box with EXT3 or ReiserFS
comes close but you don't get snapshots and I'm not sure how the failover
would work.
	</blockquote>
	<para>
Doug Schasteen wrote:
	</para>
	<para>
What does the keepalived vrrp do exactly? What are you using MySQL for?
Because if you are running scripts or web programs, then don't you need
to specify an IP in your connection strings? I'm just wondering how that
works, because if all your connection strings are set to a certain IP
and then that IP goes down, how does it know to fail over to the second
machine? The only thing I can think of is your second machine takes over
that IP somehow.
	</para>
	<blockquote>
		<para>
keepalived is an awesome tool,
bundled with <link linkend="keepalived_vrrpd">VRRP</link>
it allows for machine failover.
Basically you set it up like this.
		</para>
		<para>
Machine A:
		</para>
<programlisting><![CDATA[
 Physical IP 192.168.1.10
 MySQL Master
 keepalived Master
  VRRP IP address 192.168.1.20
]]></programlisting>
		<para>
Machine B:
		</para>
<programlisting><![CDATA[
 Physical IP 192.168.1.11
 MySQL Slave
 keepalived BACKUP
  VRRP IP address 192.168.1.20
]]></programlisting>
		<para>
The MySQL Master is setup to replicate with the MySQL Slave (192.168.1.20)
The SQL client apps connect to MySQL on 192.168.1.20.  The IP address
192.168.1.20 will only exist on the machine which keepalived determines to
be the active MASTER. If something causes that machine to crash or if the
backup machine stops recieving VRRP announcements from the master it will
enable the IP address and send out arps for the IP.  The clients will
connect to the same IP address all the time. That IP address can be on
either machine.
		</para>
		<para>
I use keepalived to fail over my LVS servers but it can be used to
failover any group of machines.
		</para>
	</blockquote>
	<para>
 I was planning on tackling this issue by writing (rewriting) all of my
 scripts/programs to include one file that does the mysql connections.
 Then I only have to change one file when I want to change where my mysql
 connections go. And then maybe I'll add a failover connection inside of
 that include file, like an "if the first connection didn't work, try the
 backup server". The problem with that is that if for some odd reason the
 first connection doesn't work (perhaps I rebooted the machine), it will
 put them on the backup server and updates will be made to the backup
 server. Any updates made to the backup mysql server while I'm rebooting
 the main mysql server will probably be lost. I can maybe add two-way
 replication for when something like this happens (but not use two-way
 replication all the time, because I've heard that has problems.)
	</para>
	<blockquote>
Have the slave server dump transaction logs so you can manually replicate
the data back over when you recover the master server.
	</blockquote>
	<para>
Ramon Kagan <emphasis>rkagan (at) YorkU (dot) ca</emphasis> 14 Aug 2002
	</para>
	<blockquote>
		<para>
We use lvs with keepalived for High Availability.  All our servers are
identical in setup, and use NFS to a cluster of Netapp filers (two F840s)
Our setup uses, LVS-DR since we push very close to the 100Mbit/s range,
NAT seemed to have too much overhead.
		</para>
		<para>
Services that we run are web(http, https), web mail, mail delivery.  Pop
and imap on soon to be added to this list.
		</para>
		<para>
New content is put onto the filers, thus all nfs clients pick it up
immediately.
		</para>
		<para>
For our MySQL setup I have a single "MySQL" machine.  I setup my MySQL to
listen on the designated port and have setup strict rules in MySQL for
authentication and access.  (see mysql.user and mysql.db tables).  For
redundancy I have a second machine running as a replication slave against
the MySQL machine.  I'm using keepalived's vrrp framework to force
failover when problems arise (hasn't happened yet, knocking on wood
really hard).  I have tested this in a development environment and it
seems to work nicely.  I found that with both machines running 100Full
Duplex, our MySQL server can complete over 10,000 write transactions per
second and the latency between databases is on average 0.0019 seconds
(yes, under 2 thousandth of a second!).  I will admit that these are
pretty strong machines (Dual P3 1.4 with 2 GB memory, 100% SCSI based),
but I seen similar performance on P3 600 with 512 MB memory, IDE based,
still 100 Full Duplex though.
		</para>
		<para>
VRRP - virtual router redundancy protocol
		</para>
		<para>
Keepalived is software writeen by Alexandre Cassen.
What is can do it as such:
		</para>
		<orderedlist>
			<listitem>
Health checking of realserver allowing removing of unresponsive ones
from an lvs table (auto control of the lvs table)
			</listitem>
			<listitem>
Heartbeat between two lvs boxes so that if one fails the other
takesover.
			</listitem>
		</orderedlist>
		<para>
So, with these two you can create a High Availibity (HA) cluster.
		</para>
		<para>
Using "2" only you can setup a service, like MySQL replication, and run
just the heartbeat (in this case VRRP framework) without the health
checking or LVS framework.  Then if the master node goes down the slave
node can run a script to convert the slave database into a master
database.
		</para>
		<para>
So, if you have a master system say dbmast.ex.com, and a slave
dbslav.ex.com you create a service IP db.ex.com.  All clients talk through
db.ex.com. On startup, dbmast.ex.com arps out gratuitously that it is
db.ex.com. On failure, dbslave.ex.com would arp out to take over the
systems.
		</para>
		<para>
This way, client need not know of any changes.
		</para>
		<para>
Go to www.keepalived.org for more info.  If you have any further
questions, there is a mailing list, and I have helped in the past with the
documentation.
		</para>
	</blockquote>
	<para>
nick garratt <emphasis>nick-lvs (at) wordwork (dot) co (dot) za</emphasis> 14 Aug 2002
	</para>
	<blockquote>
		<para>
transferring of content is currently done via tar over ssh:
		</para>
<programlisting>
<![CDATA[
tar cBf - . | ssh remoteserver "cd /to/content/location && tar xBf -"
]]>
</programlisting>
		<para>
(beware path length !)
		</para>
		<para>
it's useful for transferring entire hierarchies, preserving perms,
symlinks and whatnot, but we'll probably migrate to rsync.
		</para>
		<para>
before new content is deployed it is transferred to an intermediate
deploy server from the dev server where it is thoroughly
tested/abused. none of these machines forms part of the cluster per
se.
		</para>
		<para>
the content is transferred to the remote access server in the cluster
after testing. from this machine it it transferred to each of the web
servers in turn using the same mechanism described above.
		</para>
		<para>
any content which must be shared (rw) by all web servers (client
templates, ftp dirs) is NFS served.
		</para>
		<para>
content is database driven dynamic content (apart from obvious
exceptions) providing both web site facilities and an http/s get/post
and xml api.
		</para>
		<para>
cluster manager : lvs using fwmark  nat for (public) http/s,ftp,
smtp, dns and fwmark dr (internal clustered services) for http. mon.
www1 - wwwn : php, apache. all run msession and an ftpd although only
one is IT at any point
db : pair of mysql servers in master/slave.
loghost : responsible for misc services : ntp master for cluster,
syslogd - remote logging, tftpd for log archiving, log analysis ...)
remote : dns for the world (also fwmark) and secondary nameserver for
cluster, ssh
		</para>
	</blockquote>
	<para>
Neulinger, Nathan <emphasis>nneul (at) umr (dot) edu</emphasis> 26 Apr 2004
	</para>
	<blockquote>
We use AFS/OpenAFS as our backend storage for all regular user and web
data.  (Mail and databases are separate.) About 3 TB total capacity, of
which about 1.9 used. 
We have 3500+ clients, many of which are user desktops - thus unsuitable for
nfs. NFS is suitable for tightly controlled server clusters, but not
really for export to clients that may or may not be friendly. 
	</blockquote>
	<para>
Joe 26 Apr 2004
	</para>
	<blockquote>
If it's a readonly site, then have only static pages on the realservers
and rsync them from a staging machine (which may have dynamic html).
If you need randomly different content from dynamic pages, generate
different versions of them every few minutes and push different ones
to each realserver. You want the httpd to be fetching as much from 
the disk cache as possible.
	</blockquote>
	<para>
John Reuning <emphasis>john (at) metalab (dot) unc (dot) edu</emphasis> 26 Apr 2004 
	</para>
	<blockquote>
		<para>
Squid might be a good solution for caching static pages on real
servers.  For php caching, you can use turck mmcache.  It works well
most of the time, but is sometimes flaky with poorly-written php code.
		</para>
		<para>
We actually do what Joe suggested, manually rsync'ing content to a cache
directory on the realservers.  Alias directives are added to map the
cached content to the proper url location.  Our shared storage is nfs,
and we, too, have lots of user-maintained files.  However, we've
targeted directories that don't change often (theme and layout directories
for CMS applications, for example).  Rsync is efficient, and we run it
every hour or so.
		</para>
		<para>
There's one performance problem that's not solved by this, though. 
Apache performs lots of stat() calls when serving pages (checking for
<filename>.htaccess</filename> files).  The stat calls are made before the content is served
and go to the nfs servers.  Under a high traffic load, the stat calls
bog down our nfs servers despite the content being cached on the real
servers.
		</para>
	</blockquote>
	<para>
Graeme Fowler <emphasis>keepalived (at) graemef (dot) net</emphasis> 28 May 2004
	</para>
	<para>
There's loads of way to synchronise realserver content or the whole filesytem
incase of realserver disk failure.
	</para>
	<itemizedlist>
		<listitem>
 Have a "management station" which can do pubkey SSH logins to the managed 
machines, run scripts, push software and so on.
		</listitem>
		<listitem>
Create a disk image of a server you're happy with and have it network boot 
using syslinux/pxelinux
		</listitem>
		<listitem>
Utilise HP's open source OpenSSI project (an OSS cluster management 
system).
I've found the OpenSSI concepts to be hugely useful in theory, 
if not in practice.
		</listitem>
		<listitem>
Use a "virtual" machine system such as UML. You can then keep a "dumb" 
system running the virtual machine, make changes to the image offline, copy it 
to the "dumb" system and reboot the virtual machine instead.
		</listitem>
	</itemizedlist>
	<para>
J. Simonetti <emphasis>jeroens (at) office (dot) netland (dot) nl</emphasis> 28 May 2004
	</para>
	<para>
I also found <ulink url="http://www.systemimager.org/">systemimager</ulink>
(http://www.systemimager.org/)
myself which sounds promising as well.
	</para>
	</section>
	<section id="cfengine">
	<title>cfengine for synchronising files</title>
	<para>
<ulink url="http://www.cfengine.org/">cfengine</ulink> is designed
to control and propagate config files to large numbers of machines.
Presumably it could be used to synchronise realserver content files as well.
	</para>
	<blockquote>
Has anyone succesfully rolled-out a cluster of real-servers
using coda? (Main reason would be for the replication of config files
(Apache/qmail) across all real-servers) - Is this doable? Or am I better of
using rsync?
	</blockquote>
	<para>
Magnus Nordseth <emphasis>magnun (at) stud (dot) ntnu (dot) no</emphasis> 27 Jun 2003
	</para>
	<para>
I recommend using rdist or cfengine which are designed to distribute
configuration files, not to make exact copies of a directory
(structure). Both rdist and cfengine are more configurable than rsync.
	</para>
	</section>
	<section id="file_systems" xreflabel="filesystems for clusters">
	<title>File Systems for (really big) Clusters: Lustre, Panasas</title>
	<para>
People have discussed CODA as a filesystem for synchronisation.
In clusters NFS has a lot of overhead and failed mounts result in hung systems.
Here's a posting from the beowulf mailing list
	</para>
	<para>
Bari Ari <emphasis>bari (at) onelabs (dot) com</emphasis> 26 Sep 2002
	</para>
	<blockquote>
		<para>
NFS is dead for clusters.
We are targeting three possible systems, each having a different set of
advantages:
		</para>
		<itemizedlist>
			<listitem>
panasas (http://www.panasas.com)
			</listitem>
			<listitem>
lustre (http://www.lustre.org)
			</listitem>
			<listitem>
v9fs (http://v9fs.sourceforge.net)
			</listitem>
		</itemizedlist>
	</blockquote>
	</section>
	<section id="samba_nfs" xreflabel="comparing NFS and Samba">
	<title>File Systems for Clusters: Samba waits for a commit and is slow, NFS fills buffers and is fast</title>
	<para>
(from the TriLUG mailing list).
	</para>
	<para>
John Broome 
	</para>
	<para>
I have a RH 9 machine that is acting as a fileserver for a completly
windows network (98 and 2000), the users mentioned that the file
transfers seemed slow.
Some testing showed that samba was moving data much slower than NFS. 
NFS was using pretty much the entire speed potential of the network,
where SMB was about half that, or less.
No indication on the server that CPU, HDD, or memory is the problem.
When tested off site with different hardware and a different OS
(Ubuntu 5.04), the same problem popped up -   
SMB dragging along, NFS cranking.
Since this is a mostly windows network we can't really use NFS instead
of the samba.
	</para>
	<para>
Tanner Lovelace <emphasis>clubjuggler (at) gmail (dot) com</emphasis> 06/20/2005
	</para>
	<para>
A quick search for "samba tuning" brings up this quote from
http://www.oreilly.com/catalog/samba/chapter/book/appb_01.html
"If you run Samba on a well-tuned NFS server, Samba may perform rather 
badly."
	</para>
	<para>
If you follow the link at the bottom of the page 
(http://www.oreilly.com/catalog/samba/chapter/book/appb_02.html)
it has suggestions for things in samba to tune.
	</para>
	<para>
Jason Tower <emphasis>jason (at) cerient (dot) net</emphasis> 
	</para>
	<para>
I was testing transfer speed using my t42 with ubuntu.  
File transfers using nfs would occur at wire speed (12.5 MB/s) 
while the exact same file transferred using smb (mounted with 
<command>smbmount</command>) would only be about 5.5 MB/s.
	</para>
	<para>
However, when I booted into windows on the t42 I could copy the file 
(with smb of course) at nearly wire speed.  
So it seems that at least part of the perceived problem has something 
to do with the smb *client*, not the server.  
cpu utilization and iowait was not even close to being 
a bottleneck so I'm not sure where the slowdown is occuring or why.
	</para>
	<para>
Jon Carnes <emphasis>jonc (at) nc (dot) rr (dot) com</emphasis> 06/20/2005
	</para>
	<para>
I wrote this up for TriLUG about 5 years ago... We tested various forms
of file transfer including NFS and Samba and - if I remember correctly -
we found Samba (version 3) to be about 1/3 the speed of NFS (version
2).  The problem was that the Samba process waited for a commit before
negotiating for the next data transfer whereas NFS filled a buffer and
continuously pushed that buffer out.
	</para>
	<para>
Obviously if you're running from a buffer out of RAM you can run at
network speeds (or as fast as your internal bus and cpu can go).
	</para>
	<para>
Microsoft's implementation of SMB pumps the data to be moved into a
buffer and works similarly, so it's almost as fast as using NFS (though
it does some other weirdness that always makes it a bit slower than
NFS...)
	</para>
	<para>
NFS v3 had a toggle that also defaulted to waiting for a commit from the
remote hard drive before sending more data - that moved files around
just slightly faster than Samba (it crawled.)
	</para>
	</section>
	<section id="distributed_filesystems" xreflabel="distributed filesystems">
	<title>Discussion on distributed filesystems</title>
	<para>
This was a long thread in which everyone discussed their knowlege of the matter. 
I've added subsequent postings at the end.
If clients are reading from the realservers (<emphasis>e.g.</emphasis> webpages),
then it's simple to have the same content on each machine 
and push content once a day say.
If clients are writing to disks, you have an different problem, 
of propagating the writes to all machines.
In this case you may want an (expensive) central fileserver 
(look for NetApp elsewhere in this HOWTO for happy users
<emphasis>e.g.</emphasis>  
<link linkend="mbox_maildir">NetApp for mailservers</link>).
	</para>
	<para>
Graham D. Purcocks
	</para>
	<blockquote>
What, if any, Distributed Filesystems have any LVS users tried/use with any success?
	</blockquote>
	<para>
Joe
	</para>
	<para>
We hear little about distributed file systems with LVS. Intermezzo is supposed
to be the successor to CODA, but we don't hear much more here on the LVS
mailing list about Intermezzo than we do about CODA.
	</para>
	<para>
Distributed file systems are a subject of great interest to others
(<filename>e.g.</filename> beowulfs) and you will probably find better info elsewhere.
	</para>
	<para>
The simple (to setup) distributed filesystems 
(<emphasis>e.g.</emphasis> PVFS) are unreliable,
<emphasis>i.e.</emphasis> if one machine dies, you loose the whole file system. 
This is not a problem for beowulfs, since the calculation has to be restarted
if a compute node dies, and jobs can be checkpointed. 
Reliable distributed filesystems require some effort to setup. 
GFS looks like it would take months and much money to setup. 
A talk at OLS_2003 described 
<ulink url="http://www.lustre.com/">Lustre</ulink> (http://www.lustre.com), 
a file system for 1024 node clusters that is in deployment. 
It sounds simpler to setup than GFS, but I expect it will still be work.
Lustre expects the layer of hardware (disks) below it to be reliable
(all disks are RAID).
	</para>
	<para>
Rather than depending on the filesystem to distribute state/content,
for an LVS where clients write infrequently (if at all), state/content can be
maintained on a failover pair of machines which push content to the
realservers.
	</para>
	<para>
Graham Purcocks <emphasis>grahamp (at) wsieurope (dot) com</emphasis> 04 Nov 2003
	</para>
	<para>
My thoughts are:-
	</para>
	<itemizedlist>
		<listitem>
NFS is fine if the content is not changing often. As it is a single
point of failure, you have to have a backup and do all the failover and
synchronizing stuff mentioned in other emails.
		</listitem>
		<listitem>
With a distributed file system, this is not the case and it 'should'
sort itself out as servers go offline. This system is needed if you have
dynamically changing content which changes often, then rsync will not
cut it.
		</listitem>
	</itemizedlist>
	<para>
John Barrett <emphasis>jbarrett (at) qx (dot) net</emphasis>
04 Nov 2003
	</para>
	<para>
nfs directory naming has not been an issue for me in the least -- I always
mount nfs volumes as /nfs[n] with subdirs in each volume for specific
data -- then symlink from where the data should be to the nfs volume -- same
thing you will have to do with coda -- in either case the key is planning
your nfs/coda setup in advance so that you dont have issues with directory
layouts, by keeping the mountpoints and symlinks consistent across all the
machines.
	</para>
	<para>
I'm not currently doing replicated database -- i'm relying on raid5+hotswap
and frequent database backups to another server using mysqldump+bacula.
Based on my reading, mysql+nfs not a very good idea in any case -- mysql has
file locking support, but it really slows things down because locking
granularity is at the file level (or was the last time I looked into it --
over a year ago -- please check if there have been any improvements)
	<para>
	</para>
based on my current understanding of the art with mysql, your best bet is to
use mysql replication and have a failover server used primarily for read
only until the read/write server fails (if you need additional query
capacity) (ldirectord solution), or do strict failover (heartbeat solution),
only one server active at a time, both writing replication logs, with the
inactive reading the logs from the active whenever both machines are up
(some jumping through hoops needed to get mysql to startup both ways --
possibly different my.cnf files based on which server is active)
	</para>
	<para>
with either setup -- the worst case scenario is one machine goes down, then
the other goes down some period of time later after getting many updates,
then the out of sync server comes up first without all those updates
	</para>
	<para>
(interesting thought just now -- using coda to store the replication logs
and replicating the coda volume on both the database servers and a 3rd
server for additional protection, 3rd server may or may not run mysql, your
choice of you want to do a "tell me 3 times" setup -- then you just have to
keep a file flag that tells which server was most recently active, then any
server becoming active can easily check if it needs to merge the replication
logs -- but we are going way beyond anything I have ever actually done here,
pure theory based on old research)
	</para>
	<para>
in either case you are going to have to very carefully test that your
replication config recovers gracefully from failover/failback scenarios
	</para>
	<para>
my current cluster design concept that I'm planning to build next week might
give you some ideas on where to go (everything running ultramonkey kernels,
in my case, on RH9, with software raid1 ide boot drives, and 3ware raid5 for
main data storage):
	</para>
	<para>
M 1 -- midrange system with large ide raid on 3ware controller,
raid5+hotswap, coda SCM, bacula network backup software, configured to
backup directly to disk for first stage, then 2nd stage backup the bacula
volumes on disk to tape (allows for fast restores from disk, and protects
the raid array in case of catastophic failure)
	</para>
	<para>
M 2 and 3 heartbeat+ldirectord load balancers in LVS-DR mode -- anything that
needs load balancing, web, mysql, etc, goes through here (if you are doing
mysql with a read/write + multiple read only servers, the read only access
goes through here, write access goes direct to the mysql server and you will
need heartbeat on those servers to control possesion of the mysql write ip,
and of course your scripts will need to open seperate mysql connections for
reading and writing)
	</para>
	<para>
M 4 -- mysql server, ide raid + hotswap -- I'm not doing replication, but we
already discussed that one :)
	</para>
	<para>
then as many web/application servers as you need to do the job :) each one
is also a replica coda server for the webspace volume, giving replicated
protection of the webspace and accessability even if the scm and all the
other webservers are down -- you may want multiple dedicated coda servers if
your webspace volume is large enough that having a replicate on each
webserver would be prohibitivly expensive
	</para>
	<para>
If you use replicated mysql servers, this
script may provide a starting point for a much simplified LVS-DR
implementation: http://dlabs.4t2.com/pro/dexter/dexter-info.html -- the
script is designed to layer additional functionality on top of a single
mysql server, but the quick glance that I took shows it could be extended to
route queries to multiple servers based on the type of query.. i.e. read
requests to the local mysql instance, write requests to a mysql instance on
another server.
	</para>
	<para>
setup 1 mysql master server, it will not be part of the mysql cluster, its
sole task is to handle insert/update and replicate those requests to the
slave servers.
	</para>
	<para>
setup any number of mysql replicated slaves -- they should bind to a VIP on
the "lo" interface, and the kernel should have the hidden ip patch
(ultramonkey kernels for instance)
	</para>
	<para>
modify dexter to intercept insert/update requests and redirect them to the
master server (will mean keeping 2 mysql sessions open -- one to the master,
one to the local slave instance) -- if the master isnt there, fail the
update -- install the modified script on all the slave servers
	</para>
	<para>
setup the VIP on an ldirectord box and add all the slaves as targets --
since mysql connections can be long running, I suggest using LeastConnection
balancing
	</para>
	<para>
Now clients can connect to the VIP, the slaves handle all read accesses, and
the master server handles all writes
	</para>
	<para>
The only possible issue with this setup is allowing for propogation delays
after insert/update -- i.e. you wont be able to read back the new data
instantly at the slaves -- may take a second or 2 before the slaves have the
data -- your code can loop querying the database to see if the update has
completed if absolutly neccessary
	</para>
	<para>
you still have a single point of failure for database updates, but your
database is always backed up on the slaves, and because there is only one
point of update, its very difficult for the slaves to get out of sync, and
read access is very unlikely to fail -- also you have none of the problems
with database locking, as NFS is still not recommended based on the lists
that I scanned to get up to date on the issues
	</para>
	<para>
Lastly -- the master CAN be a read server if you wish (my setup above
assumes it is not) given that the update load is not so much that the master
gets overloaded -- if you have high update frequency, then lets the slaves
handle all the reads, and the master only updates
	</para>
	<para>
Ariyo Nugroho <emphasis>ariyo (at) ebdesk (dot) com</emphasis> 31 Oct 2003
	</para>
	<blockquote>
		<para>
After successfully setup LVS-NAT for telnet, http, and ftp services, now
I'm going to do it with databases. From the HOWTO, it's said that
implementing such configuration needs distributed filesystem. There're
so many names mentioned in the HOWTO. And it make me confused.
		</para>
		<para>
The first name I noticed from the LVS page is Coda. But then I found
that Peter Braam has stopped working in coda team. He initiated another
one, Intermezzo. Many articles stated that this new filesystems is very
promising than Coda. Unfortunately until now, I can't find whether this
Intermezzo has become stable or not.
		</para>
		<para>
So, are there anyone of you that has experience with any distributed
filesystems? Which one would you recommend?
		</para>
	</blockquote>
	<para>
Joe
	</para>
	<para>
The HOWTO says that you need someway of distributing the writes to all
the realservers. This can be done at the application level or at
the filesystem lever. At the time we first considered running
databases on LVS, neither distibuted filesystems nor replication
was easily available on Linux. Pushing writes would have to
be done via a DBI/DBD interface or similar. I expected that distributed
filesystems were just around the corner (intermezzo, CODA), but
they never arrived. In the meantime mysql has implemented
replication and pushing the writes now seems best done at
the application level.
	</para>
	<para>
Ratz in his postings to the mailing
list has shown how most problems that involve maintaining
state across the realservers can and should be solved
at the application level. It only seems reasonable
to approach the database write problem the same way.
	</para>
	<para>
If someone comes up with a bulletproof, easy to maintain,
reliable distributed filesystem, then all of this will be thrown
out the window and we'll all go to distributed filesystems.
However with the effort that's been put into distributed filesystems
and the lack of progress that's been made, relative to the
progress from modifying the application, I think it's going to
be a while before anyone has another go at distributed filesystems
for Linux.
	</para>
	<para>
I'm sure the HOWTO says that LVS databases can use distributed
filesystems. However LVS'ed databases don't require (==need)
distributed filesystems.
	</para>
	<para>
Karl Kopper <emphasis>karl (at) gardengrown (dot) org</emphasis> 31 Oct 2003
	</para>
	<para>
Did I mention I have had a good experience with NFS?
	</para>
	<para>
In my experience NFS is rock solid on the newer 2.4 Linux
kernels. What let's me say this is the fact that since late February the
company where I work has been using Linux NFS clients in an LVS cluster as
the main business system without a single problem. This is a system that
processes half a billion dollars a year in orders and prints hundreds of
documents (warehouse pick sheets for example) every day (using the
rock-solid LPRng system btw). NFS has not failed once. The existing in-house
order processing applications did not have to be rewritten to run on the
cluster over NFS because they use fcntl locking.
	</para>
	<para>
This cluster is all in one data center. I would sooner quit my job than be
forced into implementing a file system for a mission critical application
that had to do lock operations to guarantee data integrity over a WAN. I
don't care how good the file system code is.
	</para>
	<para>
Joe
	</para>
	<blockquote>
This went over my head. Are you using locking with nfs or not?
	</blockquote>
	<para>
We are doing locking with NFS (the fcntl calls from the application cause
the Linux kernel to use statd/lockd to talk to the NAS server). I just
wouldn't do locking over a WAN.
I'm just talking about doing any type of lock
operation over a WAN (for example an NFS client that connects to the NAS box
over the WAN). Not really distributed content stored on direct attached disk
on each node (though that would have to be even worse for locking over a
WAN).
	</para>
	<para>
Joe
	</para>
	<blockquote>
		<para>
I missed the WAN bit in the original posting.
So you were referring to some sort of file system
(distributed ?, eg AFS) spread over a WAN? I had forgotten that some
distributed file systems aren't local only.
		</para>
		<para>
Let's see if we understand e.o.
		</para>
		<itemizedlist>
			<listitem>
			<para>
Where you're coming from:
			</para>
			<para>
You don't like file locking onto a box on another network over possibly
non-dedicated links. You're happy with NFS because you have the disks local
(in some arrangement I don't know about yet) on a network that others
can't get to.
			</para>
			</listitem>
			<listitem>
			<para>
Where I'm coming from:
			</para>
			<para>
I think of distributed file systems as being used on machines like beowulfs
(or an LVS) where the disks are on machines on a separate and dedicated network,
that is not accessible to clients (all jobs are submitted to a master node,
and the client never sees the filesytem behind it). The people running the
beowulf have complete control over the file system(s) and network behind
the master node.
			</para>
			</listitem>
		</itemizedlist>
	</blockquote>
	<para>
Karl
	</para>
	<para>
the problem is alack of a consistent definition of the term "distributed file system."
Here is the configuration I'm referring to:
	</para>
<programlisting><![CDATA[
[LVS RS 1]------------>|   NAS       |
                       |    Server   |
[LVS RS 2]------------>|             |
                       | NFS Server) |
[LVS RS 3]------------>|_____________|
]]></programlisting>
	<para>
Each LVS RS has /var, /usr, etc. on a local disk drive, but shared data is
placed on the NFS-mounted file system. (They are just ordinary NFS clients
to the NAS box). Lock arbitration is performed by the NAS box.
	</para>
	<para>
I think the terms "distributed file system" and "cluster file system" suffer
from the same problem of vagueness of definition. Awhile back Alan Cox had
this to say about the term cluster file system (CFS):
	</para>
	<para>
It seems to mean about three different things
	</para>
	<orderedlist>
		<listitem>
A clusterwide view of the file store implemented by any unspecified
means  - <emphasis>i.e.</emphasis> an application view point.
		</listitem>
		<listitem>
A filesystem which supports operation of a cluster
		</listitem>
		<listitem>
A filesystem with multiple systems accessing a single shared
file system on shared storage
		</listitem>
	</orderedlist>
	<para>
Meaning #3 can be really confusing because a 'cluster file system' in that
sense is actually exactly what you don't want for many cluster setups,
especially those with little active shared storage'
For example if you are doing database failover you can do I/O fencing
 and mount/umount of a more normal fs.
	</para>
	<para>
John Barrett <emphasis>jbarrett (at) qx (dot) net</emphasis> 01 Nov 2003
	</para>
	<para>
I've just recently installed Coda, and must say that i'm less impressed with
it compared to NFS for a number of reasons. There is a server setup I will
be doing in a few weeks where Coda will be the only choice, so don't think
that I'm being completely against Coda, I just feel the range of areas where
it is usable is fairly narrow.
	</para>
	<itemizedlist>
		<listitem>
NFS is already in the linux kernel as is Coda, but Coda is an older
version (5.3.xx vs current 6.0.xx, make sure your user-space code is right
for your kernel module)
		</listitem>
		<listitem>
NFS -- setting up the client and server is a no-brainer, webmin handles
both if you dont want to get your keyboard dirty, and even if you hand-edit,
its no problem, no such luck with Coda
		</listitem>
		<listitem>
Coda's main strength is replicated servers, But you can do the same with
NFS if you are willing to accept some delay before changes propogate to the
other NFS servers (i.e. rsyncing the nfs servers every so often, using
heartbeat failover to bring the backup NFS server online as needed) -- if
your files on disc are frequently changing and replicated servers must be in
sync, Coda is the better choice.
		</listitem>
		<listitem>
Coda's main weakness IMHO is the hoops you have to jump through when you
make changes to the server system -- you have to kill and restart the client
daemon on each client machine to get changes to take. (adding a new server
or replicate, creating or deleting volumes, etc -- experiment a lot on
non-production systems, get the production setup right the 1st time)
		</listitem>
		<listitem>
Coda does much more in the way of local caching than NFS, and the cache
size is configurable... make the cache as large as the distributed filespace
and it is possible to continue to operate if all the servers are down, and
any changes will be committed when one or more of the servers come back
online (presuming all the files needed are in the cache)
		</listitem>
		<listitem>
Coda does not use system uid/gid for its file -- it maintains its own
user/pass database, and you must login/acquire a ticket before accessing
Coda volumes -- NFS runs off the existing uid/gid system, all you have to do
is keep the passwd/group files on all the machines in sync for key users, or
setup NIS+
		</listitem>
	</itemizedlist>
	<para>
In closing, I feel that I had a bad experience with Coda, but I wont
hessitate to try again when I have more time to dig into the detail, I was
under a lot of time pressure on this latest job, so I went with NFS just to
get the system online NOW :)
	</para>
	<para>
Todd Lyons <emphasis>tlyons (at) ivenue (dot) com</emphasis> 16 Feb 2006
	</para>
	<para>
Here are some questions to ask to compare which avenue you would like to
take for a cluster filesystem:
	</para>
	<orderedlist>
		<listitem>
In a cluster filesystem, how many real servers can go down at one time
and leave the virtual raid array still operational?
		</listitem>
		<listitem>
In a NAS box, how many drives can die simultaneously and the system is
still operational?
		</listitem>
		<listitem>
In a cluster filesystem, what happens if half of the switch ports
just all of a sudden die, or the whole switch, or some corruption
happens in your switch and several ports suddently segment themselves
into its own VLAN?
		</listitem>
		<listitem>
For a NAS box, ask #3.  (Hint: a good NAS like the FAS270c with twin
heads will do a complete takeover if necessary, so 3 of the 4 ethernet
ports can lose connectivity.  As long as one is still connected, that
one head can serve the load of both heads.)
		</listitem>
		<listitem>
In an NAS box, does it have multiple power supplies?  Multiple
ethernet ports?  Multiple parity drives?  Multiple spare drives?
		</listitem>
		<listitem>
How much money do you have available to spend?  Are you counting the
amount of time it will take you to keep a cluster filesystem running and
stable as compared to the relatively troublefree NAS boxes (assuming you
don't undersize it)?
		</listitem>
	</orderedlist>
	<para>
In terms of complete disaster recovery:
	</para>
	<orderedlist>
		<listitem>
How long does it take to backup a complete cluster fs?
		</listitem>
		<listitem>
How long does it take to backup a NAS?
		</listitem>
		<listitem>
How long would it take to rebuild and restore a cluster if half of
the machines died all at once?  If all of the machines died at once?
		</listitem>
		<listitem>
How long would it take to rebuild and restore a NAS box if half of
the drives died all at once?  If all of the drives died at once?  If
both power supplies died at the same time?
		</listitem>
	</orderedlist>
	<para>
If you think that you'll never see any of these situations, you might be
lucky and never will, but my general experience with computer hardware 
is that things run very smooth for a very long time, and then something
hiccups hard and takes a bit of work to recover from.  I've also heard
mention that "Murphy was an optimist." :-)
	</para>
	<para>
If you can't tell, I'm of the opinion that a NAS will do more for you
than a cluster filesystem, but keep in mind that's also my comfort zone.
If I was daily into the inner workings of a cluster fs production
system, I might feel differently.
	</para>
	</section>
	<section id="cookies_and_url_rewriting">
	<title>load balancing and scheduling based on the content of the packet: Cookies, URL, file requested, session headers</title>
	<para>
Mar 2002: questions on these topics have come up in the context of
<xref linkend="LVS-HOWTO.persistent_connection"/>,
<xref linkend="LVS-HOWTO.L7_switch"/>,
<xref linkend="stateful_failover"/>
or cookie based routing (see <xref linkend="l7_intro"/>).
I've tried to collect it all here.
Make sure you read these other sections if you
are implementing cookies or URL rewriting.
	</para>
	<para>
LVS being an L4 switch does not have access
to the content of packets, only the packet headers.
So LVS doesn't know the URL inside the packet.
Even if it did, LVS would need an understanding of the http
protocol to inspect cookies or rewrite URL headers.
Often people think that an L7 Switch is the answer here.
However an L7 switch is slow and expensive.
If you have what looks to be an L7 problem,
you should see if there is a solution at the L4 level first
(see <xref linkend="L7_ratz"/>).
	</para>
	<para>
The short answer is that you can't use LVS to load balance based
on the content of the packet. In the case of http, there are other tools which
understand the content of http packets and you can use those.
	</para>
		<section id="cookie">
		<title>Cookies</title>
		<para>
Cookies are an application level protocol for maintaining client state
in the stateless http/https protocols.
Cookies are passed between servers and
clients which have http, https and/or database services.
For the cookie specification see
<ulink url="http://wp.netscape.com/newsref/std/cookie_spec.html">netscape site</ulink>.
When you sign in at Ebay, you receive a cookie.
You will still be signed in days later on the same screen,
even if you don't do anything with your screen/mouse/keyboard.  
		</para>
		<para>
A cookie is left on the disk of the client machine.
It's intrusive and can be used by the server to spy
on your shopping/surfing habits.
They are a security hazard and clients should turn them off.
There are other non-intrusive methods for maintaining state,
<emphasis>e.g.</emphasis> passing information to the client in the URL
with url rewriting or session management using
<ulink url="http://www.php.net/">php</ulink>.
However many sites require you to allow cookies.
Make sure you set your browser to flush your cookies when it exits.
		</para>
		<para>
		<note>
Joe: Feb 2004. I thought having the client's data in the URL was a good idea
till I talked to people at OLS,
when I find that this method can't be used,
as the client's data is visible
to and alterable by the client and hence isn't secure.
		</note>
		</para>
		<para>
Although initially designed as a helpful tool,
the only use for cookies now is information gathering by the server
(it's like having your pocket picked while window shopping).
		</para>
		<para>
Being a layer 4 switch, LVS doesn't inspect the content of packets and
doesn't know what's in them. A cookie is contained in a packet and
the packet looks just like any other packet to an LVS.
		</para>
		<para>
If you're asked to setup an LVS infront of cookie dependant webservers, you
will need to turn on persistence so that the client will be guaranteed
of connecting to the same realserver.
		</para>
		<para>
Eric Brown wrote:
		</para>
		<blockquote>
Can LVS in any of its modes be configured to support cookie based persistent
sessions?
		</blockquote>
		<para>
Horms <emphasis>horms (at) vergenet (dot) net</emphasis> 3 Jan 2001
		</para>
		<para>
No. This would require inspection of the TCP data section, and infact an
understanding of HTTP. LVS has access only to the TCP headers.
		</para>
		<para>
valery brasseur
		</para>
		<blockquote>
I would like to to load balancing based on cookie and/or URL,
		</blockquote>
		<para>
Wensong
		</para>
		<para>
Have a look at http://www.LinuxVirtualServer.org/docs/persistence.html :-)
		</para>
		<para>
matt <emphasis>matt (at) paycom (dot) net</emphasis>
		</para>
		<blockquote>
I have run into a problem with the persistant connection flag, I'm
hoping that someone can help me. First off, I don't think there is
anything like this out now, but, is there anyway to load-balance via
URL? Such as http://www.matthew.com being balanced among 5 servers
without persistant connections turned on, and
http://www.matthew.com/dynamic.html being flagged with persistance?
Second question is this; I don't exactly need a persistant connection,
but I do need to make sure that requests from a particular person
continue to go to the same server. Is there any way to do this?
		</blockquote>
		<para>
James CE Johnson <emphasis>jcej (at) tragus (dot) org</emphasis> Jul 2001
		</para>
		<para>
We ran into something similar a while back.  Our solution was to create a simple
Apache module that pushes a cookie to the browser the when the "session" begins
(<emphasis>e.g.</emphasis> -- when no cookie exists).
The content of the cookie is some indicator of the realserver.
On the second and subsequent requests the Apache module sees
the cookie and uses the Apache proxy mechanism to forward the request to the
appropriate realserver and return the results.
		</para>
		</section>
		<section id="http_mod_proxy">
		<title>Forwarding an httpd request based on file name (mod_proxy, mod_rewrite)</title>
		<para>
Sean, 25 Dec 2000
		</para>
		<blockquote>
I need to forward request using the Direct Routing method to a server.
However I determine which server to send the request to depending on the
file it has requested in the HTTP GET not based on it's load.
		</blockquote>
		<para>
Michael E Brown
		</para>
		<para>
Use LVS to balance the load among several servers
set up to reverse proxy your realservers,
set up the proxy servers to load balance to
realservers based upon content.
		</para>
		<para>
Atif Ghaffar <emphasis>atif (at) 4unet (dot) net</emphasis>
		</para>
		<para>
On the LVS servers you can run apache with mod_proxy compiled in, then
redirect traffic with it.
		</para>
<programlisting><![CDATA[
Example

        ProxyPass /files/downloads/ http://internaldownloadserver/ftp/
        ProxyPass /images/ http://internalimagesserver/images/
]]></programlisting>
		<para>
<ulink url="http://www.linuxfocus.org/English/March2000/article147.html">
Proxy pass</ulink>,
or you can use mod_rewrite, in that case, your realservers should be
reachable from the net.
There is also a
<ulink url="http://www.stevek.com/projects/mod_tproxy/">
transparent proxy module for apache</ulink>.
		</para>
		<para>
Yan Chan <emphasis>ychan (at) ureach (dot) com</emphasis>
19 Aug 2003
		</para>
		<blockquote>
My ipvs is set up right and everything.  I set the VIP's address
of port 80 to forward to my Real Web Servers.  I then set port
90 to another Web Server with different stuff in it.  My problem
is when i try to access the page for port 80, www.abc.com, the
web page shows fine.  In order for me to access the page in port
90, i have to type www.abc.com:90.  As you can see, it doesnt
look elegant.  Is there a way to change it so i can make it
www.abc.com/ipvs equal to www.abc.com:90?  like the rewrite rule
in apache?  I tried using apache in the loadbalancer. But it
doesnt seen to work.
		</blockquote>
		<para>
Stephen Walker <emphasis>swalker (at) walkertek (dot) com</emphasis>
19 Aug 2003
		</para>
		<para>
This is how I set up my reverse proxy in apache:
		</para>
<programlisting><![CDATA[
    ProxyRequests Off
    RewriteEngine On

    ProxyPass /perl http://www.abc.com:8080/perl

    RewriteRule (^.*\.pl) http://www.abc.com:8080$1 [proxy,last]
    RewriteRule (^.*\.cgi) http://www.abc.com:8080$1 [proxy,last]

    ProxyPassReverse / http://www.abc.com:8080/
    ProxyReceiveBufferSize 49152
]]></programlisting>
		<para>
The ProxyPass rule says everything that goes to /perl is forwarded to
port 8080, the Rewrite rules take care of scripts ending in .pl or .cgi.
Obviously you need to have the rewrite and proxy modules running on your
apache server.
		</para>
		<para>
Randy Paries 4 Feb 2004
		</para>
		<blockquote>
I want to loadbalance based on file names. I want
<programlisting><![CDATA[
http://www.mydomain.com/a/ to go to realserver_1
http://www.mydomain.com/b/ to go to realserver_2
]]></programlisting>
		</blockquote>
		<para>
Dave Lowenstein
		</para>
		<para>
You could try apache's <filename>mod_rewrite</filename>.
		</para>
		<para>
Horm's
		</para>
		<para>
Actually I think <filename>mod_proxy</filename> would probably be the right choice.
Though this could be combined with <filename>mod_rewrite</filename>. Actually,
it would be pretty trivial me thinks.
		</para>
		<para>
Viperman  Aug 23, 2003
		</para>
		<blockquote>
I'm successfully using LVS with a reverse proxy configuration in apache,
everything working just fine.
I just faced a problem, when a user is trying to read the client IP address
using PHP with the $_SERVER['REMOTE_ADDR'] variable.
My RIP is showing up in place of the CIP.
		</blockquote>
		<para>
Horms <emphasis>horms (at) verge (dot) net (dot) au</emphasis> 24 Aug 2003
		</para>
		<para>
I believe that when proxies are involved you need to check variables
other than REMOTE_ADDR, which will generally be the IP address
of the proxy, as this is acting as an end-user of sorts.
See <ulink url="http://www.php.net/getenv">http://www.php.net/getenv</ulink>
		</para>
		<para>
In any case the problem should not be caused by LVS as it does
not change the source IP address nor the HTTP headers (or body).
		</para>
		</section>
		<section id="rewriting_url_headers">
		<title>Rewriting URL headers</title>
		<para>
alex (at) short (dot) net
		</para>
		<blockquote>
		<para>
We have 4 distict sites, all being virtual
hosted and load balanced by a single VIP.
Namevirtualhosts in apache picks the right content
dependent on the host header.  This works great for
those distict sites and their corresponding domains.
		</para>
		<para>
Problem is that we now have 25 domains to point to
distict site 1 and 25 domains pointing to distinct site
2. Right now the nameserver entries are www CNAME
www.domain.com for all of those domains
<emphasis>i.e.</emphasis>
distinct sites
		</para>

<programlisting><![CDATA[
www.a.com
www.b.com
www.c.com
www.d.com
]]></programlisting>
		<para>
I want
		</para>
<programlisting><![CDATA[
www.a1.com -> www.a.com
www.a2.com -> www.a.com
etc
.
.
www.b1.com -> www.b.com
]]></programlisting>
		<para>
I'd rather not fill my httpd conf with all these
domains.  I was either hoping that LVS can do some host
header modifications or I'll have to make 4 VIP and
each site have a distinct external ip.
		</para>
		</blockquote>
		<para>
Jacob Coby <emphasis>jcoby (at) listingbook (dot) com</emphasis> 19 Feb 2003
		</para>
		<para>
LVS sits too low to handle munging the HTTP headers.
Check out ServerAlias
(http://httpd.apache.org/docs-2.0/mod/core.html#serveralias), I think it
will do pretty much exactly what you want it to do with a minimal of fuss.
It's available in 1.3.x and 2.x, I only link to the 2.0 docs since they look
better.
		</para>
		<para>
You could even stick the aliases in another file (a_aliases.conf or
whatever) and include that into the VirtualHost section of Site A.  The only
real "problem" with this setup is that you have to bump apache (you can use
'apachectl graceful' if you don't have SSL) everytime you add a new alias or
aliases.
		</para>
		<para>
Magnus Nordseth <emphasis>magnun (at) stud (dot) ntnu (dot) no</emphasis>
Thu, 20 Feb 2003 18:07:17 +0100
		</para>
		<para>
If the hosts have almost identical configuration (in apache) you can use
<ulink url="http://httpd.apache.org/docs-2.0/vhosts/mass.html">dynamic virtual hosting</ulink>
		</para>
		</section>
		<section id="http_url_parsing">
		<title>URL parsing</title>
		<para>
unknown
		</para><para>
Is there any way to do URL parsing for http requests (ie send cgi-bin
requests to one server group, static to another group?)
		</para>
		<blockquote>
		<para>
John Cronin <emphasis>jsc3 (at) havoc (dot) gtf (dot) org</emphasis> 13 Dec 2000
		</para><para>
Probably the best way to do this is to do it in the html code itself;
make all the cgis hrefs to cgi.yourdomain.com.
Similarly,
you can make images hrefs to image.yourdomain.com. You then
set these up as additional virtual servers, in addition to your www
virtual server.  That is going to be a lot easier than parsing URLs;
this is how they have done it at some of the places I have done
consulting for; some of those places were using Extreme Networks load
balancers, or Resonate, or something like that, using dozens of Sun
and Linux servers, in multiple hosting facilities.
		</para>
		</blockquote>

		<para>
Horms
		</para>
		<blockquote>
		<para>
What you are after is a layer-7 switch, that is something that can
inspect HTTP packets and make decisions bassed on that information.
You can use squid to do this, there are other options. A post was made
to this list about doing this a while back. Try hunting through the
archives.
		</para><para>
LVS on the other hand is a layer-4 switch, the only information that it has
available to it is IP address and port and protocol (TCP/IP or UDP/IP). It
cannot inspect the data segment and see even understand that the request is
an HTTP request, let alone that the URL requested is /cgi-bin or whatever.
		</para><para>
There has been talk of doing this, but to be honest it is a different
problem to that which LVS solves and arguably should live in user space
rather than kernel space as a _lot_ more proccessing is required.
		</para>
		</blockquote>
		</section>
		<section id="session_headers">
		<title>session headers</title>
		<para>
Torvald Baade Bringsvor Dec 05, 2002
		</para>
		<blockquote>
We have a setup with two reverse proxies, two frontends and two backend
application servers. Usually we just use LVS to switch between the proxies,
and then establish a direct mapping from each of the reverse proxies onto an
application server. But now I am wondering if it is possible to use LVS to
switch between the two frontends and the two backends as well, in other
words to cluster the frontends and backends. Regular persistence doesn't
work here, because (as far as the backends are concerned) all the traffic
comes from just two addresses. It would be really nice to be able to inspect
the session ID (which is contained in the http header of the requests) and
route the request based on that. But is it possible? Has anybody done this?
		</blockquote>
		<para>
Horms 10 Mar 2003
		</para>
		<para>
Unfortunately LVS does not have access to the session header
so this information cannot be used for load balancing.
		</para>
		</section>
                <section id="scheduling_by_content">
                <title>Scheduling by packet content</title>
                <para>
Horms 07 May 2004
                </para>
                <para>
It would be nice to be able to use
KTCPVS-like shedulers that make use of L7 information inside LVS,
but there are major problems.
In terms of TCP the problem is that LVS wants to schedule the connection
when the first packet arrives. However, to get L7 information you need
the three way handshake to have completed.
I guess this would be possible if LVS itself handled the three-way
connection, and then buffered up the packets in the established state
until enough L7 information had been collected to schedule a given
connection. But I suspect this really would be quite painful.
                </para>
                </section>
	</section>
	<section id="tcpip_idle_timeout" xreflabel="tcpip idle timeout">
	<title>Timeouts for TCP/UDP connections to services</title>
	<note>
Sometime in 2008: LVS, as originally written, 
would timeout connections between client and server,
independently of whether the connection itself wanted to be timed out.
The timeout was short enough that people setting up a new LVS would find their sessions
disconnected, without knowing why.
Expect that sometime soon, that the timeouts will be changed to match those in netfilter.
	</note>
	<para>
This is part of an off-line discussion on why the timeouts shouldn't be set to infinity.
	</para>
	<para>
Graeme Fowler <emphasis>graeme (at) graemef (dot) net</emphasis> 23 Dec 2008
	</para>	
	<para>
Although it is (theoretically, at least, and I'll have to check the TCP
RFC for this) possible to write an app which does the three-way
handshake and then holds the connection open without exchanging any
further packets for a long time (for some value of "long"), in the case
of ip_vs this could result in resource starvation on highly loaded
systems.
	</para>
	<para>
ip_vs is essentially a man in the middle (albeit a nice one) which has some knowledge
about the transactions in progress at TCP level. If we set the timeout
to 0/infinity, then under some conditions (say broken networks, BGP
peerings dropping, or - ooh, topical - multiple undersea fibres being
severed) the director will be left with a table stuffed full of
"tracked" connections (I use the term carefully, noting the similarity
to netfilter's conntrack modules) which never go away unless a FIN/RST
turns up.
	</para>
	<para>
If that/those packet/s never arrive, the director will have an
ever-increasing number of connections in the table. Under circumstances
where there's a high turnover of connections (100,000/sec, for example,
which is deliberately high for illustrative purposes) even 0.0001% of
connections getting into that state would result in the following:
	</para>
<programlisting><![CDATA[
  100000  conns/sec
  0.0001  % never closed
     0.1  conns/sec "stalled"

   86400   secs/day
    8640   conns/day "stalled"
]]></programlisting>
	<para>
Assuming a well-managed, not-interfered-with director that would give us
3153600 "stalled" connections in a year of uptime. OK, so that may be
far-fetched for some people *but* it's perfectly plausible in terms of
embedded systems.
	</para>
	<para>
And embedded systems often don't have much RAM - and that's the killer
factor here. Low RAM means little space for the hash table, and if the
hash tables fills up we stop routing (I presume, unless it FIFOs entries
out or does some other non-time-related scavenging).
	</para>
	<para>
I see Horms commented similarly, but without numbers... now let me look
at RFC 793 and what it says...
	</para>
	<blockquote>
"The timeout, if present, permits the caller to set up a timeout for all
data submitted to TCP.  If data is not successfully delivered to the
destination within the timeout period, the TCP will abort the
connection.  The present global default is five minutes."
	</blockquote>
	<para>
It doesn't specify upper or lower bounds, so it looks like infinity is
(technically) possible. Note however that lots of firewall devices, NAT
boxes and so on will drop them anyway - Cisco PIX and ASA, Checkpoint
devices have a 24 hour default; netfilter's conntrack modules have a
default 5 day TCP session timeout for established connections. For more
netfilter goodness, see:

<filename>/proc/sys/net/netfilter/</filename>

There are lots of sysctl goodies in there!
	</para>
	<para>
Why not, as <filename>ip_vs</filename> is linked so
closely to netfilter, make use of the same sysctls?
	</para>
	<para>
Horms
	</para>
	<para>
I'm not sure how it would work in practice - perhaps some people
would want to tune LVS and netfilter separately - but at the
very least we could use the same default.
	</para>
	<note>Feb 2003:
The timeout information is now in man(8) ipvsadm.
	</note>
		<section id="2.2_kernels">
		<title>2.2 kernels</title>
		<para>
Julian, 28 Jun 00
		</para>
		<para>
LVS uses the default timeouts for idle connections set by
MASQ for (EST/FIN/UDP) of 15,2,5 mins (set in /usr/src/linux/include/net/ip_masq.h).
These values are fine for ftp or http,
but if you have people sitting on a LVS telnet connection,
they won't like the 15min timeout.
You can't read these timeout values,
but you can set them with ipchains.
The format is
		</para>
<programlisting><![CDATA[
$ipchains -M -S tcp tcpfin udp
]]></programlisting>
		<para>
Wensong Aug 2002
		</para>
		<blockquote>
		<para>
for 2.4 kernels
		</para>
<programlisting><![CDATA[
director:/etc/lvs# ipvsadm --set tcp tcpfin udp
]]></programlisting>
		</blockquote>
		<para>
example:
		</para>
<programlisting><![CDATA[
$ipchains -M -S 36000 0 0
]]></programlisting>
		<para>
sets the timeout for established connections to 10hrs.
The value "0" leaves the current timeout unchanged,
in this case FIN and UDP.
		</para>
		</section>
		<section id="2.4_kernels">
		<title>2.4 kernels</title>
		<para>
Julian Anastasov <emphasis>ja (at) ssi (dot) bg</emphasis> 31 Aug 2001
		</para><para>
The timeout is set by ipvsadm.
Although this feature has been around for a while,
it didn't work till <command>ipvsadm</command> 1.20 (possibly 1.19) and ipvs-0.9.4
(thanks to Brent Cook for finding this bug).
		</para>
<programlisting><![CDATA[
$ipvsadm --set tcp tcpfin udp
]]></programlisting>
		<para>
	The default timeout is 15 min for the LVS connections
in established (EST) state.
For any NAT-ed client connections, ask iptables.
		</para><para>
To set the tcp timeout to 10hrs, while leaving tcpfin and udp timeouts unchanged,
do
		</para>
<programlisting><![CDATA[
#ipvsadm --set 36000 0 0
]]></programlisting>
		<para>
Brent Cook <emphasis>busterb (at) mail (dot) utexas (dot) edu</emphasis> 31 Aug 2001
		</para>
		<blockquote>
			<para>
I found the relevant code in the
kernel to modify this behavior in 2.4 kernels without using ipchains.
I got this info from
http://www.cs.princeton.edu/&#126;jns/security/iptables/iptables_conntrack.html
In /usr/src/linux/net/ipv4/netfilter/ip_conntrack_proto_tcp.c , change
TCP_CONNTRACK_TIME_WAIT to however long you need to wait before a tcp
connection timeout.
			</para><para>
Does anyone foresee a problem with other tcp connections as a result of this? 
A regular tcp program will probably close the connection anyway.
			</para>
<programlisting><![CDATA[
static unsigned long tcp_timeouts[]
= { 30 MINS,    /*      TCP_CONNTRACK_NONE,     */
    5 DAYS,     /*      TCP_CONNTRACK_ESTABLISHED,      */
    2 MINS,     /*      TCP_CONNTRACK_SYN_SENT, */
    60 SECS,    /*      TCP_CONNTRACK_SYN_RECV, */
    2 MINS,     /*      TCP_CONNTRACK_FIN_WAIT, */
    2 MINS,     /*      TCP_CONNTRACK_TIME_WAIT,        */
    10 SECS,    /*      TCP_CONNTRACK_CLOSE,    */
    60 SECS,    /*      TCP_CONNTRACK_CLOSE_WAIT,       */
    30 SECS,    /*      TCP_CONNTRACK_LAST_ACK, */
    2 MINS,     /*      TCP_CONNTRACK_LISTEN,   */
};
]]></programlisting>
			<para>
In the general case you cannot change the settings at the client.
If you have access to the client, you can you can arrange
for the client to send keepalive packets often enough to reset
the timer above and keep the connection open.
			</para>
		</blockquote>
		<para>
Kyle Sparger <emphasis>ksparger (at) dialtone (dot) com</emphasis>> 5 Oct 2001
		</para>
		<para>
You can address this from the client side by reducing the tcp
keepalive transmission intervals.
Under Linux, reduce it to 5 minutes:
		</para>
<programlisting><![CDATA[
echo 300 > /proc/sys/net/ipv4/tcp_keepalive_time
]]></programlisting>
		<para>
where '300' is the number of seconds.
I find this useful in all manner of situations where the OS times out
connections.
		</para>
		</section>
		<section id="2.6_kernels">
		<title>udp flush bug in early 2.6 kernels</title>
		<para>
Ashish Jain
		</para>
		<blockquote>
			<para>
 The load balancer works fine the way I expected for one one thing:
 Sometimes after heavy load surge (500 UDP packets per sec. on the same 
 connection) , the output of <command>ipvsadm -l -c</command> shows active UDP connections 
 even if there is no traffic and I stop sending any UDP packets.
 In <command>ipvsadm</command>, the default UDP connection timout is set to 300 sec (I did 
 not change that. I did not even use persistant flag). I expect these 
 connections to go away after 300 seconds. But after the 300 sec timer 
 expires, it gets reset to 60 sec and these active UDP connectiosn stay 
 forever. What could be the reason?
 I have noticed from the ip_vs code (<filename>ip_vs_conn.c</filename>) that there are 2 
 functions implemented to expire a connection:
 <filename>ip_vs_conn_expire</filename> (This one resets the timer to 60*Hz if the reference 
 count for this connection is greater than 1 or these is error deleting 
 connection from hash tab)
 <filename>ip_vs_conn_expire_now</filename> (Deletes the connection immediately)
 The function called after timer expires is <filename>ip_vs_conn_expire</filename> and not the 
 second one. Why is this so?
			</para>
		</blockquote>
		<para>
Horms 27 Oct 2005
		</para>
		<para>
This is a bug, I believe it was fixed in 2.6.13.4
		</para>
		<blockquote>
How can I turn on debugging for ip_vs?
		</blockquote>
		<para>
You need to enable IP_VS_DEBUG at compile time, and then
fiddle the debug proc value in <filename>/proc/sys/net/ipv4/vs</filename> at run time.
		</para>
		</section>
	</section>
	<section id="name_resolution" xreflabel="name resolution">
	<title>name resolution on realservers: running name resolution friendly demons on realservers</title>
	<para>
Unless the realserver is in a <xref linkend="3-Tier_lvs"/> LVS,
it is just sending packets from the VIP to the CIP and doesn't
need name resolution.
	</para>
	<para>
The realservers however run services other than just the LVS services,
<emphasis>e.g</emphasis> smtp to mail logs and cron output.
The smtpd should only need <filename>/etc/hosts</filename> to
send mail locally.
I upgraded from <command>sendmail</command> to <command>postfix</command>
on one of my realservers to find that I could no longer mail to
or from the upgraded machine.
The problem is that
<ulink url="http://www.postfix.org/">postfix</ulink>
(http://www.postfix.org/)
requires DNS for name resolution, thus requiring a nameserver.
Postfix couldn't deliver mail on my realserver,
as there was no resolution
for the private realserver names (which have private IPs).
Thus to run postfix, you need also to run DNS.
This adds the security complications of punching
a hole in your filter and routing rules to get to port 53 on other machines.
Postfix works fine on a machine delivering mail to users on the internet
and where the hostname is publically known,
but doesn't work for machines on a private network with no DNS running.
	</para>
	<para>
A little later, I found that you can turn off DNS lookups in postfix
(see <ulink url="http://www.postfix.org/faq.html">postfix faq</ulink>,
look for "resolv").
However this doesn't get you much -
now you need to do everything via <filename>/etc/hosts</filename>.
You can't use <filename>/etc/hosts</filename> for local machines
and <filename>/etc/resolv.conf</filename> for the occasional
machine that's not on the localnetwork.
	</para>
	<para>
With (the earlier versions of) sendmail,
you can have a nameserver in <filename>/etc/resolv.conf</filename> where it will
only be used for hosts not in <filename>/etc/hosts</filename>.
You don't want to be running postfix on a realserver just for local mail.
If you run sendmail only for local mail delivery,
then you only need an <filename>/etc/hosts</filename> file.
	</para>
	<note>
Jan 2004: just installed <filename>sendmail-8.12.10</filename>.
It's been "improved" and now requires DNS for all addresses, including private addresses.
It doesn't look at <filename>/etc/hosts</filename>.
You can turn off DNS lookups by telling <command>sendmail</command>
to look at <filename>/etc/service.switch</filename> (ignoring
the already available <filename>/etc/host.conf</filename>
and <filename>nsswitch.conf</filename>),
where you can tell it to look at <filename>/etc/hosts</filename>
but now it will not use DNS.
This is a step backwards for <command>sendmail</command>.
	</note>
	<para>
From the TriLUG mailing list:
Tanner Lovelace <emphasis>clubjuggler (at) gmail (dot) com</emphasis> 26 Apr 2007 
	</para>
	<blockquote>
	<para>
Postfix is a mail transport agent and therefore by design
does not lookup A records.  Instead it looks up MX records.
Note that <filename>/etc/hosts</filename> does not contain MX records, 
so it is therefore appropriate that postfix not look there.  
However, it is possible to make postfix look for both A records and
use <filename>/etc/hosts</filename>.  
This postfix config line will make postfix use <filename>/etc/hosts</filename>:
	</para>
<programlisting><![CDATA[
disable_dns_lookups = yes
]]></programlisting>
	<para>
For more information about this see this URL:
http://www.postfix-jp.info/origdocs/QandA-en.html#4.10
	</para>
	</blockquote>
	<para>
The facilities for nameresolution on Linux are problematic.
I had assumed that when an application asked for name resolution,
that local facilities (<filename>libresolve.so</filename>?)
handled the request (gethostbyname, gethostbyaddr?)
using whatever resources were available
(in <filename>/etc/nsswitch.conf</filename> <filename>/etc/host.conf</filename>)
and the application accepted the result without knowing how the name was resolved
(<emphasis>e.g.</emphasis> whether in <filename>/etc/hosts</filename>, NIS  or DNS).
	</para>
	<para>
This isn't what happens - the application has to do it all.
If you watch <command>ping</command> deliver a packet to a remote machine,
whose name is not in <filename>/etc/hosts</filename>,
	</para>
<programlisting>
<![CDATA[
`strace ping -c 1 remote_machine > strace.out 2>&1 `
]]>
</programlisting>
	<para>
you see <command>ping</command> access files in this order
	</para>
<programlisting><![CDATA[
/etc/nsswitch.conf
/etc/protocols
/etc/resolv.conf
/etc/host.conf
/etc/hosts
]]></programlisting>
	<para>
and then finally connect to the dns port (53) on the first nameserver in
<filename>/etc/resolv.conf</filename>.
	</para>
	<para>
It turns out there is no "resolving facility".
The application has to work its way through
all these files and then handle the name resolution itself.
Ping appears to be using a "resolving facility", but only because it
goes through all the files in <filename>/etc</filename>
searching in the order you'd expect for a "resolving facility".
Applications can ignore these files and do whatever they want.
<command>nslookup</command> doesn't look at
<filename>/etc/hosts</filename>, but goes straight to DNS.
Postfix also connects directly to DNS.
	</para>
	<para>
I'm a little dissappointed to find that every application writer has
to handle name resolution themselves.
For postings on the topic where other people have been similary disabused
of their ignorance on name resolution,
do a google search on
<filename>/etc/hosts</filename>,
<filename>/etc/host.conf</filename>,
<filename>/etc/resolv.conf</filename>,
<command>gethostbyname</command>,
<command>nslookup</command>
and throw in "postfix" for more info on the postfix part of the problem.
<emphasis>e.g.</emphasis> the neohapsis archives for
<ulink url="http://archives.neohapsis.com/archives/postfix/2001-01/1638.html">postfix</ulink>
and
<ulink url="http://archives.neohapsis.com/archives/openbsd/2001-06/0360.html">openbsd</ulink>.
	</para>
	<para>
For info on setting up
<filename>/etc/hosts</filename>,
<filename>/etc/nsswitch.conf</filename>,
<filename>/etc/host.conf</filename> see
<ulink url="http://www.tldp.org/HOWTO/Net-HOWTO/">network HOWTO</ulink>
(http://www.tldp.org/HOWTO/Net-HOWTO/).
	</para>
	<para>
For an MTA on realservers with private RIPs, neither <command>postfix</command>
nor <command>sendmail</command> are suitable
(although you may have to use them).
An older version of <command>sendmail</command> should be fine.
	</para>
	<para>
From the TriLUG mailing list:
Tanner Lovelace <emphasis>clubjuggler (at) gmail (dot) com</emphasis> 26 Apr 2007 
	</para>
	<blockquote>
		<para>
nslookup is a tool that
previously came with the name server (and is now
deprecated in favor of dig, which is also a dns testing
tool). nslookup was written specifically
to test DNS resolution and therefore it is perfectly valid
that it not check local files.
		</para>
		<para>
You have to take the context of what the application
is looking for.  
The <filename>/etc/hosts</filename> file only provides names and
IP addresses.  
Postfix, by default, isn't looking for that.  
It's looking for MX records.  
The programs <command>nslookup</command>, <command>dig</command>, 
and <command>host</command>
are all tools written to test and debug the DNS system.  
It would be wrong for them to look in <filename>/etc/hosts</filename>, 
since it is not part of the DNS system.  
For most applications, though,
that only look for IP addresses (A records) or hostnames (PTR
records), looking in <filename>/etc/hosts</filename> is appropriate, 
and in fact, this is what the <command>gethostbyname</command> and <command>gethostbyipaddr</command> 
system calls do.  
Anything that uses the <command>gethostbyname</command> system
call does follow what is in <filename>/etc/nsswitch.conf</filename>.  
For instance, with this line in <filename>nsswitch.conf</filename>
		</para>
<programlisting><![CDATA[
hosts:          files dns
]]></programlisting>
		<para>
If I run ping www.trilug.org and examine what files it opens I get this:
		</para>
<programlisting><![CDATA[
open("/etc/ld.so.preload", O_RDONLY)    = -1 ENOENT (No such file or directory)
open("/etc/ld.so.cache", O_RDONLY)      = 3
open("/lib/tls/i686/cmov/libc.so.6", O_RDONLY) = 3
open("/etc/nsswitch.conf", O_RDONLY)    = 3
open("/etc/ld.so.cache", O_RDONLY)      = 3
open("/lib/libnss_db.so.2", O_RDONLY)   = 3
open("/lib/tls/i686/cmov/libnss_files.so.2", O_RDONLY) = 3
open("/usr/lib/libdb3.so.3", O_RDONLY)  = 3
open("/var/lib/misc/protocols.db", O_RDWR|O_LARGEFILE) = -1 ENOENT (No such file or directory)
open("/var/lib/misc/protocols.db", O_RDONLY|O_LARGEFILE) = -1 ENOENT (No such file or directory)
open("/etc/protocols", O_RDONLY)        = 3
open("/etc/resolv.conf", O_RDONLY)      = 4
open("/etc/host.conf", O_RDONLY)        = 4
open("/etc/hosts", O_RDONLY)            = 4
open("/etc/ld.so.cache", O_RDONLY)      = 4
open("/lib/tls/i686/cmov/libnss_dns.so.2", O_RDONLY) = 4
open("/lib/tls/i686/cmov/libresolv.so.2", O_RDONLY) = 4
]]></programlisting>
		<para>
Note that it does go to <filename>/etc/hosts</filename> first, 
as specified by <filename>nsswitch.conf</filename>.
If I then change the line in <filename>nsswitch.conf</filename> to be this instead:
		</para>
<programlisting><![CDATA[
hosts:          dns
]]></programlisting>
		<para>
and rerun the same test I get this:
		</para>
<programlisting><![CDATA[
open("/etc/ld.so.preload", O_RDONLY)    = -1 ENOENT (No such file or directory)
open("/etc/ld.so.cache", O_RDONLY)      = 3
open("/lib/tls/i686/cmov/libc.so.6", O_RDONLY) = 3
open("/etc/nsswitch.conf", O_RDONLY)    = 3
open("/etc/ld.so.cache", O_RDONLY)      = 3
open("/lib/libnss_db.so.2", O_RDONLY)   = 3
open("/lib/tls/i686/cmov/libnss_files.so.2", O_RDONLY) = 3
open("/usr/lib/libdb3.so.3", O_RDONLY)  = 3
open("/var/lib/misc/protocols.db", O_RDWR|O_LARGEFILE) = -1 ENOENT (No such file or directory)
open("/var/lib/misc/protocols.db", O_RDONLY|O_LARGEFILE) = -1 ENOENT (No such file or directory)
open("/etc/protocols", O_RDONLY)        = 3
open("/etc/resolv.conf", O_RDONLY)      = 4
open("/etc/ld.so.cache", O_RDONLY)      = 4
open("/lib/tls/i686/cmov/libnss_dns.so.2", O_RDONLY) = 4
open("/lib/tls/i686/cmov/libresolv.so.2", O_RDONLY) = 4
open("/etc/host.conf", O_RDONLY)        = 4
]]></programlisting>
		<para>
Note that it does not look in <filename>/etc/hosts</filename>.
It isn't ping that's searching these files, 
it's <command>gethostbyname</command> 
in the C library calling into <filename>libnss_*</filename>.
The <filename>libnss</filename> libraries are the resolver.
		</para>
		<para>
I agree that there should be tools other than DNS debugging tools.  
Kevin suggested probably the best one:
		</para>
<programlisting><![CDATA[
% getent hosts {hostname}
]]></programlisting>
		<para>
This will correctly use the linux name resolving functions and
follow what has been set up in <filename>nsswitch.conf</filename>.
		</para>
	</blockquote>
	<para>
TriLUG mailing list:
<emphasis>jason (at) monsterjam (dot) org</emphasis> 26 Apr 2007 
	</para>
	<para>
A very easy way to do what you want is to install <command>dnsmasq</command>.
It will allow you to treat your <filename>/etc/hosts</filename>
as dns entries to your server AND clients.
I think the -b flag will do what you want.
	</para>
<programlisting><![CDATA[
release 0.991 Added -b flag: when set causes dnsmasq to always answer
              reverse queries on the RFC 1918 private IP space itself and
              never forward them to an upstream server. If the name is not in
              /etc/hosts, dnsmasq replies with the dotted-quad address.
]]></programlisting>
	</section>
	<section id="debugging_services">
	<title>Debugging new services</title>
	<para>
At some stage trying to LVS a service that works just fine when you connect
directly to the realserver, 
but doesn't work when you connect to the same service through the director. 
There is something about the service that you've taken for granted or may
not even be aware of, and that assumption doesn't hold when the two-way
tcpip connection is spread amongst 3 machines (adding the director).
It will probably be because the service
	</para>
	<itemizedlist>
		<listitem>
uses multiple ports. The multiport problem can be solved by persistence to port 0.
This isn't a particularly subtle approach, but will at least get your service working.
		</listitem>
		<listitem>
requires multiple rounds of tcpip connections.
This can be solved by persistence to the service's port,
when all connections will go to the same realserver.
		</listitem>
		<listitem>
writes to the realserver
(see <link linkend="many_reader_single_writer">Filesystems for realserver content</link>).
		</listitem>
		<listitem>
something we don't know about or you've just plain messed up.
		</listitem>
	</itemizedlist>
	<para>
In this case you'll need brute force.
	</para>
	<itemizedlist>
		<listitem>
run tcpdump on the client and server (<emphasis>i.e.</emphasis> without a director,
and not using an LVS) to see the packet exchanges when the service is working.
Then connect up the LVS (make sure that it's working by testing say telnet as an LVS'ed
service), then run tcpdump on the client, director (both NICs if a 2 NIC director)
and the realservers. This will be tedious.
		</listitem>
		<listitem>
If you know the service's protocol (test with just the client and server, <emphasis>i.e.</emphasis>
with no LVS), you can work your way through the connection with
<xref linkend="phatcat"/>. For example sessions of phatcat with a
2 port protocol, see the section on <xref linkend="ftp"/>.
		</listitem>
	</itemizedlist>
	</section>
	<section id="broken_services">
	<title>"broken" services:servlets and j2ee</title>
	<para>
Here, Ratz is replying to a poster about his problems LVS'ing a website with servlets.
The servelets are writing content to different realservers from the same client.
This is normally handled by persistence.
	</para>
	<para>
Roberto Nibali <emphasis>ratz (at) tac (dot) ch</emphasis> 10 Jul 2003
	</para>
	<para>
You have a broken :) service which you would like to load balance with persistence.
	</para>
	<para>
Joe
	</para>
	<blockquote>
How do you handle broken services? How would you design the
service not to be broken?
	</blockquote>
	<para>
I don't know how I shall answer this question. I hope his service is not broken.
But how do you understand his problem? It should be solved by setting up port 0
service, right?
	</para>
	<para>
Sometimes things have to be done in a more complex way. The only thing that they
shouldn't do is migrate sessions within the realserver pool for CPU load
sharing, as is not uncommon for servlet technology. If they do this, they need
to have a common pool for allocated resources (and thus have the process
migration overhead) which then again defeats the purpose of inter-node CPU load
balancing at first hand. But we do not know what exactly he's trying to come up
with.
	</para>
	<para>
Another possibility would be to set up persistent fwmark pools consisting of a
mark for incoming to service:80 and the same mark for incoming to
service:defined_portrange. With the System.Properties in JDK you can set the
port range which will be allocated and thus you can pretty much restrict the
service fwmark pool. You then of course load balance the fwmark pool. I only
told him to use port 0 because he doesn't know the application so with higher
possibility he wouldn't know the dynamically opened ports of this application
either and therefor would not be able to restrict it accordingly.
	</para>
	<para>
Then again he could do something like:
	</para>
<programlisting><![CDATA[
iptables -t mangle -A PREROUTING -j MARK --set-mark 1 -p tcp -d ${VIP}/32 --dport 80
iptables -t mangle -A PREROUTING -j MARK --set-mark 1 -p tcp -d ${VIP}/32 --dport 1023:61000
ipvsadm -A -f 1 -s wlc -p 300 -M 255.255.255.255
ipvsadm -a -f 1 -r ${RIP1} -g -w 1
ipvsadm -a -f 1 -r ${RIP2} -g -w 1
[...]
]]></programlisting>
	<blockquote>
	<para>
Joao Clemente <emphasis>jpcl (at) rnl (dot) ist (dot) utl (dot) pt</emphasis> 24 Jun 2003
	</para>
	<para>
I've been talking with the developer of the j2ee app I'm trying to cluster,
and I guess I'll have a hard time with this feature:
	</para>
	<para>
After a user interaction with the web server, the user will dowload a
applet. That applet will comunicate with a service (in a well-known port)
that was started in the server (at that time).
	</para>
	<para>
So,  I see this problem coming:
	</para>
<programlisting><![CDATA[
At instance1:
Node1 gets the user http request, returns the html page, the applet, and
creates the service. Node2 knows nothing about this.

At instance2:
Applet connects to port xxx, gets round-robin to node2... bad
]]></programlisting>
	<para>
No matter what persistency rules I setup here, as I have 2 different ports
(80 and xxx) I see no way to say
"when user interacts with server, set persistency rule for yyy time that
maps user:80 to node1:80 AND ALSO user:whatever to node1:xxx"
	</para>
	<para>
Besides that, I also have another question: That service that is listening
in the server node will then give the connection to another instance, that
will control the connection from there on (there is a pool of instances
waiting to take over).
Will lvs route those connections, that it doesnt even know of?
I'm not sure, but this mechanism seems something similar to a passive-ftp
connection...
Maybe someone know a lvs-friendly tip to make things work. Btw, this applet
and the connection is used to allow
server->browser communication without using http refresh/pooling.
	</para>
	</blockquote>
	</section>
	<section id="http_logs">
	<title>http logs, error logs</title>
	<para>
The logs from the various realservers need to be merged.
	</para>
	<para>
From the postings below, at least in the period 2001-3,
using a common nfs filesystem doesn't
work and no-one knows whether this is a locking problem fixable
by NFS-v3.0 or not. The way to go seems to be
<ulink url="http://mergelog.sourceforge.net/">merglog</ulink>
	</para>
	<para>
Emmanuel Anne <emphasis>emanne (at) absysteme (dot) fr</emphasis>
	</para>
	<para>
..the problem about the logs. Apparently the best is to have
each web server process its log file on a local disk, and then
to make stats on both all files for the same period...
It can become quite complex to handle, is there not a way to
have only one log file for all the servers
	</para>
	<para>
Joe - (this is quite old <emphasis>i.e.</emphasis> 2000 or older and hasn't been tested).
	</para>
	<blockquote>
log to a common nfs mounted disk?
I don't know whether you can have httpds running on separate
machines writing to the same file. I notice (using truss on
Solaris) that apache does write locking on files while
it is running. Possibly it write-locks the log files. Normally
multiple forked httpds are running. Presumably each of them
writes to the log files and presumably each of them locks the
log files for writing.
	</blockquote>
	<para>
Webstream Technical Support <emphasis>mmusgrove (at) webstream (dot) net</emphasis> 18 May 2001
	</para>
	<para>
I've got 1 host and 2 realservers running apache(ver 1.3.12-25).
The 2nd server NFS exports a directory called /logs.
The 1st acts as a client and mounts that drive. I have apache on the 1st
card saving the access_log file for each site into that directory as
access1.log. The 2nd server saves it as access2.log in the same directory.
Our stats program on another server looks for *.log files in that directory.
The problem is that whenever I access a site (basically browse through all
the pages of a site), the 2nd card adds the access info into the access2.log
file and everything is fine. The 1st card saves it to the access1.log file
for a few seconds, then all of a sudden the file size goes down to 0 and its
empty.
	</para>
	<para>
Alois Treindl <emphasis>alois (at) astro (dot) ch</emphasis>
	</para>
	<blockquote>
		<para>
I am running a similar system, but with Linux 2.4.4 which has NFS version 3,
which is supposed to have safe locking.
Earlier NFS version are said to have buggy file locking, and as Apache
must lock the access_log for each entry, this might be the cause of your
problem.
		</para>
		<para>
I have chosen not to use a shared access_log between the realservers,
i.e. not sharing it via NFS.
I share the documents directory and a lot else via NFS between
all realservers, but not the logfiles.
		</para>
		<para>
I use remote syslog logging to collect all access logs on one
server.
		</para>
		<orderedlist>
			<listitem>
			<para>
On server w1, which holds the collective access_log and error_log, I have
in /etc/syslog.conf the entry:
			</para>
<programlisting><![CDATA[
local0.=info /var/log/httpd/access_log
local0.err   /var/log/httpd/error_log
]]></programlisting>
			</listitem>
			<listitem>
			<para>
on all other servers, I have an entry which sends the messages to w1:
			</para>
<programlisting><![CDATA[
local0.info     @w1
local0.err      @w1
]]></programlisting>
			</listitem>
			<listitem>
			<para>
On all servers, I have in http.conf the entry:
			</para>
<programlisting><![CDATA[
CustomLog "|/usr/local/bin/http_logger" common
]]></programlisting>
			</listitem>
			<listitem>
			<para>
and the utility http_logger, which sends the log messages to w1, contains:
			</para>
<programlisting><![CDATA[
#!/usr/bin/perl
# script: logger
use Sys::Syslog;
$SERVER_NAME = 'w1';
$FACILITY = 'local0';
$PRIORITY = 'info';
Sys::Syslog::setlogsock('unix');
openlog ($SERVER_NAME,'ndelay',$FACILITY);
while (<>) {
  chomp;
  syslog($PRIORITY,$_);
}
closelog;
]]></programlisting>

			</listitem>

			<listitem>
			<para>
I also to error_log logging to the same central server.
This is even easier, because Apache allows to configure in httpd.conf:
			</para>
<programlisting><![CDATA[
ErrorLog syslog:local0
]]></programlisting>
			</listitem>
		</orderedlist>
		<para>
On all realservers, except w1, thse log entries are sent to w1
by the syslog.conf given above.
		</para>
		<para>
I think it is superior to using NFS.
the access_log entries of course contain additional fields
in from of the Apache log lines, which originate from the
syslogd daemon.
		</para>
		<para>
It is also essential that the realservers are well synchonized,
so that the log entries appear in correct timestamp sequence.
		</para>
	</blockquote>
	<para>
I have a shared directory setup and both Real Servers have their
own access_log files that are put into that directory (access1.log and
access2.log...i do it this way so the Stats server can grab both files and
only use 1 license), so i dont think its a file locking issue at all.
Each apache server is writing to its own separate access log file,
it's just that they happen to be in the same shared directory. How would
httpd daemon on server A know to LOCK the access log from server B.
	</para>
	<para>
Alois
	</para>
	<blockquote>
		<para>
Why do you think it is NOT a file locking problem?
On each realserver,
you have a lot of httpd daemons running,
and to write into the same file without interfering,
they will have to use file locking,
to get exclusive access.
On one each server,
you do not have just one httpd daemon,
but many forked copies.
All these processes on ONE server need to write to the SAME logfile.
For this shared write access, they use file locking.
		</para>
		<para>
If this files sits on a NFS server,
and NFS file locking is buggy (which I only
know as rumor, not as experience),
then it might well be the cause of your problem.
		</para>
		<para>
Why don't you keep your access_log local on each server,
and rotate them frequently,
to collect them on one server (merge-sorted by date/time),
and then use your Stats server on it?
		</para>
		<para>
If you use separate log files anyway,
I cannot see the need to create them
on NFS. Nothing prevents you from rotating them every 6 hours,
and you will probably not need more current stats.
		</para>
	</blockquote>
	<para>
So the log files HAVE to be on a local disk or else one may run into such a
problem as I am having now?
	</para>
	<para>
Alois
	</para>
	<blockquote>
		<para>
I don't now. 
I only have read the NFS file locking before NFS 3.0 is broken. 
It is not a problem related to LVS.
You may want to read
http://httpd.apache.org/docs/mod/core.html#lockfile
		</para>
	</blockquote>
	<para>
Thanks but Ive seen that before. Each server saves that lock file to its own
local directory.
	</para>
	<para>
Anyone have a quick and dirty script to merge-sort by date/time the
combined apache logs?
	</para>
	<para>
Martin Hierling <emphasis>mad (at) cc (dot) fh-lippe (dot) de</emphasis>
	</para>
	<blockquote>
try <ulink url="http://mergelog.sourceforge.net/">merglog</ulink>
	</blockquote>
	<para>
Alois
	</para>
	<blockquote>
	<para>
assuming that all files contain only entries from the same month, I
think you can try:
	</para>
<programlisting><![CDATA[
sort -m -k 4 file1 file2 file3 ...
]]></programlisting>
	</blockquote>
	<para>
Arnaud Brugnon <emphasis>arnaud (dot) brugnon (at) 24pmteam (dot) com</emphasis>
	</para>
	<blockquote>
We successfuly use mergelog (you can find on freshmeat or SourceForge)
for merging logs (gz or not) from our cluster nodes.
With use a simple perl script for downloading them to a single machine.
	</blockquote>
	<para>
Juri Haberland <emphasis>list-linux.lvs.users (at) spoiled (dot) org</emphasis> Jul 13 2001
	</para>
	<para>
I'm looking for a script that merges and sorts the access_log files of my
three realservers running apache. The logs can be up to 500MB if combined.
	</para>
	<para>
Michael Stiller <emphasis>ms (at) 2scale (dot) net</emphasis> Jul 13 2001
	</para>
	<blockquote>
You want to look at <ulink url="http://www.backhand.org/mod_log_spread/">mod_log_spread</ulink>
	</blockquote>

	<para>
Stuart Fox <emphasis>stuart (at) fotango (dot) com</emphasis>
	</para>
	<blockquote>
		<para>
cat one log to the end of the other then run
		</para>
<programlisting><![CDATA[
sort -t - -k 3 ${WHEREVER}/access.log &gt; new.log
]]></programlisting>
		<para>
then you can run webalizer on it.
		</para>
		<para>
Thats what I use, doesnt take more than about
30 seconds.  If you can copy the logs from your
realservers to another box and run sort there, it
seems to be better
		</para>
		<para>
Heck, here's the whole(sanitized) script
		</para>
<programlisting><![CDATA[
#!/bin/bash

##
## Set constants
##

DATE=`date "+%d-%b-%Y"`
YESTERDAY=`date --date="1 day ago" "+%d-%b-%Y"`
ROOT="/usr/stats"
SSH="/usr/local/bin/ssh"

## First(1) Remove the tar files left yesterday
find ${ROOT} -name "*.tar.bz2" |xargs -r rm -v

##
## First get the access logs
## Make sure some_account has read-only access to the logs

su - some_account -c "$SSH some_account@real.server1 \"cat
/usr/local/apache/logs/access.log\" >  ${ROOT}/logs/$DATE.log"
su - some_account -c "$SSH some_account@real.server2 \"cat
/usr/local/apache/logs/access.log\" >> ${ROOT}/logs/$DATE.log"

##
## Second sort the contents in date order
##

sort -t - -k 3 ${ROOT}/logs/$DATE.log > ${ROOT}/logs/access.log

##
## Third run webalizer on the sorted files
## Just set webalizer to dump the files in ${ROOT}/logs

/usr/local/bin/webalizer -c /usr/stats/conf/webalizer.conf

##
## Forth remove all the crud
## You still got the originals on the realservers

find ${ROOT} -name "*.log"|xargs -r rm -v

##
## Fifth tar up all the files for transport to somewhere else

cd ${ROOT}/logs && tar cfI ${DATE}.tar.bz2 *.png *.tab *.html && chown
some_account.some_account ${DATE}.tar.bz2
]]></programlisting>
	</blockquote>

	<para>
Stuart Fox <emphasis>stuart (at) fotango (dot) com</emphasis>
	</para>
	<blockquote>
Ok scrub my last post, i just tested mergelog.
On a 2 x 400mb log it took 40 seconds, my script did it in 245 seconds.
	</blockquote>
	<para>
Juri Haberland <emphasis>list-linux.lvs.users@spoiled.org</emphasis>
	</para>
	<para>
Ok, thanks to you all very much!
That was quick and successful :-)
	</para>
	<para>
I tried mergelog, but I had some difficulties to compile it on
Solaris 2.7 until I found that I was missing GNU make...
	</para>
	<para>
But now:
Happy happy, joy joy!
	</para>

	<para>
karkoma <emphasis>abambala (at) genasys (dot) es</emphasis>
	</para>
	<blockquote>
Another posibility... http://www.xach.com/multisort/
	</blockquote>

	<para>
Stuart Fox <emphasis>stuart (at) fotango (dot) com</emphasis>
	</para>
	<blockquote>
mergelog seems to be 33&percnt; faster than multisort
using exactly the same file
	</blockquote>
	<para>
Julien 7 Jan 2003
	</para>
	<blockquote>
Does s/b know a way to merge apache error logs?
Mergelog and Multisort only merge Access logs.
	</blockquote>
	<para>
Jacob Coby 1 Dec 2003
	</para>
<programlisting><![CDATA[
cat error_log* >error_log.all
 or to sort by date
cat error_log* | sort -r > error_log.all
]]></programlisting>
	<para>
ratz 01 Dec 2003
	</para>
	<para>
This will not sort entries by date. Imagine following
two (fictive, but syntactically and semantically correct) error_logs:
	</para>
<programlisting><![CDATA[
# cat error_log.1
[Thu Dec 4 03:47:24 2002] [notice] Apache/1.3.27 (Unix) mod_jk/1.2.2
mod_perl/1.27 PHP/4.3.1 mod_ssl/2.8.14 OpenSSL/0.9.7a configured --
resuming normal operations
[Thu Mar 27 03:47:24 2003] [notice] Apache/1.3.27 (Unix) mod_jk/1.2.2
mod_perl/1.27 PHP/4.3.1 mod_ssl/2.8.14 OpenSSL/0.9.7a configured --
resuming normal operations
]]></programlisting>

<programlisting><![CDATA[
# cat error_log.2
[Sun Jan 19 06:57:41 2003] [error] [client 4.65.71.160] File does not
exist:
/var/www/htdocs/_mem_bin/..%5c../..%5c../..%5c../winnt/system32/cmd.exe
[Thu Apr 20 03:47:24 2003] [notice] Apache/1.3.27 (Unix) mod_jk/1.2.2
mod_perl/1.27 PHP/4.3.1 mod_ssl/2.8.14 OpenSSL/0.9.7a configured --
resuming normal operations
]]></programlisting>

	<para>
Your pipeline does not sort them in a correct way (entries by date) at
all. IMHO it's not so easy to script ;).
	</para>
<programlisting><![CDATA[
# cat error_log.* | sort -r
[Thu Mar 27 03:47:24 2003] [notice] Apache/1.3.27 (Unix) mod_jk/1.2.2
mod_perl/1.27 PHP/4.3.1 mod_ssl/2.8.14 OpenSSL/0.9.7a configured --
resuming normal operations
[Thu Dec 4 03:47:24 2002] [notice] Apache/1.3.27 (Unix) mod_jk/1.2.2
mod_perl/1.27 PHP/4.3.1 mod_ssl/2.8.14 OpenSSL/0.9.7a configured --
resuming normal operations
[Thu Apr 20 03:47:24 2003] [notice] Apache/1.3.27 (Unix) mod_jk/1.2.2
mod_perl/1.27 PHP/4.3.1 mod_ssl/2.8.14 OpenSSL/0.9.7a configured --
resuming normal operations
[Sun Jan 19 06:57:41 2003] [error] [client 4.65.71.160] File does not
exist:
/var/www/htdocs/_mem_bin/..%5c../..%5c../..%5c../winnt/system32/cmd.exe
]]></programlisting>
	<para>
To me the best solution is still to either write all error_logs into the
same file or to configure httpd.conf in a way that the logs are sent via
the syslog() interface.
Then you use syslog-ng to do all the needed logics, data handling,
merging, correlation and event triggering.
	</para>
	<para>
Jacob
	</para>
	<para>
If you're trying to stitch error logs from seperate sources, then yes, it
become less-trivial, and you're better off going with a scripting language
to do the stitching.
	</para>
	<para>
Guy Waugh
	</para>
	<blockquote>
		<para>
Would this work to sort the error logs...
 			</para>
<programlisting><![CDATA[
cat error_log.* | sort -o sorted-error_log -k 2M -k 3n
]]></programlisting>
		<para>
(use -r if you want the order reversed)
I don't understand why, but when I do this, it sorts on the fourth field
as well (the time)...
		</para>
	</blockquote>
	<para>
ratz 02 Dec 2003
	</para>
	<para>
It doesn't work with my sort or (more correctly) with my LC_TIME settings.
If you want to sort with the '... -k xM ...' you need an appropriate
LC_TIME entry or it will not work. A possible one is:
	</para>
<programlisting><![CDATA[
LC_TIME="%a %b %w %H:%M:%S %Y"
]]></programlisting>
	<para>
But this must be handwaved according to locale(5) and then compiled with localedef(3).
Lucky you, if you have a charmap which matches the apache log files output ;).
Also read the info page on <filename>sort</filename>
to see the difference between '-k 3n' and '-k 3,3n'.
	</para>
<programlisting><![CDATA[
`-k POS1[,POS2]'
`--key=POS1[,POS2]'
      Specify a sort field that consists of the part of the line between
      POS1 and POS2 (or the end of the line, if POS2 is omitted),
      _inclusive_.  Fields and character positions are numbered starting
      with 1.  So to sort on the second field, you'd use `--key=2,2'
      (`-k 2,2').  See below for more examples.
]]></programlisting>
	<para>
<emphasis>laurie.baker (at) bt (dot) com</emphasis> 08 Jan 2003
	</para>
	<para>
Take a look at
<ulink url="http://awstats.sourceforge.net/docs/awstats_tools.html">
logresolvemerge.pl</ulink>.
While I currently only use it myself for access logs,
I believe you can configure it for whatever your require.
	</para>
	<para>
Joe: the people on the Beowulf mailing list use
<ulink url="http://www.oit.ucsb.edu/~eta/swatch/">Swatch</ulink>
to parse logs collected on a centralised logserver.
	</para>
	<para>
Mikkel Kruse Johnsen <emphasis>mkj (dot) its (at) cbs (dot) dk</emphasis> 19 May 2003
	</para>
	<para>
You can use spreadlogd for logging the activity,
so that all your web frontends send their logs to one server.
www.spread.org, http://www.backhand.org/mod_log_spread/.
	</para>
	<para>
there are tools for migrating logs under:
http://awstats.sourceforge.net/docs/awstats_tools.html
	</para>
	<para>
Joe Stump <emphasis>joe (at) joestump (dot) net</emphasis> 22 Dec 2005 
	</para>
	<para>
I know of two ways to merge logs...
	</para>
	<itemizedlist>
		<listitem>
A centralized logging server (<emphasis>i.e.</emphasis> syslog). 
Have Apache log to  that and then parse the logs from there.
		</listitem>
		<listitem>
Use rsync or scp to sync the logs to a central server, cat them  
into one larger server and then parse them from there.
		</listitem>
	</itemizedlist>
	<para>
I'm currently doing #2, but plan on moving to #1 pretty soon.
The reason for the change is that it's a lot more streamlined  
than my current setup and it keeps logs in a single location instead  
of N locations where N is the number of nodes.
	</para>
	<para>
I currently use NFS for pretty much everything. All of my DocRoot's  
and configuration files (apache/php) are on the NFS server. I then  
aggregate the logs onto the NFS server and compile them with awstats  
on another server (don't ask).
	</para>

	<para>
Dan Trainor <emphasis>dan (at) id-confirm (dot) com</emphasis> 22 Dec 2005
	</para>
	<para>
I have a few very high traffic sites, and I've found that it would
sometimes take AWStats so long to read the logs in one pass, I'd set it
up to rotate and parse logs up to six times a day.  I would imagine
that, with a heavy LVS setup with many realservers, you may face the
same problem.
	</para>
	<para>
Perhaps the awstats author at some point will create a tool which will merge all
the gathered data into one single file or database.  This way, the
realservers could process their own logs, so you would not put all the
load on one main processign server, and not face the same kind of
problem which I previously had mentioned.
	</para>
	<para>
Todd Lyons <emphasis>tlyons (at) ivenue (dot) com</emphasis> 22 Dec 2005 
	</para>
	<para>
You tell syslog or syslog-ng to log to a remote network source instead
of or in addition to a local file on each of the real servers, then on
the central logging server configure it to listen for incoming network
log info and tell it where to put it.
	</para>
	<para>
Here's a syslog-ng master server config:
	</para>
<programlisting><![CDATA[
options { 
        long_hostnames(off); 
        sync(0); 

        # The default action of syslog-ng 1.6.0 is to log a STATS line
        # to the file every 10 minutes.  That's pretty ugly after a
        # while.
        # Change it to every 12 hours so you get a nice daily update of
        # how many messages syslog-ng missed (0).
        stats(43200); 
};

source src { unix-stream("/dev/log"); internal(); pipe("/proc/kmsg"); };
source net { udp(); };

filter f_authpriv { facility(auth, authpriv); };
filter f_cron { facility(cron); };
filter f_ldap { facility(local4); };
filter f_mail { facility(mail); };
filter f_messages { level(info .. warn)
        and not facility(auth, authpriv, cron, mail, local4); };

destination authlog { file("/var/log/auth.log"); };
destination cron { file("/var/log/cron"); };
destination ldap_net { file("/disk1/log/slapd.log"); };
destination mail_net { file("/disk1/log/maillog"); };
destination mail { file("/var/log/maillog"); };
destination messages { file("/var/log/messages"); };

# By default messages are logged to tty12...
destination console_all { file("/dev/tty12"); };
# ...if you intend to use /dev/console for programs like xconsole
# you can comment out the destination line above that references
# /dev/tty12
# and uncomment the line below.
#destination console_all { file("/dev/console"); };

log { source(src); filter(f_authpriv); destination(authlog); };
log { source(src); filter(f_cron); destination(cron); };
log { source(net); filter(f_ldap); destination(ldap_net); };
log { source(src); filter(f_mail); destination(mail); };
log { source(net); filter(f_mail); destination(mail_net); };

log { source(src); filter(f_messages); destination(messages); };
log { source(src); destination(console_all); };


Here's a client that logs maillog locally and to a remote syslog server:
options { 
        long_hostnames(off); 
        sync(0); 
        stats(43200); 
};

source src { unix-stream("/dev/log"); internal(); pipe("/proc/kmsg"); };

filter f_authpriv { facility(auth, authpriv); };
filter f_cron { facility(cron); };
filter f_mail { facility(mail); };
filter f_messages { level(info .. warn)
        and not facility(auth, authpriv, cron, mail); };
filter f_monitoring { not match("(did not issue)|(10.100.100.15)"); };
        

destination authlog { file("/var/log/auth.log"); };
destination cron { file("/var/log/cron"); };
destination mail { file("/var/log/maillog"); udp("10.100.100.250"); };
destination messages { file("/var/log/messages"); };

# By default messages are logged to tty12...
destination console_all { file("/dev/tty12"); };

log { source(src); filter(f_authpriv); destination(authlog); };
log { source(src); filter(f_cron); destination(cron); };
log { source(src); filter(f_mail); filter(f_monitoring);
destination(mail); };

log { source(src); filter(f_messages); destination(messages); };
log { source(src); destination(console_all); };


Here's a client that logs ldap only to a remote syslog server:
options { 
        long_hostnames(off); 
        sync(0); 
        stats(43200); 
};

source src { unix-stream("/dev/log"); internal(); pipe("/proc/kmsg"); };

filter f_authpriv { facility(auth, authpriv); };
filter f_cron { facility(cron); };
filter f_ldap { facility(local4); };
filter f_mail { facility(mail); };
filter f_messages { level(info .. warn)
        and not facility(auth, authpriv, cron, mail, local4); };

destination authlog { file("/var/log/auth.log"); };
destination cron { file("/var/log/cron"); };
destination ldap { udp("10.100.100.250"); };
destination mail { file("/var/log/maillog"); };
destination messages { file("/var/log/messages"); };

# By default messages are logged to tty12...
destination console_all { file("/dev/tty12"); };

log { source(src); filter(f_authpriv); destination(authlog); };
log { source(src); filter(f_cron); destination(cron); };
log { source(src); filter(f_ldap); destination(ldap); };
log { source(src); filter(f_mail); destination(mail); };

log { source(src); filter(f_messages); destination(messages); };
log { source(src); destination(console_all); };
]]></programlisting>
	<para>
Tomas Ruprich <emphasis>xruprich (at) akela (dot) mendelu (dot) cz</emphasis> 22 Dec 2005 
	</para>
	<para>
Well, I was realizing something like month ago...
In apache configuration file on each application server i have this line:
	</para>

<programlisting><![CDATA[
CustomLog "|/usr/bin/logger -t cluster_access_log" combined env=!dontlog
]]></programlisting>
	<para>
and then on log server I have <filename>syslog-ng</filename> installed, 
where are these configuration lines:
	</para>
<programlisting><![CDATA[
destination d_cluster_access_log { file("/var/log/httpd/all_clusters_log"); };
filter f_cluster_access_log { match("cluster_access_log"); };
source s_net { udp(); };
log { source(s_net); filter(f_cluster_access_log); destination(d_cluster_access_log); };
]]></programlisting>
	<para>
awstats is very good idea, I use it too
	</para>
	<para>
Here's the syslog configuration on application servers.
I think it's quite simple, but only for order...
For <filename>/etc/syslog.conf</filename>:
	</para>
<programlisting><![CDATA[
*.*                                              @<syslog_server_IP>
]]></programlisting>
	<para>
Lemaire, Olivier <emphasis>olivier (dot) lemaire (at) siemens (dot) com</emphasis> 22 Dec 2005
	</para>
	<para>
Mergelog is your friend (http://mergelog.sourceforge.net/), after
rsyncing youf file to a larger server.
A centralised logging server is probably overkill unless you need your logs up-to-date 
at the last second.
	</para>
	<para>
Graeme Fowler <emphasis>graeme (at) graemef (dot) net</emphasis> 22 Dec 2005
	</para>
	<para>
mod_log_mysql might help you out too:
http://bitbrook.de/software/mod_log_mysql/
	</para>
	<para>
...or its' Apache 1 cousin, mod_log_sql:
http://www.outoforder.cc/projects/apache/mod_log_sql/
	</para>
	<para>
Note however that for a big and/or very busy cluster you need to be
very, very careful with your database design and the setup of your
servers. At work a colleague recently ran this up across 40 Apache
servers and knocked the ass out of the MySQL logging server, jamming it
up with 1000 persistent client connections. That was bad operational
design on our part, but still something worth remembering.
	</para>
	<para>
Performance-wise it seems to do well as all the queries are inserts, and
it's obviously possible to make use of MySQL table replication to
amalgamate several collected tables onto one host for post-processing.
	</para>
	<para>
As a theory it's definitely got legs, we just have to find out how many
in practice now!
	</para>
	<para>
Joe
	</para>
	<blockquote>
when sending logs to a central server, are there any problems with
streams becoming intermixed, so that you get nonsense?
	</blockquote>
	<para>
Todd Lyons <emphasis>tlyons (at) ivenue (dot) com</emphasis> 23 Dec 2005
	</para>
	<para>
No one host's line will be interrupted but another hosts's line.  
The lines from different hosts will be intermingled, 
but they will be complete.  Here's an example:
	</para>
<programlisting><![CDATA[
Dec 23 11:48:09 smtp2 sm-mta[7171]: jBNJm7WM007171: Milter add: header: X-Spam-Status: Yes, hits=30.5 required=5.0 tests=BAYES_99,DRUGS_ERECTILE,\n\tDRUGS_MALEDYSFUNCTION,FORGED_RCVD_HELO,HTML_30_40,HTML_MESSAGE,\n\tHTML_MIME_NO_HTML_TAG,MIME_HEADER_CTYPE_ONLY,MIME_HTML_ONLY,\n\tNO_REAL_NAME,URIBL_AB_SURBL,URIBL_JP_SURBL,URIBL_OB_SURBL,URIBL_SBL,\n\tURIBL_SC_SURBL,URIBL_WS_SURBL autolearn=no version=3.1.0-gr0
Dec 23 11:48:09 smtp2 sm-mta[7171]: jBNJm7WM007171: Milter: data, reject=550 5.7.1 Blocked by SpamAssassin
Dec 23 11:48:09 smtp2 sm-mta[7171]: jBNJm7WM007171: to=<dianag@domain.com>, delay=00:00:01, pri=30500, stat=Blocked by SpamAssassin
Dec 23 11:48:09 smtp1 sm-mta[10021]: jBNJm8o0010021: from=<qylyrxy@domain2.com>,size=0, class=0, nrcpts=0, proto=SMTP, daemon=MTA, relay=[82.131.161.22]
Dec 23 11:48:09 smtp2 spamd[26407]: prefork: child states: IIIII
Dec 23 11:48:09 smtp1 sm-mta[9872]: jBNJlQPs009872: <asing@domain3.com>... User unknown
Dec 23 11:48:09 smtp1 sm-mta[10010]: jBNJm3SU010010: ruleset=check_rcpt, arg1=<admin@domain4.com>, relay=24-176-185-20.dhcp.reno.nv.charter.com [24.176.185.20] (may be forged), reject=550 5.7.1 <admin@domain5.com>... Relaying denied. IP name possibly forged [24.176.185.20]
]]></programlisting>
	<blockquote> 
If you have a central log server, what do you do if it dies?
How do failover is this solution?
	</blockquote>
	<para>
Joe Stumpf
	</para>
	<para>
Well you could always load balance your log traffic on an LVS setup  
with redundant NetApp's, but really why on God's green Earth would  
you do that? It's log traffic. I've never heard of a place where log  
traffic ever justified redundant servers.
	</para>
	<para>
Johan van den Berg <emphasis>vdberj (at) unisa (dot) ac (dot) za</emphasis> 11 Jan 2006 
	</para>
	<para>
The following works like a charm. I have 4 nodes, 1
fileserver, and 1 lvs machine...
The nodes are high usage, and log everything to syslog using "|
logger..." syntax in apache, and syslog forwards to @fileserver.
Fileserver uses the - option before a filename to only sync the access
log when needed to file, so that the access logs don't cause too much
filesystem access on the fileserver.
I am though concerned that every once in a while, I've seen a line or
two go missing if I push too much into syslog at one time.
	</para>
	<para>
Graeme Fowler <emphasis>graeme (at) graemef (dot) net</emphasis>03 May 2006 
(in reply to a query about logging from a two realserver LVS).
	</para>
	<para>
Use <ulink url="http://www.backhand.org/mod_log_spread/">mod_log_spread</ulink>
(http://www.backhand.org/mod_log_spread/).
This makes use of the multicast spread toolkit to allow you to log
messages to remote servers. The mechanics of it I leave to you as they
aren't hugely simple.
	</para>
	<para>
Alternatively, make Apache log to a remote syslog host which combines
the logs for you. This could easily be *both* of your realservers
logging to each other, and again I leave the mechanics of it to you.
Note that this will not scale up or out very far, but for a two-node
solution it's perfect IMO.
I'm saying that having each realserver act as a logging host for all the
rest won't scale. Beyond a pair, having a dedicated syslog host (or
indeed more than one, for robust logging) is the way forward, as you
say.
	</para>
	<para>
Lasse Karstensen <emphasis>lkarsten (at) hyse (dot) org</emphasis>4 May 2006
	</para>
	<para>
I tried compiling mod_log_spread a few months ago, even found a
apache2 patch on some mailling list, but without luck.
Anyone succeeded using it with apache2?
The project seems abandoned. Too bad, we used it before and
were mostly happy.
	</para>
	<para>
We're using the syslog solution. 
We're having 10-12 realservers now, with some 
moderate amounts of traffic.
	</para>
	<para>
Graeme Fowler <emphasis>graeme (at) graemef (dot) net</emphasis> 04 May 2006 
	</para>
	<para>
I used mod_log_spread with apache2, 
but I no longer have access to either the slightly modified
codebase or the production results. It worked well, however, shared
between 8 servers with a pair of collectors. There was a slight lag to
log processing as each listener piped the log arrivals through a Perl
script (running in a "while (&lt;&gt;" loop), did $magic with them, and put
them in the right users' logfiles.
	</para>
	<para>
Clint Byrum <emphasis>cbyrum (at) spamaps (dot) org</emphasis> 04 May 2006 
	</para>
	<para>
We used mod_log_spread for about 6 months at Adicio, Inc. We were
pumping 4-8 million hits per day, reaching rates of 600-1000 hits per
second at times, across 8 servers through it. I even submitted a few
patches and we paid the author, George Schlossnagle, to enhance it to be
more robust for us.
	</para>
	<para>
We gave up on it ultimately, as the underlying toolkit, spread, wasn't
scaling for us. We'd have a little network blip on one machine, and the
whole ring would stop working for 5 minutes. Server loads would go up
retrying, and retransmitting, error logs would be flying. It was a real
mess. 
	</para>
	<para>
Ultimately we needed to do some tuning that involved recompiling the
spread daemon. I gained a deep understanding of the spread protocol, and
decided it was far too complex for this purpose.
	</para>
	<para>
We've gone to a system now where logs are written locally using the
program 'cronolog' and once per hour they are collected via NFS export.
It works pretty well, though it was nice to have one big log file.
	</para>
	<para>
Dan Trainor <emphasis>dan (at) id-confirm (dot) com</emphasis>05 May 2006
	</para>
	<para>
What we've done in the past is also used mod_log_mysql.  
While not the most efficient way of logging (sure, your setup may differ) 
- this did allow us to be flexible as to where we wanted logs sent.  
We would dump this log nightly and export it back into one on disk, 
then run our stats against it.  
We later modified our stats system to read directly from 
the database, which worked out quite nicely.
That's a lot of work, though. 
I guess if you're looking for something simple, 
that's not the answer for you.  However, it's food for thought.
	</para>
	<para>
Daniel Ballenger <emphasis>lpmusix (at) gmail (dot) com</emphasis>5 May 2006
	</para>
	<para>
I just recently ran a benchmark on mysql on a machine for my company...
With MySQL I was pushing >1000 inserts per second.  This was on a Quad
700Mhz (Compaq DL580) box with 1GB of ram and 4 9.1GB drives in raid 5.
I'm sure with faster disks I'd be able to push that box even harder with mysql.
But of course, I've yet to hit that many queries per second yet with
it in production :).
	</para>
	<para>
Graeme Fowler <emphasis>graeme (at) graemef (dot) net</emphasis>06 May 2006 
	</para>
	<para>
In testing, we found an interesting limit - MySQL 4.x seems to have a
hard limit of 1000 client connections, and it can't be raised. As every
single Apache child process opens a connection to the server to log
accesses, this means that (for example) 5 Apache servers with MaxClients
set to more than 200 can block the MySQL server. In the same tests we
found that the server doesn't recover from this, so it stops Apache from
working while each child waits for its' logging connection to close.
MySQL 5.x did not show this behaviour.
	</para>
	</section>
</section>
<section id="LVS-HOWTO.services.single-port" xreflabel="single-port services">
<title>LVS: Services: single-port</title>
	<section id="ftp_single_port">
	<title>ftp, tcp 21</title>
	This is a multi-port service and is
covered in the <xref linkend="ftp"/> section of multi-port services.
	</section>
	<section id="sshd" xreflabel="sshd">
	<title>ssh, sftp, scp, tcp 22</title>
	<para>
Surprisingly (considering that it negotiates a secure connection) nothing special either.
You do not need persistent port/client connection for this.
sshd is a standard one-port tcp connection.
	</para>
	<para>
The director will timeout an idle tcp connection (<emphasis>e.g.</emphasis> ssh, telnet)
in 15mins, independantly of any settings on the client or server.
You will want to
<link linkend="tcpip_idle_timeout">change the tcpip idle timeouts</link>.
	</para>
	<para>
As well ssh has its own timeouts. 
You'll get "Connection reset by peer" independently of LVS.
	</para>
	<para>
linuxxpert <emphasis>linuxxpert (at) gmail (dot) com</emphasis> 19 Dec 2008
	</para>
	<itemizedlist>
		<listitem>
Make sure you have "TCPKeepAlive yes" in your sshd_config file.
		</listitem>
		<listitem>
If TCPKeepAlive is already yes, then add "ClientAliveInterval" in
      your <filename>sshd_config</filename>.
		</listitem>
	</itemizedlist>
	<para>
man sshd_config:
ClientAliveInterval
	</para>
	<blockquote>
Sets a timeout interval in seconds after which if no data has
been received from the client, sshd will send a message through
the encrypted channel to request a response from the 
client.  The default is 0, indicating that these messages will not be 
sent to the client. This option applies to protocol version 2 only.
	</blockquote>
	<para id="sftp" xreflabel="sftp">
	<note>
<command>sftp</command> and <command>scp</command> are also single port services
on port 22.
	</note>
	</para>
	<note>
	<para>
The current (Jul 2001) implementations of ssh (openssh-2.x/openssl-0.9.x)
all use ssh protocol 2.
Almost all the webpages/HOWTOs available are about sshd protocol 1.
None of this protocol 1 information is of any use for protocol 2 -
everything from setting up the keys onward is different.
Erase everything from your protocol 1 installations (the old ssh binaries,
/etc/ssh*), do not try to be backwards compatible, avoid the old HOWTOs and go buy
	</para>
<programlisting><![CDATA[
SSH The Secure Shell
Daniel J. Barrett and Richard E. Silverman
O'Reilly 2001
ISBN: 0-59-00011-1
]]></programlisting>
	<para>
(sometime in 2002: looks like new information is arriving on webpages.)
	</para>
	</note>
	<para>
anonymous
	</para>
	<blockquote>
How can I configure rsh/ssh to enable copying of files  between 2 machines without
human intervention?
	</blockquote>
	<para>
Brent Cook <emphasis>busterb (at) mail (dot) utexas (dot) edu</emphasis> 09 Jul 2002
	</para>
	<para>
Here are some articles on OpenSSH key management.
	</para>
<programlisting><![CDATA[
http://www-106.ibm.com/developerworks/library/l-keyc.html
http://www-106.ibm.com/developerworks/library/l-keyc2/
http://www-106.ibm.com/developerworks/linux/library/l-keyc3/
]]></programlisting>
	<para>
My realservers aren't connected to the outside world so I've
setup ssh to allow root to login with no passwd.
If you compile ssh with the default <filename>--prefix</filename>,
where it is installed in <filename>/usr/local/bin</filename>,
you will have to change the default $PATH for sshd too
(I suggest using <filename>--prefix=/usr</filename> so you
don't have to bother with this.)
	</para>
<programlisting><![CDATA[
./configure --with-none --with-default-path=/bin:/usr/bin:/usr/local/bin
]]></programlisting>
	<para>
Here's my <filename>sshd_config</filename> - the docs on passwordless
root logins were not helpfull.
	</para>
<programlisting><![CDATA[
# This is ssh server systemwide sshd_config

Port 22
#Protocol 2,1
ListenAddress 0.0.0.0
#ListenAddress ::
HostKey /usr/local/etc/ssh_host_key
ServerKeyBits 768
LoginGraceTime 600
KeyRegenerationInterval 3600
PermitRootLogin yes
#PermitRootLogin without-password
#
# Don't read ~/.rhosts and ~/.shosts files
IgnoreRhosts yes
# Uncomment if you don't trust ~/.ssh/known_hosts for RhostsRSAAuthentication
#IgnoreUserKnownHosts yes
StrictModes yes
X11Forwarding no
X11DisplayOffset 10
PrintMotd yes
KeepAlive yes

# Logging
SyslogFacility AUTH
LogLevel INFO
#obsoletes QuietMode and FascistLogging

RhostsAuthentication no
#
# For this to work you will also need host keys in /usr/local/etc/ssh_known_hosts
#RhostsRSAAuthentication no
RhostsRSAAuthentication yes
#
RSAAuthentication yes

# To disable tunneled clear text passwords, change to no here!
PasswordAuthentication yes
#PermitEmptyPasswords no
PermitEmptyPasswords yes
# Uncomment to disable S/key passwords
#SkeyAuthentication no
#KbdInteractiveAuthentication yes

# To change Kerberos options
#KerberosAuthentication no
#KerberosOrLocalPasswd yes
#AFSTokenPassing no
#KerberosTicketCleanup no

# Kerberos TGT Passing does only work with the AFS kaserver
#KerberosTgtPassing yes

CheckMail no
#UseLogin no

# Uncomment if you want to enable sftp
#Subsystem	sftp	/usr/local/libexec/sftp-server
#MaxStartups 10:30:60
]]></programlisting>
		<section id="keys">
		<title>keys for realservers running sshd</title>
		<para>
If you install sshd and generate the host keys for the realservers
using the default settings, you'll get a working
LVS'ed sshd. However you should be aware of what you've done.
The default sshd listens to 0.0.0.0 and you will have generated
host keys for a machine whose name corresponds to the RIP (and not the VIP).
Since the client will be displaying a prompt with the
name of the realserver (rather than the name associated with the
VIP) this will work just fine. However the client will get
a different realserver each connection (which is OK too) and
will accumulate keys for each realserver. If instead you want the client
to be presented with one virtual machine, you will need
each machine to have its hostname being the name associated with
the VIP, the sshd will have to listen to the VIP (if LVS-DR, LVS-Tun)
and the hostkeys will have to be generated for the name of the VIP.
		</para>
		</section>
		<section id="ssh_abort">
		<title>ssh zombie processes</title>
		<para>
The user must exit cleanly from their ssh session, or the realserver
will be left running the ssh invoked process at high load average.
The problem is that what the user thinks is a clean exit
and what the sshd thinks are a clean exit, may be different things.
(There is a similar problem on a webserver,
which is running a process invoked by a cgi script,
when the client disconnects by clicking to another page or hitting "stop").
		</para>
		<para>
Shivaji Navale
		</para>
		<blockquote>
On our realservers, after the users have logged out of their ssh session,
zombie processes run at high load average in the background.
We resort to  killing  the zombie processess.
The ssh connection to the director doesnt get closed even after ctrl-D.
From netstat, the connection is still active.
		</blockquote>
		<para>
Dave Jagoda <emphasis>dj (at) opsware (dot) com</emphasis> 23 Nov 2003
		</para>
		<para>
Does this sound like what's going on?
<ulink url="http://www.openssh.org/faq.html#3.10">
http://www.openssh.org/faq.html#3.10, ssh hangs on exit</ulink>.
		</para>
		</section>
		<section id="persistence_with_sshd">
		<title>persistence with sshd</title>
		<para>
You do not need persistence with ssh, but you can use it.
		</para>
		<para>
Piero Calucci <emphasis>calucci (at) sissa (dot) it</emphasis> 30 Mar 2004
		</para>
		<blockquote>
I use ipvs to load balance ssh and I do use persistence (and my users
are happy with it -- in fact they asked me to do so). With this setup
when they open multiple sessions they are guaranteed to reach always the
same realserver, so they can see all their processes and local /tmp
files.
		</blockquote>
		<para>
If you use persistence, be aware of the effects.
		</para>
		<para>
<emphasis>jeremy (at) xxedgexx (dot) com</emphasis>
		</para>
		<blockquote>
I'm using ipvs
to balance ssh connections but for some reason ipvs is only using one real
server and persists to use that server until I delete its arp entry from
the ipvs machine and remove the virtual loopback on the realserver.
Also, I noticed that connections do not register with this behavior.
		</blockquote>
		<para>
Wensong
		</para>
		<para>
do you use the persistent port for your VIP:22? If so, the
default timeout of persistent port is 360 seconds, once the ssh
session finishes, it takes 360 seconds to expire the persistent
session. (In ipvs-0.9.1, you can flexibly set the timeout for the
persistent port.) There is no need to use persistent
port for ssh service, because the RSA keys are exchanged in each
ssh session, and each session is not related.
		</para>
		</section>
	</section>
	<section id="telnet">
	<title>telnet, tcp 23</title>
	<para>
Simple one port service.
Use telnet (or <xref linkend="phatcat"/>) for initial testing of your LVS.
It is a simpler client/service than http (it is not persistent)
and a connection shows up as an ActiveConn in the <command>ipvsadm</command> output.
You can fabricate a fake service on the realservers with
<xref linkend="lvs_inetd"/>
	</para>
	<para>
(Also note the director timeout problem, explained in the
<link linkend="sshd">ssh</link> section).
	</para>
	</section>
	<section id="smtp">
	<title>smtp, tcp 25; pop3, tcp 110; imap tcp/udp 143 (imap2), 220(imap3). Also sendmail, qmail, postfix, and mailfarms.</title>
	<para>
(for non LVS solutions to high throughput, high availability mailers, see
<ulink url="http://uni.x-si.org/hamail.txt">tutorial by Damir Horvat</ulink>).
	</para>
		<section id="smtp_many_reader_single_writer">
		<title>The many reader, single writer problem with smtp</title>
		<para>
For mail which is being passed through, LVS is a good solution.
		</para>
		<para>
If the realserver is the final delivery target,
then the mail will arrive randomly at any one of
the realservers and write to the different filesystems.
This is the many reader/many writer problem that LVS has.
Since you probably want your mail to arrive at one place only,
the only way of handling this right now is to have the
/home directory nfs mounted on all the realservers from a
backend fileserver which is not part of the LVS. (an nfs.monitor is in
the works.) Each realserver will have to be configured to accept
mail for the virtual server DNS name (say lvs.domain.com).
		</para>
		<para>
Rio <emphasis>rio (at) forestoflives (dot) com</emphasis> 21 Jun 2007
		</para>
		<para>
We're using the proprietary  mail server software (surgemail) which 
has built-in 2-way mirroring that updates each other within milliseconds of a change.
		</para>
		<para>
(Joe: can't imagine it would be that hard to add that feature to a GPL'ed smtpd.)
		</para>
		</section>
		<section id="mbox_maildir">
		<title>mailbox formats: mbox, maildir</title>
		<para>
Joe - if mail arrives on different realservers, then people have
tried merging/synching the files on the different machines.
Only one of the file formats, maildir, is worth attempting.
Even that hasn't worked out too well and it seems that
most successful LVS mail farms are using centralised file servers.
		</para>
		<para>
Todd Lyons <emphasis>tlyons (at) ivenue (dot) com</emphasis>
13 Jan 2006
		</para>
		<itemizedlist>
			<listitem>
<emphasis role="bold">mbox</emphasis>:one file for all messages 
(like the <filename>/var/spool/mail/$USER</filename> mailbox)
			</listitem>
			<listitem>
<emphasis role="bold">maildir</emphasis>: one file per message
			</listitem>
		</itemizedlist>
		<para>
I don't know that I'd feel all that comfortable about syncing either one:
mbox - This could end up with a corrupted mbox file since it's all one
big long file.
maildir - Guaranteed that you won't end up with any filename conflicts
since the hostname is used in the filename, but there are some shared
files, such as the quota or subscribed files.  Those files could easily
get out of sync.
		</para>
		<para>
Graeme Fowler <emphasis>graeme (at) graemef (dot) net</emphasis> 13 Jan 2006
		</para>
		<para>
Indeed they can (says someone long since burnt, not exactly by rsync,
but by some other methods of attempting to sunc mailboxes...).
		</para>
		<para>
I now use NetApp filers on which my maildirs live, and I have multiple
IMAP/POP (and Horde/IMP webmail) servers living behind a pair of LVS
directors. Using maildir format [0], I export the mailboxes via NFS to
the frontend servers and it works a treat - generally because maildir
saves files using filenames derived from the hostname, so the frontend
servers don't hit race conditions when trying to manipulate files.
		</para>
		<para>
If you need really (and I mean _really_) high NFS transaction rates and
fault-tolerance, I can't recommend the NetApp kit highly enough. If you
don't, then other options - cheaper ones! - are (for example) high-end
Intel-based IBM, Dell, HP/Compaq etc. servers with large hardware RAID
arrays for redundancy. You'd have to address the various benchmarks
according to your means, but there's a price point for every pocket
somewhere.
		</para>
		<para>
[0] for the inevitable extra question: Exim v4.x for the (E)SMTP server,
Courier IMAP server for IMAP and POP; all backended with MySQL for
mailbox/address lookups and POP/IMAP/SMTP authentication.
		</para>
		</section>
		<section id="passwd_on_realserver">
		<title>Maintaining user passwds on the realservers</title>
		<blockquote>
			<para>
Gabriel Neagoe <emphasis>Gabriel (dot) Neagoe (at) snt (dot) ro</emphasis>
			</para><para>
for syncing the passwords
- IF THE ENVIRONMENT IS SAFE- you could use NIS or rdist
			</para>
		</blockquote>
		</section>
		<section id="identd_MTA">
		<title>identd (auth) problems with MTAs</title>
		<para>
You will not be explicitely configuring identd in an LVS.
However <xref linkend="LVS-HOWTO.authd"/> is used by sendmail and tcpwrappers and will cause problems.
Services running on realservers can't use identd when running on an LVS
(see <link linkend="identd_and_sendmail">identd and sendmail</link>).
Running identd as an LVS service doesn't fix this.
		</para>
		<para>
<emphasis role="bold">sendmail</emphasis>
		</para>
		<para>
in <filename>sendmail.cf</filename> set the value
		</para>
<programlisting><![CDATA[
Timeout.ident=0
]]></programlisting>
		<para>
Also see <ulink url="http://www.sendmail.org/faq/section3.html">Why do
connections to the smtp port take such a long time?</ulink>
		</para>
		<para>
<emphasis role="bold">qmail</emphasis> <ulink url="http://www.qmail.org">qmail</ulink>:
		</para>
		<para>
Martin Lichtin <emphasis>lichtin (at) bivio (dot) com</emphasis>
		</para>
		<itemizedlist>
			<listitem>
If invoked with tcp-env in inetd.conf - use the -R option
			</listitem>
			<listitem>
If spawned using svc and DJ's daemontools packages -
<programlisting><![CDATA[
#/usr/local/bin/tcpserver -u 1002 -g 1001 -c 500 -v 0 smtp /var/qmail/bin/qmail-smtpd
]]></programlisting>
			<para>
tcpserver is the recommended method of running qmail,
where you use the -R option for tcpserver
			</para>
			<blockquote>
<para>
 -R: Do not attempt to obtain $TCPREMOTEINFO from the remote host.
To avoid loops, you must use this option for servers on TCP ports 53 and 113.
</para>
			</blockquote>
			</listitem>
		</itemizedlist>
		<para>
<emphasis role="bold">exim</emphasis>
		</para>
		<para>
Michael Stiller <emphasis>ms (at) 2scale (dot) net</emphasis> 26 Jun 2003
		</para>
		<para>
in <filename>exim.conf</filename> set the timeout for identd/auth to zero
		</para>
<programlisting><![CDATA[
rfc1413_query_timeout = 0s
]]></programlisting>
		<para>
Remember to reHUP exim.
		</para>
		</section>
		<section id="postfix">
		<title>postfix</title>
Note: postfix is not <link linkend="name_resolution">name resolution friendly</link>.
This will not be a problem if smtp is an LVS'ed service, but will be a problem
if you use it for local delivery too.
		</section>
		<section id="testing_sendmail">
		<title>testing an LVS'ed sendmail</title>
		<para>
Here's an LVS-DR with sendmail listening on the VIP on the
realserver. Notice that the reply from the MTA includes the RIP
allowing you to identify the realserver.
		</para><para>
Connect from the client to VIP:smtp
		</para>
<programlisting><![CDATA[
client:~# telnet lvs.cluster.org smtp
 trying 192.168.1.110...
 Connected to lvs.cluster.org
 Escape character is '^]'.
220 lvs.cluster.org ESMTP Sendmail 8.9.1a/8.9.0; Sat 6 Nov 1999 13:16:30 GMT
 HELO client.cluster.org
250 client.cluster.org Hello root@client.cluster.org [192.168.1.12], pleased to meet you
 quit
221 client.cluster.org closing connection
]]></programlisting>
		<para>
check that you can access each realserver in turn (here the realserver with
RIP=192.168.1.12 was accessed).
		</para>
		</section>
		<section id="pop3">
		<title>pop3, tcp 110</title>
		<para>
pop3 - as for smtp. The mail agents must see the same
/home file system, so /home should be mounted on
all realservers from a single file server.
		</para><para>
Using qmail -
		</para>
		<para>
Abe Schwartz <emphasis>sloween (at) hotmail (dot) com</emphasis>
		</para>
		<blockquote>
Has anyone used LVS to balance POP3 traffic in conjunction with qmail?
		</blockquote>
		<para>
Wayne <emphasis>wayne (at) compute-aid (dot) com</emphasis> 13 Feb 2002
		</para><para>
We used LVS to balance POP3 and Qmail without any problem.
		</para>
		<para>
Mike McLean <emphasis>mikem (at) redhat (dot) com</emphasis> 21 Apr 2004
		</para>
		<para>
Generally RW activity like with POP does 
not work well with LVS.
When such things are required, one reasonable solution is to have a 
three tier setup where the lvs director load balances across multiple 
servers (in your case pop/imap), which access their data via a highly 
available shared filesystem/database.  Of course this requires more 
machines and more hardware.
		</para>
		<para>
Kelly Corbin <emphasis>kcorbin (at) theiqgroup (dot) com</emphasis> 23 Aug 2004
		</para>
		<blockquote>
			<para>
Pop-Before-SMTP and LVS
			</para>
			<para>
I just added pop and smtp services to my load balancers, 
and I wanted to know if there was a way to tie the two connections together somehow.  
I use pop-before-smtp to allow my users to send mail, 
but sometimes they reconnect to a different server for smtp than the one they pop-ed into. 
Most of the time it's OK because they have pop-ed to both of the 
servers in the cluster but every now and then I have a user with an issue.
			</para>
			<para>
Is there a way to have it keep track of the IP and always send those 
SMTP and POP connections to the same realserver?
			</para>
		</blockquote>
		<para>
Josh Marshall <emphasis>josh (at) worldhosting (dot) org</emphasis>
		</para>
		<para>
You don't need to have the smtp and pop connections on the same realserver. 
We've got three mail servers here with pop-before-smtp running... 
I just point the daemons at the same file on an nfs share and it all just works. 
The pop-before-smtp daemons can handle all writing to the same file just fine.
		</para>
		<para>
Joe
		</para>
		<para>
You can link the two services with fwmark 
(and possibly persistence, depending on the time between connections).
LVS is not really designed for writing to the realservers. 
To do so, you have to serialise the writes and then propagate the writes
to the other realservers. This is a bit of a kludge, but is the way
everyone handles writes to an LVS. The other point of an LVS is
load balancing. What you're proposing is to turn off the loadbalancing
and have the content on each of the realservers different. You need
to be able to failout a realserver.
		</para>
		<para>
What you're proposing can be done, but it isn't an LVS anymore
		</para>
		</section>
		<section id="imap">
		<title>imap tcp/udp 143 (imap2),220 (imap3)</title>
		<para>
Ramon Kagan <emphasis>rkagan (at) YorkU (dot) CA</emphasis> 20 Nov 2002
		</para>

		<blockquote>
		<para>
Previously we had been using DNS shuffle records to spread the load of
IMAP connections across 3 machines.  Having used LVS-DR for web traffic for a
long time now (about 2.5 yeras) we decided to bring our IMAP service into
the pool.  The imap servers have been setup to retain idle connections for
24 hours (not my choice but the current setup anyways).  The lvs servers have
been setup to have a persistance of 8 hours.  What has been happening
lately is that users get the following type error.
		</para>
		<para>
"The server has disconnected, may have gone down or may be a network
problem, try connecting again"
		</para>
		<para>
So, users don't have to reauthenticate per se, they just need to reclick
on whatever button, so that the client they are using reauthenticates them.
The timeout for this is as low as ten minutes.
However the imap daemon is kept alive, and the client is shipped the PID
of the imapd to reconnect directly.  This is supposed to circumvent the
necessity of reauthentication.  In the case where the connection is lost,
the reauthentication actually starts a new imapd process.
		</para>
		</blockquote>

		<para>
Joe
		</para>
		<para>
there is an LVS timeout and another
timeout (tcp-keepalive) associated with tcp connections which
affects telnet, ssh sessions.
You need to reset both
(see <link linkend="tcpip_idle_timeout">timeouts</link>).
		</para>

		<blockquote>
		<para>
The solution:
On the linux imap servers the tcp-keepalive value in
<filename>/proc/sys/net/ipv4/tcp_keepalive_time</filename>
is set to 7200
		</para>

<programlisting><![CDATA[
centaur# pwd
/proc/sys/net/ipv4
centaur# cat tcp_keepalive_time
7200
]]></programlisting>

		<para>
This must be matched by the ipvsadm tcp timeout.  So the options are to do one of:
		</para>
		<itemizedlist>
			<listitem>
use ipvsadm --set 7200 0 0 on the lvs server
			</listitem>
			<listitem>
<programlisting><![CDATA[
echo "900" >! /proc/sys/net/ipv4/tcp_keepalive_time
]]></programlisting>
			</listitem>
		</itemizedlist>
		</blockquote>
		<para>
Ramon Kagan <emphasis>rkagan (at) YorkU (dot) CA</emphasis> 27 Nov 2002
		</para>
		<blockquote>
Further update on the solution:
although this works there is one catch.  If a person logs out and comes
back within the 7200s as stated in the previous email, they continue to
get the message because the realserver and the director don't match
again.  We will be lowering the value to somewhere between 5 and 15
minutes (300-900) to address this type of usage.
		</blockquote>
		<para>
Torsten Rosenberger <emphasis>rosenberger (at) taoweb (dot) at</emphasis>
16 Sep 2003
		</para>
		<blockquote>
i want to build a mail cluster with cyrus-imapd but i don't know how to
handle the mailbox database on LVS.
		</blockquote>
		<para>
Kjetil Torgrim Homme <emphasis>kjetilho (at) ifi (dot) uio (dot) no</emphasis>
16 Sep 2003
		</para>
		<para>
we use HP ServiceGuard for clustering (12 Cyrus instances running on
three physical servers, storage on HP VA7410 connected through SAN),
Perdition as a proxy (connects user to correct instance, also acts as
an SSL accelerator, runs on two physical servers) and LVS (keepalived,
active-active on two physical servers).
		</para>
		<para>
the other route is to use Cyrus Murder.  <emphasis>e.g.</emphasis>
shared folders will
probably work better with Murder.  administration is easier, too.  we
have to connect to correct instance.  at the time we chose our
architecture, Murder seemed unfinished, and we were worried about
single point of failure.  I'm afraid I haven't followed its
development closely.
		</para>
		</section>
		<section id="thoughts_sendmail">
		<title>Thoughts about sendmail/pop</title>
		<para>
(another variation on the many reader/many writer problem)
		</para><para>
<emphasis>loc (at) indochinanet (dot) com</emphasis> wrote:
		</para><para>
I need this to convince my boss that LVS is the solution for very
scalable and high available mail/POP server.
		</para>
		<para>
Rob Thomas <emphasis>rob (at) rpi (dot) net (dot) au</emphasis>
			</para>
		<blockquote>
		<para>
This is about the hardest clustering thing you'll ever do.
Because of the constant read/write access's you -will- have
problems with locking, and file corruption.. The 'best' way to do
this is (IMHO):
		</para>
		<orderedlist>
			<listitem>
NetCache Filer as the NFS disk server.
			</listitem>
			<listitem>
Several SMTP clients using NFS v3 to the NFS server.
			</listitem>
			<listitem>
Several POP/IMAP clients using NFS v3 to the NFS server.
			</listitem>
			<listitem>
At least one dedicated machine for sending mail out (smarthost)
			</listitem>
			<listitem>
LinuxDirector box in front of 2 and 3 firing requests off
			</listitem>
		</orderedlist>
		<para>
Now, items 1 2 -and- 3 can be replaced by Linux boxes, but, NFS
v3 is still in Alpha on linux.  I -believe- that NetBSD (FreeBSD?
One of them) has a fully functional NFS v3 implementation, so you
can use that.
		</para>
		<para>
The reason why I emphasize NFSv3 is that it -finally- has 'real'
locking support.  You -must- have atomic locks to the file
server, otherwise you -will- get corruption. And it's not
something that'll happen occasionally.  Picture this:
		</para>
<programlisting><![CDATA[
  [client]  --  [ l.d ] -- [external host]
                   |
     [smtp server]-+-[pop3 server]
                   |
               [filesrv]
]]></programlisting>
		<para>
Whilst [client] is reading mail (via [pop3 server]), [external
host] sends an email to his mailbox.  the pop3 client has a file
handle on the mail spool, and suddenly data is appended to this.
Now the problem is, the pop3 client has a copy of (what it
thinks) is the mail spool in memory, and when the user deletes a
file, the mail that's just been received will be deleted, because
the pop3 client doesn't know about it.
		</para>
		<para>
This is actually rather a simplification, as just about every
pop3 client understands this, and will let go of the file
handle.. But, the same thing will happen if a message comes in
-whilst the pop3d is deleting mail-.
		</para>
<programlisting><![CDATA[
                           POP Client    SMTP Client
  I want to lock this file <--
  I want to lock this file       	<--
  You can lock the file    -->
  You can lock the file                  -->
  Consider it locked       <--
  File is locked           -->
  Consider it locked             	<--
  Ooh, I can't lock it                   -->
]]></programlisting>
		<para>
The issue with NFS v1 and v2 is that whilst it has locking support, it's
not atomic. NFS v3 can do this:
		</para>
<programlisting><![CDATA[
  I want to lock this file <--
  I want to lock this file       	<--
  File is locked           -->
  Ooh, I can't lock it                   -->
]]></programlisting>
		<para>
That's why you want NFSv3. Plus, it's faster, and it works over
TCP, rather than UDP 8-)
		</para>
		</blockquote>
		<para>
This is about the hardest clustering thing you'll ever do.
		</para>
		<para>
Stefan Stefanov <emphasis>sstefanov (at) orbitel (dot) bg</emphasis>
		</para>
		<blockquote>
		<para>
I think this might be not-so-hardly achieved with CODA and Qmail.
		</para>
		<para>
Coda (http://www.coda.cs.cmu.edu) allows "clustering" of file
system space. Qmail's (http://www.qmail.org) default mailbox
format is Maildir, which is very lock safe format (even on NFS
without lockd).
		</para>
		<para>
(I haven't implemented this, it's just a suggestion.)
		</para>
		</blockquote>
		</section>
		<section id="pop3_by_fabien">
		<title>pop3/LVS-DR by Fabien</title>
		<para>
Fabien <emphasis>fabien (at) oeilpouroeil (dot) org</emphasis> 03 Oct 2002
		</para>
		<blockquote>
		<para>
I successfully installed and tested a LVS-DR in a small network (1 director and 2 realservers)
with http and pop3 load balancing/high availability, using too some hints from ultramonkey
project (which team I thank too for the very good howto :)).
		</para>
		<para>
About the pop3 LVS here is what I did, and if someone feels like correcting me or
suggesting/advicing me something better I will be grateful !
		</para>
		<para>
I used on both realservers :
- the smtp daemon postfix with the
<ulink url="http://www.oav.net/vda/">VDA patch</ulink>
to handle maildir.
		</para>
		<para>
Here LVS doesn't handle smtp, I just use dns multiple MX feature.
- the light weighted pop3 daemon tpop3d ( http://www.ex-parrot.com/~chris/tpop3d/ )
which can manage maildir.
		</para>
		<para>
The incoming mails are stored on the realservers in maildir type account following
dns MX shedulding, and so are stored quite randomly on each realserver.
To synchronize both realservers so that pop3 accounts are correct when checked,
I use rsync and especially drsync.pl rsync wrapper ( http://hacks.dlux.hu/drsync/ )
which keeps track of a given filelist between rsync synchronizations (here the filelist
is all the maildirs content).
		</para>
		<para>
At the moment, using crontab, drsync is run on each realserver every minutes and
synchronizes the content of the other realserver with his one. It seems to work
with a dozen pop3 accounts and hundreds of mail sent (no loss).
		</para>
		</blockquote>
		<para>
Fabien <emphasis>fabien (at) oeilpouroeil (dot) org</emphasis> 03 Oct 2002
		</para>
		<blockquote>
I have an LVS-DR (1 director and 2 realservers)
with http and pop3 load balancing/high availability
(using some hints from ultramonkey project).
On both realservers I have
		<itemizedlist>
			<listitem>
the smtp daemon postfix with the
<ulink url="http://www.oav.net/vda/">VDA patch to handle maildir</ulink>.
(LVS doesn't handle smtp, I just use the dns multiple MX feature.)
			</listitem>
			<listitem>
		the lightweight pop3 daemon
<ulink url="http://www.ex-parrot.com/~chris/tpop3d/">tpop3d</ulink>
which can manage maildir format.
			</listitem>
		</itemizedlist>
		<para>
The incoming mails are stored on random realservers
in maildir format following dns MX scheduling.
To synchronize both realservers
(so that pop3 accounts are correct when checked),
I use rsync and especially the
<ulink url="http://hacks.dlux.hu/drsync/">drsync.pl rsync wrapper</ulink>,
which keeps track of a given filelist between rsync synchronizations
(here the filelist is the maildir files).
drsync is run on each realserver every minute (cron) synchronizing
the content with the other realserver(s).
So far it works with a dozen pop3 accounts and hundreds
of mail sent with no loss.
		</para>
		</blockquote>
		</section>
		<section>
		<title>strange mail problem</title>
		<para>
trietz <emphasis>trietz (at) t-ipnet (dot) net</emphasis> 18 Oct 2006
		</para>
		<para>
I'm using LVS-NAT for a simple rr-loadbalancing between two sendmail realservers. 
I setup a director with 3 NICs, one for the external connection(eth0) 
and the other two(eth1 and eth2) for connecting my realservers over crosspatch cable.
The director has two ip adresses on the external interface.
Here is the output from <command>ipvsadm-save</command>:
		</para>
<programlisting><![CDATA[
-A -t x.x.x.123:smtp -s rr
-a -t x.x.x.123:smtp -r 192.168.0.1:smtp -m -w 1
-a -t x.x.x.123:smtp -r 192.168.0.2:smtp -m -w 1
-A -t x.x.x.122:smtp -s rr
-a -t x.x.x.122:smtp -r 192.168.0.1:smtp -m -w 1
-A -t x.x.x.123:imaps -s rr
-a -t x.x.x.123:imaps -r 192.168.0.1:imaps -m -w 1
]]></programlisting>
		<para>
The packets intialized by the realservers are SNATed with iptables on the director successfully. 
My problem: loadbalancing works fine, but I see a lot of the reply packets from the realserver 
leaving the director on interface eth0 with the internal ips 192.168.0.1 and 192.168.0.2.
		</para>
		<para>
After testing I assume it is a timeout problem.
		</para>
		<itemizedlist>
			<listitem>
Client creates a smtp connection over the director to the realserver, which works perfect
			</listitem>
			<listitem>
				<para>
Connection hang for a while and times out
				</para>
			</listitem>
			<listitem>
Realserver try to close the connection, but the director doesn't "SNAT" the package
			</listitem>
			<listitem>
It looks like the director forgot the connection, 
because the timeout from the realserver is longer
than the timeout from the director.
			</listitem>
		</itemizedlist>
		<para>
My solution:
		</para>
		<itemizedlist>
			<listitem>
Patch my kernel sources with the <filename>ipvs_nfct</filename> patch.
			</listitem>
			<listitem>
				<para>
Activate conntrack:
				</para>
<programlisting><![CDATA[
echo 1 > /proc/sys/net/ipv4/vs/conntrack
]]></programlisting>
			</listitem>
			<listitem>
				<para>
Add the following iptables rule on the director 
(eth1,2 are on the DRIP network, eth0 faces the internet):
				</para>
<programlisting><![CDATA[
iptables -A FORWARD -i eth1 -o eth0 -m state --state INVALID -j DROP
iptables -A FORWARD -i eth2 -o eth0 -m state --state INVALID -j DROP
]]></programlisting>
			</listitem>
		</itemizedlist>
		<para>
Horms explanation (off-list)
		</para>
		<para>
Basically the real-server and end user have a connection open.
It idles for a long time. So long that the connection entry on
the linux director expires. Then a the real-server sends a packet
over the connection, which the linux director doesn't recognise
and sends out to the ether without unnatting it.
		</para>
		<para>
Solution? Well other than the one he suggests, changing the timeouts
would help, assuming his analysis is correct.
		</para>
		<para>
Joe - this timeout problem came up earlier.
		</para>
		<para>
Dominik Klein <emphasis>dk (at) in-telegence (dot) net</emphasis> 15 May 2006 
		</para>
		<para>
So let's just say we have a simple setup:
		</para>
<programlisting><![CDATA[
client -> switch -> director -> switch -> realserver
]]></programlisting>
		<para>
The client establishes a connection, sends some data, whatever. i
Then it does nothing for say 10 minutes. 
After that it tries to reuse the still established connection and it works just fine.
Then it does nothing for say 16 minutes and tries again to use the still established connection. 
In the meantime, the default timeout for the connection table 
(default 15 minutes) runs out and so this connection is not valid on the director. 
So the director replies with RST on the PSH packet from the client 
and the connection breaks for the client.
The realserver does not know anything about the reset on the director, 
so it still considers the connection established.
		</para>
		<para>
The client opens a new connection, 
but the old one will still be considered established on the realserver. 
That's what made my MySQL server hit the max_connection limit and reject any new clients.
I will try to set the timeout higher, 
as it can easily happen that my clients do nothing for a few hours at
night, which will - sooner or later - hit the max_connection limit again.
		</para>
		</section>
	</section>
	<section id="mail_farm">
	<title>Mail Farms</title>
		<section id="designing_mail_farms">
		<title>Designing a Mail Farm</title>
		<para>
Peter Mueller <emphasis>pmueller (at) sidestep (dot) com</emphasis> 10 May 2001
		</para>
		<para>
what open source mail programs have you guys used for
SMTP mail farm with LVS? I'm thinking about Qmail or Sendmail?
		</para>
		<para>
Michael Brown <emphasis>Michael_E_Brown (at) Dell (dot) com</emphasis>,
Joe and
Greg Cope <emphasis>gjjc (at) rubberplant (dot) freeserve (dot) co (dot) uk</emphasis> 10 May 2001
		</para>
		<blockquote>
You can do load balancing against multiple mail servers without LVS.
Use multiple MX records to load balance,
and mailing list management software (Mailman, maybe?).
DNS responds with all MX records for a request.
The MTA should then choose one at random from the same piority.
(A cache DNS will also return all MX records.)
You don't get persistent use of one MX record.
If the chosen MX record points to a machine that's down,
the MTA will choose another MX record.
		</blockquote>
		<para>
Wensong
		</para>
		<para>
I think that central load balancing is more efficient in resource
utilization than randomly picking up servers by clients, basic queuing
theory can prove this. For example, if there are two mail servers grouped
by multiple DNS MX records, it is quite possible that a mail server of
load near to 1 still receiving new connections (QoS is bad here), in the
mean while the other mail server just has load 0.1. If the central load
balancing can keep the load of two server around 0.7 respectively, the
resource utilization and QoS is better than that of the above case. :)
		</para>
		<para>
Michael Brown <emphasis>Michael_E_Brown (at) Dell (dot) com</emphasis> 15 May 2001
		</para>
		<blockquote>
		<para>
I agree, but... :-)
		</para>
		<orderedlist>
			<listitem>
You can configure most mail programs to start refusing connections when
load rises above a certain limit. The protocol itself has built-in
redundancy and error-recovery. Connections will automatically fail-over to
the secondary server when the primary refuses connections. Mail will
_automatically_ spool on the sender's side if the server experiences
temporary outage.
			</listitem>
			<listitem>
Mail service is a special case. The protocol/RFC itself specified
application-level load balancing, no extra software required.
			</listitem>
			<listitem>
Central load balancer adds complexity/layers that can fail.
			</listitem>
		</orderedlist>
		<para>
I maintain that mail serving (smtp only, pop/imap is another case entirely)
is a special case that does not need the extra complexity of LVS. Basic
Queuing theory aside, the protocol itself specifies load-balancing,
failover, and error-recovery which has been proven with years of real-world
use.
		</para>
		<para>
LVS is great for protocols that do not have the built-in protocol-level
load-balancing and error recovery that SMTP inherently has (HTTP being a
great example). All I am saying is use the right tool for the job.
		</para>
		</blockquote>
		<para>
Note this discussion applies to mail which is being forwarded by the MTA.
The final target machine has the single-writer, many-reader problem
as before (which is fine if it's a single node),
(<emphasis>i.e.</emphasis> don't run the leaf node as an LVS).
		</para>
		<para>
Joe
		</para>
		<blockquote>
How would someone like AOL handle the mail farm problem? How
do users get to their mail? Does everyone in AOL get their
mail off one machine (or replicated copies of it) or is each
person directed to one of many smaller machines to get their
mail?
		</blockquote>
		<para>
Michael Brown
		</para>
		<para>
Tough question...
AOL has a system of inbound mail relays to receive all their user's mail.
Take a look:
		</para>
<programlisting><![CDATA[
[mebrown@blap opt]$ nslookup
Default Server:  ausdhcprr501.us.dell.com
Address:  143.166.227.254

> set type=mx
> aol.com
Server:  ausdhcprr501.us.dell.com
Address:  143.166.227.254

aol.com	preference = 15, mail exchanger = mailin-03.mx.aol.com
aol.com	preference = 15, mail exchanger = mailin-04.mx.aol.com
aol.com	preference = 15, mail exchanger = mailin-01.mx.aol.com
aol.com	preference = 15, mail exchanger = mailin-02.mx.aol.com
aol.com	nameserver = dns-01.ns.aol.com
aol.com	nameserver = dns-02.ns.aol.com
mailin-03.mx.aol.com	internet address = 152.163.224.88
mailin-03.mx.aol.com	internet address = 64.12.136.153
mailin-03.mx.aol.com	internet address = 205.188.156.186
mailin-04.mx.aol.com	internet address = 152.163.224.122
mailin-04.mx.aol.com	internet address = 205.188.158.25
mailin-04.mx.aol.com	internet address = 205.188.156.249
mailin-01.mx.aol.com	internet address = 152.163.224.26
mailin-01.mx.aol.com	internet address = 64.12.136.57
mailin-01.mx.aol.com	internet address = 205.188.156.122
mailin-01.mx.aol.com	internet address = 205.188.157.25
mailin-02.mx.aol.com	internet address = 64.12.136.89
mailin-02.mx.aol.com	internet address = 205.188.156.154
mailin-02.mx.aol.com	internet address = 64.12.136.121
dns-01.ns.aol.com	internet address = 152.163.159.232
dns-02.ns.aol.com	internet address = 205.188.157.232
]]></programlisting>
		<para>
So that is on the recieve side. On the actual user reading their mail
side, things are much different. AOL doesn't use normal SMTP mail. They
have their own proprietary system, which interfaces to the normal internet
SMTP system through gateways. I don't know how AOL does their internal,
proprietary stuff, but I would guess it would be massively distributed
system.
		</para>
		<para>
Basically, you can break down your mail-farm problem into two, possibly
three, areas.
		</para>
<programlisting><![CDATA[
1) Mail receipt (from the internet)
2) Users reading their mail
3) Mail sending (to the internet)
]]></programlisting>
		<para>
Items 1 and 3 can normally be hosted on the same set of machines, but it
is important to realize that these are separate functions, and can be
split up, if need be.
		</para>
		<para>
For item #1, the listing above showing what AOL does is probably a good
example of how to set up a super-high-traffic mail gateway system. I
normally prefer to add one more layer of protection on top of this: a
super low-priority MX at an offsite location. (example: aol.com preference
= 100, mail exchanger = disaster-recovery.offsite.aol.com )
		</para>
		<para>
For item #2, that is going to be a site policy, and can be handled many
different ways depending on what mail software you use (imap, pop, etc).
The good IMAP software has LDAP integration. This means you can separate
groups of users onto separate IMAP servers. The mail client then can get
the correct server from LDAP and contact it with standard protocols
(IMAP/POP/etc).
		</para>
		<para>
For item #3, you will solve this differently depending on what software
you have for #2. If the client software wants to send mail directly to a
smart gateway, you are probably going to DNS round-robin between several
hosts. If the client expects it's server (from #2) to handle sending
email, then things will be handled differently.
		</para>
		<para>
Wenzhuo Zhang <emphasis>wenzhuo (at) zhmail (dot) com</emphasis>
		</para>
		<para>
Here's an
<ulink url="http://www.linuxworld.com/linuxworld/lw-1999-09/lw-09-sendmail.html">
article on paralleling mail servers</ulink> by Derek Balling.
		</para>
		<para>
Shain Miley 25 May 2001
		</para>
		<blockquote>
I am planning on setting up an LVS IMAP cluster.
I read some posts that talk about file locking problems
with NFS that might cause mailbox corruption.
Do you think NFS will do the trick or is there a better
(faster, journaling) file system out there that will work in a
production environment.
		</blockquote>
		<para>
Matthew S. Crocker <emphasis>matthew (at) crocker (dot) com</emphasis> 25 May 2001
		</para>
		<para>
NFS will do the trick but you will have locking problems if you use mbox
format e-mail.  You *must* use MailDir instead of mbox to avoid the
locking issues.
		</para>
		<para>
You can also use GFS (www.globalfilesystem.org) which has a fault tolerant
shared disk solution.
		</para>
		<para>
Don Hinshaw <emphasis>dwh (at) openrecording (dot) com</emphasis>
		</para>
		<para>
I do this. I use Qmail as it stores the email in Maildir format, which uses
one file per message as opposed to mbox which keeps all messages in a single
file. On a cluster this is an advantage since one server may have a file
locked for writing while another is trying to write. Since they are locking
two different files it eases the problems with NFS file locking.
		</para>
		<para>
Courier also supports Maildir format as I believe does Postfix.
		</para>
		<para>
I use Qmail+(many patches) for SMTP, Vpopmail for a single UID mail sandbox
(shell accounts my ass, not on this rig), and Courier-Imap. Vpopmail is
configured to store userinfo in MySQL and Courier-Imap auths out of
Vpopmail's tables.
		</para>
		<para>
Joe:
		</para>
		<blockquote>
I've always had the creeps about pop and imap sending clear text passwds.
How do you handle passwds?
		</blockquote>
		<para>
It's a non-issue on that particular system, which is a webmail server. There
is no pop, just imapd and it's configured to allow connections only from
localhost. The webmail is configured to connect to imapd on localhost. No
outside connections allowed.
		</para>
		<para>
But, this is another reason that I started using Vpopmail. Since it is a mail
sandbox that runs under a single UID, email users don't get a shell account,
so even if their passwords are sniffed, it only gets the cracker a look into
that user's mailbox, nothing more.
		</para>
		<para>
At least on our system. If a cracker grabs someone's passwd and then finds
that the user uses the same passwd on every account they have, there's not
much I can do about that.
		</para>
		<para>
On systems where users do have an ftp or shell login, I make sure that their
login is not the same as their email login and I also gen random passwords
for all such accounts, and disallow the users changing it.
		</para>
		<para>
I'm negotiating a commercial contract to host webmail for a company (that you
would recognize if I weren't prohibited by NDA from disclosing the name), and
if it goes through then I'll gen an SSL cert for that company and auth the
webmail via SSL.
		</para>
		<para>
You can also support SSL for regular pop or imap clients such as Netscape
Messanger or MS Outlook or Outlook Express.
		</para>
		<para>
Everything is installed in /var/qmail/* and that /var/qmail/ is an NFS v3
export from a RAID server. All servers connect to a dedicated MySQL server
that also stores it's databases on another NFS share from the RAID. Also each
server mounts /www from the RAID.
		</para>
		<para>
Each realserver runs all services, smtpd, imapd, httpd and dns. I use TWIG as
a webmail imap client, which is configured to connect to imapd on localhost
(each server does this). Incoming smtp, httpd and dns requests are load
balanced, but not imapd, since they are local connections on each server.
Each server stores it's logs locally, then they are combined with a cron
script and moved to the raid.
		</para>
		<para>
It's been working very well in a devel environment for over a year (round-
robin dns, not lvs). I've recently begun the project to rebuild the system
and scale it up into a commercially viable system, which is quite a task
since most of the software packages are at least a year old, and I'll be
using a pair of LVS directors instead of the RRDNS.
		</para>
		<para>
Matthew Croker
		</para>
		<para>
Users will also be using some sort of webmail (IMP/HORDE) to get their
mail when they are off site...other than that standard Eudora/Netscape
will be used for retrieval.
		</para>
		<para>
I settled on TWIG mainly because of it's vhost support. With Vpopmail, I can
execute
		</para>
<programlisting><![CDATA[
# /var/qmail/vpopmail/bin/vadddomain somenewdomain.com <postmaster passwd>
]]></programlisting>
		<para>
and add that domain to dns and begin adding users and serving it up. I had to
tweak TWIG just a bit to get it to properly deal with the "user@domain" style
login that Vpopmail requires, but otherwise it works great. Each vhost domain
can have it's own config file, but there is only one copy of TWIG in /www.
TWIG uses MySQL, and though it doesn't require it, I also create a seperate
database for each vhost domain.
		</para><para>
IMP's development runs along at about Mach 0.00000000004 and I got tired of
waiting for them to get a working addressbook. That plus it doesn't vhost all
that well. SquirrelMail is very nice, but again not much vhost support. Plus
TWIG includes the kitchen sink. Email, contacts, schedule, notes, todo,
bookmarks and even USENET (which I don't use), each module can be
enabled/disabled in the config file for that domain, and it's got a very
complete advanced security module (which I also don't use). It's all PHP and
using mod_gzip is pretty fast. I tested the APC optimizer for PHP, but every
time I made a change to a script I had to reload Apache. Not very handy for a
devel system, but it did add some noticable speed increases, until I unloaded
it.
		</para>
		<para>
(Joe - I've lost track of who is who here)
		</para>
		<para>
The realservers would need access to both the users home directories as
well as the /var/mail directory. I am not too familiar with the actual
locking problems...I understand the basics but I also hear that NFS V3
was supposed to fix some of the locking issues with V2...I also saw some
links to GFS,AFS,etc not too sure how they would work...
		</para>
		<para>
For those of you that missed the importance of using Maildir format...
		</para>
		<para>
Alexandra Alvarado
		</para>
		<blockquote>
I need to implement a cluster
mail server with 2 computers smtp, 2 computers pop3
and 2 computers (NAS) failover for storage.
The idea is to have duplicated copies of the mail
(/var/spool/mail and /var/spool/mqueue) in the
nas using online replication.
		</blockquote>
		<para>
Matthew Crocker <emphasis>matthew (at) crocker (dot) com</emphasis> 20 May 2003
		</para>
		<para>
Do not use mbox mailbox format.  mbox does not work well over NFS with
multiple hosts writing to the same file.  You should use Maildir
format.  Just about every SMTP server can handle Maildir.
		</para>
		<para>
I'm running 4 mail servers.  All mail servers have SMTP,POP3,IMAP,
SMTPS,IMAP-SSL,POP3-SSL running on them.  I'm using qmail, qmail-ldap,
and Courier-IMAP.
I have a Network Appliance NetFiler F720 200gig NFS server for my
Maildir storage
I have 3 OpenLDAP servers setup with 1 master and 2 slaves.
The Mail servers only talk with the slaves.  All mailAddress
information is held in the LDAP directory.
		</para>
		<para>
You need to centralize the storage of mail using NAS and centralized
the storage of account information using either LDAP or MySQL
		</para>
		<para>
How do you plan on failing over the NAS?
NFS with soft mounts should handle it pretty well.   Setup 2 Linux
boxes one as an active, one as a passive NFS server.  Both connected
via Fiber Channel to a chunk of drives.  The passive machine *must*
have a way to STOMITH (Shoot The Other Machine In The Head) the active
server if it crashes.  You do not want to have both machines mounting
the same drive space at the same time.  Very bad things will happen....
		</para>
		<para>
Soo..
Setup an EXT3 filesystem on the FC drives.  mount it on the active
Linux box, export it over NFS with a virtual IP address.
If the active server fails you need to remove power from it using a
remote power switch.  You need to be able to guarantee that it won't
come back to life and start writing to the filesystem again.  Clean the
FC filesystem.  remount it and export it over NFS on the same virtual
IP addresses.
keepalived can handle the VIP stuff with VRRP.  I think it can also
launch an external script during a failover to handle the shooting,
cleaning, mounting, exporting of the filesystem.  EXT3 cleans pretty
quickly.
		</para>
		<para>
The SMTP/POP3 servers will be very un-happy to see their NFS server
disappear so you will need to recover quickly.  Processes will probably
pile up in 'D'isk wait status on all of the machines. load will go
through the roof. After the NFS server comes back online the hung
processes should recover and finish up.
		</para>
		<para>
Adaptec makes a very nice 12 disk rack mounted RAID controller that has
U160 SCSI going to the disks and 1 gig FiberChannel going to the
servers.  Redundant power, Redundant RAID controllers, Redundant FC
loops going to each server.  It is called the DuraStor 7320S.  Plan on
about $10kUS + drives for this type of system.
		</para>
		<para>
Network Appliance make an amazing box with complete High Availability
failover of clustered data.  You can expect to pay $200KUS for a
complete clustered solution with 300GB usable storage.  Fully
redundant.  Pretty much shoot a shotgun at it and not go down or lose
data.
		</para>
		<para>
EXT3 running on Logical Volume Manager (LVM) can handle journalling and
snapshots
		</para>
		<para>
Making the servers/services redundant is easy.  Making your NAS/SAN
redundant is expensive.
		</para>
		<para>
I'm looking into the Adaptec external RAID controller/drive array setup
with 2 Linux boxes for my NAS.  I've been running my NetApp for 3 years
and have *NEVER* had it crash.  It really is an amazing box.  The
problem is it is only one box and I don't have $200k to make it a
cluster.  I think I can do a pretty good job for about $20k with the
Adaptec box, a bunch of Seagate drives and a couple Linux boxes.
		</para>
		<para>
You could also look into distributed filesystems like GFC, Coda ...
but I don't feel confident enough in them to handle production data
just yet.
		</para>
		<blockquote>
Just a quick note: About a week ago I tried compiling a kernel that had been
patched by SGI for XFS. The kernel (2.4.2) compiled fine, but choked once the
LVS patches had been applied. Not having a lot of time to play around with
it, I simply moved to 2.4.4+lvs 0.9 and decided not to bother with XFS on the
director boxes.
		</blockquote>
		<para>
also I thought
about samba and only found one post from last year where someone was
going to try it but there was no more info there.
		</para>
		<blockquote>
Well, there's how I do it. I've tried damned near every combination of GPL
software available over about the last 2 years to finally arrive at my
current setup. Now if I could just load balance MySQL...
		</blockquote>
		<para>
Greg Cope
		</para>
		<blockquote>
MySQL connections / data transfere
work much faster (20% ish) when on local host - so how about running
mysql on each host, which is a select only system, and each localhost
uses replication to a mster DB that is used for inserts and updates ?
		</blockquote>
		<para>
Ultimately I think I'll have to. After I get done rebuilding the system to
use kernel 2.4 and LVS and everything is stabilized, then I'll be looking
very hard at just this sort of thing.
		</para>
		<para>
Joe, 04 Jun 2001
		</para>
		<para>
SMTP servers need access to DNS for reverse name lookup. If they
are LVS'ed in a LVS-DR setup, won't this be a problem?
		</para>
		<para>
Matthew S. Crocker <emphasis>matthew (at) crocker (dot) com</emphasis>
		</para>
		<blockquote>
You only need to make sure you have the proper forward and reverse lookup
set. inbound mail to an SMTP server gets load balanced by the LVS but it still
sees the orginal from IP of the sender and can do reverse lookups as
normal. outbound mail from an SMTP server makes connections from its real IP
address which can be NAT'd by a firewall or not. That IP address can also
be reverse looked up.
		</blockquote>
		<para>
normally the realservers in a LVS-DR
setup have private IPs for the RIPs and hence they can't receive replies
from calls made to external name servers.
		</para>
		<para>
I would also assume that people would  write filter rules to only
allow packets in and out of the realservers that belong to the services
listed in the director's <command>ipvsadm</command> tables.
		</para>
		<para>
I take it that your LVS'ed SMTP servers can access external DNS servers,
either by NAT through the director, or in the case of LVS-DR by having
public IPs and making calls from those IPs to external nameservers
via the default gw of the realservers?
		</para>
		<blockquote>
We currently have our realservers with public IP addresses.
		</blockquote>
		<para>
Bowie Bailey <emphasis>Bowie_Bailey (at) buc (dot) com</emphasis>
		</para>
		<blockquote>
You can also do this by NAT through a firewall or router.
I am not doing SMTP, but my entire LVS setup (VIPs and all)
is private. I give the VIPs a static conduit through the firewall
for external access. The realservers can access the internet via NAT,
the same as any computer on the network.
		</blockquote>
		<para>
<emphasis>Adail Oliveira</emphasis>
		</para>
		<blockquote>
I want to build e-mail cluster using lvs, anybody have experience with this?
		</blockquote>
		<para>
<emphasis>kwijibo (at) zianet (dot) com</emphasis>
		</para>
		<para>
It is pretty much the same as setting up an LVS for any other service.  
The biggest problem you will probably have is figuring
out how handle storage for the mailboxes.
My experience is that it works great.  
I am not sure how I would handle our mail load without it.
		</para>
		<para>
Todd Lyons <emphasis>tlyons (at) ivenue (dot) com</emphasis> 2005/27/05 
		</para>
		<para>
Agreed. We use a NetApp for our central NFS server, 2 http machines for
webmail, 2 imap machines, and 2 smtp machines.  We have a 2 node load
balancer with failover that balances the 3 protocols listed above (as
well as other webservers).  The 6 machines serving mail are dual P4 2.8
GHz with 1Gig RAM boxen, the load balancers are old P3 700 boxes that
only do load balancing.  We're just a small system though compared to
many who do it.  We estimate we could scale up to about 10-20 real
servers for each service before we start to get throughput problems with
the NetApp.
		</para>
		<para>
Graeme Fowler <emphasis>graeme (at) graemef (dot) net</emphasis> 15 Dec 2005
		</para>
		<para>
My day job sees me working for an ISP; we have a number of mail systems
where we use multiple frontend servers (some behind LVS, some using
other methods) with NetApp Filer backends offering mail storage over NFS
mounts to the real/frontend servers. They handle SMTP, POP, IMAP,
Webmail (and other things not necessarily mail related) but store the
data on common NFS mounts.
		</para>
		<para>
Yes, there are well-documented issues with "mail on NFS" but that
usually happens with shared SMTP server spools rather than IMAP/POP
systems. We haven't had a problem yet; the filers are very reliable (and
good if they do go wrong on rare occasions, too) and the platform scales
out nicely.
		</para>
		<para>
Pierre Ancelot <emphasis>pierre (at) bostoncybertech (dot) com</emphasis> 15 Dec 2005 
		</para>
		<blockquote>
			<para>
I tried to implement a load balance mail system with imap and imaps
In this case, a user creating an imap folder will create it on only one node....
How do I update a mail received on one host to every other host?
Using rsync would delete every mail received in the same time on other servers...
			</para>
		</blockquote>
		<para>
Scott J. Henson <emphasis>scotth () csee ! wvu ! edu</emphasis> 2005-12-15 
		</para>
		<para>
Perdition or Courier-Imap.  Both of them are/have imap proxies(or 
directors).  So what you end up with is one(or more) front end proxies 
that send the person to the right machine.  It looks something like 
this.  Btw, we are moving to such a setup so I don't know how well it 
will be
		</para>
		<para>
The connection hits your load balancers(just straight ip_vs).
Then it hands of the connection to a pool of imap proxies.  Then each 
imap proxy figures out which real mail warehouse to send the message 
to(ldap is a good place to store this info cause it too can be load 
balanced, slaves anyway and then no need to load balance the master). 
		</para>
		<para>
At that point the user does their thing and its all stored on one 
server.  But you have many mail boxes distributed across many mail 
warehouses.  There is an issue of backups and such for the mail 
warehouse, but this distributes the load so you can serve many more mail 
boxes than one server could.  I think we are gonna go with RAID arrays 
and then hot spare mail warehouse mirrors.  If the lead warehouse fails 
the backup comes online(through something like heartbeat).  This should 
be more than enough redundancy for us, but you may want to look into 
other solutions if you want more, aka fiberchannel or some such.
		</para>
		<para>
Obviously this setup can get very complex but become very stable.  
Depending on your application you can throw money at it or not even have 
hot spares and trust in your RAID/backups. 
		</para>
		<para>
Mark<emphasis>msalists () gmx ! net</emphasis> 2005-12-15
		</para> 
		<blockquote>
Maybe I am misinterpreting this, 
but it sounds like each mailbox is assigned to exactly one realserver?
So you have distributed the mailboxes for load-balancing, 
but is there any redundancy if one of the boxes goes down?
		</blockquote>
		<para>
Scott J. Henson <emphasis>scotth (at) csee (dot) wvu (dot) edu</emphasis> 15 Dec 2005 
		</para>
		<para>
Nope, you're not misinterpreting anything.  With mail you can't really 
have the type of redundancy you can have with say a webserver serving 
out content.  The problem is that imap doesn't like to be distributed.  
The only way is to do it over something like iSCSI or fiberchannel or 
some other enterprise level storage medium.  What we are doing is to 
distribute load and to provide some redundancy.  If one mail box goes 
down then we bring up the hot spare, but most of our mail boxes still 
stay up.  Also if one has a failed RAID, then we can move all the mail 
boxes off of it and bring it down, repair the raid, then bring it back 
up and move the mail boxes back.  It really offers more flexibility and 
does increase the redundancy on a site level. 
		</para>
		<para>
Todd Lyons <emphasis>tlyons () ivenue ! com</emphasis> 
2005-12-16 
		</para>
		<para>
Could always go with something like cyrus-imap with the murder
extension, which is for an imap cluster.  I've never set it up, don't
know any details much beyond what I've stated here.  But it's supposed
to make the mail machines look like a cluster.
		</para>

		<para>
Kees Bos <emphasis>k.bos () zx ! nl</emphasis> 
2005-12-16 
		</para>
		<para>
Maybe you can put some kind of imapproxy in front of your imap servers.
The imapproxy than has to know about the multiple imap servers and the
imapproxy itself can be loadbalanced.
I haven't used it myself, but perdition seems to do this:
  http://www.vergenet.net/linux/perdition/
		</para>
		<para>
Scott J. Henson <emphasis>scotth () csee ! wvu ! edu</emphasis> 
2005-12-16 
		</para>
		<para>
Yes, I forgot to mention that, but word from the already been there, its 
HARD.  At least in my experience its more trouble than its worth. 
		</para>
		</section>
		<section id="commercial_mail_farm">
		<title>Commercial Mail Farm</title>
		<para>
Here's an example of a commercial mail farm using LVS. 
Commercial ventures are usually loathe to tell us how they use LVS - 
Seems they don't understand the spririt of GPL.
Even after you're told the setup, you still need
someone to get it going and keep it going, 
so I don't know what advantage they get
out of keeping their setups secret.
Michael Spiegle popped up on the mailing list and gave some info
about a LVS'ed mail farm he'd setup for a customer, 
so I asked off-list if he'd mind giving us more details.
So here it is. Thanks Michael. 
		</para>
		<para> 
Michael Spiegle <emphasis>mike (at) nauticaltech (dot) com</emphasis> 13 Nov 2006
		</para>
		<para>
The setup is VERY simple and straightforward. 
We have 17 mailservers in production right now.
Here's some specs on our setup:
		</para>
		<para>
Pair of LVS-NAT directors, each dual Xeon, 2GB RAM, dual 3com Fiber 1000SX NICS,
failover uses keepalived.
There is no firewall in-front of the directors.
The 17 mail servers are dual Xeon, 4GB RAM, dual 10K SCSI disks in RAID1 (software), 
dual onboard e1000.
		</para>
		<para>
During peak time today (monday has highest load), 
we were doing about 14K active connections at any
given time (probably over 30K inactive connections).  
Actual bandwidth isn't terribly high... due to the nature of the service.  
The director pair also provides load balancing for a cluster of 30 Sun X1
servers running HTTPd, which has much fewer connections, 
but a little more bandwidth intensive.  
I think we might be pushing 350mbit/sec at  peak times (haven't seen MRTG graphs in a while).
		</para>
		<para>
Our services allow local mailboxes and forwarding to external addresses.  
We have something in the
neighborhood of 250K local mailboxes and 170K external forwards.  
The load on the director pair is practically non-existent (generally 0.0x).  
		</para>
		<para>
The ONLY time we have EVER come close to maxing out our LVS was during a DDOS attack.  The
NICs we use don't have interrupt coalescence in the driver, so we were actually running out of
interrupts on the box which isn't the fault of LVS.  I don't recall any other metrics from the
DDOS attack, but LVS would have swallowed it if we had interrupt coalescence.
		</para>
		<para>
The mailservers however have some issues which need to be sorted out.  
They run anywhere from 2 to 15 as the load average.  
They use their local disks heavilly
for temporary incoming mail storage.  
We store all mail on a pair of NetApp FAS-940s which we appear
to be pushing the limits on somehow (
the excessive amount of NFS-wait we're hitting is driving up the
load on the mailservers).  
		</para>
		<para>
How does localmail get from the realservers to the NetApp?
The mailserver uses multiple daemons to accomplish mail tasks.  
When a piece of mail comes in, a message is created on the disk.  
Another daemon is dedicated to figuring out where the
messages go (to an external forward, or to a local mailbox).  
If the message is going to an external forward, 
it is handled by an external-mail daemon.  
If the message is staying local,
an internal-mail daemon puts it on the NetApp.
		</para>
		<para>
When a customer connects via POP, the POP server looks up the location of the mailbox in
memory, then goes straight to the NetApp to fetch the messages.  
All NetApps are mounted to
the realservers via Linux NFS client.
(the excessive amount of NFS-wait we're hitting is driving up the load
on the mailservers).
		</para>
		<blockquote>
nfs used to be a real dog. It's impressive that nowadays you can run a network
disk for a machine that's being pushed hard.
		</blockquote>
		<para>
On any given server, we've got 300 items in dmesg regarding "couldn't contact NetApp".  We
have some issues to sort out regarding the NFS mount options we're using.  Also, the NetApps
have an issue where if a single mailbox hits the dirsize limits (I think its something on the
order of 2 million messages in a single directory), the NetApp freaks out and pegs 100% CPU. 
During this time, load on the mailservers doubles because those mail processes/daemons can't
talk to the NetApp and causes a pile-up of connections.
		</para>
		<para>
It is a real "cluster" in the sense that customer data 
(email address to local mailbox mapping) 
is stored in a memory-resident database - therefore, access is VERY fast and
any server can handle any number of connections.
		</para>
		<para>
We have a pair of dual-xeon boxes running tinyDNS to provide caching DNS for the mail cluster.
Previously, we had our default gateways on the mailservers set to the 2nd interface 
of the directors
(which were also load balanced).  This caused all cache DNS traffic to go through the LVS which
resulted in a conntrack table of over 100K at peaktimes.  Even though the DNS traffic was UDP,
netfilter attempts to create a very basic connection status for the traffic.  
For example, if mailserver01 sends out a DNS request to dnscache01, 
netfilter will create a conntrack table entry and
label it as unack'd until LVS sees a response from dnscache01.  
When it sees this response, it relabels the connection to ack'd.  
Once I realized what was going on, I re-architected the DNS layout
slightly to allow the mailservers to directly communicate with the caching nameservers.  
Now, the LVS runs about 20-25K connections in conntrack.
		</para>
		<para>
About the limitations of conntrack.  
Previously (year ago), we had an old pair of DNS caches, 
which were nothing more than single-proc P3 boxes @ 900Mhz.  
We NEVER had a problem with these boxes until we provisioned the new cache boxes (dual xeon).  
The old boxes were on the same VLAN as the mailservers, 
so traffic/connections through LVS weren't really a problem.  
When we provisioned the new DNS caches, 
which were to be "segregated" from other internal networks, 
thus the mailservers using LVS as a gateway to hit them.  
I always had a feeling that our mail servers
were "slower" with the new caches than the old ones.  
I dug deeper one day and found out that we were
hitting conntrack limits on LVS from all these DNS queries.  
I alleviated that as I explained earlier
by re-architecting the DNS cache layout, 
but I still don't feel it was quite up to snuff.  I did
notice that each of the new DNS caches had netfilter enabled in kernel 
(unnecessary addition from our
shoddy development team) and we were hitting conntrack limits on them as well.  
		</para>
		<para>
The moral of the story is that I never had these problems with the old servers, 
because I compiled the kernel WITHOUT netfilter.  
So in the old kernel
		</para>
		<itemizedlist>
			<listitem>, 
there are no conntrack limits to hit, 
			</listitem>
			<listitem>
the kernel doesn't have to do
lookups in a massive 100K table for each connection.  
If my math serves me right, 100K
conntrack entries consumes a little over 100MB of RAM.
			</listitem>
		</itemizedlist>
		<para>
Its not very scientific, but I believe conntrack 
introduces enough latency to be noticeable at our level.  
		</para>
		<para>
Since we run a "real" cluster, we can fail out any machine as we please.  
Any mailserver can handle any customer.
		</para>
		<para>
We also have a separate LVS-DR web cluster based on linux x86.  
It runs the same memory-resident database to build apache virtualhost entries on the fly.  
Also, since each customer has their own IP (for SSL purposes), the realservers have
about 65K (250+ class Cs) bound to the loopback.  Works beautifully.
		</para>
		<blockquote>
How do you handle <xref linkend="1024_failover"/>?
		</blockquote>
		<para>
Since I haven't had a chance to work on that particular system yet, I don't know.  
I can tell you however that the slave wouldn't have to ARP for all of those IPs
in our particular setup.  We have a pair of PIX firewalls in front of the LVS which do
passthru to the LVS.  The only thing the slave has to ARP for is the placeholder IP on the
interface, and the firewall will figure out where to send the traffic.  True, if the master
firewall died, the slave would have to ARP for all the IPs... but we've found the firewalls to
be quite reliable.
		</para>
		<para>
I'm hoping to be able to push LVS a little farther with a possible project in the upcomming month.
I'm leaving this place I currently work at and am going to a company 
that does lots of media streaming.  
They're using netscalers to push 10gbit of bandwidth outbound 
in an asymmetrical-routing sort of way.  
Since they cost 80K/ea, 
I'm hoping I can convince them that LVS is just as good if not better for MUCH cheaper.
		</para>
		</section>
	</section>
	<section id="DNS_single_port" xreflabel="DNS single port">
	<title>dns, tcp/udp 53 (and dhcpd server 67, dhcp client 68)</title>
	<note>
		<para>
For an article containing a section on loadbalancing by DNS, 
see <ulink url="http://1wt.eu/articles/2006_lb/">
http://1wt.eu/articles/2006_lb/ Making applications scalable with Load Balancing</ulink>
by Willy Tarreau.
		</para>
		<para>
Another article about using 
<ulink url="http://www.zytrax.com/books/dns/ch9/rr.html">round robin DNS</ulink>
to load balance services.
		</para>
	</note>
	<para>
For rotating/round robin DNS/DNS for geographically distributed load balancing,
see <xref linkend="load_balancing_by_DNS"/>
	</para>
	<para>
DNS uses tcp and udp on port 53. It's a little more complicated than a regular
single port service and is in the multiple port section at
<xref linkend="DNS"/>
	</para>
	</section>
	<section id="httpd">
	<title>http name and IP-based (with LVS-DR or LVS-Tun), tcp 80</title>
	<para>
http with name- and ip-based http
is a simple one port service. Your httpd must be listening to the VIP
which will be on lo:0 or tunl0:0. The httpd can be listening on the
RIP too (on eth0) for mon, but for the LVS you need the httpd listening
to the VIP.
	</para>
	<para>
Thanks to Doug Bagley <emphasis>doug (at) deja (dot) com</emphasis> for getting this info on
ip and name based http into the HOWTO.
	</para>
	<para>
Both ip-based and name-based webserving in an LVS are simple.
In ip-based (HTTP/1.0) webserving, the client sends a request to a hostname
which resolves to an IP (the VIP on the director). The director
sends the request to the httpd on a realserver. The httpd
looks up its httpd.conf to determine how to handle the request (e.g.
which DOCUMENTROOT).
	</para>
	<para>
In named-based (HTTP/1.1) webserving, the client passes the HOST: header
to the httpd. The httpd looks up the httpd.conf file and directs the
request to the appropriate DOCUMENTROOT. In this case all URL's on
the webserver can have the same IP.
	</para><para>
The difference between ip- and name-based web support is handled by
the httpd running on the realservers.  LVS operates at the IP level
and has no knowledge of ip- or name-based httpd and has no need to
know how the URLs are being handled.
	</para><para>
Here's the definitive word on
<ulink url="http://www.apache.org/docs/vhosts/index.html">
ip-based and name-based web support</ulink>.
Here are some excerpts.
	</para>
	<blockquote>
	<para>
The original (HTTP/1.0) form of http was IP-based, <emphasis>i.e.</emphasis> the httpd
accepted a call to an IP:port pair, eg 192.168.1.110:80. In the
single server case, the machine name (www.foo.com) resolves to
this IP and the httpd listens to calls to this IP. Here's the
lines from httpd.conf
	</para><para>
<programlisting><![CDATA[
Listen 192.168.1.110:80
<VirtualHost 192.168.1.110>
        ServerName lvs.mack.net
        DocumentRoot /usr/local/etc/httpd/htdocs
        ServerAdmin root@chuck.mack.net
        ErrorLog logs/error_log
        TransferLog logs/access_log
</VirtualHost>
]]></programlisting>
	</para>
	</blockquote>
	<para>
To make an LVS with IP-based httpds, this IP is used as
the VIP for the LVS and if you are using LVS-DR/VS-Tun,
then you set up multiple realservers, each with the httpd
listening to the VIP (ie its own VIP). If you are running an LVS
for 2 urls (www.foo.com, www.bar.com), then you have
2 VIPs on the LVS and the httpd on each realserver
listens to 2 IPs.
	</para><para>
The problem with ip-based virtual hosts is that an IP
is needed for each url and ISPs charge for IPs.
	</para>
	<para>
Doug Bagley <emphasis>doug (at) deja (dot) com</emphasis>
	</para>
	<blockquote>
	<para>
With HTTP/1.1, a client
Name based virtual hosting uses the HTTP/1.1 "Host:" header,
which HTTP/1.1 clients send.  This allows the server to know what
host/domain, the client thinks it is connecting to.  A normal
HTTP request line only has the request path in it, no hostname,
hence the new header.  IP-based virtual hosting works for older
browsers that use HTTP/1.0 and don't send the "Host:" header, and
requires the server to use a separate IP for each virtual domain.
	</para>
	<para>
The httpd.conf file then has
	</para>
<programlisting><![CDATA[
NameVirtualHost 192.168.1.110

<VirtualHost 192.168.1.110>
ServerName www.foo.com
DocumentRoot /www.foo.com/
..
</VirtualHost 192.168.1.110>

<VirtualHost 192.168.1.110>
ServerName www.bar.com
DocumentRoot /www.bar.com/
..
</VirtualHost 192.168.1.110>
]]></programlisting>
	<para>
DNS for both hostnames resolves to 192.168.1.110 and the httpd
determines the hostname to accept the connection from the
"Host:" header. Old (HTTP/1.0) browsers will be served the
webpages from the first VirtualHost in the httpd.conf.
	</para>
	<para>
For LVS again nothing special has to be done. All the hostnames
resolve to the VIP and on the realservers, VirtualHost directives
are setup as if the machine was a standalone.
	</para>
	</blockquote>
	<para>
Ted Pavlic <emphasis>pavlic (at) netwalk (dot) com</emphasis>.
	</para>
	<para>
Note that in 2000,
http://www.arin.net/announcements/ ARIN
(look for &quot;name based web hosting&quot;
announcements, the link changes occasionally, couldn't find it anymore - May 2002)
announced that IP based webserving would be phased out
in favor of name based webserving for ISPs who have more that
256 hosts. This will only require one IP for
each webserver. (There are exceptions, ftp, ssl, frontpage...)
	</para>
		<section id="slash_terminate_urls">
		<title>"/" terminated urls</title>
		<para>
Noah Roberts wrote:
		</para>
		<blockquote>
When I use urls like www.myserver.org/directory/ everything works fine.
But if I don't have the ending / then my client attempts to find the
realserver and ask it, and it uses the hostname that I have in
/etc/hosts on the director which is to the internal LAN so it fails
badly.
		</blockquote>
		<para>
Scott Laird <emphasis>laird (at) internap (dot) com</emphasis> 02 Jul 2001
		</para>
		<para>
Assuming that you're using Apache, set the ServerName for the realserver
to the virtual server name.  When a user does a 'GET /some/directory',
Apache returns a redirect to 'http://$servername/some/directory/'.
		</para>
		</section>
	</section>
	<section id="httpd_with_lvs-nat">
	<title>http with LVS-NAT</title>
	<para>
Summary: make sure the httpd on the realserver is listening on the RIP
not the VIP (this is the opposite of what was needed for LVS-DR or LVS-Tun).
(Remember, there is no VIP on the realserver with LVS-NAT).
	</para><para>
tc lewis had an (ip-based) non-working http LVS-NAT setup. The VIP
was a routable IP, while the realservers were virtual hosts on the
non-routable 192.168.1.0/24 network.
	</para><para>
<blockquote><para>
Michael Sparks <emphasis>michael (dot) sparks (at) mcc (dot) ac (dot) uk</emphasis>
			</para><para>
What's happening is a consequence of using NAT. Your LVS is accepting
packets for the VIP, and re-writing them to either 192.168.123.3 or
192.168.123.2. The packets therefore arrive at those two servers marked
for address 192.168.123.2 or 192.168.123.3, not the VIP.
			</para><para>
As a result when apache sees this:
<programlisting><![CDATA[
<VirtualHost w1.bungalow.intra>
...
</VirtualHost>
]]></programlisting>
			</para><para>
It notices that the packets are arriving on either 192.168.123.2 or
192.168.123.3 and not w1.bungalow.intra, hence your problem.
			</para><para>
Solutions
<itemizedlist>
<listitem><para>
If this is the only website being serviced by these two servers, change
the config so the default doc root is the one you want.
			</para><para>
</para></listitem><listitem><para>
If they're servicing many websites, map a realworld IP to an alias on the
realservers and use that to do the work. IMO this is messy, and could
cause you major headaches.
			</para><para>
</para></listitem><listitem><para>
Use LVS-DR or LVS-Tun - that way the above config could be used without
problems since the VS address is a local address as well. This'd be my
choice.
</para></listitem></itemizedlist>
</para></blockquote>
			</para><para>
Joe 10 May 2001
			</para><para>
It just occured to me that a realserver in a LVS-NAT LVS
is listening on the RIP. The client is sending to the VIP.
In an HTTP 1.1 or name based httpd, doesn't the server
get a request with the URL (which will have the VIP)
in the payload of the packet (where an L4 switch doesn't see it)?
Won't the server be unhappy about this? This has come up
before with name based service like
<link linkend="https">https</link> and for
<link linkend="indexing">indexing of webpages</link>.
Does anyone know how to force an HTTP 1.1 connection
(or to check whether the connection was HTTP 1.0 or 1.1)
so we can check this?
			</para><para>
<blockquote><para>
Paul Baker <emphasis>pbaker (at) where2getit (dot) com</emphasis> 10 May 2001
			</para><para>
The HTTP 1.1 request (and also 1.0 requests from any modern browser)
contain a Host: header which specifies the hostname of the server. As
long as the webservers on the realservers are aware that they are
serving this hostname. There should be no issue with 1.1 vs 1.0 http
requests.
</para></blockquote>
			</para><para>
so both virtualHost and servername should be the reverse dns of the VIP?
<blockquote><para>
Yes. Your Servername should be the reverse dns of the VIP and you need
to have a Virtualhost entry for it as well. In the event that you are
serving more than one domain on that VIP, then you need to have a
VirtualHost entry for each domain as well.
</para></blockquote>
			</para><para>
what if instead of the name of the VIP, I surf to the actual IP?
There is no device with the VIP on the LVS-NAT realserver. Does
there need to be one? Will an entry in /etc/hosts that maps the VIP
to the public name do?
			</para><para>
<blockquote><para>
Ilker Gokhan <emphasis>IlkerG (at) sumerbank (dot) com (dot) tr</emphasis>
			</para><para>
If you write URL with IP address such as http://123.123.123.123/,
the Host: header is filled with this IP address, not hostname.
You can see it using any network monitor program (tcpdump).
</para></blockquote>
			</para><para>
	</para></section>
	<section id="http_stateless">
	<title>httpd is stateless and normally closes connections</title>
	<para>
http is stateless, in that the httpd has no memory of your previous
connections.
Unlike other stateless protocols (NFS, ntp) a connection is made
(it is tcp rather than udp based).
However httpd will usually attempt to disconnect as soon as possible,
in which case you will not see any entries in the
of <xref linkend="ActiveConn"/> column of the <command>ipvsadm</command> output.
For HTTP/1.1, the browser/server can negotiate a
<link linkend="persistent_http">persistent httpd connection</link>.
	</para>
	<para>
If you look with <command>ipvsadm</command> to see the activity on an LVS serving
httpd, you won't see much.
A non-persistent httpd on the realserver closes the connection
after sending the packets.
Here's the output from ipvsadm, immediately after retrieving
a gif filled webpage from a 2 realserver LVS.
	</para>
<programlisting><![CDATA[
director:# ipvsadm
IP Virtual Server version 0.2.5 (size=4096)
Prot LocalAddress:Port Scheduler Flags
  -> RemoteAddress:Port          Forward Weight ActiveConn InActConn
TCP  lvs2.mack.net:www rr
  -> RS2.mack.net:www            Masq    1      2          12
  -> RS1.mack.net:www            Masq    1      1          11
]]></programlisting>
	<para>
The InActConn are showing the connections that transferred
hits that have been closed and are in the FIN state waiting to timeout.
You may see &quot;0&quot; in the InActConn column, leading
you to think that you are not getting the packets via the LVS.
	</para>
	<para>
Roberto Nibali <emphasis>ratz@drugphish.ch</emphasis> 22 Dec 2003
	</para>
	<para>
If you want to see connections before they are closed,
you should invoke <command>ipvsadm</command> with <command>watch</command>,
	</para>
<programlisting><![CDATA[
watch -n 1 'ipvsadm -Ln'
]]></programlisting>
	<para>
or if you want it realtime (warning, eats a lot of CPU time):
	</para>
<programlisting><![CDATA[
watch -n -1 'ipvsadm -Ln'
]]></programlisting>
	<para>
When a client connects, you'll see a positive integer in the ActiveConn column.
	</para>
	</section>
	<section id="persistent_http" xreflabel="persistent_http">
	<title>netscape/database/tcpip persistence (keepalives)</title>
	<para>
With the first version of the http protocol, HTTP/1.0,
a client would request a hit/page from the httpd.
After the transfer, the connection was dropped.
It is expensive to setup a tcp connection just to transfer
a small number of packets, when it is likely that the
client will be making several more requests immediately afterwards 
(<emphasis>e.g.</emphasis> if the client downloads an html page which contains gifs, 
then after parsing the html page, the client will request the gifs).
With HTTP/1.1 application level persistent connection was possible.
The client/server pair negotiate to see
if persistent connection is possible.
The server uses an algorithm to determine when to drop the connection 
(KeepAliveTimeout, 15sec usually or needs to recover file handles...).
The client can drop the connection at anytime without consulting the server
(<emphasis>e.g.</emphasis> when it has got all the hits on a page).
Persistence is only allowed when the file transfer size is known
ahead of time (<emphasis>e.g.</emphasis> an html page or a gif).
The output from a cgi script is of unknown size and it will
be transferred by a regular (non-persistent) connection.
Persistent connection requires more resources from the server, 
as file handles can be open for much longer than the time needed for a tcpip transfer.
The number of keepalive connections/client and the timeout
are set in <filename>httpd.conf</filename>. 
Persistent connection with apache is called 
<ulink url="http://www.auburn.edu/docs/apache/keepalive.html">
keepalive</ulink>
(http://www.auburn.edu/docs/apache/keepalive.html)
and is described in
<ulink url="http://www.research.compaq.com/wrl/techreports/abstracts/95.4.html">
http persistent connection</ulink>.
	</para>
	<para>
With the introduction of <filename>lingering_close()</filename>
to apache_v1.2, a bug in some browsers 
would hold open the connection forever
<ulink url="http://www.auburn.edu/docs/apache/misc/fin_wait_2.html">
Connections in FIN_WAIT_2 and Apache</ulink>
(http://www.auburn.edu/docs/apache/misc/fin_wait_2.html),
leaving the output of <command>netstat</command> on the server
filled with connections in FIN_WAIT_2 state.
This required the addition of an RFC violating timeout
for the FIN_WAIT_2 state to the server's tcpip stack.
	</para>
	<para>
Kees Hoekzema <emphasis>kees (at) tweakers (dot) net</emphasis> 17 Feb 2005 
	</para>
	<para>
When using keepalive a client opens a connection to the cluster and that 
connection stays open (for as long as the clients wants, or a timeout 
occurs serverside). So the loadbalancer can not (at normal LVS level) see 
whether it is a normal connection with just one large request from the 
server or that it is a keepalived connection with lots of requests.
As far as I know persistence has no influence on keepalive.
	</para>
	<para>
Jacob Coby
	</para>
	<blockquote>
The Apache 
<ulink url="http://httpd.apache.org/docs/mod/core.html#keepalive">KeepAlive option</ulink>
is one of the first things to turn off when you start getting a lot of traffic.
	</blockquote>
	<para>
Francois JEANMOUGIN <emphasis>Francois (dot) JEANMOUGIN (at) 123multimedia (dot) com</emphasis> 2005/02/18
	</para>	
	<para>
This is a dangerous shortcut. 
Sometimes, opening/closing connections
a hundred times a second could put down your server. 
Turning off HTTP keepalive implies a good choice between the 3 available apache mpms.
In my case, I turn it off for the banner server, 
but keep it on (only a short time) on our products sites 
(which have lots of little images).
Having keepalive on or off will not affect your LVS 
performances; LVS persistence (aka affinity) will.
	</para>
	<para>
Alois Treindl <emphasis>alois (at) astro (dot) ch</emphasis> 30 Apr 2001
	</para>
	<blockquote>
when I reload a page on the client, the browser makes several http
hits on the server for the graphics in the page.
These hits are load balanced between the realservers.
I presume this is normal for HTTP/1.0 protocol, though I would
have expected Netscape 4.77 to use HTTP/1.1 with one connection for
all parts of a page.
	</blockquote>
	<para>
Joe
	</para>
	<para>
Here's the output of <command>ipvsadm</command> after downloading a test page consisting
of 80 different gifs (the html file has 80 lines of &lt;img src="foo.gif"&gt;).
	</para>
<programlisting><![CDATA[
director:/etc/lvs# ipvsadm
IP Virtual Server version 1.0.7 (size=4096)
Prot LocalAddress:Port Scheduler Flags
  -> RemoteAddress:Port             Forward Weight ActiveConn InActConn
TCP  lvs.mack.net:http rr
  -> RS2.mack.net:http              Route   1      2          0
  -> RS1.mack.net:http              Route   1      2          0
]]></programlisting>
	<para>
It would appear that the browser has made 4 connections which are left open.
The client shows (netstat -an) 4 connections which are ESTABLISHED, while the realservers
show 2 connections each in FIN_WAIT2. Presumably each connection was used to transfer
an average of 20 requests.
	</para>
	<para>
If the client-server pair were using persistent connection, I would expect
only one connection to have been used.
	</para>
	<para>
Andreas J. Koenig <emphasis>andreas (dot) koenig (at) anima (dot) de</emphasis> 02 May 2001
	</para>
	<blockquote>
	<para>
Netscape just doesn't use a single connection, and not only Netscape.
All major browsers fire mercilessly a whole lot of connections at the
server. They just don't form a single line, they try to queue up on
several ports simultaneously...
	</para>
	<para>
...and that is why you should never set KeepAliveTimeout to 15 unless
you want to burn your money. You keep several gates open for a single
user who doesn't use them most of the time while you lock others out.
	</para>
	</blockquote>
	<para>
Julian
	</para>
	<para>
	Hm, I think the browsers fetch the objects by creating 3-4
connections (not sure how many exactly). If there is a KeepAlive option
in the httpd.conf you can expect small number of inactive connections
after the page download is completed. Without this option the client is
forced to create new connections after each object is downloaded and
the HTTP connections are not reused.
	</para>
	<para>
	The browsers reuse the connection but there are more than one
connections.
	</para>
	<para>
	KeepAlive Off can be useful for banner serving but a short
KeepAlive period has its advantages in some cases with long rtt where
the connection setups costs time and because the modern browsers are
limited to the number of connections they open.
Of course, the default
period can be reduced but its value depends on the served content,
whether the client is expected to open many connections for short
period or just one.
	</para>
	<para>
Peter Mueller <emphasis>pmueller (at) sidestep (dot) com</emphasis> 01 May 2001
	</para>
	<blockquote>
	<para>
I was searching around on the web and found the following relevant links..
	</para>
<programlisting><![CDATA[
http://thingy.kcilink.com/modperlguide/performance/KeepAlive.html
http://httpd.apache.org/docs/keepalive.html -- not that useful
http://www.apache.gamma.ru/docs/misc/fin_wait_2.html -- old but interesting
]]></programlisting>
	</blockquote>
	<para>
Andreas J. Koenig <emphasis>andreas (dot) koenig (at) anima (dot) de</emphasis> 02 May 2001
	</para>
	<blockquote>
	<para>
If you have 5 servers with 15 secs KeepAliveTimeout, then
you can serve
	</para>
	<para>
    60*60*24*5/15 = 28800 requests per day
	</para>
	</blockquote>
	<para>
Joe
	</para>
	<para>
  don't you actually have MaxClients=150 servers available and this
  can be increased to several thousand presumably?
	</para>
	<para>
Peter Mueller
	</para>
	<para>
I think a factor of 64000 is forgotten here (number of possible reply
ports), plus the fact that most http connections do seem to terminate
immediately, despite the KeepAlive.
	</para>
	<para>
Andreas (?)
	</para>
	<blockquote>
	<para>
Sure, and people do this and buy lots of RAM for them. But many of
them servers are just in 'K' state, waiting for more data on these
KeepAlive connections. Moreover, they do not compile the status module
into their servers and never notice.
	</para>
	<para>
Let's rewrite the above formula:
	</para>
	<para>
    MaxClients / KeepAliveTimeout
	</para>
	<para>
denotes the number of requests that can be satisfied if all clients
*send* a keepalive header (I think that's "Connection: keepalive") but
*do not actually use* the kept-alive line. If they actually use the
kept-alive line, you can serve more, of course.
	</para>
	<para>
Try this: start apache with the -X
flag, so it will not fork children and set the keepalivetimeout to 60.
Then load a page from it with Netscape that contains many images. You
will notice that many pictures arive quickly and a few pictures arive
after a long, long, long, looooong time.
	</para>
	<para>
When the browser parses the incoming HTML stream and sees the first
IMG tag it will fire off the first IMG request. It will do likewise
for the next IMG tag. At some point it will reach an IMG tag and be
able to re-use an open keepalive connection. This is good and does
save time. But if a whole second has passed after a keepalive request
it becomes very unlikely that this connection will be re-used ever, so
15 seconds is braindead. One or two seconds is OK.
	</para>
	<para>
In the above experiment my Netscape loaded 14 images immediately after
the HTML page was loaded, but it took about a minute for each of the
remaining 4 images which happened to be the first in the HTML stream.
	</para>
	</blockquote>
	<para>
Joe
	</para>
	<para>
Here's the output of <command>ipvsadm</command> after downloading the same 80 gif page
with the -X option on apache (only one httpd is seen with ps, rather
than the 5 I usually have).
	</para>
<programlisting><![CDATA[
director:/etc/lvs# ipvsadm
IP Virtual Server version 0.2.11 (size=16384)
Prot LocalAddress:Port Scheduler Flags
  -> RemoteAddress:Port             Forward Weight ActiveConn InActConn
TCP  lvs.mack.net:http rr
  -> RS2.mack.net:http              Route   1      1          1
  -> RS1.mack.net:http              Route   1      0          2
]]></programlisting>
	<para>
The page shows a lot of loading at the status line,
then stops, showing 100&percnt; of 30k.
However the downloaded page is blank. A few seconds later the gifs are displayed.
The client shows 4 connections in CLOSE_WAIT and the realservers
each show 2 connections in FIN_WAIT2.
	</para>
	<para>
Paul J. Baker <emphasis>pbaker (at) where2getit (dot) com</emphasis> 02 May 2001
	</para>
	<blockquote>
	<para>
The KeepAliveTimeout value is NOT the connection time out.
It says how long Apache will keep an active connection open waiting for a
new request to come on the SAME connection after it has fulfilled a
request. Setting this to 15 seconds does not mean apache cuts all
connections after 15 seconds.
	</para><para>
I write server load-testing software so I have do quiet a bit of
research in the behaviour of each browser. If Netscape hits a page with
a lot of images on it, it will usually open about 8 connections. It will
use these 8 connections to download things as quickly as it can. If the
server cuts each connection after 1 request is fullfilled, then Netscape
browser has to keep reconnecting. This costs a lot of time. KeepAlive is
a GOOD THING. Netscape does close the connections when it is done with
them which will be well before the 15 seconds since the last request expire.
	</para><para>
Think of KeepAliveTimeout as being like an Idle Timeout in FTP. Imagine
it being set to 15 seconds.
	</para>
	</blockquote>
	<para>
Ivan Pulleyn <emphasis>ivan (at) sixfold (dot) com</emphasis> 23 Jan 2003
	</para>
	<blockquote>
To totally fragment the request, if using apache, 'KeepAlive off'
option will disable HTTP keep-alive sessions. So a single browser load
will have to connect() many times; once for the document, then again
for each image on the page, style sheet, etc. Also, sending a pragma
no-cache in the HTTP header would be a good idea to ensure the client
actually reloads.
	</blockquote>
		<section id="sudden_changes_in_inactconn">
		<title>Sudden Changes in InActConn</title>
		<para>
<emphasis>nigel (at) turbo10 (dot) com</emphasis>
		</para>
		<blockquote>
This weekend the web service we run came under increased load --- 
about an extra 10,000,000 queries per day ---- 
when InActConn went from 200-300 to 2000+ in about 60 seconds and the LVS locks up.
		</blockquote>
		<para>
Rob <emphasis>ipvsuser (at) itsbeen (dot) sent (dot) com</emphasis> 2005/03/13
		</para>
		<para>
I had a high number of inactive connections with apache set up to not 
use keepalive at all. After activating keep alive in apache (LVS was 
already persistant) the number of inactive connections went way down.
		</para>
		<para>
So in my case at least, connections were setup, used for a 
single GET for a gif, button, jpeg, js script, or other page component 
then the server closed the connection, only to open another for the next 
gif, etc.
		</para>
		<para>
You might be able to use something like multilog to watch a bunch of the 
logs at the same time to get an idea if the traffic looks like real 
people (get page 1, get page 1 images, get page 2, get page 2 images) or 
if it is random hammering from a dos attack.
		</para>
		<para>
I wrote a small shell script that pulled the recent log entries, counted 
the hits per IP address for certain requests and then created a iptables 
rule on the director (or some machine in front of the director) to 
tarpit requests from that IP. This worked in my situation because we 
knew that certain URLs were only hit a small number of times during a 
legit use session (like a login page shouldn't be hit 957 times in an 
hour by the same external IP) This could help reduce the tide of 
requests if you are actually encountering a (d)dos. I ran it every 12 
minutes or so. If you are getting ddos'd the tarpit function of iptables 
http://www.securityfocus.com/infocus/1723 or the tarpit standalone can 
be a great help. Also, Felix and his company seem to have helped some 
large companies deal with high traffic ddos attacks - http://www.fefe.de/
		</para>
		<para>
BTW, You might be interested in http://www.backhand.org/mod_log_spread/ 
for centralized and redundant logging. That way you can run different 
kinds of real time analysis with no extra load on the webservers or the 
normal logging hosts by just having an additional machine join/subscribe 
to the multicast spread group with the log data.
		</para>
		<para>
OK I can't find my script, but this was the start of it, it is hardly a 
shell script (but someone may find it useful):
Add a "grep blah" command just before the awk '{print $2}' if you want 
just certain requests or other filtering.
		</para>
<programlisting><![CDATA[
multidaychk.sh
#!/bin/sh
# look for mutliday patterns
# $1 is how many days back to search
# $2 is how many high usage IPs to list
ls -1tr /usr/local/apache2/logs/access_log.200*0 | tail -${1} | xargs -n 
1 cat | awk '{print $2}' | sort | uniq -c | sort -nr | head -${2}

byhrchk.sh
#!/bin/sh
# looks for IPs hitting during a certain hr of the day
# $1 is how many days back to search
# $2 is how many high usage IPs to list
# $3 is which hour of the day
ls -1tr /usr/local/apache2/logs/access_log.200*0 | tail -${1} | xargs -n 
1 cat | fgrep "2005:${3}" | awk '{print $2}' | sort | uniq -c | sort -nr 
| head -${2}

recentchk.sh
#!/bin/sh
# This just checks the latest X lines from the newest log file
# $1 is how many lines from the file
# $2 is how many high usage IPs to list
ls -1tr /usr/local/apache2/logs/access_log.200*0 | tail -1 | xargs -n 1 
tail -${1} | awk '{print $2}' | sort | uniq -c | sort -nr | head -${2}
]]></programlisting>
		</section>
	</section>
	<section id="dynamic_images">
	<title>dynamically generated images on web pages</title>
	<para>
On static webpages, all realservers serve identical content.
A dynamically generated image is only present on the webserver
that gets the request (and which generates the image).
However the director will send the client's request
for that image to any of the realservers and not neccessarily
to the realserver that generated the image.
	</para>
	<para>
Solutions are
	</para>
	<itemizedlist>
		<listitem>
generate the images in a shared directory/filesystem
		</listitem>
		<listitem>
	use fwmark to setup the LVS.
		</listitem>
	</itemizedlist>
	<para>
Both methods are described in the section using fwmark for
<link linkend="dynamic">dynamically generated images</link>.
	</para>
	</section>
	<section id="http_checks">
	<title>http: sanity checks, shutting down, indexing programs, htpasswd, apache proxy and reverse proxy to look at URL, mod_backhand, logging</title>
	<para>
people running webservers are interesting in optimising throughput 
and often want to look at the content of packets. 
You can't do this with LVS, since LVS works at layer 4.
However there are many ways of looking at the content of
packets that are passed through an LVS to backend webservers.
Material on reverse proxies is all through this HOWTO.
I haven't worked out whether to pull it all together or
leave it in the context it came up. As a start...
	</para>
	<para>
<emphasis role="bold">defn:</emphasis> forward and reverse proxy:
adapted from 
<ulink url="http://www.tldp.org/HOWTO/Apache-Overview-HOWTO-2.html">Apache Overview HOWTO</ulink>
(http://www.tldp.org/HOWTO/Apache-Overview-HOWTO-2.html) 
and 
<ulink url="http://www.apacheweek.com/features/reverseproxies">Running a Reverse Proxy with Apache</ulink>
(http://www.apacheweek.com/features/reverseproxies).
See also 
<ulink url="http://en.wikipedia.org/wiki/Proxy_server">http://en.wikipedia.org/wiki/Proxy_server</ulink>
and <ulink url="http://en.wikipedia.org/wiki/Reverse_proxy">http://en.wikipedia.org/wiki/Reverse_proxy</ulink>
	</para>
	<blockquote>
		<para>
A proxy is a program that performs requests on behalf of another program.
The source and destination IPs on the packets do not change.
		</para>
		<para>
<emphasis role="bold">forward proxy:</emphasis> 
(the traditional http proxy), accepts requests from clients,
contacts the remote http server and returns the response. 
An example is "squid". 
The main advantage of a squid is that it caches responses (it's a proxy cache).
Thus a repeat request for a webpage will be returned more quickly,
since the proxy cache will (usually) be closer to the client on the internet.
Forward proxies are of interest because of their caching. 
That they cache by doing a proxy request is not of much interest to users.
		</para>
		<para>
<emphasis role="bold">reverse proxy:</emphasis> 
a webserver placed in front of other servers, providing a
unified front end to the client, but offloading certain tasks, 
<emphasis>e.g.</emphasis> SSL processing, FTP from the backend webservers
to other machines. 
The most common reason to run a reverse proxy to enable controlled access
from the internet to servers behind a firewall.
Squid can also reverse proxy.
		</para>
		<note>
Quite what is "reverse" about this sort of proxy, I don't know - 
perhaps they needed a name to differentiate it from "forward".
"reverse" is not a helpful name here.
Both forward and reverse proxies have the same functionality: 
the forward proxy is at the client end, 
while the reverse proxy is at the server end.)
		</note> 
		<para>
In some sense, the LVS director functions as a reverse proxy for the realservers.
		</para>
	</blockquote>
		<section id="http_sanity">
		<title>sanity checks</title>
		<para>
When first setting up, to check that your LVS is working...
		</para>
		<orderedlist>
			<listitem>
put something different on each realserver's web page
(<emphasis>e.g.</emphasis> the string "realserver_1" at the top of the homepage).
			</listitem>
			<listitem>
use rr for your scheduler
			</listitem>
			<listitem>
make sure you're rotating through the different web pages
(each one is different) and look at the output of ipvsadm
to seen a new connection (probably InActConn)
			</listitem>
			<listitem>
ping the VIP from a machine directly connected to the
outside of the director. Then check the MAC address for the
VIP with arp -a
			</listitem>
		</orderedlist>
		</section>
		<section id="check_configs">
		<title>replies coming from wrong VIP (check configs)</title>
		<para>
Nicklas Bondesson <emphasis>nicklas (dot) bondesson (at) mindping (dot) com</emphasis> 24 Feb 2007
(with help from Graeme Fowler)
		</para>
		<para>
I have several VIPs. 
Regardless of the VIP the client connects to, 
they get a response from a different IP which never varies.
I found out that everything was working the way it should
with https, which further led me into debugging our apache setup rather than LVS. 
Apache didn't have the appropiate virtual hosts configured for all the vip's. 
This is why I always saw the same ip address as source - 
the ip of the _default_ (first configured) apache virtual host.
		</para>
		</section>
		<section id="http_shutting_down">
		<title>Shutting down http</title>
		<para>
You need to shut down httpd gracefully, by bringing the weight
to 0 and letting connections drop, or you will not be able to
bind to port 80 when you restart httpd.
If you want to do on the fly modifications to your httpd, 
and keep all realservers in the same state, you may have problems.
		</para>
		<para>
Thornton Prime <emphasis>thornton (at) jalan (dot) com</emphasis> 05 Jan 2001
		</para>
		<blockquote>
		<para>
I have been having some problems restarting apache on servers that are
using LVS-NAT and was hoping someone had some insight or a workaround.
		</para><para>
 Basically, when I make a configuration change to my webservers and I try
 to restart them (either with a complete shutdown or even just a graceful
 restart), Apache tries to close all the current connections and re-bind
 to the port. The problem is that invariably it takes several minutes for
 all the current connections to clear even if I kill apache, and the
 server won't start as long as any socket is open on port 80, even if it
 is in a 'CLOSING' state.
		</para>
		</blockquote>
		<para>
Michael E Brown wrote:
		</para><para>
Catch-22. I think the proper way to do something like this is to take the
affected server out of the LVS table _before_ making any configuration
changes to the machine. Wait until all connections are closed, then make
your change and restart apache. You should run into less problems this
 way. After the server has restarted, then add it back into the pool.
		</para>
		<blockquote>
 I thought of that, but unfortunately I need to make sure that the
 servers in the cluster remain in a near identical state, so the
 reconfiguration time should be minimal.
		</blockquote>
		<para>
Julian wrote
		</para><para>
        Hm, I don't have such problems with Apache. I use the default
configuration-time settings, may be with higher process limit only.
Are you sure you use the latest 2.2 kernels in the realservers?
		</para>
		<blockquote>
		<para>
 I'm guessing that my problem is that I am using LVS persistent
 connections, and combined with apache's lingering close this makes it
 difficult for apache to know the difference between a slow connection
 and a dead connection when it tries to close down, so the time it takes
 to clear some of the sockets approaches my LVS persistence time.
		</para><para>
 I haven't tried turning off persistence, and I haven't tried
 re-compiling apache without lingering-close. This is a production
 cluster with rather heavy traffic and I don't have a test cluster to
 play with. In the end rebooting the machine has been faster than waiting
 for the ports to clear so I can restart apache, but this seems really
 dumb, and doesn't work well because then my cluster machines have
 different configuration states.
		</para>
		</blockquote>
		<para>
        One reason for your servers to block is a very low value for
the client number. You can build apache in this way:
		</para>
<programlisting><![CDATA[
CFLAGS=-DHARD_SERVER_LIMIT=2048 ./configure ...
]]></programlisting>
		<para>
and then to increase MaxClients (up to the above limit). Try with
different values. And don't play too much with the MinSpareServers and
MaxSpareServers. Values near the default are preferred. Is your kernel
compiled with higher value for the number of processes:
		</para>
<programlisting><![CDATA[
/usr/src/linux/include/linux/tasks.h
]]></programlisting>
		<blockquote>
		<para>
 Is there any way anyone knows of to kill the sockets on the webserver
 other than simply wait for them to clear out or rebooting the machine?
 (I tried also taking the interface down and bringing it up again ...
 that didn't work either.)
		</para><para>
 Is there any way to 'reset' the MASQ table on the LVS machine to force a
 reset?
		</para>
		</blockquote>
		<para>
        No way! The masq follows the TCP protocol and it is transparent
to the both ends. The expiration timeouts in the LVS/MASQ box are high
enough to allow the connection termination to complete. Do you remove
the realservers from the LVS configuration before stopping the apaches?
This can block the traffic and can delay the shutdown. It seems the
fastest way to restart the apache is apachectl graceful, of course,
if you don't change anything in apachectl (in the httpd args).
		</para>
		</section>
		<section id="indexing" xreflabel="indexing">
		<title>Running indexing programs (<emphasis>e.g.</emphasis> htdig) on the LVS</title>
		<para>
(From Ted I think)
		</para>
		<para>
Setup -
		</para>
		<para>
realservers are node1.foobar.com, node2.foobar.com...
nodeN.foobar.com, director has VIP=lvs.foobar.com (all
realservers appear as lvs.foobar.com to users).
		</para>
		<para>
Problem -
		</para>
		<para>
if you run the indexing program on one of the (identical)
realservers, the urls of the indexed files will be
		</para>
<programlisting><![CDATA[
http://nodeX.foobar.com/filename
]]></programlisting>
		<para>
These urls will be unuseable by clients out in internetland since
the realservers are not individually accessable by clients.
		</para>
		<para>
If instead you run the indexing program from outside the LVS (as
a user), you will get the correct urls for the files, but you
will have to move/copy your index back to the realservers.
		</para>
		<para>
Solution (from Ted Pavlic, edited by Joe).
		</para>
		<para>
On the indexing node, if you are using LVS-NAT add a non-arping
device (eg lo:0, tunl0, ppp0, slip0 or dummy) with IP=VIP as if
you were setting up LVS-DR (or LVS-Tun). With LVS-DR/VS-Tun this
device with the VIP is already setup. The VIP is associated in
dns with the name lvs.foobar.com. To index, on the indexing node,
start indexing from http://lvs.foobar.com and the realserver will
index itself giving the URLs appropriate for the user in the
index.
		</para>
		<para>
Alternately (for LVS-NAT), on the indexing node, add the
following line to <filename>/etc/hosts</filename>.
		</para>
<programlisting><![CDATA[
127.0.0.1       localhost lvs.foobar.com
]]></programlisting>
		<para>
make sure your resolver looks to /etc/hosts before it looks to
dns and then run your indexing program. This is a less general
solution, since if the name of lvs.foobar.com was changed to
lvs.bazbar.com, or if lvs.foobar.com is changed to be a CNAME,
then you would have to edit all your hosts files. The solution
with the VIP on every machine would be handled by dns.
		</para>
		<para>
There is no need to fool with anything unless you are running
LVS-NAT.
		</para>
		</section>
		<section id="http_htpasswd">
		<title>htpasswd with http</title>
		<para>
Noah Roberts wrote:
		</para><para>
If anyone has had success
with htpasswords in an LVS cluster please tell me how you did it.
		</para>
		<para>
Thornton Prime <emphasis>thornton (at) jalan (dot) com</emphasis>
Fri, 06 Jul 2001
		</para>
		<blockquote>
We have HTTP authentication working on dozens of sites through LVS with
all sorts of different password storage from old fashioned htpasswd files
to LDAP.
LVS when working properly is pretty transparent to HTTP between the client
and server.
		</blockquote>
		</section>
		<section id="apache_proxy">
		<title>apache proxy (reverse proxy) rather than LVS</title>
		<para>
Tony Requist
		</para>
		<blockquote>
			<para>
We currently have a LVS configuration with 2 directors and a set of web
servers using LVS-DR and keepalived between the directors 
(and a set of MySql servers also).  
This is all working well using the standard RR scheduling without persistence.
We will be adding functionality that will be storing data on some but not
all web servers.  
For this, we need to be able to route requests to specific
web servers according to the URL.
Ideally I would generate URLs like:
			</para>

<programlisting><![CDATA[
stuff.domain.com://KEY
]]></programlisting>
			<para>
and I could have a little code in LVS (or called from LVS) where I could
decode KEY to find that the data is on server A, B and C -- then have LVS
route to one of these three servers.
I've looked through the HOWTO and searched around but I have not been able
to find anything.
			</para>
		</blockquote>
		<para>
Scott J. Henson <emphasis>scotth (at) csee (dot) wvu (dot) edu</emphasis>
20 Jul 2005
		</para>
		<para>
I would personally use apache proxy statements on the servers that don't 
have the information.  This will increase load slightly, but is probably 
the easiest. 
		</para>
		<para>
If you really want to go the LVS route, there are some issues, I believe.  
If my memory serves, the current version of LVS is a level 4 
router and to do what you want, you would need a level 7 router.  
I have heard of some patches floating around to turn ip_vs into a level 7 
router, but Ive not seen them personally, nor tried them.
		</para>
		<note>
			<para>
L7 <xref linkend="LVS-HOWTO.L7_switch"/>
requires much more computation than L4.
You don't want to do anything at L7 that you can handle
any way at all at L4.
			</para>
		</note>
		<para>
Todd Lyons <emphasis>tlyons (at) ivenue (dot) com</emphasis> 20 Jul 2005
		</para>
		<para>
This is application level, not network level. The better solution
(IMHO) is to put two machines doing reverse proxy with the rules to send
the requests to the correct server.  Then have your load balancers
balance among the two rproxies.
		</para>
		<para>
A poor man's solution would be to put the reverse proxying on the
webservers themselves.
		</para>
		<para>
This is not really good for HA though since you don't have redundancy if
there is only one webserver serving a particular resource.
		</para>
		<para>
If the reverse proxies have a different IP than the public IP of the
webservers, then you have more options.
		</para>

		<para>
Andres Canada
		</para>
		<blockquote>
When the cluster node gets the request it looks to apache configuration and 
whatever to serve this request.
When a Director node receives a request for a special web application that 
is only in one cluster node (for example node35) there should be something 
inside it that send that request to a "special node" (not the next one if 
it's using round robin, but the node35).
		</blockquote>
		<para>
Todd Lyons <emphasis>tlyons (at) ivenue (dot) com</emphasis> Dec 14 2005
		</para>
		<para>
You should consider setting up a reverse proxy.  This is a machine that
sits in front of your apache boxen that examines urls and sends them to
various private apache servers, and sends the reply back.  The outside
world doesn't talk directly to the private apache servers.
		</para>
		<para>
In our case, we have several different machines that handle different
types of requests.  We have 3 rp's sitting in front of them getting load
balanced by two LVS boxen.  The load balanced rp's receive the GET or
POST from the outside world, examine it, and send the request to the
appropriate private machine, waits for the reply, and sends that to the
requesting client.
		</para>
		</section>
		<section id="mod_backhand" xreflabel="mod_backhand">
		<title>mod_backhand</title>
		<para>
From Lars <emphasis>lmb (at) suse (dot) de</emphasis>
<ulink url="http://www.backhand.org/">mod_backhand</ulink>,
a method of balancing apache httpd servers that looks like ICP for web caches.
		</para>
		<para>
Jessica Yang, 8 Oct 2004
		</para>
		<blockquote>
Our application require L7 load balancing because we use URL rewriting to
keep the session info in the requested URLs, like this:
http://ip/servlet/servletname;jsessionid =*****. Basically, we want the load
balancer will deliver the requests who have the same jsessionid to the same
realserver. Looking through the LVS document, KTCPVS seems to be able to
provide L7 load balancing, but I couldn't find any documentation about
compiling, configuring, features and commands of KTCPVS. Does KTCPVS have
the feature to distinguish the jsessionid in the requested URL and/or in the
Cookie header? Does KTCPVS have to be bundled together with IPVS? And what
is the process to make it work? 
		</blockquote> 
		<para>
Wensong 09 Oct 2004
		</para>
		<para>
KTCPVS has a cookie-injection load balancing feature just as you described.
You can use something like the following
		</para>
<programlisting><![CDATA[
insmod ktcpvs.o
insmod ktcpvs_chttp.o
tcpvsadm -A -i http -s chttp
tcpvsadm -a -i http -r realserver1:80
tcpvsadm -a -i http -r realserver2:80
tcpvsadm -a -i http -r realserver3:80
]]></programlisting>
		<para>
Jacob Coby <emphasis>jcoby (at) listingbook (dot) com</emphasis> 08 Oct 2004
		</para>
		<para>
It almost sounds like you need to use a proxy instead of LVS to do the 
load balancing.  If something in your jsessionid is unique to a server, 
it would be very simple to make a rewrite rule accomplish what you want.
		</para>
		<para>
Clint Byrum <emphasis>cbyrum (at) spamaps (dot) org</emphasis> 08 Oct 2004 
		</para>
		<para>
<ulink url="http://www.backhand.org/mod_backhand/">mod_backhand</ulink>
(http://www.backhand.org/mod_backhand/).
		</para>
		<para>
VERY nice load balancing proxy module for apache. It does require that 
your content be served from Apache 1.3 (Windows or Unix) though.
		</para>
		<para>
cheaney Chen 
		</para>
		<blockquote>
There are a lot of different kinds of SLB techniques, ex. DNS-based,
Dispatcher-based(like LVS), and server-based , etc.
And my question is, for a commercial web site (like yahoo or ...)
how to do SLB.
What methods are used to handle huge numbers of client's requests?
Combination of SLB techniques above , or ... ?!
		</blockquote>
		<para>
Clint Byrum <emphasis>cbyrum (at) spamaps (dot) org</emphasis> 06 Jan 2005 
		</para>
		<para>
I've used LVS for frontend balancing, and 
<ulink url="http://www.backhand.org/">backhand</ulink>
(www.backhand.org) for backend.
		</para>
		<para>
In short, mod_backhand takes specific resource-intensive requests and
proxies them to whichever servers are least busy. It works *VERY* well.
We have a farm of cheap boxes serving lots of CPU intensive requests and
every box has the same exact load average within 2-3%. It even allows
persistence. Only downside is it requires Apache 1.3, but so far that
hasn't been a problem for us. :)
		</para>
		</section>
		<section id="apache_logging">
		<title>Apache logging</title>
		<para>
<emphasis>isplist (at) logicore (dot) net</emphasis> 2007-07-25 
		</para>
		<blockquote>
How can I exclude the logging from the LVS servers on apache? The constant 
checking for the host is creating VERY large log files.
		</blockquote>
		<para>
Graeme Fowler <emphasis>graeme (at) graemef (dot) net</emphasis> 25 Jul 2007 
		</para>
		<para>
This is really a question you should be asking on an Apache mailing
list, but anyway...
The easiest thing to do is to create a separate &lt;VirtualHost blah&gt;
definition that simply logs to /dev/null:
		</para>
<programlisting><![CDATA[
<VirtualHost 1.2.3.4:80>
  ServerName blah.test.domain
  CustomLog /dev/null combined
  ...other directives...
</VirtualHost>
]]></programlisting>
		<para>
then configure whatever healthcheck/monitor app you're using to query
the virtual host blah.test.domain by hostname - that differs so much
between mon, keepalived and ldirectord that I'll leave that as an
exercise for you.
However, I have to say that even with a check interval of 1 second that
would only give you 86400 lines per day - if you're using LB of any form
I'd expect you to be generating that number of entries per hour, if not
more.
		</para>
		</section>
	</section>
	<section id="http_1.0_1.1">
	<title>HTTP 1.0 and 1.1 requests</title>
	<para>
Joe: Does anyone know how to force an HTTP 1.1 connection?
	</para>
	<para>
Patrick O'Rourke <emphasis>orourke (at) missioncriticallinux (dot) com</emphasis>:
	</para>
	<blockquote>
<ulink url="ftp://ftp.hpl.hp.com/pub/httperf">httperf</ulink>
has an 'http-version' flag which will cause it to generate
1.0 or 1.1 requests.
	</blockquote>
	</section>
	<section id="large_http_post" xreflabel="Large HTTP /POST">
	<title>Large HTTP /POST with LVS-Tun</title>
	<para>
If a client does a large (packet&gt;MTU) POST through a tunnel device 
(<emphasis>i.e.</emphasis> LVS-Tun) the MTU will be exceeded. 
This is normally handled by the icmp layer, 
but linux kernels, at least upto 2.4.23, 
do not handle this properly for paths involving tunnel devices.
see <xref linkend="PMTUD"/>.
	</para>
	</section>
	<section id="http_keepalive">
	<title>http keepalive - effect on InActConn</title>
	<para>
Randy Paries <emphasis>rtparies (at) gmail (dot) com</emphasis> 
07 Feb 2006 
	</para>
	<blockquote>
		<para>
I just added a new realserver (local.lovejoy).
It has many more InActConn than the other servers. 
It's newer hardware. Any ideas?
		</para>
<programlisting><![CDATA[
ipvsadm
IP Virtual Server version 1.0.10 (size=65536)
Prot LocalAddress:Port Scheduler Flags
 -> RemoteAddress:Port           Forward Weight ActiveConn InActConn
TCP  www.unitnet.com:http wlc persistent 1800 mask 255.255.255.0
 -> local.lovejoy:http           Route   1      113        5568
 -> local.krusty:http            Route   1      97         223
 -> local.flanders:http          Route   1      91         158
TCP  www.unitnet.com:https wlc persistent 1800 mask 255.255.255.0
 -> local.flanders:https         Route   1      0          12
]]></programlisting>
	</blockquote>
	<para>
Graeme Fowler <emphasis>graeme (at) graemef (dot) net</emphasis> 7 Feb 2006 
	</para>
	<para>
The newer machine is a newer OS, running a newer version of Apache and 
probably newer hardware (OK, those last two are assumptions) - I bet 
it's responding more quickly.
The InActConn counter diaplays thso connection in TIME_WAIT or related 
states, after a FIN packet has arrived to end the connection. If you 
run:
	</para>
<programlisting><![CDATA[
ipvsadm -Ln --persistent-conn --sort --rate

and
 
ipvsadm -Ln --persistent-conn --sort --stats
]]></programlisting>
	<para>
You will probably see that lovejoy is handling rather more traffic than 
krusty and flanders.
	</para>
	<para>
Joe - this could have been the answer, but it wasn't. It was a timeout problem though.
	</para>
	<para>
Randy Paries 
	</para>
	<blockquote>
This ending up being the KeepAlive setting (or lack there of in the <filename>httpd.conf</filename>)
change to KeepAlive On and problem went away
	</blockquote>
	</section>
	<section id="fallback">
	<title>Fallback/Sorry pages with Apache</title>
	<para>
Gustavo Mateus
	</para>
	<para>
I want to customize a fallback server page for each of the 10 web
sites (domains) running on 5 realservers servers.
The way I imagine it can be done is setting lighttpd to respond to 10
different ips. 
One ip on the fallback server for every virtual server that I have.
Is there a way to avoid that?
	</para>
	<para>
<emphasis>prockter (at) lse (dot) ac (dot) uk</emphasis> 30 May 2007 
	</para>
	<para>
The fallback web server can use virtual hosts just like any other web
service so you can provide all sorry pages (little mini sites with
graphics and all) from a single server.
Or you can use a cgi script which varies what it does base on the
environment (which will include virtual host information)
Very very ancient web browsers don't send enough information and to
support them you will have to use IP based hosting, so if you want a
single IP just provide a catch all page for those few (if any) browsers.
	</para>
	<para>
You use
	</para>
<programlisting><![CDATA[
fallback=192.168.20.5:80 masq
]]></programlisting>
	<para>
the information about which virtual host it is, 
comes in the http request from
the users browser, just like it does when they talk to the real service.
	</para>
	</section>
	<section id="testing_with_ab">
	<title>Testing http with apachebench (ab)</title>
	<para>
Larry Ludwig <emphasis>ludes (at) yahoo (dot) com</emphasis> 12 Nov 2006
	</para>
	<para>
From testing it appears that my load balance is working.
From using apachebench (ab) I get about half of the connections fail.  
Sometimes the test doesn't even complete. 
I don't get these errors if I test directly to the server IP.  Some times I get:
	</para>
<programlisting><![CDATA[
apr_recv: No route to host (113)
Total of 1000 requests completed
]]></programlisting>
	<para>
Turns out my "error" wasn't an error after all.  
Everything was working fine, except for the apachebench error.  
What happens is apachebench (ab) stores a copy of the first downloaded web page
and if it doesn't match in future page requests marks it as an error.  
So if the pages on the load balancers are not EXACTLY the same, 
then it will spew an error like the one I got.  
In our case the page listed the server name.
	</para>
	</section>
	<section id="apache_setup">
	<title>Apache setup for DoS</title>
	<para>
Willem de Groot <emphasis>willem (at) byte (dot) nl</emphasis> 18 Apr 2006 
	</para>
	<blockquote>
To my surprise, opening 150 tcp connections to a default apache
installation is enough to effectively DoS it for a few minutes (until
connections time out). This could be circumvented by using
mod_throttle, mod_bwshare or mod_limitipconn but imho a much better
place to solve this is at the LVS loadbalancer. Which already does
source IP tracking for the "persistency" feature.
	</blockquote>
	<para>
Ratz
	</para>
	<para>
Only on a really badly configured web server or maybe a 486 machine :). 
Otherwise this does not hold. Every web server will handle at least 1000 
concurrent TCP connections easily. After that you need some ulimit or 
epoll tweaking.
	</para>
	<para>
Nope, these won't circumvent anything - 
you then just open a HTTP 1.1 channel and reload using GET / every 
MaxKeepAliveTimeout-1. Those modules will not help much IMHO. They only 
do QoS on established sockets. It's the wrong place to interfere.
	</para>
	<para>
It's not a Layer 4 issue, it's a higher layer 
issue. Even if it wasn't, how would source IP tracking ever help?
Check out HTTP 1.1 and pipelining. Read up on the timing configurations 
and so on.
	</para>
	<para>
Only poorly-configured web servers will allow you to hold a 
socket after a simple TCP handshake without sending any data, you get a 
close on the socket for HTTP 1.1 configured web servers with low timeouts.
	</para>
	<para>
You are right however, in that using such an approach of blocking TCP 
connections (_inluding_ data fetching) can tear down a lot of (even very 
well known) web sites. I've actually started writing a paper on this 
last year, however never finished it. I wrote a proof-of-concept tool 
that would (after some scanning and timeout guessing) block a whole web 
site, if not properly configured. This was done using the CURL library. 
It simulates some sort of slow-start slashdot-effect.
	</para>
	<para>
Ken Brownfield <emphasis>krb (at) irridia (dot) com</emphasis> 18 Apr 2006 
	</para>
	<para>
This 150 connection limit is the default MaxClients setting in  
Apache, which in practice should be adjusted as high as you can  
without Apache using more memory than you want it to (e.g., 80-100%  
of available RAM -- no need for the DoS to swap-kill your box, too).   
Each Apache process will use several megabytes (higher or lower  
depending on 32- or 64-bit platforms, add-on modules, etc) so this  
can't be set too high.  Disabling KeepAlives will drop your working  
process count by roughly an order of magnitude, and unless you're  
just serving static content it's generally worth disabling.  But for  
your case of 150 idle connections, it doesn't help.
	</para>
	<para>
Netfilter has various matching modules that can limit connections  
from and/or to specific IPs, for example:
	</para>
<programlisting><![CDATA[
iptables --table filter --append VIP_ACCEPT --match dstlimit -- 
dstlimit 666 --dstlimit-mode srcipdstip-dstport --dstlimit-name  
VIP_LIMIT --jump ACCEPT
]]></programlisting>
	<para>
The reason DoS attacks are so successful (especially full-handshake  
attacks) is that something needs to be able to cache and handle  
incoming connections.  And that is exactly where Apache is weakest --  
the process model is terrible at handling a high number of  
simultaneous, quasi-idle connections.
	</para>
	<para>
LVS has some DoS prevention settings which you should consider  
(drop_entry, drop_packet, secure_tcp) but they're generally only  
useful for SYN floods.  A full handshake will be passed on through  
LVS to the application, and that is where the resources must be  
available.  And given persistence, a single-IP attack will be  
extremely effective if you only have one (or few) real servers.
	</para>
	<para>
Once a connection has been made to Apache, it will need to either  
relegate idle connections out of process (see Apache 2.2's new event  
MPM, not sure if it only works on idle keepalives) or limit based on  
IP with the modules you mention.
	</para>
	<para>
This problem is difficult to solve completely, and I agree that  
solving it in Apache is the least powerful, least convenient, and  
highest overhead solution.  Given Netfilter functionality (2.6 and  
later), the absence of throttles or connection limits in LVS isn't  
fatal.  But I do feel that LVS could be made a more comprehensive  
system if it rolled in even basic connection throttling/limiting,  
plus a more closely integrated and maintained health checking  
system.  And source-routing support. ;)
	</para>
	<para>
There are commercial products available that implement heavy-duty DoS/ 
intrusion protection.  They block the vast majority of simple attacks  
and are crucial for any large-scale public-facing services.  But a  
good distributed full-handshake or even valid HTTP request DoS is  
almost impossible to fully block.
	</para>
	<para>
I agree that the ~1,000 simultaneous connection count is indeed the  
general breaking point for select()- or poll()-based web servers (in  
my experience), and epoll() is a much better solution as you say.
But Apache will not handle 1,000 simultaneous connections unless you  
have 4GB of RAM, you're on a 32-bit platform, and you have every  
feature turned off.  And then only if you don't want any disk buffer/ 
cache. :)
	</para>
	<para>
With typical application server support (<emphasis>e.g.</emphasis>, mod_php), Apache will  
not reach 1000 processes without something like 8-16G of RAM.  I've  
never been able to set MaxClients above 200...  Copy-on-write only  
goes so far.
	</para>
	<para>
Sorry for the tangent, but throttling/DoS prevention is especially  
important for any web/application server based on the process model.
	</para>
	<para>
Graeme Fowler <emphasis>graeme (at) graemef (dot) net</emphasis> 18 Apr 2006 
	</para>
	<para>
This is an application (Apache) configuration issue, not really a load
balancing issue at all.
A default Apache configuration shouldn't, ideally, be in production. The
MaxClients setting is 150 (may be higher depending on distro and choice
of MPM) for a reason, which is that not everyone has the same hardware
and resource availability. It's better that you're given a limited
resource version than one which immediately spins away and causes your
server to expire due to lack of memory, for example.
	</para>
	<para>
This is a problem which LVS itself can't help with, given
that the concept of true feedback isn't implemented.
	</para>
	<para>
If you spend the time to get to know your server, you'll find that you
can sort out this sort of resource famine quite easily by tuning Apache,
with the caveat that it will _always_ be possible to cause Apache (or
any other webserver for that matter) to fall over by flooding it. Think
about the infamous "Slashdot effect".
	</para>
	<para>
You could, in theory, do some limiting with netfilter/iptables on the
director, but that's OT for this list.
To test, just use ApacheBench, which comes with Apache :)
	</para>
	<para>
Ratz
	</para>
	<para>
Too bad that apache only allows epoll for MPM event models. For the 
other interested readers, we're essentially talking about a feature 
which is best described here: http://www.kegel.com/c10k.html
	</para>
	<para>
Now, as for the memory pressure mentioned below, I beg to differ a bit ...
I have rarely hit the problems serving 800-1000 concurrent 
sessions on 32bit using a normal 2G/2G-split 2.4.x or 2.6.x kernel. 
As for memory/cache...
Again, I believe that if you already hit the memory limits, you did 
something wrong in your configuration or setup :).
mod_php or even mod_perl are memory hogs,  
but if you use a proper m:n 
threading model, I bet you can still serve a couple of hundred 
concurrent connections.
	</para>
	<para>
I would argue that copy on write kills your performance because your application 
was not designed properly :). No pun intended, but I've more than once 
fixed rather broken web service architectures based on  PHP or Servlets 
or JSP or ASP or -insert you favourite web service technology-.
	</para>
	<para>
DoS prevention does not exist, this topic has been beaten to death 
already :). DoS mitigation, maybe yes. Maybe we should define throttling 
before continuing discussing its pro/cons. It could very well be that we 
agree on that.
	</para>
	<para>
Most of our customer's httpd show RSS between 800KB and 2MB; some of 
them it's including mod_perl or mod_php.
You can drop the process count if you set your timeouts correctly, 
or you implement proper state 
mapping using a reverse proxy and a cookie engine.
With your iptables command, no wonder you have no memory left on your box :).
	</para>
	<para>
You can't drop a certain amount of illegitimate _and_ 
legitimate connections when you're running on a strict 
SLA. QoS approaches based on window scaling help a bit more.
	</para>
	<para>
Regarding throttling, I reckon you use the TC framework available in the 
Linux kernel since long before netfilter hit the tables.
	</para>
	<para>
Commercial packages use Traffic contracts and the 
sorts, just like TC for example.
Blocking or dropping is not acceptable, diverting or migrating is. The 
biggest issue on large-scale web services according to my experience is 
the detection of malicious requests.
	</para>
	<para>
Ken
	</para>
	<para>
The mod_python and mod_php applications currently under my care are  
at 38-44MB resident on 64-bit.  On a minimal 64-bit box, I'm seeing  
6MB resident.  I've honestly never seen an application, either CGI-  
or mod-based, use less than 2MB on 32-bit including the CGI, and most  
in the 15-45MB range.  As you say, I think the application is a huge  
variable, but therein lies the weakness of the process model.
	</para>
	<para>
Timeouts certainly help, but that's somewhat akin to saying that if  
you set your synrecv timeout low enough, the DoS won't hurt you. :)   
KeepAlives by their nature will increase the simultanous connection  
count, but I apologize if I came across as advocating turning them  
off as a knee-jerk fix to connection-count problems.
	</para>
	<para>
Whether they're beneficial or not (for scalability reasons) depends  
on whether you bottleneck on CPU or RAM first, and whether you're  
willing to scale wider to keep the behavior change due to keepalives.
	</para>
	<para>
The iptables rule I gave was just an example, and 666 is my numeric "foo".
	</para>
	<para>
I was just mentioning dropping packets, not advocating them.  drop_packet  
and secure_tcp, set to 1, seem decent choices.  If LVS is out of RAM,  
I think your SLA is doomed, only to be perhaps aided by these  
settings.  Having them on all the time is indeed Bad.
	</para>
	<para>
I had forgotten about TC, though I'm not sure it can  
throttle *connections* vs *throughput*.
	</para>
	<para>
As for improving LVS:
I had to completely rewrite the LVS alert module for mon, in addition  
to tweaking several of the other mon modules.  Now, this was on a so- 
last-year 2.4 distro -- I haven't worked with LVS under 2.6 yet or  
more modern mon installs.  I also wrote a simple CLI interface  
wrapper to ipvsadm, since editing the ipvsadm rules file isn't  
terribly operator-friendly and prone to error for simple host/service  
disables.
	</para>
	<para>
I think all the parts are there for a Unix admin to complete an  
install.  But for a health-checking, stateful-failover, user-friendly- 
interface setup, it's pretty piecemeal.  And there's no L7 to my  
knowledge.  There are some commercial alternatives (that will appeal  
to some admins for these reasons) that are likely inferior overall to  
LVS.  I think the work lies most in integration, both of the  
documentation and testing, and perhaps patch integration.
	</para>
	<para>
The primary parts of the commercial DoS systems I alluded to are the attack  
fingerprints and flood detection that intelligently blocks bad  
traffic, not good traffic.  Nothing is 100%, but in terms of  
intelligent, low-false-positive malicious request / flood blocking,  
they do extremely well at blocking the bad stuff and passing the good  
stuff.
Is it worth the bank that they charge, or the added points of  
failure?  Depends on how big your company is I suppose.  But I know  
of no direct OSS alternative -- or I'd use it!
	</para>
	<para>
Ratz
	</para>
	<para>
As for RSS - these seem to be my findings as well (contrary to what I stated
earlier), after logging into various high volume web servers of our
customers. In fact, I quickly set up an apache2 with some modules and
this is the result:
	</para>
<programlisting><![CDATA[
vmware-test:~# chroot /var/apache2 /apache2/sbin/apachectl -l
Compiled in modules:
  core.c
  mod_deflate.c
  mod_ssl.c
  prefork.c
  http_core.c
  mod_so.c
vmware-test:~# grep ^LoadModule /var/apache2/etc/apache2/apache2.conf
LoadModule php5_module modules/libphp5.so
LoadModule access_module modules/mod_access.so
LoadModule dir_module modules/mod_dir.so
LoadModule fastcgi_module modules/mod_fastcgi.so
LoadModule log_config_module modules/mod_log_config.so
LoadModule mime_module modules/mod_mime.so
LoadModule perl_module modules/mod_perl.so
LoadModule rewrite_module modules/mod_rewrite.so
LoadModule setenvif_module modules/mod_setenvif.so
vmware-test:~# ps -U wwwrun -u wwwrun -o pid,user,args,rss,size,vsz
  PID USER     COMMAND                       RSS    SZ    VSZ
 8761 wwwrun   /apache2/sbin/fcgi-pm -f /e 11660  2964  17144
 8762 wwwrun   /apache2/sbin/apache2 -f /e 11764  3096  17332
 8763 wwwrun   /apache2/sbin/apache2 -f /e 11760  3096  17332
 8764 wwwrun   /apache2/sbin/apache2 -f /e 11760  3096  17332
 8765 wwwrun   /apache2/sbin/apache2 -f /e 11760  3096  17332
 8766 wwwrun   /apache2/sbin/apache2 -f /e 11760  3096  17332
]]></programlisting>
	<para>
If I disable everything non-important except mod_php, I get following:
	</para>
<programlisting><![CDATA[
vmware-test:~# ps -U wwwrun -u wwwrun -o pid,user,args,rss,size,vsz
  PID USER     COMMAND                       RSS    SZ    VSZ
 9088 wwwrun   /apache2/sbin/fcgi-pm -f /e  9768  2304  15004
 9089 wwwrun   /apache2/sbin/apache2 -f /e  9856  2304  15060
 9090 wwwrun   /apache2/sbin/apache2 -f /e  9852  2304  15060
 9091 wwwrun   /apache2/sbin/apache2 -f /e  9852  2304  15060
 9092 wwwrun   /apache2/sbin/apache2 -f /e  9852  2304  15060
 9093 wwwrun   /apache2/sbin/apache2 -f /e  9852  2304  15060
]]></programlisting>
	<para>
A bare apache2 which only serves static content (not stripped or
optimized) yields:
	</para>
<programlisting><![CDATA[
vmware-test:~# ps -U wwwrun -u wwwrun -o pid,user,args,rss,size,vsz
  PID USER     COMMAND                       RSS    SZ    VSZ
 9191 wwwrun   /apache2/sbin/apache2 -f /e  2588  1364   5376
 9192 wwwrun   /apache2/sbin/apache2 -f /e  2584  1364   5376
 9193 wwwrun   /apache2/sbin/apache2 -f /e  2584  1364   5376
 9194 wwwrun   /apache2/sbin/apache2 -f /e  2584  1364   5376
 9195 wwwrun   /apache2/sbin/apache2 -f /e  2584  1364   5376
]]></programlisting>
	<para>
However, copy on write does not occur for carefully designed application logic
with shared data. So, normally even 40 rss does not hurt you. Stripping
both perl and python to a minimal set of functionality helps further.
	</para>
	<para>
I checked with various customers' CMS installations based on CGIs and
they range between 1.8MB and 11MB RSS. Again, this does not hurt so long
 as the thread model is enabled. However, one has to be cautious
regarding the thread pool settings and for the application handler
(perl, python, ...) within the thread model of apache or else resource
starvation or locking issues bite you in the butt. For Perl I believe
the thread-related settings are:
	</para>
<programlisting><![CDATA[
   PerlInterpStart    <ThreadLimit/4>
   PerlInterpMax      <ThreadLimit/3*2>
   PerlInterpMaxSpare <ThreadLimit/2>
]]></programlisting>
	<para>
Which however heavily interferes with the underlying apache threading
model. If you only use LWPs (pre-2.6 kernel time) those settings are
better not used or you get COW behaviour of the perl thread pool. For
NPTL based setups, this yield much reduced memory constraints. I cannot
post customer data for obvious reasons.
	</para>
	<para>
I believe that 3 simple design techniques help reduce the weakness of the process model.
	</para>
	<itemizedlist>
		<listitem>
Design your web service with shared sources in mind
		</listitem>
		<listitem>
Use caches and ram disks for your storage
		</listitem>
		<listitem>
Optimise your OS (most people don't know this)
		</listitem>
	</itemizedlist>
	<para>
The last point sounds trivial but I've seen people running web servers
on SuSE or RedHat using a preemtive Kernel, NAPI and runlevel 5 with KDE
or Gnome, d/i-notify and power management on!
	</para>
	<para>
Basic debugging with valgrind, vmstat, slabtop could have showed them
immediately why there was I/O starvation, memory pressure and heavy
network latency.
	</para>
	<para>
I didn't actually mean TCP timeouts, but KeepAlive timeouts for example.
	</para>
	<para>
I don't buy the CPU bottleneck for web service applications. Yes, I have
seen 36-CPU nodes go down to their knees by simply invoking a Servlet
directly, but after fixing that application and moving to a multi-tier
load balanced environment things smoothed down quite a bit. My
experience is that CPU constraints for web services are a result of bad
software engineering. Excellent technology and frameworks are available,
people sometimes just don't know how to use them ;).
	</para>
	<para>
For RAM, I'd have to agree that this is always a weakness in the system,
but I reckon that a sane IT budget to implement and map your business
into an e-business web service is certainly considering high enough
expenses in buying hardware, including enough (fast and reliable) RAM.
	</para>
	<para>
You should seriously consider giving advice regarding
installing iptables/netfilter stuff on high-volume networked machines.
At least make sure you do not load the ip_conntrack module, or you're
running out of memory in no time. I've seen badly configured web servers
which had the ip_conntrack module loaded (collecting every incoming
connection tuple and setting a timeout of a couple of hours) running out
of memory within hours. The customer before this fix rebooted his box 3
times a day per cronjob ... go figure.
	</para>
	<para>
In my 8+ years of LVS development and usage, I have never seen
an LVS box run out of memory. I'd very much like to see such a site :).
	</para>
	<para>
For TC: with the (not so very well documented) action classifier and the u32
filter plus a few classes you should get there.
	</para>
	<para>
As for L7:
ktcpvs is a start, not much tested in the wild though I believe. OTOH
putting my load balancer consultancy hat on, I rarely see L7 load
balancing needs, except maybe cookie based load balancing. I would very
much like to see a simple, working and proper VRRP implementation or
integration into LVS. This is what gives hardware load balancers USPs.
	</para>
	<para>
We spend a considerable amount of time doing consultant work
in banking or government environments (after all, what else is there in
Switzerland :)), and there is the tendency to zero-tolerance regarding
false-positives in blocking. Trying to explain why this happens
nevertheless is sort of difficult at times.
	</para>
	</section>
	<section id="squids">
	<title>squids, tcp 80, 3128</title>
	<para>
A squid realserver for the most part can be regarded as just another
httpd realserver.
Squids were one of the first big uses of LVS.
There are some exceptions 
	</para>
	<itemizedlist>
		<listitem>
			<para>
<link linkend="scheduling_squids">scheduling squids</link>). 
			</para>
			<para>
In an LVS of squids, the content of each squid will be different.
This breaks one of the assumptions of LVS, 
so you need to use an appropriate scheduler.
			</para>
		</listitem>
		<listitem>
see <xref linkend="3-Tier_lvs"/> setups
		</listitem>
	</itemizedlist>
	<para>
I haven't set up a squid LVS myself but some people have found
problems.
	</para>
	<para>
Rafael Morales
	</para>
	<blockquote>
		<para>
Before I run the <filename>rc.lvs_dr</filename> script,
my realserver can connect to the outside world,
but after I run it, I lost connection.
The only difference in the route table is this:
		</para>
<programlisting><![CDATA[
10.2.2.71 dev lo  scope link  src 10.2.2.71
]]></programlisting>
	</blockquote>
	<para>
Francois JEANMOUGIN <emphasis>Francois (dot) JEANMOUGIN (at) 123multimedia (dot) com</emphasis> 16 Jan 2004
	</para>
	<blockquote>
		<para>
I had the same thing happen. You should not add any lo route. I don't know why.
		</para>
		<para>
Here is how I configure my realservers for LVS-DR :
		</para>
		<itemizedlist>
			<listitem>
I use <command>noarpctl</command> and first of all I had the noarp entry
			</listitem>
			<listitem>
I add a lo:n interface using <command>ifconfig</command>
(never use <command>ifup</command>, it seems to make some arp things,
and operate badly on an already running cluster).
			</listitem>
			<listitem>
I start the service. Then I configure the director via keepalived.
			</listitem>
			<listitem>
				<para>
To make it right in case of reboot.
I add the <command>ifcfg-lo:n</command> part of the script
to the redhat <filename>/etc/sysconifg/network-script</filename> directory :
				</para>
<programlisting><![CDATA[
DEVICE=lo:1
IPADDR=(VIP)
NETMASK=255.255.255.255
BROADCAST=(VIP)
ONBOOT=yes
]]></programlisting>
				<para>
And then I have this <filename>init.d</filename> script I use for noarp :
				</para>
<programlisting><![CDATA[
#!/bin/bash
# noarp init script
# For LinuxVirtualServer realservers
# FJ 05/01/2004 (logical, french date format)
# noarp devs are welcome to add it to the noarp distribution as
# an example under the GPLv2 or BSD licence (but I would never grant
# any rights for such a simple script).

start () {
# This is a little bit tricky. I use my director for both
# public (194.*) and private (10.*) IPs. So...
for i in /etc/sysconfig/network-scripts/ifcfg-eth* ; do
        . $i
        if [ `echo $IPADDR | cut -f 1 -d "."` ==  194 ] ; then
                RIPPUB=$IPADDR
        fi
        if [ `echo $IPADDR | cut -f 1 -d "."` ==  10 ] ; then
                RIPPRIV=$IPADDR
        fi
done
# Let's have a look at the loopback aliases
for i in /etc/sysconfig/network-scripts/ifcfg-lo:* ; do
        . $i
        if [ `echo $IPADDR | cut -f 1 -d "."` ==  194 ] ; then
                /usr/local/sbin/noarpctl add $IPADDR $RIPPUB
        fi
        if [ `echo $IPADDR | cut -f 1 -d "."` ==  10 ] ; then
                /usr/local/sbin/noarpctl add $IPADDR $RIPPRIV
        fi
done
}

stop () {
/usr/local/sbin/noarpctl reset
}
status () {
/usr/local/sbin/noarpctl list
}

case "$1" in
  start)
        start $1
        ;;
  stop)
        stop $1
        ;;
  restart|reload)
        restart $1
        ;;
  status)
        status
        ;;
  *)
        echo $"Usage: $0 {start|stop|restart|status}"
        exit 1
esac
]]></programlisting>
			</listitem>
		</itemizedlist>
	</blockquote>
	<para>
Palmer J.D.F <emphasis>J (dot) D (dot) F (dot) Palmer (at) swansea (dot) ac (dot) uk</emphasis> Nov 05, 2001
	</para>
	<blockquote>
With the use of
IP-Tables etc on the directors can you route various URLs/IPs (such as ones
requiring NTLM authentication like FrontPage servers etc) not to go through
the caches, but just to be transparently routed to their destination.
	</blockquote>
	<para>
Horms
	</para>
	<para>
This can only be done if the URLS to be passed directly through can be
identified by IP address and/or Port. LVS only understands IP addresses and
Ports, whether it is TCP or UDP, and other spurious low level data that can
be matched using ipchains/iptables.
	</para>
	<para id="requests_based_on_URL" xreflabel="requests based on URL">
In particular LVS does _not_ understand HTML, it cannot differentiate
between, for instance http://blah/index.html and http://blah/index.asp.
rather you would need to set up something along the lines of
http://www.blah/index.html and http://asp.blah/index.asp, and have www.blah
and asp.blah resolve to different IP addresses.
	</para>
	<para>
Further to this you may want to take a look at
<ulink url="http://wwwcache.ja.net/JanetService/PilotService.html">Janet</ulink>,
(http://wwwcache.ja.net/JanetService/PilotService.html)
one of the first big uses of LVS with squids.
	</para>
	<para>
Jezz Palmer had to add a default route from his squid realservers to get them
to work. Squid accessed machines on the internet.
An alternate approach would be to use iproute2 to add routes only
for the services required, and to not add a default route.
	</para>
	<para>
Jezz <emphasis>J (dot) D (dot) F (dot) Palmer (at) swansea (dot) ac (dot) uk</emphasis> 10 Apr 2002
	</para>
	<blockquote>
Here is a list of ports that squid accesses on the internet (outside world).
<programlisting><![CDATA[
80          # http
21          # ftp
443,563     # https, snews
70          # gopher
210         # wais
1025-65535  # unregistered ports
280         # http-mgmt
488         # gss-http
591         # filemaker
777         # multiling http (multilingual translation services)
83,81,90    # Special web sites. These are web servers we need to access,
            # running on idiotic reserved ports.
]]></programlisting>
	</blockquote>
		<section id="squid_with_fwmark">
		<title>Setting up squids with fwmark on the director and transparent proxy on the realservers</title>
		<para>
With squids you can't use a VIP to set up a virtual service - 
the requests you're interested in are all going to a port, port 80.
Since the requests are being to an IP that's not on the director,
you also need to force the director to accept the packets for local
processing (see <xref linkend="LVS-HOWTO.routing_to_VIP-less_director"/>).
Both of these problems were handled in one blow in the 2.0 and 2.2 kernels by
<xref linkend="horms_method"/> using the <filename>-j REDIRECT</filename>
option to <command>ipchains</command>. 
This doesn't work for the 2.4 and beyond kernels, 
as the dst_addr of the packet is rewritten before the packet
is delivered to the director.
A possible (untested) solution is the <xref linkend="tp_redirect"/>
method.
		</para>
		<para>
The method used starting with the 2.4 kernels is to mark all
packets to port 80 and schedule on the mark. 
The packets are accepted locally by <command>iproute2</command>
commands.
		</para>
		<para>
Con Tassios <emphasis>ct (at) swin (dot) edu (dot) au</emphasis> 13 Feb 2005 
		</para>
		<para>
Transparent proxy with squid works well if you use fwmarks. I use it
with the following LVS-DR configuration:
		</para>
		<itemizedlist>
			<listitem>
				<para>
Directors: kernel 2.4.29, keepalived 1.1.7
				</para>
				<para>
Assumming 192.168.0.0/16 is the local network, mark all non local http packets with mark 1.
				</para>
<programlisting><![CDATA[
# iptables -t mangle -A PREROUTING -p tcp -d !192.168.0.0/16 --dport 80 -j MARK --set-mark 1
]]></programlisting>
				<para>
Then configure LVS using fwmark 1 as the virtual service.
				</para>
				<para>
Use these commands so the director will accept the packets
				</para>
<programlisting><![CDATA[
# ip rule add prio 100 fwmark 1 table 100
# ip route add local 0/0 dev lo table 100
]]></programlisting>
			</listitem>
			<listitem>
				<para>
Realservers: standard RHEL kernel, squid, noarp:
				</para>
				<para>
Configure the squid servers to handle transparency the normal way 
as described in the squid documentation.
				</para>
			</listitem>
		</itemizedlist>
		<para>
<emphasis>bikrant (at) wlink (dot) com (dot) np</emphasis> Jun 24 2005
		</para>
<programlisting><![CDATA[
   <cisco router>
    202.79.xx.230
       |
       |-------------------------|-----------------------|
       |                         |                       |
       |                         |                       |
eth0:202.79.xx.240/24 fxp0: 202.79.xx.241/24     202.79.xx.235/24
    <Director>           <realserver >             <client>
    (gw: cisco)           (gw: cisco)              (gw: cisco)
]]></programlisting>
		<para>
The default route for all machines is the router. 
Forwarding is by LVS-DR. 
		</para>
		<para>
Director
		</para>
<programlisting><![CDATA[
Gentoo Linux with 2.6.10 Kernel

ipvsadm -A -f 1 -s sh
ipvsadm -a -f 1 -r 202.79.xx.241:80

(-g is the default, the :80 is ignored for LVS-DR)

iptables -t mangle -A PREROUTING -p tcp --dport 80 -j MARK --set-mark 1

ip rule add prio 100 fwmark 1 table 100
ip route add local 0/0 dev lo table 100

echo 0 >  /proc/sys/net/ipv4/ip_forward
]]></programlisting>
		<para>
Real server Configuration:
FreeBSD 5.3 with squid configured by trans-proxy.
		</para>
		<para>
Cisco Router:
		</para>
<programlisting><![CDATA[

interface Ethernet0/0
ip address 202.79.xx.230 255.255.255.0
ip policy route-map proxy-redirect

access-list 110
     access-list 110 deny tcp host 202.79.xx.241 any eq 80
     access-list 110 permit tcp 202.79.xx.0 0.0.0.255 any eq 80

route-map proxy-redirect permit 10
    match ip address 110
    set ip next-hop 202.79.xx.240
]]></programlisting>
		</section>
	</section>
	<section id="tcpd">
	<title>authd/identd, tcp 113 and tcpwrappers (tcpd)</title>
	<para>
You do not explicitely setup authd (identd) as an LVS service.
Some services
(<emphasis>e.g.</emphasis> sendmail and services running inside tcpwrappers).
initiate a call from the identd client on the realserver to
the identd server on the client.
With realservers on private networks (192.168.x.x)
these clients will have non-routable src_addr'es and
the LVS'ed service will have to wait for the call to timeout.
authd initiates calls from the realservers to the client.
LVS is designed for services which receive connect requests from clients.
LVS does not allow authd to work anymore and this must be taken into
account when running services that cooperate with authd. The inability
of authd to work with LVS is important enough that there is a
separate section on <xref linkend="LVS-HOWTO.authd"/>.
	</para>
	</section>
	<section id="ntp" xreflabel="ntp">
	<title>ntp, udp 123</title>
	<para>
ntp is a protocol for time synching machines.
The protocol relies on long time averaging of data
from multiple machines, statistics being kept separately for
each machine. The protocol has its own loadbalancing
and failure detection and handling mechanisms.
If LVS is brought in to an ntp setup, then an ntp
client machine would be balanced to several different
servers over a long time period, negating the effort
to average the data as if it were coming from one machine.
ntp is probably not a good service to LVS.
	</para>
	<para>
Joe May 2002
	</para>
	<para>
I tried setting up ntp under LVS-DR and found that
on the realserver, ntpd did not bind to the VIP (on lo:xxx).
ntpd bound to 0.0.0.0, 127.0.0.1 and the RIP on eth0, but not to the VIP.
Requests to the VIP:ntp from the client would receive a reply from RIP:ntp.
The client does not accept these packets (reachable = 0).
	</para>
	<para>
Attempts to fix this on the realserver,
all of which produced reply packets which were _not_ accepted by the client,
were
	</para>
	<itemizedlist>
		<listitem>
bring up ntpd while only lo was up. ntpd is bound to 0.0.0.0 and 127.0.0.1.
		</listitem>
		<listitem>
bring up ntpd while the VIP was on lo:xxx and while eth0
was down: result ntpd bound to 0.0.0.0 and 127.0.0.1 but not to the VIP.
		</listitem>
		<listitem>
put the VIP onto another ethernet card, <emphasis>e.g.</emphasis> eth1.
Under these conditions, the realserver worked for LVS:telnet.
However ntpd bound to eth0, lo and 0.0.0.0, but not to the VIP on eth1.
		</listitem>
		<listitem>
put the VIP onto eth0 and the RIP onto eth1. ntpd now bound
to the VIP, but with my hardware, only eth1 was connected to the network
and I couldn't figure out how to route between the RIP on eth0
and the outside world.
		</listitem>
	</itemizedlist>
	<para>
For comparison, telnet also binds to 0.0.0.0 under the same circumstances, but
LVS-DR telnet realservers return packets from the VIP rather than the RIP,
allowing telnet to work in an LVS. The difference is that telnet
is invoked by inetd and when a packet arrived on the VIP, then
a copy of telnetd is attached to the VIP on the realserver.
	</para>
	<para>
If you run ntpd under inetd using this line in <filename>inetd.conf</filename>
	</para>
<programlisting><![CDATA[
ntp      dgram   udp     wait    root    /usr/local/bin/ntpd  ntpd
]]></programlisting>
	<para>
and look in the logfiles, you'll see that for every ntp
packet that arrives from the client, ntpd is invoked, rereads
the /etc/ntp.drift file, finds that another ntpd is bound
to port 123 and gets a signal_no_reset.
However ntpd is bound to the VIP on the realserver
and the client does get back packets from
the VIP and starts accumulating data.
Meanwhile on the realservers,
100's of copies of ntpd are running and
100's of entries appear in ntpq&gt;peer.
You can now kill all the ntpds but the first and have a working
ntp realserver with ntpd listening on the VIP (lo:xxx).
ntp is not designed to run under inetd.
Postings on the news:comp.protocols.time.ntp about binding ntpd
to select IPs indicate that the code for binding to an interface
was written early in the history of ntpd and is due a rewrite.
	</para>
	<para>
Invoking ntpd under inetd with the nowait option, produces similar
results on the realserver, except that now the client does not
get (accept) any packets.
	</para>
	<para id="NAT_client_ntp" xreflabel="NAT ntp clients in LVS-DR realservers">
Tc lewis managed to get ntp working on LVS-DR realservers,
<ulink url="http://marc.theaimsgroup.com/?l=linux-virtual-server&amp;m=97442249716948&amp;w=2">
after some wrestling with the routing tables</ulink>.
ntp was being NAT'ed to the outside world,
rather than being LVS'ed (<emphasis>i.e.</emphasis> the realservers were
time synching with outside ntp master machines).
See also <link linkend="NAT_clients_in_LVS-DR">NAT clients under LVS-DR</link>.
	</para>
	<para>
Wayne <emphasis>wayne (at) compute-aid (dot) com</emphasis> 2000-04-24
	</para>
	<blockquote>
		<para>
I'm setting up an LVS for NTP (udp 123) using LVS-NAT.
Two issues are
		</para>
		<orderedlist>
			<listitem>
<para>
rr seems to balance better than lc
</para>
			</listitem>
			<listitem>
<para>
the balance seems in a large time frame is fine (by sampling
the NTP log every 5 minutes) but not fine by sampling
the NTP log every second.  Is round robin sending
traffic to servers based on each request or based on
a period of time?
</para>
			</listitem>
		</orderedlist>
		<para>
We have tested LVS with DNS, which is UDP based, too.
What we are doing with this test is not for heavy load
issue, rather to see if LVS can provide a fail-over
mechanism for the services.  By load balancing the
servers, we can make two servers backup one, if the
one failed, the service will not stop.
		</para>
		<para>
If round-robin does this one request per server, it is
pretty hard to explain what we saw at the server log,
which indicating one server getting twice the requests
than other two in some seconds, and getting a lot less
at other seconds.  Could you explain why we seeing
that?
		</para>
	</blockquote>
	<para>
Joe
	</para>
	<para>
DNS occasionally issues tcp requests too, which might muddy the waters. I
tested LVS on DNS about 6 months ago at moderate load (about 5/sec I
believe) and it behaved well. I don't remember looking for exact balance
and I doubt if I would have regarded a 50% imbalance a problem. I was just
seeing that it worked and didn't lock up etc.
	</para>
	<para>
If you have two ntp servers at the same
stratum level and the rest of the machines are slaves, the whole setup
will keep functioning if you pull the plug on one of the two servers. Will
LVS give you anything more than that?
	</para>
	<para>
Just realised that you must be running a busy site there. If I have only
one client, after everything has settled down, it will only be making one
request/1024secs. If I have 5 servers they'll only be getting requests
every 5120 secs. Got any suggestions about simulating a busy network? run
ntpdate in a loop on the client?
	</para>
	<blockquote>
One client will not do.  We setup a lot of clients.  The reason is
the NTP server somehow remember the client and if a client
asked too much, it would not answer it for a period of time. Do
not know who designed this in, but we found it out from our tests.
We have close to 100 clients computers in the test.
	</blockquote>
	<para>
If you have 100 clients
making requests every 1024 secs, thats only 1 request
every 10secs. You seem to be getting more than that.
Even at startup with 1 request every 64secs, that's only
2 requests/sec.
	</para>
	<blockquote>
Make two to three requests per second per client. At some
seconds later, NTP servers will stop talking, but that is
fine.  You already got the profit by then.
The scheduling has been
changed to round-robin now, it does work better, but it
still has problem on the micro scale.
	</blockquote>
	</section>
	<section id="https">
	<title>https, tcp 443</title>
	<para>
http is an <emphasis>IP based</emphasis> protocol,
while https is a <emphasis>name based</emphasis> protol.
	</para>
	<para>
http: you can test an httpd from the console by
configuring it to listen on the RIP of the realserver.
Then when you bring up the LVS you can re-configure it to
listen on the VIP.
	</para>
	<para>
https: requires a certificate with the official (DNS) 
name of the server as the client sees it 
(the DNS name of the LVS cluster which is associated with  the VIP).
The https on the realserver then must be setup as if it had the name of the LVS cluster.
To do this, activate the VIP on a device on the realserver (it can
be non-arping or arping - make sure there are no other machines
with the VIP on the network or disconnect your realserver from the LVS),
make sure that the realserver can resolve the DNS
name of the LVS to the VIP (by dns or /etc/hosts), setup the
certificate and conf file for https and startup the httpd. Check
that a netscape client running on the realserver (so that it
connects to the realserver's VIP and not to the arping VIP on
the director) can connect to https://lvs.clustername.org.
Since the certificate is for the URL and not for the IP,
you only need 1 certificate for an LVS running LVS-DR serving https.
	</para>
	<para>
Do this for all the realservers, then use <command>ipvsadm</command> on the
director to forward https requests to each of the RIPs.
	</para>
	<para>
The scheduling method for https must be persistent for keys to
remain valid.
	</para>
	<para>
When doing health checking of the https service, you can connect directly to the IP:port. 
<emphasis>e.g.</emphasis> see code in <filename>https.monitor</filename> at 
<ulink url="http://ftp.kernel.org/pub/software/admin/mon/contrib/monitors/https/https.monitor">
http://ftp.kernel.org/pub/software/admin/mon/contrib/monitors/https/https.monitor</ulink>
	</para>
	<para>
Jaroslav Libak <emphasis>jarol1 (at) seznam (dot) cz</emphasis>
	</para>
	<para>
I run several apache ip based virtual servers on several RSs 
and test them using ldirectord via http only, 
even though they run https too. 
If https is configured properly it will work whenever http does.
	</para>
	<blockquote>
When compiling in Apache.. What kind of certificate should I
create for a real application with Thawte?
	</blockquote>
	<para>
Alexandre Cassen <emphasis>Alexandre (dot) Cassen (at) wanadoo (dot) fr</emphasis>
	</para>
	<para>
When you generate your CSR, use the CN (Common Name) of the DNS entry of
your VIP.
	</para>
	<para>
pb <emphasis>peterbaitz (at) yahoo (dot) com</emphasis> 18 Feb 2003
	</para>
	<para>
F5 and Foundry both DO NOT put SSL Cert processing on their
load balancers, they offload it to SSL Accelerator boxes.
So, don't let anyone tell you anything negative about LVS in this regard.
The big boys don't recommend or do it either.
	</para>
		<section id="https_on_localnode" xreflabel="https_on_localnode">
		<title>use reverse proxy to run https on localnode while other services are forwarded</title>
		<para>
peterbaitz - 27 Jan 2003
		</para>
 		<para>
Is it possible for SSL to be supported on the
director rather than on the realserver(s)?
 		</para>
		<para>
Right now, the powers that be have brought up the
question of placing a purchased Mirapoint email system
behind a "free" load balancer (neglecting to consider
that Mirapoint runs on FreeBSD, and that Piranha is a
purchasable LVS product as well).
 		</para>
		<para>
Joe
		</para>
		<blockquote>
I think you're saying that you want the director to forward
port 80 and to accept port 443 locally, ie to not forward port 443.
If this is the case then you add entries with ipvsadm for port 80
only. All other traffic sent to the VIP on other ports will
be handled locally.
		</blockquote>
		<para>
Matthew Crocker <emphasis>matthew (at) crocker (dot) com</emphasis> 27 Jan 2003
		</para>
		<blockquote>
		<para>
It can be done,  in fact just about anything can be done these days.
If it is a smart thing to do is another matter...  What you are trying
to do isn't really a function of LVS.  You can setup Apache+SSL running
in a reverse proxy configuration.  That apache and be running on or in
front of the LVS director.  The apache can then make normal web
connections to the internal machines which can be run through the LVS
director and load balanced.
		</para>
		<para>
You can use keepalived or hearbeat to manage the high availability
functions of your Apache/SSL proxy. You can use hardware based SSL
engines to handle the encryption/decryption. This is all transparent to
the functions of LVS.
		</para>
		<para>
LVS is 'just' a smart IP packet router,  you give it a packet and tell
it how you want it handled.  It can be configured to do a bunch of
things.
		</para>
		<para>
The ideal solution for the highest performance and greatest availability
is to have 2 groups of directors, each group having N+1 machines running
LVS.  Have 1 group of Apache/SSL servers configured and 1 group of
internal web servers.
		</para>
		<para>
LVS group 1 load balances the inbound SSL traffic to one of the
Apache/SSL servers.  The apache servers make connections to the internal
servers though LVS group 2.  LVS group 2 load balances the internel HTTP
traffic into the realservers.
		</para>
		<para>
To save money you could move Apache/SSL onto the LVS directors but that
could hurt performance.
		</para>
		</blockquote>
		</section>
		<section id="mattvenn">
		<title>Matt Venn's director(NAT)+mod_proxy+mod_ssl+apache HOWTO (howto run https in localnode while forwarding other services, uses reverse proxy)</title> 
		<para>
Matt Venn <emphasis>lvs (at) attvenn (dot) net</emphasis> Jul 6 2004
		</para>
		<para>
You might want to do this if you have highly specced director(s) that you don't want
to waste, or not much SSL traffic.
I use this setup to cache all images, and to do SSL acceleration for my realservers.
Requirements
		</para>
		<itemizedlist>
			<listitem>		
2.4.26 kernel on the director
			</listitem>
			<listitem>
Carlos Lozano's <xref linkend="carlos_solution"/> 
			</listitem>
			<listitem>
<filename>ipvsadm-1.21</filename>
			</listitem>
			<listitem>
your preferred versions of apache and mod_ssl, mod_proxy
			</listitem>
		</itemizedlist>
		<para>
Method:
		</para>
		<para>
patch <filename>ip_vs_core.c</filename> with Carlos' patch, configure the kernel for LVS,
build kernel, install and reboot, compile and install <filename>ipvsadm-1.21</filename>.
		</para>
		<para>
Here are my config files for a small cluster with 1 director and 2 realservers.
This config will do the SSL for traffic to editcluster.localnet, and load balance
both https and http traffic to the 2 realservers.
		</para>
<programlisting><![CDATA[
#/etc/hosts
127.0.0.1               localhost
192.168.0.50            director1.localnet editcluster.localnet vhost1.localnet
192.168.1.1             director1.safenet editcluster.safenet vhost1.safenet

192.168.1.3             processor1.safenet
192.168.1.4             processor2.safenet
]]></programlisting>
		<para>
<command>ipvsadm</command> rules for a setup 
which listens on the director 8080, 
and load balances the realservers on port 80.
		</para>
<programlisting><![CDATA[
-A -t 192.168.1.1:8080 -s rr
-a -t 192.168.1.1:8080 -r 192.168.1.3:80 -m -w 1
-a -t 192.168.1.1:8080 -r 192.168.1.4:80 -m -w 1
]]></programlisting>
		<para>
apache: note that I have many virtual hosts, 
and then one domain for the SSL content.
		</para>
		<para>
for reverse proxy cache
		</para>
<programlisting><![CDATA[
<IfModule mod_proxy.c>
        CacheRoot                                               "/tmp/proxy"
        CacheSize                                               1000000 
</IfModule>
]]></programlisting>
		<para>
for SSL content
		</para>
<programlisting><![CDATA[
<VirtualHost 192.168.0.50:443>
        ServerName editcluster.localnet
        SSLEngine                                               On
        ProxyPass / http://editcluster.safenet:8080/
        ProxyPassReverse / http://editcluster.safenet:8080/
</VirtualHost>
]]></programlisting>
		<para>
one of these for each virtual host
		</para>
<programlisting><![CDATA[
<VirtualHost 192.168.0.50:80>
        ServerName vhost1.localnet
        ProxyPass / http://vhost1.safenet:8080/
        ProxyPassReverse / http://vhost1.safenet:8080/
</VirtualHost>
]]></programlisting>
		<para>
Then you need a properly configured apache on your realservers that is set up
with virtual hosts for vhost1.safenet and editcluster.safenet, all on port 80.
		</para>
		</section>
		<section id="https_from_the_mailing_list">
		<title>https without persistence, how sessions work</title>
		<para>
William Francis 29 Jul 2003 14:46:08
		</para>
		<blockquote>
Is it possible to use LVS-DR with https without persistence?
		</blockquote>
		<para>
James Bourne <emphasis>james (at) sublime (dot) com (dot) au</emphasis>
30 Jul 2003
		</para>
		<para>
It is possible. I made sure that the SSL certificate was available to each
realserver/virtual host via an NFS mount. I use a single centralised
httpd.conf file across all realservers. For example:
		</para>
<programlisting><![CDATA[
<VirtualHost <VIP>:443>
        SSLEngine               On
        ServerName              servername:443

        DocumentRoot            "/net/content/httpd/vhostname"
        ServerAdmin             email@domain.com
        ErrorLog                /net/logs/httpd/vhostname/ssl_error_log
        TransferLog             /net/logs/httpd/vhostname/ssl_access_log
        CustomLog               /net/logs/httpd/vhostname/ssl_request_log "%t
%h %{SSL_PROTOCOL}x %{SSL_CIPHER}x \"%r\" %b"
        SSLCertificateFile      /net/conf/httpd/certs/vhostname.crt
        SSLCertificateKeyFile   /net/conf/httpd/certs/vhostname.key
        SSLCipherSuite
ALL:!ADH:!EXPORT56:RC4+RSA:+HIGH:+MEDIUM:+LOW:+SSLv2:+EXP:+eNULL

	<Directory />
                Options         None
                AllowOverride   None
                Order           Allow,Deny
                Allow from      a.b.c.d/255.255.255.0 a.b.c.d/255.255.255.0
	</Directory>
</VirtualHost>
]]></programlisting>
		<para>
/net/logs, /net/conf and /net/content are all NFS mount points.
		</para>
		<para>
The downside is that unless you have real signed certificates from Thawte etc.
your browser may want to confirm the legitimacy of the certificate presented
each time it hits a new realserver. This depends on the load balancing method
used.
		</para>
		<para>
Hence why the use of persistence is good with https.
		</para>
		<para id="ssl_sessions">
Horms
		</para>
		<para>
The other reason that persistance is a good idea relates to session
resumption. This allows subsequent connections to be set up much
faster if an end-user connects to the same realserver. Some Layer 4
Switching implementations allow persistance bassed on session Id for
this reason. LVS doesn't do this. And it is a bit hard to put into
the current code (when I say a bit, I mean more or less impossible).
		</para>
		<para>
For those who are interested, this is how Session IDs are used.
		</para>
		<para>
An basic SSL/TLS connection has two main phases, the handshake phase
and the data transfer phase. Typically the handshake occurs at the
begining of the connection and once it has finished data transfer
takes place. The handshake uses asymetric (public key) cryptography,
typically RSA, while the data transfer uses symetric cryptography,
typially something like DES3. When the sesssion begins the
public keys are generated. They are then used to securly transfer
the keys that are generated for use with the symetric cryptography
that is used for the data transfer.
		</para>
		<para>
In a Nutshell the idea is
to use slow asymetric cryptography to share the keys required
for fast symetric cryptography which is used to transfer the data.
Unfortunately the handshake itself is quite slow. Especially for
many short connections - as the handshake usually only occurs once
its persentage of time for a connection diminishes the longer
the connection lasts.
		</para>
		<para>
To avoid this problem SessionIDs may be used. This alows an end-user
and real-server to identify each other using the SessionID that was
issued by the real-server in a previous session. When this occurs
an abreviated handhake is used which avoids the more expensive
parts of the handshake. Thus making things faster.
		</para>
		<para>
Note that using different real-servers will not cause connections
that try to use Session IDs to fail. They will just use the slower
version of the handshake.
		</para>
		<para>
Nicolas Niclausse Jul 30, 2003
		</para>
		<blockquote>
			<para>
Indeed, it will be MUCH slower. I've made a few benchmarks, and https
with renegotiation is ~20 times slower.
			</para>
			<para>
There is an alternative to persistance: you can share the session IDs on
the realservers side with distcache http://distcache.sourceforge.net/ .
			</para>
		</blockquote>
		<para>
Christian Wicke Jul 31, 2003
		</para>
		<blockquote>
Is load balancing based on the session id extracted from the request possible?
		</blockquote>
		<para>
Horms
		</para>
		<para>
LVS works at layer 4 so fundamentally it doesn't have
the capability to handle session ids.
		</para>
		</section>
		<section id="2_VIPs_on_https">
		<title>You can have two IPs for an https domainname</title>
		<para>
Cheong Tek Mun
		</para>
		<blockquote>
Is it possible to have one domain name for https with two VIPs.  For
example, the DNS for domain name http:/test.com is 166.166.166.100.  I have
an LVS with these two VIPs: 166.166.166.100 and 166.166.166.101.  Can I
have https service on both VIPs?
		</blockquote>
		<para>
Horms 21 Dec 2004
		</para>
		<para>
Yes.
		</para>
		<para>
Joe - I assume test.com is listed in DNS as having two IPs
		</para>
		</section>
	</section>
	<section id="https_name_based_virtual_hosts">
	<title>name based virtual hosts for https</title>
	<para>
Dirk Vleugels <emphasis>dvl (at) 2scale (dot) net</emphasis> 05 Jul 2001
	</para>
	<blockquote>
I want to host several https domains on a single LVS-DR cluster.
The setup of http virtual hosts is straightforward,
but what about https?
The director needs to be known with several VIP's
(or it would be impossible to select the correct server certificate).
	</blockquote>
	<para>
Matthew S. Crocker <emphasis>matthew (at) crocker (dot) com</emphasis>
	</para>
	<para>
SSL certs are labelled with the URL name but the SLL session
is established before any HTTP requests.
So, you can only have one SSL cert tied to an IP address.
If you want to have a single host handle
multiple SSL certs you need a seperate IP for each cert.
You also need to setup the director to handle all the IP's
	</para>
	<para>
named based HTTP DO NOT WORK with SSL because the SSL cert is sent BEFORE
the HTTP so the sever won't know what cert to send.
	</para>
	<note>
	<para>
Horms has described <link linkend="ssl_sessions">how sessions are established</link>.
	</para>
	</note>
	<para>
Martin Hierling <emphasis>mad (at) cc (dot) fh-lippe (dot) de</emphasis>
	</para>
	<para>
You can't do Name Based VHosts, because the SSL Stuff is done before HTTP snaps in.
So at the Beginning there is only the IP:Port and no www.domain.com.
Look at
<ulink url="http://www.modssl.org/docs/2.4/ssl_faq.html">
Why can't I use SSL with name-based/non-IP-based virtual hosts?</ulink>
(here reproduced in its entirety).
	</para>
	<blockquote>
	<para>
The reason is very technical.
Actually it's some sort of a chicken and egg problem:
The SSL protocol layer stays below the HTTP protocol layer and encapsulates HTTP.
When an SSL connection (HTTPS) is established Apache/mod_ssl has to
negotiate the SSL protocol parameters with the client.
For this mod_ssl has to consult the configuration of the virtual
server (for instance it has to look for the cipher suite,
the server certificate, etc.).
But in order to dispatch to the correct virtual server
Apache has to know the Host HTTP header field.
For this the HTTP request header has to be read.
This cannot be done before the SSL handshake is finished.
But the information is already needed at the SSL handshake phase.
	</para><para>
Bingo!
	</para>
	</blockquote>
	<para>
Simone
	</para>
	<blockquote>
I have done a configuration with LVS-DR and
keepalived.
I will use the server for an intranet application.
I need to menage various intranet domain over the "job machine"
and each domain has to be encrypted over ssl.
Apache needs to use a different IP for any ssl certificate.
What is the right way to implement about 10 ssl domains over the job
machine?
	</blockquote>
	<para>
Stephen Walker <emphasis>swalker (at) walkertek (dot) com</emphasis>
18 Aug 2003
	</para>
	<para>
You cannot use name-based virtual hosts in conjunction with a secure Web
server.
The SSL handshake occurs before the HTTP request identifies the
appropriate name-based virtual host.
Name-based virtual hosts only work with the non-secure Web server.
	</para>
	<para>
Dirk
	</para>
	<blockquote>
With LVS-NAT this would be no problem (targeting different
ports on the RS's). But with direct routing I need different virtual IP's
on the RS. The question: will the return traffic use the VIP-IP by
default? Otherwise the client will notice the mismatch during the SSL
handshake.
	</blockquote>
	<para>
"Matthew S. Crocker" <emphasis>matthew (at) crocker (dot) com</emphasis>
	</para>
	<para>
Yes, on the realservers you will have multiple dummy interfaces, on for
each VIP.  Apache will bind itself to each interface.  The sockets for the
SSL session are also bound to the interface.   The machine will send
packets from the IP address of the interface the packet leaves the machine
on.  So, it will work as expected.  The clients will see packets from the
IP address they connected to.
	</para>
	<para>
Julian Anastasov <emphasis>ja (at) ssi (dot) bg</emphasis>
	</para>
	<blockquote>
<programlisting><![CDATA[
NAT:	one RIP for each name/key
DR/TUN: one VIP for each name/key
]]></programlisting>
Is this correct?
	</blockquote>
	<para>
James Ogley <emphasis>james (dot) ogley (at) pinnacle (dot) co (dot) uk</emphasis>
	</para>
	<para>
The realservers also need a VIP for each https URL, as they need to be
able to resolve that URL to themself on a unique IP (this can be
achieved with /etc/hosts of course)
	</para>
	<para>
Joe
	</para>
	<blockquote>
Are you saying that https needs its own IP:port rather than just IP?
	</blockquote>
	<para>
Dirk
	</para>
	<para>
Nope. A unique IP is sufficient. Apache has to decide which csr to use
_before_ seeing the 'Host' header in the HTTP request (SSL handshake
comes first). A unique port is also sufficient to decide which virtual
server is meant though (and via NAT easier to manage imho).
	</para>
	<blockquote>
(I interpret Dirk as saying that the IP:port must be unique. Either
the IP is unique and the port is the same for all urls, or the IP is common
and there is a unique port for each url.)
	</blockquote>

	<para>
anon:
	</para>
	<blockquote>
how would you run two virtual domains in apache with
different certificates, but just one ip address?
	</blockquote>

	<para>
Jacob Coby <emphasis>jcoby (at) listingbook (dot) com</emphasis> 26 Feb 2003
	</para>
	<para>
It is impossible to share an ip address across multiple https domains on the
standard port.
Why?  Because the HTTP Host header is encapsulated inside the SSL session,
and apache (or anything else) can't figure out which SSL cert to use, until
AFTER decoding the session.  But, to decode the session, it must first send
the cert to the client.
	</para>
	<para>
Catch-22.
	</para>
	<para>
To use multiple https domains, you'll have to either differenciate them
by IP and/or by port.
	</para>

	<blockquote>
What if I use a <link linkend="SSL_accelerator">SSL-hardware decoder box</link>
	</blockquote>
	<para>
I'm not sure what you are talking about,
but I really don't think it will help.
The problem is still the same: trying to serve up two different SSL certs
based on a Host: header alone in the HTTP stream which is encapsulated by
the SSL session which can only be verified by the correct SSL cert.
	</para>
	<para>
The server _cannot_ get to this Host header without sending a SSL cert.
	</para>
	<para>
Niraj Patel <emphasis>niraj (at) vipana (dot) com</emphasis> 20 Dec 2006
	</para>
	<blockquote>
		<para>
Since https uses name resolution to pull the SSL cert, would I also need something like
the following:
		</para>
		<itemizedlist>
			<listitem>
a dns entry for each virtual host that maps a fqdn like web.abc.com to
each of the RIPs <emphasis>i.e.</emphasis>  web.abc.com resolves to RIP1, RIP2, etc.
			</listitem>
			<listitem>
an SSL certificate for web.abc.com that's installed on each RS.
			</listitem>
		</itemizedlist>
	</blockquote>
	<para>
Jaro <emphasis>jarol1 (at) seznam (dot) cz</emphasis> Dec 20 2006
	</para>
	<para>
Name resolution is used to discover IP address not pull SSL certificates. 
Client initiates a TCP connection to server IP address to  receive the SSL certificate. 
SSL will also work if you connect  to IP directly in your browser (in sence that encryption will take place).
	</para>
	<para>
You don't need the DNS entries. ldirectord should be able to perform https checks to IP directly.
You will need the certificates.
	</para>
	<para>
I run several apache ip based virtual servers on several RSs 
and test them using ldirectord via http only even though they run https too. 
If https is configured properly it will work whenever http does.
	</para>
	</section>
	<section id="certificates">
	<title>Obtaining certificates for https</title>
	<para>
May 2006:
<ulink url="http://en.wikipedia.org/wiki/Van_Jacobson">Van Jacobson (of TCP/IP fame)</ulink>
(http://en.wikipedia.org/wiki/Van_Jacobson) has a talk on how they got from 
circuit switching to packet switching. 
Now he wants networking changed from point-to-point 
to allow fetching signed data BitTorrent style without having to specify the location.
The problem with the current system is that only the connection is certified
(you know who you've connected to via ssl/ssh, 
you don't know who originated the data/e-mail).
If each webpage/piece of data was signed, then there'd be no more pharming, phishing or spam. 
	</para>
	<para>
He points out that obtaining certificates 
from Verisign is a single point of failure.
He tells the story that in about 2004, someone (and they don't know who)
obtained a root certificate in the name of Microsoft from Verisign.
Better is a distributed (and presumably revokable) system 
<emphasis>e.g.</emphasis> like 
<ulink url="http://en.wikipedia.org/wiki/Public_key_infrastructure">PKI</ulink>
(http://en.wikipedia.org/wiki/Public_key_infrastructure).
	</para>
	<para>
Zachariah Mully <emphasis>zmully (at) smartbrief (dot) com</emphasis> 26 Aug 2002
	</para>
	<blockquote>
	<para>
	Finally received the quote from Verisign for 128-bit SSL certs for our
website, and I was blown away, $1595/yr! These guys must be making money
hand over foot at these prices. They want $895 for one cert and license
for one server and another $700 for each additional server in the
cluster. This is only for one FQDN, by the end of next year, I'll need
to secure three more domains hosted by these servers... Perhaps I heard
wrong, but I had thought that I could simply get one cert for a domain
(in this case www.smartbrief.com) and use it on all the servers hosting
it in my LVS system, but the Verisign people said I needed to buy
licenses for each server in the system!
	</para>
	<para>
	So I am wondering if Verisign is yanking my chain and if anyone has any
recommedations for other Root CA's that have more reasonable pricing.
	</para>
	</blockquote>
	<para>
Joe (warning - rant follows)
	</para>
	<blockquote>
	<para>
I'll sell you one for $1500 or for $1 if you like. They're both the same ;-\
	</para>
	<para>
This is a rip-off because Verisign got their certificates into Netscape/IE back when
it counted and no-one else bothered to do the same thing.
It's the same monopoly
that they had on domain names and they've just got greedy.
When I needed to get a certificate, I looked up all the companies listed in my
Netscape browser. Most didn't exist anymore or weren't offering certificates.
The only two left were verisign and Thawte. Thawte was in South Africa and were half
the price of Verisign. I wasn't sure how well a South African certificate would
stand up in a US court. Thawte then bungled by setting the expiration of their
certificates to be short enough that everyone with the current browsers of the time
would not recognise Thawte certificates anymore. End of Thawte.
	</para>
	<para>
Eventually Verisign bought out Thawte. No more competition.
	</para>
	<para>
The webpage to get a certificate was an abomination a few years back.
I can't imagine the dimwit who wrote it.
	</para>
	<para>
No-one has stepped in to be an alternate RootCA, and I can't imagine
why. I would expect EFF could do it, anyone could do it. You do need
a bit of money and have to setup secure machine(s), have some way of
keeping track of keys and making sure that the webbrowsers have them
pre-installed. It appears to be more than anyone else wants to do, even
with the price going through the roof at $1500 a pop.
	</para>
	<para>
The browser people could help here by making newly approved RootCA certificates
downloadable from the website for each browser, but it would appear that
all are colluding with Verisign.
	</para>
	<para>
As far as the website operation is concerned a self signed certificate
is just as good as one from Verisign. The only problem is when the user
gets the ominous message warning them that the signing authority of
this certificate is not recognised.
	</para>
	<para>
You could engage in a bit of user education here and tell them that Verisign's
signature is no better than yours.
	</para>
	<para>
Otherwise you're over a barrel that doesn't need to be there and no-one
has stepped forward to fix the situation.
	</para>
	</blockquote>
	<para>
Doug Schasteen <emphasis>dschast (at) escindex (dot) com</emphasis> 26 Aug 2002
	</para>
	<blockquote>
www.ssl.com sells certs but their prices aren't much better. $249 per
domain. The real kick in the teeth is that you need a separate
certificate for not only each domain, but also sub-domains. So I have to
pay an additional $249 if I want to secure something like
intranet.mywebsite.com or mail.mywebsite.com as opposed to just
www.mywebsite.com. As far as I know, Thawte is still the cheapest, even
though they are owned by Verisign.
	</blockquote>
	<para>
nick garratt <emphasis>nick-lvs (at) wordwork (dot) co (dot) za</emphasis> 26 Aug 2002
	</para>
	<blockquote>
	<para>
if you're using NAT you'll just need the one cert for, as you
correctly state, its per FQDN. one cert works fine for my NATed
cluster. not too sure what the implications of DR would be in this
context...
	</para>
	<para>
all a CA is a trusted third party with the buy-in from the browser
manufacturers. the tech is not rocket science either. could be
anyone; there's clearly an opportunity for another operator.
	</para>
	</blockquote>
	<para>
Zachariah Mully wrote:
	</para>
	<para>
Thanks Joe, this is unfortunately exactly what I expected to hear. And
yes, the omnious warning will definitely confuse and scare our brain
dead users.
	</para>
	<para>
	Joe
	</para>
	<blockquote>
	<para>
They aren't really brain dead. They just don't understand what's going on
and quite reasonably in that situation they are worried about their credit card
number and what's going to happen to it. They have a right to know that
their connection isn't being rerouted to some other entity and this
fear is how Verisign is making their money.
	</para>
	<para>
I've just had an offline exchange with someone who self signs and send the client
a pop-up explaining the situation. This appears to be for inhouse stuff.
I don't know if this is going to work in the general case -
I expect that you'll get a different reception if you are the Bank of London
and if you are selling dubious services. You could try it initially and log
the connections that don't follow through after getting the educational
pop-up to see how much people are scared off.
	</para>
		<blockquote>
As someone pointed out, one cert should work fine for many NAT'ed
servers, anyone know if my DR config would change that?
		</blockquote>
	<para>
The certificate is for a domainname. All realservers think they are running
that domainname. For LVS-DR they all have the same IP (the VIP). For LVS-NAT
they all have different IPs (the various RIPs) in which case you have to have
a different /etc/hosts file for each realserver (see the HOWTO). In all cases
the machines have the same domainname and can run the same certificate.
(Hmm, it's been a while, I can't remember whether the RootCA asks you for your IP
or not, so I don't remember if the IP is part of the cert). I can't imagine
how Verisign is ever going to tell that you have multiple machines using the same
cert. Perhaps you could NFS export the one copy of the cert to all realservers.
	</para>
	</blockquote>
	<para>
You do need
a bit of money and have to setup secure machine(s), have some way of
keeping track of keys and making sure that the webbrowsers have them
pre-installed.
	</para>
	<para>
Greg Woods <emphasis>woods (at) ucar (dot) edu</emphasis> 26 Aug 2002
	</para>
	<blockquote>
	<para>
The last part of this is the difficult part. We run our own RootCA here,
because we were quoted a price from Verisign in excess of $50K per year
for what we wanted to do. Then there is the ominous-looking spam that
VeriSign sends that makes it sound like you will lose your domain name if
you don't register it through them, so I won't do business with them
anyway even if the price *has* come down.
	</para>
	<para>
So we had little choice, and we've just had to guide our users through the
scary dialog boxes to get them to accept our CA. Once that's done though,
we can now use SSL with authentication to control viewing of our internal
web pages. Works for us, but your mileage may vary. I do recall hearing a
lot of cursing coming from the security administrator's office while they
were trying to get the RootCA working, too.  That can be rather tricky.
	</para>
	</blockquote>
	<para>
Eric Schwien <emphasis>fred (at) igtech (dot) fr</emphasis> 26 Aug 2002
	</para>
	<blockquote>
	<para>
Thawte is selling 1 year certs at 199 $ each. If you have a Load
Balancer System, they ask you to buy additional "Licences" for the
second, third, etc ... Real server.
	</para>
	<para>
In fact, if you just copy and paste the original cert, all is working fine
(ie, without additional "licences"), ... But you do not have the right
for it. This is a new pricing scheme of Thawte, that still seems cheaper
than offers you had!
	</para>
	<para>
However, you still need one cert for each domain.
	</para>
	<para>
Their Web Site is all new, quite long to read everything, but procedures
are well explained.
	</para>
	</blockquote>
	<para>
"Chris A. Kalin" <emphasis>cak (at) netwurx (dot) net</emphasis> 26 Aug 2002
	</para>
	<blockquote>
Nope, he was talking about 128 bit certs, which even from Thawte are
$449/year.
	</blockquote>
	<para>
Joe Cooper <emphasis>joe (at) swelltech (dot) com</emphasis> 26 Aug 2002
	</para>
	<blockquote>
How about GeoTrust? Looks like $119/year for a 128-bit cert.  Though
some colo/hosting providers seem to be offering the same product for
$49/year (RackShack.net, for example).  Maybe only for their own
customers, I don't know.
	</blockquote>
	<para>
Bobby Johns <emphasis>bobbyj (at) freebie (dot) com</emphasis> 29 Aug 2002
	</para>
	<blockquote>
	<para>
If you're using DR you only need one cert.  I'm running that way right now
and it works flawlessly.
	</para><para>
Also, if you're interested in the nuts and bolts of making your own
certificates, see Holt Sorensen's articles on SecurtyFocus.
	</para><para>
Parts 1-4:
<programlisting><![CDATA[
http://online.securityfocus.com/cgi-bin/sfonline/infocus.pl?id=1388
http://online.securityfocus.com/cgi-bin/sfonline/infocus.pl?id=1462
http://online.securityfocus.com/cgi-bin/sfonline/infocus.pl?id=1466
http://online.securityfocus.com/cgi-bin/sfonline/infocus.pl?id=1486
]]></programlisting>
	</para>
	</blockquote>
	<para>
Here's what the
readers at Slashdot have to say about
<ulink url="http://ask.slashdot.org/askslashdot/03/01/21/207244.shtml?tid=93">
why certificates are so expensive
</ulink>
	</para>

	<para>
Malcolm Turnbull wrote
	</para>
	<blockquote>
As far as I am aware Thwate do not require you to buy a seperate cert
for each realserver (just for each domain).
	</blockquote>
	<para>
Simon Young <emphasis>simon-lvs (at) blackstar (dot) co (dot) uk</emphasis> 18 Feb 2003
	</para>
	<para>
Just for the record, here's the relevant section from the definitions
section of Thawte's ssl certificate license agreement:
	</para>
	<blockquote>
	<para>
  "Licensing Option" shall mean the specific licensing option on the
  enrollment screen that permits a subscriber to use of a Certificate on
  one physical Device and obtain additional Certificate licenses for
  each physical server that each Device manages, or where replicated
  Certificates may otherwise reside
	</para>
	<para>
  "Device" shall mean a network management tool, such as a server load
  balancer or <xref linkend="SSL_accelerator"/>,
that routes electronic data from one
  point to single or multiple devices or servers.
	</para>
	</blockquote>
	<para>
And from section 4 or the agreement:
	</para>
	<blockquote>
  ... You are also prohibited from using your Certificate on more than
  one server at a time, except where you have purchased the specific
  licensing option on the enrollment screen that permits the use of a
  Certificate on multiple servers (the Licensing Option). ...
	</blockquote>
	<para>
So it looks like all realservers do indeed require a license for each
realserver - or at least you have to buy the 'multiple server' license
option, which is more expensive than the single machine license.
	</para>
	<para>
In addition:
	</para>
	<blockquote>
  In the event you purchase the Licensing Option, you hereby acknowledge
  and agree that ... you may not copy the Certificate on more than five
  (5) servers.
	</blockquote>
	<para>
So a large number of realservers may need a multiple server license for
every five machines. This could get expensive...
	</para>
	<para>
In summary, you need a valid license for every copy of your certificate
being used, whether it be single licenses for each, or multiple licenses
for every 5 machines.
	</para>
	<para>
anon
	</para>
	<blockquote>
You only need a certificate per domain.  You should be able to copy it
to as many servers as you want.  I had a SSL IPs load balanced using LVS-TUN
with two computers, using the same certificate, and nothing complained about
the certificate.
	</blockquote>
	<para>
Malcolm Turnbull <emphasis>Malcolm (at) loadbalancer (dot) org</emphasis> 22 Oct 2003
	</para>
	<para>
Me too, and it only took 2 years for me to realise that I was breaking
the licence/law... Verisign <emphasis>et. al.</emphasis>
 have clauses in their contracts
stating that you can't use a cert on more than one web server unless you
pay for a multiple use licence...
	</para>
	<para id="Crypto">
Joe Dec 2003,
	</para>
	<para>
"Crypto" Steven Levy, Viking Pub, 2001, ISBN 0-670-85950-8.
I enjoyed this book - it describes the people involved in producing cryptography
for the masses: Diffie, Hellman, Rivest, Shamir, Adleman, Zimmermann, Chaum and Ellis
(and many others), how they did it and how they had to fight the NSA, and the
legislators to get their discoveries out into the public in a useful way.
	</para>
	<para>
The real story of why RSA (or its descendants, <emphasis>e.g.</emphasis> Verisign)
has the only certificate in Netscape is revealed in this book on p278. I will
attempt to summarise
	</para>
	<blockquote>
RSA owned or controlled all the patents needed for cryptography for the masses.
They had licensed their patents for Lotus Notes and to Microsoft but were limited
to 40 bits for the export version and 56 bits for the US version
(Microsoft shipped 40 bit enabled code in all versions, to simplify
maintenance).
RSA was not making much money and attempts to put their patents to use
were hobbled by the NSA, the US laws on cryptography, and by
the lack of awareness amongst the general public and application
writers that cryptography was useful (<emphasis>c.f.</emphasis>
how hard it is to get wifi users to enable WEP).
The Netscape team was assembled from the authors of Mosaic by
Jim Clark, the just departed CEO of Silicon Graphics, who was
casting about for a new idea for a start-up company.
		<blockquote>
		<para>
	&quot;
	The idea was to develope an improved browser called the Navigator, along
with software for servers that would allow businesses to go on-line.
The one missing component was security. If companies were doing to sell
products and make transactions over the internet, surely customers would
demand protection. It was the perfect job for encryption technology.
		</para>
		<para>
	Fortunately Jim Clark knew someone in the field - Jim Bidzos (the
business manager at RSA). By the time negotiations were completed,
Netscape had a license for RSA and the company's help in developing
a security standard for the Web: a public key-based protocol known
as the Secure Sockets Layer.
Netscape would build this into its software, ensuring that its estimated
millions of users would automatically get the benefits of crypto as
envisioned by Merkle, Diffie and Hellman, and implemented by
Rivest, Shamir and Adleman. A click of the mouse would send Netscape
users into crypto mode: a message would appear informing them that
all information entered from that point was secure.
Meanwhile, RSA's encryption and authentication would be running
behind the scenes.
		</para>
		<para>
Jim Bidzos drove his usual hard bargain with Netscape: in exchange
for its algorithms, RSA was given 1% of the new company.
In mid-1995, Netscape ran the most successful public offering in
Wall Street's history, making RSA's share of the company worth
over 20$M.
	&quot;
		</para>
		</blockquote>
	<para>
The point of this quote is that the people who'd invented cryptography
for the masses, had struggled against their own evil empire (NSA, the
US Govt) and were now in a position to make good. Because of the patents,
there was only one game in town, RSA, and when Netscape was casting around
for crypto, RSA was it. Even if RSA had been staffed by GPL true believers,
there weren't any other companies with root CA's (if there were, they
would have had to license RSA's patents).
	</para>
	<para>
So because of historical accident (the crypto algorithms were all patented
and because the US Govt/NSA tried to keep the genie of crypto from
getting out by sitting on people) RSA was the only company that had
crypto at the dawn of the internet.
	</para>
	</blockquote>
	</section>
	<section id="self_made_certificates" xreflabel="self made certificates">
	<title>Self made certificates</title>
	<para>
Matthias Krauss <emphasis>MKrauss (at) hitchhiker (dot) com</emphasis>
18 Aug 2003
	</para>
	<para>
you can find
a nice explain of self made certs configure and virt. addresses under:
<ulink url="http://www.eclectica.ca/howto/ssl-cert-howto.php">
http://www.eclectica.ca/howto/ssl-cert-howto.php</ulink>
	</para>
	</section>
	<section id="SSL_accelerator" xreflabel="SSL accelerator">
	<title>SSL Accelerators and Load Balancers</title>
	<note>
	<para>
Horms has described <link linkend="ssl_sessions">how sessions are established</link>
	</para>
	<para>
For a description of the (commerical) Radware SSL accelarator setup see
<xref linkend="radware"/>. This setup has the SSL accelarator as a realserver
and the decrytped http traffice is fed back to the director for loadbalancing
as http traffic.
	</para>
	</note>
	<para>
Encrypted versions of services
(<emphasis>e.g.</emphasis> https/http, imaps/imap, pops/pop, smtps/smtp)
are available which require decryption of the client stream,
with the plain text being fed to the regular demon.
In the reply direction, the plain text must be re-encrypted.
Decryption/Encryption are CPU intensive processes and also require the tracking of keys.
Vendors have produced SSL accelerators (cards or stand-alone boxes),
which do the de- and en-cryption, thus taking the load off the CPU
in the server allowing it to do other things.
These accelerator cards are useful if
	</para>
	<itemizedlist>
		<listitem>
		you need to increase the capacity of your server(s)
and don't want to buy a bigger server to handle the extra load from encryption/decryption,
		</listitem>
		<listitem>
you already have the biggest server you can buy
		</listitem>
		<listitem>
you don't have the SSL enabled version of the demon
		</listitem>
	</itemizedlist>
	<para>
The cards (or boxes) usually have proprietary software.
There are only 2 products which work with Linux
(both based on the Broadcom chip?).
	</para>
	<para>
Since these SSL accelerator boxes are not commodity items,
they are always going to be more expensive than the
equivalent extra computing power in more servers.
The niche for SSL accelerators seems to be the suits,
who faced with choosing between
	</para>
	<itemizedlist>
		<listitem>
a low cost solution which requires some
understanding of technology
		</listitem>
		<listitem>
or a high cost solution supported by an external vendor,
which requires no understanding of technology
		</listitem>
	</itemizedlist>
	<para>
will choose the high cost solution.
The people with money understand money;
they usually don't understand technology.
They have little basis to judge the information coming from
the technologically aware people they hire
and whose job it is to advise them
(<emphasis>i.e.</emphasis> the suits don't trust the people at the keyboard.)
	</para>
	<para>
solutions for the technologically aware people are
(this is not my area - anyone care to expand on this - Joe)
	</para>
	<itemizedlist>
		<listitem>
add more servers and use a load balancer.
The demon on the servers will have its own SSL code.
		</listitem>
		<listitem>
use apache with mod_reverse_proxy
		</listitem>
		<listitem>
use ssl engine
		</listitem>
	</itemizedlist>
	<para>
The dominant school of thought amongst LVS'ers is to add realservers
running the SSL'ified demon.
	</para>
	<para>
Kenton Smith
	</para>
	<blockquote>
		<para>
Do I terminate the SSL traffic at the director or the realserver?
How do I handle the certs?
If the traffic is terminated at the realserver,
do I need a certificate for each realserver?
Can I use a name-based cert using the domain name that goes
with the virtual IP on the director, thus only requiring one certificate?
		</para>
	</blockquote>
	<para>
Joe (caveat: I haven't done SSL with LVS).
	</para>
	<para>
Some rules when thinking about how to handle services on LVS
	</para>
	<itemizedlist>
		<listitem>
each realserver thinks it is being connected
directly by the client.
		</listitem>
		<listitem>
each client thinks it is directly connected to a
single box (the realserver).
		</listitem>
		<listitem>
Neither the client or the realserver knows the
director exists.
		</listitem>
	</itemizedlist>
	<para>
So - setup each realserver as if the client was directly
connecting to it.
Put a name based cert on each realservers and
let the realserver handle the SSL de/encoding.
	</para>
	<para>
pb <emphasis>peterbaitz (at) yahoo (dot) com</emphasis> 15 Oct 2003
	</para>
	<para>
Where I work we use Piranha (Red Hat's spin of LVS)
and regarding SSL, we let the realservers do the SSL
work.
No sense busying the director with processing the SSL, and
even if you wanted to, you would look to SSL
Accelerators, which we have not implemented, though we
looked at the technology theoretically speaking - but
you also get into what service(s) you are using SSL
for, webmail, web sites, etc.
Better to let the realservers handle the SSL... you
can always add more realservers if SSL processing
bogs them down by some fraction.
	</para>
	<para>
Horms
	</para>
	<para>
I agree. And arguments that I have heard to the contrary
are usually tedious at best. SSL is probably the
most expensive thing that your cluster needs to do.
Thus disributing amongst the realservers makes the most sense
as you can scale that by just adding new machines.
	</para>
	<para>
You can terminate the SSL connection at the director,
perhaps using something like squid as a reverse proxy, 
but then the Linux Director has to do a _lot_ of work.
You probably want to get an hardware crypto card if
you are going down that road and have a reasonable ammount of traffic.
	</para>
	<para>
You shold use the same certificate on each of the realservers.
That way end-users will always see the same certificate
for a given virtual service.
	</para>
	<blockquote>
Can I use a
name-based cert using the domain name that goes with the virtual IP on
the director, thus only requiring one certificate?
	</blockquote>
	<para>
I am not sure that I follow this. The name in the certificate
needs to match the name that your end-users are connecting to.
So if you have www.a.com, www.b.com and www.c.com then they
can't use the same certificate. Though the certificates can
have wildcarsd, so you could use the same certificate for
www1.a.com, www2.a.com and www3.a.com.
	</para>
	<para>
On a related note. You have to have a different IP address or
use a different port for each different certificate. There is
no way to use name based virtual services with certificates
as SSL has no facility for virtal hosting and thus there
is no way for the ssl server to select beetween different
certificates on the same IP/Port.
	</para>
	<para>
Peter Mueller
	</para>
	<blockquote>
If I wanted to use a hardware SSL decrypting device such as a card in my
LVS-director boxes, how could I set this up in LVS?  I see no problem
getting 443 to decrypt, but how do people then forward this traffic to the
realserver boxes?  I like the idea of saving 20-30+ Thawte bills a month
AND offloading a whole bunch of CPU for the one time cost of $500/card..
	</blockquote>
	<para>
AFIK at this time the only real way to do this is to use
a user-space proxy of some sort. Once you have it in user space it
is pretty straight forward as long as the card is supported
by openssl / provides the appropriate engine library for openssl.
	</para>
	<para>
On the other hand, surely there is someone who isn't
committing highway robbery to provide certificates.
AFIK the reason you offer above is the only reason to use
an accellearator card in this situation. It is a technical
solution to Thwate overcharging. A much better solution is to
distribute load on the cluster, that is what it is there for.
	</para>
	<para>
Matthew Crocker <emphasis>matthew (at) crocker (dot) com</emphasis> 22 Oct 2003
	</para>
	<para>
There are more than one way to handle SSL traffic.  This is how I do it
	</para>
	<para>
I have 2 working machines (aka realservers) running Linux/Apache/SSL
I have 1 /24 subnet (256 IP addresses) assigned to SSL serving
I register 1 SSL certificate per SSL domain I host ( www.abc.com,
www.def.com ,www,ghi.com)
I assign each domain to an IP address from the SSL pool using DNS
(www.abc.com  IN A 159.250.20.1, www.def.com IN A 159.250.20.2)
I use LVS-DR to load balance the connections to the 2 realservers.
I setup  the realservers to handle every IP in the SSL pool.
	</para>
	<para>
In short, SSL certificates are branded with the domain name.  The SSL
protocol establishes security before any HTTP requests.  The client web
browser checks the domain it went to (location bar) wit the domain in
the certificate.  If the domains do not match the web browser complains
to the user.  SSL is still established.   Due to this processes you
must us separate IP address for each SSL certificate so Apache will
know what SSL cert to use when establishing the connection.
	</para>
	<para>
I use a hybrid LVS-NAT/LVS-DR setup with fwmarks and some static routes
to handle my SSL traffic.  Check a couple months back in the logs where
I detail how I do it.
	</para>
	<para>
My realservers are not on the Internet. Only traffic in the SSL Pool
going to port 80 and 443 are routed to the realservers. Each real
server has a copy of all SSL certs (shared drive). If I need SSL
decryption hardware I would place it in the realservers. Persistence
is set on the LVS box for the connections. Port 80 and 443 are bound
together for persistence.
	</para>
	<para>
As part of his work, PB, has been finding out
about SSL accelerators. Here's his writeup (Mar 2003).
	</para>
		<section id="pb_SSL_accelerator">
		<title>PB's SSL Accelerator write up</title>
		<para>
I've been working with SSL accelerators and
have been thinking about using them with LVS.
After having Foundry, F5 and Cisco in here for a
technical review of their products,
I find that LVS has the same basic load balancing functionality.
F5 uses BSD Unix,
Cisco runs on Linux with ASIC chips,
and they have fancy GUI and various additional functionality,
but LVS has all the same basic stuff.
		</para>
		<para>
		<note>
Note: Red Hat is a Cisco customer, and uses Cisco
load balancing and ssl solution in-house (I assume),
rather than using their own Red Hat Advanced
Server + Piranha + SSL solution of their own which
would have helped all us RH Linux Piranha customers.
		</note>
		</para>
		<para>
An SSL accelerator is a piece of software running either
on a separate box which is inserted into your
data stream, decrypting on the way to the server and
then re-encrypting on the way back to the client, or
running on a card with its own processor,
that's inserted into the server to do the same thing.
		</para>
		<para>
In simpler times we put SSL Certificates
(Verisign, Thawte, etc.) on the realservers, and
let the load balancer route the traffic to
the realservers where the SSL decryption is done.
https, e-mail protocols smtps, imaps, and pops are all
SSL Encryption oriented. Additionally, many new
applications today have joined the SSL bandwagon.
Now SSL decryption is CPU-intensive and adds actual
load on your realservers.  Solution?  Add more real
servers behind your load balancer, right?  Yes and no.
 		</para>
		<para>
Adding additional realservers behind your load
balancer to offset SSL decryption load is the
intuitive solution, since that is what the purpose of
a load balancer is, to allow many realservers, and
lower the load to each. However some folks today
add what is gernerally called "SSL Accelerator" solution to the
mix, and remove as many SSL Certificates and SSL
decryption from the realservers and pre-process the
SSL Encrypted data stream before it hits the real
servers. In short SSL Accelerators decrypt the data,
then pass the decrypted data via clear-text (standard)
protocols (like http, smtp, imap, pop) to the real
servers.
		</para>
		<para>
<emphasis>e.g.</emphasis>
for https, in a standard server, the decrypted https
is sent as clear text to the httpd on port 80.
Same for smtps -> smtp, imaps ->imap, pops-> pop, etc.
		</para>
		<para>
What happens to ssh?
I think because ssh is
using its own RSA keys (not SSL) on the server
the information is
encrypted all the way.
		</para>
		<para>
The point of the SSL accelerator is to reduce the
load on your server (which is now busy crypting, rather
than serving pages),
so that it can deliver more pages of data to clients
without changing your server setup.
However you could do the same thing by beefing up
you server (or putting an array of realservers behind an
LVS) without any change in software on your servers.
		</para>
		<para>
The problem then is one of cost.
The Ingrian and Sonicwall SSL boxes are in the multiple
10K$ range. The cards cost less, and other
stand-alone units that support fewer protocols (like
http/https only) cost a few thousand. Suits feel
better spending money when it is available (ie. an SSL
accelerator array will insure we don't need to spend more
money on 1 or 2 or 3 more realservers in the future).
So an SSL accelerator is aimed at non-technical, but
financially knowlegable managers, rather than techically
competent but financially naive computer people.
(When faced with the choice of going to an L7 load-balancer
or rewriting the application to be L4 friendly, the
suits will go for the slow and expensive L7 load-balancer,
while the programmers will re-write the application -
the choice depends on what you have at hand that you
understand).
		</para>
		<para>
You can have an SSL Accelerator without a load
balancer, but in order to have an array of them, you
want a load balancer.  (Another choice is DNS round
robin, which several people, including Horms, have
found, is not a good way to go).
		</para>
		<para>
There are two main ways this passing the baton is
done.  First, your load balancer can load balance all
data steams to a few of these SSL Accelerator units,
which decrypt any SSL encrypted data, and themselves
load balance all protocols to your realservers.
Second, your load balancer can load balance just the
SSL encrypted data streams to several SSL Accelerator
units, which after they decrypt the data, pass it back
to your load balancer as clear-text to be routed by
your load balancer as non-encrupted data over standard
protocols to your realservers.
		</para>
		<para>
SSL Accelerators are available as stand alone units
(you would normally buy several and make an array of
them) or as SSL Accelerator CARDS which plug into your
realservers to speed them up with regard to SSL
decryption (which is yet another solution).
		</para>
		<para>
In principle you could separate out the
SSL handingly from a linux server and
run it on a separate box to make a linux only
SSL accelerator box.
The natural people to do this would be the mod_ssl
people, but they are supporting linux compatible SSL hardware
(<emphasis>e.g.</emphasis> cards that use the Broadcom chipset)
via the "OpenSSL engine" feature.
(see the
<ulink url="http://marc.theaimsgroup.com/?l=apache-modssl&amp;r=1&amp;w=2">
mod_ssl mailing list archives
</ulink>)
		</para>
		<para>
This will allow you to build a
SSL Accelerator Linux box
or to beef up your realserver with a
Broadcom card in your Linux LVS load balancer.
Since the extra processing is now on a separate
processor, in principle this should not add a lot
of extra load to your realserver.
		</para>
		<para>
Ingrian and Sonicwall
are a couple fairly expensive SSL Accelorator
solutions which support all the protocols you need.
Broadcom makes the card you can add to your real
servers.  There are other brands which make less
expensive SSL Accelerators that support only https
(web) protocol.
		</para>
		<para>
The information from most vendors is vendor-speak,
however Ingrian has some
<ulink url="http://www.ingrian.com/resources/index.html#wp">white papers</ulink>.
		</para>
		<para>
I peronally called Ingrian and found them to be
extremely TECHNICALLY helpful (more than I could
understand myself). They seemed willing to help me
even though I told them I use Piranha/LVS (and not
Foundry their partner). I did not find any level of
open-source style detail on SSL
Acceleration/decruption. Got all my info from the
load balancer companies, Ingrian, and white papers.
		</para>
		<para>
I don't know how an SSL accelerator box/card works.
Presumably several levels are involved.
		</para>
		<itemizedlist>
			<listitem>
			<para>
The box has to get the packets
			</para>
			<para>
One of the two methods (called "one arm config")
you have the load balancer route only SSL-bound
protocals (ie. https, imaps, smtps, etc.)
to the SSL accelerator.
			</para>
			</listitem>
			<listitem>
for a card, it has to grab the packets off
the PCI bus. (Anyone know how this is done?).
			</listitem>
			<listitem>
the SSL accelerator has to keep track
of session data etc.
			</listitem>
		</itemizedlist>
		<para>
The end result is that the box/card
takes the SSL encrypted form of the data, decrypts it to clear text,
and shoots it out like it was never encrypted.
		</para>
		<para>
Some SSL accelerators have load balancing
built-in (eg Ingrian).  But not all.
The standard "one arm config" does NOT require it.
You use your own load balancer, and send SSL encrypted
data to your SSL Accelerators, then they output
decrypted clear text data sending it back to the load
balancer for routing to the realservers.
Only Ingrian mentioned/recommended that they can also
do load balancing.
		</para>
		<para>
I don't know how you would use an SSL accelerator with LVS-DR.
The load balancer companies talk about
the decrypted clear text going to the realservers,
but do not recall a dicussion about going back out
again.
		</para>
		</section>
		<section id="SSL_accelerator_mailing_list">
		<title>from the mailing list</title>
		<para>
Matthias Krauss <emphasis>MKrauss (at) hitchhiker (dot) com</emphasis> 10 Mar 2003
(severly editorialised by Joe)
		</para>
        	<para>
I had LVS-DR forwarding http (but not https).
I hoped to decrypt the https packets on the director with the SSL accelerator
card and then pass the decrypted packets to the realserver via the LVS,
to save cpu time on realservers.
I simulated 10 concurrent requests and
downloads of about 3 GB via the ssl acclerator, apache's cpu time went
up to 30% on a 1Ghz/512MB host.
        	</para>
        	<blockquote>
when you had the accelerator card in front of the director,
what does it do with traffic to other ports eg port 80?
Does it just pass them through?
Does it look like a router/bridge except for port 443?
        	</blockquote>
        	<para>
For me it looked like some kind of proxy,
dealing with the incomming ssl/443/encrypted traffic,
decrypts it and passed http/80/decrypted traffic to the LVS .
With tcpdump I saw that between the ssl rewrite
engine and the VIP was only regular http traffic.
By the way, I didnt have an acclerator card for the apache box,
I just used apache rewrite and proxy pass mod for the decrytion job.
        	</para>
		<para>
Julian 11 Mar 2003
		</para>
		<para>
The SSL Accelerator cards I know allow user space processes (usually
many threads) to accelerate the handling of private keys. What I know
is that the normal traffic is still encrypted and decrypted from the
CPU(s).
		</para>
		<para>
OTOH, decryptying the SSL data in directors is used mostly
to modify the HTTP headers for cookie and scheduling purposes.
For other applications it can be for another reason. Even the HTTP stream
from the realservers is modified. So, I don't think LVS can be used here.
Of course, it is possible to implement everything in such way so the
user space handling is avoided and all processing is moved in kernel
space: queues for SSL async processing, HTTP protocol handling, cookies,
just like ktcpvs works in kernel space to avoid memory copy.
		</para>
		<para>
I don't follow the SSL forums, so I don't know at what
stage is the kernel-level SSL acceleration. My experience shows
that the user-space model needs many threads just for private keys
to keep the accelerator busy and the rest is spent for CPU encryption
and decryption of the data.
		</para>
		<blockquote>
			<para>
Joe: private keys are kept in threads rather than in a table?
			</para>
			<para>
Julian:

	If you have to use the following sequence for an incoming
SSL connection (user space):
			</para>

<programlisting><![CDATA[
SSL_accept
loop:
	SSL_read, SSL_write to client
	read, write to realserver
]]></programlisting>
			<para>
The SSL_accept operation is the bottleneck for non-hardware SSL
processing, SSL_accept handles the private key which costs very
much. The hw accel cards offload atleast this processing (the
engine is used internally from SSL_accept) but we continue to call
SSL_read and SSL_write without using the hw engine.
			</para>
			<para>
	Considering the above sequence we have two phases which
repeat for every incoming connection:
			</para>
			<itemizedlist>
				<listitem>
wait the card drivers to finish the private key operations.
That means one thread waiting in blocked state for SSL_accept
to finish.
				</listitem>
				<listitem>
do I/O for the connection (this includes data encryption and
decryption and everything else)
				</listitem>
			</itemizedlist>
			<para>
	What we want is while the card is busy with processing
(it does not have any PCI I/O during this processing) to use
the CPU not for the idle kernel process but for encryption and
decryption of other connections that are not waiting the engine.
So, the goal is to keep the queue of the hwaccel busy with
requests and to use the CPU at the same time for other processing.
As result, the accel reaches its designed limit of RSA keys/sec
and we don't waste CPU in waiting only one SSL_accept for results.
			</para>
			<blockquote>
Joe:
if there was only one thread, the accelerator would be a bottle neck
or it wouldn't work at all?
			</blockquote>
			<para>
	The CPU is idle waiting SSL_accept (the card) then the
card is idle waiting the CPU to encrypt/decrypt data. The result
could be 20% usage of the card and (30% usage of the CPU) and
the idle process is happy: 70% CPU.
			</para>
		</blockquote>
		<para>
I don't know if this is true
for all cards. But even with an accelerator, the using of SSL costs 3-4
times more than just the plain HTTP. My opinion is that this game is
useful only for cookie persistence. For other cases LVS can be used
in directors and the accelerators on the realservers - LVS forwards
TCP(:SSL:HTTP) at L4, the accel is used from user space as usually.
		</para>
		<blockquote>
Joe: is this 3-4 times the number of CPU cycles?
		</blockquote>
		<para>
	Yes, handling of SSL encrypted HTTP traffic with hwaccel
is 3-4 times slower than handling the same HTTP traffic without
using SSL. Of course, without hwaccel this difference could be
20 and that depends on the used CPU model. What I want to say
is that it is better to delay this processing at the place where it
is needed: if the SSL traffic needs to be decrypted for scheduling
and persistence reasons than it should be done in director but
if SSL is used only as secure transport and not for the above
reasons than it is better to buy one or more hwaccel cards for
the realservers. Loading the director should be avoided if
possible.
		</para>
		<para>
	As for any tricks to include LVS in the SSL processing I
don't know how that can be done without using kernel-space SSL
hwaccel support. And even then, LVS can not be used, may be
ktcpvs can perform URL switching and cookie management.
		</para>

		<para>
pb Mar 11, 2003
		</para>
		<blockquote>
I wonder if a software engine could be written to
accept data from any SSL service
(https/smtps/imaps/pops) and let apache rewrite +
proxy pass mod decrypt it, then get it sent back out
the correct clear text port (http/smtp/imap/pop).
Its all SSL encrypted the same way, so once decrypted
just pass it to the right protocol.  No?
		</blockquote>
		<para>
Horms
		</para>
		<para>
Yes this would be possible. But I fail to see why it would be desirable
unless you are running a daemon that can't do SSL itself
(not all demons are SSL enabled).
		</para>
		<para>
Joe: see <link linkend="qmail_posting">SSL'ifying demons</link>.
		</para>

		<blockquote>
unknown:
Would an SMP system make a difference such that the OS and general I/O
is not bogged down?
		</blockquote>
		<para>
Horms
		</para>
		<para>
Surely the problem is CPU and not I/O so to that end one would expect
that an SMP machine would help.
		</para>

		<para>
Ratz
		</para>
		<para>
the simple solution that works in almost all cases is apache + mod_reverse_proxy.
You can build highly scalable and secure transaction servers.
No need for SSL accelerators, since after all,
there are only 2 known products out there that work with linux.
Also you can double-balance the requests with the
same load balancer before the reverse proxy and after the proxy with LVS-DR and
two NICs which leads to a pretty nice HA setup.
(The healthchecking scripts however are a bit complex though.)
		</para>
		<para>
Horms
		</para>
		<para>
Personally I agree that SSL accelerators are pointless.
I don't really see that you
can do much that can't be done with a reverse proxy or better still,
just handling the SSL on the realservers.
When you think about it, SSL
is probably at least as CPU intensive as whatever else the Real Servers
are doing, so it makes sense to me that load should be spread out.
I can see some arguments relating to SSL session IDs and the like.
But the only real way forward here is to move stuff into the kernel.
I haven't given this much thought, but what Julian had to say on the
matter makes a lot of sense.
		</para>
		<para>
(from a while back)
		</para>
		<blockquote>
			<para>
Jeremy Johnson <emphasis>jjohnson (at) real (dot) com</emphasis> 12 Oct 2000
			</para>
			<para>
I have been evaluating the Intel 7110 and the 7180 SSL E-commerce
accelerators recently. I would prefer to use the 7110's (Straight SSL
Accelerators) coupled with LVS instead of throwing out LVS and using the
7180 as the cluster director.
			</para>
			<para>
Now, before anyone says "You can do that with LVS-Tun", I am aware that
I can fix this problem with LVS-Tun but I would like to see if there is
a fix for LVS-DR that would let this work as I prefer the performance of
LVS-DR over LVS-Tun.
Here is how I have the network setup
			</para>
<programlisting><![CDATA[
                        ________
                       |        |
                       | client |
                       |________|
                           |
                        (router)
                           |
             __________    |
            |          |   |
            | director |---|
            |__________|   |
                           |
                           |
          -----------------------------------
          |                |                |
          |                |                |
    ____________      ____________    ____________
   |            |    |            |  |            |
   | 7110 SSL   |    |  7110 SSL  |  | 7110 SSL   |
   |____________|    |____________|  |____________|
          |                |                |
          |                |                |
    ____________      ____________    ____________
   |            |    |            |  |            |
   | realserver |    | realserver |  | realserver |
   |____________|    |____________|  |____________|
]]></programlisting>
			<para>
These 7110 SSL Accelerators have 2 Ports, IN one and OUT one. The
problem is that when the request comes into the Director and the
director looks up the MAC address of the RealServer, it is getting the
MAC address of the First NIC in the 7110 Director, so when the packet
headers are rewritten with the Destination MAC Address, the MAC address
of a NICK in the 7110 is written instead of the MAC of the RealServer.
The effect is a black hole.The cluster works fine without the 7110 in
between LVS and the RealServer, as soon as I swap in the 7110, all
traffic bound for the RealServer with the 7110 in front of it is
blackholed.
			</para>
			<para>
Any Ideas? I could be wrong about what exactly is happening but
basically as soon as I swap in the 7110 LVS for the RealServer Dies,
same thing when I set the box in fail-through mode, the box is acting as
a straight piece of wire then and I am having the same problem so I
believe it has something to do with the wrong MAC address, any ideas?
			</para>
			<para>
I am really hoping that someone has encountered something like this and
has a fix. The obvious fix would be to be able to on the director force
the MAC addresses of the RealServer instead of looking them up.
			</para>
		</blockquote>
		<para>
Terje Eggestad <emphasis>terje (dot) eggestad (at) scali (dot) no</emphasis> 13 Oct 2000
		</para>
		<para>
Since you're in an evaluation process, I offer another solution to
the accelerator problem, that will give you a cleaner lvs setup.
I've tried a PCI accelerator card from RainBow,
<ulink url="http://isg.rainbow.com/cryptoswift/cs_pci.html">RainBow</ulink>.
My experience was with Netscape Enterprise
Server on HP, but RedHat flags that their version of Apache, Stronghold,
has drivers for this card.
The effect was nothing short of amazing. Before adding this card the
CPU usage ration between  the web server and the CGI programms was 75:25.
After adding this card it was in the neighbourhood of 10:90.
		</para>
		<para>
Ryan Leathers <emphasis>ryan (dot) leathers (at) globalknowledge (dot) com</emphasis> 17 Aug 2005
		</para>
		<blockquote>
			<para>
I have been using LVS for a small farm for a couple of years now.  I am
interested in adding SSL hardware acceleration to my two LVS servers.
It is my goal to maintain performance by offloading the SSL chores, and
reduce the cost of certificate renewal by not applying certificates to
my web servers.  
			</para>
			<para>
Can anyone offer advice from experience doing the same?  I am using an
LVS-NAT configuration currently and am happy with it.  It has been
suggested that I get a commercial product to do this (Big-IP from F5)
which I am not absolutely opposed to, but if there is a good track
record with adding SSL hardware acceleration to LVS then I will be happy
to stick with what I've been using.
			</para>
		</blockquote>
		<para>
Peter Mueller <emphasis>pmueller (at) sidestep (dot) com</emphasis>
		</para>
		<para>
Intel used to make a daisy-chain network device that would do this.  A lot of
companies still add an SSL card to a few servers, <emphasis>e.g.</emphasis>
http://h18004.www1.hp.com/products/servers/security/axl600l/ or
http://www.chipsign.com/modex_7000.htm.  And then there are the accelerators
on F5s and their like.  I think the least disruptive way will be the
add-on-card to two servers and a :443 vip containing only them.
		</para>
		<para>
<emphasis>kwijibo (at) zianet (dot) com</emphasis>
		</para>
		<para>
Why are you worrying about offloading it?  I would just buy some boxes
with faster CPU's if speed is a concern.  The time it takes to ship
the data back and forth over the bus to the SSL accelerator your processor
probably could have taken care of it.  Especially if the algorithm uses
all the bell and whistle features todays CPUs have.
		</para>
		<note>
			<para>
Joe: as Horms says, it's all about the number of certificates. 
This is not a problem that has a technical solution.
			</para>
		</note>
		</section>
		<section id="qmail_posting">
		<title>SSL'ifying demons</title>
		<para>
Richard Lyons posting to the qmail mailing list, 05 Feb 2003
		</para>

		<para>
To configure Qmail to use "pop3s" and "smtps",
there are plenty of examples in the archives at
http://www-archive.ornl.gov:8000/, but let me hit the high points.
		</para>
		<para>
There are two ways to offer secure versions of the SMTP and
POP services.  In the first, the existing services on port 25
and 110 can be enhanced with the STARTTLS and STLS extensions
(RFCs 2487 and 2595), allowing clients to negotiate a secure
connection.  The other method is to provide services on
different ports and wrap or forward connections on the new
ports to the existing services.
		</para>
		<para>
STARTTLS for qmail-smtpd is done either with the starttls patch
(look for starttls on http://www.qmail.org) or with Scott
Gifford's TLS proxy, see
http://www.suspectclass.com/~sgifford/stunnel-tlsproxy/stunnel-tlsproxy.html
		</para>
		<para>
As far as I know, the only implementation of STLS for qmail-pop3d
is Scott's TLS proxy, see the above link.
		</para>
		<para>
The starttls patch requires patching and installing a modified
qmail-smtpd/qmail-remote but no other changes (apart from
configuring certs, etc).  The starttls patch also allows secure
connections from your mailserver to others supporting RFC2487.
		</para>
		<para>
The TLS proxy requires patching and installing a modified
stunnel and changing your run scripts, but doesn't modify the
current qmail install.
		</para>
		<para>
Creating new services can be done with stunnel (http://www.stunnel.org)
or sslwrap (http://www.quiltaholic.com/rickk/sslwrap/).  You can
either configure a daemon to listen on the secure ports (465 and
995 for SSMTP and SPOP3) and forward the traffic to the normal
services, or run a service on the ports that invokes the secure
wrapper inline.  A drawback of the first approach is that connections
appear to be from 127.0.0.1, reducing the usefullness of tcpserver
on the unencrytped port (I'm told there's a work around for this on
Linux machines).
		</para>
		<para>
New services requires configuring stunnel and new run scripts but
no changes to the existing installation.
		</para>
		<para>
An example of stunnel-3 wrapped services can be found in
http://www.ornl.gov/its/archives/mailing-lists/qmail/2003/01/msg01105.html
		</para>
		<para>
Jesse reports success with stunnel-4 wrapped services in
http://www.ornl.gov/its/archives/mailing-lists/qmail/2002/09/msg00238.html
		</para>
		<para>
Finally, let me note that if your users want secure services, they
should using something like PGP/GPG and APOP.
		</para>

		<para>
Brad Taylor <emphasis>btaylor (at) Autotask (dot) com</emphasis> 8 Aug 2005 
		</para>
		<blockquote>
I'm running a web server and Squid in reverse proxy mode and terminating
SSL on the Squid box allowing HTTP to the realserver.  I want to add two
more real servers for a total of 3.  Could I put and LVS into this mix
in front of the Squid server and add IP's to Squid and load balancing
the Squid IP's allowing Squid to continue to terminate SSL?  Traffic
would move like this:
HTTPS -> (LVS) -> HTTPS (1 of 3 Squid IP's) -> HTTP (1 of 3 real
servers).
Or would the SSL traffic at the LVS need to decrypted 1st?
		</blockquote>
		<para>
Joe 2005-08-08
		</para>
		<para>
Whether it's better to have the SSL decryption on the 
realserver or in a separate SSL accelarator isn't clear AFAIK.
It's not like it comes up a lot and we've figured out what to do.
Horms probably has the clearest point on the 
matter which is not to have a separate SSL engine but to 
have each realserver do its own decrypting/encrypting.
		</para>
		<para>
Graeme Fowler <emphasis>graeme (at) graemef (dot) net</emphasis> 08 Aug 2005 
		</para>
		<para>
I've built a similar system at work (can't go into too much detail about
certain parts of it, sadly) but the essence is as follows:
		</para>
<programlisting><![CDATA[
           director + failover director (keepalived/LVS)
                    |
    _________________________________
   |                |                |
squid 1      ... squid 2      ... squid N
   |________________|________________|
   |                |                | 
realserver 1 ... realserver 2 ... realserver N
]]></programlisting>
		<para>
The Squids are acting in reverse proxy mode and I terminate the SSL
connections on them via the frontend LVS, so they're all load balanced.
Behind the scenes is a bit more complicated as certain vhosts are only
present on certain groups of servers within the "cluster" and the Squids
aren't necessarily aware where they might be, so the Squids use a
custom-written redirector to do lookups against an appropriate directory
and redirect their requests accordingly.
		</para>
		<para>
In a position where you have a 1:1 map of squids/realservers you could
in theory park a single server behind a single squid, but that doesn't
give you much scaleability. It does however mean if a webserver fails
then that failure gets cascaded up into the cluster more easily. Then
again, if you're shrewd with your healthchecks you can combine tests for
your SSL IP addresses and take them down if all the webservers fail.
		</para>
		<para>
Also, don't overallocate IP addresses on the Squids. If I say "think TCP
ports", you only need a single IP on your frontend NIC... but I'll leave
you to work that one out!
		</para>
		<para>
Remember that the LVS is effectively just a clever router; it isn't
application-aware at all. That's what L7 kit is for :)
		</para>
		<para>
Horms
		</para>
		<para>
Here is a description I wrote a while ago about SSL/LVS
In a nutshell, you probably want to use persistance
and have the real-servers handle the SSL decryption.
http://archive.linuxvirtualserver.org/html/lvs-users/2003-07/msg00184.html
Actually, using the lblc scheduler, or something similar,
might be another good solution to this problem.
		</para>
		<para>
Graeme
		</para>
		<para>
...this is OK if you have a set of servers onto which you can install 
multiple SSL Certs and undergo the pain of potentially having an IP 
management nightmare:
		</para>
<programlisting><![CDATA[
1 realserver, 1 site -> 1 "cluster" IP
2 realservers, 1 site -> 2 "cluster" IPs
...
10 realservers, 10 sites -> 100 "cluster" IPs
]]></programlisting>
		<para>
I think you can see where this is going! Very rapidly the IP address 
management becomes unwieldy.
		</para>
		<para>
You can of course get around this by assigning different *ports* to 
each site on each server, but if you have the cert installed on all 
servers in the cluster this soon becomes difficult to manage too.
		</para>
		<para>
Offloading onto some sort of SSL "proxy", accelerator, engine (call it 
what you will) means that you can then simply utilise the processing 
power of that (those) system(s) to do the SSL overhead and keep your 
webservers doing just that, serving pages. If each VIP:443 points to a 
different port on the "engine" you greatly simplify your address 
management too.
		</para>
		<para>
Horms
		</para>
		<para>
I do not follow how having traffic that arrives on the
real-servers in plain-text or SSL changes the IP address situation
you describe above.
		</para>
		<para>
Graeme
		</para>
		<para>
Also, most commercial SSL certification authorities will charge you an 
additional fee to deploy a cert on more than one machine, so if you can 
reduce the number of "engine" servers you reduce your costs by quite 
some margin.
		</para>
		<para>
Horms
		</para>
		<para>
This is the sole reason to use an SSL accelerator in my opinion.
The fact is that SSL is likely to be the most expensive ($) operation
your cluster is doing. And that in many cases it is cheaper to 
buy some extra servers, and offload this processing to an
LVS cluster, than to by an SSL accelerator card.
		</para>
		<para>
Graeme
		</para>
		<para>
You do however still need to use persistence, and potentially deploy 
some sort of "pseudo-persistence" in your engines too to ensure that 
they are utilising the same backend server. If you don't, you'll get 
all sorts of application-based session oddness occurring (unless you 
can share session states across the cluster).
		</para>
		<para>
Horms	
		</para>
		<para>
If you have applications that need persistence, then of course
you need persistence regardless of SSL or not. But if you are delivering
SSL to the real servers then you probably want persistence, regardless
of your applications, to allow SessionID to work, and thus lower
the SSL processing cost.
		</para>
		</section>
	</section>
	<section id="lozano">
	<title>SSL termination at localnode: patch by Carlos Lozano, Siim Poder and Malcolm Turnbull</title>
	<note>
		<para>
This code was originally written by Carlos Lozano <xref linkend="carlos_solution"/>. 
Malcolm wanted it ported to the current kernel and offered to pay for the work.
Siim Poder did the recoding.
This patch will be in 2.6.28 (Dec 2008). 
		</para>
		<para>
Malcolm
		</para>
		<para>
I just paid Siim Poder for the work to convert Carlos Lozano's earlier patch to the latest kernel... 
And then luckily Horms thought it was a good idea... 
I think that Kemp and Barracuda did it as well but didn't feed it back to the community.
		</para>
	</note>
	<para>
lists <emphasis>lists (at) loadbalancer (dot) org</emphasis> 01 May 2008
	</para>
	<blockquote>
		<para>
At the moment I can do SSL termination with 
<ulink url="http://www.apsis.ch/pound/">Pound</ulink>
(http://www.apsis.ch/pound/), 
then hand off locally to 
<ulink url="http://haproxy.1wt.eu/">HaProxy</ulink>
(http://haproxy.1wt.eu/) 
for cookie insertion and load balancing:
		</para>
<programlisting><![CDATA[
Pound -> HaProxy -> Real Servers
x.x.x.10:443 -> x.x.x.10:80 -> Real Servers
]]></programlisting>

		<para>
But I'd like to do :
		</para>
<programlisting><![CDATA[
Pound -> LVS -> Real Servers
x.x.x.10:443 -> x.x.x.10:80 -> Real Servers
]]></programlisting>
		<para>
But the Pound process on the director can't access Real servers via the 
local LVS set up at x.x.x.10:80?
Is this the local node problem?
I've tried in NAT and DR mode.
Is their anyway I can get LVS to pick up a local request i.e. wget 
x.x.x.10:80  (from local console) picks up data from a real server?
		</para>
		<para>
I found what I was after in the HOWTO (<xref linkend="carlos_solution"/>)!
		</para>
	</blockquote>
	<para>
Malcolm 17 Dec 2008
	</para>
	<para>
The patch is so that we can have a local server proxy 
<emphasis>e.g.</emphasis> mod_proxy, pound, stunnel, haproxy 
feed into an LVS server pool on the same server (Joe <emphasis>i.e.</emphasis> director).
We use Pound (reverse proxy) to terminate HTTPS traffic and then pass
it to an LVS VIP (masq/NAT) which then distributes to HTTP servers.
This only works in LVS-NAT mode with the load balancer as the default gateway.
	</para>
	<para>
Blog post here:
<ulink url="http://www.loadbalancer.org/blog/lvs-local-node-patch-for-linux-2625-centos-5-kernel-build-how-to/">
LVS Local node patch for Linux 2.6.25, Centos 5 kernel build how-to
</ulink>
(http://www.loadbalancer.org/blog/lvs-local-node-patch-for-linux-2625-centos-5-kernel-build-how-to/)
	</para>
	<note>
Joe: you don't need to do the patch/build. The code is in the kernel.
	</note>
	<para>
Siim Poder <emphasis>siim (at) p6drad-teel (dot) net</emphasis> 18 Dec 2008 
	</para>
	<para>
afaik it doesn't require the director to be the default gw in general (for
any LVS mode), as a director's IP will be the source IP of the packet.
The added functionality is that the director can connect to one of it's
own VIPs and have the connections load balanced to a number of RSs. As
Malcolm already mentioned, the main use case would be having having a
https proxy on the director accepting https using local VIP to LB to http
RSs, instead of LBing https to https RSs (potentially using director
resources more efficiently, in case the traffic is low enough).
	</para>
	<para>
The reason it didn't work (before the patch) is that traditionally ipvs code only tried
to load balance packets that were coming IN to the director (from the
network). This patch adds the possibility to load balance packets that
are leaving the director - that is, packets originating from the
director itself.
	</para>
	<para>
Localnode only comes to play, if you have two directors and a setup that
load balances both incoming and outgoing connections. For only load
balancing the outgoing connections (that is, just one director) you do
not need to have a VIP:443, the https_proxy can just listen on your
"normal every-day" IP.
	</para>
<programlisting><![CDATA[
 CLIENTS
    |
    v
 VIP:443
DIRECTOR1
    |
    |\----------------\
    |                 |
    v                 v
localnode          lvs-dr
    |                 |
    v                 v
DIRECTOR1          DIRECTOR2
https_proxy        https_proxy
    |                 |
    v                 v
 VIP:80             VIP:80
DIRECTOR1           DIRECTOR2
    |                 |
    |                 |
    |\               /|
    | \----\ /------/ |
    |       x         |
    | /----/ \------\ |
    |/               \|
    |                 |
    v                 v
 lvs-dr             lvs-dr
    |                 |
    v                 v
REALSERVER1        REALSERVER2
httpd              httpd
]]></programlisting>
	<para>
The part that was not previously possible, is the https_proxy connecting
to VIP:80 on the DIRECTOR1 itself and having the connections load
balanced between RS1 and RS2.
	</para>
	<para>
There is nothing special to the setup. 
You just have to connect to one of the
VIPs from the director. Before the patch, the connection would get reset,
but after patch, it is load balanced to whatever real servers behind the
VIP.
	</para>
	<para>
Something like this:
	</para>
<programlisting><![CDATA[
ipvsadm -A -t 192.168.0.1:80 -s rr
ipvsadm -a -t 192.168.0.1:80 -r 192.168.1.2:80 -m
ipvsadm -a -t 192.168.0.1:80 -r 192.168.1.3:80 -m

nc 192.168.0.1:80	#after setup, run netcat to VIP:80
]]></programlisting>
	<para>
For unpatched kernels, you would get connection refused, 
for patched ones you get connected to either to 1.2:80 or 1.3:80.
	</para>
	</section>
	<section id="rshd">
	<title>r commands; rsh, rcpi (and their ssh replacements), tcp 514</title>
	<para>
The r commands use multiport protocols. see <xref linkend="rshd_multiport"/>.
	</para>
	</section>
	<section id="lpd"><title>lpd, tcp 515</title><para>
			</para><para>
Network printers have a functioning tcpip stack and can be used as realservers
in an LVS-NAT setup to produce a print farm.
I got the idea for this at Disneyworld in Florida.
At the end of one of the roller coaster rides
(Splash Mountain) cameras take your photo and if you buy your photo,
it is printed out on one of about 6 colour printers.
I watched the people collecting the print-outs -
they didn't seem to know which printer
the output was going to and looked at all of them looking for your print.
The same thing would happen with an LVS-NAT printer farm,
since you can't pick the realserver that will get the job.
			</para><para>
Using LVS-NAT with lpd is written up in
<ulink url="http://www.linuxvirtualserver.org/Joseph.Mack/performance/single_realserver_performance.html#lpd">
section 5.3 of the article on performance of single realserver LVSs</ulink>.
	</para>
	</section>
	<section id="databases">
	<title>Databases</title>
	<para>
Because of the large cost of distributed or parallel database servers,
people have looked at using LVS with mysql or postgres.
	</para>
	<para>
A read-only LVS of databases is simple to setup;
you only need some mechanism to update the database (on all of the realservers) periodically.
A read-write LVS of databases is more difficult,
as the write to the database on one realserver has to be propagated
to the databases on the other realservers.
A read-mostly database (like a shopping cart), 
can be loadbalanced by LVS with the updates occuring outside the LVS. 
However a full read-write LVS database is not feasible at the moment.
	</para>
	<para>
Moving data around between realservers is external to LVS.
If clients are writing, you need to do something
at the back end to propagate the writes to the other nodes on
a time scale which is atomic compared to the time of reads by other users.
If you have a shopping cart, then other user's don't need to know about the a particular
user's writes, till they commit to ordering the item (decrementing the stock),
so you have some time to propagate the writes.
	</para>
	<para>
Currently most LVS databased are deployed in a multi-tier setup.
The client connects to a web-server, 
which in turn is a client for the database;
this web-server database client then connects to a
<emphasis role="bold">single</emphasis> databased.
In this arrangement the LVS should balance the webservers/database
clients and not balance the database directly.
	</para>
	<para>
Production LVS databases, <emphasis>e.g.</emphasis>
the service implemented by
Ryan Hulsker <emphasis>RHulsker (at) ServiceIntelligence (dot) com</emphasis> (sample load
data at http://www.secretshopnet.com/mrtg/) have the LVS users
connect to database clients (perl scripts running under a webpage)
on each realserver. These database clients connect to a
single databased running on a backend machine that the LVS
user can't directly access. The databased isn't being LVS'ed -
instead the user connects to LVS'ed database clients on the
realserver(s) which handle intermediate dataprocessing,
increasing your throughput.
	</para>
	<para>
Next, replication was added to mysqld
and updates to one database could be propagated to another. 
Rather than using peer-to-peer replication, LVS users
setup replication in a star, with a master that accepted the writes,
which were propagated to slave databases on the realservers.
Then mysqld acquired functionality similar to loadbalancing
removing any need to develope LVS for loadbalancing a database
(<emphasis>e.g.</emphasis> - from Ricardo Kleeman 4 Aug 2006 -  
multi-master replication, 
which means you can have 2 servers as master and slave... 
so in that sense a pair should be usable for load balancing).
(also see 
<ulink url="http://www.howtoforge.com/loadbalanced_mysql_cluster_debian">
loadbalanced mysql cluster</ulink>)
Some of the earlier comments about mysqld below may no longer be
relevant to current versions of mysqld.
	</para>
	<para>
Malcolm Turnbull <emphasis>malcolm (at) loadbalancer (dot) org</emphasis> 10 Dec 2008
	</para>
	<para>
Load balancing SQL server is no problem with LVS but just like every
other database pretty difficult to get your application to work with
it unless its a read only copy.
Normal configuration is a shared storage twin-head write cluster +
load balanced read-only clusters.
	</para>
		<section id="multiple_writer_common_filesystem">
		<title>Multiple Writer, Common Filesystem</title>
		<note>
summary: this doesn't work
		</note>
		<para>
An alternative to propagating updates to databases is to use a 
distibuted filesystem, which then becomes responsible for the updates appearing
on other machines.
(see <link linkend="many_reader_single_writer">Filesystems for realserver content</link>
and <link linkend="synchronising_content">Synchronising realserver content</link>).
While this may work for a webserver, a databased is not happy about having
agents outside its control writing to its data filesystem.
		</para>
		<para>
A similar early naive approach approach of having databaseds on each realserver
accessing a common filesystem on a back-end server, fails.
Tests with mysqld running on each of two realservers working off
the same database files mounted from a backend machine, showed that
reads were OK, but writes from any realserver either weren't seen
by the other mysqld or corrupted the database files. Presumably
each mysqld thinks it owns the database files and keeps copies
of locks and pointers. If another mysqld is updating the filesystem
at the same time then these first set of locks and pointers are invalid.
Presumably any setup in which multiple (unlocked) databaseds were writing
to one file system (whether NFS'ed, GFS'ed, coda, intermezzo...)
would fail for the same reason.
		</para>
		<para>
In an early attempt to setup this sort of LVS
jake buchholz <emphasis>jake (at) execpc (dot) com</emphasis> setup an LVS'ed mysql
database with a webinterface. LVS was to serve http
and each realserver to connect to the mysqld running
on itself. Jake wanted the mysql service to be lvs'ed as
well and for each realserver to be a mysql client. The solution
was to have 2 VIPs on the director, one for http and the other
for mysqld. Each http realserver makes a mysql request to the
myqslVIP. In this case no realserver is allowed to have both
a mysqld and an httpd. A single copy of the database is nfs'ed from a
fileserver. This works for reads.
		</para>
		</section>
		<section id="parallel_databases">
		<title>Parallel Databases</title>
		<para>
Malcolm Cowe
		</para>
		<blockquote>
What if the realservers were also configured to be part of an HA
cluster like SGI Failsafe or MC/ServiceGuard (from HP)? Put the real
servers into a highly available configuration (probably with shared
storage), then use the director to load balance connections to the
virtual IP addresses of the HA cluster. Then you have a system that
parallelises the database and load balances the connections. This might
require ORACLE Open Parallel Server (OPS) edition of the database, you'd
have to check.
		</blockquote>
		<para>
"John P. Looney" <emphasis>john (at) antefacto (dot) com</emphasis> 12 Apr 2002
		</para>
		<para>
My previous employer did try such a system, and had very little luck with
it. In general, you are much better off having one writer, and multiple
readers. Then, update the "read-only" databases from the write-database.
We were using Oracle Parallel Server on HP-UX, and it crashed about once
every two weeks, not always just under heavy load. Databases are by design
single entities. Trying to find a technical solution to such a
mathematical problem is asking for pain and suffering, over a prolonged
period of time.
		</para>
		</section>
		<section id="lsd_project">
		<title>Linux Scalable Database project</title>
		<para>
			<note>
May 2001: 
The LSD project does not seem to be active anymore.
The <link linkend="replication">replication feature of mysql</link>
is functionally equivelant.
			</note>
The Linux Scalable Database (LSD) project
http://lsdproject.sourceforge.net/
is working on code to serialise client writes so that they can be written to all
realservers by an intermediate agent. Their code is experimental
at the moment, but is a good prospect in the long term for
setting up multiple databased and file systems on separate
realservers.
		</para>
		</section>
		<section id="another_mysql">
		<title>Gaston's Apache/mysql setup</title>
		<para>
Gaston <emphasis>Gorosterrazgoro (at) hostarg (dot) com (dot) ar</emphasis>
Jun 12 2003
		</para>
		<para>
I solved my problems quite
different than seen in the HOW-TO. So, someone may need this email in the
near future:
		</para>
<programlisting><![CDATA[
-------------------------------------------------------------------------
    Director
        192.168.0.23 (eth1)
        192.168.0.24 (eth0:100)
        10.0.0.1 (eth0)
        Just configured ip_vs to load balance Apache between Server3 and
Server1 (in this order because for me, Server3 is the primary apache server)
-------------------------------------------------------------------------
    Server1 (primary MySQL, secondary Apache)
        10.0.0.3 (eth0)
        10.0.0.10 (eth0:100)
        MySQL is Master/slave for Server3

-------------------------------------------------------------------------
    Server2 (secordary MySQL)
        10.0.0.4 (eth0)
        Mon running, checking every 10 secs. MySQL in 10.0.0.3. If it fails,
then this machine configures eth0:100 as 10.0.0.10.
        MySQL is Master/slave for Server1
-------------------------------------------------------------------------
    Server3 (primary Apache)
        10.0.0.5
        Apache (in my case php), connects always to 10.0.0.10.
-------------------------------------------------------------------------
]]></programlisting>
		<para>
    End of story. I have better security in the MySQL daemons (not accesible
from clients), less charge in the director machine (don't have to worry
about MySQL, neither run MON yet),  and I'm happy. :) Now is the turn for
Cyrus in Server2 and Server3.
		</para>
		</section>
	</section>
	<section id="mysql" xreflabel="mysql">
	<title>Databases: mysql</title>
		<section id="mysql_cluster_debian">
		<title>How To Set Up A Load-Balanced MySQL Cluster</title>
		<para>
There is a writeup (Mar 2006) at 
<ulink url="http://www.howtoforge.com/loadbalanced_mysql_cluster_debian">
http://www.howtoforge.com/loadbalanced_mysql_cluster_debian</ulink> 
by Falko Timme based on UltraMonkey.
(we don't know this guy and he's never posted to the LVS mailing list 
- he seems to know what he's doing though.)
		</para>
		</section>
		<section id="replication">
		<title>mysql replication</title>
		<para>
<ulink url="http://www.mysql.com">MySQL</ulink>
(and most other databases) supports replication of databases.
		</para>
		<para>
Ted Pavlic <emphasis>tpavlic (at) netwalk (dot) com</emphasis> 23 Mar 2001
		</para>
		<blockquote>
			<para>
When used with LVS, a replicated database is still a single database.
The MySQL service is not load balanced. HOWEVER, it is possible to put some of
your databases on one server and others on another. Replicate each SET of
databases to the OTHER server and only access them from the other server
when needed (at an application or at some fail-over level).
			</para>
		</blockquote>
		<para>
Doug Sisk <emphasis>sisk (at) coolpagehosting (dot) com</emphasis> 9 May 2001
		</para>
		<blockquote>
An <ulink url="http://www.phpbuilder.com/columns/tanoviceanu20000912.php3">
article on mysql's built in replication facility</ulink>
		</blockquote>
		<para>
Michael McConnell <emphasis>michaelm (at) eyeball (dot) com</emphasis>> 13 Sep 2001
		</para>
		<blockquote>
		<para>
Can anyone see a down side or a reason why one could not have two
Systems in a Failover Relationship running MySQL.
The Database file would be synchronized between
the two systems via a crontab and rsync.
Can anyone see a reason why rsync would not work?
I've on many occasions copied the entire mysql data
directory to another system and start it up without a problem.
I recognize that there are potential problems that the rsync might take place
while the master is writing and the sync will only have part of a table,
but mysql's new table structure is supposed to account for this.
If anything, a quick <command>myismfix</command> should resolve these problems.
		</para>
		</blockquote>
		<para>
Michael McConnel <emphasis>michaelm (at) eyeball (dot) com</emphasis> 2001-09-14
		</para>
		<para>
There are many fundamental problems with MySQL Replication.
MySQL's Replication requires that two systems be setup with identical data
sources, activate in a master/slave relationship. If the Master fails all
requests can be directed to the Slave. Unfortunately this Slave does not
have a Slave, and the only way to give it a slave, is to turn it off,
synchronize it's data with another system and then Activate them in a
Master/Slave relationship, resulting in serious downtime when databases are in
excess of 6 gigs (-:
		</para>
		<para>
This is the most important problem, but there are many many more, and I
suggest people take a serious look at other options. Currently I use a
method of syncing 3 systems using BinLog's.
		</para>
		<para>
Paul Baker <emphasis>pbaker (at) where2getit (dot) com</emphasis>>
		</para>
		<blockquote>
			<para>
What is the downtime when you have to run <command>myisamchk</command>
against the 6 gig
database because rsync ran at exactly the same time as mysql was
writting to the database files and now your sync'd image is corrupted?
			</para>
			<para>
There is no reason you can not set up the slave as a master in advance from the
beginning. You just use the same database image as from the original master.
			</para>
			<para>
When the master master goes down, set up a new slave by simple copying
the original master image over to the new slave, then point it to the
old slave that was already setup to be a master. You wouldn't need to
take the original slave down at all to bring up a new one. You would
essentially be setting up a replication chain but only with the first 2
links active.
			</para>
		</blockquote>
		<para>
Michael McConnell <emphasis>michaelm (at) eyeball (dot) com</emphasis>>
		</para>
		<para>
In the configuration I described using <command>Rsync</command>,
the <command>MyISMchk</command> would take place
on the slave system, I recognize the time involved would be very large, but
this is only the slave. This configuration would be setup so an Rsync
between the master and slave takes place every 2 hours, and then the Slave
would execute a MyISMchk to ensure the data is ready for action.
		</para>
		<para>
I recognize that approximately 2 hours worth of data could be lost, but I
would probably us the MySQL BinLogs rotated at 15 minutes interval and
stored on the slave to allow this to be manually merged in, and keep the
data loss time down to only 15 minutes.
		</para>
		<para>
Paul, you said that I could simply copy the Data from the Slave to a new
Slave, but you must keep in mind, in order to do this MySQL requires that
the Master and Slave data files be IDENTICAL, that means the Master must be
turned off, the data copied to the slave, and then both systems activated.
Resulting in serious downtime.
		</para>
		<para>
Paul
		</para>
		<blockquote>
			<para>
You only have to make a copy of the data one time when you initial set
up your Master the first time. As long as it takes to do this is your
downtime:
			</para>
<programlisting><![CDATA[
   kill mysqlpid
   tar cvf mysql-snapshot.tar /path/to/mysql/datadir
   /path/to/mysql/bin/safe_mysqld
]]></programlisting>
			<para>
Your down time is essentially only how long it takes to copy your 6 gigs
of data NOT across a network, but just on the same machine. (which is
far less than a myisamchk on the same data) Once that is done, at your
leisure you can copy the 6 gigs to the slave while the master is still
up and serving requests.
			</para>
			<para>
You can then continue to make slave after slave after slave just by
copying the original snap shot to each one. The master never has to be
taking offline again.
			</para>
		</blockquote>
		<para>
Michael McConnell
		</para>
		<para>
You explained that I can kill the MySQL on the Master, tar it up, copy the
data to the Slave and activate it as the Slave. Unfortunately this is not
how MySQL works. MySQL requires that the Master and Slave be identical data
files, *IDENTICAL* that means the Master (tar file) cannot change before the
Slave comes online.
		</para>
		<para>
Paul
		</para>
		<blockquote>
			<para>
Well I suppose there was an extra step that I left out (because it
doesn't affect the amount of downtime). The complete migration steps
would be:
			</para>
			<orderedlist>
				<listitem>
Modify <filename>my.cnf</filename> file to turn on replication of the master server. This
is done while the master mysql daemon is still running with the previous
config in memory.
				</listitem>
				<listitem>
			shutdown the mysql daemon via kill.
				</listitem>
				<listitem>
		tar up the data.
				</listitem>
				<listitem>
start up the mysql daemon. This will activate replication on the
master and cause it to start logging all changes for replication since
the time of the snapshot in step 3.
At this point downtime is only as long as it takes you to do steps 2, 3,
and 4.
				</listitem>
				<listitem>
copy the snapshot to a slave server and active replication in the
my.cnf on the slave server as both a master and a slave.
				</listitem>
				<listitem>
start up the slave daemon. at this time the slave will connect to the
master and catch up to any of the changes that took place since the
snapshot.
				</listitem>
			</orderedlist>
			<para>
So as you see, the data can change on the master before the slave comes
online. The data just can't change between when you make the snapshot
and when the master daemon comes up configured for replication as a master.
			</para>
		</blockquote>
		<para>
Michael McConnell
		</para>
		<para>
Paul you are correct.
I've just done this experiment.
		</para>
<programlisting><![CDATA[
A(master) -> B(slave)
B(master -> C(slave)
]]></programlisting>
		<para>
A Died. Turn off C's Database, tar it up, replicated the Data to A,
Activate A as Slave to C. No data loss, and 0 downtime.
		</para>
		<para>
(there appears to have been an offline exchange in here.)
		</para>
		<para>
Michael McConnell <emphasis>michaelm (at) eyeball (dot) com</emphasis>>
		</para>
		<para>
I've just completed the Rsync deployment method, this works very well. I
find this method vastly superiors to both other methods we discussed.
Using Rsync allows me to only use 2 HOSTS and I can still provide 100%
uptime. In the other method I need 3 systems to provide 100% uptime.
		</para>
		<para>
In addition the Rsync method is far easier to maintain and setup.
		</para>
		<para>
I do recognize this is not *perfect* I run the Rsync every 20 minutes, and
then I run myismchk on the slave system immediately afterwards. I run the
MyISMChk to only scan Tables that have changed since the last check. Not all
my tables change every 20 minutes. I will be timing operations and lowering
this Rsync down to approximately 12 minutes. This method works very
effectively for managing a 6 Gig Database that is changing approximately 400
megs of data a day.
		</para>
		<para>
Keep in mind, there are no *real time* replication methods available for
MySQL. Running with MySQL's building Replication commonly results (at least
with a 6 gig / 400 megs changing) in as much as 1 hour of data
inconsistency. The only way to get true real time is to use a shared storage
array.
		</para>
		<para>
Paul Baker
		</para>
		<blockquote>
			<para>
MySQL builtin replication is supposed to be "realtime" AFAIK. It should
only fall behind when the slave is doing selects against a database that
causes changes to wait until the selects are complete. Unless you have a
select that is taking an hour, there is no reason it should fall that
far behind. Have you discussed your findings with the MySQL developers?
			</para>
		</blockquote>
		<para>
Michael McConnell
		</para>
		<para>
I do not see MySQL making any claims to Real-time. There are many situations
where a high load will result in systems getting backed up, especially if
your Slave system performs other operations.
		</para>
		<para>
MySQL's built-in replication functions like so;
		</para>
		<orderedlist>
			<listitem>
Master writes updates to Binary Log
			</listitem>
			<listitem>
Slave checks for Binary Updates
			</listitem>
			<listitem>
Slave Downloads new Bin Updates / Installs
			</listitem>
		</orderedlist>
		<para>
Alexander N. Spitzer<emphasis>aspitzer (at) 3plex (dot) com</emphasis>
		</para>
		<blockquote>
how often are you running rsync? since this is not realtime replication,
you run the risk of losing information if the master dies before the rsync
has run (and new data has been added since the last rsync.)
		</blockquote>
		<para>
Don Hinshaw <emphasis>dwh (at) openrecording (dot) com</emphasis>>
		</para>
		<para>
I have one client where we do this. At this moment ( I just checked) their
database is 279 megs. An rsync from one box to another across a local 100mbit
connections takes 7-10 seconds if we run it at 15 minute intervals. If we run
it at 5 minute intervals it takes &lt;3 seconds. If we run it too often, we get
an error of "unexpected EOF in read_timeout".
		</para>
		<para>
I don't know what causes that error, and they are very happy with the current
situation, so I haven't spent any time to find out why. I assume it has
something to do with write caching or filesystem syncing, but that's just a
wild guess with nothing to back it up. For all I know, it could be ssh related.
		</para>
		<para>
We also do an rsync of their http content and httpd logs, which total
approximately 30 gigs. We run this sync hourly, and it takes about 20 minutes.
		</para>

		<para>
Benjamin Lee <emphasis>benjaminlee (at) consultant (dot) com</emphasis>>
		</para>
		<para>
For what it's worth, I have also been witness to the EOF error. I have
also fingered ssh as the culprit.
		</para>
		<para>
John Cronin
		</para>
		<blockquote>
What kind of CPU load are you seeing? rsync is more CPU intensive than
most other replication methods, which is how it gains its bandwidth
efficiency. CPU Load?
How many files are you syncing up - a whole filesystem, or just a few
key files?  From you answer, I assume you are not seeing a significant
CPU load.
		</blockquote>
		<para>
Michael McConnell
		</para>
		<para>
I RSync 6 Gigs worth of data, Approximately 50 files (tables). Calculating
Checksum's is really a very simple calculation, the cpu used to do this is
less than 0% - 1% of a PIII 866. (care of vmstat)
		</para>
		<para>
I believe all of these articles you have found are related to RSync Servers
that serve in the function one would see a system as a major FTP Server. For
example ftp.linuxberg.org or ftp.cdrom.com
		</para>
		<para>
Mark
		</para>
		<blockquote>
We're using master/slave replication. The LVS balances the reads
from the slaves and the master isn't in the load-balancing pool at
all. The app knows that writes go to the master and reads go the
VIP for the slaves. Aside from replication latency, this works very
reliably.
		</blockquote>
		<para>
Todd Lyons <emphasis>tlyons (at) ivenue (dot) com</emphasis> 26 Oct 2005
		</para>
		<para>
This works for us too.  We have an inhouse DBI wrapper that knows to
read from slaves and write to the master.  Reads are directed to a
master for a certain number of seconds until we are reasonably sure that
the data has been replicated out.
		</para>
		<blockquote>
this is exactly how i was doing it.
The problem was that i expected the data on the slaves to be realtime
- and the replication moved too slow. not to mention it broke 
a lot (not sure why) - anytime there was a query that failed 
it halted replication.
		</blockquote>
		<para>
We've not seen this.  Our replication has been very stable, and our
system is roughly 80% read, 20% write.  But we do as few reads as
possible on the master, keeping all of the reads on the slaves, doing
writes to the master.
		</para>
		<blockquote>
in which case, i had to either take the master down, or put 
it in read-only mode, so i could copy the database over, and 
re-initialize replication.
		</blockquote>
		<para>
Make a tarball of the databases that you replicate and keep that tarball
someplace available for all slaves.  Record the replication point and
filename.  Then when you have to restart a slave, blow away the db,
extract the tarball, configure the info file to the correct data, then
start mysql and it will populate itself from the bin files on the
master.  For us, we try to do it once per month, but I've seen 100 day
bin file processing and it only took about 30 minutes to catch the
database up.  We have gig networking though, so your results may vary.
		</para>
		<para>
We also have a script that connects and checks the replication status
for each slave and spits out email warnings if the bin logs don't match.
It doesn't check position because it frequently changes mid-script,
sometimes more than once.  Here's an example:
		</para>
<programlisting><![CDATA[
[todd@tlyons ~]$ checkmysqlslave.sh 
Status Check of MySQL slave replication.
Log file names should match exactly, and
log positions should be relatively close.

Machine      : sql51
Log File     : fs51-bin.395
Log Position : 18123717

Machine      : sql52
Log File     : fs51-bin.395
Log Position : 18123863

Machine      : images3
Log File     : fs51-bin.395
Log Position : 18123863

Machine      : images4
Log File     : fs51-bin.395
Log Position : 18124769

Machine      : images5
Log File     : fs51-bin.395
Log Position : 18125333

Machine      : images6
Log File     : fs51-bin.395
Log Position : 18125333
]]></programlisting>
		<blockquote>
of course, this was on sub-par equipment, and maybe nowadays 
it runs better. i'm thinking that the NDBcluster solution 
might be better since it's designed for this more - 
replication still (afaik) sucks because when you need to 
re-sync it requires the server to be down or put in 
read-only, which is essentially downtime.
The main problem I see with NDB is that it requires the entire database
(or whatever part each node is reponsible for) to be in memory. 
		</blockquote>
		<para>
We have had very stable results from mysql stable releases doing
replication.  We typically use the mysql built rpms instead of the
vendor rpms.  We had serious stability problems with NDB, but we were
also trying a very early version.  It is liable to be much more solid
now.
		</para>
		<blockquote>
not work with files the way normal InnoDB, MyIsam, etc engines work.
And I think this is still the case in MySQL 5 (correct me if I'm
wrong.) I don't know what happens if your storage node suddenly runs
out of Memory.
		</blockquote>
		<para>
It won't be until MySQL 5.1 that you'll be able do file based
clustering.  Then load balancing becomes simple, for both reads and
writes.
		</para>
		<para>
Dan Yocum <emphasis>yocum (at) fnal (dot) gov</emphasis> 10 Dec 2008 
		</para>
		<para>
While not strictly on topic wrt to LVS, with MySQL one can use 
multi-master, shared-nothing replication or MySQL clustering (yes, these 
are 2 separate methods for replicating data), with all nodes having read 
and write access.  I have implemented the former with LVS load balancing 
the connections to the MySQL RSs with good success.  I used these guides 
to set this up:
http://www.howtoforge.com/mysql_database_replication
http://www.howtoforge.com/loadbalanced_mysql_cluster_debian
And I wrote up the whole procedure for our (grid) authentication and 
authorization environment:
https://docs.google.com/View?docID=ddszv68g_19d88pzv&amp;revision=_latest
		</para>
		</section>
		<section id="clustering_mysql">
		<title>Clustering mysql</title>
		<para>
Matthias Mosimann <emphasis>matthias_mosimann (at) gmx (dot) net</emphasis> 2005/03/01
		</para>
		<para>
I also don't have experience with any of these solutions but...
		</para>
		<itemizedlist>
			<listitem>
MySQL's solutions to make a mysql cluster are at 
<ulink url="http://www.mysql.com/products/cluster/">MySQL cluster</ulink>
(http://www.mysql.com/products/cluster/).
			</listitem>
			<listitem>
The book "High Performance MySQL Cluster" is available from O'Reilly.
			</listitem>
			<listitem>
For people using PHP with a MySQL cluster see
<ulink url="http://sqlrelay.sourceforge.net/">SQL relay</ulink>
(http://sqlrelay.sourceforge.net/).
			</listitem>
			<listitem>
If you're using a java application maybe this page could help you:
<ulink url="http://c-jdbc.objectweb.org/">ObjectWeb: Clustered JDBC</ulink>
(http://c-jdbc.objectweb.org/)
			</listitem>
		</itemizedlist>
		<para>
Jan Klopper <emphasis>janklopper (at) gmail (dot) com</emphasis> 2005/03/02
		</para>
		<para>
Your best method (if you only do a lot of Select query's) would be to use 
one mysql master server which gets all the update/delete/insert query's 
and stores the main database,.
Then you could use mysql master-slave setup to replicate this master 
database to a couple of slave servers on which you could do all of your 
selects.
		</para>
		<para>
You could use Mon/ldirectord to make a LVS cluster out of these select 
servers just like any other type of servers.
I'm not sure what you should do with the persistence though (especially 
if you use mysql_pconnect from within php/apache).
		</para>
		<para>
I have the following setup:
		</para>
		<itemizedlist>
			<listitem>
cheap webservers (LVS)
			</listitem>
			<listitem>
cheap load balancers (VIP)
			</listitem>
			<listitem>
expensive raid 10 mysql server (master)
			</listitem>
			<listitem>
cheap fileserver + mysql slave (just for backup, not for queries)
			</listitem>
		</itemizedlist>
		<para>
Granted, if your database server dies, you're screwed, but with the 
current mysql master/slave/replication/cluster technologies you wouldn't 
be able to provide failover for update/insert/delete query's anyway.
		</para>
		<note>
making one of the slaves into a master and thus change its database 
will give you a serious problem when you master comes back up again. 
You'd have to make the master a slave, stop the current master 
(breaking the whole point of allways online) and replicate to it, then 
when it is up2date change its role to be master again.
		</note>
		<para>
Jan Klopper 
		</para>
		<para>
So you can setup a mysql 
server on each of the nodes of you cluster (allowing all of the nodes to 
be load balanced mysql servers)
		</para>
		<para>
What would be a better sollution (afaik) is to place mysql on all the 
apache servers as well, since this would would allow them to connect to 
their own database instead of using a network connect, decreasing the 
overhead for each query/connect.
And if one of the webserver nodes went down, so does its mysql, so thats 
not a real problem. 
LVS will just not redirect any request to the machine at all.
A not clustered server would then be the nbdd server managing and 
updating all of the mysql servers on the nodes itself.
And thus you could use really inexpensie hardware for the mysql server, 
as you won't need UBER speed on that machine to handle all requests from 
all LVS-nodes anymore.
		</para>
		<para>
Todd Lyons <emphasis>tlyons (at) ivenue (dot) com</emphasis> 
		</para>
		<para>
We've always found that separating services out to different machines
works better than running multiple services on each machine. 
		</para>
		<para>
Francois JEANMOUGIN <emphasis>Francois (dot) JEANMOUGIN (at) 123multimedia (dot) com</emphasis> 
(replying to Jan)
		</para>
		<para>
Well you still need a very powerfull nbdd server, 
with high network capabilities,
and you should use at least two data nodes.
		</para>
		<para>
Matthias Mosimann 
		</para>
		<para>
Here's a thread in
the mysql mailing list about clustering / loadbalancing mysql
http://forums.mysql.com/read.php?25,14754,14754#msg-14754
		</para>
		<para>
Francois JEANMOUGIN 
		</para>
		<para>
The idea is to have small MySQL nodes on the
realservers and 2 or 3 data nodes (powerfull machines) on the backend.
The current state of the artr for MySQL is to use an NBD cluster. You can use
LVS to load-balance connections to your MySQL servers. You need a small
management server to manage it.
		</para>
		<para>
Todd Lyons <emphasis>tlyons (at) ivenue (dot) com</emphasis> 2005/03/02
		</para>
		<para>
We worked for a short while with NBD clustering and experienced huge problems.  
It was probably more an issue with perl-DBD instead of NBD itself, 
but it was enough that we had to go back to standard replication.
Our current setup uses a homegrown DBI wrapper that does all reads from
the slave and directs all writes to the master (and for a short time
all reads in that session go to that master too).  As read load
escalates, just add another slave and put it on an LVS VIP.
		</para>
		<para>
Francois JEANMOUGIN 
		</para>
		<para>
To check whether a MySQL server is alive or not, you have two
solutions (assuming you choose Keepalived):
		</para>
		<itemizedlist>
			<listitem>
Use a TCP_CHECK that will detect if the server accepts connections.
			</listitem>
			<listitem>
Use the check_mysql from nagios-plugins embedded in a MISC_CHECK script.
			</listitem>
		</itemizedlist>
		<para>
Jan Klopper 
		</para>
		<para>
But as soon as you start doing updates to the database, you will horribly 
screw up your data, because mysql can't propagate the changes made on 
slaves back to the master and so on.
This will lead to inconsistency's in your database.
If you only need to do load (and I mean loads) of select queries with no 
changes than you could very well use mysql slaves inside a LVS to run 
these queries. 
		</para>
		<blockquote>
			<para>
Francois JEANMOUGIN 
			</para>
			<para>
Are we talking about the same thing? I'm not talking about master/slave or
active-slave method using old MySQL replication process. I'm talking about
NBD cluster: http://dev.mysql.com/tech-resources/articles/mysql-cluster-for-two-servers.html, 
http://dev.mysql.com/doc/mysql/en/mysql-cluster-basics.html
I'm currently evaluating this solution, which as passed the "case study"
test. I will implement it at the end of this month. I would like to know if
anyone here have any (bad or good) experience with such MySQL setup.
			</para>
		</blockquote>
		<para>
Todd Lyons <emphasis>tlyons (at) ivenue (dot) com</emphasis> 
		</para>
		<para>
We've had experience and it was bad.  
Things like 'DESCRIBE table' would give erratic results.
Required a beta version of perl-DBD.
Performance was good though.  
We had a 2 node cluster with plans to scale upwards.  
I think once supporting code stabilizes it will be a good solution.  
I like the way they keep things in memory because RAM is cheap.
We are also evaluating the true clustering solution provided by Emic Networks.  
It is fantastic in my opinion, but it's not cheap.  
It requires custom configuration of your switches and routers to handle multicast MACs, 
a virtual gateway, and some VLAN'ing.  
It works well though and scales well.  
If your system has more than 50% reads, it will work well for you.
		</para>
		<para>
Jan Klopper (replying to Francois) 
		</para>
		<para>
You are talking about pure failover only right?
I was talking about load balancing for mysql which is pretty much undoable.
Pure failover might be possible, just make sure the slave becomes the 
master on failover, and when the old master get back up it starts being 
a slave, and replicates from the new master.
		</para>
		<para>
Francois
		</para>
		<blockquote>
			<para>
No no no.
Please read the links I sent, and add this one :
http://dev.mysql.com/doc/mysql/en/mysql-cluster-overview.html
I'm talking about pure active-active cluster. This setup could be strenghted
by LVS and a Keepalived MISC checker. In the figure above, you put LVS
between Applications and SQL. About the link above, note that mysqld server
and nbdd server can be on the same machine.
			</para>
		</blockquote>
		<para>
Jan Klopper 
		</para>
		<para>
Even normal master-slave replication still gives loads of problems, so 
anything cutting edge which might do the trick and allow for the slaves 
to be full database servers (and thus capable of handling 
updates/inserts/deletes) should not be trusted in my opinion.
Granted, if they get the slaves to also be masters to each other, and 
they get it to pay nice, then we're all set to have the best and 
fastest clustering database on the planet (except for oracle?).
		</para>
		<para>
Bosco Lau <emphasis>bosco (at) musehub (dot) com</emphasis> 
		</para>	
		<para>		
Lets forget about 'multi'-master scenario. 
It is basically an unsolvable problem for MySQL (at the moment).
The only sensible multi-server setup for MySQL is 'single master' - 
'mutiple slave', preferbly in 'star shape formation' i.e. each slave 
connected directly to master. Also don't bother about 'daisy-chaining' 
the slaves, this creates a single point of failure.
With the mutiple slaves/LVS setup , you can just use MYISAM tables 
in the slaves database whereas you may have innoDB tables in the master. 
This will make your SELECT performances even better. Since the slaves 
just replicates the data from the master, there is no need for 
transactional tables type in the slave database.
		</para>
		<para>
Jan Klopper  
		</para>	
		<para>
Multi-master setups are a huge problem in mysql.
If you do use slaves for just the queries, use <filename>MyIsam</filename> tables 
(preferrable stored completely in memmory) to increase select speeds.
I'm using mysql to run huge banner/advertisement systems, and thus i need 
at least one update/insert per view. or i should store them outside of 
the db, and thus i can;t use normal slaves. (because i'd still need to 
connect to the master to make the update.)
Star formation is the way to go, unless you have a huge amount of 
changes on the master which make you need a seccond cascade in there to 
load balance the updates and release the master from most of the slave 
replication querys.
I think this step could also be done with LVS (having a couple of 
slave's to retreive the updates from one master, balanced by LVS, ) and 
then use them as masters for a couple of other normal query slaves.
		</para>
		<para>
Matthias Mosimann <emphasis>matthias_mosimann (at) gmx (dot) net</emphasis> 2005/04/18
		</para>
		<para>
In a mysql cluster, data is stored in memory.
If you store about 100 GB
in your databaes you need about 100 GB of Memory (ram + swap). 
Now it looks that there will be a solution for that. 
I found a thread in the myslq-cluster mailing list and a link in the manual. 
Mysql 5.1 will be able to handle disk-based records in the cluster.
		</para>
<programlisting><![CDATA[
Thread:
http://forums.mysql.com/read.php?25,20801,20801#msg-20801

Link:
http://dev.mysql.com/doc/mysql/en/mysql-5-1-cluster-roadmap.html
]]></programlisting>

		<para>
Nigel Hamilton <emphasis>nigel (at) turbo10 (dot) com</emphasis> 2005/04/18
		</para>
		<para>
The RAM requirements of the initial MySQL Cluster design makes 
it unworkable for me so a hybrid RAM + disk-based system is welcome news.
Our writes may equal or 
exceed reads - I was planning on using "memcached" to help with handing 
off as many reads as possible to a distributed RAM bucket. But I'm still 
thinking of ways to distribute writes - ideally at the application level 
all I need is a database handle that connects to one big high speed 
amorphous distributed DB.
My current short term solution to distributing writes is to use a MySQL 
heap/ram table on each node which acts as a bucket collecting writes which 
is periodically emptied to the Master's disk.
		</para>
		<para>
Matthias Mosimann <emphasis>matthias_mosimann (at) gmx (dot) net</emphasis> 
		</para>
		<para>
IIRC we had a discussion (Jan Klopper, Francois Jeanmougin and me) on the
2nd March this year on the same topic allready. Here's the link:
http://archive.linuxvirtualserver.org/html/lvs-users/2005-03/mail4.html
		</para>
		<para>
Francoise Jeanmougin
		</para>
		<para>
We made some other testing on high availabilty/high performance MySQL:
		</para>
		<itemizedlist>
			<listitem>
InnoDB has a bottleneck, 
if you have more than 1024 simultaneous concurrent
connections to the DB (We have about 5000).
			</listitem>
			<listitem>
Ndb (the MySQL cluster) works quite great, but has a problem with DB
opening (use database ;) which limits the scalability of the solution.
			</listitem>
		</itemizedlist>
		<para>
We didn't had time to test Ndb properly on our environment, the solution
seems to be good in terms of design, it is memory based, and uses table
patitionning (so it'll split the datas on several servers). It has to be
improved to be really usable and strong.
		</para>
		<para>
Troy Hakala <emphasis>troy (at) recipezaar (dot) com</emphasis> 25 Oct 2005
		</para>
		<para>
We're using master/slave replication. The LVS balances the reads from the
slaves and the master isn't in the load-balancing pool at all. The app knows
that writes go to the master and reads go the VIP for the slaves. Aside from
replication latency, this works very reliably.
		</para>
		<para>
The problem then is failure of the master.
The master is redundant in itself (RAID drives, redundant
power) to minimize the risk. But yes, we are very read-intensive and keeping
the master out of the read load-balancing further increases the master's
lifespan.
		</para>
		<para>
We haven't tried master-master replication, but it's pretty easy and quick
to turn a slave into a master. We prefer simplicity to complexity. Besides,
we're not a bank and no one dies if the master db goes down for a few
minutes every 5 years. :-)
		</para>
		<para>
FWIW, our outages have been caused by bandwidth outages more than server
hardware failure. There's supposed to be redundancy there too, but for some
reason or another, the redundancy never kicks in. ;-)
		</para>
		<para>
Replication can be restarted easily:
<command>slave start</command> after you fix the error, which is usually just a
mysqlcheck on the table. You shouldn't have to take the master down at all.
		</para>
		<para>
And if you use a replication check in LVS, LVS will take the db server out
of rotation if it's not replicating, so it shouldn't even be noticed until
you can get around to fixing it. Nagios is also recommended to let you know
when a slave is no longer replicating.
		</para>
		<para>
The latency is on the order of a couple seconds and it's easy to take care
of in the app. In fact, it's only a problem if you cache db results for
hours or days (we use memcached). So it's not much of a problem in reality
if you account for it.
		</para>
		<para>
NDB violates my simplicity+commodity ideals... it's complicated and requires
very expensive (lots of RAM) servers. And, I think it *requires* SCSI drives
for some reason (I thought it was memory-based)! Doesn't Yahoo use MySQL
replication? If it's good enough for Yahoo, it's good enough for most
people. :-)
		</para>
		<para>
If the master went down, we'd make a slave into a master manually. 
But it's never happened in real life, just in lab tests. A script
could be written to do it, I guess, but it's not that simple.
		</para>
		<para>
All the talk about redundancy and high-availability is a bit academic, IMO,
unless it really is mission-critical -- and if it was, I'd be using Oracle
and not MySQL so I could blame them. ;-)
		</para>
		<para>
As I mentioned, none of this matters if bandwidth and electricity go out,
which is less reliable in my experience than solid-state computer hardware.
		</para>

		<para>
mike <emphasis>mike503 (at) gmail (dot) com</emphasis> 25 Oct 2005 
		</para>
		<blockquote>
			<para>
perhaps changing a slave to a master has changed from when I used it
- anytime a slave died, it
would not start replicating (or you wouldn't want to) unless it caught
up to the master since it died. but to grab a snapshot of the master
data, you would have to take the master down or flush tables with a
read lock until it was done getting the data synced. then you could
restart it...
			</para>
			<para>
for example, i was using this on a forum - when someone posts a message:
			</para>
<programlisting><![CDATA[
webserver inserts data into master
master replicates to slave
webserver reads from slave
]]></programlisting>
			<para>
if that doesn't happen within milliseconds, the user is taken to a
page that doesn't have their post show up yet.
			</para>
		</blockquote>
		<para>
Pierre Ancelot <emphasis>pierre (at) bostoncybertech (dot) com</emphasis> 26 Oct 2005
		</para>
		<para>
I run NDB and it works pretty fine...  
Debian GNU/Linux Sarge Mysql 4.1 2 nodes and a management server.
		</para>

		<para>
Francois JEANMOUGIN <emphasis>Francois (dot) JEANMOUGIN (at) 123multimedia (dot) com</emphasis> 26 Oct 2005
		</para>
		<para>
Note that it is unable to handle more than about 1000rq/s. Our MySQL server
(standalone MyISAM) goes up to 3000rq/s. InooDB hangs at 1024rq/s.
		</para>
		</section>
	</section>
	<section id="zope">
	<title>Using Zope with databases</title>
	<para>
Karl Kopper <emphasis>karl (at) gardengrown (dot) org</emphasis> 10 Feb 2004
	</para>
	<para>
Here is the
<ulink url="http://www.zope.org/Products/ZEO/ZEOFactSheet">
Zope database (ZODB)</ulink>
(http://www.zope.org/Products/ZEO/ZEOFactSheet).
The "ZEO" client/server model was designed to
make ZODB work in a cluster for read mostly data
	</para>
	<para>
I'm using it, or about to use it in production. Here is a quick write-up:
	</para>
	<blockquote>
		<para>
<ulink url="http://www.zope.org/">Zope</ulink>
(http://www.zope.org/)
is collection of python programs that help display web content.
Zope can run as a standalone web server or underneath Apache.
Add-on features to Zope are called "products." One Zope product is called
the Content Management Framework or CMF. The CMF product introduces the
concept of users to the Zope content. A separate project later sprung up on
top of the CMF called <ulink url="http://plone.org">Plone</ulink>
(plone.org). Plone and Zope let you
build your own web pages using either the TAL or the deprecated DTML
language that Zope interprets. Zope has connectors to external databases
like Postgres and MySQL but it also comes with its own database called ZODB.
		</para>
		<para>
ZEO sits between Zope scripts that you write and the ZODB. The ZEO client
grabs all calls the local Zope server makes to the ZODB and trys to satisfy
them using a local cache or by sending the request over the network to a ZEO
server. The ZEO server then writes the data to local storage using the ZODB.
		</para>
		<para>
Because ZEO clients talk to the ZEO server on an IP address the ZEO server
can be made highly available with Heartbeat (on a server pair outside the
cluster), and each realserver in the LVS cluster can be a ZEO client. There
are a few catches to this, the biggest is that all Zope servers should share
an "instancehome".  See the Zope web site for details.
		</para>
	</blockquote>
	</section>
	<section id="SQL">
	<title>Databases: Microsoft SQL server, tcp 1433</title>
	<para>
Malcolm Turnbull had a 3-Tier LVS with database clients running on the 
realserver webservers
connecting back through the VIP on the director to other realservers running
M$SQL. The requests never made it from the database clients to the database.
	</para>
	<para>
Malcolm Turnbull <emphasis>malcolm (at) loadbalancer (dot) org</emphasis> 10 May 2004
	</para>
	<blockquote>
		<para>
Apparently if you use either a netbios name in an ASP db connection 
string, or if your web server has M$oft authentication turned on,
IIS will use a challenge response hand shake to log on to the SQL server 
even though you've specified a basic username and password.
Anyway its working fine now.
Heres the
<ulink url="http://support.microsoft.com/default.aspx?scid=kb;EN-US;175671">
M$oft article</ulink>
(http://support.microsoft.com/default.aspx?scid=kb;EN-US;175671).
		</para>
	</blockquote>
	</section>
	<section id="oracle">
	<title>Databases: Oracle</title>
	<para>
Bilia Gilad <emphasis>giladbi (at) rafael (dot) co (dot) il</emphasis> 03 Feb 2005
	</para>
	<blockquote>
		<para>
Hi i configured oracle application server 10g with lvs .
All works fine except oracle portal .
In the oracle portal cluster manual :
http://www.tju.cn/docs/oas90400/core.904/b12115/networking.htm
		</para>
		<blockquote>
			<para>
"  The Parallel Page Engine (PPE) in Portal makes loopback connections to Oracle Application Server Web Cache for requesting page metadata information. In a default configuration, OracleAS Web Cache and the OracleAS Portal middle-tier are on the same machine and the loopback is local. When Oracle Application Server is front-ended by an LBR, all loopback requests from the PPE will start contacting OracleAS Web Cache through the LBR. Assume that the OracleAS Portal middle-tier and OracleAS Web Cache are on the same machine, or even on the same subnet. Then, without additional configuration, loopback requests result in network handshake issues during the socket connection calls. " 
			</para>
			<para>
" In order for loopbacks to happen successfully, you must set up a Network Address Translation (NAT) bounce back rule in the LBR, which essentially configures the LBR as a proxy for requests coming to it from inside the firewall. This causes the response to be sent back to the source address on the network, and then forwarded back to the client. "
 			</para>
		</blockquote>
		<para>
Does any one know how can I make the bounce back rule in the LBR( load balancer ) ?
Does this mean We have to work with NAT ( we prefer DR )?
 		</para>
	</blockquote>
	<para>
Con Tassios <emphasis>ct (at) swin (dot) edu (dot) au</emphasis> 03 Feb 2005 
	</para>
	<para>
We run LVS-DR with Oracle portal and don't experience any problems.  When the 
application server connects to the VIP the connection is internal to the 
server itself as each server is configured with the VIP on lo:1.
	</para>
	</section>
	<section id="ldap">
	<title>Databases: ldap, tcp/udp 389, tcp/udp 636</title>
		<section id="ldap_ro">
		<title>ldap, read only</title>
		<para>
Tim Mooney <emphasis>Tim (dot) Mooney (at) ndsu (dot) edu</emphasis> 10 Sep 2007 
		</para>
		<para>
We've been load balancing OpenLDAP for years using LVS-DR.
When clients can update LDAP, balancing becomes much more
tricky.
It's a pretty standard setup.  
Original setup was done by someone else, but
openldap was the first service we used LVS for, before even http.  We've
been using LVS-DR with OpenLDAP for at least 5 years, probably closer to 7.
For now it's only one port.  
Clients don't need to bind and can't retrieve anything
that's sensitive, so we're only doing ldap (no ldaps).
We have additional balanced services beyond LDAP, but the LDAP portion
looks like:
		</para>
<programlisting><![CDATA[
IP Virtual Server version 1.2.1 (size=4096)
Prot LocalAddress:Port Scheduler Flags
   -> RemoteAddress:Port           Forward Weight ActiveConn InActConn
TCP  vs2.ndsu.NoDak.edu:ldap lc
   -> obscured2.NoDak.edu:ldap       Route   1      16         982
   -> obscured1.NoDak.edu:ldap       Route   1      17         984
]]></programlisting>
		<para>
If you do an ldapsearch against our directory, you're getting our LVS-DR
openldap:
i		</para>
<programlisting><![CDATA[
ldapsearch -x -LLL -h vs2.ndsu.nodak2.edu -b dc=ndsu,dc=nodak,dc=edu uid=mooney
]]></programlisting>
		<para>
There's another organization co-located with the IT organization here at
the university, and they've also been running LVS-DR in front of their
openldap directory for nearly as along as we have.
LDAP is a critical component of Hurderos, which we've been using since
its inception.  Hence the need for a highly-available LDAP.
		</para>
		<para>
There can be replication between ldap servers, like there is with mysql, 
but in our case we have a master repository
(an Oracle database) that feeds adds/deletes/modifies directly to our
two back-end LDAP servers (bypassing the LVS-DR director).
The built-in replication of ldap has really matured.  
Once OpenLDAP 2.4 is out,
I need to revisit what's possible with it.
		</para>
		</section>
		<section id="ldap_rw">
		<title>ldap, read/write</title>
		<para>
We haven't got ldap working in read/write mode with LVS yet.
		</para>
		<blockquote>
			<para>
<emphasis>Konrads (dot) Smelkovs (at) emicovero (dot) com</emphasis> 03 Jul 2003
			</para>
			<para>
I have an LVS-DR, wlc,  with three realservers running openldap 2.0.
I have noticed that when going through the loadbalancer the nodes do not always reply, while if
issuing requests directly, I get a reply all the time.
The service is pretty busy (about 1k connections at any given moment).
Adding persistence does not help.
If I understand it correctly, LDAP is a simple TCP service. Usually, after
performing an initial connection and query it idles there and reuses the
connection.
			</para>
		</blockquote>
		<para>
Joe
		</para>
		<para>
Not knowing anything about ldap I looked at some of the HOWTOs. They
are all long on configuring and using ldap, but none describe the
ldap protocol.
From the <ulink url="http://www.ibiblio.org/pub/Linux/docs/HOWTO/other-formats/html_single/LDAP-HOWTO.html#HowitWorks">LDAP HOWTO</ulink>
I see that ldap uses iterative calls to the slapd (somewhat like DNS), that can
be sent to other slapds (I don't know how this would work in your case). As well
the slapd needs a 3rd tier database (eg dbm). If the clients are writing to the
database, then you're going to have the many reader, many writer LVS problem.
You're going to have to have only one copy of the database if clients are
writing to the slapd
		</para>
		<blockquote>
My setup: I have a "master" LDAP server that performs all writes and it
replicates to the other "slave" servers. If a write request is sent to
a slave, it is refered to the master server. The client then follows
this reference and makes a succesful write. So in my case I have a
stand-alone master, which is not load-balanced.
Also, due to specific of the application (think authentification or such),
it performs one or two exact search requests, like uid=konrads and
requests for a attribute to be returned, e.g. : userPassword.
		</blockquote>
		<para>
presumably these are two consecutive tcpip connections? If so you'll need
persistence.
As to what else is missing I don't know.
Just for sanity checks, you can use these machines, IPs to setup
some conventional LVS'ed service eg telnet, httpd?
You know the ldap realservers are working OK outside of the LVS
(ie you can connect to them directly, possibly after fiddling IPs)?
After that it's brute force eg tcpdump I'm afraid. If you know the protocol
well enough you can debug also with <xref linkend="phatcat"/>.
		</para>
		</section>
	</section>
	<section id="NFS">
	<title>nfs, udp 2049</title>
	<para>
It is possible with LVS to export directories from realservers to a client,
making a highly capacity nfs fileserver (see
<ulink url="http://www.linuxvirtualserver.org/Joseph.Mack/performance/single_realserver_performance.html">
performance data for single realserver LVS</ulink>, near the end).
This would be all fine and dandy, except that there is no way to fail-out the nfs service.
	</para>
	<para>
The problem is that the filehandle the client is handed is derived from the location
of the file on the disk and not from the filename (or directory).
The filehandle is required by the NFS spec to be invariant under name change
or a move to a new mount point, or to another directory.
I've talked to the people who write the NFS code for Linux and they
think these are all good specs and there's no way the specs are going to change.
The effect this has for LVS is that if you have to failout a realserver 
(or shut it down for routine maintenance), 
the client's file presented from a different realserver will have a different
filehandle and the filehandle the client has will be for a file that
doesn't exist. The client will get a 
<xref linkend="stale_file_handle"/> requiring a reboot. 
	</para>
	<para>
Although no-one has attempted it, a <xref linkend="ro_nfs"/> is possible.
	</para>
		<section id="nfs_early_days">
		<title>NFS, the dawning of awareness of the fail-out problem</title>
		<blockquote>
			<para>
Matthew Enger <emphasis>menger (at) outblaze (dot) com</emphasis>
1 Sep 2000
			</para>
			<para>
	I am looking into running two NFS servers, one as a backup for
serving lots of small text files and am wondering what would be the best
solution for doing this. Does anyone have any recomendations.
			</para>
		</blockquote>
		<para>
Joe
		</para>
		<para>
LVS handles NFS just fine (see the
<ulink url="http://www.linuxvirtualserver.org/Joseph.Mack/performance/single_realserver_performance.html">
performance document</ulink> on the docs page of the lvs website).
You have to handle the problem of writes yourself to keep both NFS servers in sync.
		</para>
		<blockquote>
			<para>
Jeremy Hansen <emphasis>jeremy (at) xxedgexx (dot) com</emphasis> 1 Sep 2000
			</para>
			<para>
Can nfs handle picking up a client machine in a failover situation.
If my primary nfs server dies,
and my secondary takes over the first, can nfs clients handle this?
Something tells me nfs wouldn't be very happy in this situation.
			</para>
		</blockquote>
		<para>
Wayne <emphasis>wayne (at) compute-aid (dot) com</emphasis> 01 Sep 2000
		</para>
		<para>
It will not work for NFS.  NFS is working based on server
hand over an opaque packet to the client. Client
then will communicate with the server based on that opaque
handle.  Normal NFS construct that opaque handle involves
some file system ID from that particular server, which most
likely will be different from one server to the other.
		</para>
		<blockquote>
			<para>
Joe
			</para>
			<para>
this is a problem even for UDP NFS? (I know NFS is supposed to be
stateless but isn't)
			</para>
		</blockquote>
		<para>
Wayne
		</para>
		<para>
If the NFS servers are identical, there is a chance that it may
work. However, if the file systems are not identical (from file
system ID point of view), it will not work, no matter if it is UDP
or not.  The stateless is only true to that particular server. BUT,
that is the NFSes I had been worked on before based on Sun's
original invention, it may not true for others implementations.
		</para>
		<para>
Alan Cox <emphasis>alan (at) lxorguk (dot) ukuu (dot) org (dot) uk</emphasis>
1 Sep 2000
		</para>
		<para>
IFF your NFS servers are running some kind of duplexing protocol and handling
write commits to both disk sets before acking them then the protocl is good
enough - for any sane performance you would want NFSv3
The implementations are another matter
		</para>
		<para>
John Cronin <emphasis>jsc3 (at) havoc (dot) gtf (dot) org</emphasis>
		</para>
		<para>
It works as long as the filesystems are identical.  That means either
readonly content dd'd to identical disk on failover machine, or dual
ported disk storage with two hosts (or more) attached.  When the failover
happens the backup system then mounts the disks and takes over.  You
need to be VERY sure that the primary system is NOT up and writing to
the disk or you will have to go to backups after the disk gets corrupted
(having two systems perform unsynchronized writes to the same filesystem
is not a good idea).
		</para>
		<para>
This is the way Sun handles it in their HA cluster.  They go a step
further by using Veritas Volume Manager, and Veritas has to forcibly
import the disk group to the backup when a failover is done - the
backup also sends a break or poweroff command to the primary via the
serial terminal interface to make darn sure the primary is down.
That said, I have seen three systems all mounting the same volume
during some pathological testing I did on some systems at a Sun
HA training course.  The storaage used in this situation was
Sun D1000/A1000 (dual ported UltraSCSI) and Sun A5000 (Fiberchannel).
		</para>
		<blockquote>
			<para>
			Joe
			</para>
			<para>
	Would the client get a stale file handle on real-server failure?
Now that I think about it, I snooped on a tread with similar
content recently. It would have been linux-ha or beowulf.
I had assumed you could fail out an NFS server, since file servers
like the Auspex boxes use NFS (I thought) and can failover. How they work
at the low level I don't know.
			</para>
		</blockquote>

		<blockquote>
			<para>
Joe
			</para>
			<para>
in principle this could be handled by generating the filehandle
from the path/filename which would be the same on all systems?
			</para>
		</blockquote>
		<para>
Wayne
		</para>
		<para>
It could be done like that.  But if the hard drive SCSI ID is
different that could cause system uses different file system ID
assigned to the file system, and end up stalled handle.
		</para>
		</section>
		<section id="nfs_failover">
		<title>failover of NFS</title>
		<para>
Here we're asking one of the authors of the Linux NFS code.
		</para>
		<blockquote>
		<para>
Joseph Mack
		</para>
		<para>
One of the problems with running NFS as an LVS'ed service (ie to
make an LVS fileserver), that has come up on this mailing list is that a
filehandle is generated from disk geometry and file location data. In
general then the identical copies of the same file that are on different
realservers will have different file handles. When a realserver is
failed out (<emphasis>e.g.</emphasis> for maintenance)  and the client is swapped over to a new
machine (which he is not supposed to be able to detect), he will now have
an invalid file handle.
		</para>
		<para>
Is our understanding of the matter correct?
		</para>
		</blockquote>
		<para>
Dave Higgen <emphasis>dhiggen (at) valinux (dot) com</emphasis> 14 Nov 2000
		</para>
		<para>
In principle.  The file handle actually contains a 'dev', indicating the
filesystem, the inode number of the file, and a generation number used
to avoid confusion if the file is deleted and the inode reused for
another file.  You could arrange things so that the secondary server has
the same FS dev... but there is no guarantee that equivalent files will
have the same inode number; (depends on order of file creation etc.)
And finally the kicker is that the generation number on any given system
will almost certainly be different on equivalent files, since it's
created from a random seed.
		</para>
		<blockquote>
		<para>
If so is it possible to generate a filehandle only on the
path/name of the file say?
		</para>
		</blockquote>
		<para>
Well, as I explained, the file handle doesn't contain anything
explicitly related to the pathname.  (File handles aren't big enough for
that; only 32 bytes in NFS2, up to 64 in NFS3.)
		</para>
		<para>
Trying to change the way file handles are generated would be a MASSIVE
redesign project in the NFS code, I'm afraid... In fact, you would
really need some kind of "universal invariant file ID" which would have
to be supported by the underlying local filesystem, so it would ramify
heavily into other parts of the system too...
		</para>
		<para>
NFS just doesn't lend itself to replication of 'live' filesystems in
this manner.  It was never a design consideration when it was being
developed (over 15 years ago, now!)
		</para>
		<para>
There HAVE been a number of heroic (and doomed!) efforts to do this kind
of thing; for example, Auspex had a project called 'serverguard' a few
years ago into which they poured millions in resources... and never got
it working properly...  :-(
		</para>
		<para>
Sorry.  Not the answer you were hoping for, I guess...
		</para>
		</section>
		<section id="nfs_shared_scsi">
		<title>shared scsi solution for NFS</title>
		<para>
It seems that the code which calculates the filehandle in NFS is
so entrenched in NFS, that it can't be rewritten to allow
disks with the same content (but not neccessarily the same
disk geometry) to act as failovers in NFS.
The current way around this problem is for a reliable (eg RAID-5)
disk to be on a shared scsi line. This way two machines can
access the same disk. If one machine fails, then the other
can supply the disk content. If the RAID-5 disk fails, then
you're dead.
		</para>
		<para>
John Cronin <emphasis>jsc3 (at) havoc (dot) gtf (dot) org</emphasis> 08 Aug 2001
		</para>
		<blockquote>
		<para>
You should be able to do it with shared SCSI, in an active-passive
failover configuration (one system at a time active, the second
system standing by to takeover if the first one fails).  Only by
using something like GFS could both be active simultaneously, and
I am not familiar enough with GFS to comment on how reliable it
is.  If you get the devices right, you can have a seamless NFS
failover.  If you don't, you may have to umount and remount
the file systems to get rid of stale file handle problems.
For SMB, users will have to reconnect in the event of a
server failure, but that is still not bad.
		</para>
		</blockquote>
		<blockquote>
			<para>
Salvatore J. Guercio Jr <emphasis>sguercio (at) ccr (dot) buffalo (dot) edu</emphasis>
12 Jun 2003
			</para>
			<para>
Here is background on my LVS/NFS setup:
			</para>
			<para>
I have 4 IBM x330 and an IBM FastT500 SAN, this project I am working is
to set up the SAN to server 635GB worth of storage space to the Media
Studies department of the University. Each x330 is connected to the SAN
with GB fibre channel and 100MB to a Cisco 4006 Switch. The Switch has a
GB connection to the media studies department where they have a lab of 4
Macs running MacOS X. They will mount the share and access media data on
the share. Each client has a GB connection to the Cisco switch.
			</para>
			<para>
The LVS comes in handy to increase the bandwidth of the SAN as well as
gives us some redundancy.  Since I have a
shared SCSI solution, I will not run into the file handle problem and I
am hoping that using IBM GPFS filesystem, will help me with the lockd
problem.
			</para>
			<para>
Did you have to do anything as far as forwarding your portmap or any
other ports to the realservers? Right now I am only forwarding udp port
2049.
			</para>
		</blockquote>
		<para>
Joe
		</para>
		<para>
Just a sanity check here...
Do you understand the problems of exporting NFS via LVS (see the HOWTO)?
Are these problems going to affect you (if not, this would be
useful for us to know).
I assume this setup will handle write locking etc.
For my information, how is LVS going to help here?
Is it increasing throughput to disk?.
		</para>
		</section>
		<section id="nfs_detecting_failure">
		<title>detecting failed NFS</title>
		<para>
Don Hinshaw
		</para>
		<blockquote>
		<para>
Would a simple TCP_CONNECT be the right way to test NFS?
		</para>
		</blockquote>
		<para>
Horms
		</para>
		<para>
If you are running NFS over TCP/IP then perhaps, but in my experience NFS
deployments typically use NFS over UDP/IP. I'm suspecting a better test
would be to issue some rpc calls to the NFS server and look at the
response, if any. Something equivalent to what showmount can do might not
be a bad start.
		</para>
		<para>
Joe
		</para>
		<blockquote>
		<para>
how about exporting the directory to the director as well and doing an `ls`
every so often
		</para>
		</blockquote>
		<para>
Malcolm Cowe <emphasis>malcolm_cowe (at) agilent (dot) com</emphasis> 7 Aug 2001
		</para>
		<para>
HP's MC/ServiceGuard cluster software monitors NFS using the "rpcinfo"
command -- it can be quite sensitive to network congestion, but it is
probably the best tool for monitoring this kind of service.
		</para>
		<para>
The problem with listing an NFS exported directory is that when the
service bombs, ls will wait for quite a while -- you don't want the
director hanging because of an NFS query that's gone awry.
		</para>
		<para>
Nathan Patrick <emphasis>np (at) sonic (dot) net</emphasis> 09 Aug 2001
		</para>
		<para>
Mon includes a small program which extends what "rpcinfo" can do (and shares
some code!) Look for rpc.monitor.c in the mon package, available from kernel.org
among other places. In a nutshell, you can check all RPC services or specific
RPC services on a remote host to make sure that they respond (via the RPC null
procedure). This, of course, implies that the portmapper is up and responding.
		</para>
		<para>
From the README.rpc.monitor file:
		</para>
		<blockquote>
		<para>
This program is a monitor for RPC-based services such as the NFS
protocol, NIS, and anything else that is based on the RPC protocol.
Some general examples of RPC failures that this program can detect
are:
		</para>
<programlisting><![CDATA[
  - missing and malfunctioning RPC daemons (such as mountd and nfsd)
  - systems that are mostly down (responding to ping and maybe
    accepting TCP connections, but not much else is working)
  - systems that are extremely overloaded (and start timing out simple
    RPC requests)
]]></programlisting>
		<para>
To test services, the monitor queries the portmapper for a listing of
RPC programs and then optionally tests programs using the RPC null
procedure.
		</para>
		<para>
At Transmeta, we use:
		</para>
<programlisting><![CDATA[
  "rpc.monitor -a" to monitor Network Appliance filers
  "rpc.monitor -r mountd -r nfs" to monitor Linux and Sun systems
]]></programlisting>
		</blockquote>
		<para>
Michael E Brown <emphasis>michael_e_brown (at) dell (dot) com</emphasis> 08 Aug 2001
		</para>
		<para>
how about rpcping?
		</para>
		<para>
(Joe - rpcping is at <ulink url="ftp://ftp.navya.com/nocol/">nocol_xxx.tar.gz</ulink>
for those of us who didn't know rpcping existed.)
		</para>
		</section>
		<section id="nfs_locking">
		<title>NFS locking and persistence</title>
		<para>
Steven Lang Sep 26, 2001
		</para>
		<para>
The primary protocol I am interested in here is NFS.  I have the director
setup with DR with LC scheduling, no persistence, with UDP connections timing
out after 5 seconds.  I figured the time it would need to be accessing the
same host would be when reading a file, so they are not all in contention for
the same file, which seems to cost preformance in GFS.  That would all come
in a series of accesses.  So there is not much need to keep the traffic to
the same host beyond 5 seconds.
		</para>
		<para>
Horms <emphasis>horms (at) vergenet (dot) net</emphasis>
		</para>
		<blockquote>
		<para>
I know this isn't the problem you are asking about, but I think there
are some problems with your architecture. I spent far to much of last
month delving into NFS - for reasons not related to laad balancing -
and here are some of the problems I see with your design. I hope they
are useful.
		</para>
		<para>
As far as I can work out you'll need the persistance to be much longer than
5s. NFS is stateless, but regardless, when a client connects to a server a
small ammount of state is established on both sides. The stateless aspect
comes into play in that if either side times out, or a reboot is detected
then the client will attempt to reconnect to the server.  If the client
doesn't reconnect, but rather its packets end up on a different server
because of load balancing the server won't know anything about the client
and nothing good will come of the sitiation. The solution to this is to
ensure a client consistently talks to the same server, by setting a really
long persistancy.
		</para><para>
There is also the small issue of locks. lockd should be running on the
server and keeping track of all the locks the client has.  If the client
has to reconnect, then it assumes all its locks are lost, but in the mean
time it assumes everything is consistent. If it isn't accessing the same
server (which wouldn't work for the reason given above) then the server
won't know about any locks it things it has.
		</para><para>
Of course unless you can get the lockd on the different NFS servers to talk
to each other you are going to have a problem if different clients
connected to different servers want to lock the same file.  I think if you
want to have any locking you're in trouble.
		</para>
		</blockquote>
		<para>
I actually specifically tested for this.  Now it may just be a linux thing,
not common to all NFS platforms, but in my tests, when packets were sent to
the server other than the one mounted, it happily serves up the requested
data without even blinking.  So whatever state is being saved (And I do know
there is some minimal state) seems unimportant.  It actually surprised me how
seamlessly it all worked, as I was expecting the non-mounted server to reject
the requests or something similar.
		</para>
		<blockquote>
			<para>
That is quite suprising as the server should maintain state as to
what clients have what mounted.
			</para><para>
There is also the small issue of locks. lockd should be running on the
server and keeping track of all the locks the client has.  If the client
has to reconnect, then it assumes all its locks are lost, but in the mean
time it assumes everything is consistent. If it isn't accessing the same
server (which wouldn't work for the reason given above) then the server
won't know about any locks it things it has.
			</para>
		</blockquote>
		<para>
This could indeed be an issue.  Perhaps setting up persistence for locks.
But I don't think it is all bad.  Of course, I am basing this off several
assumptions that I have not verified at the moment.  I am assuming that NFS
and GFS will Do The Right Thing.  I am assuming the NFS lock daemon will
coordinate locks with the underlying OS.  I am also assuming that GFS will
then coordinate the locking with the rest of the servers in the cluster.  Now
as I understand locking on UNIX, it is only advisory and not enforced by the
kernel, the programs are supposed to police themselves.  So in that case, as
long as it talks to a lock daemon, and keeps talking to the same lock daemon,
it should be okay, even if the lock daemon is not on the server it is talking
to, right?
		</para>
		<blockquote>
			<para>
That should be correct, the locks are advisor. As long as
the lock daemons are talking to the underlying file system (GFS) then
the behaviour should be correct, regarldess of which lock daemon
a client talks to, as long as the client consistently talks to
the same lock daemon for a given lock.
			</para>
		</blockquote>
		<para>
Of course, in the case of a failure, I don't know what will happen.  I will
definitely have to look at the whole locking thing in more detail to know if
things work right or not, and maybe get the lock daemons to coordinate
locking.
		</para>
		<blockquote>
			<para>
Given that lockd currently lives entirely in the kernel
that is easier said than done.
			</para>
		</blockquote>
		</section>
		<section id="nfs_other">
		<title>Other Network file systems: replacements for NFS</title>
		<para>
This is from the beowulf mailing list
		</para>
		<para>
Ronald G Minnich <emphasis>rminnich (at) lanl (dot) gov</emphasis> 26 Sep 2002
		</para>
		<blockquote>
			<para>
NFS is dead for clusters.
We are targeting three possible systems, each having a different set of
advantages:
			</para>
			<itemizedlist>
				<listitem>
				<para>
panasas (http://www.panasas.com)
				</para>
				</listitem>
				<listitem>
				<para>
lustre (http://www.lustre.org)
				</para>
				</listitem>
				<listitem>
				<para>
v9fs (http://v9fs.sourceforge.net), from yours truly
				</para>
				</listitem>
			</itemizedlist>
		</blockquote>
		</section>
		<section id="nfs_hard_soft">
		<title>nfs mounts: hard and soft</title>
		<para>
This is not LVS exactly, but here's from a discussion on hard and soft mounts
from the beowulf mailing list.
		</para>
		<para>
Alvin Oga <emphasis>alvin (at) Maggie (dot) Linux-Consulting (dot) com</emphasis> 14 May 2003
		</para>
		<blockquote>
		<para>
if you export a raid subsystem via nfs... you will have
problems
		</para>
		<itemizedlist>
			<listitem>
			<para>
if you export it w/ hard mount,  all machines sit and wait
   for the machine that went down to come back up
			</para>
			</listitem>
			<listitem>
			<para>
if you export it w/ soft mount,  you can ^C out of any commands
   that try to access the machine went down, and continue on
   your merry way as long as you didnt need its data
			</para>
			</listitem>
		</itemizedlist>
		<para>
best way to get around NFS export problems
	- have 2 or 3 redundant systems of identical data
	( a cluster of data ... like that of www.foo.com websites )
		</para>
		</blockquote>
		<para>
Greg Lindahl <emphasis>lindahl (at) keyresearch (dot) com</emphasis> 15 May 2003
		</para>
		<blockquote>
		<para>
There are soft and hard mounts, and there are interruptable mounts
("intr" -- check out "man nfs").
		</para>
		<itemizedlist>
			<listitem>
		<para>
A hard mount will never time out. If you make it interruptable, then
the user can choose to ^C. This is the safe option.
		</para>
			</listitem>
			<listitem>
		<para>
A soft mount will time out, typically leaving you with data corruption
for any file open at the time.  This is the option you probably never
want to use.
		</para>
			</listitem>
		</itemizedlist>
		<para>
By the way, if you use the automounter to make sure that unused NFS
filesystems are not mounted, it can help quite a bit when you have a
crash, depending on your usage pattern.
		</para>
		<para>
Other potential problems include: inadequate power or airflow, high
input air temperature, old BIOS on the 3ware card, old Linux kernel,
etc.
		</para>
		</blockquote>
		</section>
		<section id="linux_nfs">
		<title>linux nfs in general</title>
		<blockquote>
			<blockquote>
				<para>
		Benjamin Lee <emphasis>ben (at) au (dot) atlas-associates (dot) com</emphasis>
				</para>
				<para>
I am wondering what (currently) people consider a production quality
platform to run an NFS server on? I am thinking maybe a BSD although
the kernel NFS code in Linux is much more stable now, I've heard.
The idea is to put together a RAID boxen which will serve web pages and
mail spool via NFS. (Don't worry, I'm only mounting the mail spool
once. ;-) It's not a large enterprise system. )
				</para>
			</blockquote>
			<para>
Ted Pavlic <emphasis>tpavlic (at) netwalk (dot) com</emphasis> 19 Sep 2000
			</para>
			<para>
While Linux does not provide very good NFS support and generally has problems
with things like locking (major problems), and quotas, don't rule it out.
Personally I have a system now which is very similar to the system in which
you sound like you want to build.
Until recently, it was a Linux server with an external RAID serving both
mailspool and web pages to four realservers. (and a couple of other
servers -- application, news, etc.) Right now (for various reasons most
having to do with how nightly backups are handled) I have two Linux servers
both with external RAIDs. One handles mailspool, the other handles web
pages. Both are configured so that if and when one machine Linux server dies
completely the other can pick up the other RAID and serve both RAIDs again.
There will be some manual interaction, of course, but I have NOCs 24/7 and
hopefully such a problem would occur when a tech was available to handle the
switch.
			</para>
			<para>
Such a system seems to work fine for me. (It's worked for a long time). It's
easy for me to administrate because everything's Linux. I run into problems
here or there when a program has trouble locking and requires a local share,
but I get around those problems... and overall it's not that bad.
			</para>
		</blockquote>
		</section>
		<section id="stale_file_handle" xreflabel="stale file handle"> 
		<title>stale file handles</title>
		<para>Joe 16 Dec 2005</para>
		<para>
The client gets a stale file handle when the client has a 
file||directory open and the server stops serving the 
file||directory. This error is part of the protocol
(<emphasis>i.e.</emphasis> it's not a bug or a problem, 
it's supposed to happen). 
The stale file handle doesn't happen at the server end
(the server doesn't care if the client is totally hosed).
		</para>
<programlisting><![CDATA[
client                     server

                           server:# export /home/user/
                           server:# ls /home/user
                                  foo

client:# mount /home/user
client:# cd /home/user/
client:# ls ./
          foo

client:# cd foo
client:# ls
    ..listing of files in foo

                          server:# unexport /home/user/

client:# ls
      error: stale file handle
]]></programlisting>
		<para>
df and mount will hang (or possibly return
after a long timeout). The error goes away
when the server comes back.
		</para>

<programlisting><![CDATA[
                          server#: export /home/user

client:# ls
    .. listing of files in foo
]]></programlisting>
		<para>
If the servers went down and the clients 
(realservers) stayed up, all with open file handles,
the clients just have to wait till the servers come up again.
The stale file handle will mess up the client till
the server comes back. Since <filename>foo</filename> is on the same
piece of disk real-estate, <filename>foo</filename>
comes back with the same
file handle when the server reappears
		</para>
		<para>
An irrecoverable example:
		</para>
<programlisting><![CDATA[
                            server:# export /home/user

client:# mount /home/user
client:# cd /home/user
client:# ls ./
    foo

(ie as before so far)

do something different, 
force an irreversible failure on the server

                            server:# rmdir /home/user/foo

client:# ls ./

    stale file handle

                            server:# mkdir /home/user/foo

client:# ls ./
    stale file handle
]]></programlisting>
		<para>
In this example, when <filename>/home/user/foo</filename> is recreated, 
it's on a new piece of disk real-estate 
and will have a different file handle. 
The client is hung and you can't <command>umount /home/user</command> 
(maybe you can with <command>umount -f</command>). 
If you can't <command>umount /home/user</command>, 
you will have to reboot the client.
		</para>
		</section>
		<section id="ro_nfs" xreflabel="read-only NFS LVS">
		<title>read-only NFS LVS</title>
		<para>
Joseph L. Kaiser 7 Mar 2006
		</para>
		<blockquote>
I have been tasked to mount a read-only NFS mounted 
software area to 500+ nodes.  I wanted to do this with NFS 
and LVS, but after reading all the howtos with regard to 
NFS and LVS and reading all the email with regard to this 
in the archives (twice), it seems clear to me that this 
doesn't work.
		</blockquote>
		<para>
Joe
		</para>
		<para>
I haven't done any of this, I've just talked to people - so 
my knowledge is only theoretical.
		</para>
		<para>
(ro) is a different kettle of fish. If you use identical 
disks (you only need identical geometry, so you could in 
principle use different model disks) and make the disks bitwise 
identical (<emphasis>e.g.</emphasis> made with dd), 
then clients will always get the same filehandle for the same file, 
no matter which realserver they connect to. 
For disk failure, make sure you have a few dd copies spare. 
I assume (but don't know) you won't be able to use RAID etc because of problems
keeping the individual disks identical on the different
realservers. You'll only be able to use single disks.
		</para>
		<para>
If you have to update files, then you'll have to do it bitwise. 
I don't have any ideas on how to do this off the top of my head. 
Perhaps you could have two disks, one mounted and the other
umounted, but having received the new <command>dd</command> copy. 
You would change the weight to 0 with <command>ipvsadm</command>
and let the connections expire (about 3 mins <xref linkend="TCP_UDP_scheduling"/>)
<command>umount</command> the current disk and then <command>mount</command> the new disk. 
Presumably you'll have some period in the changeover where the
realservers are presenting different files.
		</para>
		<para>
Presumably for speed, you should have as much memory in the realservers
as possible, so that recently accessed files are still in memory.
		</para>
		<blockquote>
However, I have a boss, and he wanted me to ask if turning 
off no-attribute caching (noac) would help in the 
reliability of this service.
		</blockquote>
		<para>
If the disks are (ro) then the attributes on the server will 
never change, in which case you want the client to cache the 
attributes forever.
		</para>
		<blockquote>
He has seen with another NFS mounted filesystem that using 
the "noac" turns off caching and clients that sometimes 
get "Stale NFS file handle" will reread the file and 
succeed.  
		</blockquote>
		<para>
Is having the client not reboot only "sometimes" an acceptable spec? 
With "noac" will it now pass the tests in <xref linkend="stale_file_handle"/>?
		</para>
		</section>
		<section id="drbd">
	</section>
	<title>DRBD</title>
	<note>
DRBD is not a service in the network sense, but it used as a file server.
	</note>
	<para>
Neamtu Dan <emphasis>dlxneamtu(at)yahoo(dot)com</emphasis>
	</para>
	<blockquote>
I have a test system made up by a director, 
3 servers running ftp and http and 2 storage computers from where the servers take their data. 
If I were to stick to one storage computer there would be no problem, but I want redundacy. 
So I've set up  a working heartbeat on both the storage computers, 
but when the primary fails the servers can no longer use the data unless the servers
umount and mount again on the Virtual IP address the heartbeat uses 
(I tryed mounting with nfs and samba so far). 
As I understand these 2 mounting methods will not work in case of failover because of different disk geometry.
Do you  know what I should do for nfs or samba to work in case of failover 
(at least for read only, if read-write on the storage is not possible).
	</blockquote>
	<para>
mike <emphasis>mike503 (at) gmail (dot) com</emphasis> 1 Apr 2006 
	</para>
	<para>
DRBD+NFS works for me, pretty well too.
check out linux-ha.org for <ulink url="http://linux-ha.org/HaNFS">HaNFS</ulink>. 
	</para>

	<para>
Martijn Grendelman <emphasis>martijn (at) pocos (dot) nl</emphasis> 21 Mar 2007
	</para>
	<para>
I have recently set up a two-node cluster, both servers configured
identically, both handling HTTP, HTTPS and FTP connections over LVS.
Both machines are capable of playing the role of LVS director, but only
one is active at once. Monitoring of real servers is done with Mon.
	</para>
	<para>
Files are on a DRBD device, which is exported over NFS. Failover of LVS
(VIP + rules), DRBD, NFS and MySQL (also on DRBD) is handled by
Heartbeat. Works like a charm!!
The information on http://www.linux-ha.org/DRBD/NFS was extremely useful.
	</para>
	</section>
</section>
<section id="LVS-HOWTO.services.multi-port" xreflabel="multi-port services">
<title>LVS: Services: multi-port</title>
	<section id="multi_port_intro">
	<title>Introduction</title>
	<para>
While <xref linkend="LVS-HOWTO.services.single-port"/>
all use the same scheme (server listens, client connects),
multi-port services each have their own scheme
(<link linkend="ftp">ftp</link> has two schemes, active and passive).
For multi-port services, the initial connection is the standard single-port connection,
but the setup of the 2nd (or more) port occurs through information sent in the
payload of the connection to the first port.
The director does not inspect the payload of packets and has no information
about subsequent connection(s) that the client and realserver is attempting to setup.
Approaches used to load balance multi-port services are
	</para>
	<itemizedlist>
		<listitem>
		<para>
Use persistence to all ports at once on the realserver.
(Persistence can also be set for a single port,
but this is not used here).
		</para>
		<para>
This is a brute force approach.
Once the initial connection is made from the client to the first port on the realserver,
then any packet from any port on the client is forwarded to any port that the client
requests on the realserver.
This has been the approach historically used for ftp on LVS-DR or LVS-Tun.
While it works, it is not secure,
since any packets are allowed between the client and the LVS,
and not just the packets required for the ftp transfer.
For ftp, where no state is maintained on the realserver and where
idle timeouts are just a matter of the client reconnecting,
then persistence is a satisfactory solution for LVS/ftp.
It would be nice if we could do better than this,
but currently this is the state of the art for LVS with ftp.
		</para>
		</listitem>
		<listitem>
Use other code to inspect the payload of packets that are passed in the first port opened.
Since this code must talk to ip_vs, it must run on the director.
All packets in the first connection then must pass through the director
and so this approach will only work for LVS-NAT 
(or LVS-DR with Julian's forward shared patch)
(for LVS-DR, LVS-Tun, the packets returning to the client from
the realservers, go directly to the client and not through the director).
Code which inspects packets passing through the director
to aid setup of other ports includes
		<itemizedlist>
			<listitem>
Helper modules:
ftp is the only multi-port service for which a helper module has been written
(see <xref linkend="ftp_helper_module"/>).
			</listitem>
			<listitem>
fwmark: for ftp this requires the contrack module <filename>ip_conntrack_ftp</filename> to
look for packets which are RELATED.
			</listitem>
		</itemizedlist>
		</listitem>
		<listitem>
		<para>
<xref linkend="e-commerce_fwmark"/> listening on ports 80 and 443:
This is not a multi-port tcpip protocol.
A multi-port tcpip protocol requires one demon running
on the realserver sending packets on two ports.
For an e-commerce site, the connections are independant at the tcpip level
and are serviced by different demons.
For LVS, it is convenient to think of an e-commerce site as multi-port,
for following the initial connection to port 80,
you want the client's subsequent connection to 443
to go to the same realserver.
This is handled by persistence or by persistent fwmark.
		</para>
		</listitem>
	</itemizedlist>
	</section>
	<section id="ftp" xreflabel="ftp">
	<title>ftp general, active tcp 20,21; passive 21,high_port</title>
	<para>
ftp is a 2 port service in both active and passive modes.
For a description of active and passive ftp see
<ulink url="http://slacksite.com/other/ftp.html">
Active FTP vs. Passive FTP, a Definitive Explanation</ulink> on Slaksite.
Also see the
<ulink url="http://www.faqs.org/rfcs/rfc1579.html">RFC 1579 for passive ftp</ulink>
and the
<ulink url="ftp://nic.merit.edu/documents/rfc/rfc0959.txt">RFC 959 for ftp</ulink>
(where ftp is referred to as just "ftp", but with the arrival of passive ftp, 
is now called "active ftp").
The usual resource for this sort of information,
"TCP/IP Illustrated Vol 1", by W. Richard Stevens (Chapter 27 on FTP),
only discusses what is now called active FTP.
	</para>
	<para id="port_forwarded_ftp" xreflabel="port forwarded ftp">
Useful links (from Ratz 30 Nov 2003)
<ulink url="http://www.ssh.com/support/documentation/online/ssh/winhelp/32/Forwarding_FTP.html">
http://www.ssh.com/support/documentation/online/ssh/winhelp/32/Forwarding_FTP.html Forwarding ftp</ulink>.
(port forwarded ftp is not the same as <xref linkend="sftp"/> or <xref linkend="ssl_ftp"/>).
	</para>
	<para>
Because of the problems securing ftp,
Ratz suggests that you use a
single ftp server that is not part of your LVS
and secure it separately.
	</para>
	</section>
	<section id="ftp_helper_module" xreflabel="LVS-NAT ftp helper module">
	<title>ftp helper modules: ip_vs_ftp/ip_masq_ftp</title>
	<para>
The <filename>ip_vs</filename> build produces the modules <filename>ip_masq_ftp</filename> (2.2.x)
or <filename>ip_vs_ftp</filename> (2.4.x and later, written as a netfilter module).
The <filename>ip_masq_ftp</filename> module is a patched version of the file which
allowed ftp through a NAT box.
The patch stopped the original function (at least in early versions of LVS)
and is probably why it has a new name in 2.4.x kernels.
	</para>
	<para>
The <filename>ip_vs_ftp</filename> module will autoload (Nov 2003) 
when <command>ipvsadm</command> is invoked 
- check that the module is loaded by running <command>lsmod</command>.
	</para>
	<para>
The ipvs ftp helper module needed for LVS-NAT has resulted 
in a disproportionate number of problems on the LVS mailing list (presumably this will continue). 
In Dec 2006, Eric Robinson <emphasis>eric (dot) robinson (at) pmcipa (dot) com</emphasis>
was the unwitting guinea pig in straightening some of this out.
	</para>
	<para>
Problems include:
	</para>
	<itemizedlist>
		<listitem>
Few people are using LVS-NAT with ftp, so we wouldn't hear any problems 
even if the helper module was completely broken. 
When we hear of a problem we don't know whether to believe the poster, 
since we haven't heard a problem with ftp for ... oh you know, years.
		</listitem>
		<listitem>
Bugs have affected other services and we get reports of problems with (say) http
when no-one is using the LVS'ed ftp service and the poster doesn't tell us
that they have LVS'ed ftp (and doesn't realise that it's relevant).
		</listitem>
		<listitem>
different <filename>ftpd</filename> demons give different responses to calls from the client
and listen on different ports. 
Unless you take appropriate action, ftp demons listening on non-standard ports stop working,
when put behind an LVS director. 
		</listitem>
		<listitem>	
			<para>
the docs and fuctionality were out of step for quite a while.
			</para>
			<para>
Tony Clarke <emphasis>sam (at) palamon (dot) ie</emphasis>
found (Sep 2002) that the ftp helper module <filename>ip_masq_ftp</filename>
had not been patched for LVS for 2.2.19 at least a year after its release.
			</para>
			<para>
I was testing ftp with its default settings 
(without being terribly aware that I was using active ftp) 
and found that I didn't need the helper module. 
It took at least a year before anyone else (Wensong 17 Sep 2002) 
would agree with me. 
The conventional wisdom from 2002-2006 was that the ftp helper module
wasn't needed for active ftp. 
I thought the helper function for active ftp must
have been in ip_vs.
A possible explanation is Mark de Vries comment immediately below,
although not having the setup around any more I don't know for sure.
			</para>
		</listitem>
		<listitem>	
			<para>
Mark de Vries <emphasis>markdv (dot) lvsuser (at) asphyx (dot) net</emphasis> 23 Dec 2006.
			</para>
			<para>
ftp-clients don't care which IP the connection originates from.
			</para>
			<para>
Joe - the ftp-data connection then would originate on the RIP, rather than the VIP.
With the ftp helper, the ftp-data connections would be nat'ed to src_addr=VIP.
In my test setup, with no ftp helper and two private networks (which I routed locally),
the packets src_addr=RIP:ftp-data would have been routed directly
through the director to the CIP.
Complicating matters, I don't remember whether the ftpd was listening
to the VIP or 0.0.0.0.
			</para>
		</listitem>
	</itemizedlist>
	<para>
Mark de Vries <emphasis>markdv (dot) lvsuser (at) asphyx (dot) net</emphasis> 23 Dec 2006
	</para>
<programlisting><![CDATA[
from ip_vs_ftp.c:

/*
 * Look at incoming ftp packets to catch the PASV/PORT command
 * (outside-to-inside).
 *
 * The incoming packet having the PORT command should be something like
 *      "PORT xxx,xxx,xxx,xxx,ppp,ppp\n".
 * xxx,xxx,xxx,xxx is the client address, ppp,ppp is the client port number.
 * In this case, we create a connection entry using the client address and
 * port, so that the active ftp data connection from the server can reach
 * the client.
 */
]]></programlisting>
	<para>
So that would suggest (to me) that you do need the ip_vs_ftp helper
module, to do the src address translation in the active connection from
server to client.
	</para>
	<para>
Horms 27 Dec 2006
	</para>
	<para>
I just skimmed through the code, and the helper seems to listen for both the
PASV and PORT command. My FTP knowledge is a bit rusty, but I think the
latter is for non-passive ftp, so yes it seems to be needed for both.
	</para>
	<para>
The auto-loading is just a hack for the convenience of most people.
Basically, in recent versions of ipvsadm, if you're setting
up a virtual service on port 21, it guesses that there is a good chance
that it is ftp and tries to load ip_vs_ftp.
The ftp helper auto-load went in on 9 Oct 2003 - look at the date
of your ipvsadm (due to a releaes procedure that is beyond my control,
it seems that ipvsadm has been released multiple times with
the version number of 1.24. Indeed, the version only seems to denote
that it is the ipvsadm that works with the 2.6 kernels, or perhaps
an revision of the ABI, rather than a release of the utility itself. Grrr.
- <emphasis>i.e.</emphasis> the version number doesn't mean anything.)
	</para>
	<para>
If you are using a port other than 21, then you will need to set the
ports argument to the module when it is loded
	</para>
<programlisting><![CDATA[
insmod ip_vs_ftp.ko ports=8021
]]></programlisting>
	<para>
The default is 21. You can have up to IP_VS_APP_MAX_PORTS (8).
They are comma delimited
	</para>
<programlisting><![CDATA[
insmod ip_vs_ftp.ko ports=21,8021,9021
]]></programlisting>
	<para>
If the ftp helper module doesn't load, maybe you have an old version of ipvsadm? 
ftp is running on a port other than 21?
The module couldn't be found by modprobe for some reason?
	</para>
	<para>
Eric: with the ftp helper loaded, the ftp-data packets arriving at the client have src_addr=VIP
(the expected behaviour).
	</para>
	<para>
Joe - The 2.2.x ftp module is only available as a module
(<emphasis>i.e.</emphasis> it can't be built into the kernel).
	</para>
	<para>
Juri Haberland <emphasis>juri (at) koschikode (dot) com</emphasis> 30 Apr 2001
	</para>
	<blockquote>
AFAIK the IP_MASQ_* parts can only be built as modules.
They are automagically selected if you select CONFIG_IP_MASQUERADE.
	</blockquote>
	<para>
Julian Anastasov May 01, 2001
	</para>
	<blockquote>
		<para>
Starting from 2.2.19 the following module parameter is required:
		</para>
<programlisting><![CDATA[
modprobe ip_masq_ftp in_ports=21
]]></programlisting>
		<para>
Joe
		</para>
		<blockquote>
I don't see this mentioned in /usr/src/linux/Documentation, ipvs-1.0.7-2.2.19/Changelog,
google or dejanews. Is this an ip_vs feature or is it a new kernel feature?
		</blockquote>
		<para>
ratz
		</para>
		<blockquote>
		<para>
I see info only in the source. This is a new 2.2.19 feature.
It's <filename>/usr/src/linux/net/ipv4/ip_masq_ftp.c</filename>:
		</para>
<programlisting><![CDATA[
 * Multiple Port Support
 *      The helper can be made to handle up to MAX_MASQ_APP_PORTS (normally 12)
 *      with the port numbers being defined at module load time.  The module
 *      uses the symbol "ports" to define a list of monitored ports, which can
 *      be specified on the insmod command line as
 *              ports=x1,x2,x3...
 *      where x[n] are integer port numbers.  This option can be put into
 *      /etc/conf.modules (or /etc/modules.conf depending on your config)
 *      where modload will pick it up should you use modload to load your
 *      modules.
 * Additional portfw Port Support
 *      Module parameter "in_ports" specifies the list of forwarded ports
 *      at firewall (portfw and friends) that must be hooked to allow
 *      PASV connections to inside servers.
 *      Same as before:
 *              in_ports=fw1,fw2,...
 *      Eg:
 *              ipmasqadm portfw -a -P tcp -L a.b.c.d 2021 -R 192.168.1.1 21
 *              ipmasqadm portfw -a -P tcp -L a.b.c.d 8021 -R 192.168.1.1 21
 *              modprobe ip_masq_ftp in_ports=2021,8021
]]></programlisting>
		<para>
And it is a new kernel feature, not LVS feature.
		</para>
		</blockquote>
	</blockquote>
	<para>
what are these modules for: from ipvsadm(8) (ipvs 0.2.11)
	</para>
	<blockquote>
If  a virtual service is to handle FTP connections then persistence
must be set for the virtual service if Direct  Routing  or  Tunnelling  is
used  as  the forwarding mechanism. If Masquerading is used in conjunction
with an FTP service than persistence is not necessary, but  the  ip_vs_ftp
kernel module must be used.  This module may be manually inserted into the
kernel using insmod(8)
	</blockquote>
	<para>
The modules are <emphasis>NOT</emphasis> used for LVS-DR or LVS-Tun:
in these cases persistence is used (or fwmarks version of persistence).
	</para>
	<para> Joe 23 May 2001:
	</para>
	<para>
I run these rules on the director (without the ftp module)
and ftp works fine
	</para>
<programlisting><![CDATA[
$ ipchains -A forward -p tcp -j MASQ -s RIP ftp -d 0.0.0.0/0
$ ipchains -A forward -p tcp -j MASQ -s RIP ftp-data -d 0.0.0.0/0
$ ipchains -A forward -p tcp -j MASQ -s RIP 1024:65535 -d 0.0.0.0/0
]]></programlisting>
	<para>
Julian - these rules are risky. What happens with ICMP? It is not
masqueraded. I hope there is a similar rule for ICMP.
	</para>
	<note>
Joe Dec 2006 - We're a little more careful nat'ing out clients running on the realservers now.
We'd at least make sure the packets came out with src_addr=VIP.
	</note>
	<para> 
Stephane Klein 
	</para>
	<blockquote>
		<para>
I've tried to use your example to setup active and passive FTP.
I can authenticate, but i can't list or send data. I can see packet
in the conntrack file that with dport=20, but the ftp server tried
to send a SYN_SENT and have no reply.
		</para>
		<para>
<filename>ip_vs_ftp</filename> is loaded as module, 
<filename>ip_nat_ftp</filename> and <filename>ip_conntrack_ftp</filename> are in the kernel.
I used iptables rules of your example in the HOWTO.
		</para>
		<para>
I saw this article where you said it's necessary to patch the
kernel to work with <filename>ip_nat_ftp</filename>
(http://www.in-addr.de/pipermail/lvs-users/2004-June/011955.html)
That patch is for kernel 2.6.5. Is this patch included in
your NFCT patch or is it necessary to apply this patch?
		</para>
	</blockquote>
	<para> 
Julian 29 Aug 2004 
	</para>
	<para>
	Yes, it is needed if you are loading <filename>ip_nat_ftp</filename>. 
I didn't received any replies from the netfilter coreteam about this patch,
so I just linked it to the web site: ip_nat_ftp-2.6.5-1.diff
	</para>
	<para>
There are problems with the helper module approach for ftp,
since there is no agreement amongst <filename>ftpd</filename> code authors about the
responses given.
To help passive ftp, the <filename>ip_vs_ftp</filename> module looks for the response
<programlisting><![CDATA[
227 Entering Passive Mode
]]></programlisting>
from the ftpd.
Postings to the LVS mailing list
(starting with a
<ulink url="http://www.in-addr.de/pipermail/lvs-users/2002-October/006981.html">posting
by Tom Cronin</ulink> on LVS-NAT ftp), show that this response is not universal for ftpds.
As well Rutger van Oosten found for passive ftp, that the ftpd must be set to listen
on the correct IP.
	</para>
		<section id="active_ftp_expects_port_20">
		<title>For active ftp, the helper module expects ftp-data=20 (problems with vsftp)</title>
		<para>
Mark de Vries found that his ftp LVS-NAT didn't work, 
the reason being that the ftp helper module
wasn't forwarding the reply packets from the ftp-data port (usually port 20).
On further exploration, Mark found that the ftpd (the GPL'ed vsftp) wasn't
using the standard ftp-data port, but was using a high (>1024) port, 
thus allowing the ftpd to run with lower privileges 
(vsftp can be setup to run with the standard ftp-data port).
Currently the ftp helper expects ftp-data=20. 
We're working on a fix for this.
Here's the discussion so far.
		</para>
		<para>
Mark de Vries <emphasis>markdv (dot) lvsuser (at) asphyx (dot) net</emphasis>
25 Nov 2005
		</para>
		<para>
Problem found...
The thing is that ip_vs(_ftp) seems to assume that the ftp-data connection
will be initiated from port 20. Seems like a valid assumption...
But unfortunately this is not always the case... the vsftpd I was testing
with was configured to "connect_from_port_20=NO" by default. Once I
swithched to "=YES" active FTP worked fine.
Otherwise I just used some SNAT rules on the director.
So.... Now the question is: is this a vsftpd 'problem'? MUST ftp-data
connections originate from port 20? Or should this assumption be relaxed?
		</para>
		<para>
Aparently the iptables contrack_ftp module does not assume it; Connections
from ports other then 20 are considered "RELATED".
(I have not checked the src or debugged anything, I just observed that
this type of connection is indeed matched by a "RELATED" rule in my own
iptables setup.)
		</para>
		<para>
I don't think adding an option <filename>--data-port="some_number"</filename>
to the ftp helper would get us anywhere - the src port is not always the same.
vsftpd (probably) just connects without binding to a specific port, just
getting a random one in the ip_local_port_range...
Is there anything against not matching on the src port like the
ip_contrack(_ftp) stuff, <emphasis>i.e.</emphasis> matching/finding
the source port on the fly?
		</para>
		<para>
vsftp has passive ftp (pasv_enable = YES).
A lot of clients will default to
passive mode or fallback to it if active does not seem to be working.
which is probably the main reason I've had relatively few complaints about
active ftp not working.
		</para>
		<para>
As far as I understands the RFC leaves no room for a different src port
for the data connection. It's not fixed at 20 but should be 1 below the
controll port. Which is what ip_vs uses literally IIRC.
		</para>
		<para>
<filename>ip_vs_ftp</filename> and <filename>ip_conntrack_ftp</filename> 
do much of the same thing. 
The only difference is that in iptables you need an explicit rule
to handle the connection entries created, when in ipvs they are allways
used.
The real difference is only in the details of the connection entry they
create.  In ipvs there is the assumption/requirement that the connection
will originate from port 20 (assuming the ftpd is listening on port 21).
The ip_contrack_ftp module (aparently) does not make this assumption.
Taking the RFC as a guide the assumption is of course valid. 
		</para>
		</section>
		<section id="fowler_checklist">
		<title>Graeme Fowler's checklist for ftp</title>
		<para>
Graeme Fowler <emphasis>graeme (at) graemef (dot) net</emphasis> 23 Aug 2006
		</para>
		<itemizedlist>
			<listitem>
Ensure the LVS FTP helper is loaded.
			</listitem>
			<listitem>
Make sure that you define (or make a note of) the range of ports your FTP
server uses for data connections (this varies from server to server).
			</listitem>
			<listitem>
Ensure that you will accept traffic to those ports on your director.
If the packets are rejected by netfilter/iptables on the director, the FTP
helper never sees them so the connections will almost never work.
			</listitem>
		</itemizedlist>
		</section>
		<section id="ftp_lvs_nat_2.2">
		<title>LVS-NAT, 2.2.x director</title>
I found that ftp worked just
fine without the module for 2.2.x (1.0.3-2.2.18 kernel).
(see discussion following Mark de Vries comments in the ftp helper section above 
for a possible explanation.)
		</section>
		<section id="ftp_lvs_nat_2.4">
		<title>LVS-NAT, 2.4.x director</title>
For 2.4.x you can connect with ftp without any extra modules,
but you can't &quot;ls&quot; the contents of the ftp directory.
For that you need to load the ip_vs_ftp module.
Without this module, your client's screen won't lock up,
it just does nothing. If you then load the module,
you can list the contents of the directory.
		</section>
		<section id="ftp_lvs_dr_tun">
		<title>LVS-DR, LVS-Tun</title>
For LVS-DR, LVS-Tun active ftp needs persistence.
Otherwise it does not work, with or
without ip_masq_ftp loaded. You can login, but
attempting to do a `ls` will lockup the client
screen. Checking the realserver, shows connections on
ports 20,21 to paired ports on the client.
        	</section>
	</section>
	<section id="ftp_active">
	<title>ftp (active) - the classic command line ftp</title>
	<para>
This is a 2 port service.
	</para>
	<itemizedlist>
		<listitem>
		port 20 calls - data (files transferred in either direction,
and the output of the listing from <command>ls</command> command)
		</listitem>
		<listitem>
		port 21 listens - commands
(<emphasis>e.g.</emphasis> <command>user</command>, <command>pass</command>, <command>ls</command>)
		</listitem>
	</itemizedlist>
	<para>
Here's part of my <filename>/etc/services</filename> 
	</para>

<programlisting><![CDATA[
ftp-data         20/tcp    #File Transfer [Default Data]
ftp-data         20/udp    #File Transfer [Default Data]
ftp              21/tcp    #File Transfer [Control]
ftp              21/udp    #File Transfer [Control]
]]></programlisting>

	<para>
To setup ftp with LVS, you schedule only port 21 for forwarding.
While the realserver is listening on port 21,
it calls the client from port 20
(<emphasis>i.e.</emphasis> it's not listening on port 20)
rather than the client calling the realserver (through the director).
You do not add entries for port 20 with <command>ipvsadm</command>.
Port 20 is handled by persistence for LVS-DR and LVS-Tun.
For active ftp with LVS-NAT, you don't need the ipvs ftp helper module
(the ftp helper module is only needed for passive ftp, Wensong 17 Sep 2002)
(however see <link linkend="ftp_helper_module">ftp helper module</link>.
	</para>
		<section id="active_ftp_no_LVS" xreflabel="active ftp, no LVS">
		<title>session: active ftp (no LVS)</title>
		<para>
	Here's a standard non-LVS active ftp session using <xref linkend="phatcat"/>.
The ftp "client" machine (192.168.1.254) connects to the ftp server machine "sneezy" (192.168.1.11).
Since two ports are involved, <command>phatcat</command> is run from two windows,
xterm_1, xterm_2.
		</para>
		<para>
<emphasis role="bold">xterm_1:</emphasis>
		</para>
<programlisting><![CDATA[
client:~# phatcat sneezy 21
sneezy.mack.net [192.168.1.11] 21 (ftp) open
220 sneezy.mack.net FTP server (Version wu-2.4.2-academ[BETA-15](1) Wed May 20 13:45:04 CDT 1998) ready.
help
214-The following commands are recognized (* =>'s unimplemented).
   USER    PORT    STOR    MSAM*   RNTO    NLST    MKD     CDUP
   PASS    PASV    APPE    MRSQ*   ABOR    SITE    XMKD    XCUP
   ACCT*   TYPE    MLFL*   MRCP*   DELE    SYST    RMD     STOU
   SMNT*   STRU    MAIL*   ALLO    CWD     STAT    XRMD    SIZE
   REIN*   MODE    MSND*   REST    XCWD    HELP    PWD     MDTM
   QUIT    RETR    MSOM*   RNFR    LIST    NOOP    XPWD
214 Direct comments to ftp-bugs@sneezy.mack.net.
user ftp
331 Guest login ok, send your complete e-mail address as password.
pass mack
230 Guest login ok, access restrictions apply.
]]></programlisting>
		<para>
On the client, use <command>netstat -an</command> to find
the highest unprivileged port in use (in this case port 1029).
		</para>
		<para>
<emphasis role="bold">xterm_2:</emphasis>
tell the client to listen on the first unused port (here 1030).
		</para>
<programlisting><![CDATA[
client:~# phatcat -l -p 1030
]]></programlisting>
		<para>
<emphasis role="bold">xterm_1:</emphasis> tell the ftpserver to connect to client:1030
(192,168,1,254,256,6) (1030=256x4 + 6),
and then <command>list</command> the contents of the directory
		</para>
<programlisting><![CDATA[
port 192,168,1,254,4,6
200 PORT command successful.
list
150 Opening ASCII mode data connection for /bin/ls.
226 Transfer complete.
]]></programlisting>
		<para>
<emphasis role="bold">xterm_2:</emphasis> receives the output of <command>list</command>.
		</para>
<programlisting><![CDATA[
connect to [192.168.1.254] from (UNKNOWN) [192.168.1.11] 20
total 9
drwxr-xr-x   8 root     root        1024 Nov  6 20:15 .
drwxr-xr-x   8 root     root        1024 Nov  6 20:15 ..
drwxr-xr-x   2 root     root        1024 Apr  7  1998 bin
drwxr-xr-x   2 root     root        1024 Aug 30  1993 etc
drwxr-xr-x   2 root     root        1024 Dec  3  1993 incoming
drwxr-xr-x   2 root     root        1024 Nov 17  1993 lib
drwxr-xr-x   2 root     root        1024 Jun  4  2001 pub
-rw-r--r--   1 root     root           0 Oct 24 13:24 this_is_sneezy
drwxr-xr-x   3 root     root        1024 Aug 30  1993 usr
-rw-r--r--   1 root     root         312 Aug  1  1994 welcome.msg
]]></programlisting>
		<para>
The ftpserver then closes the connection from port 21
(<emphasis>i.e.</emphasis> you can't do a second listing).
		</para>
		<para>
<emphasis role="bold">xterm_1:</emphasis>
		</para>
<programlisting><![CDATA[
list
425 Can't build data connection: Connection refused.
]]></programlisting>
<para>
<emphasis role="bold">xterm_2:</emphasis>
on the ftp client, initiate another listener (on the next unused port).
</para>
<programlisting><![CDATA[
client:~# phatcat -l -p 1033
]]></programlisting>
		<para>
<emphasis role="bold">xterm_1:</emphasis> tell the ftp server to connect to client:1033
(1033 = 256 x 4 + 9), prepare for upload of an ascii file (<command>type a</command>),
check the size of the file (<command>size welcome.msg</command>
about to be downloaded, then retreive it (<command>retr welcome.msg</command>).
(ftp server will then close connection from port 20.)
		</para>
<programlisting><![CDATA[
port 192,168,1,254,4,9
200 PORT command successful.
type a
200 Type set to A.
size welcome.msg
213 317
retr welcome.msg
150 Opening ASCII mode data connection for welcome.msg (312 bytes).
226 Transfer complete.
]]></programlisting>
		<para>
<emphasis role="bold">xterm_2:</emphasis> watch welcome.msg being delivered.
		</para>
<programlisting><![CDATA[
connect to [192.168.1.254] from (UNKNOWN) [192.168.1.11] 20
Welcome, archive user!  This is an experimental FTP server.  If have any
unusual problems, please report them via e-mail to root@%L
If you do have problems, please try using a dash (-) as the first character
of your password -- this will turn off the continuation messages that may
be confusing your ftp client.
]]></programlisting>
		<para>
<emphasis role="bold">xterm_1:</emphasis>say goodbye (the data connection has
closed, so you can't <command>list</command> using the same connection).
		</para>
<programlisting><![CDATA[
list
425 Can't build data connection: Connection refused.
quit
221 Goodbye.
]]></programlisting>
		</section>
		<section id="active_ftp_LVS-DR_no_persistence_one_network" xreflabel="active ftp, one network LVS-DR with no persistence">
		<title>
session: active ftp, one network LVS-DR with no persistence
(this is NOT going to work)
		</title>
		<para>
The example illustrates what happens with active ftp on LVS-DR without persistence
(it is <emphasis role="bold"> not </emphasis> going to work).
Set up a working one network LVS-DR
(<emphasis>i.e.</emphasis> all IPs are in the same network),
add rules to forward ftp
		<note>
Here you are only running commands to forward port 21.
You have not handled the data port 20 in any way.
		</note>
		</para>
<programlisting><![CDATA[
pip:/etc/lvs# ipvsadm -A -t lvs.mack.net:ftp -s rr
pip:/etc/lvs# ipvsadm -a -t lvs.mack.net:ftp -r bashfull.mack.net -g -w 1
pip:/etc/lvs# ipvsadm -a -t lvs.mack.net:ftp -r sneezy.mack.net -g -w 1
pip:/etc/lvs# ipvsadm
IP Virtual Server version 0.9.4 (size=4096)
Prot LocalAddress:Port Scheduler Flags
  -> RemoteAddress:Port           Forward Weight ActiveConn InActConn
TCP  lvs.mack.net:ftp rr
  -> sneezy.mack.net:ftp          Route   1      0          0
  -> bashfull.mack.net:ftp        Route   1      0          0
]]></programlisting>
		<para>
Use <command>phatcat</command> (as above)
to connect attempt to setup an ftp session with the VIP.
		</para>
		<para>
<emphasis role="bold">xterm_1:</emphasis>connect to VIP:ftp
		</para>
<programlisting><![CDATA[
client:~# phatcat lvs 21
lvs.mack.net [192.168.1.110] 21 (ftp) open
220 sneezy.mack.net FTP server (Version wu-2.4.2-academ[BETA-15](1) Wed May 20 13:45:04 CDT 1998) ready.
user ftp
331 Guest login ok, send your complete e-mail address as password.
pass mack
230 Guest login ok, access restrictions apply.
]]></programlisting>
		<para>
With <command>netstat -an</command> on the realserver, note that the client is connected to VIP:21,
not to RIP:21.
		</para>
		<para>
<emphasis role="bold">xterm_2:</emphasis>listen on the next available port
		</para>
<programlisting><![CDATA[
client:~# phatcat -l -p 1036
]]></programlisting>
		<para>
<emphasis role="bold">xterm_1:</emphasis>tell the realserver to connect to client:1036,
and then <command>list</command> the contents of <filename>/home/ftp</filename>.
(The connection hangs for a while - eventually you'll get the 425 message).
		</para>
<programlisting><![CDATA[
port 192,168,1,254,4,12
200 PORT command successful.
list
425 Can't build data connection: Connection timed out.
]]></programlisting>
		<para>
On the realserver, <command>netstat -an</command> shows
		</para>
<programlisting><![CDATA[
sneezy:/home/ftp# netstat -an | grep 103
tcp        0      1 192.168.1.110:20        192.168.1.254:1036      SYN_SENT
tcp        5      0 192.168.1.110:21        192.168.1.254:1035      ESTABLISHED
]]></programlisting>
		<para>
On the client, <command>netstat -an</command> shows that client is listening, but
not connecting
		</para>
<programlisting><![CDATA[
client:~# netstat -an | grep 103
tcp        0      0 0.0.0.0:1036            0.0.0.0:*               LISTEN
tcp        0      0 192.168.1.254:1035      192.168.1.110:21        ESTABLISHED
]]></programlisting>
		<para>
following the <command>list</command>,
if you run <command>tcpdump</command> on the realserver
when you run the <command>list</command> command, you'll see that
the realserver is sending
SYN packets from VIP:20-&gt;client:1036 but not receiving any replies.
The problem is that the ACK from the client is sent to VIP:20 which is
routed to the director, which has no forwarding rules for VIP:20.
Even if the director had forwarding rules for VIP:20,
it requires the first packet in a connection to be a SYN,
to start the process of making an
entry in the ipsvadm table for packets to port 20.
Thus the director will reject the ACK from the client to VIP:20
and no connection will be made.
		</para>
		</section>
		<section id="active_ftp_LVS-DR_persistence_one_network" xreflabel="active ftp, one network LVS-DR with persistence">
		<title>session: active ftp, one network LVS-DR with persistence</title>
		<para>
This is the normal method of setting up LVS-DR for ftp.
		</para>
<programlisting><![CDATA[
pip:/etc/lvs# ipvsadm -A -t lvs.mack.net:ftp -s rr -p 600
pip:/etc/lvs# ipvsadm -a -t lvs.mack.net:ftp -r  bashfull.mack.net -g -w 1
pip:/etc/lvs# ipvsadm -a -t lvs.mack.net:ftp -r  sneezy.mack.net -g -w 1
pip:/etc/lvs# ipvsadm
IP Virtual Server version 0.9.4 (size=4096)
Prot LocalAddress:Port Scheduler Flags
  -> RemoteAddress:Port           Forward Weight ActiveConn InActConn
TCP  lvs.mack.net:ftp rr persistent 600
  -> sneezy.mack.net:ftp          Route   1      0          0
  -> bashfull.mack.net:ftp        Route   1      0          0
]]></programlisting>
		</section>
	</section>
	<section id="passive_ftp">
	<title>ftp (passive)</title>
	<para>
Passive ftp is used by netscape to get files from an ftp url like
ftp://ftp.domain.com/pub/ . Here's an explanation of passive ftp
from http://www.tm.net.my/learning/technotes/960513-36.html
	</para>
	<blockquote>
		<para>
 If you can't open connections from Netscape Navigator through a firewall
 to ftp servers outside your site, then try configuring the firewall to
 allow outgoing connections on high-numbered ports.
		</para><para>
 Usually, ftp'ing involves opening a connection to an ftp server and then
 accepting a connection from the ftp server back to your computer on a
 randomly-chosen high-numbered telnet port. the connection from your
 computer is called the "control" connection, and the one from the ftp
 server is known as the "data" connection. All commands you send and the
 ftp server's responses to those commands will go over the control
 connection, but any data sent back (such as "ls" directory lists or
 actual file data in either direction) will go over the data connection.
		</para><para>
 However, this approach usually doesn't work through a firewall, which
 typically doesn't let any connections come in at all; In this case you
 might see your ftp connection appear to work, but then as soon as you do
 an "ls" or a "dir" or a "get", the connection will appear to hang.
		</para><para>
 Netscape Navigator uses a different method, known as "PASV" ("passive
 ftp"), to retrieve files from an ftp site. This means it opens a control
 connection to the ftp server, tells the ftp server to expect a
 control connection to the ftp server, tells the ftp server to expect a
 second connection, then opens the data connection to the ftp server
 itself on a randomly-chosen high-numbered port. This works with most
 firewalls, unless your firewall retricts outgoing connections on
 high-numbered ports too, in which case you're out of luck (and you
 should tell your sysadmins about this).
		</para><para>
 "Passive FTP" is described as part of the ftp protocol specification in
 RFC 959 ("http://www.cis.ohio-state.edu/htbin/rfc/rfc959.html").
		</para>
	</blockquote>
	<para>
If you are setting up an LVS ftp farm, it is likely that users will retrieve
files with a browser and you will need to setup the LVS to handle passive ftp.
You will need the ftp helper module or <xref linkend="LVS-HOWTO.persistent_connection"/> (also
see on the LVS website under documentation; persistence handling in LVS)
or <link linkend="fwmark_passive_ftp">fwmark persistent connection for ftp</link>.
	</para><para>
For passive ftp, the ftpd sets up a listener
on a high port for the data transfer.
This problem for LVS is that the IP for the listener is the RIP and not
the VIP.
	</para>
	<para>
Wenzhuo Zhang 1 May 2001
	</para>
	<blockquote>
		<para>
I've been using 2.2.19 on my dialup masquerading box for quite some
time. It doesn't seem to me that the option is required, whether in
PASV or PORT mode.
We can actually get ftp to work in NAT mode without using the
ip_masq_ftp module. The trick is to tell the real ftp servers to use
the VIP as the passive address for connections from outside; <emphasis>e.g.</emphasis> in
wu-ftpd, add the following lines to the /etc/ftpaccess:
		</para>
<programlisting><![CDATA[
passive address RIP <localnet>
passive address 127.0.0.1 127.0.0.0/8
passive address VIP 0.0.0.0/0
]]></programlisting>
		<para>
Of course, the ftp virtual service has to be persistent port 0.
		</para>
	</blockquote>
	<para>
Alois Treindl, 3 May 2001
	</para>
	<blockquote>
		<para>
I found (with kernel 2.2.19) that I needed the command
		</para>

<programlisting><![CDATA[
modprobe ip_masq_ftp in_ports=21
]]></programlisting>
		<para>
so that (passive mode) ftp from Netscape would work.
without the in_ports=21 it did not work.
		</para>
	</blockquote>
	<para>
Julian Anastasov <emphasis>ja (at) ssi (dot) bg</emphasis> 03 May 2001
	</para>
	<para>
	Yes, it seems this option is not useful for the active FTP
transfers because if the data connection is not created while the
client's PORT command is detected in the command stream, then it is
created later when the internal realserver creates normal in->out
connection to the client. So, it is not a fatal problem for active
FTP to avoid this option. The only problem is that these two connections
are independent and the command connection can die before the data
connection, for long transfers. With the in_ports option used this
can not happen.
	</para>
	<note>
Joe - in previous HOWTOs I had a comment from Julian saying that the
ftp helper was "recommended" for active ftp (presumably not required).
Presumably this is what he's talking about.
	</note>
	<para>
	The fatal problems come for the passive transfers
when the data connection from the client must hit the LVS service.
For this, the ip_masq_ftp module must detect the 227 response from
the realserver in the in->out packets and to open a hole for the
client's data connection. And the "good" news is that this works only
with in_ports/in_mark options used.
	</para>
	<para>
Alois
	</para>
	<blockquote>
on option so that I could configure on the server that it
gives the VIP to clients making a PASV request; it always gives
the realserver IP address in replies to such requests.
	</blockquote>
	<para>
	Bad ftpd :) It seems the follwing rules are valid:
	</para>
	<itemizedlist>
		<listitem>
active ftp always works through stupid balancers (for external clients)
that have minimum support for masquerading, with some drops in the
command connection
		</listitem>
		<listitem>
		passive ftp always works through stupid masq boxes (for internal clients).
The passive ftp setup is useful because the data connection can
be marked as a slave to the command connection and in this way
avoid connection reconnects.
		</listitem>
	</itemizedlist>
		<section id="ftp_passive_missmatch">
		<title>passive ftp client/server miss-match with LVS-NAT</title>
		<para>
Jeremy Kusnetz:
		</para>
		<blockquote>
although Julian says that all you need for ftp with LVS-NAT
is the ip_masq_ftp module, it doesn't work for me
(director 2.2.19-1.0.7 with ip_masq_ftp in_ports=21)
my ftp client just hangs.
              	</blockquote>
		<para>
Julian
		</para>
		<para>
The Netfilter guys use another approach when detecting
the 227 message in Linux 2.4, i.e. they try to ignore the message and to
use only the code (I'm not sure what is the final status of this handling
there). But in Linux 2.2 the word "Entering" may be a requirement :(
You have to select another FTPd, IMO.
		</para>
		<para>
Jeremy Kusnetz <emphasis>JKusnetz (at) nrtc (dot) org</emphasis> 24 May 2001
		</para>
		<blockquote>
			<para>
It was my ftp server.
When going into passive mode it said:
			</para>
<programlisting><![CDATA[
   Passive mode on (x,x,x,x,x,x)
]]></programlisting>
			<para>
instead of:
			</para>
<programlisting><![CDATA[
   Entering Passive Mode (x,x,x,x,x,x)
]]></programlisting>
		</blockquote>
		</section>
	</section>
	<section id="LVS-NAT_ftp_bug" xreflabel="LVS-NAT ftp helper bug">
	<title>ftp helper bug(s)</title>
	<para>
In early 2005 
Johan van den Berg, and Simon Schwendemann
sent a report of a problem
with LVS-NAT (2.4.x) where the ACK reply to a SYN would not be source-NAT'ed and so would
emerge with src_addr=RIP and not src_addr=VIP. 
(http://archive.linuxvirtualserver.org/html/lvs-users/2005-02/msg00299.html)
Johan van den Berg switched to using LVS-DR. 
http://archive.linuxvirtualserver.org/html/lvs-users/2005-02/msg00299.html
	</para>
	<para>
Even to figure this out took a while.
Initially only one in 60 or so SYNs would have the problem.
No-one had any idea what the problem was and cries for help were greeted by silence. 
Then Jari Takkala <emphasis>Jari (dot) Takkala (at) Q9 (dot) com</emphasis> 15 Aug 2005
found it only occured when the LVS-NAT was forwarding ftp, 
but the problem occured on all VIPs, not just the VIP that had the ftp service.
	</para>
	<para>
With Jari's posting, other people started to recognise the problem too.
	</para>
	<para>
Graeme Fowler <emphasis>graeme (at) graemef (dot) net</emphasis> 16 Aug 2005 
	</para>
	<blockquote>
This is very interesting; 
I have a number of clusters behind LVS-NAT 
and hadn't managed to observe myself that the one having problems - 
which I posted about sometime in the last year - 
is the only one of the whole lot which has ip_vs_ftp loaded. 
It's also a 2.4.x kernel, and can't be in-service upgraded.
	</blockquote>
	<para>
Julian Anastasov <emphasis>ja (at) ssi (dot) bg</emphasis> 26 Aug 2005 
	</para>
	<para>
        I can not reproduce it, I tried with 2.4.32-pre3 as it contains
some changes. Can you show your vs settings?:
	</para>
<programlisting><![CDATA[
grep . /proc/sys/net/ipv4/vs/*
]]></programlisting>
	<para>
So, you don't have any iptables rules, fwmarking, NAT or
linux ethernet bridging? Any extra patches for IPVS?
	</para>
	<para>
From your explanation <filename>ip_vs_ftp</filename> leads to problems where SYN
creates web connection, it is hashed in table, DNAT-ed to RS, then RS
replies SYN+ACK which can not match the connection in table.
It looks like this connection is not present (may be removed, do you see something
in debug logs from the SYN to the SYN+ACK) or the hash table is damaged. Do 
you still think it is caused by ip_vs_ftp? About your tests, is the
client IP on lan? Do you think this client IP has many connections to
the director?
	</para>
	<para>
	Jari (data dumps omitted)
	</para>
	<blockquote>
The client IP is not on the LAN. 
The problem occurs from any source IP trying to visit a load balanced VIP. 
Whenever we add the FTP service to ipvsadm, and begin load balancing to it, 
the problem begins to occur on all services. 
However, it is not consistent. 
Some outgoing SYN+ACK packets will get translated correctly for a certain period of time, 
then after awhile some packets will not be translated.
I do not think it is load related. 
We have other load balancers built from the same image handling many more connections.
	</blockquote>
	<para>
There were various discussions (under the title "LVS bugs") between Julian and 
Agostino di Salle <emphasis>a (dot) disalle (at) fineco (dot) it</emphasis>
that you can find in the archives if you want to know more.
	</para>
	<para>
Julian
	</para>
	<para>
        As reported from some users, the ip_nat_ftp module causes some
problems with other virtual services. ip_nat_ftp can keep 
ip_vs_conn_no_cport_cnt > 0 for the time it expects connections
from unknown client ports. This is fatal for the persistence services
as the normal packets start to hit persistence templates instead of
valid connections. Such packets are correctly forwarded to real servers
but the reply packets do not see connections as they are not created.
As result, the reply packets are not SNAT-ed by the IPVS code.
	</para>
	<para>
It is enough to have passive FTP connection
that waits to learn its client port to trigger problems with
non-ftp persistent services. The used VIPs do not matter.
	</para>
	<para>
        I tried to fix this problem with the following patch:
Linux 2.6.13: http://www.ssi.bg/~ja/tmp/ipvs-2.6/ct-2.6.13-1.diff,
Linux 2.4.32-pre3: http://www.ssi.bg/~ja/tmp/ipvs-2.4/ct-2.4.32-pre3-1.diff
	</para>
	<para>
        These patches do the following:
	</para>
	<itemizedlist>
		<listitem>
introduce IP_VS_CONN_F_TEMPLATE connection flag to mark the
connection as template
		</listitem>
		<listitem>
create new connection lookup function just for templates:
ip_vs_ct_in_get
		</listitem>
		<listitem>
make sure ip_vs_conn_in_get hits only connections with 
IP_VS_CONN_F_NO_CPORT flag set when s_port is 0. By this way
we avoid returning template when looking for cport=0 (ftp)
		</listitem>
	</itemizedlist>
	<para>
        There is a second patch that properly invalidates the
templates as Agostino di Salle noticed:
Linux 2.6.13:
http://www.ssi.bg/~ja/tmp/ipvs-2.6/invct-2.6.13-1.diff
Linux 2.4.32-pre3:
http://www.ssi.bg/~ja/tmp/ipvs-2.4/invct-2.4.32-pre3-1.diff
	</para>
	<para>
        I performed simple tests, so please test these patches,
for example, persistence+ip_nat_ftp, the ip_vs_sync code is changed
too. If there is a better solution please speak before including them
in next kernel releases. I'm expecting confirmation from people
with the problem that reply packets were not translated from IPVS.
	</para>
	<para>
Jari Takkala <emphasis>Jari (dot) Takkala (at) Q9 (dot) com</emphasis> 9 Sep 2005
	</para>
	<blockquote>
We applied these patches to a production load balancer on kernel 2.4.26. Our IPVS code is one version behind, however
the patches applied cleanly. We began load balancing FTP last night, and so far everything is working properly.
Thanks very much for your help!
	</blockquote>
	<para>
The patches worked from Graeme Fowler too.
	</para>
	<para>
Julian thinks this problem has been affecting people for a while.
	</para>
	<para>
Julian Anastasov <emphasis>ja (at) ssi (dot) bg</emphasis> 12 Sep 2005 
	</para>
	<para>
        thanks to Graeme and to Jari for the tests.
It seems the problems reported from many users in last 2 years and
more are now fixed. 
	</para>
	</section>
	<section id="ftp_secure">
	<title>ftp is difficult to secure</title>
	<para>
Roberto Nibali <emphasis>ratz (at) tac (dot) ch</emphasis> 06 May 2001
	</para><para>
If you are trying to secure the LVS
using the LVS as a packetfilter, will have no big success in doing it
for the ftp protocol, because it is so open.
You can do a lot to minimize full breaches.
At least put the ftp daemon in a chroot environment.
	</para><para>
We have multiple
choices if we want to narrow down the input ipchains rules on the front
interface of director
	</para>
	<itemizedlist>
		<listitem>
Use ftp via LVS. (this is not a solution actually, we still need special
input rules on the EXT_IF for 1024:65535)
		</listitem>
		<listitem>
		Use ftp without LVS but with SNAT. (difficult to setup)
		</listitem>
		<listitem>
		Use SuSE ftp proxy suite
		</listitem>
		<listitem>
		Use 2.4 kernel and ip_conntrack_ftp (don't know much about this, ask Rusty)
		</listitem>
		<listitem>
		Don't use ftp at all (this is what we want)
		</listitem>
		<listitem>
The  <ulink url="http://ftpfs.sourceforge.net/">ftpfs project</ulink>.
I haven't fully tested it and it's a very dangerous approach but it is
worth to a look.
		</listitem>
	</itemizedlist>
	<para>
The biggest problem is with the ip_masq_ftp module.
It should create an ip_fw entry in the masq_table for the PORT port.
It doesn't do this and we have to open the whole port range.
For PASV we have to DNAT the range.
	</para>
<programlisting><![CDATA[
ipchains -A forward -i $EXT_IF -s $INTERNAL_NET $UNPRIV_PORTS -d $DEP -j MASQ
]]></programlisting>
	<para>
FTP is made up of two connections, the Control- and the Data- Connection.
	</para>
	<itemizedlist>
		<listitem>
		<para>
ftp Control Connection
		</para>
		<para>
The Client contacts the Servers port 21 from an UNPRIV Port.
No trouble, standard, plain, vanilla TCP-Connection, we all love it.
Over this connection the client sends commands to the server.
We will see examples later.
		</para>
		</listitem>
		<listitem>
		<para>
FTP Data Connection
		</para>
		<para>
"Data" can be either the content of a file (sent as <emphasis>e.g.</emphasis> the result of
a "get" or "put" command) or the content of a directory-listing (i.e.
the result of a "ls" or "dir" command).
		</para>
		<para>
The data connection is where the trouble starts.
To transfer data, a second connection is opened.
		</para><para>
Usually the client opens this second connection to the server.
But for active ftp, the server opens this second connection,
using the well-known port 20 (called ftp-data) as sourceport.
But which port on the client should he connect to?
The client announces the port via a "port"-command over the control connection.
This is nasty: Ports are negotiated on application-level where
L4 switches like LVS can see what's going on.
		</para>
		<para>
For passive ftp, the server announces the port the client should connect to
in its reply to the client's "pasv"-command (this command starts passive FTP,
active is the default).
The client then opens the data-connection to the server.
The port that the server listens on is an unprivileged port (rather
than a privileged port as is normal for internet services).
A passive ftp transfer then requires that connections be allowed between all
63000 unprivileged ports on both the client and realservers rather than just one.
A passive ftp server is difficult to secure with packet filter rules.
		</para>
		</listitem>
	</itemizedlist>
	<para>
If we have to protect a client, we would like to only allow passive ftp,
because then we do not have to allow incoming connections.
If we have to protect a server, we would like to only allow active ftp,
because then we only have to allow the incoming control-connection.
This is a deadlock.
	</para>
		<section id="example_ftpsession">
		<title>Example ftp sessions with <xref linkend="phatcat"/></title>
		<para>
We need 2 xterms (x1, x2), fatcat and an ftp-server (here &quot;ftpserver&quot; 172.23.2.30).
		</para><para>
First passive mode (because it is conceptionally easier)
		</para>
<programlisting><![CDATA[
#x1: Open the control-connection to the server,
#and sent the command "pasv" to the server.
$ phatcat ftpserver 21
220 ftpserver.terreactive.ch FTP server (Version 6.4/OpenBSD/Linux-ftpd-0.16) ready.
user ftp
331 Guest login ok, send your complete e-mail address as password.
pass ftp
230 Guest login ok, access restrictions apply.
pasv
227 Entering Passive Mode (172,23,2,30,169,29)
]]></programlisting>
		<para>
The server replied with 6 numbers:
		</para>
		<itemizedlist>
			<listitem>
172,23,2,30 is the IP I have to connect to
			</listitem>
			<listitem>
(169*256+29=43293) is the Port
			</listitem>
		</itemizedlist>
			<para>
In x2 I open a second connection with a second <command>phatcat</command>
			</para>
<programlisting><![CDATA[
$ phatcat 172.23.2.30 43293
# x2 will now display output from this connection
]]></programlisting>
			<para>
Now in x1 (the control-connection)
			</para>
<programlisting><![CDATA[
$ list
list
150 Opening ASCII mode data connection for '/bin/ls'.
226 Transfer complete.
]]></programlisting>
			<para>
and in x2 the listing appears.
			</para><para>
Active ftp
			</para><para>
I use the same control-connection in x1 as above,
but I want the server to open a connection.
Therefore I first need a listener.
I do it with <command>phatcat</command> in x2:
			</para>
<programlisting><![CDATA[
$ phatcat -l -p 2560
]]></programlisting>
			<para>
Now I tell the server on the control connection to connect (2560=10*256+0)
			</para>
<programlisting><![CDATA[
port 172,23,2,8,10,0
200 PORT command successful.
]]></programlisting>
			<para>
Now you see, why I used port 2560.
172.23.2.8 is, of course, my own IP-address.
And now, using x1, I ask for a directory-listing
with the list command, and it appears in x2.
For completeness sake, here is the the full in/output.
			</para><para>
First the xterm 1:
			</para>
<programlisting><![CDATA[
phatcat ftpserver 21
220 ftpserver.terreactive.ch FTP server (Version 6.4/OpenBSD/Linux-ftpd-0.16) ready.
user ftp
331 Guest login ok, send your complete e-mail address as password.
pass ftp
230 Guest login ok, access restrictions apply.
pasv
227 Entering Passive Mode (172,23,2,30,169,29)
list
150 Opening ASCII mode data connection for '/bin/ls'.
226 Transfer complete.
port 172,23,2,8,10,0
200 PORT command successful.
list
150 Opening ASCII mode data connection for '/bin/ls'.
226 Transfer complete.
quit
221 Goodbye.
]]></programlisting>
			<para>
xterm 2:
			</para>
<programlisting><![CDATA[
phatcat 172.23.2.30 43293
total 7
dr-x--x--x   2 root     root         1024 Jul 26  2000 bin
drwxr-xr-x   2 root     root         1024 Jul 26  2000 dev
dr-x--x--x   2 root     root         1024 Aug 20  2000 etc
drwxr-xr-x   2 root     root         1024 Jul 26  2000 lib
drwxr-xr-x   2 root     root         1024 Jul 26  2000 msgs
dr-xr-xr-x  11 root     root         1024 Mar 15 14:26 pub
drwxr-xr-x   3 root     root         1024 Mar 11  2000 usr
]]></programlisting>
<programlisting><![CDATA[
phatcat -l -p 2560
total 7
dr-x--x--x   2 root     root         1024 Jul 26  2000 bin
drwxr-xr-x   2 root     root         1024 Jul 26  2000 dev
dr-x--x--x   2 root     root         1024 Aug 20  2000 etc
drwxr-xr-x   2 root     root         1024 Jul 26  2000 lib
drwxr-xr-x   2 root     root         1024 Jul 26  2000 msgs
dr-xr-xr-x  11 root     root         1024 Mar 15 14:26 pub
drwxr-xr-x   3 root     root         1024 Mar 11  2000 usr
]]></programlisting>
			</section>
		<section id="ftp_secure_mail">
		<title>mail on securing ftp</title>
		<para>
Joe
		</para>
		<blockquote>
I see that ftp is hard to make secure and your prime recommendation
is to have an ftp server isolated from all other machines.
Do you recommend that people not use ftp and say instead use http for LVSs
that are delivering files?
I don't like http for file download. At home (28k phone ppp link)
if I do anything else over the line (like load a webpage) while doing
a download, the download stalls and doesn't start up again. This is
pain as a 10M file takes 2hrs and I have to start again.
		</blockquote>
		<para>
Joe Cooper <emphasis>joe (at) swelltech (dot) com</emphasis> 07 May 2001
		</para>
<programlisting><![CDATA[
wget -c http://url
]]></programlisting>
		<para>
will solve that problem.
		</para>
		<para>
<xref linkend="sftp"/> is now available as part of the openssh packages I believe, but
requires clients to have a recent version of openssh -- probably
not what folks want if they have enough clients to justify an LVS
cluster.  I don't think LVS really has anything to do with whether
someone should use ftp for security reasons or not. Securing ftp is a
separate issue from securing LVS.
		</para>
		</section>
	</section>
	<section id="ssl_ftp" xreflabel="ftps, ssl based ftp">
	<title>ftps (ssl based ftp), tcp 21, 22?</title>
	<note>
This is not ftp port forwarded through ssh
(see <xref linkend="port_forwarded_ftp"/>), nor is it <xref linkend="sftp"/>.
	</note>
	<para>
From Ratz, 30 Nov 2003, see
<ulink url="http://www.stunnel.org/examples/ftp.html">
http://www.stunnel.org/examples/ftp.html FTP+SSL, FTP+TLS</ulink>.
There are two deprecated methods of doing SSL+FTP.
Make sure that what you're doing and talking about is
<ulink url="http://www.ietf.org/rfc/tfc2228.txt">
http://www.ietf.org/rfc/tfc2228.txt RFC228 ftps</ulink>.
The session starts by the client connecting to port 21 and issuing the "PROT P"
command. Quite what happens after that I don't know
(which ports, are the packets encrypted?).
	</para>
	<para>
Kai
	</para>
	<blockquote>
I am using LVS/NAT with ssl based ftp.
I can ftp via realserver by using either port
mode or passive mode.
	</blockquote>
	<para>
ratz  29 Nov 2003
	</para>
	<para>
Over the director, correct?
	</para>
	<blockquote>
For security reasons SSL based ftp was required.
After adding ssl based ftp auth to the realservers,
the client computers cannot connect to
the realserver with passive mode,
but port mode works well.
	</blockquote>
	<para>
IIRC you need to load balance port 22 too.
	</para>
	<blockquote>
I think the problem is ,data which ftp server send to client include the
server's passive port was crypted by ssl.
so the LVS don't know which port
should be translate and open.
	</blockquote>
	<para>
AFAICR this isn't the issue. The client receives the PASV command and
then translates the PORT into a local ssh tunnel forward. So I think you
have to also load balance port 22 TCP.
You can use the port 0 feature :).
	</para>
	<para>
Kai reposted this on 19 Feb 2004
	</para>
	<blockquote>
I think  the problem is,
the data which ftp server sends to the client includes the
server's passive port was crypted by SSL.
So the LVS don't know which port
should be translated and opened.
	</blockquote>	
	<para>
Horms 20 Feb 2004
	</para>
	<para>
Yes, that sounds likely. Try tracing the traffic using something like
ngrep.
	</para>
	<blockquote>
Does LVS support the SSL based FTP?
If not, is there any solution?
	</blockquote>
	<para>
If your guess is correct, then no. Well, not unless
you get the linux director to handle the ssl and just
talk plain-text to the real-servers, but then
that isn't LVS.
	</para>
	</section>
	<section id="DNS" xreflabel="DNS">
	<title>dns, tcp/udp 53 (and dhcpd server 67, dhcp client 68)</title>
	<para>
(from the IPCHAINS-HOWTO)
DNS doesn't always use UDP; 
if the reply from the server exceeds 512 bytes, 
the client uses a TCP connection to port number 53, 
to get the data. 
Usually this is for a zone transfer.
	</para>
	<para>
The <xref linkend="name_resolution"/> 
(ulink url="LVS-HOWTO.services.general.html#name_resolution")
process is broken.
It's possible for a client (resolver) to get a reply
from a hung nameserver which it interprets as "no resolution for that name", 
rather than allowing the client to go on to the next nameserver in the list. 
This is a design flaw that will take some fixing
(all the clients and all the nameservers must be fixed).
DNS should have it's own failover mechanism, but it doesn't.
In the meantime, some other failover mechanism
will have to present a perfect nameserver to the clients.
	</para>
	<para>
There is no consensus amongst people running LVS as to whether
it's best to have <filename>named/bind</filename> LVS'ed 
or to just to have a set of machines in a failover setup
(Horms, 2 Oct 2006,  is of the opinion than <command>named</command> can't be load
balanced by nature of the protocol). 
If you're running DNS in a failover setup, 
you might think that you could have one primary machine and a secondary
machine and that on failover of the primary you could promote the
secondary to be the primary. 
By design of DNS, there can only be one primary machine.
The primary and secondary have different config files and it's not simple
to programatically switch the secondary into the primary role 
(it can be done, it just requires some thinking).
A failover DNS setup then requires two machines with identical
config files, one as the master and one as the backup.
However if you have <filename>dhcpd</filename> running on the network, 
the primary name server machine will be updated continuously
with the addresses from the <filename>dhcpd</filename>, 
which the backup primary will not get. 
On failover, you will loose name resolution on these addresses until they renew their lease.
	</para>
	<para>
If you are going to LVS <filename>named</filename>, 
and are running LVS-DR or LVS-Tun, as usual make sure
your <filename>named</filename> is listening on the VIP (not the RIP). 
	</para>
	<para>
<filename>dhcpd</filename> has its own failover/redundancy mechanism. 
You can't LVS a <filename>dhcpd</filename> server - it has a database of its leases
and no other machine can have the same list.
<filename>dhcpd</filename> can be setup with multiple <filename>dhcpd</filename> 
servers on the same network and they pass the updates to each other.
Unfortunately it doesn't work - you get to a stage where one machine
will mistakenly think that another machine is incharge of all the IPs and both
machines refuse to answer requests.
The problem has been posted to the <filename>dhcpd</filename> mailing list for several 
years without any answers from the <filename>dhcpd</filename> authors.
The only thing to do when this happens is to kill all the <filename>dhcpd</filename> servers, 
erase the lease table files, touch new ones, and start the servers again. 
I went back to having only one <filename>dhcpd</filename> server and left the other one
turned off waiting as a backup. 
	</para>
	<para>
This setup for LVS'ing <filename>named</filename> is from Ted Pavlic. 
Two (independant) connections,
tcp and udp to port 53 are needed.
	</para>
	<para>
Here is part of an <filename>lvs.conf</filename> file which has dns on two realservers.
	</para>
<programlisting><![CDATA[
#dns, note: need both udp and tcp
#A realserver must be able to determine its own name.
#(log onto machine from console and use nslookup
# to see if it knows who it is)
# and to do DNS on the VIP and name associated with the VIP
#To test a running LVS, on client machine, run nslookup and set server = VIP.
SERVICE=t dns wlc 192.168.1.1 192.168.1.8
SERVICE=u dns wlc 192.168.1.1 192.168.1.8
]]></programlisting>
	<para>
If the LVS is run without mon, then any setup that allows the
realservers to resolve names is fine (ie if you can sit at the
console of each realserver and run nslookup, you're OK).
	</para>
	<para>
If the LVS is run with <command>mon</command> 
(<emphasis>e.g.</emphasis> for production), 
then dns needs to be setup in a way that <filename>dns.monitor</filename> 
can tell if the LVS'ed form of dns is working. 
When <filename>dns.monitor</filename> tests a realserver for valid dns service, 
it first asks for the zone serial number from the authoritative (SOA) nameserver 
of the virtualserver's domain. 
This is compared with the serialnumber
for the zone returned from the realserver. 
If these match then <filename>dns.monitor</filename> 
declares that the realserver's dns is working.
	</para>
	<para>
The simplest way of setting up an LVS dns server is for the
realservers to be secondaries (writing their secondary zone info
to local files, so that you can look at the date and contents of
the files) and some other machine
(<emphasis>e.g.</emphasis> the director) to be the
authoritative nameserver. Any changes to the authoritative
nameserver (say the director) will have to be propagated to the
secondaries (here the realservers) (delete the secondary's zone files
and HUP <filename>named</filename> on the realservers). After the HUP, new files will be
created on the secondary nameservers (the realservers) with the time of
the HUP and with the new serial numbers. If the files on the
secondary nameservers are not deleted before the HUP, then they
will not be updated till the refresh/expire time in the zonefile
and the secondary nameservers will appear to <filename>dns.monitor</filename>
to not be working.
	</para>
	<para>
LVS is no better than DNS for the same number of working DNS servers.
However if a DNS server fails...
	</para>
	<para>
Nick Burrett <emphasis>nick (at) dsvr (dot) net</emphasis> 20 Jan 2004
	</para>
	<para>
Consider a client with a <filename>resolv.conf</filename> with IPs:
	</para>
<programlisting><![CDATA[
10.0.0.10
10.0.0.11
]]></programlisting>
	<para>
If 10.0.0.10 is taken offline, then the client
application's speed at getting domains resolved is drastically reduced,
because the resolver library will always query 10.0.0.10 before querying
10.0.0.11.
Sticking DNS behind LVS alleviates this.
Monitoring software will failout the dead DNS realserver.
	</para>
	<para>
anon
	</para>
	<blockquote>
I'm planning to put my company's dns on lvs with ha.
	</blockquote>
	<para>
Greg Woods <emphasis>woods (at) ucar (dot) edu</emphasis> 30 Aug 2002
	</para>
	<para>
Unless you have a really unusual situation, I think using LVS for
DNS is massive overkill. There is no way that DNS load should
overwhelm a single server. If it does, you probably are in dire
need of some subdomains.  What I do here is just use the heartbeat
code so that the hot spare backup machine will take over if
the primary goes down, and I do have a restart script that uses
scp to move the data files that have been modified over to the
backup machine. scp is called out of a script that will keep
trying the scp until it succeeds, in case the backup machine
is down at the time a change is made. This seems to work for us.
	</para>
	<para>
I do use LVS for our mail system, but then, the mail system does
anti-spam IP address blacklist checking, and virus scanning. That
means the overhead of establishing a connection through LVS is small
compared to the load on the server to process a connection. I don't
think this is the case for DNS.
	</para>
	<para>
Jeff Kilbride
	</para>
	<blockquote>
Does anybody else agree that 
load balancing DNS servers with LVS is not worthwhile?
	</blockquote>
	<para>
Peter Mueller <emphasis>pmueller (at) sidestep (dot) com</emphasis> 2005/04/18
	</para>
	<para>
Yes, for authorative.  
ISC-bind has some kind of response-latency measurement built-in. 
For client side, LVS is useful.  
In the event of the first server in <filename>/etc/resolv.conf</filename> 
failing, there's a 2 second timeout that can be avoided.
	</para>
	<para>
If you're LVS'ing named, you may wind up with many VIP's on your director.
	</para>
	</section>
	<section id="samba" xreflabel="samba">
	<title>samba, udp 137, udp 138, tcp 139, tcp 445</title>
	<para>
The problems to be solved with setting up an LVS'ed samba are
	</para>
	<itemizedlist>
		<listitem>
it's peer-to-peer (rather than client-server)
		</listitem>
		<listitem>
you have to authenticate users 
		</listitem>
		<listitem>
if clients can write to the samba'ed disks, you have to propagate the
updates to the other realservers.
		</listitem>
	</itemizedlist>
		<section id="Fred_Lacombe">
		<title>Fred Lacombe's LVS-Samba HOWTO</title>
		<para>
Lapin(c) <emphasis>lapin (at) linagora (dot) com</emphasis> 04 Mar 2004
		</para>
		<para>
Here is a draft for an
<ulink url="http://www.lapinux.org/howto/">LVS-Samba HOWTO</ulink>
(http://www.lapinux.org/howto/)
that load balances Samba with LVS-NAT.
There are still modifications to add and some tricks to point out,
but all feedback will be helpful.
		</para>
		<para>
I just tried to make the samba realservers invisible to each other with
<command>iptables</command> rules.
The only visible machines are an LDAP server and the director.
It still has some (undocumented) drawbacks,
but I can authenticate against 2 samba realservers
and I can access shares on each of them (directly in their filesystem).
Unsolved is the problem of sync for the shares: I've
thought about a SAN, or some DRBD cross definition.
I still to solve this.
		</para>
		<blockquote>
Joe: This is big news. I haven't read all of Fred's docs yet,
or set one of these up, but Fred seems to have solved the many reader/
single writer problem by having a single LDAP database for all Samba
servers and by having (or assuming) a single file system for the shares.
		</blockquote>
		</section>
		<section id="will_mcdonald">
		<title>Will McDonald's setup</title>
		<para>
Will McDonald <emphasis>wmcdonald (at) gmail (dot) com</emphasis> 21 Mar 2006
		</para>
		<para>
We have a simple Samba share available on some systems sat behind a
pair of LVSs. 
We have 2 directors in Active/Passive NATing through to two realservers
running Heartbeat in Active/Passive. So only one of the realservers
has the Heartbeat managed VIP the LVSs NAT through to at any one time.
I know for our purposes the realservers could just sit on the same
subnet as our other servers but this is an inherited setup and there
are other reasonable reasons for it to be like this. Samba's not the
realservers *primary* role, there are other services too. The reason
they're Active/Passive is because DRBD devices can only be mounted on
one node at any one time.
		</para>
		<para>
The LVSs are running CentOS4 and the repackaged
Ultramonkey packages out of the CentOS Extras repository
		</para>
<programlisting><![CDATA[
heartbeat-ldirectord-1.2.3.cvs.20050927-1.centos4
heartbeat-stonith-1.2.3.cvs.20050927-1.centos4
heartbeat-pils-1.2.3.cvs.20050927-1.centos4
heartbeat-1.2.3.cvs.20050927-1.centos4
]]></programlisting>
		<para>
		</para>
<programlisting><![CDATA[
ipvsadm: #

TCP  192.168.24.45:445 rr persistent 600
  -> 192.168.25.10:445            Masq    1      2          0
TCP  192.168.24.45:139 rr persistent 600
  -> 192.168.25.10:139            Masq    1      0          0
UDP  192.168.24.45:137 rr persistent 600
  -> 192.168.25.10:137            Masq    1      0          0
UDP  192.168.24.45:138 rr persistent 600
  -> 192.168.25.10:138            Masq    1      0          0
]]></programlisting>
		<para>
The <filename>ldirectord.cf</filename> on the LVSs looks as follows...
		</para>
<programlisting><![CDATA[
# TEST SAMBA THROUGH TO DBVIP
virtual=192.168.24.45:137
        real=192.168.25.10:137 masq
        service=none
        scheduler=rr
        persistent=600
        protocol=udp
# TEST SAMBA THROUGH TO DBVIP
virtual=192.168.24.45:138
        real=192.168.25.10:138 masq
        service=none
        scheduler=rr
        persistent=600
        protocol=udp
# TEST SAMBA THROUGH TO DBVIP
virtual=192.168.24.45:139
        real=192.168.25.10:139 masq
        service=none
        scheduler=rr
        persistent=600
        protocol=tcp
# TEST SAMBA THROUGH TO DBVIP
virtual=192.168.24.45:445
        real=192.168.25.10:445 masq
        service=none
        scheduler=rr
        persistent=600
        protocol=tcp
]]></programlisting>
		<para>
The back-end boxes are FC3 running Ultramonkey packages again, and
DRBD for disk replication.
		</para>
<programlisting><![CDATA[
heartbeat-stonith-1.2.3-2.fr.c.1
heartbeat-pils-1.2.3-2.fr.c.1
heartbeat-1.2.3-2.fr.c.1
]]></programlisting>
		<para>
Samba startup is handled from /etc/ha.d/haresources by simply
including "smb" as a resource which starts/stops on failover. The
smb.conf's very simple too...
		</para>
<programlisting><![CDATA[
[global]
        server string = Samba on %h
        hosts allow = 192.168.24.
        log file = /var/log/samba/%m.log
        max log size = 5000
        security = share
        socket options = TCP_NODELAY SO_RCVBUF=8192 SO_SNDBUF=8192
        interfaces = 192.168.25.6/32 192.168.25.10/32
        dns proxy = no
[ftp]
        comment = Test FTP Homes
        browseable = yes
        writeable = yes
        guest ok = yes
        path = /mnt/sharedhomes/
]]></programlisting>
		<para>
This has been pretty reliable but it's not high volume by any stretch
of the imagination. Nor is it attached to a domain so I'm not sure how
you'll get on with browser mastering etc.
		</para>
		</section>
		<section id="samba_early_history">
		<title>early attempts to LVS samba</title>
		<para>
The topic of serving samba on an LVS was first raised by
John Rodkey <emphasis>rodkey (at) wesmont (dot) edu</emphasis>
who wondered if he could serve 300 w2k machines with samba/LVS.
Not knowing much about SMB I put out a request for help on
<emphasis>samba-technical (at) lists (dot) samba (dot) org</emphasis>.
I got replies from several people,
including the samba developer Chris Hertal,
and from Ryan Fox
(who had setup an LVS and who had even read the LVS-HOWTO).
I also got a free 2hr phone tutorial by John Terpstra
<emphasis>jht (at) samba (dot) org</emphasis> on 26 Oct 2001.
One of the big problems is that samba is peer-peer,
while LVS works with server-client connections.
Wensong has said on the mailing list that you can use samba in
read-only mode over LVS,
but this will not be of much use to a bunch of windows boxes.
		</para>
		<para>
Apparently there's a lot of interest in the commecial world
in highly available samba clustering
and some effort has been put into making LVS work with samba,
by people who don't come up on the LVS mailing list.
No-one has succeeded and now it's generally thought
that LVS is not the way to go.
		</para>
		<para>
Here's John's tutorial as I copied it down over the phone.
Thanks John for your help and time.
		</para>
		</section>
		<section id="samba_for_unix_people">
		<title>Attitude adjustment zone for unix people.</title>
		<itemizedlist>
			<listitem>
	cifs==smb (two names for the same thing)
			</listitem>
			<listitem>
For more information on cifs/smb
see ftp://ftp.samba.org/pub/samba/specs "samba ftp docs"
(Sep 2002 link is dead).
You'll need to go to a mirror site.
			</listitem>
		</itemizedlist>
		<para>
Microsoft's clustering service is derived from the DEC Wolfpack,
which was originally a bulletproof, all things to all men, industrial
strength, cluster and failout framework.
Microsoft is using the part of Wolfpack
that corresponds to Linux-HA.
		</para><para>
Most communication between windows machines in setting up logins, finding
resources (printers, disks, network) is between peers,
rather than server/client as for unix.
Any machine then will be able to find the resources on the network,
whereas in unix, the clients have to find out
by some mechanism external to the host
(<emphasis>e.g.</emphasis>phone up the sysadmin).
The same ports are used at both ends and communication
is usually by broadcast (at least initially).
Thus there is no distinction between a samba server and a samba client.
One host may have the files the user wants and to unix people,
this host would be the server. But in windows there are two peers:
one machine has a file and the other machine may want it - the role
can in principle be reversed without any change in the setup.
Election amongst peers is used to determine who will have the role
of knowing the location of other resources
(<emphasis>e.g.</emphasis> becoming the domain node controller).
Unlike unix where you setup a machine deliberately to be a server,
by setting up demons listening on a socket,
with windows you cannot be guarantee that a
certain machine will assume a particular role.
You can bias the election
(<emphasis>e.g.</emphasis> machines which have been up longer have more weight),
but you can't rig the election. If you have to bring a machine
down, it's down and it's less likely to win any new elections
(possibly for a long time).
In a LVS clustered samba setup (if such a thing could be made to exist),
a long running client machine out on the
internet might win the election and assume the role of locator service.
		</para><para>
Communication between machines using IP, is in fact encapsulating
netware (if running Novell) or netbuei datagrams inside IP.
Samba uses netbios over IP.
		</para><para>
To unix people the network is sometimes thought of as a hardware layer.
To windows, the network is a netbios messaging layer.
Two windows machines could be connected by several protocols
(netbuei, netbios, tcpip) over the same piece of wire (ethernet).
These connections are regarded as being separate and independant networks -
<emphasis>i.e.</emphasis> they use different names for the machines at each end.
		</para>
		</section>
		<section id="samba_resource_cloud">
		<title>the kernel resources are a cloud which receives broadcast messages</title>
		<para>
Here is an application talking to the kernel in windows.
		</para>
<programlisting><![CDATA[
 ----------
|          |
|   app    |
|          |
 ----------
     |
     |   user space
__________________
     |
     |   kernel space
     |
 ----------
|          |
| WIN32API |  communicates with cloud by broadcast messages
|          |
 ----------
     |
/--------------------------------------------\
| CLOUD                                      |
| replies to bcast messages from WIN32API    |
|                                            |
|  ---------   ---------   ------------      |
| |         | |         | |            |     |
| | locator | | SMB API | | redirector |     |
| | service | |         | |            |     |
|  ---------   ---------   ------------      |
|                                            |
|                                            |
|  ---------   -----------   -----------     |
| | file    | | local     | | remote    |    |
| | system  | | procedure | | procedure |    |
| | drivers | | calls     | | calls     |    |
|  ---------   -----------   ------------    |
|                                            |
\--------------------------------------------/
]]></programlisting>
		<para>
WIN32API - all communication with cloud is by broadcast. The
appropriate box from the cloud will reply.
There is no direct connection to drivers as in unix,
where the kernel asks the disk driver to "open file X"
(on behalf of the application).
		</para><para>
SMB API - nothing happens in windows without SMB being involved.
		</para><para>
locator - knows where resources (printers, disks, network connections) are
		</para><para>
redirector - sends services.
		</para><para>
resolver - uses SMB messages to find out where to go.
		</para><para>
netware - messes everything up, it's incompatible with the rest of the kernel
(<emphasis>e.g.</emphasis> as you'll find if you try to connect by netware _and_ tcpip).
		</para><para>
let's look a little more closely
		</para>
<programlisting><![CDATA[
 ----------
| win32api |
 ----------
     |
 ---------
| sbm api |
 ---------
     |
 ---------
| Netbios |
|   api   |
 ---------
]]></programlisting>
		<para>
SMB has to decide if request is local or remote
		</para>
		<itemizedlist>
			<listitem>
local - passes call to local PC. anything local has a name like
/DEVICE/xxx
			</listitem>
			<listitem>
remote - these have UNC names \\SERVER\share\path\filename
			</listitem>
		</itemizedlist>
		<para>
Netbios converts SMB message to a netbios datagram and puts it
on the wire as a netbuei or netware message when running IP.
		</para><para>
SMB uses netbios over tcpip (not netbios or netware). It uses
3 ports
		</para>
		<itemizedlist>
			<listitem>
udp 137 - netbios nameservice (==WINS). WINS namespace is flat, rather than hierachial like DNS.
			</listitem>
			<listitem>
udp 138 - browse list (<emphasis>i.e.</emphasis> network neighbourhood)
			</listitem>
			<listitem>
tcp 139 - persistent connection to other machine: session traffic, printing, filesharing.
			</listitem>
		</itemizedlist>
		<para>
Every client has to be able to find the <emphasis>local master browser</emphasis>,
(domain master browser != local master browser).
This could be any machine.
Election is conducted by broadcast over udp 137,138 (the election
can be biased, but the outcome cannot be forced/guaranteed).
What we think of as the samba server, may not win.
Broadcast udp will not go over a router, so if the network is
routed, then tcp unicast is used for the election (as well
as udp broadcasts), telling client to use WINserver (which will
be a samba machine or NTWINserver).
		</para>
		</section>
		<section id="samba_connecting_to_cluster">
		<title>connecting to the cluster, windows style</title>
		<para>
When a new windows machine comes on the net (<emphasis>e.g.</emphasis> an
smb client or our samba server), it needs to establish that
it has a unique name.
Name space is handled by contest.
The machine udp broadcasts its name (<emphasis>e.g.</emphasis> JACK)
4 times at 200msec interval and asks "who is local master browser?".
A samba server will announce that it is "JILL".
If there is another machine of the same name already, it will
send back a &lt;NACK&gt;.
If there are no &lt;NACK&gt;s, the local master
browser will accept the name. The client will register
its name by udp broadcast (or possibly tcp unicast) with the
WINserver, into the workgroup or domain.
		</para><para>
The user will then see something in "network neighborhood".
The client machine will do a udp 138 unicast to the local master
browser "give me browse list enumeration" (the local
master browser has information from the domain master browser too).
		</para><para>
On a multisegmented, routed network, each segment has its own
local master browser. One machine will be both a local master browser
and a domain master browser.
		</para><para>
If the user clicks on a machine in "network neighbourhood"
(and is using WINserver), the client machine will send a
"name lookup request" (like a DNS request)
- a netbios unicast request to udp 137 on the local master browser
and get the IP of the machine.
The client registers (includes services available) with the other
machine.
		</para><para>
The client machine will then send a tcp 139 "session setup request",
and then sets up a netbios connection over tcp to IPC$share on the machine.
This setup involves an SMB "net_prot" (negotiate
protocol) exchange to setup protocol(s) and establish whether the client
can use long filename support and UC/lc letters.
		</para><para>
The client has connected with an empty username and passwd at this stage.
The client now authenticates and receives back a list of printers, files
and is given a persistent connection. The original (passwdless) connection
is pulled down.
		</para><para>
After 10-15mins of inactivity, the client kernel may elect to drop its session
(even if an application is in the middle of editing an open file on the remote machine).
The application has no knowlege of this disconnect. When something
happens in the application again (or you click on network neighbourhood etc),
the session will be renegotiated.
		</para><para>
If the remote machine has gone down in the mean time
or the client is connected to our hypothetical samba LVS
and is redirected to a new samba server
(which doesn't know anything about the client's original connection),
the user will get a message that the connection cannot be re-established
and that the user will have to exit from the application
(without saving the edits).
Ha-ha, just kidding - that's what you should get - you'll actually get the BSOD.
		</para>
		</section>
		<section id="samba_with_distributed_filesystem">
		<title>Samba using a distributed filesystem on the realservers</title>
		<para>
Kai Suchomel1 <emphasis>KAISUCH (at) de (dot) ibm (dot) com</emphasis> 12 Jun 2006
		</para>
		<para>
The Samba Service uses a SAN Filesystem, here
GPFS. This File system is shared among all the Samba Services on the RS.
When I connect to VIP and the SAN Filesystem, the client
can connect to any realserver.
When the RS fails, after doing a reconnect, the Client can access the SAN
Filesystem over another RS.
		</para>
		</section>
	</section>
	<section id="xdmcp">
	<title>xdmcp, X-window, udp 177 (xdmcp), tcp 6000 (and ssh X-forwarding)</title>
	<note>
	<para>
Multiple ports are involved here. However you don't have to LVS all the ports.
As far as LVS is concerned, only port 177 needs to be LVS'ed.
However you have to know about all the ports to get xdmcp to work, 
so it's in the multi-port services section.
	</para>
	</note>
	<para>
Not so long ago, a common practice was to serve all applications
from a central server to a diskless X-terminal (like an NCD) which
ran an X-server from ROM. User's files were backed up centrally.
Upgrades/fixes to applications for 100s of clients was a matter of writing the
new files to the single, large, reliable central server.
The fixes appeared simultaneously for all clients.
We've all realised the fundamental flaw in this setup and
now we have the applications running on several 100 desktop machines,
where upgrades and fixes can take weeks to propagate.
The fix to the fix is to run thin clients on the desktops
(no wait, didn't we already do that one).
	</para>
		<section>
		<title>X - attempt 1, connecting directly to X being served by the LVS</title>
		<para>
		<warning>
		This method does not work
		</warning>
		</para>
		<para>
X window is another client-server protocol. 
The X-client asks for a connection to the X-server 
by calling from ports starting at 6000 
and the server will start displaying X images on its display. 
If you don't think about it too much, it seems that X should work through LVS. 
However
		</para>
		<para>
Lidsa <emphasis>lidsa (at) legend (dot) com (dot) cn</emphasis> 24 Apr 2002
		</para>
		<blockquote>
..but the realserver is the X-client and the X-server does not reside on the realserver.
So I think it impossible for LVS to forward X-window.
		</blockquote>
		<para>
If you connect from your LVS client to VIP:telnet on an LVS-DR (you will
now be connected to one of the realservers) and start xclock on the realserver,
you'll get the xclock image on the lvs client (provided that you have a direct
connection also between the realserver and the client).
If you look with <command>netstat -an</command>
you'll find that RIP:1025 is ESTABLISHED with CIP:6000.
Yes, the LVS client is the X-server - it is not the X-client.
The realserver is the X-client.
You can't use LVS to forward X-sesssions.
		</para>
		</section>
		<section>
		<title>X - attempt 2, connecting to LVS:xdmcp</title>
		<para>
This method is most like the login from a diskless xterm.
		</para>
		<para>
Severin Olloz showed that you can use an LVS to serve X-sessions
by running xdmcpd on the realservers.
Severin had problems initially with some logins locking up, 
but this apparently was due to a misconfiguration of one
of his realservers.
		</para>
		<para>
When I tried it, I was still able to login from the lvs client after leaving the
connection idle for a few hours at the xdm login screen.
After leaving the nodes idle overnight I couldn't
get a login at the LVS client anymore.
On one occasion xdm was running on the node corresponding to
the login shown on the client. I restarted xdm on that
node and could connect again. On another occasion xdm had
died on one of the realservers and the client was just showing
the background color for the X-window and a functional mouse,
but no xdm login screen. The connections to port 6000 on the
lvs client were also gone. I restarted xdm on all the realservers
and restarted the client ("X :1 -query VIP") but did not
get the xdm login screen. I could connect after running ipvsadm
again.
		</para>
		<para>
Presumably timeouts will need to be explored to make a working
xdmcp LVS.
		</para>
		<para>
Severin Olloz <emphasis>S (dot) Olloz (at) soid (dot) ch</emphasis> 30 Apr 2002
		</para>
		<blockquote>
		<para>
I have set up an LVS-DR X11-Server. The LVS client makes a
XDMCP-Query with a command like this:
		</para>
<programlisting><![CDATA[
X :1 -query VIP
]]></programlisting>
		<para>
and the director of the cluster sends the UDP packets on port 177 (XDMCP) to
the realserver. The realserver accepts the request and opens a X11-session
for the user. (Note: the realserver is opening a direct connection to CIP:600x
- this is not under control of the LVS. The LVS client and the realserver must
be able to exchange packets directly.)
My <command>ipvsadm</command> table looks like this:
		</para>
<programlisting><![CDATA[
director:~# grep xdmcp /etc/services
xdmcp           177/tcp                         # X Display Manager Control Protocol
xdmcp           177/udp
]]></programlisting>
		<para>
		</para>
<programlisting><![CDATA[
IP Virtual Server version 1.0.2 (size=4096)
Prot LocalAddress:Port Scheduler Flags
  -> RemoteAddress:Port        Forward Weight ActiveConn InActConn
UDP  VIP:xdmcp wlc persistent 360
  -> node1:xdmcp                  Local   100    0          0
  -> node2:xdmcp                  Route   100    0          0
]]></programlisting>
		<para>
The director is a realserver too, using localnode.
		</para>
		</blockquote>
		<para>
Here's more details I discovered when I reproduced Severin's setup.
		</para>
		<para>
For info on XDMCP,
see the <ulink url="http://www.tldp.org/HOWTO/XDMCP-HOWTO/">Linux XDMCP HOWTO</ulink>
and the many links provided therein.
		</para>
		<para>
In this method, X-clients on the realservers connect directly
to the X-server on the LVS client. The LVS is only used
for xdmcp authentication. Once this step has been accomplished,
the LVS steps out of the way and the X-session is between the
realserver selected and the client.
The client then must be able to send packets directly to the RIP on the
realserver. In a normal LVS-DR, the RIP is not routable
from the lvs client. The RIPs will have to be routable or public IPs.
		</para><para>
For a test, first connect directly from your lvs client box to a realserver
(no director or LVS involved yet).
Setup your xdm-config, Xaccess files on the realserver(s)
as described in the XDMCP HOWTO and check the permissions of Xservers and Xsetup_0.
Make sure xdm is running on the realserver
(the XDMCP-HOWTO does this via the inittab file,
but you can just fire it up from the command line for a test).
Check that xdm is running
		</para>
<programlisting><![CDATA[
RS1:/etc# ps -auxw | grep xdm
root       329  0.0  1.7  2892 1088 ?        S    11:40   0:00 xdm
root       331  0.5  3.9  5612 2456 ?        S    11:40   0:01 /usr/X11R6/bin/X -auth /usr/X11R6/lib/X11/xdm/authdir/authfiles/A:0-Z
]]></programlisting>
		<para>
Run the next command.
If you don't have X running, it will be started for you.
If your LVS client is displaying an X-window
(<emphasis>i.e.</emphasis> you ran `startx`)
then the client at the other end will overwrite your current X-session.
		</para>
<programlisting><![CDATA[
client# X :1 -query RIP
]]></programlisting>
		<para>
The original window manager screen should disappear on your client box to
be replaced by the xdm login from the realserver.
If you just have a blank screen on the client, with a mouse X but
no login box, check that xdm is running on the realserver.
After you login, you get the window manager set in /etc/X11/xdm/Xsessions.
In the default Xsession file, xsm is used which defaults (see man xsm)
to running twm with smproxy and an xterm. This is pretty gruesome,
so I substituted xsm with my window manager, fvwm2. Here's part of Xsession.
		</para>
<programlisting><![CDATA[
if [ -f "$startup" ]; then
        exec "$startup"
else
        if [ -f "$resources" ]; then
                xrdb -load "$resources"
        fi
        #exec xsm
        exec /usr/X11/bin/fvwm2
fi
]]></programlisting>
		<para>
From the console on the client,
you can see the connections from the realserver back
to the X-server on the client.
		</para>
<programlisting><![CDATA[
client# netstat -an
Active Internet connections (including servers)
Proto Recv-Q Send-Q Local Address           Foreign Address         State
tcp        0      0  client:6001            realserver:1067         ESTABLISHED
tcp        0      0  client:6001            realserver:1066         ESTABLISHED
tcp        0      0  client:6001            realserver:1065         ESTABLISHED
tcp        0      0  client:6001            realserver:1063         ESTABLISHED
tcp        0      0  client:6001            realserver:1059         ESTABLISHED
tcp        0      0 0.0.0.0:6001            0.0.0.0:*               LISTEN
tcp        0      0 0.0.0.0:6000            0.0.0.0:*               LISTEN
.
.
Active UNIX domain sockets (including servers)
Proto RefCnt Flags       Type       State         I-Node Path
unix  1      [ ACC ]     STREAM     LISTENING     399263 /tmp/.X11-unix/X1
.
]]></programlisting>
		<para>
Now set up the director to forward xdmcp/udp and connect to VIP:xdmcp.
Note: I'm not using persistence, while Severin is. Non-persistence seems
to work for an LVS of 4 realservers.
		</para>
<programlisting><![CDATA[
client# X :1 -query VIP
]]></programlisting>
Here's the output of <command>ipvsadm</command> after connecting
<programlisting><![CDATA[
director:~# ipvsadm
IP Virtual Server version 0.9.4 (size=4096)
Prot LocalAddress:Port Scheduler Flags
  -> RemoteAddress:Port           Forward Weight ActiveConn InActConn
UDP  lvs.mack.net:xdmcp rr
  -> RS4.mack.net:xdmcp           Route   1      0          1
  -> RS3.mack.net:xdmcp           Route   1      0          0
  -> RS2.mack.net:xdmcp           Route   1      0          0
  -> RS1.mack.net:xdmcp           Route   1      0          0
]]></programlisting>
		<para>
<command>`netstat -an`</command>
doesn't show any connections to the VIP (it's udp afterall),
but the connections to the X-server ports on the client are seen along
with the entry for X1.
Once you have logged in via xdm,
the client and realserver are connected directly and LVS is not involved anymore.
After you logout from the X-session at the client, and return to the XDMCP
login screen, the connections to port 600x are gone.
		</para><para>
After exiting from an X-session the client will be presented
with a new xdm login screen.
Watching with tcpdump shows the following steps following
the termination of an X-session.
		</para>
		<itemizedlist>
			<listitem>
many packets are exchanged between RIP:high port and CIP:6001,
presumably repainting the login screen.
			</listitem>
			<listitem>
single udp packet from CIP:high_port to VIP:xdmcp is forwarded to
realserver. (The director has no further role after this).
			</listitem>
			<listitem>
2.5 secs later, an exchange of two pairs of udp packets between RIP:xdmcp and
CIP:high_port.
			</listitem>
			<listitem>
the login screen appears on the LVS client and the InActConn
counter is incremented in ipvsadm.
			</listitem>
			<listitem>
if you wait here, the InActConn counter (ipvsadm) decrements in about 3mins.
If you login and out before the timer decrements, you are returned to the same
realserver. If you disconnect after the timeout, you are reconnected with the next realserver.
			</listitem>
			<listitem>
Whether you wait or not, when you enter your name/passwd,
no further packets are passed by udp/xdmcp.
Instead, there is another flood of tcp packets from RIP:high_port to CIP:6001.
			</listitem>
		</itemizedlist>
		<para>
It appears that xdmcp only presents the login screen and that login occurs
via the X connection later. If both painting the login screen initially and
(after the timeout on the director, about 3mins) sending the name/passwd used xdcmp,
then it's possible that the login data could be sent to a different host
that painted the screen. This apparently can't happen. (Joe, May 2004: I have no
idea why I said that this "apparently can't happen.)
		</para>
		<para>
You could setup an xterm farm with this using a bunch of diskless 486 PCs with
16M memory.
		</para>
		</section>
		<section>
		<title>X - attempt 3, X-forwarding with ssh and connecting to LVS:sshd</title>
		<para>
In this method, you have your window manager running on your LVS client
and you are displaying realserver X-clients
on the X-server running on your LVS client.
		</para>
		<para>
To setup, on the realserver, have the entry "X11Forwarding yes" in sshd_config
(re-HUP sshd if neccessary).
On the client, have the entry "ForwardX11 yes" in ssh_config.
If you like, as a test, ssh (with <command>`ssh -v`</command>)
directly from the client box to the realserver
(not to the VIP) as if you were doing a regular ssh login.
After login, look to see that X-forwarding is turned on by
looking at the DISPLAY variable.
		</para>
<programlisting><![CDATA[
.
- verbose output from login with `ssh -v remote_node` -
.
debug1: channel_free: channel 1: status: The following connections are open:
  #0 client-session (t4 r0 i1/0 o16/0 fd 4/5)
  #1 x11 (t4 r2 i8/0 o128/0 fd 7/7)
realserver:~# echo $DISPLAY
realserver:10.0
realserver:~#
]]></programlisting>
		<para>
		<note>
"realserver" is the name of the machine you have logged into (it might be "localhost").
The name you get will <emphasis role="bold">NOT</emphasis> be the name of the
machine with the X-server that will be displaying the X (as would normally happen with
non-forwarded X connections). Here your X-server is the lvs client.
		</note>
The $DISPLAY variable is showing where X-clients running on the realserver
will send their output.
In this case "realserver:10.0" is a proxy X-server running on the remote machine,
which will forward the X-calls to the X-server running on the lvs client machine
(the output will not go to the realserver).
If you now run `xclock` on the realserver, 
it will be displayed on the lvs client machine.
		</para>
		<para>
Next setup your director to forward ssh.
For more info see the section on
<xref linkend="sshd"/>.
In particular make sure all the host keys
on the realservers are identical.
Connect to VIP:sshd.
You should now be able to start X-clients apparently running on the
VIP (but really running on the realserver).
		</para>
		</section>
	</section>
	<section id="rshd_multiport">
	<title>r commands; rsh, rcp, and their ssh replacements, tcp 513 (,514) and another connection</title>
	<para>
An example of using rsh to copy files is in
<ulink url="http://www.linuxvirtualserver.org/Joseph.Mack/performance/single_realserver_performance.html">performance data for single realserver LVS</ulink> Sect 5.2,
	</para>
	<note>
Caution: The matter of rsh came up in a private e-mail exchange. The
person had found that rshd, operating as an LVS'ed service,
initiated a call (rsh client request) to the rshd running on the LVS client.
(See Stevens &quot;Unix Network Programming&quot; Chapter 14, which explains rsh.)
This call will come from the RIP rather than the VIP.
This will require rsh to be run under LVS-NAT or else
the realservers must be able to contact the client directly.
Similar requests from the <xref linkend="LVS-HOWTO.authd"/> client
and <link linkend="passive_ftp">passive ftp</link> on realservers
cause problems for LVS.
	</note>
	<para>
David Lambe <emphasis>david (dot) lambe (at) netunlimited (dot) com</emphasis> Mon, 13 Nov 2000
	</para>
	<blockquote>
I've recently completed "construction" of a LVS cluster consisting of 1 LVS
and 3 realservers. Everything seems to work OK with the setup except for rcp.
All it ever gives is "Permission Denied" when running rcp blahfile node2:/tmp/blahfile
from a console on  node1.
Both rsh and rlogin function, BUT require the password to be entered twice.
	</blockquote>
	<para>
Joe
	</para>
	<para>
sounds like you are running RedHat. You have to fix the pam files.
The beowulf people have been through all of this.
You can either recompile the r* executables without pam
(my solution), or you can fiddle with the pam files.
For suggestions, go to the beowulf mailing archives -
you have to download the
whole archive at
<ulink url="http://www.beowulf.org/pipermail/beowulf/">whole archive</ulink>
and grep through it.
	</para>
	<para>
If you go to the beowulf site, you'll find people are moving to replace
rsh etc with ssh etc on sites which could be attacked from outside
(and turning off telnet, r* etc). For examples setup files for ssh
see the section on <link linkend="sshd">sshd</link>.
	</para>
	</section>
	<section id="streaming_media">
	<title>Streaming Media: RealNetworks, Quicktime, Windows Media Server, tcp/udp 554 (and other ports)</title>
		<section id="real_networks">
		<title>RealNetworks streaming protocols, tcp 554, many ports</title>
		<para>
Jerry Glomph Black <emphasis>black (at) real (dot) com</emphasis> August 25, 2000
		</para>
		<para>
RealNetworks' streaming protocols are
		</para>
		<itemizedlist>
			<listitem>
		PNM (TCP on port 7070, UDP from server -&gt; player on ports 6970-7170).
PNM was the original protocol in version 1 through 5. It's now mostly legacy.
			</listitem>
			<listitem>
RTSP (TCP on port 554, similar UDP as above, but often on multiple ports)
With the G2 release, we adopted the RTSP delivery standard. The current
version, RealPlayer 8 came out about two weeks ago. A free one is
available to run on just about any platform in common use today. The Linux
versions are great.
			</listitem>
			<listitem>
There's also a HTTP/TCP-only fallback mode which is (usually) on port 8080.
			</listitem>
		</itemizedlist>
		<para>
The server configuration can be altered to run on any port, but the above
numbers are the customary, and almost universally-used ones.
		</para>
		<para>
Mark Winter, a network/system engineer in my group wrote up the following
detailed recipe on how we do it with LVS:
		</para>
		<para>
add IP binding in the G2 server config file
		</para>
<programlisting><![CDATA[
<List Name="IPBindings">
     <Var Address_1="<real ip address>"/>
     <Var Address_2="127.0.0.1"/>
     <Var Address_3="<virtual ip address>"/>
</List>

On the LVS side
./ipvsadm -A -u <VIP>:0  -p
./ipvsadm -A -t <VIP>:554  -p
./ipvsadm -A -t <VIP>:7070  -p
./ipvsadm -A -t <VIP>:8080  -p

./ipvsadm -a -u <VIP>:0 -r <REAL IP ADDRESS>
./ipvsadm -a -t <VIP>:554 -r <REAL IP ADDRESS>
./ipvsadm -a -t <VIP>:7070 -r <REAL IP ADDRESS>
./ipvsadm -a -t <VIP>:8080 -r <REAL IP ADDRESS>
]]></programlisting>
		<para>
(Ted)
		</para><para>
I just wanted to add that if you use FWMARK, you might be able to make it a
little simpler and not have to worry about forwarding EVERY UDP port.
		</para>
<programlisting><![CDATA[
# Mark packets with FWMARK1
ipchains -A input -d <VIP>/32 7070 -p tcp -m 1
ipchains -A input -d <VIP>/32 554 -p tcp -m 1
ipchains -A input -d <VIP>/32 8080 -p tcp -m 1
ipchains -A input -d <VIP>/32 6970:7170 -p udp -m 1

# Setup the LVS to listen to FWMARK1
director:/etc/lvs# ipvsadm -A -f 1 -p

# Setup the realserver
director:/etc/lvs# ipvsadm -a -f 1 -r <RIP>
]]></programlisting>
		<para>
Not only is this only six lines rather than eight, but now you've setup a
persistent port grouping. You do not have to forward EVERY UDP port, and
you're still free to setup non-persistent services (or other persistent
services that are persistent based on other ports).
		</para><para>
When you want to remove a realserver, you now do not have to remove FOUR
realservers, you just remove one. Same thing with adding. Plus, if you want
to change what's forwarded to each realserver, you can do so with ipchains
and not bother with taking up and down the LVS. ALSO... if you have an
entire network of VIPs, you can setup IPCHAINS rules which will forward the
entire network automatically rather than each VIP one by one.
		</para><para>
Jerry Glomph Black <emphasis>black (at) prognet (dot) com</emphasis> 07 Jun 2001
		</para><para>
Following is a currently-operational configuration for
LVS balancing of a set of 3 RealServers (or Real Servers, in LVS-terminology)
It has been running at very high loads (thousands of simultaneous
connections) for months, in addition to numerous conventional LVS
setups for more familiar web load-balancing at massive loads.
		</para>
<programlisting><![CDATA[
#!/bin/sh
# LVS initialization for RealNetworks streaming.
#
# client connects on TCP ports 554 (rtsp) or 7070 (pnm, deprecated)
# data returns to client either as UDP on port-range 6970-7170, or
# via the initial TCP socket, if the client cannot receive the UDP stream.

# written and tested to very high (several thousand simultaneous) client load by
# Mark Winter, network department, RealNetworks
# additional LVS work by Rodney Rutherford and Glen Raynor, internet operations
# with random comments by Jerry Black, former Director of Internet Operations
# supplied with no warranty, support, or sympathy, but it works great for us

# Setup IP Addresses
VIP="publicly-advertised-IP-number.mynet.com"
RIP_1="RealServer-1.mynet.com"
RIP_2="RealServer-2.mynet.com"
RIP_3="RealServer-3.mynet.com"

# Load needed modules
BALANCE="wrr"
# Load LVS fwmark module
/sbin/modprobe ip_masq_mfw
# Load appropriate LVS load-balance algorithm module
/sbin/modprobe ip_vs_$BALANCE

# Mark packets with FWMARK1
/sbin/ipchains -F
/sbin/ipchains -A input -d ${VIP}/32 7070 -p tcp -m 1
/sbin/ipchains -A input -d ${VIP}/32 554 -p tcp -m 1
/sbin/ipchains -A input -d ${VIP}/32 8080 -p tcp -m 1
/sbin/ipchains -A input -s 0.0.0.0/0 6970:7170 -d ${VIP}/32 -p udp -m 1

# Setup the LVS to listen to FWMARK1
/sbin/ipvsadm -C
/sbin/ipvsadm -A -f 1 -p -s $BALANCE

# Setup the realservers
/sbin/ipvsadm -a -f 1 -r ${RIP_1}
/sbin/ipvsadm -a -f 1 -r ${RIP_2}
/sbin/ipvsadm -a -f 1 -r ${RIP_3}
]]></programlisting>
		<para>
Roberto Nibali <emphasis>ratz (at) tac (dot) ch</emphasis> 08 Jun 2001
		</para><para>
there is no fwmark module, and the ip_vs module
is loaded by <command>ipvsadm</command> now. Why do you need persistence?
		</para>
		</section>
		<section id="realnetworks_g2">
		<title>RealNetworks g2 server</title>
		<para>
<emphasis>philz (at) testengeer (dot) com</emphasis> 3 Apr 2000 
		</para>
		<blockquote>
A realnetworks g2 server is the
daemon that serves up real audio/video streams (http://real.com).
I'm using LVS-Tun.
When I tried setup a realnetworks g2 server I
could not get it to accept the connection (tcp port 7070). A telnet to
port 7070 on the VIP yeilds a connection refused. while telnet to the
realserver ip yeilds a "connect" (it also serves video and audio if you
use the proper client). 
		</blockquote>
		<para>
Joe
		</para>
		<para>
Is the service listening on the VIP 
(a common thing to forget when setting up LVS-DR or LVS-Tun)?
		</para>
		<blockquote>
			<para>
That's it. Success! Here is what has to be done:
			</para>
			<itemizedlist>
				<listitem>
The real real audio/video daemon must be configured to listen/respond
to _BOTH_ the VIP and its RIP (see Configure->General Setup->IP
Binding on the RealAdministrator web page).
				</listitem>
				<listitem>
Both the 7070 and 554 (PNAPort and RTSPPort respectively) must be
redirected. You might have to do more ports for other features of the
real audio/video daemon. 
				</listitem>
			</itemizedlist>
		</blockquote>
		<para>
er OK. The demon listening on the RIP never hears from anyone though ;-\
		</para>
		<blockquote>
You actually need the RIP to respond so that you can manage/monitor it.
		</blockquote>
		<para>
congratulations. You've got a realserver to be a RealServer. Is this the
thing that costs $2995 with RedHat?
		</para>
		<blockquote>
Nope. This is the free one that supports 25 session per server ;-) 
		</blockquote>
		<para>
What's on each of 7070 and 554? Is one video and the other audio?
What does PNAPort and RTSPPort stand for?
What happens if the client gets 7070 from one realserver and 554 from another?
Did you have to link the 2 services with persistent connection?
		</para>
		</section>
		<section id="quicktime">
		<title>Quicktime, tcp 554, many ports</title>
		<para>
First, a quicktime primer from Andy Wettstein:
		</para>
		<blockquote>
It is similar to Real.
554 is rtsp, and there is an option on the quicktime server
to stream over port 80 to avoid firewall problems.
The ports 6970:7170 are what the client will actually send/receive the
stream on (if not blocked by firewall rules, etc).
The udp stuff is why you need persistence.
The stream would try to switch between servers
without persistence enabled (since udp is really connectionless).
		</blockquote>

		<para>
Andy Wettstein <emphasis>awettstein (at) cait (dot) org</emphasis> 20 Dec 2002
		</para>

		<blockquote>
		<para>
 I'm trying to set up the quicktime (darwin) streaming server through
 lvs.  It kind of works, but it is very slow, much slower than just
 accessing the stream without going through lvs.
 I have set it up exactly the same as the Real rtsp examples.  I am using
 lvs-dr with fwmark on ports.
 Here are the iptables commands I used:
 		</para>
<programlisting><![CDATA[
# iptables -t mangle -A PREROUTING -i eth0 -p tcp -s 0.0.0.0/0 -d 209.174.123.48 --dport 80 -j MARK --set-mark 1
# iptables -t mangle -A PREROUTING -i eth0 -p tcp -s 0.0.0.0/0 -d 209.174.123.48 --dport 554 -j MARK --set-mark 1
# iptables -t mangle -A PREROUTING -i eth0 -p udp -s 0.0.0.0/0 -d 209.174.123.48 --dport 6970:7170 -j MARK --set-mark 1
]]></programlisting>

		<para>
 Then I added the lvs-dr like the examples:
 		</para>
<programlisting><![CDATA[
# ipvsadm -A -f 1 -s rr
# ipvsadm -a -f 1 -r 209.174.123.45
# ipvsadm -a -f 1 -r 209.174.123.47
]]></programlisting>

		<para>
And I get this with ipvsadm:
 		</para>
<programlisting><![CDATA[
FWM  1 rr
  -> lead.web.cait.org:0          Route   1      0          1
  -> tin.web.cait.org:0           Route   1      1          1
]]></programlisting>
		<para>
I am also unable to access the stream on port 80 through lvs.
If anyone has experience with quicktime please let me know if there is
anything further that I need to do.
		</para>
		</blockquote>
		<para>
I figured it out. It needs persistence (or streaming movies will fail)
<emphasis>i.e.</emphasis> the <command>ipvsadm -A</command> command needs a <command>"-p"</command>.
		</para>
		<para>
Here's the <filename>mon.cf</filename>
		</para>
<programlisting><![CDATA[
watch tin
   service rtsp
      interval 30s
      monitor tcp.monitor -p 554
      period wd {Sun-Sat}
         startupalert qtss.alert -u -V caittv.cait.org -R tin.cait.org -W 3 -m 1 -S wlc
         upalert qtss.alert -R tin.cait.org -W 3 -m 1 -F dr -s wlc
         alert qtss.alert -R tin.cait.org -m 1
]]></programlisting>

		<para>
and the <filename>qtss.alert</filename>
		</para>

<programlisting><![CDATA[
#!/bin/bash
#


IPTABLES="/sbin/iptables"
IPVSADM="/sbin/ipvsadm"

while getopts ":s:g:h:l:t:V:m:o:W:R:S:u" Option
do
  case $Option in
    V)	VIRTUALSERVER="$OPTARG";;
    m)	MARK="$OPTARG";;
    o)	OPTION="$OPTARG";;
    W)	WEIGHT="$OPTARG";;
    R)	REALSERVER="$OPTARG";;
    S)	SCHEDULER="$OPTARG";;
    u)	UP=1;;
  esac
done

shift $(($OPTIND - 1))

if [ $UP ]; then
	# won't add more iptables MARK rules after the initial go
	# so we don't clog up the rules
	# you'll have to resolve problems if you need to add more to the marked service
	if ! $IPTABLES -L -t mangle | grep "MARK set 0x$MARK" > /dev/null; then
		$IPTABLES -t mangle -A PREROUTING -i eth0 -p tcp -s 0.0.0.0/0 -d $VIRTUALSERVER --dport 80 -j MARK --set-mark $MARK
		$IPTABLES -t mangle -A PREROUTING -i eth0 -p tcp -s 0.0.0.0/0 -d $VIRTUALSERVER --dport 554 -j MARK --set-mark $MARK
		$IPTABLES -t mangle -A PREROUTING -i eth0 -p udp -s 0.0.0.0/0 -d $VIRTUALSERVER --dport 6970:7170 -j MARK --set-mark $MARK
	fi
   # set up the virtual server
	$IPVSADM -A -f $MARK -s $SCHEDULER -p
   # add the realserver
  	$IPVSADM -a -f $MARK -w $WEIGHT -r $REALSERVER
else
	# remove
	$IPVSADM -d -f $MARK -r $REALSERVER

fi
exit 0
]]></programlisting>
		</section>
		<section id="windows_media_server" xreflabel="windows media server">
		<title>Windows Media Server, tcp/udp 554, tcp 1755, udp 1024:5000</title>
		<para>
Mark Weaver <emphasis>mark (at) npsl (dot) co (dot) uk</emphasis> 23 Mar 2004
		</para>
		<para>
Here's how to setup Windows Media Server.
This information is not easy to come across as I can't find a simple
published document which lists what WMS actually does.  There is also some
attempt here at WMS9 support, but that's untested and is just based on what
the player tries to do (the player connects more quickly, however, if you
reject rather than drop those connection attempts, which I'm letting the
server do).
		</para>
<programlisting><![CDATA[
# WMS: we want to group TCP 1755 and UDP 1024-500
# Also uses 554/tcp + 554/udp for WMS9.
# You might also want to add port 80 if serving up via http as well.
# To do this, set an fw mark on such connections, and use LVS fwmark
balancing (
# will forward matching IP+fwmark to the same server).  Just what we need.
EXT_IP="1.2.3.4"
EXT_IF="eth0"
WMS_MARK="1"
RS1_IP="192.168.1.2"
RS2_IP="192.168.1.3"

# Allow appropriate ports in...
$IPTABLES -A INPUT -i $EXT_IF -p tcp -s 0/0 -d $EXT_IP --dport 1755 -j ACCEPT
$IPTABLES -A INPUT -i $EXT_IF -p tcp -s 0/0 -d $EXT_IP --dport 554 -j ACCEPT
$IPTABLES -A INPUT -i $EXT_IF -p udp -s 0/0 -d $EXT_IP --dport 554 -j ACCEPT
$IPTABLES -A INPUT -i $EXT_IF -p udp -s 0/0 -d $EXT_IP --dport 1024:5000 -j ACCEPT

# Group with fwmark...
$IPTABLES -t mangle -A PREROUTING -i $EXT_IF -p tcp -s 0/0 -d $EXT_IP --dport 1755 -j MARK --set-mark $WMS_MARK
$IPTABLES -t mangle -A PREROUTING -i $EXT_IF -p tcp -s 0/0 -d $EXT_IP --dport 554 -j MARK --set-mark $WMS_MARK
$IPTABLES -t mangle -A PREROUTING -i $EXT_IF -p udp -s 0/0 -d $EXT_IP --dport 554 -j MARK --set-mark $WMS_MARK
$IPTABLES -t mangle -A PREROUTING -i $EXT_IF -p udp -s 0/0 -d $EXT_IP --dport 1024:5000 -j MARK --set-mark $WMS_MARK

# Tell LVS to do the load balancing
$IPVSADM -D -f $WMS_MARK
$IPVSADM -A -f $WMS_MARK -s rr -p 600
$IPVSADM -a -f $WMS_MARK -r $RS1_IP:0 -m
$IPVSADM -a -f $WMS_MARK -r $RS1_2P:0 -m
]]></programlisting>
		</section>
	</section>
	<section id="radius">
	<title>Radius, udp 1645,1646</title>
	<para>
Francois Baligant 2000-05-10
	</para>
	<blockquote>
	<para>
We have a very weird problem load-balancing UDP-based RADIUS packets.
	</para>
<programlisting><![CDATA[
UDP 195.74.212.37:16450 rr
      -> 195.74.212.26:16450   Route   1      0          0
      -> 195.74.212.34:16450   Route   1      0          0
UDP 195.74.212.31:1646 wlc
      -> 195.74.212.26:1646    Route   1      0          106
      -> 195.74.212.10:1646    Route   1      0          106
UDP 195.74.212.31:1645 wlc
      -> 195.74.212.26:1645    Route   1      0          1
      -> 195.74.212.10:1645    Route   1      0          0
]]></programlisting>
	<para>
I have a series of NAS (Network Access Server) sending
Authentication Requests to a single central Proxy Radius server
(packets arrive sometimes 5packets/sec).
This Proxy Radius Server then forwards Authentication Request
to the load-balancer which should normally dispatch them
to several nodes for processing (check with DB etc..)
	</para><para>
We want to load-balance 3 ports: 1645 (authentication),
1646 (accounting) and 16450 (authentication for another
kind of service).
	</para>
	<para>
The rule for port 1646 loadbalances. However for
rule 16450 and 1645, all UDP requests go to only one realserver.
(rule 16450 is not used at the moment. 1645 is. You can
see the strange little "1" for 195.74.212.26)
What's weird is that 1645 works really fine but the 2
others rules just do not load-balance. Packets are always
sent to the same host. (in fact the first that was added
to the VS IP)
	</para>
	</blockquote>
	<para>
Joe
	</para>
	<para>
Someone had a similar sounding problem with udp <link linkend="ntp">ntp</link>.
All packets would go to one host and then after a little while to
another. In the short term the load balancing was bad, but
over the long term (>15mins) the loadbalancing was fine.
The udp LVS code sends all udp packets to one realserver, till a timeout
is reached, and then sends the next packets to another realserver.
	</para><para>
(See also <link linkend="TCP_UDP_scheduling">Scheduling TCP/UDP</link>.)
	</para>
	<para>
Julian
	</para>
	<para>
Julian
	</para>
	<para>
Single Radius Server? Does that mean that all packets come
from a single IP:port too?
	</para>
	<para>
Don't forget that
for UDP the autobind ports are not rotated. For TCP you have
ports selected in the 1024..4999 range but it is possible
all your client UDP packets to come from the same port
on the client.
This can be a good reason they to be redirected to
the same realserver if the UDP entry is not expired. Show
a tcpdump session or try to set UDP timeout to a small value:
	</para>
<programlisting><![CDATA[
ipchains -M -S 0 0 2
]]></programlisting>
	<para>
Any difference? How many clients (UDP sockets) you have?
If you have one, it can't be balanced. There is a persistency
according to the default UDP timeout value.
	</para>
	<blockquote>
<programlisting><![CDATA[
14:06:36.277177 195.74.193.40.60774 > 195.74.212.31.1645: udp 244 (DF)
14:06:36.277205 195.74.193.40.60774 > 195.74.212.31.1645: udp 244 (DF)
14:06:36.430549 195.74.193.40.60774 > 195.74.212.31.1645: udp 244 (DF)
14:06:36.430575 195.74.193.40.60774 > 195.74.212.31.1645: udp 244 (DF)
14:06:36.639869 195.74.193.40.60774 > 195.74.212.31.1645: udp 244 (DF)
14:06:36.639894 195.74.193.40.60774 > 195.74.212.31.1645: udp 244 (DF)
14:06:38.040246 195.74.193.40.60774 > 195.74.212.31.1645: udp 246 (DF)
14:06:38.040276 195.74.193.40.60774 > 195.74.212.31.1645: udp 246 (DF)
14:06:38.117694 195.74.193.40.60774 > 195.74.212.31.1645: udp 243 (DF)

14:06:49.899222 195.74.193.40.40190 > 195.74.212.31.1646: udp 349 (DF)
14:06:49.899256 195.74.193.40.40190 > 195.74.212.31.1646: udp 349 (DF)
14:06:50.358085 195.74.193.40.40223 > 195.74.212.31.1646: udp 349 (DF)
14:06:50.358114 195.74.193.40.40223 > 195.74.212.31.1646: udp 349 (DF)
14:06:51.494628 195.74.193.40.40346 > 195.74.212.31.1646: udp 349 (DF)
14:06:51.494656 195.74.193.40.40346 > 195.74.212.31.1646: udp 349 (DF)
14:06:51.810022 195.74.193.40.40381 > 195.74.212.31.1646: udp 349 (DF)
14:06:51.810051 195.74.193.40.40381 > 195.74.212.31.1646: udp 349 (DF)
14:06:52.351541 195.74.193.40.40485 > 195.74.212.31.1646: udp 199 (DF)
]]></programlisting>

		<para>
I think you just helped me to understand what was
the problem. Port 1645 is not loadbalancing.
I will patch the radius to increate port
number for accounting request too.
		</para>
	</blockquote>
	</section>
</section>
<section id="LVS-HOWTO.services_that_dont_work_yet" xreflabel="services that don't work yet">
<title>LVS: Services that we haven't got to work with LVS yet</title>
	<para>
You may get some hints at <xref linkend="debugging_services"/>.
	</para>
	<section id="Kerberos">
	<title>Kerberos</title>
	<note>
		<para>
Kerberos is a secure authentication protocol. 
Many ports are involved, making it difficult to setup firewalls: <emphasis>e.g.</emphasis> 
<ulink url="http://www.lns.cornell.edu/public/COMP/krb5/krb5-admin/Configuring-Your-Firewall-to-Work-With-Kerberos-V5.html">
Configuring your firewall to work with Kerberos</ulink>.
Further down this section, someone is ssh tunneling by LVS forwarding ssh to
the realservers which use kerberos for authentication. 
In this case kerberos is just a login protocol that has nothing to do with LVS.
		</para>
		<para>
There should only be one kerberos (ticket) server in your realm.
You shouldn't LVS kerberos servers.
Kerberos is a login protocol. 
There's no more reason to LVS kerberos, than there is to LVS login.
However you can have the client login to kerberos'ed realservers.
		</para>
	</note>
	<para>
several people
	</para>
	<blockquote>
I'd be interested to know if LVS can be used and setup for silent 
login(no password prompting, i.e. using ticket forwarding) using 
ssh and kerberos.
	</blockquote>
	<para>
Ryan Leathers <emphasis>ryan (dot) leathers (at) globalknowledge (dot) com</emphasis> 07 Mar 2006
	</para>
	<para>
this is not a good idea.
	</para>
	<para>
The kerberos replication system only permits one active admin server, so
there is no opportunity for load balancing of the admin function.  You
shouldn't try to fool it by using LVS.  You'll likely screw up the
replication.
	</para>
	<para>
What you should do instead is to list multiple Kerberos key distribution centers (KDC'si) 
in your <filename>krb5.conf</filename>.
Take a look at that and notice the section under [realms].  All
you need to do is list multiple kdc's like so:
	</para>
<programlisting><![CDATA[
[realms]
	EXAMPLE.COM = {
	default_domain = example.com
	admin_server = krbadmin
	kdc = kdcserver1
	kdc = kdcserver2
	kdc = kdcserver3
	}
]]></programlisting>
	<para>
So, there you have it.  By specifying multiple KDC servers you will be
getting the behavior you really want, in case you lose a server for a
little while, things will just keep on chugin' in your network.  Don't
get me wrong - LVS is a great tool, but its not the answer to every
problem of service redundancy.  
	</para>
	<para>
Ryan Leathers <emphasis>ryan (dot) leathers (at) globalknowledge (dot) com</emphasis> 02 Mar 2006
	</para>
	<para>
If you kerberize your host - that is to say, you have stuff like your
ssh client using kerberos-compatible versions, and your authentication
happening against kerberos, then kerberos works something like this:
	</para>
	<para>
I sit down at my favorite Linux workstation and open a shell so I can
ssh to some other host on my network.  Assuming I have not done so
recently, the host I'm trying to reach won't be able to verify me.
Instead, both my local host and the target host will rely on an
authentication server to generate a new encryption key and distribute it
to both parties.  This is the session key.  A Kerberos ticket is used to
distribute the session key which includes info about me / my host that
will be used by the target host to verify my connection.  When the
server passes this back to me, I forward it on to the target host as
part of my authentication request.  So, the ticket will be encrypted in
a server key, which is known only by the server and the target host.
nifty huh?
	</para>
	<para>
The ticket-granting-ticket just extends this to make life a little
easier.  We assume that some period of time is an acceptable amount for
ticket granting without requiring the user to type in a password every
time a ticket is needed.  In short, I authenticate myself once to the
server, and it allows me to perform any number of permitted
authentications during the allowed time period.  The ports used are
likely going to be 88 for the kdc and possibly 749 for the admin server.
	</para>
	<para>
Karen Shepelak <emphasis>shepelak (at) fnal (dot) gov</emphasis> 04 Feb 2005 
	</para>
	<blockquote>
		<para>
We are trying to get kerberos to work with LVS.
We're ssh tunnelling to the realservers in an LVS forwarding ssh.
We can kerberos through the ssh tunnel when connecting directly
to the realservers, but not when we ssh to VIP:ssh.
We get the following errors.
		</para>
<programlisting><![CDATA[
[karen@neptune karen]$ ssh -l shepelak minos-lvs01

Last login: Fri Feb  4 16:34:23 2005 from linux-test.fnal.gov
aklog: Couldn't get fnal.gov AFS tickets:
aklog: unknown RPC error (-1765328346) while getting AFS tickets
/usr/X11R6/bin/xauth:  timeout in locking authority file /afs/fnal.gov/files/home/room3/shepelak/.Xauthority
Terminal type is xterm
There are no available articles.
/bin/touch: creating `/afs/fnal.gov/files/home/room3/shepelak/.Info': Permission denied
<minos09>
]]></programlisting>
	</blockquote>
	<para>
Horms 
	</para>
	<itemizedlist>
		<listitem>
xauth isn't working. You should probably just turn off xforwarding in
your sshd config rather than make xauth work.
		</listitem>
		<listitem>
Your user doesn't have permission to access
<filename>/afs/fnal.gov/files/home/room3/shepelak/.Info</filename>
		</listitem>
	</itemizedlist>
	</section>
	<section id="rmi">
	<title>RMI</title>
	<note>
		<para>
Joe: multiport protocols are difficult to loadbalance under LVS
		</para>
	</note>
	<para>
Francois JEANMOUGIN <emphasis>Francois (dot) JEANMOUGIN (at) indexmultimedia (dot) com</emphasis> 03/10/2006
	</para>
	<para>
Rmi is NOT a TCP protocol as is. It is a subprotocol that
is similar to FTP. The two RMI ports are dealing a
transaction on the standard RMI port, and then,
there is a dynamic port negociation. There is no way to
make RMI load balanced, as well as there is no way to make
it go through a firewall...
	</para>
	<para>
If you look at google:RMI+Firewal, you will find relevant
documents about port negociation and all the (bad) ways to
handle this (bad) idea that is RMI.
	</para>
	<para>
Mr. CBoy <emphasis>cboy168 (at) gmail (dot) com</emphasis> 10 Mar 2006 
	</para>
	<blockquote>
		<para>
Currently I am using LVS-Nat with 2 real JBoss servers.
In my test environment I have 1 client that spawns hundreds of threads that
will invoke methods through RMI.
The flow is like this:
		</para>
		<para>
Client sends a request to the VIP for a naming proxy which will get
forwarded to RS1.
RS1 will then push down the naming proxy back to the client, but will be
masquerated by the director.
The client will ask for the stub on the remote object so that it can invoke
methods and it will be returned.
Now the client has the stub and can start to invoke methods, but here lies
the problem.
The stub came from RS1 and when the client calls a method on the stub, it
gets load balanced to RS2 and becomes invalid.
In a real world example, turning on persistance would remedy this however in
a test environment, I'm limited by hardware.
Is there anyway to get threads on the same client to talk to the same real
server?
		</para>
		<para>
The client code is something simple like
		</para>
<programlisting><![CDATA[
MyObject obj = (MyObject) Naming.lookup("rmi://VIP/obj");
obj.callSomeMethod();
]]></programlisting>
		<para>
All the underlying connection details are handled by Sun's RMI so I'm unable
to keep 1 connection for each thread myself, so my only guess is to figure
out a way for LVS to handle it.
		</para>
	</blockquote>
	</section>
</section>
<section id="LVS-HOWTO.UDP" xreflabel="udp">
<title>LVS: UDP Services - unique problems</title>
<para>
LVS has been able to schedule and forward UDP packets from the very beginning.
Most of our users have been load balancing TCP services and we've 
glibly assumed that all our TCP knowledge and coding applied to UDP as well.
However while TCP connections are alike (start with SYN and end with FIN),
a service using UDP has more flexibility.
</para>
<itemizedlist>
	<listitem>
ntp requires that the client be sent and receive packets from the same realserver forever.
	</listitem>
	<listitem>
some services only send one packet as the sum total of information transfer.
There will never be any information transfer in the reverse direction.
	</listitem>
	<listitem>
SIP is NAT'ed. It's unlikely that SIP will work out of the box with LVS.
	</listitem>
</itemizedlist>
<para>
A single scheduler is not going to work for all of these.
Little progress has been made for UDP over LVS 
because few people are using UDP services with LVS.
Most UDP services of interest (ntp, dns) have their own inbuilt loadbalancing
and so their has been no pressing requirement for LVS/UDP, like there has for LVS/TCP.
</para>	
	<section id="SIP" xreflabel="SIP">
	<title>SIP (Session Initiation Protocol)</title>
	<para>
SIP is an all UDP protocol for VoIP (voice over IP) telephony. 
It has lots of ports and is a bit complicated for LVS
(no-one has it working under LVS).
Asterisk has its own load balancer (see below).
Currently we suggest that you try that first.
	</para>
	<para>
Joao Filipe Placido, Jul 19, 2005
	</para>
	<blockquote>
I have read some posts about a SIP module for lvs.
Is this available? Does it do SIP dialog persistence?
	</blockquote>
	<para>
Horms
	</para>
	<para>
Unfortunately it is not available as the project was halted before
it became ready for release. I'm not entirely sure what SIP dialog
persistance is, but in a nutshell all my design did was to provide
persistance based on the Caller-ID, rather than the client's address and
port as LVS ususally does.
	</para>
	<para>
Mike Machado <emphasis>mmachado (at) o1 (dot) com</emphasis> 20 Aug 2004
	</para>
	<blockquote>
		<para>
I have a LVS-DR setup with two realservers. My service is a voip
application, SIP specifically. I am trying to balance requests between
the two. I have all the LVS stuff setup, and was able to get the telnet
test to work properly. With UDP though, there seems to be a problem.
When the application is forming its reply, it uses the realserver as the
source IP, instead of the VIP, as it does with the telnet test. I assume
this is because UDP is stateless. I tried to SNAT the packets back to
the correct IP, but you cannot SNAT locally generated packets.
		</para>
		<para>
I was able to change my voip application to just BIND to the VIP, but
due to the nature of this application, it needs to be able to
communicate on both the VIP and the RIP, I just want reply packets to
use the same source IP and the inbound packets.
		</para>
		<para>
Anyone come across this problem for UDP applications, along with a
possible solution?
		</para>
	</blockquote>
	<para>
Julian 
	</para>
	<para>
	What about using IP_PKTINFO in sendmsg, "srcip" is your server
IP used in each request packet as daddr:<emphasis>e.g.</emphasis>
<ulink url="http://www.ussg.iu.edu/hypermail/linux/kernel/0406.1/0771.html">example</ulink>
(http://www.ussg.iu.edu/hypermail/linux/kernel/0406.1/0771.html);
<ulink url="http://www.ussg.iu.edu/hypermail/linux/kernel/0406.1/index.html#0247">thread</ulink>
(http://www.ussg.iu.edu/hypermail/linux/kernel/0406.1/index.html#0247).
	</para>
	<para>
Horms 
	</para>
	<para>
Fixing the application to send reply packets from the addresses
that they were received on is the best solution IMHO. 
It is the way I have resolved this problem in the past. 
The alternative would be to use LVS-NAT instead.
	</para>
	<para>
Erik Versaevel <emphasis>erik (at) infopact (dot) nl</emphasis> 13 Jan 2005
	</para>
	<blockquote>
		<para>
I'm currently trying to create a loadbalacing SIP (voip protocol) 
cluster, however for this to work I need SIP messages from the same call 
(identifiable by the sip callid field) to get to the same realserver 
over and over again. (so, I need persistence based on the contents of 
the SIP Call-ID field). This would call for ktcpvs as we need to process 
packets at layer 7, however that poses 2 new problems, the first is that 
SIP uses clear text  UDP messages, not tcp and the second is that there 
are no SIP modules for ktcpvs.
		</para>
		<para>
Another option would be to mark SIP packets with iptables/netfilter 
based on the callid, however i run into the same problem, there are no 
modules to accomplish this.
		</para>
		<para>
I know that there are commercial products available who are able to do 
SIP session persistence based on callid, the F5 Big-IP for example, the 
downside of that is it costs around $ 10.000 for a single loadbalancer 
(which is a SPOF so you need 2) and is a bit overkill as i don't need 
multi gigabit loadbalancing.
		</para>
		<para>
High persistence won't work because reply packets from another SIP 
source might be balanced to the wrong server, ie packets from 
192.168.0.2 might be balanced to real server 1, which sends it's reply 
directly to 192.168.0.3 (the end point for the call) but the replies 
from 192.168.0.3 might end up at another real server.
(be aware I'm using direct routing because of NAT traversal)
		</para>
		<para>
Using TCP Sip would only solve half the problem (and couse some more).
Answers to request could still end up at the wrong server (but one would 
only have to write a module for that, and not a kudpvs) and not all 
clients support TCP based sip.
		</para>
	</blockquote>
	<para>
Wensong Zhang <emphasis>wensong (at) linux-vs (dot) org</emphasis> 17 Jan 2005 
	</para>
	<para>
We cannot use ktcpvs, because ktcpvs supports TCP only, and there is no
SIP modules for TCP transport.
The firewall marking doesn't solve the problem. However, we can write a 
special SIP UDP scheduling module for IPVS. It can detect the Call-Id from 
UDP packet and send it to the SIP server according to the recorded Call-Id 
table. We assume that there is no UDP fragments. Some NAT boxes (such as 
early IOS version of Cisco router) may drop UDP fragements except the 
first one.
	</para>
	<para>
Erik Versaevel
	</para>
	<blockquote>
Such a module would definitly solve the problem. A round robin with 
call-id persistence would be awsome. Currently a device which can do 
that costs around $ 10000 each (times 2 for HA).
	</blockquote>
	<para>
Malcolm Turnbull wrote:
	</para>
	<blockquote>
If I wanted to test load balancing SIP using standard LVS UDP is their
an OpenSource or Commercial Free Server to test against ?
	</blockquote>
	<para>
Joe
	</para>
	<para>
AFAIK you can do all of VOIP PBX on Linux 
<ulink url="http://www.asterisk.org/">Asterisk</ulink>
The handsets (phones) are more of a problem. I believe you can
get a linux box with a sound card and mic/headphones to be a phone.
There was a large purchase of VOIP phones a while ago, that someone
got to run linux, but these have all gone. You'll probably need
to buy a real VOIP phone to test with.
	</para>
	<para>
Curt Moore <emphasis>tgrman21 (at) gmail (dot) com</emphasis> 11 Feb 2005
	</para>
	<para>
I believe that Wensong has the right idea here.  Although SIP does
support TCP the vast majority of SIP endpoints ony support UDP.
	</para>
	<para>
Asterisk can be used for a SIP application
server but it's not geared/written to be a SIP proxy.  For this you
need something like SER, SIP Express Router.
	</para>
	<para>
When correctly configured, SER acting as a SIP proxy does support the
distributing of calls to Asterisk boxes acting as media/application
servers.  The issue becomes how to load balance/distribute calls to
multiple SER boxes, based on SIP call-id, so that the same SIP call-id
always goes to the same SER box.  Once you've statefully routed a
call, based on call-id, to a particular SER box, SER can take over and
ensure that things go to the correct Asterisk media/application server
or endpoint based on its routing configuration.  The director nodes
just need to be smart enough to send the right call to the right SIP
proxy residing in the LVS cluster.
	</para>
	<para>
As far as NAT goes, I've found though lots of experience that you'll
never be able to penetrate every NAT implementation out there when it
comes to SIP/UDP, you can only hope to get 99% of them as many of them
don't fully conform to the RFC.
	</para>
	<para>
Gerry Reno <emphasis>greno (at) verizon (dot) net</emphasis> 16 May 2008
	</para>
	<blockquote>
Ok, I finished setting up some pbx (asterisk).  Can I use LVS to load 
balance the call traffic between multiple pbx's?  Or with SIP protocol 
is it necessary to use OpenSER?
	</blockquote>
	<para>
Graeme
	</para>
	<para>
You probably can, but given the nature of SIP - two transport protocols,
multi-port, session based - it could get very complicated.
You could definitely sort out the main ports - TCP/UDP port 5060 -
trivially; but the follow-on complication is how you then track the
session traffic which can wander around all over the place (cf. the LVS
FTP helper).
	</para>
	<para>
I'd strongly recommend you have a good read of the Asterisk mailing list
- it seems that there are several app-based load balancing schemes for
Asterisk, and if they do what you need, I'd use them.
	</para>
	<para>
Morgan Fainberg <emphasis>morgan (at) mediatemple (dot) net</emphasis> 17 May 2008 
	</para>
	<para>
In theory, you could use a FWM (firewall mark) setup and persistent  
connections.  If you map the virtual server group to use the same FWM  
for the TCP ( SIP uses TCP port 5060) and UDP (RTP usually is  
configured for UDP ports 16384-32767)  datastreams.  It should work in  
theory.
	</para>
	<para>
However, the application-based Load-balancing in Asterisk does  
function fairly well and you might end up with a better solution.   
Typically, with load-balancing I find that the more complexity you add  
just makes it that much harder to debug when things go awry.
	</para>
	<para>
Gerry
	</para>
	<blockquote>
		<para>
I think the fwmark approach might work. And I like this since 
load-balancing with LVS is better for me because I have all my other 
services on it.
I'm keeping all traffic going through the Asterisk box with 
canreinvite=no. canreinvite=yes would present a further scenario as the 
endpoints would then end up in direct communication for RTP.
You'll have to excuse me if I've oversimplified this. I have not used 
fwmarks before.
		</para>
		<para>
So let's see, I'm using keepalived so in the conf I guess I would have 
something like:
		</para>
<programlisting><![CDATA[
virtual service RS_IP 5060 { # SIP
persistent...
virtual service fwmark 1 { # SIP RTP
persistent...

In iptables (directors):
iptables -t mangle -A PREROUTING -p udp -d 192.168.1.27-28 --dport \
10000:20000 -j MARK --set-mark 1 # SIP RTP: where -d has ip of real servers

In iptables (realservers): # only for NAT, what about DR?
iptables -A PREROUTING -t mangle -d <VIRTUAL_IP> -j MARK --set-mark 1 # 
route back to director
]]></programlisting>
	</blockquote>
	<para>
Morgan
	</para>
	<para>
Those looks reasonable, however, you will probably not want to  
separate the SIP and RTP traffic.  It would make more sense to use two  
iptables rules that set the same firewall mark.  IE: You can set as  
many iptables rules as the system can handle to assign a given  
firewall mark.  Any traffic (regardless of port/type) can be balanced  
with the FWM.  FWM is (as you can see by the ipvsadm man-page) it's  
own service type.  Instead of specifying --tcp-service or --udp- 
service you specify --fwmark-service.  Given that I use Keepalived vs.  
the other methods, it is slightly different than making direct calls  
with ipvsadm.
	</para>
	<para>
In short, no need to have separate VIPS for SIP and RTP unless you  
have different servers handing SIP traffic.
	</para>
	<para>
It would probably look something more like this:
	</para>
<programlisting><![CDATA[
virtual service fwmark 1 { # SIP RTP
persistent...

iptables -t mangle -A PREROUTING -p udp -d 192.168.1.27-28 --dport \ 
10000:20000 -j MARK --set-mark 1 # SIP RTP: where -d has ip of real  servers
iptables -t mangle -A PREROUTING -p tcp -d 192.168.1.27-28 --dport \
5060 -j MARK --set-mark 1 # SIP RTP: where -d has ip of real servers
]]></programlisting>
	<para>
  I've not used FWM+NAT in a good long while.  You probably don't need  
to set the firewall mark on the realservers as the firewall mark (I  
don't believe) stays with the packet once it leaves the local  
networking stack (ie, it is not sent out on the wire).  So unless the  
system needs to do something specific with the firewall mark (IE  
iprule to policy-route to the director) the firewall mark will not  
need to be set on the real-server.
	</para>
	<para>
A DR configuration should work almost identically, however, I've not  
done UDP in a DR configuration (always NAT).  A standard DR  
configuration ~should~ function for a Asterisk setup like this.
	</para>
	<para>
Gerry
	</para>
	<blockquote>
Yes, of course, I need to keep the SIP and RTP together since I'm not 
using a separate SIP server.  So now if we use ARA we should have a good 
extensible solution.  To me this seems like it might be better than 
OpenSER because with OpenSER you have a SPOF whereas with keepalived/LVS 
you have more robust solution.    My setup is LVS-DR so I need to think 
is the direct return route is going to create any problems.  Otherwise, 
the only thing lacking in this picture is FreePBX does not support ARA :-(
	</blockquote>
	<para>
later...Gerry Reno <emphasis>greno (at) verizon (dot) net</emphasis> 26 Dec 2008
	</para>
	<para>
Actually, I abandoned plans for LVS+Asterisk. 
We just beefed up our recovery techniques and made sure everyone knew what to do
if Asterisk crashed or hung on us. 
Yes, we lose calls and it's a pain but we live with it right now.
	</para>
	</section>
	<section id="udp_timeouts_sip">
	<title>UDP timeouts (SIP)</title>
	<para>
Benjamin Lawetz <emphasis>blawetz (at) teliphone (dot) ca</emphasis> 30 Jun 2005 
	</para>
	<para>
I have a setup that load balances SIP UDP packets between 4 servers. Today
one of my servers failed and mon removed it from the load-balancing, but
some  of the connections still remain and keep getting refreshed. 
I noticed something bizarre though with the ipvsadm UDP timeout, it is set
to 35s, but the 3 connections that "stay stuck" seem to have an expire of 60
seconds instead of 35. And even though the server is removed and the rest of
the connections timeout and get redirected to another server. Those 3 just
keep going to the failed server.
	</para>
	<para>
Anyone have any idea why these 3 connections are (so it seems)
auto-refreshing every 60s on a server that doesn't exist?
Any way to clear these?
	</para>
	<para>	
Ipvsadm startup script: 
	</para>
<programlisting><![CDATA[
echo 1 > /proc/sys/net/ipv4/ip_forward
/sbin/ipvsadm --set 0 0 35
/sbin/ipvsadm -A -u 192.168.89.220:5060 -s rr
/sbin/ipvsadm -a -u 192.168.89.220:5060 -r 192.168.89.231 -i -w 5
/sbin/ipvsadm -a -u 192.168.89.220:5060 -r 192.168.89.232 -i -w 5
/sbin/ipvsadm -a -u 192.168.89.220:5060 -r 192.168.89.233 -i -w 5
/sbin/ipvsadm -a -u 192.168.89.220:5060 -r 192.168.89.234 -i -w 5
]]></programlisting>
	<para>
Before removal this is what I have:
	</para>
<programlisting><![CDATA[
Ipvsadm -L -n:

IP Virtual Server version 1.2.1 (size=4096)
Prot LocalAddress:Port Scheduler Flags
  -> RemoteAddress:Port           Forward Weight ActiveConn InActConn
UDP  192.168.89.220:5060 rr
  -> 192.168.89.233:5060            Tunnel  5      0          4
  -> 192.168.89.231:5060            Tunnel  5      0          3
  -> 192.168.89.232:5060            Tunnel  5      0          3
  -> 192.168.89.234:5060            Tunnel  5      0          6

Ipvsadm -L -n -c:

IPVS connection entries
pro expire state       source             virtual            destination
UDP 00:30  UDP         10.10.250.209:5060 192.168.89.220:5060 192.168.89.231:5060
UDP 00:25  UDP         192.168.85.25:1035 192.168.89.220:5060 192.168.89.233:5060
UDP 00:34  UDP         10.10.125.23:5060  192.168.89.220:5060 192.168.89.232:5060
UDP 00:26  UDP         206.55.81.128:5060 192.168.89.220:5060 192.168.89.234:5060
UDP 00:22  UDP         10.10.233.189:5060 192.168.89.220:5060 192.168.89.232:5060
UDP 00:32  UDP         192.168.85.25:5060 192.168.89.220:5060 192.168.89.234:5060
UDP 00:21  UDP         10.10.142.148:5060 192.168.89.220:5060 192.168.89.234:5060
UDP 00:20  UDP         192.168.85.25:1036 192.168.89.220:5060 192.168.89.232:5060
UDP 00:34  UDP         10.10.249.211:5060 192.168.89.220:5060 192.168.89.234:5060
UDP 00:23  UDP         10.10.249.211:1024 192.168.89.220:5060 192.168.89.233:5060
UDP 00:31  UDP         10.10.208.97:5060  192.168.89.220:5060 192.168.89.234:5060
UDP 00:32  UDP         10.10.184.83:5060  192.168.89.220:5060 192.168.89.231:5060
UDP 00:27  UDP         70.80.53.141:5060  192.168.89.220:5060 192.168.89.233:5060
UDP 00:40  UDP         192.168.85.5:58040 192.168.89.220:5060 192.168.89.233:5060
UDP 00:28  UDP         10.10.14.83:5060   192.168.89.220:5060 192.168.89.234:5060
UDP 00:25  UDP         10.10.215.175:6084 192.168.89.220:5060 192.168.89.231:5060
]]></programlisting>
	<para>
After removal I have:
	</para>
<programlisting><![CDATA[
Ipvsadm -L -n:

IP Virtual Server version 1.2.1 (size=4096)
Prot LocalAddress:Port Scheduler Flags
  -> RemoteAddress:Port           Forward Weight ActiveConn InActConn
UDP  192.168.89.220:5060 rr
  -> 192.168.89.231:5060            Tunnel  5      0          3
  -> 192.168.89.232:5060            Tunnel  5      0          3
  -> 192.168.89.234:5060            Tunnel  5      0          6

Ipvsadm -L -n -c:

IPVS connection entries
pro expire state       source             virtual            destination
UDP 00:28  UDP         10.10.250.209:5060 192.168.89.220:5060 192.168.89.231:5060
UDP 00:31  UDP         192.168.85.25:1035 192.168.89.220:5060 192.168.89.231:5060
UDP 00:31  UDP         10.10.125.23:5060  192.168.89.220:5060 192.168.89.232:5060
UDP 00:31  UDP         10.10.81.128:5060  192.168.89.220:5060 192.168.89.234:5060
UDP 00:29  UDP         10.10.233.189:5060 192.168.89.220:5060 192.168.89.232:5060
UDP 00:27  UDP         192.168.85.25:5060 192.168.89.220:5060 192.168.89.234:5060
UDP 00:24  UDP         10.10.142.148:5060 192.168.89.220:5060 192.168.89.234:5060
UDP 00:24  UDP         192.168.85.25:1036 192.168.89.220:5060 192.168.89.232:5060
UDP 00:33  UDP         10.10.249.211:5060 192.168.89.220:5060 192.168.89.234:5060
UDP 00:40  UDP         10.10.249.211:1024 192.168.89.220:5060 192.168.89.233:5060
UDP 00:11  UDP         10.10.208.97:5060  192.168.89.220:5060 192.168.89.234:5060
UDP 00:57  UDP         10.10.53.141:5060  192.168.89.220:5060 192.168.89.233:5060
UDP 00:57  UDP         192.168.85.5:58040 192.168.89.220:5060 192.168.89.233:5060
UDP 00:33  UDP         10.10.14.83:5060   192.168.89.220:5060 192.168.89.234:5060
UDP 00:33  UDP         10.10.215.175:6084 192.168.89.220:5060 192.168.89.231:5060
]]></programlisting>
	<para>
Sorry to answer myself, but narrowed down the problem.
	</para>
	<para>
I sniffed the traffic on the load balancer coming from one of the "stuck" IPs 
and I'm getting no traffic whatsoever.
So basically while getting no traffic coming in, having no destination to go
to and having a timeout of 35 seconds, the connection entries counts down
from 59 seconds to 0 seconds and loops back to 59 seconds again. Is there a
way to remove these connections? Anyone have any idea why they are looping
when no traffic is coming in?
	</para>
	<para>
Horms
	</para>
	<para>
Which kernel do you have? This sounds like a counter bug
that was resolved recently. However I couldn't convince myself
that it manifests in 2.4 (I looked at 2.4.27).
http://archive.linuxvirtualserver.org/html/lvs-users/2005-05/msg00043.html
Also, I may as well mention this as it has been floating around:
http://oss.sgi.com/archives/netdev/2005-06/msg00564.html
	</para>
	<para>
Marcos Hack <emphasis>marcoshack (at) gmail (dot) com</emphasis> 20 Dec 2005
	</para>
	<para>
I'm using LVS to load balance SIP UDP connections, and when a virtual
service fail on a real server the director don't clean up the UDP
connection on connection table. The solution seems to be just setting
<filename>/proc/sys/net/ipv4/vs/expire_nodest_conn=1</filename> 
and change keepalived to remove the virtual service on failure instead of using 
"inhibit_on_failure" (set weight to 0).
	</para>
	<para>
Michael Pfeuffer <emphasis>wq5c (at) texas (dot) net</emphasis> 18 Nov 2008 
	</para>
	<blockquote>
I've got an LVS-NAT configuration that works for HTTP traffic, but SIP UDP 
traffic is not being load balanced (and all SIP packets come from the same source address) 
- it always goes to the 1st RIP on the list.  
The services are all configured the same except for the checktype.
	</blockquote>
	<para>
Graeme
	</para>
	<para>
The same source address would explain it.
You could artificially reduce the UDP protocol timeout for testing:
	</para>
<programlisting><![CDATA[
ipvsadm --set <tcp> <tcpfin> <udp>  (see man ipvsadm for info)
]]></programlisting>
	<para>
but you can't make it less than 1 second.
Also, because UDP is stateless, a "session" is viewed as traffic
arriving from $host with $source_port to a given VIP/Port within the UDP
timeout detailed above. This causes problems with SIP signalling data in
some cases, because it has a tendency to be sourced from port 5060 to
port 5060, and is quite regular.
	</para>
	<para>
If you have a larger spread of clients, over time things will become
roughly balanced according to your RS weights.
	</para>
	</section>
	<section id="udp_timeouts_dns" xreflabel="udp timeouts dns">
	<title>UDP timeouts (DNS)</title>
	<note>
the sysctl
<filename>expire_quiescent_template</filename> (see <xref linkend="new_persistence"/> seems to be useful in several situations.
	</note>
	<note>
we don't find out till the end that Adrian is using persistence
	</note>
	<para>
Adrian Chapela <emphasis>achapela (dot) rexistros (at) gmail (dot) com</emphasis> 05 Mar 2007
	</para>
	<para>
I have a two directors in high availability configuration. All
it's OK for TCP, but for UDP it's no OK. In UDP load balance it's ok,
but the fail over don't happens.  If one client is "redirected" to one
real server, the connections are redirected always to this server, even
the server goes down.
I'm not using DNS's built in redundancy. 
I use a failover mechanism with LVS to have a
high availibility of my DNS servers.
Today I change my config of virtual server to a DNS servers. Before I have
two config, One in UDP and another in tcp for the "same" service. A DNS
service can be in UDP or TCP. I config my DNS servers to serve dns queries
in the two protocols.
When I serve with keepalived the DNS service in UDP and TCP the fail over is
OK, but when I config to serve in UDP only the fail over doesn't happens..
	</para>
	<para>
My UDP health check does the right things (I think...). 
The checks recognize well when a server goes down. 
In the list doesn't appear, but the packets are thrown to
the serve many minutes later. I then the packets are thrown to the "limbo"
(/dev/null I think..). I don't know what is happen but in another situation
with a firewall maked with Shorewall, I had a similar problem. I changed the
rules in firewall (one port for another) and the packets was ruled to the
first port. I reboot the machine and all OK. With TCP this not happens
never.
	</para>
	<blockquote>
Later - apparently after help from Graeme
	</blockquote>
	<para> 
The solution was set <filename>/proc/sys/net/ipv4/vs/expire_nodest_con=1</filename>. 
When a server is removed from the pool the 'established'
connections are removed but before the connections are waiting to the
protocol timeout and in UDP is too high.
Other important variable is 
<filename>/proc/sys/net/ipv4/vs/expire_quiescent_template</filename>
(see <xref linkend="new_persistence"/>.
For now I don't use it.
	</para>
	<para>
Simon Pearce <emphasis>sp (at) http (dot) net</emphasis> 27 Nov 2006
	</para>
	<para>
I am running a dns cluster (Gentoo) with two directors
active/active and 4 realservers running powerdns.
Each server has a 3Ghz Pentium 4 and 1 Gig of Ram.
I have about 250 VIPs.
I could do it all with one VIP of course,
but quite a few of our customers require there own dns servers with
there own ip address. 
A lot of them don't really need it, but it looks good to them.
	</para>
	<para>
Everytime time the dns cluster exceedes a certain limit some of
the ip addresses stop working properly. It effects the system in a way
that for certain domains you get a timeout when querying the cluster.
Some of the transfered IP's seem to stop working or slow down to an
extend that other dns servers stop querying us. 
Load average is 1-2. Even though queries don't get through the
director (reply in 4000ms), the realservers answer direct requests.
The only iptables rule is on the director to masquerade out calls
to the internet.
	</para>
	<para>
Joe: Is the problem load or the number of IPs (if you can tell)?
There is another problem with failover of large numbers of IPs, 
just incase you want to read more on
the topic (it may not be related to your problem).
http://www.austintek.com/LVS/LVS-HOWTO/HOWTO/LVS-HOWTO.failover.html#1024_failover
	</para>
	<para>
Can you setup ipvsadm with a single fwmark instead of all the IPs? That would shift the
responsibility for handling all the IPs to iptables, rather than ipvsadm.
	</para>
	<para>
Graeme Fowler <emphasis>graeme (at) graemef (dot) net</emphasis> 27 Nov 2006 
	</para>
	<para>
I know it was LVS-DR, and that it didn't have 250+ IP addresses, but the
DNS system I built for my previous employer used LVS with keepalived.
The last time I had access to the statistics, it was running at
something like 1200 queries/sec (which will have risen now by something
like 25% if memory serves), 99% of which were UDP, without a glitch.
	</para>
	<para>
However - as Joe mentioned - I built it to balance on fwmarks,
not on TCP or UDP. Incoming packets were marked in the netfilter
'mangle' table according to protocol and port, and the LVS was then
built up from the corresponding fwmarks.
	</para>
	<para>
There was one network "race" we never bottomed, which has affected the
system once or twice since I left, where an unmarked packet somehow
slipped through to the "inside" (ie. realserver-facing rather than
client-facing) LAn and then caused massive traffic amplification. That
however isn't related in any way to the OP's problem.
	</para>
	<para> 
Wayne <emphasis>wayne (at) compute-aid.com</emphasis> who has a financial interest (works for?)
Webmux, posted that only Webmux has solved this problem, but didn't give any details
(Simon has now solved it).
At the moment this stands as an uncorroborated statement by Wayne.
Presumably the 53-tcp/udp replies and calls to forwarders (from the RIP?) were being correctly nat'ed.
A solution was posted by Graeme Fowler where the IPs are fwmark'ed and the LVS balances the fwmark, 
but this was for a smaller number of IPs and Graeme didn't know if it would work for 250IPs.
	</para>
	<para>
Simon Pearce <emphasis>sp (at) http (dot) net</emphasis> 6 Apr 2007 
	</para>
	<para>
Some of you on the list might remember my problem concerning our DNS cluster last year.
http://archive.linuxvirtualserver.org/html/lvs-users/2006-11/msg00278.html
	</para>
	<para>
These problems (DNS timeouts) have continued throughout this year and I have been desperately trying to find the solution. I have
been folowing the mailing list and stumbled over the probems Adrian Chapela was having with his DNS setup. Which brought me to the
solution ipvsadm -L --timeout the default settings for UDP packets was set to 500 seconds which should be changed. Which is way to
long the load balancers were waiting for 5 minutes to timeout a UDP packet I get ablout 1500 queries a second. I changed the
setting to 15 seconds last week. And moved some of our old windows/bind DNS servers to the new linux DNS cluster. Before I changed
the timeout settings I always recieved a call from our customers within two hours your DNS services are not responding correctly.
The IP's that refused to answer would always change I have 254 IP's some of the large German dialup providers would refuse to talk
to us which resulted in domains not being reachable. Our DNS cluster is autorative for about 250000 domains so you can imagine how
many complaints I recieved. I was about to give up and scrap keepalived I am so glad I did not. Changing the timeout value solved
my problems and I am a happy man at the moment. Is there a way to set the timeout value permently so it is saved after a reboot of
the server? One last thing I would like to say is a big thank you to Graeme Fowler, Horms, Adrian Chapela and Alexandre Cassen for
writing this great piece of software. and anyone else on the list who maybe contributed to help me finaly find the solution. Thank
you guys you do a great job on the mailing list.
	</para>
	<para>
horms 8 May 2007
	</para>
	<para>
glad to hear that you got to the bottom of your problem.
I am a little concerned about the idea of reducing UDP timeouts
significantly because to be quite frank UDP load-balancing is a bit of
a hack. The problem lies in the connectionless nature of the protocol,
so naturally LVS has a devil of a time tracking UDP "connections" - that
is a series of datagrams between a client and server that are really
part of what would be a connection if TCP was being used.
	</para>
	<para>
As UDP doesn't really have any state all LVS can do to identify
such "connections" is to set up affinity based on the source and
destination ip and port tuples. If my memory serves me correctly
DNS quite often originates from port 53, and so if you are getting
lots of requests from the same DNS server then this affinity heristic
breaks down.
	</para>
	<para>
The trouble is that if the timeout is significatnly reduced, the
probablility of it breaking down the other way - in the case where
that affinity is correct - increases.
	</para>
	<para>
I'm not saying that you don't have a good case. Nor am I saying that
changing the default timeout is off-limits. Just that what exactly is a
good default timeout is a tricky question, because what works well in
some cases will not work well in others, and vice versa.
	</para>
	<para>
To some extent I wonder if the userspace tools should have the smarts to
change the timeout if port 53 (DNS) is in use. Thought that may be an
even worse heuristic.
	</para>
	<para>
I wonder if a better idea might be the one packet scheduling patches
by Julian http://archive.linuxvirtualserver.org/html/lvs-users/2005-09/msg00214.html.
Much to my surprise these aren't merged. Perhaps thats my
fault. I should look into it.
	</para>
	<para>
I also wonder, if problem relates to connection entries for servers that
have been quiesced, then does setting expire_quiescent_template help (see <xref linkend="new_persistence"/>)?
	</para>
<programlisting><![CDATA[
echo 1 > /proc/sys/net/ipv5/vs/expire_quiescent_template
]]></programlisting>
	<para>
Rudd, Michael <emphasis>Michael (dot) Rudd (at) tekelec (dot) com</emphasis> 8 May 2007 
	</para>
	<para>
My 2 cents in dealing with DNS and your idea of the OPS feature. I have
implemented the OPS feature into the 2.6 kernel and its running well.
Without that feature, we wound up having all the DNS queries from our
DNS client get sent to the same realserver.
	</para>
	<para>
The problem we did run into, which I've gotten help from the community
on, is when using LVS-NAT, the source packet isn't SNAT'd. This is
because LVS on the outgoing packet doesn't know the packet is an LVS
packet, so it just forwards it out. I fixed this with an iptables rule
to SNAT it myself. 
Just an FYI if you ever choose to use OPS with LVS-NAT. 
	</para>
	<para>
Horms
	</para>
	<para>
Mmm, I guess OPS isn't quite the right solution to the DNS problem :(
	</para>
	</section>
	<section id="one_packet_scheduler" xreflabel="One Packet Scheduler">
	<title>Julian's One Packet Scheduler (OPS) for UDP, timeouts for DNS</title>
	<para>
Although UDP packets are connectionless and independant of each other, in an LVS,
consecutive packets from a client are sent to the same realserver, 
at least till a timeout or a packet count has been reached. 
This is required for services like <xref linkend="ntp"/> where each realserver
is offset in time by a small amount from the other realservers and the client must
see the same offset for each packet to determine the time.
The output of <command>ipvsadm</command> in this situation will not show a balanced LVS,
particularly for a small number of client IPs.
	</para>
	<para>
Julian has experimental patch <ulink url="http://www.ssi.bg/~ja/#lvs_patches">LVS patches</ulink>
for a "one packet scheduler" which sends each client's UDP packet to a different realserver.
	</para>
	<blockquote>
	<para>
Ratz 17 Nov 2006 
	</para>
	<para>
First off: OPS is not a scheduler :), it's a scheduler overrider, at best.
	</para>
	</blockquote>
	<para>
Its really a bit of a hack (but probably a hack that is needed),
especially with regard to the non-visible part in user space. 
I have solved this in my previously submitted Server-Pool implementation, 
where several flags are exported to user space and displayed visibly.
Now I remember that all this has already been discussed ... with
viktor (at) inge-mark (dot) hr and Nicolas Baradakis has already ported stuff to 2.6.x kernels:
	</para>
<programlisting><![CDATA[
http://archive.linuxvirtualserver.org/html/lvs-users/2005-09/msg00214.html
]]></programlisting>
	<para>
Julian's reply:
	</para>
<programlisting><![CDATA[
http://archive.linuxvirtualserver.org/html/lvs-users/2005-09/msg00221.html
]]></programlisting>
	<para>
So Julian sees this patch in 2.6.x as well :). I've also found a thread
where I put my concerns regarding OPS:
	</para>
<programlisting><![CDATA[
http://archive.linuxvirtualserver.org/html/lvs-users/2006-07/msg00061.html
]]></programlisting>
	<para>
The porting is basically all done, once we've put effort into Julian's and my
concerns. User space is the issue here, and with it how Wensong believes it
should look like.
	</para>
	<para>
Horms
	</para>
	<para>
As an option, I can't see any harm in this and I do appreciate that it is needed for some applications.
Definitely not as default policy for UDP, because the semantic difference is rather big:
	</para>
<programlisting><![CDATA[
non-OPS
-------
srcIP:srcPort --> dstIP:dstPort --> call scheduler code & add template
srcIP:srcPort <-- dstIP:dstPort --> do nothing
srcIP:srcPort --> dstIP:dstPort --> read template entry for this hash
srcIP:srcPort <-- dstIP:dstPort --> do nothing
srcIP:srcPort --> dstIP:dstPort --> read template entry for this hash
srcIP:srcPort <-- dstIP:dstPort --> do nothing
[IP_VS_S_UDP]
srcIP:srcPort --> dstIP:dstPort --> call scheduler code & add template
srcIP:srcPort <-- dstIP:dstPort --> do nothing

OPS
---
srcIP:srcPort --> dstIP:dstPort --> call scheduler code (RR, LC, ...)
srcIP:srcPort <-- dstIP:dstPort --> do nothing
srcIP:srcPort --> dstIP:dstPort --> call scheduler code
srcIP:srcPort <-- dstIP:dstPort --> do nothing
srcIP:srcPort --> dstIP:dstPort --> call scheduler code
srcIP:srcPort <-- dstIP:dstPort --> do nothing
[IP_VS_S_UDP]
srcIP:srcPort --> dstIP:dstPort --> call scheduler code
srcIP:srcPort <-- dstIP:dstPort --> do nothing
]]></programlisting>
	<para>
The other question is, if it makes sense to restrict it to UDP, or give a
choice with TCP as well?
	</para>
	<para>
Ratz
	</para>
	<para>
This is a problem with people's perception and expectation regarding load
balancing. Even though the wording refers to a balanced state, this is all
dependent on the time frame you're looking at it. Wouldn't it be more
important to evaluate the (median) balanced load over a longer period on the
RS to judge the fairness of a scheduler? I've had to explain this to so many
customers already. There are situations where the OPS (I prefer EPS for each
packet scheduling) approach makes sense.
	</para>
	<para>
Julian Nov 18 2006
	</para>
	<para>
	I don't know what the breakage is and who will solve it but I
can only summarize the discussions:
	</para>
	<itemizedlist>
		<listitem>
RADIUS has responses, not only requests
		</listitem>
		<listitem>
DNS expects responses (sometimes many if client retransmits)
		</listitem>
		<listitem>
there is a need for application aware scheduling (<emphasis>e.g.</emphasis>SIP). 
SIP does not look like a good candidate for OPS in its current semantics.
		</listitem>
		<listitem>
Everyone talks about OPS. But for what applications? May be that is
why OPS is not included in kernel - there is no enough demand and
understanding about the test case which OPS solved, in one or two setups.
		</listitem>
		<listitem>
		<para>
Last known 2.6 patch for OPS (parts):
		</para>
<programlisting><![CDATA[
http://marc.theaimsgroup.com/?l=linux-virtual-server&m=115295228311142&w=2
]]></programlisting>
		</listitem>
	</itemizedlist>
	<para>
Threads of interest:
	</para>
<programlisting><![CDATA[
2005-Sep, Oct:
http://marc.theaimsgroup.com/?t=112800269500002&r=1&w=2

2006-Jul:
http://marc.theaimsgroup.com/?t=115260255100003&r=1&w=2
]]></programlisting>
	<para>
"Rudd, Michael" <emphasis>Michael (dot) Rudd (at) tekelec (dot) com</emphasis> 12 Apr 2007
	</para>
	<blockquote>
With the OPS feature turned off, the source
IP address is correctly SNATed to my VIP. With the OPS feature on and
working correctly(which we need for our UDP service), the source IP
address isn't correctly SNATed. 
	</blockquote>
	<para>
Julian 18 Apr 2007 
	</para>
	<para>
	OPS is implemented for setups where there is no reply for the original
packet. 
	</para>
	<para>
DNS and RADIUS have reply, so they need something different (which is not done by OPS):
	</para>
	<itemizedlist>
		<listitem>
every original packet should pass scheduling step
		</listitem>
		<listitem>
reply (or replies) should go back properly, the hash connection
should keep the needed information (VIP, VPORT)
		</listitem>
	</itemizedlist>
	<para>
	So, what you need is something different. OPS now works in this way:
	</para>
	<itemizedlist>
		<listitem>
schedule original packet but don't hash the connection
		</listitem>
		<listitem>
when reply packet is received it can not find connection and the
reply packet is treated as non-IPVS packet (real server receives ICMP
or packets goes further). That is why such replies don't have proper
VIP:VPORT if passed to output device.
		</listitem>
	</itemizedlist>
	<blockquote>
Is anybody aware of the code for this? I assume its related to not
looking up the connection in the hash table anymore with OPS thus not
SNATing. Maybe an iptables rule could fix this possibly? 
	</blockquote>
	<para>
	You can use rule but may be you will not get the right VPORT every
time. Not sure why you need OPS. It was created when someone needed
to generate many requests from same CIP:CPORT with the assumption that
there are no replies. Only when many connections come from same CIP:CPORT
in the configured UDP time period the connection reusing does not
allow scheduling to be used for every packet. That is why OPS was needed
to schedule many packets (coming before expiration) from same
CIP:CPORT->VIP:VPORT to different real servers.
	</para>
	<para>
	May be what you need from OPS is impossible: when OPS is not used
if reply is delayed, IPVS will wait until the configured UDP timeout is
expired, but this value can be different from the timeout your clients is
using. Difference in miliseconds can be fatal. What can happen is that a
different request from same CPORT will go to the same real server as long
as the UDP timeout is not expired. There can be different situations:
	</para>
	<itemizedlist>
		<listitem>
clients can retransmit on some timeout (DNS, RADIUS)
		</listitem>
		<listitem>
nobody is instructed how many requests should be passed (and the same
number of replies if such application mode is used) before removing
NAT connection explicitly before expiration to allow next request to be
scheduled to different real server.
		</listitem>
	</itemizedlist>
	<para>
	So, the main problem is that it is not easy to balance single
CIP to many real servers if there are replies that can be delayed or
when requests can be retransmitted. There is no way IPVS to know when
to forget one connection to allow scheduling for the next packet from
same CIP:CPORT. So, if the client expects replies then OPS should not
be used. Instead, short UDP timeout should be used and one should be
ready single CIP:CPORT to be scheduled to same real server even if
many distinct (from application point of view) requests are sent
from same socket.
	</para>
	<blockquote>
So I send my DNS query to my VIP on my directors. It gets routed to a
realserver which I've attached the vip to bond1.201:0. According to
others I've talked to I shouldn't need an iptables rule but I still
don't see the packet out with the source ip address of the VIP. I see
the packet with the source IP of the actual realserver. Its possible it
is a routing issue though so I plan on digging deeper on that today. 
	</blockquote>
	<para>
	For LVS-DR reply should be generated in real server with src=VIP.
If you ask the question for LVS-NAT then with OPS you will need the
iptables SNAT rule because IPVS does not recognize replies. But I have
never tested such setup. Without OPS you don't need iptables SNAT rule, 
IPVS translates the source address.
	</para>
	<blockquote>
Should I need an iptables rule at all for LVS-DR? 
	</blockquote>
	<para>
	No, reply goes directly from real server to client.
	</para>
	</section>
	<section id="icmp_vipless_directors">
	<title>icmp responses aren't generated by UDP timeouts on VIP-less directors</title>
	<para>
Janusz Krzysztofik <emphasis>jkrzyszt (at) tis (dot) icnet (dot) pl</emphasis> 19 Jan 2007
	</para>
	<blockquote>
I am using LVS director with no VIP for load balancing ipsec servers accessed 
by NAT'ed clients (udp 500/4500, fwmark method). 
When I remove a realserver (<command>ipvsadm -d ...</command>), 
its clients are not notified after their connections expire.  
I suspect that icmp responses are simply not generated on the director as they should be.
	</blockquote>
	<para>
Julian
	</para>
	<para>
	Yes, <command>icmp_send()</command> has code that feeds <command>ip_route_output*()</command> 
with non-local source address (the VIP that is not configured as IP
address in director). The ICMP reply logic is implemented in a way
that ensures the ICMP packet will use local IP address, for example,
when IP router wants to send reply for packet destined to next
hop (looks like our case).
	</para>
	<para>
	The networking maintainers still wait for someone to go and
split all callers of <command>ip_route_output*()</command> to such that require local
source address and others that don't require. The goal is to move
the check for local source address out of <command>ip_route_output</command> to allow
code such as NAT or IPVS to get output route with non-local source
address (may be there are other such uses). Every place should be
audited and check for local IP should be added only if needed.
	</para>
	<para>
	The ICMP reply code is a such place that needs to send ICMP
replies with local address, the receiver should see who generates
the error.
	</para>
	<para>
	So, for the problem in original posting: the IPVS users
that need to send ICMP replies for VIPs should configure the VIPs
in director. I'm not sure there will be another solution. If one
day <command>ip_route_output</command> does not validate the source address may be
icmp_send can rely only on this check as before:
	</para>
<programlisting><![CDATA[
        saddr = iph->daddr;
        if (!(rt->rt_flags & RTCF_LOCAL))
                saddr = 0;
]]></programlisting>
	<para>
	Then director will send ICMP replies from VIPs, 
by using the local-delivery method to accept traffic for VIP.
	</para>
	<para>
	I hope the problem can be solved in another way, <emphasis>e.g.</emphasis>
	</para>
	<itemizedlist>
		<listitem>
isakmp keep alive
		</listitem>
		<listitem>
longer UDP timeout
		</listitem>
		<listitem>
persistency
		</listitem>
	</itemizedlist>
	<para>
	It is against principles UDP users to expect reliability
from internet. See RFC1122, 4.1.1
	</para>
	<para>
Any support for ISAKMP keep alives in your devices?
	</para>
	<para>
Janusz Krzysztofik <emphasis>jkrzyszt (at) tis (dot) icnet (dot) pl</emphasis> 13 Feb 2007 
	</para>
	<para>
If you mean DPD (dead peer detect) - yes, it is supported (I use OpenSwan),
but it does not work very well for me. In my case, several tunnels can use
the same ISAKMP association, and only one of them is removed when the peer
is assumed dead. Other tunnels stay on, ignoring ICMP port unreachable
messages my patched director is sending, until they expire.
My current workaround is not using DPD, but setting a short rekey period (15
mins or less).
	</para>
	<para>
Ratz 5 Feb 2007
	</para>
	<para>
It does generally not make
sense for the director to send notification of the connection expiration
since the connection establishment was between the CIP and VIP. 
The director does not have any open sockets. However, I can understand the need
for such a notification.
If the director knew the endpoint's socket state, we
wouldn't have the need for this opportunistic timeout handling currently
present in IPVS.
From my understanding it's not required from anyone to send ICMP message
back, especially on the grounds of pulling a machine from the network. I
would need to re-read the RFC and study the Steven's diagrams to make a
supported statement.
	</para>
	<para>
Here's Janusz's description of the patch (which is being incorporated into LVS).
If a realserver goes down, then the director being the last
hop is supposed to let the client know that the (virtual) service it was
connected to doesn't exist anymore. Presumably shortly thereafter,
failover will fix up the ipvsadm table and the client gets to pick a new
service?
	</para>
	<para>
Janusz Krzysztofik <emphasis>jkrzyszt (at) tis (dot) icnet (dot) pl</emphasis> 27 Mar 2007 
	</para>
	<para>
Yes, that is it, but there's more too. It acts on a VIP-less director in two cases at least:
	</para>
	<para>
In an overload case, it should allow using the VIP source address in icmp
port unreachable packets which are sent by ip_vs_leave(), "called by ip_vs_in, when
the virtual service is available, but no destination is available for a new
connection" (quote from ip_vs_core.c).
	</para>
	<para>
As you said, but with some tricks:
On my VIP-less fwmark LVS-DR director, I use it for sending icmp port
unreachable packets after a UDP connection is removed when a relaserver goes
down, or it just expires and a packet could be sent to a different
realserver without client knowledge (for TCP, TCP_RESET is sent that does
not need this patch).
	</para>
	<para>
First of all, my LVS-DR traffic all goes through conntrack (see
<ulink url="http://www.austintek.com/LVS/LVS-HOWTO/HOWTO/LVS-HOWTO.LVS-NAT.html#F5_snat">F5_snat</ulink>
http://www.austintek.com/LVS/LVS-HOWTO/HOWTO/LVS-HOWTO.LVS-NAT.html#F5_snat)
Only the first packet of each connection is marked for a specific service to
get IPVS connection entry established. Next packets are just marked for
local routing rule, so they can be seen, matched against existing connection
and redirected by <filename>ip_vs_in()</filename>. If the connection is removed (expired, timeout
after realserver goes down, or immediately with help of <filename>expire_nodest_conn</filename>),
the packet goes through <filename>ip_vs_in()</filename> untouched (no matching connection nor
service) and ends up in <filename>udp_rcv()</filename>, 
where the icmp port unreachable packet with the VIP source address is generated 
and sent to client with help of the patch in question.
	</para>
	<para>
Unfortunately, this does not remove the corresponding conntrack entry
(unlike TCP_RESET does), 
so if a client ignores icmp errors and keeps sending, 
all following packets go the same way and director keeps responding with icmp errors. 
To solve this problem, I have moved <filename>ip_vs_in()</filename> before INPUT filter hook
(http://www.icnet.pl/download/ip_vs_core-input-before-filter.patch), set up
netfilter rules that generate log entries for this case, and set up a
user-space daemon tracing log and removing conntrack entries for
non-existing LVS connections (http://www.icnet.pl/download/delete_connection.sh).
	</para>
	</section>
</section>
<section id="LVS-HOWTO.routing_to_VIP-less_director" xreflabel="routing to a director without a VIP">
<title>LVS: Routing and packet delivery to a director without a VIP (for fwmark and transparent proxy)</title>
	<section id="routing_intro" xreflabel="VIP-less routing info">
	<title>Introduction</title>
	<note>
		<para>
This problem comes up for
<xref linkend="1024_failover"/>.
		</para>
	</note>
	<note>
		<para>
You need this if you are setting up a director
without a VIP.
You don't need a VIP on a director if you're forwarding packets by fwmark,
or if machines are accepting packets by transparent proxy.
(All the simple LVS setups use VIPs on the director.
You can skip this chapter if you aren't using 
fwmark or transparent proxy.)
		</para>
	</note>
	<para>
LVS rearranges the tcip connection that normally requires exchanges
between 2 machines (client &lt;-&gt;server)
so that (for LVS-DR) the packets are moved in a circle
between 3 machines (client-&gt;director-&gt;realserver-&gt;client).
In the case of <xref linkend="LVS-HOWTO.fwmark"/> or
<xref linkend="LVS-HOWTO.transparent_proxy"/>,
the packets from the client are sent to and accepted by
a machine (the director) which doesn't have the IP of the dst_addr.
The routing and tcpip connections must not break the tcpip RFCs
and the client must still think it is connected to one machine.
	</para>
	</section>
	<section id="routing_and_delivery">
	<title>Routing to and accepting packets by a VIP-less director</title>
	<para>
When setting up an LVS on a VIP, normal routing mechanisms will
deliver the packet from the client (with dst_addr=VIP) to the director.
Once the packet has arrived on the director, it will be accepted locally,
as the director has the VIP on one of its ethernet devices.
IPVS picks up the packet from there and forwards it to the
realservers.
	</para>
	<para>
When the director is setup to forward fwmark'ed packets by LVS,
it (usually) will not have an IP that matches the dst_addr
of the client's packets.
The client doesn't know that the LVS is setup with fwmarks
and sends requests to one (or several) VIP:ports.
The fwmark on the director could be put onto packets that consist of
an arbitary grouping of IP:ports.
The VIP:port that the client is connecting to,
is actually on the realservers (which are not replying to arp requests),
but there is no VIP on the director, just some iptables rules
marking the packet and ipvs forwarding the marked packets.
Without a VIP on the director,
normal routing mechanisms will not send the packets to the director.
How does a packet get to the director (or realserver),
which is accepting packets for the VIP,
if the host doesn't have the VIP on an eth device to respond to arp requests?
You have to intervene to make sure the packets get to the director.
	</para>
	</section>
	<section id="route_to_MAC_address">
	<title>Routing to the MAC address of the director</title>
	<para>
This solution is to configure the router by hand to forward
packets with dst_addr to the director.
These rules rely on forwarding the packet
from the router (or test client) to a known MAC address on the director.
	</para>
	<itemizedlist>
		<listitem>
put an entry for the MAC address of the director in the arp table of the
router (see <link linkend="ethers">/etc/ethers</link>.
		</listitem>
		<listitem>
add a route to the router with <command>route add -host ...</command>
		</listitem>
	</itemizedlist>
	<para>
On the realservers in a LVS-DR LVS the routing is already handled for you.
In LVS-DR when the director wants to send a packet to a realserver,
it looks up the MAC address for the RIP and sends the packet with addresses
CIP->VIP by linklayer to the MAC address of the realserver.
Once the packet arrives at the realserver, processes listening to VIP:port
pick up the packet.
	</para>
	<para>
These routing methods do not work well when director failover is required,
as the router tables need to be programmatically
updated about the identity of the new director.
This requires code and you may not have access to the router tables.
	</para>
	<para>
		<note>
The original plan for
<link linkend="keepalived_vrrpd">vrrpd</link>
had a virtual MAC address assigned to an interface.
This MAC address could then be moved to the new director on failover.
Unfortunately Alexandre found this too difficult to code up
due to lack of access to information about the hardware and
the plan has not been implemented.
		</note>
	</para>
	<para>
Normally, once a packet arrives on the director, it is either delivered
locally (if the dst_addr is on the director) or else routed somewhere
(after consulting routing tables). In the case of a director
forwarding by fwmarks, there is neither a VIP for local delivery,
nor routing rules for forwarding packets with dst_addr=VIP.
If you send a packet to a director configured this way,
it will send arp requests "who has VIP, tell director".
	</para>
	</section>
	<section id="julians_iproute2_solutions" xreflabel="Julian's iproute2 solutions">
	<title>Julian's iproute2 solutions</title>
	<para>
Julian 09 Dec 2003
	</para>
	<para>
	Currently, IPVS requires the traffic to VIPs to be locally
delivered (LOCAL_IN). It means the VIPs should be local IPs or
you have to use ip rules selecting table(s) with local route(s).
IIRC, transparent proxy does not work for IPVS in standard 2.4 kernels
as it is in DNAT form.
This is a local route:
	</para>
<programlisting><![CDATA[
ip route add local 0/0 dev lo table XXX
]]></programlisting>
	<para>
Realservers can have fwmark rules to process packets with dst_addr=VIP.
With LVS-DR the routing problem is already handled; the director
sends the packets to the interface with the MAC address of the RIP
(LVS-Tun also routes packets to the realservers).
	</para>
	<para>
Several methods are available to enable local delivery of a packet
which has arrived on a machine which does not have the IP of the dst_addr.
	</para>
	<itemizedlist>
		<listitem>
			<para>
If you are using a single (or small number of) VIPs,
you can put these IPs on the director on an ethernet device or on lo.
			</para>
			<para>
If a range of addresses is required,
an alias can be set to accept a network of addresses,
without assigning an IP to the device
			</para>
			<para>
Horms <emphasis>horms (at) vergenet (dot) net</emphasis> 10 Apr 2000
			</para>
<programlisting><![CDATA[
ifconfig lo:0 192.168.1.0 netmask 255.255.255.0
]]></programlisting>
			<para>
You can now ping anything in the 192.168.1.0/24 network
from the console.
			</para>
			<para>
Note: You can't ping any of those IP's from a remote host
(<emphasis>i.e.</emphasis> after adding a route on the remote host to this network).
If you put this network onto an eth0 alias
(rather than an lo alias),
it won't reply to pings from the console -
presumably the ping replies in the lo:0 case are coming from 127.0.0.1.
			</para>
			<para>
For another example of routing to an interface without an IP,
see <link linkend="route_on_non_ip_interface">
routing to realservers from director in LVS-DR</link>.
			</para>
			<para>
Here's the iproute2 method of getting all packets delivered locally.
This is now the currently preferred method of arranging for packets
to be accepted locally.
			</para>
			<para>
Julian 7 Jul 2002
			</para>
			<blockquote>
				<para>
The local routes are used for transparent proxy, for example:
				</para><para>
http://marc.theaimsgroup.com/?l=linux-virtual-server&amp;m=101674735204704&amp;w=2
				</para><para>
The recipe is
				</para>
<programlisting><![CDATA[
ip rule add prio 100 fwmark 1 table 100
ip route add local 0/0 dev lo table 100
]]></programlisting>
				<note>
Joe: you might (should?) be able to route packets to the VIP this way, 
allowing packets for an IP which is not on the machine to be
accepted by LVS.
				</note>
				<para>
If you have just 1 VIP, you don't need these rules, you can just setup
the VIP on the director in the normal manner
				</para>
<programlisting><![CDATA[
ifconfig eth0:1 90.0.0.35 netmask 255.255.255.255
]]></programlisting>
			</blockquote>
			<para>
In many ways, having an IP on the director for no other reason
than so that it can accept the packet, is a step backwards.
			</para>
			<blockquote>
Joe 9 Jul 2002: is it possible/reasonable/sensible for ipvs,
when forwarding fwmarks,
to pick the marked packet up from the PREROUTING chain (or wherever it is)?
Currently ipvs needs an IP or a functional equivelent of
ipchains redirect to be able to get the packet.
			</blockquote>
			<para>
Julian: Yes, it is useful for some cases. Such feature is in the
bottom of our TODOs but requires many changes, including breaking
the routing func prototypes. So, for now the answer is no :)
			</para>
		</listitem>
		<listitem>
			<para>
(for 2.2.x kernels)
you can use <xref linkend="LVS-HOWTO.transparent_proxy"/>
to accept packets for the VIP
			</para>
			<para>
Transparent proxy code was written for squids to allow
them to accept packets destined for remote addresses.
Only the transparent proxy code for kernel 2.2.x works for LVS.
With this code the packet arrives with dst_addr=VIP and
is picked up by ipvs.
With the 2.4.x kernels, the packet arrives with dst_addr=127.0.0.1.
This is fine for squids, but ipvs ignores the packet.
It's unfortunate that by the time the netfilter people were
informed that this was a problem for us, the new code
was too entrenched and they didn't want to change it.
			</para>
			<para>
Transparent proxy in the standard 2.4.x kernels, where most
future development of LVS will be, does not work for LVS.
RedHat have patched their kernel so this is fixed
(Mike McLean <emphasis>mikec (at) redhat (dot) com</emphasis>
4 Dec 2002).
			</para>
			<note>
<xref linkend="Balazs"/> has patched the 2.4 kernel to restore
the original transparent functionality.
			</note>
		</listitem>
	</itemizedlist>
	<para id="hook_pre_routing" xreflabel="LVS hook in PRE_ROUTING">
Horms (from a thread on another topic)
	</para>
	<para>
Use a fwmark service and be rid of your VIP on an interface all together.
	</para>
	<para>
Joe 26 Aug 2003
	</para>
	<blockquote>
getting rid of the VIP altogether is still a bit of a problem isn't it?
there are solutions that apparently came originally from Julian
(urls in the archive were then listed).
	</blockquote>
	<para>
<ulink url="http://marc.theaimsgroup.com/?l=linux-virtual-server&amp;m=106020019020431&amp;w=2">
http://marc.theaimsgroup.com/?l=linux-virtual-server&amp;m=106020019020431&amp;w=2</ulink>
pretty straight forward and basically the way fwmarks
work if you are using them for more than one IP address, which
was the reason fwmarks were origionally added to the LVS code.
	</para>
	<para>
The route commands are needed because ipvs is called after routing takes
place. I think that in the case of fwmarks it would be best to move the
code to the prerouting stage to avoid the need for this. I.e. hook
ip_vs_in into NF_IP_PRE_ROUTING instead of NF_IP_LOCAL_IN.
	</para>
	<blockquote>
what will this get us? Will we still need the route command? Are you
going to do implement it, or are you just thinking out loud?
	</blockquote>
	<para>
Horms
	</para>
	<para>
Yes, it will remove the requirement for traffic to be local.
I made the change - it is one line - and very briefly tested it.
It seemed to work quite well. But it is a change that will most
likely have side effects so it warrants further thought
and investigation.
	</para>
	<para>
Julian
	</para>
	<para>
	such move can allow IPVS not to require local
delivery. There will be some issues with properly identifying
the direction of the packets but it is possible to implement. The
problem is that we are stuck with the netfilter hooks. If we move out of
the hooks or if we add some changes to the kernel we can do
everything including proper routing for inout packets (working
with multiple ISPs), avoiding the LOCAL_IN->LOCAL_OUT problems
that start to appear with 2.6, etc. May be we will need ROUTING
hook. IIRC, fwmark is present in PRE_ROUTING but such move can
create some compatibility problems, are all we ready for this?
	</para>
	<para>
Horms
	</para>
	<para>
In <ulink url="http://marc.theaimsgroup.com/?l=linux-virtual-server&amp;m=106020171022117&amp;w=2">
http://marc.theaimsgroup.com/?l=linux-virtual-server&amp;m=106020171022117&amp;w=2
</ulink>
the packets are delivered locally because of the "local" in
	</para>
<programlisting><![CDATA[
ip route add local 0/0 dev lo table 100
]]></programlisting>
	<para>
Again, this isn't really the way it was supposed to work AFAIR.
	</para>
	<blockquote>
if/since Julian's routing method works, why do we need transparent proxy (if we ever did)?
	</blockquote>
	<para>
Julian
	</para>
	<para>
The people have alternatives, all these methods differ in some
way and can be selected according to their behaviour. IPVS is
liberal for the local delivery method.
	</para>
	<para>
	Note the main things:
	</para>
	<itemizedlist>
		<listitem>
fwmark is a common way to mark packets in the kernel, provided
from the firewall functionality
		</listitem>
		<listitem>
IPVS can use this marking to know which packets are destined for
the virtual service (fwmark-based servers)
		</listitem>
		<listitem>
		<para>
the local delivery does not depend on fwmark, i.e. you can safely
route locally without using fwmarks, <emphasis>e.g.</emphasis>
		</para>
<programlisting><![CDATA[
# select incoming packets by DADDR
ip rule add prio 100 to VIP1 table 100
ip rule add prio 100 to VIP2 iif eth0 table 100
ip rule add prio 100 to VIP3 iif eth1 table 100
# and deliver them locally
ip route add local 0/0 dev ANY_DEVICE table 100
]]></programlisting>
		<para>
Note ANY_DEVICE: it does not matter until you try to play
with the device state, lo is preferred as it is always up
		</para>
		</listitem>
	</itemizedlist>
	<para>
This routing method does not handle ICMP errors, because it is assumed
the VIPs are not configured as local IPs. The current kernels
have checks for local source IP when generating packets (icmp_send
uses ip_route_output which has such checks starting from 2.4) and
if they are not configured as local IPs, then the reply is not generated.
So, there are some corner cases where the kernel does not like
our local delivery methods. If that is considered a problem,
better the VIP to be configured locally.
	</para>
		<note>
Joe: If you're being secure about your LVS, you aren't going to have a route
from the VIP on the director back to the outside world
(see <xref linkend="Pearthree"/>) and you won't be sending back
icmp traffic anyhow).
		</note>
	<para>
As for the original subject, the LVS directors can not be
realservers, clients and backup servers at the same time
for the same virtual service.
The VIP must be announced only
from one director.
If the backup director has the VIP configured
then it cannot communicate with other hosts from the cluster.
Also, the backup server must not create ARP problem if the VIP
is configured there.
	</para>
	<para>
Joe
	</para>
	<blockquote>
Can you set up a squid then with this routing method, without using transparent proxy?
	</blockquote>
	<para>
Julian
	</para>
	<para>
	I thought the people know about/use such alternative:
	</para>
<programlisting><![CDATA[
http://marc.theaimsgroup.com/?l=linux-virtual-server&m=101723197128822&w=2
http://marc.theaimsgroup.com/?l=linux-virtual-server&m=101674735204704&w=2
]]></programlisting>
	<para>
	may be someone has experience with this method and he
can provide actual settings. It is useful in setups where the packet
header must be preserved. IIRC, 2.4 TP breaks this rule.
	</para>
	<para>
Joe
	</para>
	<blockquote>
Is this routing method a a generalised way of accepting packets
on the director when using fwmark with LVS?
	</blockquote>
	<para>
Horms
	</para>
	<para>
I was wondering that on the way home last night. I would suspect so.
It has the potential to cover a lot of issues in a manner
that is supported by stock kernels. That would be nice.
But then again those issues may disappear if LVS was moved
to prerouting.
	</para>
	</section>
	<section id="ludos_LVS_target" xreflabel="Ludo's LVS target in iptables">
	<title>Ludos LVS target in iptables</title>
	<para>
For <xref linkend="LVS-HOWTO.ludos_reinject_forwarder"/>
the director needs to accept packets with dst_addr=0/0
	</para>
	<para>
I don't force the director to accept the packets as local packets.
I modified the kernel to send all forwarded traffic into LVS.
Thus I force the director to accept them as forwarded packets! This is
the purpose of the "LVS" iptables target.
No need for other fancy tricks, just match the traffic in iptables and use "-j
LVS" as the target.
This patch
provides an iptables target called "LVS" which calls the entry
function of LVS. Thus you can match the traffic to the VIP on the
FORWARD hook of iptables:
	</para>
<programlisting><![CDATA[
#iptables -A FORWARD -t mangle -d <VIP> -m state --state NEW -j MARK - --set-mark 1
#iptables -A FORWARD -t mangle -m mark --mark 1 -j LVS
]]></programlisting>
	<para>
This last line mimics the behaviour of packets going to the director
directly, it will call the LVS functions as if the packet was on the
local-delivery path.
	</para>
	</section>
	<section id="TP_QandA">
	<title>Transparent proxy Q and A</title>
	<para>
Q. Some demons listen only to specific IPs. What IP is the telnet/httpd
listening to when it accepts a connection by transparent proxy?
	</para>
	<para>
A. It depends where you are when you make the connect request
(this is for 2.2.x kernels).
	</para>
	<para>
example:
	</para>
	<para>
You are on the console of a host and add x.x.x.111:http by transparent
proxy and setup the httpd to listen to x.x.x.111:80.
You cannot ping x.x.x.111. To connect to x.x.x.111:http you need to
	</para>
<programlisting><![CDATA[
# route add -host 192.168.1.111 lo
]]></programlisting>
	<para>
(adding a route to eth0 does not work).
	</para>
	<para>
If you go to an outside machine, you still cannot ping x.x.x.111 and you
cannot connect to x.x.x.111:http unless you make the target box the default gw
or add a host route to x.x.x.111.
	</para>
	<para>
If you now go back to the console of the transparent proxy machine and
change the httpd to listen to 127.0.0.1:http (and not to x.x.x.111:http)
you can still connect to x.x.x.111:http even though nothing is listening to that
IP:port (linux tcpip does local delivery to local IPs).
(You can also connect to 127.0.0.1:http, but this is not concerned with
transparent proxy.)
	</para>
	<para>
Returning to the outside machine, you cannot connect to x.x.x.111:http.
	</para>
	<para>
The connections from the outside machine model connections to the director
with the VIP by transparent proxy, while the connections from the console
model the realserver which has a packet delivered from the director.
On the realserver you could have your services listening to 127.0.0.1
rather than the VIP. You may run into DNS problems (see <link linkend="indexing">Running
indexing programs</link>) if the process listening to 127.0.0.1 doesn't know that
it's answering to lvs.domain.org.
	</para>
	</section>
	<section id="other_tricks">
	<title>Other tricks</title>
	<para>
For other examples of routing and accepting packets without IPs,
look at the section on <link linkend="Pearthree">default gw for LVS-DR</link>.
	</para>
	</section>
</section>
<section id="LVS-HOWTO.fwmark" xreflabel="firewall mark (fwmark)">
<title>LVS: Fwmarks (firewall marks)</title>
	<section id="fwmark_intro">
	<title>Introduction</title>
	<note>
		<para>
<emphasis>fwmark nomenclature:</emphasis>
		</para>
		<para>
Karl Kopper (Apr 2004) said that he thinks the correct term for this is "netfilter mark". 
A google search finds references to "netfilter mark" back to 2001, 
and with "fwmark" current at least to 2003. Both terms seem to be in use.
The various netfilter HOWTOs don't say anything about new terminology.
Horms (who wrote the fwmark code) doesn't know anything about a change in terminology,
but thinks it's possible that fwmark is the implementation of netfilter marks.
		</para>
		<para>
I asked Harald Welte about this at OLS_2004 and the explanation was as clear as day, 
except that I didn't write it down and now I've forgotten it (geez, sorry about this).
It was a matter of nomenclature rather than logic: it was something like -
the entity in the command line is called a <emphasis role="bold">mark</emphasis>
while the method of marking packets is called <emphasis role="bold">fwmark</emphasis>.
Whatever it is, you can use either term and people will know what you're talking
about.
		</para>
	</note>
	<para>
fwmark is a way of aggregating an arbitary collection of VIP:port services into
one virtual service (the entry made with <command>ipvsadm -A</command>).
Thus a virtual service could be composed of multiple VIP:ports
(<emphasis>e.g.</emphasis> VIP1:port1, VIP2:port2...VIPn:portn).
This is usefull if the client needs to connect to all of the VIP:port
services together on one realserver.
	</para>
	<para>
Common uses for fwmark are
	</para>
	<itemizedlist>
		<listitem>
aggregate VIP:http and VIP:https,
so that when a client fills their shopping cart on VIP:http and they
move to VIP:https (to give their credit card information),
they will stay on the same realserver.
		</listitem>
		<listitem>
with multi-port services like ftp
(there are some wrinkles with ftp, since the 2nd port calls from
the realserver rather than from the client
- read the setup of ftp elsewhere in this section
and in <xref linkend="ftp"/>).
		</listitem>
		<listitem>
when the realserver is a squid. 
All traffic to port 80 (for all IPs) is aggregated with a fwmark.
		</listitem>
	</itemizedlist>
	<para>
A minor advantage is that a realserver can be added,
removed and re-weighted with one ipvsadm command.
To enable fwmark, the packets coming into the director have to
be labelled with a fwmark (some bits are flipped in the tcp packet).
This is done with iptables (or ipchains).
	<note>
	<para>
The fwmark is only a part of the packet while it stays in the skb of the
machine which marked the packet (here the director).
The fwmark is not on the packet when the packet is put out on the external network
(<emphasis>i.e.</emphasis> the fwmark that is put on the packet
when it is on the director is not on the packet when it arrives at the realserver).
	</para>
	</note>
Once the component services are fwmark'ed,
filtering (with iptables/ipchains) can be done on the fwmark,
rather than on the individual IP:ports.
	</para>
	<para>
The original method for setting up an LVS used
the VIP as the target for <command>ipvsadm</command> commands.
Using the VIP as the target, it is possible for LVS to forward multiple services
on the same VIP and to forward packets for several different VIPs.
However this method does not scale well to large numbers of
services or IPs.
As well, the connections to each service are independant,
unless persistence is invoked.
	</para>
	<para>
The more flexible fwmark method was introduced by Horms in Apr 2000.
Ted Pavlic then showed how used fwmarks to group arbitary services.
In this way connection to two otherwise independent services,
<emphasis>e.g.</emphasis> http and https,
will be linked as one service as far as ipvs is concerned
and the client will stay on the same realserver for both services.
The fwmarks method is more flexible and simpler to administer for large
numbers of services than is the VIP method.
	</para>
	<para>
fwmark is used
	</para>
	<itemizedlist>
		<listitem>
	to group services together within a single LVS <emphasis>e.g.</emphasis>
		<itemizedlist>
			<listitem>
		group 1 - port 80,443 for an e-commerce site
			</listitem>
			<listitem>
		group 2 - port 20,21 for an ftp server
			</listitem>
		</itemizedlist>
		</listitem>
		<listitem>
	group large numbers of VIPs together
		</listitem>
	</itemizedlist>
	<para>
Setting up an LVS on fwmarks rather than the VIP is now the method
of choice for setups with multiple VIPs or a group of ports that
need to be aggregated.
	</para>
	<para>
fwmark can be used with all forwarding methods and should have no
affect on performance (throughput, latency).
	</para>
	<para>
Fwmarks are numbers but can be translated into names using the
<link linkend="fwmark_nametable">fwmark name translation table</link> patch.
	</para>
	<para>
Some history from Horms 
(this 
has also been described in &quot;Wired&quot; Magazine - 
see <xref linkend="LVS_in_the_news"/>).
	</para>
	<blockquote>
		<para>
The story starts with a trip from Sillicon Valley, where I was working
for VA Linux Systems, to a VA Linux Systems Professional Services customer
site in Fort Laurderdale.
It was mid-February 2000.
I was called onsite to help sway the customer towards using LVS.
The customer was interested in using LVS for a very
large number of customers. Part of their requirement called for a very
large number of virtual services to be configured.  I suggested that we
could simplify this by collecting the virtual services into contiguous
network blocks and modifying LVS to recognised all addresses in a block
as belonging to a virtual service.  The customer seemed to like this
idea.
My original proposal and implementation was
to allow virtual services based on netmasks.
Wensong rejected this because of some potential performance issues.
		</para>
		<para>
I distinctly remember working on the original implementation on a
train trip from the Blue Mountains to Sydney's Central Station
with my then girlfriend. By the
time I had to change trains go to Wynyard the code was working :)
		</para>
		<para>
When I got back home to Sillicon Valley I finished off the changes
and emailed them to Wensong.
That was
on the 20th March. He wasn't particularly happy with some aspects
of the change, particularly some performance overhead that
my implementation introduced. I made some changes and sent him
a new version. He suggested making the new code optional, I made
that so too. We exchanged email and code for about a week.
		</para>
		<para>
A few days latter Julian came up with the idea of using a fwmark,
a feature of the ip_masq code that had been around for a while,
but wasn't heavily used.
Wensong passed this on to me (30 Mar).
Wensong clearly was not happy with my approach to the problem and
suggested the implementation that he and Julian had hashed out.
The change involved using netfilter (iptables) to handle deciding
which packets belong to a virtual service, rather than putting
that logic into LVS itself - it was this portion of the code
that Wensong was worred about the performance of.
		</para>
		<para>
We talked this over a little bit over email and I implemented
the idea. On the 6th of April I sent the new code to Wensong
and Julian. On the 7th Wensong wrote back explaining a few changes
he was going to make, mostly involving having the code always
compiled in rather than making it an option as there didn't appear
to be any performance overhead in the new code. The new option,
which by then was known as firewall mark virtual services was
included in IPVS 0.9.10 which was released on the 9th April.
Minor fixes were made, mainly by Wensong over the following
few months and made it into subsequent releases.
		</para>
		<para>
I wrote the kernel, <command>ipvsadm</command> and ldirectord changes
and largely have maintained them ever since.
		</para>
		<para>
It is of note that as a part of the work that came out of this customer the
-R and -S options to <command>ipvsadm</command> were suggested and implemented by myself.
These were released just before the inclusion of the fwmark code.
		</para>
		<para>
This customer was also the impetus for putting together what is now known
as Ultra Monkey. All in all quite an interesting outcome for a couple of
days on site. Pleasingly I believe that the customer in question is using
Ultra Monkey with the fwmark support in LVS.
		</para>
	</blockquote>
	<para>
A bio of Horms:
	</para>
	<blockquote>
		<para>
I am from Sydney Australia. I have been involved
in Linux for, well, a long time. My main area of expertise
is High Availability and Load Balancing. Though anything
from email to routing is just fine by me. You can see
a list of the projects I have worked on as well as the papers
that I have presented at confereneces on my
<ulink url="http://www.vergenet.net/linux/">web page</ulink>
(http://www.vergenet.net/linux/).
		</para>
		<para>	
I used to work at VA Research which became VA Linux Systems
until they changed their business model and became
VA Software. During that time I was based in Sillicon Valley,
New York City and Sydney (though not all at the same time :).
I currently work for VA Linux Systems Japan, in Tokyo - which
I should point out is majority owned by the Sumitomo Coropration and
is independant of VA Software (USA) these days. I primarily
work on the Ultra Monkey Project in conjunction with NTT Commware.
		</para>
		<para>
<ulink url="http://www.ultramonkey.org/">http://www.ultramonkey.org/</ulink>,
<ulink url="http://www.vasoftware.com/">http://www.vasoftware.com/</ulink>,
<ulink url="http://www.valinux.co.jp/">http://www.valinux.co.jp/</ulink>,
<ulink url="http://www.nttcom.co.jp/">http://www.nttcom.co.jp/</ulink>.
		</para>
	</blockquote>
	<para>
(Joe) I first saw Horms when he gave a talk at the 4th Annual Linux Expo at
Duke University, Durham, NC in May 1998, on
<ulink url="http://www.vergenet.net/linux/redundant_linux_paper/">
Creating Redundant Linux Servers</ulink>
(http://www.vergenet.net/linux/redundant_linux_paper/).
Although I attended the talk and thought it pretty neat,
it never occured to me to introduce myself.
Later when we both joined the LVS project,
it took quite some time before I connected Horms on the LVS mailing list
with the person who gave the presentation at the Linux Expo.
	</para>
	<para>
Sample configurations/topologies for fwmarks are at
<ulink url="http://www.ultramonkey.org/">Ultramonkey</ulink>.
	</para>
	</section>
	<section id="ipvsadm_fwmark_syntax">
	<title>ipvsadm syntax for fwmark</title>
		<section id="fwmark_and_ipvsadm">
		<title>ipvsadm command ignores ports, fwmark can't translate ports</title>
		<para>
You can enter a port number with a fwmark command with <command>ipvsadm</command>
but it is ignored.
		</para>
		<para>
Leonard Soetedjo
		</para>
		<blockquote>
		<para>
From the HOWTO, when using fwmark, I can set the port to be 0.  Is this
correct?  Is it ok if I do that for a single port service such as telnet?
for example
		</para>
<programlisting><![CDATA[
iptables -t mangle -A PREROUTING -i eth0 -p tcp -s 0/0 -d VIP --dport telnet -j MARK --set-mark 1
ipvsadm -a -f 1 -r RS1:0 -g -w 1
]]></programlisting>
		<para>
Is the use of "0" not important? i.e. I can set to whatever I want?
		</para>
		</blockquote>
		<para>Horms 17 Dec 2002:
The LVS kernel code that handles fwmarks really doesn't care about ports
at all. If you want a service to match on specific ports, then you
should set up the iptables rules to only mark packets to that port or
ports.
		</para>
		<para>
nick garratt Mar 25, 2004
		</para>
		<blockquote>
			<para>
I'm experiencing issues with port translation using LVS-NAT and FWMARK:
 			</para>
<programlisting><![CDATA[
iptables -t mangle -A PREROUTING -d VIP -p tcp -m tcp --syn --dport 1237:1239 -j MARK --set-mark 1238

ipvsadm -A -f 1238 -s wlc -p 900
ipvsadm -a -f 1238 -r 192.168.20.1:1237 -m -w 5 # daemon instance 1
ipvsadm -a -f 1238 -r 192.168.20.1:1238 -m -w 5 # daemon instance 2
]]></programlisting>
			<para>
 What I am trying to achieve is the following:
 we have a custom written SMPP service that accepts two connection
 (transmitter and receiver) from a client. We have run into problems
 with maximum threads per process and large numbers of binds. As an
 interim measure we are considering running multiple instances of the
 daemon on the same server. Its is imperative that a user's two binds
 are routed to the same daemon instance. The user may connect to a
 port range so as to allow them to specify different receiver and
 transmitter ports according to their whim or the peculiarities of
 their client software but the daemon instance will handle both
 connections on the same port.
			</para>
			<para>
 The intention is to group the VIP port range using FWMARK as we do
 with many other services and load balance them across the RIP service
 ports ensuring that:
 			</para>
<programlisting><![CDATA[
 userIP:56789 -> VIP:1237 -> RIP:n
 userIP:56790 -> VIP:1238 -> RIP:n
]]></programlisting>
			<para>
 where n is the same port guaranteed by persistence.
 Problem: FWMARK and LVS-NAT port translation does not seem to work at
 all. what actually happens is:
 			</para>
<programlisting><![CDATA[
 userIP:56789 -> VIP:1237 -> RIP:1237
 userIP:56790 -> VIP:1238 -> RIP:1238
]]></programlisting>
			<para>
 which splits the binds across daemon instances.
			</para>
		</blockquote>
		<para>
Horms <emphasis>horms (at) verge (dot) net (dot) au</emphasis> 06 Apr 2004
		</para>
		<para>
Yes, port translation does not work with fwmarks, because there is no
way for LVS to tell what the port translation should be. In a fwmark
service the virtual service does not have a port (or address for that
matter). So it can't know that it is accepting packets for, say port
1237, and then use the realserver entry to translate that to port 1237
(not much of a translaton) or 1238 (or anything else). It has to just
assume that the port will be unchanged.
		</para>
		<para>
It would be possible to modify LVS to allow this kind of translation
to take place, but it isn't immediately obviously how this would
be configured.
		</para>
		<blockquote>
			<para>
 Another approach to the problem is to configure multiple virtual
 interfaces on my realserver, get the daemon instances to bind to
 specific IPs/same port ranges and handle as per normal i.e. no port
 translation:
			</para>
<programlisting><![CDATA[
iptables -t mangle -A PREROUTING -d VIP -p tcp -m tcp --syn --dport 1237:1239 -j MARK --set-mark 1238

ipvsadm -A -f 1238 -s wlc -p 900
ipvsadm -a -f 1238 -r 192.168.20.11:0 -m -w 5 # daemon instance 1 listening on 1237 - 1239
ipvsadm -a -f 1238 -r 192.168.20.12:0 -m -w 5 # daemon instance 2 listening on 1237 - 1239
]]></programlisting>
			<para>
 However I would prefer to keep down the number of IPs I need to failover.
			</para>
		</blockquote>
		<para>
I would suggest doing this. You shouldn't need to failover
the IP addresses of your realservers anyway. Just use something like
ldirectord to monitor their availability and manipulate the LVS
table accordingly.
		</para>
		</section>
	</section>
	<section id="routing_to_director">
	<title>setting up routing and packet delivery to the director</title>
	<para>
If you are accepting packets by a fwmark rather than by the VIP,
then (in principle) you don't need the VIP on the node with the fwmark rules
(which could be either the director or realserver).
	</para>
	<para>
To get a working LVS without configuring the VIP on a machine,
you need to
	</para>
	<itemizedlist>
		<listitem>
be able to deliver the packets to
the machine concerned (arp now won't be able to find the machine with the VIP)
		</listitem>
		<listitem>
and you have to arrange for the machine with the fwmark rules to accept
the packet locally.
The node normally only accepts a packets for an address on the machine.
Without the VIP, the node will forward the packet to somewhere else.
It should be possible to arrange for LVS to accept the packet,
and Julian has said this is possible, but he's working on other things
right now.
		</listitem>
	</itemizedlist>
	<para>
To do the examples below, you can either setup the fwmarks to mark
only one IP (the VIP) and install the VIP on the director, or you
can read the section on
<link linkend="routing_and_delivery">routing and delivery</link> of packets
and use one of the methods suggested there.
	</para>
	</section>
	<section id="fwmark_telnet">
	<title>single-port service: telnet with fwmarks</title>
	<para>
Assuming you already have setup the networks and default gw for the machines
in your LVS, here's how you'd setup telnet <emphasis>without</emphasis> fwmarks
(<emphasis>i.e.</emphasis> the "normal" method, using the VIP as the target for <command>ipvsadm</command> commands)
on a two realserver LVS-DR.
	</para><para>
<programlisting><![CDATA[
#make a table for connections to VIP:telnet, with round robin scheduling
#schedule realserver RS2 for connections to VIP:telnet, weight=1, forwarding method=DR
#schedule realserver RS1 for connections to VIP:telnet, weight=1, forwarding method=DR
director:# ipvsadm -A -t VIP:telnet -s rr
director:# ipvsadm -a -t VIP:telnet -r RS2:telnet -g -w 1
director:# ipvsadm -a -t VIP:telnet -r RS1:telnet -g -w 1
]]></programlisting>
	</para><para>
Here's how to do the same thing with fwmarks.
You first mark the packets with ipchains or iptables.
	</para>
		<section id="fwmark_ipchains">
		<title>ipchains for 2.2.x director</title>
		<para>
Here's the recipe for setting a fwmark with ipchains:
		</para><para>
<programlisting><![CDATA[
#flush ipchains tables
#mark with value=1, tcp packets from anywhere,
#arriving on eth1 (holds the VIP on my setup),
#with dst_addr=192.168.2.110 (the VIP) for port telnet
#show ipchains tables
director:# ipchains -F
director:# ipchains -A input -p tcp -i eth1 -s 0.0.0.0/0 -d 192.168.2.110/32 \
	--dport telnet -m 1
director:# ipchains -L input
Chain input (policy ACCEPT):
target     prot opt     source                destination           ports
-          tcp  ------  anywhere             lvs2.mack.net         any ->   telnet
]]></programlisting>
		</para>
		</section>
		<section id="iptables_fwmark">
		<title>iptables for 2.4.x director</title>
		<para>
Here's the recipe for setting a fwmark with iptables:
		</para>
		<para>
The iptables parameters are taken from an example by
Paul Schulz
(http://www.foursticks.com.au/&#126;pschulz/qos/pfifo.sample,
link dead Jan 2003),
which I found through
<ulink url="http://www.google.com">google</ulink>.
			</para><para>
First put a mark of value=1 on tcp packets which arrive from anywhere
with dst_addr=VIP:telnet (the VIP is on eth1 in my setup).
			</para><para>
<programlisting><![CDATA[
#flush the mangle table
#in the skb, put mark=1 on all tcp packets arriving on eth1 from anywhere, with dest=VIP:telnet
#output the mangle table, just for a look
director:# iptables -F -t mangle
director:# iptables -t mangle -A PREROUTING -i eth1 -p tcp -s 0.0.0.0/0 -d 192.168.2.110/32 \
	--dport telnet -j MARK --set-mark 1
director:/etc/lvs# iptables -L -t mangle
Chain PREROUTING (policy ACCEPT)
target     prot opt source               destination
MARK       tcp  --  anywhere             lvs2.mack.net       tcp dpt:telnet MARK set 0x1

Chain OUTPUT (policy ACCEPT)
target     prot opt source               destination
]]></programlisting>
			</para><para>
The fwmark is only associated with the packet while it is in
the director skb (socket buffer).
The packet which emerges from the director and is forwarded
to the realserver is a normal (unmarked) packet.
(You can't use the director's fwmark information when the
packet arrives on the realserver to
decide on how to handle the packet.)
		</para>
		</section>
		<section id="install_fwmark_with_ipvsadm">
		<title>install the LVS with ipvsadm</title>
<programlisting><![CDATA[
#setup an ipvsadm table for packets with mark=1,
#schedule them with round robin.
#schedule realserver RS1 for connections with mark=1, forwarding method=DR, weight=1
#schedule realserver RS2 for connections with mark=1, forwarding method=DR, weight=1
director:# ipvsadm -A -f 1 -s rr
director:# ipvsadm -a -f 1 -r RS1.mack.net:telnet -g -w 1
director:# ipvsadm -a -f 1 -r RS2.mack.net:telnet -g -w 1
]]></programlisting>
		<para>
Here's the output of ipvsadm
		</para>
<programlisting><![CDATA[
director:/etc/lvs# ipvsadm
IP Virtual Server version 0.2.7 (size=4096)
Prot LocalAddress:Port Scheduler Flags
  -> RemoteAddress:Port               Forward Weight ActiveConn InActConn
FWM  1 rr
  -> RS2.mack.net:23                  Route   1      0          0
  -> RS1.mack.net:23                  Route   1      0          0
]]></programlisting>
		<para>
You can now telnet to the VIP. You'll get the expected round robin
scheduling of your connections to RS2 and RS1.
		</para>
		</section>
	</section>
	<section id="single_group">
	<title>Grouping services: single group, active ftp(20,21)</title>
	<para>
The telnet example above could equally well be done using
the VIP or a fwmark as the target for <command>ipvsadm</command> commands.
The same is true for any one port service, where connections
to services are made independantly of each other.
Sometimes we need to group services together,
<emphasis>e.g.</emphasis> port 20,21 for an ftp server or port 80, 443 for an e-commerce site.
With persistence, you can only make ports persistent singly (but
you can make persistent as many or as few as you want, they will be
persistent independently); or make all ports persistent at once (with the
:0 option), in which case persistence of the ports will be linked.
There is no way to make pairs (or groups) of ports persistence
with the current persistence code.
The current method for handling this,
<xref linkend="LVS-HOWTO.persistent_connection"/>,
links all ports on the VIP, and the director will forward
connections to all ports, not just the two we are interested in.
For security purposes, if persistence is used to group services, then
connection requests to the other ports will have to be blocked.
Although workable, it's an ugly solution.
			</para><para>
For background on how the specifications for fwmarks were set to
allow services to be grouped,
see <link linkend="fwmarks_persistence">Appendix 1</link> for the
initial discussion between Ted and the LVS developers (Horms and Julian),
<link linkend="fwmarks_persistence_proof_of_principle">Appendix 2</link> where
Ted let me know that he'd had it working, and
<link linkend="fwmarks_persistence_announcement">Appendix 3</link> for
Ted's announcement to the mailing list.
			</para>
		<section id="port_grouping">
		<title>port grouping using VIP and persistence</title>
		<para>
Here's an example grouping ports 20,21 for ftp.
This uses persistence and the VIP as the target for <command>ipvsadm</command> commands
(this is the original, VIP way of setting up ftp).
			</para><para>
<programlisting><![CDATA[
#make a table for connections to all ports on VIP
#with round robin scheduling, persistence timeout=360secs
#schedule realserver RS2 for connections to all ports on VIP, weight=1, forwarding method=DR
#schedule realserver RS1 for connections to all ports on VIP, weight=1, forwarding method=DR
director:# ipvsadm -A -t VIP:0 -s rr -p 360
director:# ipvsadm -a -t VIP:0 -r RS1.mack.net:0 -g -w 1
director:# ipvsadm -a -t VIP:0 -r RS2.mack.net:0 -g -w 1
]]></programlisting>
			</para><para>
Here's the output of ipvsadm
			</para><para>
<programlisting><![CDATA[
director:/etc/lvs# ipvsadm
IP Virtual Server version 0.2.7 (size=4096)
Prot LocalAddress:Port Scheduler Flags
  -> RemoteAddress:Port               Forward Weight ActiveConn InActConn
TCP  lvs2.mack.net:0 rr persistent 360
  -> RS1.mack.net:0                   Route   1      0          0
  -> RS2.mack.net:0                   Route   1      0          0
]]></programlisting>
			</para><para>
After the client has made the initial connection on port 21, then any subsequent
connection on port 20 (within the 360sec timeout period)
will go to the same realserver.
			</para><para>
The problem is that the director will forward to the same realserver,
connection requests made to any port by the client.
If we have listeners on port 80 and 443 on the realserver,
then these services will be linked to each other (which we may want),
and they will also be linked to the ftp service (which we may not want).
If you telnet to the VIP, this request will be forwarded to the
realservers too (in production you'll have to block this).
		</para>
		</section>
		<section id="grouping_with_fwmark">
		<title>grouping with fwmarks</title>
		<para>
Here's how to setup an ftp server with fwmarks.
First mark the packets of interest with ipchains or iptables
(<emphasis>i.e</emphasis> mark all tcp packets destined for VIP:ftp
and VIP:ftp-data arriving on eth1).
			</para>
			<section>
			<title>ipchains for 2.2 director</title>
<programlisting><![CDATA[
#flush ipchains tables
#mark ftp packets
#put the same mark on ftp-data packets
#show ipchains tables
director:# ipchains -F
director:# ipchains -A input -p tcp -i eth1 -s 0.0.0.0/0 -d 192.168.2.110/32 \
	--dport ftp -m 1
director:# ipchains -A input -p tcp -i eth1 -s 0.0.0.0/0 -d 192.168.2.110/32 \
	--dport ftp-data -m 1
director:# ipchains -L input
Chain input (policy ACCEPT):
target     prot opt     source                destination           ports
-          tcp  ------  anywhere             lvs2.mack.net         any ->   ftp
-          tcp  ------  anywhere             lvs2.mack.net         any ->   ftp-data
]]></programlisting>
			</section>
			<section>
			<title>iptables for 2.4 director</title>
<programlisting><![CDATA[
#clear mangle table
#mark ftp packets
#put the same mark on ftp-data packets
#show mangle table
director:# iptables -F -t mangle
director:/etc/lvs# iptables -t mangle -A PREROUTING -i eth1 -p tcp -s 0.0.0.0/0 -d 192.168.2.110/32 \
	--dport ftp -j MARK --set-mark 1
director:/etc/lvs# iptables -t mangle -A PREROUTING -i eth1 -p tcp -s 0.0.0.0/0 -d 192.168.2.110/32 \
	--dport ftp-data -j MARK --set-mark 1
director:/etc/lvs# iptables -L -t mangle
Chain PREROUTING (policy ACCEPT)
target     prot opt source               destination
MARK       tcp  --  anywhere             lvs2.mack.net      tcp dpt:ftp MARK set 0x1
MARK       tcp  --  anywhere             lvs2.mack.net      tcp dpt:ftp-data MARK set 0x1

Chain OUTPUT (policy ACCEPT)
target     prot opt source               destination
]]></programlisting>
			</section>
			<section>
			<title>install LVS with ipvsadm</title>
			<para>
Next setup <command>ipvsadm</command>
to schedule packets marked with fwmark=1 to your realservers.
You need persistence (here timeout set to 600secs).
			</para>
			<para>
<programlisting><![CDATA[
director:# ipvsadm -A -f 1 -s rr -p 600
director:# ipvsadm -a -f 1 -r RS1.mack.net:0 -g -w 1
director:# ipvsadm -a -f 1 -r RS2.mack.net:0 -g -w 1
]]></programlisting>
			</para><para>
Here's the output of <command>ipvsadm</command> with two current
connections to the LVS and 3 expiring ones.
Note they are all to the same realserver, as
expected for a persistent connection.
Since forwarding is by LVS-NAT, the ip_vs_ftp module automatically loads.
			</para><para>
<programlisting><![CDATA[
director:/etc/lvs# ipvsadm
IP Virtual Server version 0.2.7 (size=4096)
Prot LocalAddress:Port Scheduler Flags
  -> RemoteAddress:Port               Forward Weight ActiveConn InActConn
FWM  1 rr persistent 600
  -> RS2.mack.net:0                   Route   1      2          3
  -> RS1.mack.net:0                   Route   1      0          0
]]></programlisting>
			</para><para>
A netpipe test showed the same latency and throughput for a connection
based on fwmark or based on VIP.
			</para><para>
What happens now when you telnet from the client to the VIP? (pause to let you think.)
The director is only forwarding packets with fwmark=1 to the LVS, so
a telnet request to the VIP is accepted by the director
and not forwarded to the realservers.
If telnetd is running on the director,
you'll get a login prompt from the director.
In production you'll have to block this too (just like you had to when setting
up on a VIP).
			</para><para>
So what's the difference, you ask,
between setting up an ftp server with persistence on the VIP on one hand
(which requires you to block all other packets with iptables rules),
and grouping 20,21 with fwmarks on the other
(which requires exactly the same blocking of unwanted packets)?
Not a lot. At the moment you're at least even
			</para>
			<blockquote>
			<para>
Lars Marowsky-Br&eacute;e <emphasis>lmb (at) suse (dot) de</emphasis> 2000-05-11
			</para><para>
When using the LVS box as a firewall/router,
the fwmark technique is a perfectly adequate
solution, which doesn't cost anything.
			</para>
			</blockquote>
			<para>
But look at the next example.
			</para></section>
		</section>
	</section>
	<section id="e-commerce_fwmark" xreflabel="e-commerce sites with fwmark">
	<title>Grouping services: two groups, active ftp(20,21) and e-commerce(80,443)</title><para>
Setup 2 groups of services, group 1 - ftp(20,21), group 2 - ecommerce(80,443).
			</para><para>
First mark packets in 2 groups.
			</para>
		<section><title>ipchains for 2.2 director</title><para>
<programlisting><![CDATA[
director:# ipchains -F
director:# ipchains -A input -p tcp -i eth1 -s 0.0.0.0/0 -d 192.168.2.110/32 \
	--dport ftp -m 1
director:# ipchains -A input -p tcp -i eth1 -s 0.0.0.0/0 -d 192.168.2.110/32 \
	--dport ftp-data -m 1
director:# ipchains -A input -p tcp -i eth1 -s 0.0.0.0/0 -d 192.168.2.110/32 \
	--dport http -m 2
director:# ipchains -A input -p tcp -i eth1 -s 0.0.0.0/0 -d 192.168.2.110/32 \
	--dport https -m 2
director:# ipchains -L input
Chain input (policy ACCEPT):
target     prot opt     source                destination           ports
-          tcp  ------  anywhere             lvs2.mack.net         any ->   ftp
-          tcp  ------  anywhere             lvs2.mack.net         any ->   ftp-data
-          tcp  ------  anywhere             lvs2.mack.net         any ->   www
-          tcp  ------  anywhere             lvs2.mack.net         any ->   https
]]></programlisting>
		</para></section>
		<section><title>iptables for 2.4 director</title>
		<para>
<programlisting><![CDATA[
director:# iptables -t mangle -A PREROUTING -i eth1 -p tcp -s 0.0.0.0/0 -d 192.168.2.110/32 \
	--dport ftp -j MARK --set-mark 1
director:# iptables -t mangle -A PREROUTING -i eth1 -p tcp -s 0.0.0.0/0 -d 192.168.2.110/32 \
	--dport ftp-data -j MARK --set-mark 1
director:# iptables -t mangle -A PREROUTING -i eth1 -p tcp -s 0.0.0.0/0 -d 192.168.2.110/32 \
	--dport http -j MARK --set-mark 2
director:# iptables -t mangle -A PREROUTING -i eth1 -p tcp -s 0.0.0.0/0 -d 192.168.2.110/32 \
	--dport https -j MARK --set-mark 2
director:/etc/lvs# iptables -L -t mangle
Chain PREROUTING (policy ACCEPT)
target     prot opt source               destination
MARK       tcp  --  anywhere             lvs2.mack.net      tcp dpt:ftp MARK set 0x1
MARK       tcp  --  anywhere             lvs2.mack.net      tcp dpt:ftp-data MARK set 0x1
MARK       tcp  --  anywhere             lvs2.mack.net      tcp dpt:www MARK set 0x2
MARK       tcp  --  anywhere             lvs2.mack.net      tcp dpt:https MARK set 0x2

Chain OUTPUT (policy ACCEPT)
target     prot opt source               destination
]]></programlisting>
		</para>
		</section>
		<section><title>setup LVS to schedule (with persistence) 2 groups of packets</title>
		<para>
<emphasis>Note</emphasis>: The ipvs code in Apr 2001 needed a patch to get
the expected behaviour.
This section describes the function of LVS before and after this patch.
As a result of these tests, the patch will be applied to future
releases. ipvs-1.0.7-2.2.19 is already patched (Apr 2001). The
2.4.3 series are not patched yet. To see if the code has been
patched look in ipvs/Changelog for something like this
		</para>
		<blockquote>
		<para>
Julian changed persistent connection template for fwmark-based
service from &lt;CIP,VIP,RIP&gt; to &lt;CIP,FWMARK,RIP&gt;, so that different
fwmark-based services that share the same VIP can work correctly.
		</para>
		</blockquote>
		<para>
If your ipvs code is pre-patched, then you can skip down to the part
where the behaviour after applying the patch is described.
If your code isn't patched, you should just go get the
patch and skip to the part where
<link linkend="fwmark_persistent_patch">the expected behaviour is described</link>.
		</para>
		</section>
		<section id="unexpected_behaviour">
		<title>unexpected behaviour</title>
		<para>
Here's what happened with the original code.
			</para><para>
<programlisting><![CDATA[
director:# ipvsadm -A -f 1 -s rr -p 600
director:# ipvsadm -a -f 1 -r RS1.mack.net:0 -g -w 1
director:# ipvsadm -a -f 1 -r RS2.mack.net:0 -g -w 1
director:# ipvsadm -A -f 2 -s rr -p 600
director:# ipvsadm -a -f 2 -r RS1.mack.net:0 -g -w 1
director:# ipvsadm -a -f 2 -r RS2.mack.net:0 -g -w 1
]]></programlisting>
			</para><para>
<programlisting><![CDATA[
IP Virtual Server version 0.2.7 (size=4096)
Prot LocalAddress:Port Scheduler Flags
  -> RemoteAddress:Port               Forward Weight ActiveConn InActConn
FWM  1 rr persistent 600
  -> RS2.mack.net:0                   Route   1      0          0
  -> RS1.mack.net:0                   Route   1      0          0
FWM  2 rr persistent 600
  -> RS2.mack.net:0                   Route   1      0          0
  -> RS1.mack.net:0                   Route   1      0          0
]]></programlisting>
			</para><para>
If you ftp and http to the VIP, you'd expect the ftp connections to go to
fwmark 1 (presumably to the first realserver RS2) and the http
connections to go to fwmark 2 (again presumably to RS2).
			</para><para>
With the director running 1.0.6-2.2.19 (ipvs/kernel version),
all connections (ftp, http) go to group 1.
With the director 0.2.7-2.4.2, all connections go to group 2.
Here's the output from <command>ipvsadm</command> for the 2.2.19 example immediately
after downloading a webpage.
You would expect the http InActConn to be associated with FWM2.
			</para><para>
<programlisting><![CDATA[
IP Virtual Server version 1.0.6 (size=4096)
Prot LocalAddress:Port Scheduler Flags
  -> RemoteAddress:Port             Forward Weight ActiveConn InActConn
FWM  1 rr persistent 30
  -> RS2.mack.net:0                 Route   1      0          2
  -> RS1.mack.net:0                 Route   1      0          0
FWM  2 rr persistent 30
  -> RS2.mack.net:0                 Route   1      0          0
  -> RS1.mack.net:0                 Route   1      0          0
director:/etc/lvs#
]]></programlisting>
			</para><para>
It appears (Apr 2001) that the ipvs code doesn't really follow the
<link linkend="fwmarks_persistence">persistent fwmarks spec</link>.
When there is a collision between VIP space and
fwmark space (eg in these examples, where all packets are
going to the same VIP), then the VIP takes precedence and
the two fwmark groups are not differentiated. The collision
arises because there is only one set of templates for the
connection tables.
		</para></section>
		<section id="fwmark_persistent_patch" xreflabel="fwmark persistent patch">
		<title>expected behaviour</title>
		<para>
Note: May 2001: the ipvs code now has the persistent-fwmark behaviour.
		</para>
		<para>
<blockquote><para>
(
The code to produce the expected behaviour requires a separate
set of templates for fwmarks and VIP.
The patch to do this is on
<ulink url="http://www.ssi.bg/~ja/">Julian's patch page</ulink>
and has names like
persistent-fwmark-0.2.8-2.4-1.diff, persistent-fwmark-1.0.5-2.2.18-1.diff.
(Note: the 0.2.8 patch had DOS carriage control and wouldn't
patch till I removed the ^M characters).
(Note: as of ipvs-0.9.0, this
patch has been applied to the source tree.)
			</para><para>
			</para><para>
After patching the ip_vs code to produce the new ip_vs.o module
(rmmod the old one first), you get the expected fwmark behaviour.
)
</para></blockquote>
			</para><para>
			</para><para>
Here's the output of <command>ipvsadm</command> after ftp'ing and http'ing from a client.
Note that the ftp connection is to fwmark=1. The InActConn is
the expiring connection from the http client to fwmark=2.
			</para>
<programlisting><![CDATA[
director:/etc/lvs# ipvsadm
IP Virtual Server version 0.2.8 (size=4096)
Prot LocalAddress:Port Scheduler Flags
  -> RemoteAddress:Port               Forward Weight ActiveConn InActConn
FWM  1 rr persistent 30
  -> RS2.mack.net:0                   Route   1      1          0
  -> RS1.mack.net:0                   Route   1      0          0
FWM  2 rr persistent 30
  -> RS2.mack.net:0                   Route   1      0          1
  -> RS1.mack.net:0                   Route   1      0          0
]]></programlisting>
		</section>
		<section id="fwmark_example_from_Ratz">
		<title>example</title>
		<para>
Here's an example of using persistence granularity (from Ratz 3 Jan 2001).
The -M 255.255.255.255 sets up /32 granularity. Here port 80 and port 443
are being linked by fwmarks.
		</para>
<programlisting><![CDATA[
ipchains -A input -j ACCEPT -p tcp -d 192.168.1.100/32 80 -m 1 -l
ipchains -A input -j ACCEPT -p tcp -d 192.168.1.100/32 443 -m 1 -l
director:/etc/lvs# ipvsadm -A -f 1 -s wlc -p 333 -M 255.255.255.255
director:/etc/lvs# ipvsadm -a -f 1 -r 192.168.1.1 -g -w 1
director:/etc/lvs# ipvsadm -a -f 1 -r 192.168.1.2 -g -w 1
]]></programlisting>
		</section>
		<section id="teds_idea">
		<title>The original idea from Ted Pavlic</title>
		<para>
Ted Pavlic <emphasis>tpavlic (at) netwalk (dot) com</emphasis> 2000-10-08
			</para><para>
Just another persistence option that you may or may not have thought of...
LVS does support port-group sticky persistance.
Before FWMARK support was added to LVS, the only types of
persistance one could do were:
			</para><para>
<itemizedlist>
<listitem><para>One port persistence (all queries to 80 return to the same realserver per
CIP)
</para></listitem><listitem><para>ALL port persistence (all queries to all ports return to the same RIP per
CIP)
</para></listitem></itemizedlist>
			</para><para>
But now that FWMARK support exists in LVS, it is easy to create group-based
sticky persistence. That is... It adds the option where:
			</para><para>
<itemizedlist>
<listitem><para>
Only these two ports (443 and 80) return to the same RIP per CIP
</para></listitem><listitem><para>
Meanwhile, another persistence table keeps track of 20, 21, and 1024:65535
</para></listitem><listitem><para>
Any other port is not persistent
</para></listitem></itemizedlist>
			</para><para>
Just have ipchains keep track of flagging the incoming packets with the
correct port group identifier:
			</para><para>
<programlisting><![CDATA[
ipchains -A input -D VIPNET/VIPMASK PORT -p PROTOCOL -m FWMARK
]]></programlisting>
			</para><para>
And have IPVS stop looking at IPs and start look at FWMARKs:
			</para><para>
<programlisting><![CDATA[
director:/etc/lvs# ipvsadm -A -f FWMARK
director:/etc/lvs# ipvsadm -a -f FWMARK -r RIP:0
]]></programlisting>
		</para></section>
		<section id="ssl_cookies">
		<title>ssl and cookies</title>
		<para>
Ted Pavlic <emphasis>tpavlic (at) netwalk (dot) com</emphasis> 2000-10-13
			</para><para>
LVS DIRECTLY supports two types of persistence and INDIRECTLY
supports another.
If you are just asking how to make port 443 persistent so that those
who receive a cookie on 443 will come back to the same realserver on 443,
simply:
			</para><para>
<programlisting><![CDATA[
/sbin/ipvsadm -A -t 192.168.1.110:443 -p
/sbin/ipvsadm -a -t 192.168.1.110:443 -R 192.168.2.1
/sbin/ipvsadm -a -t 192.168.1.110:443 -R 192.168.2.2
/sbin/ipvsadm -a -t 192.168.1.110:443 -R 192.168.2.3
...
]]></programlisting>
			</para><para>
Will setup persistence just for port 443.
			</para><para>
However, say someone gets a cookie on port 80 and gives it back on port
443 -- in that case you want to have persistence between multiple ports.
Using port 0 accomplishes this:
			</para><para>
<programlisting><![CDATA[
/sbin/ipvsadm -A -t 192.168.1.110:0 -p
/sbin/ipvsadm -a -t 192.168.1.110:0 -R 192.168.2.1
/sbin/ipvsadm -a -t 192.168.1.110:0 -R 192.168.2.2
/sbin/ipvsadm -a -t 192.168.1.110:0 -R 192.168.2.3
...
]]></programlisting>
			</para><para>
In this setup, anyone who visits ANY service will continue to go back to the
same realserver. So requests which come in on 80 or 443 will continue to
come in to the same realserver regardless of port.
			</para><para>
This is an OK solution, but it basically makes all services persistent which
might mess up scheduling. That is, this is a decent solution but sometimes
not extremely desirable.
			</para><para>
If you want to simply group ports 80 and 443 together, you need to do
something more intuitive. Use FWMARK...
			</para><para>
<programlisting><![CDATA[
ipchains -A input -d 192.168.1.110/32 80 -p tcp -m 1
ipchains -A input -d 192.168.1.110/32 443 -p tcp -m 1
/sbin/ipvsadm -A -f 1 -p
/sbin/ipvsadm -a -f 1 -R 192.168.2.1
/sbin/ipvsadm -a -f 1 -R 192.168.2.2
/sbin/ipvsadm -a -f 1 -R 192.168.2.3
...
]]></programlisting>
			</para><para>
Now only port 80 and 443 will be grouped together via persistence. Any other
director:/etc/lvs# ipvsadm rules will be completely separate. This means that you can make 80
and 443 persistence by their own little "port group" and leave ports 25 and
110 (for example) not persistent. OR... You could group all the FTP ports
together as well on a completely different persistence group... i.e.
			</para><para>
<programlisting><![CDATA[
ipchains -A input -d 192.168.1.110/32 80 -p tcp -m 1
ipchains -A input -d 192.168.1.110/32 443 -p tcp -m 1
/sbin/ipvsadm -A -f 1 -p
/sbin/ipvsadm -a -f 1 -R 192.168.2.1
/sbin/ipvsadm -a -f 1 -R 192.168.2.2
/sbin/ipvsadm -a -f 1 -R 192.168.2.3
# Really adding port 20 isn't needed
ipchains -A input -d 192.168.1.110/32 20 -p tcp -m 2
ipchains -A input -d 192.168.1.110/32 21 -p tcp -m 2
ipchains -A input -d 192.168.1.110/32 1024:65535 -p tcp -m 2
/sbin/ipvsadm -A -f 2 -p
/sbin/ipvsadm -a -f 2 -R 192.168.2.1
/sbin/ipvsadm -a -f 2 -R 192.168.2.2
/sbin/ipvsadm -a -f 2 -R 192.168.2.3
...
]]></programlisting>
			</para><para>
and again
			</para><para>
<blockquote><para>
Wayne wrote
			</para><para>
Is there a easy way to relating server in both port 80 and
port 443 (with LVS-NAT)?
			</para><para>
			</para><para>
Say I have two farms, each with same three servers.
One farm load balancing HTTP requests and another
farm load balancing HTTPS farms.  To make sure the
user in the persistent mode connected to the HTTP
server always go to the same server for HTTPS service,
we would like to have some way to relate the services
between the two farms, is there a easy way to do it?
</para></blockquote>
			</para><para>
ratz <emphasis>ratz (at) tac (dot) ch</emphasis> 2001-01-03
			</para><para>
Two possibilities to solve this with LVS
<orderedlist>
<listitem><para> Use port 0 in your setup. (advantage: easy to set up and easy understand)
</para></listitem><listitem><para> Use fwmark and group them together.
(advantage: finer port granularity possible)
</para></listitem></orderedlist>
			</para><para>
Example (1):
<programlisting><![CDATA[
director:/etc/lvs# ipvsadm -A -t 192.168.1.100:0 -s wlc -p 333 -M 255.255.255.255
director:/etc/lvs# ipvsadm -a -t 192.168.1.100:0 -r 192.168.1.1 -g -w 1
director:/etc/lvs# ipvsadm -a -t 192.168.1.100:0 -r 192.168.1.2 -g -w 1
]]></programlisting>
			</para><para>
Example (2):
<programlisting><![CDATA[
ipchains -A input -j ACCEPT -p tcp -d 192.168.1.100/32 80 -m 1 -l
ipchains -A input -j ACCEPT -p tcp -d 192.168.1.100/32 443 -m 1 -l
director:/etc/lvs# ipvsadm -A -f 1 -s wlc -p 333 -M 255.255.255.255
director:/etc/lvs# ipvsadm -a -f 1 -r 192.168.1.1 -g -w 1
director:/etc/lvs# ipvsadm -a -f 1 -r 192.168.1.2 -g -w 1
]]></programlisting>
		</para></section>
	</section>
	<section id="fwmark_passive_ftp"><title>passive ftp</title><para>
You can setup <link linkend="passive_ftp">passive ftp</link> with the VIP
as the target using persistence. This is not a particular satisfactory
solution, as connect requests to all ports will be forwarded. As well,
if another service on the realserver fails (eg http),
then all services have to be failed out together.
			</para><para>
Here's a solution to passive ftp from Ted Pavlic using fwmark.
This allows setting up passive ftp independantly of other services.
Passive ftp listens on an unknown and unpredictable high port on realserver.
This is handled by forwarding requests to all high ports (it's still
ugly, but at least this way, we can fail out ftp independently
of other services).
			</para>
		<section><title>test session with active ftp</title><para>
Here's ftp setup in active mode, as a control.
		</para><para>
<programlisting><![CDATA[
director:# iptables -L -t mangle
Chain PREROUTING (policy ACCEPT)
target     prot opt source               destination
MARK       tcp  --  anywhere             lvs2.mack.net      tcp dpt:ftp MARK set 0x1
MARK       tcp  --  anywhere             lvs2.mack.net      tcp dpt:ftp-data MARK set 0x1
#
#setup ipvsadm, making all packets with mark=1 persistent
director:# ipvsadm -A -f 1 -s rr -p 600
director:# ipvsadm -a -f 1 -r RS1:0 -g -w 1
director:# ipvsadm -a -f 1 -r RS2:0 -g -w 1
director:# ipvsadm
IP Virtual Server version 0.2.8 (size=4096)
Prot LocalAddress:Port Scheduler Flags
  -> RemoteAddress:Port               Forward Weight ActiveConn InActConn
FWM  1 rr persistent 600
  -> RS2.mack.net:0                   Route   1      0          0
  -> RS1.mack.net:0                   Route   1      0          0
]]></programlisting>
		</para><para>
Here's netstat -an on the client and the realserver (RS2)
immediately after an ftp file transfer (with the client still connected).
		</para><para>
<programlisting><![CDATA[
#client:
client:~# netstat -an | grep 110 #110 is part of the VIP
tcp        0      0 client:1176   VIP:21           ESTABLISHED
#realserver
RS2:/home/ftp/pub# netstat -an | grep 254 #254 is part of the client IP
tcp        0      0 VIP:20        client:1180      TIME_WAIT
tcp        0      0 VIP:20        client:1178      TIME_WAIT
tcp        0      0 VIP:20        client:1177      TIME_WAIT
tcp        0      0 VIP:21        client:1176      ESTABLISHED
]]></programlisting>
		</para><para>
Only port 20,21 are involved here.
		</para><para>
Here's the command line at the client during the active ftp transfer
(all expected output).
		</para><para>
<programlisting><![CDATA[
ftp> get tulip.c
local: tulip.c remote: tulip.c
200 PORT command successful.
150 Opening BINARY mode data connection for tulip.c (104241 bytes).
226 Transfer complete.
104241 bytes received in 0.0232 secs (4.4e+03 Kbytes/sec)
]]></programlisting>
		</para><para>
The iptables rules on the director do not allow passive ftp connection.
To test this put the ftp client into passive mode.
<programlisting><![CDATA[
ftp> pass
Passive mode on.
ftp> dir
227 Entering Passive Mode (192,168,2,110,4,72)
ftp: connect: Connection refused
ftp>
]]></programlisting>
		</para><para>
connection is not allowed.
To check that the system is still
functioning, put the client back into active mode.
		</para><para>
<programlisting><![CDATA[
ftp> pass
Passive mode off.
ftp> dir
200 PORT command successful.
150 Opening ASCII mode data connection for /bin/ls.
total 155178
.
.
-rw-r--r--   1 root     root       104241 Nov 10  1999 tulip.c
226 Transfer complete.
ftp>
]]></programlisting>
		</para>
		</section>
		<section><title>test session with passive ftp</title><para>
Here's the setup for passive ftp (2.4.x director) (you can leave ipvsadm
untouched).
		</para><para>
<programlisting><![CDATA[
director:# iptables -F -t mangle
#mark ftp packets
director:# iptables -t mangle -A PREROUTING -i eth1 -p tcp -s 0.0.0.0/0 -d 192.168.2.110/32 \
	--dport ftp -j MARK --set-mark 1
director:# iptables -t mangle -A PREROUTING -i eth1 -p tcp -s 0.0.0.0/0 -d 192.168.2.110/32 \
	--dport 1024: -j MARK --set-mark 1
director:# iptables -L -t mangle
Chain PREROUTING (policy ACCEPT)
target     prot opt source               destination
MARK       tcp  --  anywhere             lvs2.mack.net      tcp dpt:ftp MARK set 0x1
MARK       tcp  --  anywhere             lvs2.mack.net      tcp dpts:1024:65535 MARK set 0x1
]]></programlisting>
		</para><para>
Here's the command line from the ftp client still in active mode
<programlisting><![CDATA[
ftp>  dir
200 PORT command successful.
]]></programlisting>
		</para><para>
The session is hung, the server shows an established connection
to port 21 and the client session has to be killed.
		</para><para>
Here's the passive session.
		</para><para>
<programlisting><![CDATA[
client:~# ftp VIP
Connected to VIP.
220 RS2.mack.net FTP server (Version wu-2.4.2-academ[BETA-15](1) Wed May 20
 13:45:04 CDT 1998) ready.
Name (VIP:root): ftp
331 Guest login ok, send your complete e-mail address as password.
Password:
230 Guest login ok, access restrictions apply.
Remote system type is UNIX.
Using binary mode to transfer files.
ftp> pass
Passive mode on.
ftp> cd pub
250 CWD command successful.
ftp> dir *.c
227 Entering Passive Mode (192,168,2,110,4,75)
150 Opening ASCII mode data connection for /bin/ls.
-rw-r--r--   1 root     root       104241 Nov 10  1999 tulip.c
226 Transfer complete.
ftp> mget *.c
mget tulip.c? y
227 Entering Passive Mode (192,168,2,110,4,78)
150 Opening BINARY mode data connection for tulip.c (104241 bytes).
226 Transfer complete.
104241 bytes received in 0.0233 secs (4.4e+03 Kbytes/sec)
ftp>
]]></programlisting>
		</para><para>
Here's the connections at the realserver immediately
after the file transfer. There is the
regular connection at the ftp port (21) and a connection
timing out to a high port on the realserver.
		</para><para>
<programlisting><![CDATA[
RS2:/home/ftp/pub# netstat -an | grep 254 #254 is part of the client IP
tcp        0      0 VIP:1104      client:1191      TIME_WAIT
tcp        0      0 VIP:21        client:1184      ESTABLISHED
]]></programlisting>
		</para><para>
Here's the output from <command>ipvsadm</command> after connecting to the URL ftp://vip/ using
a web-browser
		</para><para>
<programlisting><![CDATA[
director:# ipvsadm
IP Virtual Server version 0.2.8 (size=4096)
Prot LocalAddress:Port Scheduler Flags
  -> RemoteAddress:Port               Forward Weight ActiveConn InActConn
FWM  1 rr persistent 600
  -> RS2.mack.net:0                   Route   1      1          5
  -> RS1.mack.net:0                   Route   1      0          0
]]></programlisting>
		</para></section>
		<section id="two_groups">
		<title>LVS with 2 groups: group 1 = ftp(active and passive), group 2 = http</title>
		<para>
<programlisting><![CDATA[
#fwmark rules
director:# iptables -F -t mangle
#active and passive ftp in group 1
director:# iptables -t mangle -A PREROUTING -i eth1 -p tcp -s 0.0.0.0/0 -d 192.168.2.110/32 \
	--dport ftp -j MARK --set-mark 1
director:# iptables -t mangle -A PREROUTING -i eth1 -p tcp -s 0.0.0.0/0 -d 192.168.2.110/32 \
	--dport ftp-data -j MARK --set-mark 1
director:# iptables -t mangle -A PREROUTING -i eth1 -p tcp -s 0.0.0.0/0 -d 192.168.2.110/32 \
	--dport 1024: -j MARK --set-mark 1
#http as group 2
director:# iptables -t mangle -A PREROUTING -i eth1 -p tcp -s 0.0.0.0/0 -d 192.168.2.110/32 \
	--dport http -j MARK --set-mark 2
director:/etc/lvs# iptables -L -t mangle
Chain PREROUTING (policy ACCEPT)
target     prot opt source               destination
MARK       tcp  --  anywhere             lvs2.mack.net      tcp dpt:ftp MARK set 0x1
MARK       tcp  --  anywhere             lvs2.mack.net      tcp dpt:ftp-data MARK set 0x1
MARK       tcp  --  anywhere             lvs2.mack.net      tcp dpts:1024:65535 MARK set 0x1
MARK       tcp  --  anywhere             lvs2.mack.net      tcp dpt:www MARK set 0x2
#
#setup LVS for 2 groups
director:# ipvsadm -C
#ftp (active and passive) are persistent as group 1
director:# ipvsadm -A -f 1 -s rr -p 600
director:# ipvsadm -a -f 1 -r RS1:0 -g -w 1
director:# ipvsadm -a -f 1 -r RS2:0 -g -w 1
#http as group 2 (not persistent)
director:# ipvsadm -A -f 2 -s rr
director:# ipvsadm -a -f 2 -r RS1:http -g -w 1
director:# ipvsadm -a -f 2 -r RS2:http -g -w 1
director:# ipvsadm
IP Virtual Server version 0.2.8 (size=4096)
Prot LocalAddress:Port Scheduler Flags
  -> RemoteAddress:Port               Forward Weight ActiveConn InActConn
FWM  1 rr persistent 600
  -> RS2.mack.net:0                   Route   1      0          0
  -> RS1.mack.net:0                   Route   1      0          0
FWM  2 rr
  -> RS1.mack.net:80                  Route   1      0          0
  -> RS2.mack.net:80                  Route   1      0          0
]]></programlisting>
		</para><para>
The client connected (in order) ftp://VIP/,  http://VIP/ (passive ftp)
and then by active (command line) ftp to VIP. Here's the <command>ipvsadm</command> output.
		</para><para>
<programlisting><![CDATA[
director:# ipvsadm
IP Virtual Server version 0.2.8 (size=4096)
Prot LocalAddress:Port Scheduler Flags
  -> RemoteAddress:Port               Forward Weight ActiveConn InActConn
FWM  1 rr persistent 600
  -> RS2.mack.net:0                   Route   1      2          3
  -> RS1.mack.net:0                   Route   1      0          0
FWM  2 rr
  -> RS1.mack.net:80                  Route   1      2          2
  -> RS2.mack.net:80                  Route   1      4          0
]]></programlisting>
		</para><para>
Here's the connections showing on the realserver.
The most recent ones are at the top of the list.
The connection list shows (from the bottom, <emphasis>i.e.</emphasis>
in the order of connection), passive ftp, http, and active ftp.
		</para><para>
<programlisting><![CDATA[
RS2:/home/ftp/pub# netstat -an | grep 254 #254 is part of the CIP
tcp        0      0 VIP:21        client:1207      ESTABLISHED
tcp        0      0 VIP:80        client:1206      FIN_WAIT2
tcp        0      0 VIP:80        client:1204      FIN_WAIT2
tcp        0      0 VIP:1108      client:1202      TIME_WAIT
tcp        0      0 VIP:21        client:1201      ESTABLISHED
]]></programlisting>
		</para><para>
The whole point of this setup is to make ftp and http, which belonged
to one persistence group when setup on a VIP, into two groups.
Now you can bring the httpd and the ftpd up and down independantly
(if you want to fail them out, to change the configuration or
software).
		</para>
		</section>
	</section>
	<section id="fwmark-LVS-NAT">
	<title>fwmark with LVS-NAT</title>
	<para>
(based on a posting by Horms on 14 Jul 2000)
	</para>
	<para>
Here we setup a LVS-NAT LVS on a 2.4.x director.
(Note: With 2.4 LVS, the masquerading is setup by the ipvs code,
<emphasis>i.e.</emphasis> you don't have to masquerade
the packets back from the realservers).
These examples assume that the VIP is on eth1 and
your network is already setup
(<emphasis>i.e.</emphasis> the realservers are using the director as the default gw etc).
	</para>
	<para>
Mark packets for the VIP and setup the LVS for telnet.
	<warning>
this first example is not going to get you anything you want.
	</warning>
	</para>
<programlisting><![CDATA[
#
#mark packets
director:# iptables -F -t mangle
director:# iptables -t mangle -A PREROUTING -i eth1 -p tcp -s 0.0.0.0/0 -d 192.168.2.110/32 -j MARK --set-mark 1
director:# iptables -L -t mangle
Chain PREROUTING (policy ACCEPT)
target     prot opt source               destination
MARK       tcp  --  anywhere             lvs2.mack.net      MARK set 0x1
#
#Setup ipvsadm
director:# ipvsadm -C
director:# ipvsadm -A -f 1 -s rr
director:# ipvsadm -a -f 1 -r RS1.mack.net:telnet -m -w 1
director:# ipvsadm -a -f 1 -r RS2.mack.net:telnet -m -w 1
director:# ipvsadm
IP Virtual Server version 0.2.8 (size=4096)
Prot LocalAddress:Port Scheduler Flags
  -> RemoteAddress:Port               Forward Weight ActiveConn InActConn
FWM  1 rr
  -> RS2.mack.net:23                  Masq    1      0          0
  -> RS1.mack.net:23                  Masq    1      0          0
]]></programlisting>
	<para>
You can connect with telnet to the VIP and you'll be forwarded to both
realservers in the expected way.
	</para><para>
All packets from the client will be marked and processed by the
director:/etc/lvs# ipvsadm rules.
What happens if you attempt to connect to VIP:80 (pause to think)?
	</para><para>
Here's the answer.
	</para>
<programlisting><![CDATA[
client:~# telnet VIP 80
Trying 192.168.2.110...
Connected to lvs2.mack.net.
Escape character is '^]'.

Welcome to Linux 2.2.19.


RS2 login: root
Linux 2.2.19.
Last login: Fri Apr 13 11:43:52 on ttyp1 from client2.mack.net.
No mail.
]]></programlisting>
	<para>
If you connect to VIP:80 using a browser for a client,
it sits there showing the watch symbol for quite a while.
	</para><para>
What happened?
The explanation is that you told the director to mark all packets
(<emphasis>i.e.</emphasis> from any port) from the client,
rewrite them to have dest_addr=RIP:telnet
and forward the rewritten packets to the realserver.
So when you telnet'ed to VIP:80, the packets were forwarded to RIP:23.
	</para><para>
Just to make sure that I'd interpretted this correctly,
here's the first packets seen by tcpdump running
on the client and the realserver during the connect attempts.
(These are from different sessions, so the ports shown on the client
are different.)
	</para><para>
client: here the client is connecting to VIP:80 (lvs2.www)
	</para>
<programlisting><![CDATA[
12:09:44.449566 client2.1118 > lvs2.www: S 2887976275:2887976275(0) win 5840 <mss 1460,sackOK,timestamp 118456418[|tcp]> (DF) [tos 0x10]
12:09:44.450453 lvs2.www > client2.1118: S 1441372470:1441372470(0) ack 2887976276 win 32120 <mss 1460,sackOK,timestamp 117741798[|tcp]> (DF)
12:09:44.450579 client2.1118 > lvs2.www: . ack 1 win 5840 <nop,nop,timestamp 118456418 117741798> (DF) [tos 0x10]
]]></programlisting>
	<para>
realserver (RS2): here the realserver is receiving packets to the RIP:23 (RS2.telnet)
	</para>
<programlisting><![CDATA[
11:44:28.319675 client2.1116 > RS2.telnet: S 2722509719:2722509719(0) win 5840 <mss 1460,sackOK,timestamp 118440378[|tcp]> (DF) [tos 0x10]
11:44:28.319974 RS2.telnet > client2.1116: S 1283414485:1283414485(0) ack 2722509720 win 32120 <mss 1460,sackOK,timestamp 117725760[|tcp]> (DF)
11:44:28.320681 client2.1116 > RS2.telnet: . ack 1 win 5840 <nop,nop,timestamp 118440378 117725760> (DF) [tos 0x10]
]]></programlisting>
	<para>
If you want only telnet requests to be forwarded to the realservers,
you should mark only packets for VIP:telnet. If you want both
telnet and http forwarded then you should give them each their
own mark. Here's how to setup LVS-NAT with fwmark for both
telnet and http.
	</para>
<programlisting><![CDATA[
director:# iptables -F -t mangle
#telnet packets to the VIP get fwmark=1
director:# iptables -t mangle -A PREROUTING -i eth1 -p tcp -s 0.0.0.0/0 -d 192.168.2.110/32 \
	--dport telnet -j MARK --set-mark 1
#http packets to the VIP get fwmark=2
director:# iptables -t mangle -A PREROUTING -i eth1 -p tcp -s 0.0.0.0/0 -d 192.168.2.110/32 \
	--dport http -j MARK --set-mark 2
director:# iptables -L -t mangle
Chain PREROUTING (policy ACCEPT)
target     prot opt source               destination
MARK       tcp  --  anywhere             lvs2.mack.net      tcp dpt:telnet MARK set 0x1
MARK       tcp  --  anywhere             lvs2.mack.net      tcp dpt:www MARK set 0x2
#
#setup ipvsadm
director:# ipvsadm -C
#forward packets with mark=1 to the telnet port
director:# ipvsadm -A -f 1 -s rr
director:# ipvsadm -a -f 1 -r RS1.mack.net:telnet -m -w 1
director:# ipvsadm -a -f 1 -r RS2.mack.net:telnet -m -w 1
#forward packets with mark=2 to the httpd port
director:# ipvsadm -A -f 2 -s rr
director:# ipvsadm -a -f 2 -r RS1.mack.net:http -m -w 1
director:# ipvsadm -a -f 2 -r RS2.mack.net:http -m -w 1
director:# ipvsadm
IP Virtual Server version 0.2.8 (size=4096)
Prot LocalAddress:Port Scheduler Flags
  -> RemoteAddress:Port               Forward Weight ActiveConn InActConn
FWM  1 rr
  -> RS2.mack.net:23                  Masq    1      0          0
  -> RS1.mack.net:23                  Masq    1      0          0
FWM  2 rr
  -> RS2.mack.net:80                  Masq    1      0          0
  -> RS1.mack.net:80                  Masq    1      0          0
]]></programlisting>
	<para>
Here's the (expected) output of <command>ipvsadm</command> showing the client
with 2 telnet sessions and having just downloaded a webpage from the LVS.
	</para>
<programlisting><![CDATA[
director:/etc/lvs# ipvsadm
IP Virtual Server version 0.2.8 (size=4096)
Prot LocalAddress:Port Scheduler Flags
  -> RemoteAddress:Port               Forward Weight ActiveConn InActConn
FWM  1 rr
  -> RS2.mack.net:23                  Masq    1      1          0
  -> RS1.mack.net:23                  Masq    1      1          0
FWM  2 rr
  -> RS2.mack.net:80                  Masq    1      0          1
  -> RS1.mack.net:80                  Masq    1      0          0
]]></programlisting>
	</section>
	<section id="fwmark_vip_collisions">
	<title>collisions between fwmark and VIP rules</title>
	<para>
Since it's possible to write iptables rules
that include many different types of packets,
it's possible to write VIP and fwmark rules that
would conflict by accepting the same packet.
Here's a setup that would accept telnet by both VIP and fwmarks.
			</para><para>
<programlisting><![CDATA[
director:# iptables -t mangle -A PREROUTING -i eth1 -p tcp -s 0.0.0.0/0 -d 192.168.2.110/32 \
	--dport ftp -j MARK --set-mark 1
director:# ipvsadm -A -t lvs2.mack.net:telnet -s rr
director:# ipvsadm -a -t lvs2.mack.net:telnet -r RS1.mack.net:telnet -g -w 1
director:# ipvsadm -a -t lvs2.mack.net:telnet -r RS2.mack.net:telnet -g -w 1
director:# ipvsadm -A -f 1 -s rr
director:# ipvsadm -a -f 1 -r RS1.mack.net:telnet -g -w 1
director:# ipvsadm -a -f 1 -r RS2.mack.net:telnet -g -w 1
#
director:# iptables -L -t mangle
Chain PREROUTING (policy ACCEPT)
target     prot opt source               destination
MARK       tcp  --  anywhere             lvs2.mack.net      tcp dpt:ftp MARK set 0x1
#
director:# ipvsadm
IP Virtual Server version 0.2.8 (size=4096)
Prot LocalAddress:Port Scheduler Flags
  -> RemoteAddress:Port               Forward Weight ActiveConn InActConn
TCP  lvs2.mack.net:telnet rr
  -> RS2.mack.net:telnet              Route   1      0          0
  -> RS1.mack.net:telnet              Route   1      0          0
FWM  1 rr
  -> RS2.mack.net:telnet              Route   1      0          0
  -> RS1.mack.net:telnet              Route   1      0          0
]]></programlisting>
			</para><para>
Here's the <command>ipvsadm</command> output after 4 telnet connections from a client
			</para><para>
<programlisting><![CDATA[
director:/etc/lvs# ipvsadm
IP Virtual Server version 0.2.8 (size=4096)
Prot LocalAddress:Port Scheduler Flags
  -> RemoteAddress:Port               Forward Weight ActiveConn InActConn
TCP  lvs2.mack.net:telnet rr
  -> RS2.mack.net:telnet              Route   1      2          0
  -> RS1.mack.net:telnet              Route   1      2          0
FWM  1 rr
  -> RS2.mack.net:telnet              Route   1      0          0
  -> RS1.mack.net:telnet              Route   1      0          0
]]></programlisting>
			</para><para>
All connections go to the first (here VIP) entries.
The same <command>ipvsadm</command> table
and connection pattern results if you feed the VIP and fwmarks rules
into <command>ipvsadm</command> in the reverse order.
This behaviour is not part of the spec (yet).
You might want to check the behaviour, if you are doing this sort of setup.
	</para></section>
	<section id="fwmark_persistence_granularity" xreflabel="persistence granularity with fwmark">
	<title>persistence granularity with fwmark</title>
		<section>
		<title>Introduction</title>
		<para>
Persistence granularity was added to LVS by 
Lars <emphasis>lmb (at) suse (dot) de</emphasis> 1999-10-13
		</para>
		<blockquote>
This patch adds netmasks to persistent ports, so you
can adjust the granularity of the templates.
It should help solve the problems created with
non-persistent cache clusters on the client side."
		</blockquote>
		<para>
The problem being addressed is that some clients (eg AOL customers)
connect to the internet via large proxy farms.
The IP they present to the server will not neccessarily be
the same for different sessions (tcp connections),
even though they remain connected to their proxy machine.
Persistence granularity makes all clients from a network
equivalent as far as persistence is concerned.
Thus a client could appear as CIP=x.x.x.13 for their http
connections, but CIP=x.x.x.14 for their https connections.
With persistence granularity set to /24, all CIPs from
the same class C network will be sent to the same realserver.
The default behaviour
(<emphasis>i.e.</emphasis> persistence granularity is /32)
has the effect that all connections from the same
CIP to be sent to the one realserver but other connections
from the same network will be scheduled to other realservers.
		</para>
		<para>
Persistence granularity is applied to the CIP and works the
same whether you are using fwmark or the VIP to setup the LVS.
		</para>
		<para>
You set the netmask (granularity) for
<link linkend="persistence_granularity">persistence granularity</link> with ipvsadm.
If the LVS was setup with the following command, the persistence
granularity is 255.255.255.0.
		</para>
<programlisting><![CDATA[
director:/etc/lvs# ipvsadm -A -t 192.168.1.100:0 -s wlc -p 333 -M 255.255.255.0
]]></programlisting>
		<para>
Let's say a client from a class C network
(<emphasis>e.g.</emphasis> with IP=100.100.100.2) connects to the LVS.
If any other client connects from 100.100.100.0/24 they will
also connect to the same realserver as long as the original
client's entry in the persistence table has not expired
(<emphasis>i.e.</emphasis> the first client is still connected, or
disconnected &lt; 333 secs ago).
		</para>
		</section>
		<section>
		<title>examples</title>
		<para>
Here's an example LVS-DR LVS set to mark packets for
an IP on the outside of the director
(this IP serves as the VIP in the usual LVS setup, but there's
no such thing as a VIP with fwmarks) with --dport telnet.
Persistence granularity is set to the default (-M 255.255.255.255).
		</para>
<programlisting><![CDATA[
director:# ipvsadm -C
director:# ipvsadm -A -f 1 -s rr -p 600
director:# ipvsadm -a -f 1 -r RS1:0 -g -w 1
director:# ipvsadm -a -f 1 -r RS2:0 -g -w 1
]]></programlisting>
		<para>
Two clients (192.168.2.254, 192.168.2.253) connect to the LVS.
Each host connects to different realservers but multiple
connects from each client go to the same realserver
(<emphasis>i.e.</emphasis> client A always goes to realserver A; client
B always goes to realserver B, at least till the persistence
timeout clears).
Here both clients have connected twice.
		</para>
<programlisting><![CDATA[
director:# ipvsadm
IP Virtual Server version 0.2.8 (size=4096)
Prot LocalAddress:Port Scheduler Flags
  -> RemoteAddress:Port               Forward Weight ActiveConn InActConn
FWM  1 rr persistent 600
  -> RS2.mack.net:0                   Route   1      2          0
  -> RS1.mack.net:0                   Route   1      2          0
]]></programlisting>
		<para>
This is the connection pattern expected if the connections were
based on the CIP/32 and fwmark (ie all clients are scheduled independently).
		</para>
		<para>
Here's the same setup with persistence granularity set to /24.
		</para>
<programlisting><![CDATA[
director:# ipvsadm -C
director:# ipvsadm -A -f 1 -s rr -p 600 -M 255.255.255.0
director:# ipvsadm -a -f 1 -r RS1:0 -g -w 1
director:# ipvsadm -a -f 1 -r RS2:0 -g -w 1
director:# ipvsadm
IP Virtual Server version 0.2.8 (size=4096)
Prot LocalAddress:Port Scheduler Flags
  -> RemoteAddress:Port               Forward Weight ActiveConn InActConn
FWM  1 rr persistent 600 mask 255.255.255.0
  -> RS2.mack.net:0                   Route   1      0          0
  -> RS1.mack.net:0                   Route   1      0          0
]]></programlisting>
		<para>
Here's what happens when the 2 clients, both of who belong to
the same CIP/24 persistence group, connect twice - all connections
go to the same realserver.
		</para>
<programlisting><![CDATA[
director:/etc/lvs# ipvsadm
IP Virtual Server version 0.2.8 (size=4096)
Prot LocalAddress:Port Scheduler Flags
  -> RemoteAddress:Port               Forward Weight ActiveConn InActConn
FWM  1 rr persistent 600 mask 255.255.255.0
  -> RS2.mack.net:0                   Route   1      4          0
  -> RS1.mack.net:0                   Route   1      0          0
]]></programlisting>
		</section>
		<section>
		<title>Discussion with Julian about persistence granularity</title>
		<para>
Joe
		</para>
		<blockquote>
I expect if you were using persistence with fwmark, then any
connection requests arriving with the same fwmark will
be treated as belonging to that persistence group.
Presumably any combination of client IPs and/or
networks could have been used to make the rules
which marks the packets.
		</blockquote>
		<para>
Julian
		</para><para>
	Yes, it is for the same group but in one fwmark group there
are many templates created. These templates are different for the
client groups. The template looks like this:
		</para>
<programlisting><![CDATA[
CIPNET:0 -> SERVICE(FWMARK/VIP):0 -> RIP:0
]]></programlisting>
		<para>
All ports 0 for the fwmark-based services
		</para><para>
So, for client 10.1.2.3/24 (24=persistent granularity) the template
looks like this:
		</para>
<programlisting><![CDATA[
10.1.2.0:0 -> VIP:0 -> RIP:0
]]></programlisting>
		<para>
LVS patched with the persistent_fwmark patch:
		</para>
<programlisting><![CDATA[
10.1.2.0:0 -> FWMARK:0 -> RIP:0
]]></programlisting>
		<para>
So, the templates are created with CIP/GRAN in mind and the lookup
uses CIPNET too. We use
		</para>
<programlisting><![CDATA[
CIPNET = CIP & CNETMASK
]]></programlisting>
		<para>
before creation and lookup.
		</para>
		<blockquote>
			<para>
so if I did
			</para>
<programlisting><![CDATA[
iptables -s 10.1.2.3 -m 1
director:/etc/lvs# ipvsadm -A -f 1 -s rr -p 600 -M 255.255.255.0
]]></programlisting>
			<para>
only packets from 10.1.2.3 will have a fwmark on them,
but the director would forward all packets from
10.1.2.0/24, even those without fwmarks?
			</para>
		</blockquote>
		<para>
	The patched LVS will accept only the marked packets for this
fwmark service, from the same /24 client subnet. If only one client IP
sends packets that are marked then the real service will receive packets
only from 10.1.2.3. The current LVS versions don't consider the
service and all packets CIPNET -> VIP will be forwarded using the
first created template for CIPNET:0->VIP:0, i.e. these packets will
randomly hit one of the many services that accept packets for the
same VIP (just like in your setup) and then may be a wrong realserver.
		</para>
		<blockquote>
			<blockquote>
The current LVS versions don't consider the
service and all packets CIPNET -> VIP
			</blockquote>
			<para>
but there is no VIP here, I'm using fwmark only.
what does the -M 255.255.255.0 do in this case?
			</para>
		</blockquote>
		<para>
	The current LVS versions (<emphasis>i.e.</emphasis> without the persistent_fwmark patch)
assume the VIP is the iphdr->daddr,
i.e. the destination address in the datagram and this addresses is
used to lookup/create the template.
		</para>
		<blockquote>
how about your persistent-patch, which I've been working with?
		</blockquote>
		<para>
The patch ignores this daddr when creating or looking for
templates. Instead, the service fwmark values is used when the service
is fwmark-based: CIPNET:0 -> FWMARK:0 -> RIP:0
		</para><para>
The normal services use daddr as VIP when looking for or creating
templates: CIPNET:0 -> daddr:0 -> RIP:0
		</para><para>
The persistence is associated with the client address (CIP).
The sequence is this:
		</para><para>
- packet comes from CIP to VIP1
		</para><para>
- fw marking, optional
		</para><para>
- lookup for existing connection CIP:CPORT->VIP1:VPORT, if yes => forward,
if not found:
		</para><para>
- lookup service => fwmark 1, persistent
		</para><para>
- try to select real service in context of the virtual service
		</para>
		<para>
Apply the persistence granularity to the client address
		</para>
<programlisting><![CDATA[
CIPNET = CIP & svc->netmask
]]></programlisting>
		<para>
Now lookup for template
		</para>
		<orderedlist>
			<listitem>
not patched: check for existing template CIPNET:0, VIP1:0
			</listitem>
			<listitem>
patched: check for existing template CIPNET:0, 1(fwmark):0
			</listitem>
		</orderedlist>
		<para>
if there is template, bind the new connection to the template's
destination
		</para><para>
if there is no existing template, get one destination using
the scheduler and bind it to the newly created template and
the new connection. The created template is
		</para>
		<orderedlist>
			<listitem>
CIPNET:0, VIP1:0, DEST_RIP:0
			</listitem>
			<listitem>
CIPNET:0, 1(fwmark):0, DEST_RIP:0
			</listitem>
		</orderedlist>
		<para>
- forward the packet
		</para>
		<blockquote>
Persistence granularity was designed for people coming in from
large proxy servers (eg AOL). With fwmarks, this can be handled
by iptables rules.
		</blockquote>
		<para>
Yes, the fact that we group the clients using this netmask
is not related to the virtual service type: normal or fwmark-based.
		</para><para>
Yes, each different IP is treated as different client. When
a netmask &lt;32 is used, the group of addresses is treated as one
client when applying the persistence rules. This is not related to
the packet marking and virtual service type.
		</para>
		</section>
	</section>
	<section id="fwmark_director_gw">
	<title>fwmark allows LVS-DR director to be default gw for realservers</title>
	<para>
If a LVS-DR director is accepting packets by fwmarks, then it does not
have a VIP.
The director can then be the default gw for the realservers (see
<link linkend="LVS-DR_director_default_gw">LVS-DR director is default gw for realservers</link>).
	</para>
	</section>
	<section>
	<title>fwmark simplifies configuration for large numbers of addresses</title>
	<para>
If a fwmark rule accepts packets for a /24 network, then 254 IPs are
configured in one instruction. The next sections are examples.
	</para>
	</section>
	<section id="firewall_farm">
	<title>Example: firewall farm</title>
	<para>
Horms <emphasis>horms (at) vergenet (dot) net</emphasis> 2000-12-06
			</para><para>
Assume that packets from out local network (192.168.0.0/23) are
outgoing traffic.
			</para><para>
Mark all outgoing packets with fwmark 1
			</para><para>
<programlisting><![CDATA[
ipchains -A input  -s 192.168.0.0/23 -m 1
# Now, set up a virtual service to act on the marked packets
director:/etc/lvs# ipvsadm -A -f 1
director:/etc/lvs# ipvsadm -a -f 1 -r 192.168.1.7
director:/etc/lvs# ipvsadm -a -f 1 -r 192.168.1.8
director:/etc/lvs# ipvsadm -a -f 1 -r 192.168.1.9
]]></programlisting>
			</para><para>
Where 192.168.1.7, 192.168.1.8 and 192.168.1.9 are your firewall boxen.
	</para></section>
	<section id="lvs_cidr">
	<title>Example: LVS'ing a CIDR block</title>
	<para>
Matthew S. Crocker wrote:
<blockquote><para>
would like to put a CIDR block of addresses (/25) through my LVS
server. Is there a way I can set one entry for a VIP range and then the
load balancing will be handled over the entire range.
</para></blockquote>
			</para><para>
Horms <emphasis>horms (at) vergenet (dot) net</emphasis> 2001-01-13
			</para><para>
Set up fwmark rules on the input chain to match incoming packets for
the CIDR and mark them with a fwmark.
			</para><para>
e.g.
<programlisting><![CDATA[
ipchains -A input -d 192.168.192.0/24 -m 1
]]></programlisting>
			</para><para>
Use the fwmark (1 in this case) as the virtual service.
			</para><para>
<programlisting><![CDATA[
director:/etc/lvs# ipvsadm -A -f 1
director:/etc/lvs# ipvsadm -a -f 1 -r 10.0.0.1
director:/etc/lvs# ipvsadm -a -f 1 -r 10.0.0.2
]]></programlisting>
			</para><para>
<blockquote><para>
Miri Groentman, 11 Jul 2001
			</para><para>
Is it possible to configure a range of ports rather than a single-port
</para></blockquote>
			</para><para>
Joe
			</para><para>
if you mean ports for services, yes, see fwmark in the HOWTO.
You can also forward a range of IPs.
			</para><para>
	</para></section>
	<section id="scheduling_on_cip">
	<title>Example: forwarding based on client source IP</title>
	<para>
client A (from 192.x.x.x) should go to realserver 1..3,
and client B (from 10.x.x.x) should go to realserver 4..6.
			</para><para>
(Julian, 10-05-2000)
			</para><para>
Write fwmark rules based on the source IP of the packets.
Then create two virtual services, one for each fwmark.
	</para>
	</section>
	<section id="multiple_class_c">
	<title>Example: load balancing multiple class C networks</title>
	<para>
Ian Courtney wrote:
<blockquote><para>
Basically here at our ISP, we tend to have 2-3
Class C's worth of hosting per server. We would
like to move the the LVS, but I'm not exactly
sure how I should be setting it up.
</para></blockquote>
			</para><para>
Chris <emphasis>chris (at) isg (dot) de</emphasis> 2001-01-15
			</para><para>
You can use the fwmark option for the loadbalancing
			</para><para>
<programlisting><![CDATA[
#mark the incoming packets with ipchains
ipchains -A input -s 0.0.0.0/0 -d 192.168.0.0/24 -m 1
#then you can setup your LVS like
director:/etc/lvs# ipvsadm -A -f 1 -s wlc
director:/etc/lvs# ipvsadm -a -f 1 -r 10.10.10.15 -g
director:/etc/lvs# ipvsadm -a -f 1 -r 10.10.10.16 -g
]]></programlisting>
			</para><para>
the router should point to the director.
			</para><para>
Ian Courtney wrote back:
<blockquote><para>
It didn't work until
I aliased all 3 class C's to my director. Do I have to do this?
</para></blockquote>
			</para><para>
Julian Anastasov <emphasis>ja (at) ssi (dot) bg</emphasis> 2001-01-16
			</para><para>
Yes, only the packets destined for local addresses/networks
are accepted. The others are dropped or forwarded to another box.
			</para><para>
<blockquote><para>
the next project involves redoing our standard linux web
space, which so far consists of about 8 webservers, each hosting atleast
2 class C's worth of hosting. I some how don't think Linux will take
nicely to have 16 or more class C's aliased to it.
</para></blockquote>
			</para><para>
If possible use netmask &lt;24.
I assume you execute (replace with the right Class C nets):
			</para><para>
<programlisting><![CDATA[
ifconfig lo:1 207.228.79.0  netmask 255.255.254.0
ifconfig lo:2 207.148.155.0 netmask 255.255.255.0
ifconfig lo:3 207.148.151.0 netmask 255.255.255.0
]]></programlisting>
			</para><para>
on the director and on each realserver and solve the arp problem using:
			</para><para>
<programlisting><![CDATA[
echo 1 > /proc/sys/net/ipv4/conf/all/hidden
echo 1 > /proc/sys/net/ipv4/conf/lo/hidden
]]></programlisting>
			</para><para>
in the realservers. If you don't want to advertise these addresses
using ARP to the Cisco LAN, you can execute the above two commands in
the director too.
			</para><para>
	</para></section>
	<section id="proxy_server">
	<title>Example: proxy server</title>
	<para>
Thomas Proell, 16 Aug 2000
			</para><para>
<blockquote><para>
How do you use fwmark if you want the director to accept packets for a wide range of
addresses, for which is doesn't have IPs.
</para></blockquote>
			</para><para>
(Horms)
			</para><para>
Here's a setup I used...
			</para><para>
<programlisting><![CDATA[
                                               Internet
                                                  |
                                                Router 192.168.128.1
"client"                  Linux Director          |
  va2-------------------------va3-----------------+--------- proxy (va4)
192.168.16.3      192.168.16.1   192.168.128.2        192.168.128.5
]]></programlisting>

			</para><para>
I have used 192.168/16, but these could be real addresses too.
I have only put one proxy server in the diagram but I did test it with 2
			</para><para>
<programlisting><![CDATA[
Client: default gw va3 (192.168.16.1)

Linux Director:
eth0: 192.168.128.2             (internet/proxy side)
eth1:  192.168.16.1             (client side)
Default gw: Router ,192.168.128.1
IPV4 forwarding enabled.

Ipvsadm rules - these can be translated into ldirectord configuration.
director:/etc/lvs# ipvsadm -A -f 1 -s wlc
director:/etc/lvs# ipvsadm -a -f 1 -r 192.168.128.3:0 -g -w 1
... add additonal proxy servers
]]></programlisting>
			</para><para>
Interestingly enough if you add a proxy that just forwads traffic
then it will end up going direct. This may be useful as a failback
server if the proxy servers fail.
			</para><para>
<programlisting><![CDATA[
ipchains -A input -s 0.0.0.0/0.0.0.0 -d 127.0.0.1/255.255.255.255 -j ACCEPT
ipchains -A input -s 0.0.0.0/0.0.0.0 -d 192.168.128.2/255.255.255.255 -j ACCEPT
ipchains -A input -s 0.0.0.0/0.0.0.0 -d 192.168.16.2/255.255.255.255 -j ACCEPT
ipchains -A input -s 0.0.0.0/0.0.0.0 -d 0.0.0.0/0.0.0.0 80 -p tcp -j REDIRECT 80 -m 1
]]></programlisting>
			</para><para>
The -m 1 means that IPVS will regognise packets patched by this filter
as belonging to the virtual service as long as it sees the packets as
local. -j REDIRECT 80 makes the packets appear as local. It is of note
that the port you redirect to is _ignored_ because of the way IPVS works -
paickets using fwmark are sent to the port they arrived on. This means that
packets will be sent to proxy servers as port 80 traffic.
			</para><para>
<programlisting><![CDATA[
Proxy:
eth0: 192.168.128.5
Default gw: 192.168.128.1 (router)
IPV4 forwarding enabled.

ipchains -A input -s 0.0.0.0/0.0.0.0 -d 127.0.0.1/255.255.255.255 -j ACCEPT
ipchains -A input -s 0.0.0.0/0.0.0.0 -d 192.168.128.5/255.255.255.255 -j ACCEPT
ipchains -A input -s 0.0.0.0/0.0.0.0 -d 0.0.0.0/0.0.0.0 80:80 -p 6 -j REDIRECT +8080
]]></programlisting>
Note, this is where the redirection to port 8080 takes place.
			</para><para>
	</para></section>
	<section id="example_transparent_proxy">
	<title>Example: transparent web cache</title>
	<para>
<emphasis>Pongsit (at) yahoo (dot) samart (dot) co (dot) th</emphasis> May 08, 2000
	</para>
	<para>
If I would like to use LVS to balance 3 transparent proxy is this how i do it ?
	</para>
<programlisting><![CDATA[
                 Internet
                    |
                    |
 ------------------------------------------- hub 1
          |          |           |
          |eth0      |           |           proxy1 ,2 and 3 set as a
        proxy1     proxy2      proxy3        transparent proxy with firewall
          |eth1      |           |           where eth0 connect to internet
          |          |           |           and eth1 to the internal network
 ___________________________________________
             |          |     |     |    |    hub 2
             |          |     |     |    |
          LVS/DR       client machines   |
                                         |
                                         |
 ___________________________________________  hub 3 if i have more internel
                                                   users
]]></programlisting>
	<para>
Horms <emphasis>horms (at) vergenet (dot) net</emphasis> 2000-05-08
	</para>
	<para>
If you want to do transparent proxying then I would suggest a topology
more along the lines of:
	</para>
<programlisting><![CDATA[
                 Internet
                    |
                    |
------------------------------------------------ hub 1
                    |
                    |
                 LVS/DR
                    |
                    |
________________________________________________
   |      |      |      |     |     |    |    hub 2
   |      |      |      |     |     |    |
 proxy1 proxy2 proxy3  client machines   |
                                         |
                                         |
_________________________________________________
                                               hub 3 if i have more internel users
]]></programlisting>
	<para>
Use IP chains mark all outgoing port 80 traffic, other than from the 3
proxy servers with firewall mark 1 (ipchains -m 1...).
	</para><para>
Set up a IPVS virtual service matching of fwmark 1 (ipvsadm -A -f 1...).
	</para><para>
The proxy servers will need to be set up to recognise all port 80 traffic
forwarded to them as local.
	</para><para>
This way all outgoing traffic hits the LVS box. If it is for port 80 and
isn't from one of the proxy servers then it gets load balanced and
forwarded to one of the proxy servers.
	</para><para>
You may want to consider a hot standby LVS/DR host to eliminate a single
point of failure on your network.
	</para><para>
I haven't tested this but I think it should work.
	</para></section>
	<section id="multiply_connected_router">
	<title>Example: Multiply-connected router</title>
	<para>
(Joe: my initial -apparently incorrect- reaction
was that routing protocols would handle this better.)
	</para><para>
Martin Sk?tt <emphasis>martin (at) xenux (dot) dk</emphasis> 19 Jun 2001
	</para><para>
I have several ADSL connections to the Internet (same ISP) and I wan't
all the users on my network to be using them. I would like it to
work in a way so that all the lines are utilised all the time and without
assigning groups of users to specific gateways.
	</para>
<programlisting><![CDATA[
                                              Internet
                                            /
My users ---- Linux box with LVS - Internet
                                            \
                                              Internet
]]></programlisting>
	<para>
What I want to do is assign one default gateway, the LVS box.
	</para><para>
Joe
	</para>
	<blockquote>
		<para>
..for doing by LVS, you could set
up a director to be a router and setup like it was infront of 4 squid
boxes (you'll need the IP's of the other end of the ADSL link).
		</para><para>
There's an <link linkend="example_transparent_proxy">example proxy</link>
above.
		</para>
	</blockquote>
	<para>
Alexandre Cassen <emphasis>Alexandre (dot) Cassen (at) wanadoo (dot) fr</emphasis>
	</para>
	<blockquote>
		<para>
I have tried some time ago that kind of setup. I have test 4 differents
topology
		</para>
		<itemizedlist>
			<listitem>
Using a dynamic routing protocol like BGP. Using BGP you can use cost
onto your routing path. To setup a multipath Internet connection using BGP
all the ISP connected to your BGP setting must be informed to add BGP their
side. This setup is recommanded by ISP for corporate Internet use.
It is mostly expensive due to ISP router side reconfiguration.
			</listitem>
			<listitem>
Implementing a loadsharing topology like discribed into the "Linux 2.4
advanced routing HOWTO" section 9.5. You need here to use the same ISP for
all your Internet connections because your ISP must implement the symetric
config. This mean that ISP must support linux 2.4 loadsharing over
multiple interface. This is rarely implemented by ISP because it is much
more interesting implementing constructor integration that is more
expensive. This is my feedback in France :/
			</listitem>
			<listitem>
Setting up router with multiple default gateway. That way you will
 loadbalance by TCP conversation. I have only implemented this on CISCO,
your are limited to the max default gw number implemented (3 or 4 for CISCO).
			</listitem>
			<listitem>
Implement the solution discribed in the LVS HOWTO (above). Loadbalancing a
squid server pool, each squid directly connected to your ADSL line.
			</listitem>
		</itemizedlist>
		<para>
Personally, I prefer the LVS solution which is much more easy and
recommanded because it is ISP configuration independent. I have tested that
on a RTSP proxy pool.
		</para>
	</blockquote>
	</section>
	<section id="browsers"><title>httpd clients (browsers)</title><para>
Initially when testing you should use a non-persistent (in the
netscape sense) client, <emphasis>e.g.</emphasis> telnet VIP 80, or lynx VIP.
Or else revert to these if you don't understand what you're seeing
with netscape.
			</para>
		<section id="opera">
		<title>Opera</title>
		<para>
			</para><para>
Peter Mastren <emphasis>Peter (dot) Mastren (at) chron (dot) com</emphasis> 18 Dec 2001
			</para><para>
For the past several weeks, we have experienced almost daily denial of
service attacks/events on our www servers. A
remote client somewhere has opened a number of TCP connections to LVS
that have absolutely no traffic whatsoever, save a single keepalive packet
every two minutes.  I have seen few as 3 and as many as 120 connections
in the various incidents over the weeks.
			</para><para>
These open connections are counted in the algorithm LVS uses to schedule
servers, so the server that has all these open connections receives
proportionately fewer new connections, in most cases taking the target
server completely out of rotation.
			</para><para>
Yesterday, I noticed an event coming from 130.80.XXX.XXX, our
firewall address. Three connections were being held open from
a machine inside our network. The culprit was my own workstation.
I killed my browser and the connections went away. I fired up my browser again
and tried to retrace my steps to duplicate the situation.
			</para><para>
To make a long story short, it appears that Opera version 6.0 beta will
leave a connection open to a server even after the window that was used
for that connection has been closed.  The only time the connection is
closed is when Opera exits.
			</para><para>
I will submit a problem report to Opera, in the meantime, there could be
hundreds if not thousands of beta Opera browsers out there that could
lock up ports on our servers for hours or days or longer.
			</para><para>
This morning I made a configuation change to LVS that seems to have
solved the problem.  The masquerading portion of the Linux kernel
(using LVS_NAT) uses default times to keep connections open, one for
TCP connections, one for closed TCP connections that have received a
FIN, and one for UDP  connections.  These defaults are 15, 2, and 5
minutes respectively. I changed the TCP timeout from 15 minutes to 110
seconds, which is shorter that the two minute intervals that the
keepalive packets occur, yet long enough for any imaginable connection
to a web server.
			</para><para>
The change I made was:

<programlisting><![CDATA[
      ipchains -M -S 110 0 0
]]></programlisting>

			</para><para>
<blockquote><para>
Wensong Aug 2002,
			</para><para>
for 2.4 kernels

<programlisting><![CDATA[
director:/etc/lvs# ipvsadm --set tcp tcpfin
]]></programlisting>

</para></blockquote>
		</para></section>
	</section>
	<section id="dynamic"><title>Example: dynamically generated images in webpages</title><para>
			</para><para>
One of the assumptions of setting up an LVS is that the content
presented on the realservers is identical. This is required
because the client can be sent to any of the realservers.
This requirement is not handled if the client fills in a form
which produces a gif on the realserver.
			</para><para>
Alois Treindl <emphasis>alois (at) astro (dot) ch</emphasis> 30 Apr 2001
			</para><para>
<blockquote><para>
If a page is created by a CGI and contains dynamically created GIFs,
the requests for these gifs will land on a different realserver
than the one where the cgi runs. Will I need persistence?
			</para><para>
			</para><para>
I am running an astrology site; a typical request is to a CGI which
creates an astrological drawing, based on some form data; this drawing
is stored as a temporary GIF file on the server.
A html page is output by the CGI which contains a reference to this GIF.
			</para><para>
The browser receives the html, and then requests the GIF file from the
server. It will mostly hit a different server than the one who created
the GIF.
			</para><para>
So either we make sure that the new client request for the GIF hits
the same realserver which ran the CGI (i.e. have persistence) or we must
create the GIF on a shared directory, so that each realserver sees it.
			</para><para>
I have not tested it yet (not ported the CGIs yet to the new LVS box)
but I think things are not so simple.
In a 'rr' scheduling configuration, for example, the scheduler
could play dirty, depending on the number of http requests for the
given page, and the number of realservers.
Both could be incommensurable in a way that the http request for
the GIF never reaches the same realserver as the one which ran the
CGI request.
			</para><para>
I had already decided that I need shared directories between all
realservers for our CGI environment
which does computationally expensive things all the time.
Some CGIs create also data files which are used by later CGIs.
It is either shared directories for such files, or a shared database
(which we also use).
			</para><para>
These temp files will be sitting in the RAM cache of the NFS server,
so that only network bandwidth between the realservers and the NFS server is the
limiting factor.
This is why I give the NFS server 2 gb of RAM, the max it
will physically take, and this is why I chose 2.2.19
as the kernel because it contains NFS-3, which is said to be faster than NFS-2.
</para></blockquote>
			</para><para>
(Joe)
			</para><para>
I tested it here on a page which generates a gif for the client.
I found that I could never get the gif.
Presumably after downloading the
page containing the reference to the gif, the round robin scheduler
sends the request for the gif to another realserver.
			</para><para>
Presumably even page counters will have this problem.
Writing to a shared directory should work.
			</para><para>
Here's a solution with persistent fwmark using ip_tables to setup on a 2.4.x kernel.
(Note: for page counters, this method will increment for each realserver,
and not for the total page count over all the realservers as would happen
with a shared directory.)
			</para><para>
<programlisting><![CDATA[
#put fwmark=1 on all tcp packets for VIP:http arriving on eth0
director:# iptables -t mangle -A PREROUTING -i eth0 -p tcp -s 0.0.0.0/0 -d 192.168.1.110/32 \
	--dport http -j MARK --set-mark 1
#setup a 2 realserver LVS to persistently forward packets with fwmark=1 using rr scheduling.
director:# ipvsadm -A -f 1 -s rr -p 600
director:# -a -f 1 -r RS1.mack.net:0 -g -w 1
director:# -a -f 1 -r RS2.mack.net:0 -g -w 1
#output setup
director:# iptables -L -t mangle
Chain PREROUTING (policy ACCEPT)
target     prot opt source               destination
MARK       tcp  --  anywhere             lvs.mack.net       tcp dpt:http MARK set 0x1
director:# ipvsadm
IP Virtual Server version 0.2.11 (size=16384)
Prot LocalAddress:Port Scheduler Flags
  -> RemoteAddress:Port             Forward Weight ActiveConn InActConn
FWM  1 rr persistent 600
  -> RS2.mack.net:0                 Route   1      0          0
  -> RS1.mack.net:0                 Route   1      0          0
]]></programlisting>
			</para><para>
Here's the output of <command>ipvsadm</command> after the successful generation and display of the
dynamically generated gif. Note all connections went to one realserver.
			</para><para>
<programlisting><![CDATA[
director:/etc/lvs# ipvsadm
IP Virtual Server version 0.2.11 (size=16384)
Prot LocalAddress:Port Scheduler Flags
  -> RemoteAddress:Port             Forward Weight ActiveConn InActConn
FWM  1 rr persistent 600
  -> RS2.mack.net:0                 Route   1      5          3
  -> RS1.mack.net:0                 Route   1      0          0
]]></programlisting>
	</para></section>
	<section id="balancing_as_block">
	<title>Example: Balancing many IPs/services as one block</title>
	<para>
The simplest LVS balances requests to a VIP:port amongst a group of realservers.
If you are servicing many VIPs, then few requests may be present for any particular
IP at any time and a disproportionate number of requests will be sent to the
first realserver. In this case you should balance all the different IPs as one group.
			</para><para>
Josh Marcus <emphasis>josh (at) serve (dot) com</emphasis>> 02 Oct 2001
			</para><para>
I'm using LVS to serve a few thousand domains,
but I don't see how I can setup LVS to load balance all of the domains
as if they were all a single ip.  In my ideal world, I would have a
   single entry *:80 that would forward all of our ips at port 80 to
   our set of realservers, and load balance all requests coming in.  The
   way LVS is working for us now, the vast majority of all of our requests
   are going to the server that is for some reason being listed first.
   Only sites with heavy traffic get pushed along to the other servers.
			</para><para>
			</para><para>
Michael E Brown <emphasis>michael_e_brown (at) dell (dot) com</emphasis>>
<blockquote><para>
fwmarks
</para></blockquote>
	</para>
	</section>
	<section id="source_controlled_lvs">
	<title>Example: Source controlled LVS - services and realserver customised by Client IP</title>
	<para>
In a LVS, you may want requests from a certain IP/netmask to
to be forwarded to one set of realservers/services (which may be a subset of the
total realservers, or may be other dedicated realservers), while the
rest of the requests are forwarded normally to the whole LVS.
	</para>
	<para>
Or another way of putting it... You may want 2 (or more) LVSs setup on the one director,
with one of the LVS's accepting only packets from an IP/netmask, while
the rest of the requests go to other LVS.
	</para>
	<para>
Peter Mueller <emphasis>pmueller (at) sidestep (dot) com</emphasis> 18 Apr 2002
	</para>
	<blockquote>
		<para>
source-controlled routing for us gives a few advantages.
		</para>
		<orderedlist>
			<listitem>
when clients inside our company launch the client for our product (Sidestep),
we want that client to redirect automatically to staging.  Going to staging directly
means it is easier to test code, etc. This is a small advantage and is
merely the "proving grounds" or first step.
			</listitem>
			<listitem>
One of our customers has a proxy server java-code caching problem
(their client doesn't work) and we want to steer them to a server that won't
have the problem. Unfortunately the customer is not technically
competent, and we'd like to avoid changing anything at their end.
			</listitem>
			<listitem>
It'd be nice to redirect our competitors/delinquent customers to a machine that had
incorrect or out of date information. Surely most companies would think
this is a cool feature!
			</listitem>
			<listitem>
it is advantageous to have more control in case of mishap.
			</listitem>
		</orderedlist>
		<para>
Julian supplied the recipe.
		</para>
<programlisting><![CDATA[
#for each $client, mark their packets with fwmark 1
director:# ipchains -A input -p TCP -s $client -d VIP 80 -m 1 -j ACCEPT
.
.
#create an LVS for packets with fwmark 1
director:# ipvsadm -A -f 1 -s wlc
director:# ipvsadm -a -f 1 -r $real_server
#create LVS for other client IPs (or for everyone) <emphasis>i.e.</emphasis> normal LVS setup here
.
.
]]></programlisting>
	</blockquote>
	<para>
Here's the implementation for iptables.
	</para>
	<para>
Armin.Haken <emphasis>Armin (dot) Haken (at) Sun (dot) COM</emphasis>
10 Feb 2006 
	</para>
	<para>
How to forward packets based on source address
	</para>
	<para>
Using the <filename>fwmarks</filename> in <command>iptables</command> 
you can create ipvs rules to forward packets to particular realservers 
or groups of realservers based on source address or source network. 
I got this information out of a December 2002 post to the lvs-users group by Ratz
	</para>
	<para>
Here is an example using LVS-NAT with 2 realservers with RIP 10.1.1.1 and 10.1.1.2.
The first realserver serves clients on the 10.0.1.X network and the 10.0.5.X network, 
while the other realserver serves clients on 10.0.2.X. The VIP is 10.0.1.1.
	</para>
	<para>
Packets destined for server 1 get mark 1, packets destined for server 2 get mark 2
	</para>
<programlisting><![CDATA[
iptables -t mangle -A PREROUTING -s 10.0.1.0/24 -d 10.0.1.1 -j MARK --set-mark 1   
iptables -t mangle -A PREROUTING -s 10.0.5.0/24 -d 10.0.1.1 -j MARK --set-mark 1 
iptables -t mangle -A PREROUTING -s 10.0.2.0/24 -d 10.0.1.1 -j MARK --set-mark 2   
]]></programlisting>
	<para>
The following command shows you counters of matched rules
	</para>
<programlisting><![CDATA[
iptables -t mangle -L PREROUTING -n -v
]]></programlisting>
	<para>
ipvs forwards based on the marks
	</para>
<programlisting><![CDATA[
ipvsadm -A -f 1
ipvsadm -A -f 2
ipvsadm -a -f 1 -r 10.1.1.1 -m
ipvsadm -a -f 2 -r 10.1.1.2 -m
]]></programlisting>
	<para>
The <command>iptables</command> 
rules also allow you to specify the protocol or interface of the packets you mark 
and you can use negations, specify port numbers, etc. 
If a packet matches several of the rules, 
the marks get overwritten so the last matching rule determines the mark.
	</para>
	<para>
For failover you could either configure multiple realservers per fwmark 
or put in a system that changes the marking rules 
or forwarding rules once a failed realserver is detected.
	</para>
	</section>
	<section id="fwmarks_persistence"><title>Appendix 1: Specificiations for grouping of services with fwmarks</title><para>
Here are the discussions that has resulted in the
current specifications for handling of persistence with fwmarks in LVS.
			</para><para>
Ted Pavlic Jul 14, 2000
			</para><para>
<blockquote><para>
What I was asking about would be something like this:
			</para><para>
			</para><para>
<programlisting><![CDATA[
	virtual=192.168.6.2-192.168.6.30:80
	real=192.168.6.240:80 gate
	service=http
	request="index.html"
	receive="Test Page"
	scheduler=rr
]]></programlisting>
			</para><para>
I have 1029 virtual servers -- that is I have 1029 hosts
which need to be load balanced.
</para></blockquote>
			</para><para>
Horms <emphasis>horms (at) vergenet (dot) net</emphasis> 2000-07-14
			</para><para>
(fwmark) has the advantage of
simplfying the amount of _kernel_ configuration that has to be done
which is a big win, even if this is automated by a user space application.
The basic idea is that this provides a means for LVS to have virtual
services that have more than one host/port/protocol triplet. In your
situation this means that you can have a single virtual service that
handles many virtual IP addresses and all ports and protocols (UDP, TCP and
			</para><para>
You should take a look at
<ulink url="http://www.ultramonkey.org/">ultramonkey</ulink>
(note from Joe, April 2001, UM is now 1.0.2, look for examples there).
My understanding is that this is
quite similar to how your LVS topology will be set up, though I understand
you will be having more than one of these configured.
			</para><para>
Basically what happens is that you set up LVS to consider any packets
like other LVS virtual services other than that no VIP is specified.
			</para><para>
<emphasis>e.g.</emphasis>

<programlisting><![CDATA[
director:/etc/lvs# ipvsadm -A -f 1 -s rr
director:/etc/lvs# ipvsadm -a -f 1 -r 192.168.6.3:80 -m
director:/etc/lvs# ipvsadm -a -f 1 -r 192.168.6.2:80 -m
director:/etc/lvs# ipvsadm -L -n
IP Virtual Server version 0.9.11 (size=4096)
Prot LocalAddress:Port Scheduler Flags
  -> RemoteAddress:Port          Forward Weight ActiveConn InActConn
FWM  1 rr
  -> 192.168.6.3:80              Masq    1      0          0
  -> 192.168.6.2:80              Masq    1      0          0
]]></programlisting>
			</para><para>
The other half of the equation is that ipchains is used to match incoming
traffic for virtual IP addresses and mark them with fwmark 1.  Say you have
8 contiguous class C's of virtual addresses beginning at 192.168.0.0/24.
The ipchains command to set up matching of these packets would be:
			</para><para>
<programlisting><![CDATA[
ipchains -A input -d 192.168.0.0/21 -m 1
]]></programlisting>
			</para><para>
You also need to set up a silent interface so that the LVS box sees traffic
for the VIPs as local. To do this use:
			</para><para>
<programlisting><![CDATA[
ifconfig lo:0 192.168.0.0 netmask 255.255.248.0 mtu 1500
echo 1 > /proc/sys/net/ipv4/conf/all/hidden
echo 1 > /proc/sys/net/ipv4/conf/lo/hidden
]]></programlisting>
			</para><para>
Now, as long as 192.168.0.0/21 is routed to the LVS box, or more
particularly the floating IP address of the LVS box brought up by
heartbeat, traffic for the VIPs will be routed to the LVS box, the ipchains
rules will mark it with fwmark 1 and LVS will see this fwmark and consider
the traffic as destined for a virtual service.
			</para><para>
			</para><para>
Ted Jul 14, 2000
<blockquote><para>
for me to enable persistent connections to every port using direct routing,
would this work?
			</para><para>
			</para><para>
<programlisting><![CDATA[
director:/etc/lvs# ipvsadm -A -f 1 -s rr -p 1800
director:/etc/lvs# ipvsadm -a -f 1 -r 216.69.192.201:0 -g
director:/etc/lvs# ipvsadm -a -f 1 -r 216.69.192.202:0 -g
]]></programlisting>
</para></blockquote>
Horms
			</para><para>
Yes, that would work. The port in the "ipvsadm -a" commands is ignored
if the realservers are being added to a fwmark service. Connections
will be sent to the port on the realserver that they will be recieved on
the virtual server. So port 80 traffic will go to port 80, port 443 traffic
will go to port 443 etc...
			</para><para>
As a caveat you should really make sure that your ipchains statments
catch all traffic for the given addresses including ICMP traffic so
ICMP traffic is handled correctly by LVS.
			</para><para>
(Julian on catching ICMP traffic)
			</para><para>
        IIRC, this is already not a requirement in the last LVS
versions. If we look in skb-&gt;fwmark for ICMP packets it is
impossible to use normal and fwmark virtual services to same VIP
because we can't create such ipchains rules. The good news is that
in 2.4 (0.0.3) the virtual service lookup (the fwmark field)
is used only for the new connections. In 2.2 the service is looked
up even for existing entries but we don't want to break the MASQ
code entirely
			</para><para>
Ted Pavlic <emphasis>tpavlic (at) netwalk (dot) com</emphasis> 19 Jul 2000
			</para><para>
When using fwmark to assign realservers to virtual servers, how is
scheduling and persistence handled?
			</para><para>
In my particular example, I have: 216.69.196.0/22 (ie 4 class C networks)
all marked with a fwmark of 1. <command>ipvsadm</command> setup is
			</para><para>
<programlisting><![CDATA[
Prot LocalAddress:Port Scheduler Flags
-> RemoteAddress:Port          Forward Weight ActiveConn InActConn
FWM  1 lc persistent 600
-> nw01:0                      Route   1      0          0
-> nw02:0                      Route   1      0          0
]]></programlisting>
			</para><para>
Say someone connects to 216.69.196.1 and the connection is assigned to nw01.
At this point <command>ipvsadm</command> shows
			</para><para>
<programlisting><![CDATA[
Prot LocalAddress:Port Scheduler Flags
-> RemoteAddress:Port          Forward Weight ActiveConn InActConn
FWM  1 lc persistent 600
-> nw01:0                      Route   1      1          0
-> nw02:0                      Route   1      0          0
]]></programlisting>
			</para><para>
A new person connects to another IP in 216.69.196.0/22 (say 216.69.196.2).
Will this new connection to 216.69.196.2 go to nw02 because it has the least
number of TOTAL connections, or will it go to nw01 because for that
PARTICULAR IP, both have 0 connections?
			</para><para>
Now then say that the person who just connected to 216.69.196.1 makes a
connection (within the 600 persistence seconds) to 216.69.196.3. Will this
new connection go to nw01 because it's being persistent? Or will it go to
either server depending on the number of connections?
			</para><para>
Here's what I think would be the best way to do things...
			</para><para>
If multiple IPs are marked with FWMARK 1, LVS should consider them all one
entry in its active/inactive table. I don't believe that's how things are
currently being handled.
			</para><para>
(Julian)
			</para><para>
The templates are not accounted in the active/inactive counters.
			</para><para>
<blockquote><para>
(Joe, almost a year later - Julian, what do you mean here?)
(Julian 13 Apr 2001)
			</para><para>
			</para><para>
	Ted here thinks that the templates are accounted in the
inactive/active counters. And before the persistent-fwmark patch we
can have many templates for one fwmark-based service:
			</para><para>
			</para><para>
<programlisting><![CDATA[
CIPNET:0 -> VIP1:0 -> RIP_A:0
CIPNET:0 -> VIP2:0 -> RIP_B:0
]]></programlisting>
			</para><para>
	where VIP1 and VIP2 are marked with same fwmark.
			</para><para>
	Ted recommends these two templates to be replaced with one,
i.e. just like in the persistent-fwmark patch:
			</para><para>
CIPNET:0 -> FWMARK:0 -> RIP1:0
			</para><para>
			</para><para>
	We can't see the templates (which are normal connection
entries with some reserved values in the connections structure
fields) accounted in the inactive/active counters. The reason for
this is that the inactive/active counters are used to represent
the realserver load but our templates don't lead to any load in
the realservers, we use them only to maintain the persistence.
</para></blockquote>
			</para><para>
When a service is marked persistent all connections from
CIP to VIP go to same RIP for the specified period. Even for the
fwmark based services. This works for many independent VIPs.
			</para><para>
The other case is fwmark service covering a DNS name.
I expect comments from users with SSL problems and persistent fwmark
service. Is there a problem or may be not?
			</para><para>
I agree, may be the both cases can be useful:
			</para><para>
<programlisting><![CDATA[
1. CIP->VIP
2. CIP->FWMARK
]]></programlisting>
			</para><para>
Any examples where/why (2) is needed?
			</para><para>
But switching the LVS code always to use (2) for the
persistent fwmark services is possible.
			</para><para>
(Ted)
			</para><para>
In my opinion, here are some pros and cons of case 2:
			</para><para>
Pros:
			</para><para>
Improves scheduling, I think, and true load balancing. If someone is
using [W]RR or [W]LC, the LVS box will actually look at the realservers as
a whole rather than separate realserver entries for EACH VIP. Does that
make sense?
			</para><para>
For example, in my particular configuration I have over one thousand VIPs
which are load balanced onto four RIPs. When I configure the LVS server to
use LC scheduling, I'd like it to look at how many TOTAL connections are
being made to each RIP not how many connections are being made to each RIP
PER VIP. I would like to load balance all one thousand VIPs as a WHOLE onto
the four RIPs rather than load balance EACH VIP.
			</para><para>
That is, in some of my less active sites, most of their traffic will
probably hit one VIP just because not much traffic will need to be load
balanced. However, more active sites will hit both servers. The load will
then not be distributed equally among the servers as one server will
probably get not only the active traffic but also the less active traffic
and the other server will only get the more active traffic (in the case of
having two RIPs).
			</para><para>
Cons:
			</para><para>
One person on the Internet will keep connecting to the same RIP for many
different VIPs if persistence is turned on.
			</para><para>
If this causes a problem, the LVS administrator can do one of two
different things:
			</para><para>
1) Rather than load balancing a fwmark template, go back to load balancing
specific VIPs. The scheduling will then be unique for those particular VIPs.
			</para><para>
2) Create multiple fwmark templates. The scheduling for each template will
be unique.
			</para><para>
			</para><para>
In my opinion if you group a bunch of IPs together by marking them with an
fwmark, that you say that you want to load balance all of those
COLLECTIVELY -- almost like load balancing one site.
			</para><para>
I'm just saying, are there any examples where CIP->FWMARK is not needed?
			</para><para>
As far as the LVS is concerned, if someone connects to a
VIP marked with fwmark 1, it should treat it just like every other VIP
marked with fwmark 1 -- as if they were all one VIP.
			</para><para>
But today on my LVS (where I have a ten minute persistence setup) I
connected to one virtual server marked with fwmark 1 and got a certain real
server. I then expected to connect to another virtual server also marked
with fwmark 1 and get that same realserver. I did not, however. If what
you're telling me is correct, the persistence should have connected me to
the same realserver as long as I was connecting within that ten minute
window.
			</para><para>
Now in this particular example -- connecting to DIFFERENT virtual servers --
it isn't so necessary for persistence to be carried through PER virtual
server. I'm just worried that least connection scheduling and round-robin
scheduling aren't working at the fwmark level -- I'm worried that they are
working at the VIP level as if I had setup hundreds of explicit VIP rules
inside IPVSADM.
			</para><para>
<blockquote><para>
Julian
			</para><para>
I hope this feature (2) will be implemented in the next LVS
version (if Wensong don't see any problems). I.e. the templates
can be changed to case (2) for the persistent fwmark services.
For now we (I and Horms) don't see any problems after this change.
Then connections from one client IP to different VIPs (from the same
fwmark service) will go to the same realserver (only for the persistent
fwmark services).
</para></blockquote>
			</para><para>
Do you see any reason why enabling CIP->FWMARK for all cases would be a bad
thing?
			</para><para>
 That is, not only using case 2 for persistent fwmark, but just whenever
 fwmark was used. Personally, I cannot ever forsee a scenerio when a person
 would setup an fwmark for load balancing and want each VIP associated with
 that fwmark to act independently.
			</para><para>
<blockquote><para>
Web cluster for independent domains (VIPs). fwmark service
is used only to reduce the amount of work for configuration.
</para></blockquote>
			</para><para>
 I've always thought that the scheduling algorithms should look directly at
 the realservers rather than the realserver stats for each particular
 virtual server. That is, least connection scheduling would look at the total
 number of connections on a realserver, not just the connections from that
 particular VIP. Round-robin would go round-robin from realserver to real
 server based on the last connection from ANY VIP to the realservers...
 However, before fwmark I realized that this would probably very difficult to
 do especially in cases where an LVS administrator was load balancing to a
 number of different realserver clusters that may overlap.
			</para><para>
<blockquote><para>
This is a job for the user space tools: WRR scheduling
method + weights derived from the realserver load. Yes, one real
server can be loaded from:
			</para><para>
<itemizedlist>
<listitem><para>many directors
</para></listitem><listitem><para>many virtual services
</para></listitem><listitem><para>other processes not part from the real service
</para></listitem></itemizedlist>
			</para><para>
In this case the director's opinion (for each virtual service)
about the realserver load is wrong. The only way to handle such case
properly is to use WRR method. In the other cases WLC, LC and RR can do
their job.
</para></blockquote>
fwmark, to me, just by causing all VIPs marked with a particular fwmark to
look like one big VIP makes it possible to do basically that which I just
described. I don't see why anyone would not want such functionality with the
fwmark services. If one did want such functionality, he would probably
partition the VIPs associated with his fwmark into separate fwmarks or even
explicit VIP entries anyway.
			</para><para>
<blockquote><para>
Yes. IMO, this can be a problem only for the balancing but
I don't think so. The problems will come when one realserver dies
and the client can't access any VIP part from the fwmark service for a
period of time.
</para></blockquote>
	</para></section>
	<section id="fwmarks_persistence_proof_of_principle"><title>Appendix 2: Demonstration of grouping services with fwmarks</title><para>
Here's the original e-mail between Ted <emphasis>tpavlic (at) netwalk (dot) com</emphasis> 3 Aug 2000 and Joe
			</para><para>
    One of the things it fwmarks lets me do is make ports sticky by groups.
			</para><para>
    Basically I setup ipchains rules that say all packets to ports 80/tcp
and 443/tcp mark with a 1. All packets to ports 20/tcp and 21/tcp as well as
1024:65535/tcp mark with a 2. Voila... I just made ports stick by groups.
			</para><para>
    I then go into IPVS and setup my realservers under FWMARK1 and FWMARK2.
Ports 80 and 443 are now persistent as a group just as 20 and 21 and
1024:65535 are persistent as a group. If my HTTP goes down on one of my real
servers, I do not have to take my FTP down as well. I only have to remove
the realserver from the FWMARK1 group. It's great!
			</para><para>
<blockquote><para>
Joe
			</para><para>
most people don't program their own on-line transaction processing program
and the point of an LVS is for the realservers to be running the same code
as when they're stand alone.
</para></blockquote>
			</para><para>
My users run PHP scripts as well as ASPs that keep session information.
That session information is unique per server and usually is stored in a
local /tmp directory. Users are handed cookies which tie them to their
session information. If they go to the wrong realserver, that session
information won't exist and a number of things could go wrong.
			</para><para>
most of my realservers run
a lot of services...  HTTP, HTTPS, FTP, SMTP, POP3, IMAP, DNS,
And when one of them went down (with persistence set up),
I would have to take the entire realserver down.
			</para><para>
Several problems:
			</para><para>
*) One little thing goes down... POP3, for example. Now the load increases a
great deal on all my other realservers... Perhaps causing the load to
become so high that sendmail starts rejecting connections... and then THAT
realserver also is taken COMPLETELY down... domino effect. If I could have
just taken POP3 down off of that server, it would have been perfect.
			</para><para>
*) Say something horrible happens causing sendmail to go down on all the
servers... or HTTP... or POP3... any one service -- just as long as it goes
down on all servers. Rather than just causing that service to be affected,
ALL of my services go down because every realserver was taken completely
off-line until that ONE service is fixed. :(
			</para><para>
But I figured that those two problems wouldn't be that big of a deal... I
could probably put such a system in production.
			</para><para>
Well -- I put such a system in production and those problems weren't that
big of a deal... Except for a COUPLE of times when all services went down
and caused a BIG hassle. So my superiors wanted something better -- needed
in fact.
			</para><para>
So at first I came up with the interim idea of separating persistent
services and non-persistent services by IP. All of my persistent services
were basically on one supernet and all of my non-persistent services were on
another subnet. Consequently, I could tie the one supernet to one FWMARK and
the other subnet to another FWMARK. Now if a persistent service went down,
it would bring down only all of the persistent services. Also, if a
non-persistent service went down, it would only bring down all of the
non-persistent services.
			</para><para>
This was definitely an interim solution because it required a lot more IPs
that any one administrator should need, and it still was far from perfect..
BUT... I started to realize that just as I could mark different supernets
and subnets with different FWMARKs, I could go farther down the TCP/IP
layers and mark things at their protocol and port level. That's where I
realized that we COULD do persistents by port group just with a little help
from ipchains.
			</para><para>
<blockquote><para>
Joe
			</para><para>
 I asked Horms if there was any point in having multiple fwmarks.
 His only example was if you had duplicate sets of realservers. Eg the
 paying customers get the fast servers, while the people coming into the
 free site get the 486 with 16M.
</para></blockquote>
			</para><para>
Similar idea here... except rather than setting up your policies like:
			</para><para>
<itemizedlist>
<listitem><para>Paying customers -> fast server
</para></listitem><listitem><para>Free -> slow server
</para></listitem></itemizedlist>
			</para><para>
You have:
			</para><para>
<itemizedlist>
<listitem><para>SMTP -> a realserver
</para></listitem><listitem><para>POP3 -> another realserver
</para></listitem><listitem><para>HTTP/HTTPS -> yet another realserver
</para></listitem><listitem><para>FTP -> and another realserver
</para></listitem></itemizedlist>
			</para><para>
The key of it all is the fact that you can group by about any parameter
that ipchains can see. If ipchains can segregate it, you can group it.
Anything that ipchains can do IPVS can then add onto itself.
			</para><para>
<blockquote><para>
Joe
			</para><para>
Have you solved passive ftp without using persistance?
</para></blockquote>
			</para><para>
I really don't think there's any way to get around it... In order to get
passive FTP to work, you need to make TCP port 21 persistent with every TCP
port above 1024. I mean -- how else could you do it without putting some big
brother software inside of LVS which would keep an eye on FTP and see what
port it tells the end-user to connect to.
			</para><para>
Still, putting 21 and 1024:65535 together is a lot better than putting
everything together. Personally I only plan on load balancing
things in the &lt;1024 range anyway, so I have no problem including that huge
group above 1024.
			</para><para>
This is my setup
			</para><para>
<programlisting><![CDATA[
FWMARK1 => HTTP/HTTPS (persistent)
FWMARK2 => FTP (persistent)
FWMARK3 => SMTP
FWMARK4 => POP3
FWMARK5 => DOMAIN
FWMARK6 => IMAP
FWMARK7 => ICMP (for kicks)

================
IP Virtual Server version 0.9.12 (size=4096)
Prot LocalAddress:Port Scheduler Flags
  -> RemoteAddress:Port          Forward Weight ActiveConn InActConn
FWM  1 lc persistent 600
  -> nw04:0                      Route   1      58         121
  -> nw03:0                      Route   1      49         76
  -> nw02:0                      Route   1      60         98
  -> nw01:0                      Route   1      61         44
FWM  2 lc persistent 600
  -> nw04:0                      Route   1      0          2
  -> nw03:0                      Route   1      0          2
  -> nw02:0                      Route   1      1          13
  -> nw01:0                      Route   1      1          0
FWM  3 lc
  -> nw04:0                      Route   1      4          11
  -> nw03:0                      Route   1      4          12
  -> nw02:0                      Route   1      3          20
  -> nw01:0                      Route   1      3          16
FWM  4 lc
  -> nw04:0                      Route   1      3          54
  -> nw03:0                      Route   1      1          74
  -> nw02:0                      Route   1      3          51
  -> nw01:0                      Route   1      2          73
FWM  5 lc
  -> nw03:0                      Route   1      0          46
  -> nw01:0                      Route   1      0          44
  -> nw02:0                      Route   1      0          45
  -> nw04:0                      Route   1      0          45
FWM  6 lc
  -> nw04:0                      Route   1      0          0
  -> nw03:0                      Route   1      0          0
  -> nw02:0                      Route   1      1          0
  -> nw01:0                      Route   1      0          0
FWM  7 lc
  -> nw04:0                      Route   1      0          0
  -> nw03:0                      Route   1      0          0
  -> nw02:0                      Route   1      0          0
  -> nw01:0                      Route   1      0          0
==============
]]></programlisting>
			</para><para>
Is this anything new?
			</para><para>
<blockquote><para>
Joe
			</para><para>
It's new to me and Horms didn't have any other ideas for multiple
fwmarks 3 weeks ago, so I expect it will be new to him.
</para></blockquote>
			</para><para>
I've been thinking of ways of combining different programs which
already exist out there to get L7 scheduling working. For example -- you
have some program (sorta like policy routing but one more layer up) that
filters packets at the application layer and does something to them...
routes them to a particular IP... something like that... and then have
ipchains mark each one of those packets with a particular mark... and have
LVS work from there.
			</para><para>
You see -- using multiple fwmarks makes me think that you can do a lot more
with LVS.
			</para><para>
We could probably borrow some of the ideas used for some of the
dynamic routing protocols, like BGP or RIP. A master could advertise its
IPVS hash table. If it didn't advertise within a given interval of time,
other LVS's could take over.
			</para><para>
During the failover, rather than trading an IP
like we were talking about, all LVSs could know which one is the active one
and ICMP redirect to that LVS or something like that.
			</para><para>
Right now I'm routing every virtual server through the active LVS. This lets
me do a lot of nifty things (for me at least):
			</para><para>
* Very little has to happen on the LVS during failovers. They basically just
trade an IP. In fact -- I COULD do the failover right at the router before
the LVS's -- just have it route to another IP.
			</para><para>
* I do not have to bring every IP up on my realservers -- I
just have to bring the network that they're on up on a hidden loopback
device. When you route an entire network to a loopback device, the loopback
device answers every IP on that subnet automatically. So even with 1024+
IPs, I have to setup very few interfaces/aliases because a great deal of
them are on the same subnet.
	</para></section>
	<section id="fwmarks_persistence_announcement"><title>Appendix 3: Announcement of grouping services with fwmarks</title><para>
Ted Pavlic <emphasis>tpavlic (at) netwalk (dot) com</emphasis> 4 Aug 2000
			</para><para>
Periodically the issue comes up regarding wanting to do persistence by
groups of ports. Until now, an LVS administrator could make a single-port
persistent or all ports persistent.
			</para><para>
Single port persistence was nice for quite a few things. However, things
like HTTP and HTTPS caused complications with it. Someone who connected to a
webpage on HTTP and started a session tied to them with a cookie would want
to return to that same realserver when they went to the HTTPS version of
that site. FTP would also cause a problem with single-port persistence as
someone who wanted to use passive FTP wouldn't be gauranteed the same server
when they returned on a random TCP port above 1024. There are other examples
as well.
			</para><para>
So the solution to these problems would be to make every port persistent.
This works pretty well, but now anytime a user of a large network behind a
firewall would connect to a realserver on ANY service, everyone behind that
firewall would hit that same realserver. Plus, if an administrator wanted
to stop scheduling a single service to a single realserver, he would have
to take all services down on that single realserver. This causes many
problems as well... especially if one small service dies on every real
server -- brings down every service on every realserver.
			</para><para>
So there has been the need for persistence by port GROUPS. Rather than
saying all ports are persistent, it would be nice to tell LVS to tie just
80/tcp and 443/tcp together or just 21/tcp and 1024:65535/tcp together.
Before the wonderful FWMARK additions to LVS, this was not possible.
			</para><para>
But now that LVS listens to FWMARKs, it becomes possible to group ports
together inside ipchains with different FWMARKs and then tell LVS to listen
to those FWMARKs.
			</para><para>
For example, one can setup a rule inside FWMARK to do this...
<programlisting><![CDATA[
80/tcp, 443/tcp --> FWMARK1
21/tcp, 1024:65535/tcp --> FWMARK2
25/tcp --> FWMARK3
110/tcp --> FWMARK4
]]></programlisting>
			</para><para>
Then inside LVS (assume on this setup all of these services are served by
the same realserver cluster), say:
<programlisting><![CDATA[
FWMARK1 -> PERSISTENT -> real1,real2,real3,real4
FWMARK2 -> PERSISTENT -> real1, real2, real3, real4
FWMARK3 -> real1, real2, real3, real4
FWMARK4 -> real1, real2, real3, real4
]]></programlisting>
			</para><para>
Not only have you now setup persistence by port groups, but you've also
split your services back up into autonomous services that will not bring
EVERY server down for the sake of persistence. If FTP goes down on real1,
real1 only needs to be stopped scheduling for FTP.
			</para>
		<section><title>another explanation</title><para>
			</para><para>
Ted Pavlic <emphasis>tpavlic (at) netwalk (dot) com</emphasis> 2000-09-15
			</para><para>
Using fwmark, you can setup something which used to be a big desire in LVS,
persistence by port groups.
			</para><para>
For example... Say you were serving HTTP and HTTPS. In this case, you would
probably want calls to one HTTP server to end up hitting the same HTTPS
server. This way session information and such would be accessable no matter
how the end-user was accessing the website.
			</para><para>
Say you also wanted all forms of FTP to work... You would need persistence
there, but not necessarily the same persistence as HTTP/HTTPS.
			</para><para>
And other protocols do not need to be persistent.
			</para><para>
Back in the olden days before fwmark, to do any of this you would have to
make ALL ports persistent. You couldn't simply say "Group 80 and 443
together and make them persistent and then make 21, 20, AND 1024:65535
persistent." If one service went down, you would have to bring down ALL
services. Some sort of persistence by port groups would allow you to only
need to take down whatever went down and the affected server could still
serve other services.
			</para><para>
FWMARK allows you to do this by way of setting up multiple FWMARKs.
			</para><para>
That is -- you can use ipchains to say that:
			</para><para>
<programlisting><![CDATA[
HTTP,HTTPS --> FWMARK1
FTP --> FWMARK2
SMTP --> FWMARK3
POP --> FWMARK4
]]></programlisting>
			</para><para>
Then in LVS, setup:
			</para><para>
<programlisting><![CDATA[
FWMARK1 --> WLC Persistent 600
FWMARK2 --> WLC Persistent 300
FWMARK3 --> WLC
FWMARK4 --> WLC
]]></programlisting>
			</para><para>
And if FTP went down, all you'd have to do is stop scheduling FTP rather
than stop scheduling EVERYTHING.
			</para><para>
Also note that FWMARK makes setting up MASS VIPs really easy (of course
because of recent ARIN policy changes, this probably won't be done much more
anymore). That is, if you wanted to load balance 1000 VIPs, it might be easy
to setup one single rule in ipchains to cover them all, where it would be
1000 rules for EACH realserver in ipvsadm.
			</para><para>
It makes me think that if there was a utility already out there that could
sit on a director and figure out where name-based packets were going it
might be able to mark each name-based host with a different FWMARK and pass
that right back to LVS... Then LVS wouldn't have to worry about handling
name-based stuff ITSELF. Of course the name-based challenge is even more
challenging considering how much data needs to be looked at to figure out if
a TCP stream is a name-based HTTP session going to specific name X.... but
that's a completely other argument... Just food for thought.
		</para>
		</section>
	</section>
	<section id="fwmark_mailing_list">
	<title>fwmark examples from the mailing list</title>
	<para>
Simone Sestini, September 23, 2003
	</para>
	<blockquote>
		<para>
I would like to use director and a backup director as a realserver too.
I would like to run http and https on the backup director/realserver
		</para>
		<para>
how can I configure more than one https domain for each server ?
Apache need to use a unique IP for each https domain
		</para>
	</blockquote>
	<para>
Matthew Crocker <emphasis>matthew (at) crocker (dot) com</emphasis>
24 Sep 2003
	</para>
	<para>
Search some of the archives a bit.  I handle my HTTPS servers with
LVS-DR going through my LVS director.  The actual web servers are not
on the Internet.
Here is what I do.
	</para>
	<orderedlist>
		<listitem>
Setup keepalived/VRRP to handle a VIP failover between two LVS boxes
		</listitem>
		<listitem>
Setup a static route in the upstream router for a /24 to the VIP IP
address
		</listitem>
		<listitem>
Setup netfilter/iptables to mark packets with dest = the /24 and
dport = 443 and 80 with fwmark 0x1
		</listitem>
		<listitem>
Setup LVS to load balance FWM 1 using LVS-DR to the Real servers
internal IP (192.168.x.y)
		</listitem>
		<listitem>
Setup the LVS servers (presumably directors - Joe) to treat packets with FWM1 as local
		</listitem>
		<listitem>
Setup the realservers to list on each IP in the /24
		</listitem>
		<listitem>
Setup apache with SSL certs for each /24 IP address.
		</listitem>
		<listitem>
Point DNS records for https servers to unqiue IPs in the /24
		</listitem>
	</orderedlist>
	<para>
This works great for me.  Only packets in the /24 that are marked with
the firewall mark actually hit the LVS server and/or the realservers.
All other packets are not treated local by the lVS server and will be
routed to its default route which will create a routing loop.  If you
ping/traceroute it will look broken but if you telnet to port 80 on one
of the IPs you will get an answer.  This also eliminated any ARP issues
because the realservers are not on the same LAN segment as the LVS
directors and the router doesn't ARP for the /24 IPs anyway because of
the static route.
	</para>
	<para>
Most of the configs for steps 3,4,5 are in the archives from a couple
months ago.
	</para>
	</section>
</section>
<section id="LVS-HOWTO.transparent_proxy" xreflabel="Transparent Proxy (Horm's method)">
<title>LVS: Transparent proxy (TP or Horms' method)</title>
<para>
Horms worked out that transparent proxy could be used in an LVS
</para>
<para>
Transparent proxy is a piece of Linux kernel code
which allows a packet destined for an IP _not_ on the host, 
to be accepted locally, as if the IP was on the host.
Transparent proxy is the mechanism by which you can make a
director (or realserver) work without having the VIP configured on it.
</para>
<para>
Transparent proxy allows the realserver to solve <xref linkend="LVS-HOWTO.arp_problem"/>.
The director sends the packets to the MAC address of the realserver;
transparent proxy tells the realserver to accept the packet with
dst_addr=VIP (even though this IP is not on the realserver);
since there is no VIP on the realserver, 
it does not reply to arp queries for the VIP.
</para>
<para>
Without the VIP on a machine, methods other than the normal
IP routing are required to deliver packets with dst_addr=VIP
(see <xref linkend="LVS-HOWTO.routing_to_VIP-less_director"/>).
</para>
<para>
A VIP-less way of setting up an LVS is
<xref linkend="LVS-HOWTO.fwmark"/>.
There an incoming packet is marked and the mark (rather
than a VIP) is used to forward the packet.
In the case of using a fwmark on a director, the packet
still has to be accepted on the director.
For this you need the VIP on the outside NIC or
you need TP.
It would be nice for an LVS if a packet with
a fwmark that is in the <command>ipvsadm</command>
table (<emphasis>i.e.</emphasis> this is a packet
to be forwarded by ip_vs) could be accepted
by the node without having to also put the VIP
on the node (and without using TP), by
a modification of the LVS code.
In principle this is possible and Julian
would write it, if he thought it was going
to be used. At the moment I'm the only one
asking for it.
</para>
<note>
<para>
Feb 2003: The TP implementation for stock 2.4.x kernels behaves
differently than the 2.2.
For 2.4 the packet is accepted locally with the primary IP of the
NIC, rather than the VIP, as for 2.2 kernels.
This makes 2.4 TP unusable for LVS directors,
although it still works fine for web-caches
(<emphasis>i.e.</emphasis> squids), it's original purpose.
On talking to Harald Welte at the 2001 Ottawa Linux Symposium,
there had been much discussion on the netfilter mailing lists
as to whether to preserve the original behaviour.
Since no-one (that they knew about) needed the original behaviour,
that functionality was dropped. It seems too late to restore
the functionality to netfilter now.
</para>
<para>
Some of the functionality
that LVS wants out of TP is available via <xref linkend="LVS-HOWTO.fwmark"/>
and so the issue is probably moot now, and we're not going to
ask the netfilter people to restore the original TP functionality
for 2.4 kernels.
</para>
<para>
It's possible to patch the code for LVS,
but this would require someone to keep track of
the netfilter code for each version of the kernel.
RedHat has patched its kernels to restore the TP functionality
and Ratz maintains patches for the standard kernel (see below).
</para>
<para>
Most of the writeup for 2.4 kernels in this section was my efforts
to find out what was happening with 2.4 TP.
This section of the HOWTO will have to
be rewritten when people start using the 2.4 TP patches.
</para>
</note>
<para>
Take-home lesson: TP only works for LVS (directors and realservers) 
on 2.0 and 2.2 kernels.
For 2.4 (and higher) TP only works on realservers for LVS to
handle the Arp problem.
</para>
<para>
Note: web caches (proxies) can operate in transparent mode,
when they cache all IP's on the internet.
In this mode, requests are received and transmitted without
changing the port numbers (ie port 80 in and port 80 out).
In a normal web cache, the clients are asked to reconfigure
their browsers to use the proxy, some_IP:3128.
It is difficult to get clients to do this, and the
solution is transparent caching.
This is more difficult to setup, but all clients will
then use the cache.
</para>
<para>
In the web caching world, transparent caching is often
called &quot;transparent proxy&quot; because it is
implemented with transparent proxy.
In the future,
it is conceivable that transparent web caching will be implemented
by another feature of the tcpip layer and it would be nice
if functionality of transparent web caching had a name
separate from the command that is used to implement it.
</para>
	<section id="TP_routing_to_director">
	<title>setting up routing and packet delivery to the director</title>
	<para>
To use TP in an LVS, packets from the client have to be
delivered to a machine which does not have
the IP of the dst_addr of the client's packets (<emphasis>i.e.</emphasis> the VIP).
Read the part of the section on
<link linkend="routing_and_delivery">routing and delivery</link> concerned with
routing packets to machines without the dst_addr.
	</para>
	</section>
	<section id="TP_general">
	<title>General</title>
	<para>
This is Horms' (<emphasis>horms (at) vergenet (dot) net</emphasis>) method 
(also called the transparent proxy or TP method).
It uses the transparent proxy feature of ipchains to accept packets with dst=VIP
by the host (director or realservers) when it doesn't
have the IP (eg the VIP) on a device.
It can be used on the realservers
(where it handles the <xref linkend="LVS-HOWTO.arp_problem"/>)
or the director to accept packets for the VIP.
When used on the director, TP
allows the director to be the default gw for LVS-DR
(see <xref linkend="martian_modification"/>).
	</para>
	<para>
Unfortunately the 2.2 and 2.4 versions of transparent proxy
are as different as chalk and cheese in an LVS.
Presumably the functionality has been maintained for
for transparent web caching but the effect on LVS has not
been considered.
	</para>
	<para>
You can use transparent proxy for
	</para>
	<itemizedlist>
		<listitem>
2.2.x, director and realservers
		</listitem>
		<listitem>
2.4.x, realservers only (where it handles the Arp problem)
		</listitem>
	</itemizedlist>
	<para>
(Historical note from Horms:)
From memory I was getting a cluster ready for a demo at Inetnet World, New
York which was held in October 1999. The cluster was to demo all sorts of
services that Linux could run that were relevant to ISPs. Apache, Sendmail,
Squid, Bind and Radius I believe. As part of this I was playing with LVS-DR
and spotted that the realservers coulnd't accept traffic for the VIP. I
had used Transparent Proxying in the past so I tried it and it worked.
That cluster was pretty cool, it took me a week to put it together
and it was an ISP in an albeit very large box.
	</para>
	<para>
Transparent proxy is only implemented in Linux.
	</para>
	<itemizedlist>
		<listitem>
2.2.x you need IP masquerading,
transparent proxing and IP firewalls turned on.
		</listitem>
		<listitem>
2.4.x, TP is a standard part of the kernel build,
there is no separate TP option.
In the netfilter options, there are the options under
&quot;Full NAT (NEW)&quot; MASQUERADE, REDIRECT.
I suspect you need all these.
		</listitem>
	</itemizedlist>
	<para>
Julian
	</para>
	<para>
Transparent proxy support calls ip_local_deliver from where the LVS
code is reached. One of the advantages of this method is that it
is easy for a director and realserver to <link linkend="promote">exchange roles</link>
in a failover setup.
	</para>
	</section>
	<section id="TP_how_to_use">
	<title>How you use TP</title>
	<para>
This is a demonstration of TP using 2 machines: a realserver (which will accept packets by TP)
and a client (<emphasis>i.e.</emphasis> this is not an LVS).
	</para>
	<para>
On the realserver: ipv4 forwarding must be on.
	</para>
<programlisting><![CDATA[
echo "1" > /proc/sys/net/ipv4/ip_forward
]]></programlisting>
	<para>
You want your realserver to accept telnet requests on an IP that is
not on the network (say 192.168.1.111).
Here's the result of commands run at the server console before
running the TP code, confirming that you can't ping or telnet to the IP.
	</para>
<programlisting><![CDATA[
realserver:# ping 192.168.1.111
PING 192.168.1.111 (192.168.1.111) from 192.168.1.11 : 56(84) bytes of data.
From realserver.mack.net (192.168.1.11): Destination Host Unreachable

realserver:# telnet 192.168.1.111
Trying 192.168.1.111...
telnet: Unable to connect to remote host: No route to host
]]></programlisting>
	<para>
so add a route and try again (lo works here, eth0 doesn't)
	</para>
<programlisting><![CDATA[
realserver:# route add -host 192.168.1.111 lo
realserver:# telnet 192.168.1.111
Trying 192.168.1.111...
Connected to 192.168.1.111.
Escape character is '^]'.

Welcome to Linux 2.2.16.
realserver login:
]]></programlisting>
	<para>
This shows that you can connect to the new IP from the localhost.
No transparent proxy involved yet.
	</para>
	<para>
If you go to another machine on the same network and add a route to the new IP.
	</para>
<programlisting><![CDATA[
client:# route add -host 192.168.1.111 gw 192.168.1.11
client:# netstat -rn
Kernel IP routing table
Destination     Gateway         Genmask         Flags   MSS Window  irtt Iface
192.168.1.111   192.168.1.11    255.255.255.255 UGH       0 0          0 eth0
192.168.1.0     0.0.0.0         255.255.255.0   U         0 0          0 eth0
127.0.0.0       0.0.0.0         255.0.0.0       U         0 0          0 lo
]]></programlisting>
	<para>
raw sockets work between the client and server -
	</para>
<programlisting><![CDATA[
client:# traceroute 192.168.1.111
traceroute to 192.168.1.111 (192.168.1.111), 30 hops max, 40 byte packets
 1  server.mack.net (192.168.1.11)  0.634 ms  0.433 ms  0.561 ms
]]></programlisting>
	<para>
however you can't ping (i.e. icmp doesn't work)
or telnet to that IP from the other machine.
	</para>
<programlisting><![CDATA[
client:# ping 192.168.1.111
PING 192.168.1.111 (192.168.1.111) from 192.168.1.9 : 56(84) bytes of data.
From realserver.mack.net (192.168.1.11): Time to live exceeded

client:# telnet 192.168.1.111
Trying 192.168.1.111...
telnet: Unable to connect to remote host: No route to host
]]></programlisting>
	<para>
Here's the output of tcpdump running on the target host
	</para>
<programlisting><![CDATA[
14:09:09.789132 client.mack.net.1101 > tip.mack.net.telnet: S 1088013012:1088013012(0) win 32120 <mss 1460,sackOK,timestamp 7632700[|tcp]> (DF) [tos 0x10]
14:09:09.791205 realserver.mack.net > client.mack.net: icmp: time exceeded in-transit [tos 0xd0]
]]></programlisting>
	<para>
(Anyone have an explanation for this, apart from the fact that icmp is not working?
Is the lack of icmp the only thing stopping the telnet connect?)
	</para>
	<para>
The route to 192.168.1.111 is not needed for the next part.
	</para>
<programlisting><![CDATA[
realserver:# route del -host 192.168.1.111
]]></programlisting>
	<para>
Now add transparent proxy to the server to allow the realserver to
accept connects to 192.168.1.111:telnet
	</para>
	<para>
This is the command for 2.2.x kernels
	</para>
<programlisting><![CDATA[
realserver:# ipchains -A input -j REDIRECT telnet -d 192.168.1.111 telnet -p tcp
realserver:# ipchains -L
Chain input (policy ACCEPT):
target     prot opt     source                destination           ports
REDIRECT   tcp  ------  anywhere             192.168.1.111          any ->   telnet => telnet
Chain forward (policy ACCEPT):
Chain output (policy ACCEPT):
]]></programlisting>
		<section id="redirect_81">
		<title>redirecting any port at all</title>
		<para>
In the normal functioning of an LVS, once the packet has been redirected,
the director steps in and sends it to the realservers and the reply
comes from the realservers.
However you can use the REDIRECT to connect with a socket on a different port
independantly of the LVS function.
		</para>
		<para>
Joe, 4 Jun 2001
		</para>
		<para>
If I have 2 boxes (not part of an LVS) and on the server box
I run
		</para>
<programlisting><![CDATA[
$ipchains -A input -j REDIRECT telnet serverIP 81 -p tcp
]]></programlisting>
		<para>
then I can telnet to port 81 on the realserver box and have a normal
telnet session.
I watched with tcpdump on the server and all I see is a normal
exchange of packets with dest-port=81.
		</para>
		<para>
I thought with REDIRECT that the packet with dest-port=81
was delivered to the listener on realserverIP:telnet. How does the
telnetd know to return a packet with source-port=telnet?
		</para>
		<para>
Julian
		</para>
		<blockquote>
			<para>
This is handled from the protocol, TCP in this case:
			</para>
<programlisting><![CDATA[
grep redirport net/ipv4/*.c
]]></programlisting>
			<para>
	The higher layer (telnet in this case) can obtain the two dest
addr/ports by using getsockname(). In 2.4 this is handled additionally
by using getsockopt(...SO_ORIGINAL_DST...)
			</para>
			<para>
	The
<ulink url="http://marc.theaimsgroup.com/?l=netfilter&amp;r=1&amp;w=2">netfilter mailing list</ulink>
contains examples on this issue.
You can search for "getsockname"
			</para>
		</blockquote>
		</section>
		<section id="TP_2.4.x">
		<title>For 2.4.x kernels</title>
<programlisting><![CDATA[
server:# iptables -t nat -A PREROUTING -p tcp -d 192.168.1.111 --dport telnet -j REDIRECT
server:# iptables -L -t nat
Chain PREROUTING (policy ACCEPT)
target     prot opt source               destination
REDIRECT   tcp  --  anywhere             192.168.1.111       tcp dpt:telnet
			</para><para>
Chain POSTROUTING (policy ACCEPT)
target     prot opt source               destination
			</para><para>
Chain OUTPUT (policy ACCEPT)
target     prot opt source               destination
]]></programlisting>
		<para>
You still can't ping the transparent proxy IP on the server from the client
		</para>
<programlisting><![CDATA[
client:# ping 192.168.1.111
PING 192.168.1.111 (192.168.1.111) from 192.168.1.9 : 56(84) bytes of data.
From server.mack.net (192.168.1.11): Time to live exceeded
]]></programlisting>
		<para>
The transparent proxy IP on the server will accept telnet connects
		</para>
<programlisting><![CDATA[
client:# telnet 192.168.1.111
Trying 192.168.1.111...
Connected to 192.168.1.111.
Escape character is '^]'.

Welcome to Linux 2.2.16.
server login:
]]></programlisting>
		<para>
but not requests to other services
		</para>
<programlisting><![CDATA[
client:# ftp 192.168.1.111
ftp: connect: No route to host
ftp>
]]></programlisting>
		<para>
Conclusion: The new IP will only accept packets for the specified service.
It won't ping and it won't accept packets for other services.
		</para>
		</section>
	</section>
	<section id="TP_original_2.2">
	<title>The original 2.2 TP setup method</title>
<programlisting><![CDATA[
                        ________
                       |        |
                       | client |
                       |________|
                       CIP=192.168.1.254
                           |
                        (router)
                           |
                 VIP=192.168.1.110 (eth0, arps)
                      __________
                     |          |
                     | director |
                     |__________|
                     DIP=192.168.1.1 (eth1, arps)
                           |
                           |
          -------------------------------------
          |                |                  |
  RIP1=192.168.1.2  RIP2=192.168.1.3   RIP3=192.168.1.4 (eth0)
   _____________     _____________      _____________
  |             |   |             |    |             |
  | realserver  |   | realserver  |    | realserver  |
  |_____________|   |_____________|    |_____________|
          |                |                  |
      (router)          (router)           (router)
          |                |                  |
          ----------------------------------------------> to client
]]></programlisting>
	<para>
Here's a script to run on 2.2.x realservers/directors to setup Horms' method.
This is incorporated into the configure script.
	</para>
<programlisting><![CDATA[
#!/bin/sh
#rc.horms
#script by Joseph Mack and Horms (C) 1999, released under GPL.
#Joseph Mack jmack (at) wm7d (dot) net, Horms horms (at) vergenet (dot) net
#This code is part of the Linux Virtual Server project
#http://www.linuxvirtualserver.org
#
#
#Horm's method for solving the LVS arp problem for a LVS-DR LVS.
#Uses ipchains to redirect a packet destined for an external
#machine (in this case the VIP) to the local device.

#-----------------------------------------------------
#Instructions:
#
#1. Director: Setup normally (eg turn on LVS services there with ipvsadm).
#2. Realservers: Must be running 2.2.x kernel.
# 2.1 recompile the kernel (and reboot) after turning on the following under "Networking options"
#       Network firewalls
#       IP: firewalling
#       IP: transparent proxy support
#       IP: masquerading
# 2.2 Setup the realserver as if it were a regular leaf node on the network,
#      <emphasis>i.e.</emphasis> with the same gateway and IP as if it were in the LVS, but DO NOT
#      put the VIP on the realserver. The realserver will only have its regular IP
#      (called the RIP in the HOWTO).
#3. Edit "user configurable" stuff below"
#4. Run this script
#-----------------------------------------------------
#user configurable stuff

IPCHAINS="/sbin/ipchains"
VIP="192.168.1.110"

#services can be represented by their name (in /etc/services) or a number
#SERVICES is a quote list of space separated strings
# eg SERVICES="telnet"
#    SERVICES="telnet 80"
#    SERVICES="telnet http"
#Since the service is redirected to the local device,
#make sure you have SERVICE listening on 127.0.0.1
#
SERVICES="telnet http"
#
#----------------------------------------------------
#main:

#turn on IP forwarding (off by default in 2.2.x kernels)
echo "1" > /proc/sys/net/ipv4/ip_forward

#flush ipchains table
$IPCHAINS -F input

#install SERVICES
for SERVICE in $SERVICES
do
        {
        echo "redirecting ${VIP}:${SERVICE} to local:${SERVICE}"
        $IPCHAINS -A input -j REDIRECT $SERVICE -d $VIP $SERVICE -p tcp
        }
done

#list ipchain rules
$IPCHAINS -L input

#rc.horms----------------------------------------------
]]></programlisting>
	<para>
Here's the conf file for a LVS-DR LVS using TP on both the
director and the realservers. 
This is for a 2.2.x kernel director.
(For a 2.4.x director, the VIP device can't be TP -
TP doesn't work on a 2.4.x director).
	</para>
<programlisting><![CDATA[
#-------------------------------------
#lvs_dr.conf for TP on director and realserver
#you will have to add a host route or equivelent on the client/router
#so that packets for the VIP are routed to the director
LVS_TYPE=VS_DR
INITIAL_STATE=on
#note director VIP device is TP
VIP=TP lvs 255.255.255.255 lvs
DIP=eth0 dip 192.168.1.0 255.255.255.0 192.168.1.255
DIRECTOR_DEFAULT_GW=client
SERVICE=t telnet rr realserver1 realserver2
#note realserver VIP device is TP
SERVER_VIP_DEVICE=TP
SERVER_NET_DEVICE=eth0
SERVER_DEFAULT_GW=client
#----------end lvs_dr.conf------------------------------------
]]></programlisting>
	<para>
Here's the output from ipchains -L showing the redirects for just
the 2.2.x director
	</para>
<programlisting><![CDATA[
Chain input (policy ACCEPT):
target     prot opt     source                destination           ports
REDIRECT   tcp  ------  anywhere             lvs2.mack.net         any ->   telnet => telnet
REDIRECT   tcp  ------  anywhere             lvs2.mack.net         any ->   telnet => telnet
REDIRECT   tcp  ------  anywhere             lvs2.mack.net         any ->   www => www
REDIRECT   tcp  ------  anywhere             lvs2.mack.net         any ->   www => www
Chain forward (policy ACCEPT):
Chain output (policy ACCEPT):
]]></programlisting>
	</section>
	<section id="TP_2.4_problems" xreflabel="TP_2.4_problems">
	<title>Transparent proxy for 2.4.x (and presumably 2.6.x)</title>
	<para>
For 2.4.x kernels transparent proxy is built on netfilter
and is installed with ip_tables (not ipchains as with 2.2.x kernels).
	</para>
	<note>
		<para>
You need ip_tables support in the kernel and the ip_tables module must be loaded.
The ip_tables module is incompatible with the ipchains module
(which in 2.4.x is available for compatibility with scripts written for 2.2.x kernels).
If present, the ipchains module must be unloaded.
You shouldn't be running ipchains on 2.4.x kernels anymore and you
should have changed over to ip_tables.
		</para>
	</note>
	<para>
Unfortunately the transparent proxy that comes with 2.4 kernels does not
work for LVS.
The packet arrives locally with the IP of the NIC which accepts the packet,
rather than with an unchanged IP (the VIP).
This still allows a squid to work, but is useless for LVS.
The netfilter people didn't realise that someone (<emphasis>i.e.</emphasis> LVS)
had found a use for the original behaviour and it was dropped from the 2.4 code.
	</para>
	<para id="Balazs" xreflabel="Balazs">
Balazs Scheidler <emphasis>bazsi (at) balabit (dot) hu</emphasis>
has written a netfilter patch which restores the original functionality of
tproxy, for the firewall Zorp
(note: no-one has tested it with LVS yet).
Here is Balazs'
<ulink url="http://www.balabit.com/products/oss/tproxy/README.txt">
2.4 transparent proxy patches README</ulink>.
(In previous HOWTO's, I incorrectly attributed the patch to Ratz.
My apologies to Balazs.
Ratz has written a tproxy patch for LVS as part of his job,
but he is not allowed to release the code -
it seems I confused the two patches.)
	</para>
	<para>Mike McLean <emphasis>mikem (at) redhat (dot) com</emphasis> 04 Dec 2002
	</para>
	<blockquote>
The patch for 2.4 kernels should be shipped by RedHat.
If not please file a bug at bugzilla.redhat.com.
	</blockquote>
	<para>
If RedHat is patched with Balazs' code, then it is possible that it has been tested
with LVS (RedHat doesn't necessarily test their released code).
	</para>
	<para>
(Dec 2002).  Nearly all the following section is me
figuring out that TP for 2.4 doesn't work for LVS.
It will have to be rewritten as Balazs's patches are incorporated into LVS.
(Mar 2006, seems like noone is using them.)
	</para>
	<para>
The command for installing transparent proxy with iptables for 2.4.x came from
looking in Daniel Kiracofe's
<emphasis>drk (at) unxsoft (dot) com</emphasis>
<ulink url="http://www.tldp.org/HOWTO/mini/TransparentProxy.html">
Transparent Proxy with Squid mini-HOWTO</ulink>
and guessing the likely command. It turns out to be
	</para>
<programlisting><![CDATA[
director:# iptables -t nat -A PREROUTING [-i $SERVER_NET_DEVICE] -d $VIP -p tcp \
	--dport $SERVICE -j REDIRECT
]]></programlisting>
	<para>
(where $SERVICE = telnet, $SERVER_NET_DEVICE = eth0).
	</para>
	<para>
Here's the result of installing the VIP by transparent proxy on one of the
realservers.
	</para>
<programlisting><![CDATA[
realserver:~# iptables -L -t nat
Chain PREROUTING (policy ACCEPT)
target     prot opt source               destination
REDIRECT   tcp  --  anywhere             lvs2.mack.net      tcp dpt:telnet
REDIRECT   tcp  --  anywhere             lvs2.mack.net      tcp dpt:http

Chain POSTROUTING (policy ACCEPT)
target     prot opt source               destination

Chain OUTPUT (policy ACCEPT)
target     prot opt source               destination
]]></programlisting>
	<para>
This works fine for the realserver allowing it to accept packets for the VIP, 
without having the VIP on an ethernet device (eg lo, eth0).
	</para>
	<para>
With the problems of 2.4 kernel TP for the VIP on the director, 
people seem to have forgotten that TP
will still allow the realserver to accept packets for the VIP, 
solving the arp problem. Bill Omer rediscovered this a few years later
	</para>
	<para>
Bill Omer <emphasis>bill (dot) omer (at) gmail (dot) com</emphasis> 2 Mar 2006
	</para>
	<blockquote>
		<para>
Here's my setup with all the nitty gritty.  I'm using rhel3as, I have
all of the lvs portions of the kernel compiled as modules.
		</para>	
		<para>
the director part is straight forward:
		</para>
<programlisting><![CDATA[
ifconfig eth0:0 cvg1-lvs-vip netmask 255.255.255.255 broadcast cvg1-lvs-vip up
ipvsadm -A -t cvg1-lvs-vip:0 -s wlc -p
ipvsadm -a -t cvg1-lvs-vip:0 -r cvg1-app-101 -g
ipvsadm -a -t cvg1-lvs-vip:0 -r cvg1-app-102 -g
ipvsadm -a -t cvg1-lvs-vip:0 -r cvg1-app-103 -g
ipvsadm -a -t cvg1-lvs-vip:0 -r cvg1-app-104 -g
ipvsadm -a -t cvg1-lvs-vip:0 -r cvg1-app-105 -g
]]></programlisting>
		<para>
	The realserver(s)
		</para>
<programlisting><![CDATA[
RIP:
iptables -t nat -F
iptables -t nat -A PREROUTING -d cvg1-lvs-vip -p tcp --dport 0:65535 
-j REDIRECT
echo 1 > /proc/sys/net/ipv4/ip_forward
]]></programlisting>
		<para>
As far as ports 0:65535 goes, I know its a security risk. It's as
secure as the RIP's them self.  I plan on having about 30-40 thin
clients book up over the network (PXE, which I'd like to in time be
lvs'd) to an xdm.  After I get some stress testing done and pin point
some more bugs here and there, I'll narrow down the port range to be a
lil more complaint to rudimentary security measures.  However,
everything is being ran over a local lan and nothing is exposed to the
wild wild web.
		</para>
	</blockquote>
	<para>
If you do the same with TP on the director,
setup for an LVS with (say) telnet forwarded in the <command>ipvsadm</command> tables,
then the telnet connect request from the client is accepted
by the director, rather than forwarded by ipvs to the realservers
(<command>tcpdump</command> sees a normal telnet login to the director).
Apparently <command>ipchains</command> is sending the packets
to a place that ipvs can't get at them.
	</para>
	<para>
Joe
	</para>
	<blockquote>
		<para>
I have got TP to work on a LVS-DR telnet 2.4 realserver with the command
		</para>
<programlisting><![CDATA[
#iptables -t nat -A PREROUTING -p tcp -d $VIP --dport telnet -j REDIRECT
]]></programlisting>
		<para>
When I put the VIP onto the director this way, the LVS doesn't work.
I connect to the director instead of the realservers.
<command>ipvsadm</command> doesn't show any connections (active or otherwise)
		</para>
		<para>
If I run the same command on the director, with <command>ipvsadm</command> blank
(ie no LVS configured), then I connect to the director from the
client (as expected) getting the director's telnet login.
		</para>
		<para>
I presume that I'm coming in at the wrong place in the input chain
 of the director and <command>ipvsadm</command> is not seeing the packets?
		</para>
	</blockquote>
	<para>
Julian
	</para>
	<para>
	I haven't tried tproxy in 2.4 but in theory it can't work.
The problem is that netfilter implements tproxy by mangling the
destination address in the prerouting. LVS requires from the tproxy
implementation only to deliver the packet locally and not to alter
the header. So, I assume LVS detects the packets with daddr=local_addr
and refuses to work.
	</para>
	<para>
	Netfilter maintains a sockopt SO_ORIGINAL_DST that can be
used from the user processes to obtain the original dest addr/port
before they are mangled in the pre routing nat place. This can be used
from the squids, for example, to obtain these original values.
	</para>
	<para>
	If LVS wants to support this broken tproxy in netfilter we
must make a lookup in netfilter to receive the original dst and then
again to mangle (for 2nd time) the dst addr/port. IMO, this is very
bad and requires LVS always to require netfilter nat because it will
always depend on netfilter: LVS will be compiled to call netfilter
functions from its modules.
	</para>
	<para>
	So, the only alternative remains to receive packets with
advanced routing with fwmark rules. There is one problem in 2.2 and
2.4 when the tproxy setups must return ICMP to the clients (they
are internal in such setup), for example, when there is no realserver
LVS returns ICMP DEST_UNREACH:PORT_UNREACH. In this case both kernels
mute and don't return the ICMP. icmp_send() drops it. I contacted
Alexey Kuznetsov, the net maintainer, but he claims there are more
such places that must be fixed and "ip route add table 100 local
0/0 dev lo" is not a good command to use. But in my tests
I don't have any problems, only the problem with dropped ICMP
replies from the director.
	</para>
	<para>
	So, for TP, I'm not sure if we can support it in the
director. May be it can work for the realservers and even when
the packet is mangled I don't expect peformance problems but who
knows.
	</para>
	</section>
	<section id="identd_with_2.4_TP">
	<title>Experiments showing that 2.4TP is different to 2.2TP</title>
	<para>
These experiments were conducted with 2.2 or 2.4 kernel realservers accepting packets
for the VIP by TP. I initially noticed that the connection to 2.4 realservers was
not delayed by identd (which is running on my realservers). What was happening
was that the realserver was accepting the packet at the RIP and generating
the reply from the RIP, rather than the VIP. On my setup, the RIP is routable
to the client and the client probably received the identd request directly
from the realserver (I didn't figure out what was going on for a while after
I did this. I originally thought this had something to do with identd).
	</para>
	<para>
Here's the data showing that TP behaves differently for 2.2 and 2.4 kernels.
If you want to <link linkend="2.4_TP_IP">skip ahead</link>, the piece of information
you need is that the IP of the packet when it arrives on the target machine by TP,
is different for 2.2 and 2.4 TP.
	</para>
	<para>
As we shall see, for 2.2.x the TP'ed packets arrive on the VIP,
while for 2.4.x, the TP'ed packets arrive on the RIP.
	</para>
		<section>
		<title>Realserver, Linux 2.4.2 kernel accepting packets for VIP on lo:110, is delayed</title>
		<para>
Here's the tcpdump on the realserver (RS2) for a telnet request delayed
by authd (the normal result for LVS). Realserver 2.4.2 with Julian's hidden patch,
director 0.2.5-2.4.1. The VIP on the realserver is on lo:110.
		</para>
		<para>
Note: all packets on the realserver are originating and arriving on the VIP (lvs2)
as expected for a LVS-DR LVS.
		</para>
<programlisting><![CDATA[
initial telnet request

21:04:46.602568 client2.1174 > lvs2.telnet: S 461063207:461063207(0) win 32120 <mss 1460,sackOK,timestamp 17832675[|tcp]> (DF) [tos 0x10]
21:04:46.611841 lvs2.telnet > client2.1174: S 3724125196:3724125196(0) ack 461063208 win 5792 <mss 1460,sackOK,timestamp 514409[|tcp]> (DF)
21:04:46.612272 client2.1174 > lvs2.telnet: . ack 1 win 32120 <nop,nop,timestamp 17832676 514409> (DF) [tos 0x10]
21:04:46.613965 client2.1174 > lvs2.telnet: P 1:28(27) ack 1 win 32120 <nop,nop,timestamp 17832676 514409> (DF) [tos 0x10]
21:04:46.614225 lvs2.telnet > client2.1174: . ack 28 win 5792 <nop,nop,timestamp 514409 17832676> (DF)

realserver makes authd request to client

21:04:46.651500 lvs2.1061 > client2.auth: S 3738365114:3738365114(0) win 5840 <mss 1460,sackOK,timestamp 514413[|tcp]> (DF)
21:04:49.651162 lvs2.1061 > client2.auth: S 3738365114:3738365114(0) win 5840 <mss 1460,sackOK,timestamp 514713[|tcp]> (DF)
21:04:55.651924 lvs2.1061 > client2.auth: S 3738365114:3738365114(0) win 5840 <mss 1460,sackOK,timestamp 515313[|tcp]> (DF)

after delay of 10secs, telnet request continues

21:04:56.687334 lvs2.telnet > client2.1174: P 1:13(12) ack 28 win 5792 <nop,nop,timestamp 515416 17832676> (DF)
21:04:56.687796 client2.1174 > lvs2.telnet: . ack 13 win 32120 <nop,nop,timestamp 17833684 515416> (DF) [tos 0x10]
]]></programlisting>
		</section>
		<section>
		<title>Realserver, Linux 2.4.2, accepting packets for VIP by TP, is not delayed</title>
		<para>
Here's the tcpdump on the realserver (RS2) for a telnet request which
connects immediately. This is not the normal result for LVS.
Realserver 2.4.2 with Julian's hidden patch (not used),
director 0.2.5-2.4.1. Packets on the VIP are being accepted by TP rather than
on lo:0 (the only difference).
		</para>
		<para>
Note: some packets on the realserver (RS2) are arriving and originating on the
VIP (lvs2) and some on the RIP (RS2). In particular all telnet packets from
the CIP are arriving on the RIP, while all telnet packets from the realserver
are originating on the VIP. For authd, all packets to and from the realserver
are using the RIP.
		</para>
<programlisting><![CDATA[
initial telnet request

20:56:43.638602 client2.1169 > RS2.telnet: S 4245054245:4245054245(0) win 32120 <mss 1460,sackOK,timestamp 17784379[|tcp]> (DF) [tos 0x10]
20:56:43.639209 lvs2.telnet > client2.1169: S 3234171121:3234171121(0) ack 4245054246 win 5792 <mss 1460,sackOK,timestamp 466118[|tcp]> (DF)
20:56:43.639654 client2.1169 > RS2.telnet: . ack 3234171122 win 32120 <nop,nop,timestamp 17784380 466118> (DF) [tos 0x10]
20:56:43.641370 client2.1169 > RS2.telnet: P 0:27(27) ack 1 win 32120 <nop,nop,timestamp 17784380 466118> (DF) [tos 0x10]
20:56:43.641740 lvs2.telnet > client2.1169: . ack 28 win 5792 <nop,nop,timestamp 466118 17784380> (DF)

realserver makes authd request to client

20:56:43.690523 RS2.1057 > client2.auth: S 3231319041:3231319041(0) win 5840 <mss 1460,sackOK,timestamp 466123[|tcp]> (DF)
20:56:43.690785 client2.auth > RS2.1057: S 4243940839:4243940839(0) ack 3231319042 win 32120 <mss 1460,sackOK,timestamp 17784385[|tcp]> (DF)
20:56:43.691125 RS2.1057 > client2.auth: . ack 1 win 5840 <nop,nop,timestamp 466123 17784385> (DF)
20:56:43.692638 RS2.1057 > client2.auth: P 1:10(9) ack 1 win 5840 <nop,nop,timestamp 466123 17784385> (DF)
20:56:43.692904 client2.auth > RS2.1057: . ack 10 win 32120 <nop,nop,timestamp 17784385 466123> (DF)
20:56:43.797085 client2.auth > RS2.1057: P 1:30(29) ack 10 win 32120 <nop,nop,timestamp 17784395 466123> (DF)
20:56:43.797453 client2.auth > RS2.1057: F 30:30(0) ack 10 win 32120 <nop,nop,timestamp 17784395 466123> (DF)
20:56:43.798336 RS2.1057 > client2.auth: . ack 30 win 5840 <nop,nop,timestamp 466134 17784395> (DF)
20:56:43.799519 RS2.1057 > client2.auth: F 10:10(0) ack 31 win 5840 <nop,nop,timestamp 466134 17784395> (DF)
20:56:43.799738 client2.auth > RS2.1057: . ack 11 win 32120 <nop,nop,timestamp 17784396 466134> (DF)

telnet connect continues, no delay

20:56:43.835153 lvs2.telnet > client2.1169: P 1:13(12) ack 28 win 5792 <nop,nop,timestamp 466137 17784380> (DF)
20:56:43.835587 client2.1169 > RS2.telnet: . ack 13 win 32120 <nop,nop,timestamp 17784399 466137> (DF) [tos 0x10]
]]></programlisting>
		<para>
Evidently TP on the realserver is making the realserver think that the packets
arrived on the RIP, hence the authd call is made from the RIP.
		</para>
		<para>
As it happens in my test setup, the client can connect directly to the RIP.
(In a LVS-DR LVS, the client doesn't exchange packets with the RIP,
so I haven't blocked this connection.
In production, the router would not allow these packets to pass).
Since the authd packets are between the RIP and CIP,
the authd exchange can proceed to completion.
		</para>
		</section>
		<section>
		<title>Realserver, Linux 2.2.14, accepting packets for VIP by TP, is delayed</title>
		<para>
Here's the tcpdump on the realserver (RS2) for a telnet request which
connects immediately. This is not the normal result for LVS.
Realserver 2.2.14,
director 0.2.5-2.4.1. Packets on the VIP are being accepted by TP rather than
on lo:0.
		</para>
		<para>
Note: TP is different in 2.2 and 2.4 kernels.
Unlike the case for the 2.4.2 realserver, the packets all arrive at the RIP.
		</para>
		<para>
<programlisting><![CDATA[
initial telnet request

22:16:23.407607 client2.1177 > lvs2.telnet: S 707028448:707028448(0) win 32120 <mss 1460,sackOK,timestamp 18262396[|tcp]> (DF) [tos 0x10]
22:16:23.407955 lvs2.telnet > client2.1177: S 3961823491:3961823491(0) ack 707028449 win 32120 <mss 1460,sackOK,timestamp 21648[|tcp]> (DF)
22:16:23.408385 client2.1177 > lvs2.telnet: . ack 1 win 32120 <nop,nop,timestamp 18262396 21648> (DF) [tos 0x10]
22:16:23.410096 client2.1177 > lvs2.telnet: P 1:28(27) ack 1 win 32120 <nop,nop,timestamp 18262396 21648> (DF) [tos 0x10]
22:16:23.410343 lvs2.telnet > client2.1177: . ack 28 win 32120 <nop,nop,timestamp 21648 18262396> (DF)

authd request from realserver

22:16:23.446286 lvs2.1028 > client2.auth: S 3966896438:3966896438(0) win 32120 <mss 1460,sackOK,timestamp 21652[|tcp]> (DF)
22:16:26.445701 lvs2.1028 > client2.auth: S 3966896438:3966896438(0) win 32120 <mss 1460,sackOK,timestamp 21952[|tcp]> (DF)
22:16:32.446212 lvs2.1028 > client2.auth: S 3966896438:3966896438(0) win 32120 <mss 1460,sackOK,timestamp 22552[|tcp]> (DF)

after delay of 10secs, telnet proceeds

22:16:33.481936 lvs2.telnet > client2.1177: P 1:13(12) ack 28 win 32120 <nop,nop,timestamp 22655 18262396> (DF)
22:16:33.482414 client2.1177 > lvs2.telnet: . ack 13 win 32120 <nop,nop,timestamp 18263404 22655> (DF) [tos 0x10]
]]></programlisting>
		</para>
		</section>
	</section>
	<section id="2.4_TP_IP">
	<title>What IP TP packets arriving on?</title>
	<para>
Note: for TP, there is no VIP on the realservers as seen by ifconfig.
	</para>
	<para>
Since telnetd on the realservers listens on 0.0.0.0,
we can't tell which IP the packets have on the realserver after being TP'ed.
tcpdump only tells you the src_addr after the packets have left the sending host.
	</para>
	<para>
Here's the setup for the test.
	</para>	
	<para>
The IP of the packets after arriving by TP
was tested by varying the IP (localhost, RIP or VIP)
that the httpd listens to on the realservers.
At the same time the base address of the web page was
changed to be the same as the IP that the httpd was listening to.
The nodes on each network link
can route to and ping each other (eg 192.168.1.254 and 192.168.1.12).
	</para>
<programlisting><![CDATA[
        ____________
       |            |192.168.1.254 (eth1)
       |  client    |----------------------
       |____________|                     |
     CIP=192.168.2.254 (eth0)             |
              |                           |
              |                           |
     VIP=192.168.2.110 (eth0)             |
        ____________                      |
       |            |                     |
       |  director  |                     |
       |____________|                     |
     DIP=192.168.1.9 (eth1, arps)         |
              |                           |
           (switch)------------------------
              |
     RIP=192.168.1.12 (eth0)
     VIP=192.168.2.110 (LVS-DR, lo:0, hidden)
        _____________
       |             |
       | realserver  |
       |_____________|
]]></programlisting>
	<para>
The results (LVS-DR LVS) are
	</para>
	<para>
For 2.2.x realservers
	</para>
	<itemizedlist>
		<listitem>
the httpd can bind to the VIP, RIP and localhost.
		</listitem>
		<listitem>
LVS client gets webpage if realserver is listening to RIP or VIP.
		</listitem>
		<listitem>
LVS client does not get webpage if realserver is listening to localhost.
		</listitem>
	</itemizedlist>
	<para>
For 2.4.x realservers
	</para>
	<itemizedlist>
		<listitem>
httpd can bind to the RIP and localhost.
		</listitem>
		<listitem>
httpd cannot bind to the VIP.
		</listitem>
		<listitem>
LVS client gets webpage if realserver is listening to RIP.
		</listitem>
		<listitem>
LVS client does not get webpage if realserver is listening to localhost.
		</listitem>
	</itemizedlist>
	<para>
During tests, the browser says "connecting to VIP", then says "transferring from..."
	</para>
	<itemizedlist>
		<listitem>
LVS-DR, VIP on TP, kernel 2.4.2, "transferring data from RIP"
		</listitem>
		<listitem>
LVS-DR, VIP on TP, kernel 2.2.14, "transferring data from VIP" (or RIP)
		</listitem>
		<listitem>
LVS-DR VIP on lo:0, httpd listening to VIP, "transferring data from VIP"
		</listitem>
		<listitem>
LVS-Tun VIP on tunl0:0, httpd listening on VIP, "transferring from VIP"
		</listitem>
		<listitem>
LVS-NAT, httpd listening on RIP, "transferring data from realserver1" (or realserver2)
		</listitem>
	</itemizedlist>
	<para>
Some of these connections are problematic.
The client in a LVS-DR LVS isn't supposed to be getting packets from the RIP.
What is happening is
	</para>
	<itemizedlist>
		<listitem>
the httpd on the realserver is listening on the RIP
		</listitem>
		<listitem>
the base address of the webpage is the RIP
		</listitem>
		<listitem>
an incoming request from the client to the VIP will retrieve a webpage
with references to gif etc that are at the RIP
		</listitem>
		<listitem>
the client will then ask for the gifs from the RIP.
		</listitem>
		<listitem>
in the above setup that I use for testing,
the client does not request packets from the RIP.
		</listitem>
		<listitem>
in the above setup, the client can connect to the RIP directly
(this will not be allowed in a production server,
either the router will prevent the connection,
or the RIP will be a non-routable IP).
		</listitem>
		<listitem>
the client retrieves the gifs, and the rest of the page,
directly from the realserver
		</listitem>
	</itemizedlist>
	<para>
The way to prevent this is to remove the route on the client to the RIP network
(eg see <link linkend="Pearthree">removing routes not needed for LVS-DR</link>).
Doing so when the httpd is listening to the RIP and the base address is the
RIP causes the browser on the client to hang.
This shows that the client is really retrieving packets directly
from the RIP.
Changing the base address of the
webpage back to the VIP allows the webpage to be delivered to the client,
showing that the client is now retrieving packets by making requests to the
VIP via the director.
	</para>
	<para>
It would seem then that with 2.4 TP, the realserver is receiving packets on the
RIP, rather than the VIP as it does with 2.2 TP. With a service listening to only
1 port (eg httpd) then the httpd has to
	</para>
	<itemizedlist>
		<listitem>
listen on the RIP
		</listitem>
		<listitem>
the addresses on the webpage have to be for the VIP
		</listitem>
	</itemizedlist>
	<para>
The client will then ask for the webpage at the VIP.
The realserver will accept this request on the RIP and return
a webpage full of references to the VIP (eg gifs).
The client will then ask for the gifs from the VIP.
The realserver will accept the requests on the RIP and return
the gifs.
	</para>
	</section>
	<section id="TP_settingup_realservers">
	<title>Take home lesson for setting up TP on realservers</title>
		<section>
		<title>2.2.x</title>
		<para>
Let httpd listen on VIP or RIP, return pages with references to VIP
		</para>
		</section>
		<section>
		<title>2.4.x</title>
		<para>
Let httpd listen on RIP, return pages with references to VIP.
		</para>
		</section>
	</section>
	<section id="identd_with_TP_realservers">
	<title>Handling identd requests from 2.4.x LVS-DR realservers using TP</title>
	<para>
Since the identd request is coming from the RIP (rather than the VIP)
on the realserver, you can use
Julian's <link linkend="NAT_clients_in_LVS-DR">method for NAT'ing client
requests from realservers</link>.
	</para>
	</section>
	<section id="TP_performance" xreflabel="transparent proxy performance">
	<title>Performance of Transparent Proxy</title>
	<para>
Using transparent proxy instead of a regular ethernet device
has slightly higher latency, but the same maximum throughput.
	</para>
	<para>
For performance of transparent proxy compared to accepting packets on an
ethernet device see the
<ulink url="http://www.linuxvirtualserver.org/Joseph.Mack/performance/single_realserver_performance.html">performance page</ulink>.
	</para>
	<para>
Transparent proxy requires reprocessing of incoming packets,
and could have a similar speed penalty as LVS-NAT. However only the incoming
packets are reprocessed. Initial results (before the performance tests above)
were initially not encouraging.
	</para>
	<para>
Doug Bagley <emphasis>doug (at) deja (dot) com</emphasis>
	</para>
	<blockquote>
		<para>
Subject: [lvs-users] chosen arp problem solution can apparently affect performance
		</para>
		<para>
 I was interested in seeing if the linux/ipchains workaround for the
 arp problem would perform just as well as the arp_invisible kernel
 patch.  It is apparently much worse.
		</para>
		<para>
 I ran a test with one client running ab ("apache benchmark"), one
 director, and one realserver running Apache.  They are all various
 levels of pentium desktop machines running 2.2.13.
		</para>
		<para>
 Using the arp_invisible patch/dummy0 interface, I get 226 HTTP
 requests/second.  Using the ipchains redirect method, I get 70
 requests per second.  All other things remained the same during the
 test.
		</para>
	</blockquote>
	<para>
See the
<ulink url="http://www.linuxvirtualserver.org/Joseph.Mack/performance/single_realserver_performance.html">performance page</ulink>
for discussion and sample graphs of hits/sec
for http servers. Hits/sec can increase to high levels as the payload
decreases in size. While large numbers for hits/sec may be impressive,
they only indicate one aspect of a web server's performance. If large
(> 1 packet) files are transferred/hit or computation is involved,
then hits/sec is not a useful measure of web performance.
	</para>
	<para>
Here's the current explanation for decreased latency of transparent proxy.
	</para>
	<para>
Kyle Sparger <emphasis>ksparger (at) dialtoneinternet (dot) net</emphasis>
	</para>
	<blockquote>
		<para>
 Logically, it's just a function of the way the redirect code operates.
		</para>
<programlisting><![CDATA[
Without redirect:
Ethernet -> TCP/IP -> Application -> TCP/IP -> Ethernet

With redirect:
Ethernet -> TCP/IP -> Firewall/Redirect Code -> TCP/IP -> Application -> TCP/IP -> Ethernet
]]></programlisting>
		<para>
 That would definitely explain the slowdown, since _every single packet_
 received is going to go through these extra steps.
		</para>
	</blockquote>
	<para>
Other people are happy with TP
	</para>
	<para>
Jerry Glomph Black <emphasis>black (at) real (dot) com</emphasis> Nov 99 (or thereabouts)
	</para>
	<blockquote>
The revival of Horms' posting, which I overlooked a month ago, was
a lifesaver for us. We had a monster load distribution problem, and
spread 4 virtual IP numbers across 10 'real' boxes (running Roxen,
a fantastic web platform). The ipchains-REDIRECT feature works perfectly,
without any of that arp aggravation! A PII_450 held up just fine at
20 megabits/s of HTTP -REQUEST- TRAFFIC!
	</blockquote>
	<para>
Here's Jerry 18 months later.
	</para>
	<para>
Jerry Glomph Black <emphasis>black (at) prognet (dot) com</emphasis> 06 Jul 2001
	</para>
	<blockquote>
		<para>
The ipchains/iptables REDIRECT method (introduced to this list by Mr Horms
a long time ago) works fine, we've used it in production in the past.
		</para>
		<para>
However, at -very- high packet loads it is far less CPU-efficient than
getting the ARP settings correctly working.   The REDIRECT method was bogging
down our LVS boxes during peak traffic, something which does not happen with
doing it the 'right way' with LVS-DR and silent arp-less interfaces on the real
servers.
		</para>
	</blockquote>
	</section>
	<section id="tp_redirect" xreflabel="TPROXY">
	<title>The difference between REDIRECT and TPROXY</title>
	<para>
Horms
	</para>
	<para>
REDIRECT works by changing the destination IP address
to a local address so that it ends up in the LOCAL_IN chain.
	</para>
	<note>
REDIRECT with 2.2 kernels was the original basis for "Horm's method"
	</note>
	<para>
Joe Oct 03, 2003
	</para>
	<blockquote>
is the original 2.4.x REDIRECT disaster (see <xref linkend="TP_2.4_problems"/>)
fixed now?
	</blockquote>
	<para>
TPROXY looks like it would work because it is completely different
from REDIRECT and uses its own connection tracking.
REDIRECT uses netfilter's internal connection tracking routines.
Because of the way that LVS is implemented, these do not work for
packets that are handled by LVS. Thus the connection tracking
for REDIRECT does not work. Thus the return packets from the
realservers are not modified and the connection fails.
From my reading TPROXY uses its own connection tracking routines
(though for what reason I am not sure). These routines probably
aren't effected by LVS and thus TPROXY should work.
	</para>
	<para>
N.B: I have not verified this.
	</para>
	</section>
</section>
<section id="LVS-HOWTO.transparent_bridging" xreflabel="Transparent Bridging">
<title>LVS: Transparent Bridging</title>
<para>
Here's a summary of bridging as it relates to LVS directors
with help from Julian and Joe Cooper <emphasis>joe (at) swelltech (dot) com</emphasis> Apr 2002.
We haven't done anything thing with transparent bridging in LVS yet,
but the subject comes up in the mailing list often enough to
warrant some info in the HOWTO.
			</para><para>
The director sits between 2 networks, the realserver network and the
outside world.
Bridging has been proposed several times on the list for the director
as a way of getting packets between the realservers and the outside world.
Initially I thought that bridging could be used to send packets through the
director to 0/0 from a realserver in LVS-DR, thus solving the problem
now solved by the <xref linkend="martian_modification"/>.
			</para><para>
A bridge is a layer-2 device for connecting 2 physically separate networks.
Being a layer-2 device, a bridge only looks at the MAC addresses on a packet.
The bridge doesn't look at the IPs and has no information about routing
at the IP level. Here's a 2 NIC bridge connecting 2 networks.
			</para><para>
			</para><para>
<programlisting><![CDATA[
     network A
     -------------------------------
                  |
                  |
                  | eth0
            -------------
           |             |
           |    bridge   |
           |             |
            -------------
                  | eth1
                  |
                  |
     --------------------------------
     network B
]]></programlisting>
			</para><para>
In one implementation (the transparent bridge) the bridge learns
the network location of hosts (<emphasis>i.e.</emphasis> which NIC the host
is attached to) by inspecting the source MAC addresses of
packets.
			</para><para>
Since the bridge only inspects the MAC addresses on packets, the IPs
on the hosts in network
A and network B, can belong to the same or different IP networks/netmasks.
A bridge can be used to separate traffic. If all hosts are on 192.168.1.0/24
but most of the packets are passed between 2 hosts, these two hosts
can be put on one of the networks and the rest on the other network.
At the same time the bridge connects separate networks, without adding
route table entries on the hosts in the two networks.
So bridging allows connection of different physical networks without
requiring route entries (needed if a router had been used instead),
but keeps the traffic off networks that don't need to hear them.
Not being a router, the bridge is not seen by traceroute.
			</para><para>
About transparent bridging from the howstuffworks site
			</para><para>
http://www.howstuffworks.com/lan-switch4.htm
			</para><para>
and from cisco (including an explanation of the spanning tree algorithm)
			</para><para>
http://www.cisco.com/univercd/cc/td/doc/cisintwk/ito_doc/transbdg.htm
			</para><para>
About bridging from the internet encyclopedia at freesoft
			</para><para>
http://www.freesoft.org/CIE/Topics/30.htm (site down 14 Sep 2004)
			</para><para>
transparent proxy with bridging from the Transparent Proxy with Linux and Squid mini-HOWTO
http://www.tldp.org/HOWTO/mini/TransparentProxy-7.html
			</para><para>
In Linux, the first bridges were implemented by proxy-arp and is called pseudo-bridging.
Proxy-arp works only for IPv4.
			</para><para>
http://www.tldp.org/HOWTO/Adv-Routing-HOWTO-16.html (from the Advanced Routing HOWTO).
			</para><para>
Here's some more on proxy-arp.
			</para><para>
http://www.sjdjweis.com/linux/proxyarp/
			</para><para>
With proxy-arp running on the setup above, eth1 would be configured to reply to arp
requests for an IP on network A allowing packets from network B to be sent to that
host on network A.
			</para><para>
With proxy-arp, packets are sent through the tcpip stack and routing tables
on the bridge host. These packet can be filtered (iptables/ipchains), but
also martian packets will be recognised and dropped.
			</para><para>
Kate (aka John Looney) asked if bridging could be used to put a director
infront of a functioning server, to make an LVS, without breaking service
to the clients accessing that server.
			</para><para>
<blockquote><para>John P. Looney 18 Apr 2002
			</para><para>
The director is configured to listen for the IPs of the realservers at
the internal side of the network bridge, and pass them on, with some
intelligence.
			</para><para>
<programlisting><![CDATA[
     RS1    RS2    RS3
     |       |      |
     \--------------/
             |
         DR/Bridge
             |
          router
             |
          Clients

  RS1=original webserver (ip 293.2.2.1/26)
  RS2=new webserver (ip 293.2.2.2/26)
  RS3=new webserver (ip 293.2.2.3/26)
  DR =Director (ip 293.2.2.4/26)
  router (ip 293.2.2.63/26 and 293.2.3.63/26)
]]></programlisting>
			</para><para>
Note the router is not on the same physical network as the realservers,
but is on the same logical network.
			</para><para>
So, when a connection comes in for RS1 (293.2.2.1), the router sends out an ARP
request. The DR answers with it's own MAC, and transparently forwards all
</para></blockquote>
			</para><para>
Julian Anastasov <emphasis>ja (at) ssi (dot) bg</emphasis> 18 Apr 2002
			</para><para>
	not with the director's MAC when bridging
is used.
			</para><para>
<blockquote><para>
connections on to RS1/RS2/RS3 depending on it's load balancing algorithm.
The realservers still have their gateway set to be the router.
</para></blockquote>
			</para><para>
	By using the bridging code you have to stick with the
following rules:
			</para><para>
<orderedlist>
<listitem><para>it is Layer 2, i.e. the decisions to do something with the packet
are based entirely on the link layer protocol info (until you
patch the code, of course)
			</para><para>
</para></listitem><listitem><para>at link layer level we have broadcast/multicast/unicast addresses
			</para><para>
</para></listitem><listitem><para>all received non-unicast frames are passed to the IP stack and to all
other bridge ports
			</para><para>
</para></listitem><listitem><para>all unicast frames are passed to the IP stack or to the
appropriate bridge port according to the destination link layer
address
			</para><para>
</para></listitem><listitem><para>Linux IP does not accept packets destined to foreign lladdr
(for ethernet, link layer address == MAC).
			</para><para>
</para></listitem><listitem><para>Linux does not send ICMP replies for frames not destined to
our lladdr (one of the reasons not to see ICMP errors against
UDP broadcsts, for example, for missing listener)
			</para><para>
</para></listitem><listitem><para>Linux TCP accepts frames destined only to our lladdr
			</para><para>
</para></listitem><listitem><para>Linux does not forward packets not destined to our lladdr
</para></listitem></orderedlist>
			</para><para>
	To put this in the LVS space (we assume the Director is using
bridging and is between the uplink router and the realservers):
			</para><para>
- according to (3) we can't stop the broadcast ARPs reaching
the realservers and they to reply to the requestor (the router),
<emphasis>i.e.</emphasis> we can't avoid the ARP problem for DR and TUN methods.
			</para><para>
- according to (4) the realservers can reach the router directly
without disturbing the director's rp_filter. As result, the bridging
helps the director to pass the LVS-DR replies from the realservers
to the uplink router
			</para><para>
- the uplink router sees one LAN because the bridging code passes
all frames preserving the original source link layer addresses
			</para><para>
	We can say that the default bridging behavior is not
the desired one for all cases. There are some useful modes we
can require from the bridging. For example, in one mode we can
grab all IP packets (even packets destined to foreign lladdrs)
and to feed them to the upper layers and to rely on the proper
routing rules for filtering, etc. The bonus is that you don't need
to place your IPs, routes, etc on the bridging interfaces, you don't
need to implement firewalling specificaly designed for the
bridged ports, etc, etc.
			</para><para>
			</para><para>
<blockquote><para>Joe Cooper <emphasis>joe (at) swelltech (dot) com</emphasis>
CONFIG_NET_DIVERT is the IP packet diverter that allows one to configure
selective redirects from a bridged interface, so that it can then be
REDIRECTED or whatever by the iptables rules.  Benoit Locher wrote it
and his homepage about the project is here: http://diverter.sourceforge.net/
			</para><para>
It is a part of the official Linux trees (2.2.19+ and 2.4.10+) these
days, so no patching is necessary, but you do need the divert-utils
package to configure it if you're going to use it.  It makes the Linux
bridging code a lot cooler than your ordinary bridge.
</para></blockquote>
			</para><para>
<blockquote><para>Julian
There is layer 2 software under CONFIG_BRIDGE option (the currently discussed
solution)
			</para><para>
http://bridge.sourceforge.net
			</para><para>
        With Bridging the realservers can send packets to the
uplink router through the director's layer 2 bridge. So, yes, the
packets are handled from director but do not reach routing. The
trick is that if the packets are destined to the director's MAC (which
is always true for proxy ARP) then in both solutions the IP
packet reaches routing. So, the director's IP should not be used
as gateway. But director can run Linux Bridging and to stay betwen
the realserver(s) and the client(s)/uplink router. In this case
the realservers don't know that when talking to the uplink
router's MAC their packets go through director's layer 2.
			</para><para>
        If DIP is used as GW in realservers then even with
bridging you have to use the forward_shared flag. If uplink router's
IP is used as GW then we can run Bridging on the director if we want
to split the segment.
			</para><para>
        Where is the trick: the realservers resolve with ARP their
GW IP and later send the packets to the resulting MAC. If GWIP is
a director's IP then we receive director's MAC and the traffic
reaches routing.
			</para><para>
        So, if we want to put director physically between uplink
router and realservers and to use DR or TUN methods without
forward_shared flags we can do it by using Bridging and by using
the uplink router's IP as GW in the realservers. The only thing that
Bridging gives us is that we can use the uplink router's IP as GW
in realservers. The Bridging connects the two network segments.
</para></blockquote>
			</para><para>
The critical difference then is the gw configured on the realservers.
If it is an IP/MAC on the director, then the directors routing tables
will see the packet. If the gw is the router on the outside of the
director, then the packet will be bridged without seeing the director's
routing tables. Presumably this will solve the martian problem.
(No-one has tried this out yet).
</para>
</section>
<section id="LVS-HOWTO.persistent_connection" xreflabel="persistent connection">
<title>LVS: Persistent Connection (Persistence, Affinity in cisco-speak)</title>
<para>
<note>
	<para>
Apr 2006: No-one has tried this, but it seems that the <xref linkend="SH-scheduler"/>
could replace persistence, without the failover problems of persistence.
The SH scheduler schedules according to the client IP, 
meaning that all of a client's connection requests will be sent to the same RIP. 
The SH scheduler has been around for a while, 
but it seems that no-one has known what it did.
One of the problems was that no-one knew how to use the weight parameter.
	</para>
</note>
<note>Sep 2002: Rewritten.
All references to the LVS persistence used in kernels &lt;2.2.12 have been dropped.
</note>
</para>
<para>
(For another writeup on persistence, see
<ulink url="http://www.linuxvirtualserver.org/docs/persistence.html">
LVS persistence page
</ulink>.)
</para>
<para>
For LVS, the term &quot;persistence&quot; has 2 meanings. 
</para>
<itemizedlist>
	<listitem>
&quot;persistent connection&quot;
a term used for clients connecting to webservers and databases.
For Apache this is called a "keepalive" and is set in <filename>httpd.conf</filename>
and is described in <xref linkend="persistent_http"/>. 
	</listitem>
	<listitem>
&quot;persistent connection&quot; used in LVS.
LVS persistence is closer to the concept of 
"affinity" as used by cisco
	</listitem>
</itemizedlist>
<para>
The two types of persistence are quite different.
Unfortunately, both features are persistent 
and can reasonably claim the name "persistent".
This causes some confusion in nomenclature.
LVS persistence could alternately be described as connection affinity or port affinity.
</para>
<para>
LVS persistence directs all (tcpip) connection requests from the client 
to one particular realserver. 
Each new (tcpip) connection request from the client resets a timeout 
(time set by the <command>-p</command> option of <command>ipvsadm</command>)
LVS persistence has been part of LVS for quite a while
(first implementation by Pete Kese, when it was called pcc) 
and was added to handle ssl connections, squids and multiport connections like ftp
(squids now have their own scheduler).
</para>
<para>
(LVS) persistence is also used when the realserver must maintains state 
(<emphasis>i.e.</emphasis> when the client sends information to the
realserver in shopping carts, or writing to an application such as a database,
or the client must hold a cookie).
</para>
<para>
Persistence has the following effects
</para>
<itemizedlist>
	<listitem>
		<para>
Because the client is connected to one server for the session,
applications like shopping carts and databases don't have to be rewritten when moving
services to an LVS. 
The shopping cart can accumulate information just as it does when it runs on a standalone server.
This is the original reason for the persistence feature.
		</para>
		<para>
Because the client's data is only on one realserver, 
the data must be propagated to the other realservers before
anyone else needing that information connects.
		</para>
	</listitem>
	<listitem>
		<para>
There is no load balancing for the client, 
<emphasis>i.e.</emphasis> all connections are sent to one realserver.
This is not a big problem, since a heavily loaded server will be
handling thousands of connections at any one time, and whether
one client has all its connections to one realserver or to many
doesn't make much difference to anyone.
		</para>
	</listitem>
	<listitem>
		<para>
The difficulty of handling failover is the worst side effect of using persistence. 
As initially implemented, if a realserver crashed, 
or was brought down for maintenance (by setting the weight to zero),
the director would still send connections from the client to the same realserver,
until the timeout expired. 
In the case of a crashed realserver, the client wouldn't get a connection
and its session would be hung (or get a tcpip reset).
In the case of bringing a machine down for maintenance, 
the administrator would have to wait till all the clients finished their session.
		</para>
		<para>
Because of the hung connections on realserver failure with persistent connection,
in late 2004, Horms 
<link linkend="new_persistence">
changed the behaviour on bringing down a persistent connection </link>
so that it was the same as for non-persistent connection,
<emphasis>i.e.</emphasis> the no new tcpip connections would be allowed.
The problem now is that data written to the crashed realserver is lost.
The client will make their next click expecting to move to the next screen, 
only to find that the realserver has no idea who they are.
Presumably the application will have to be written to behave sensibly with this client
("we're sorry, your connection is important to us - who are you and why are you connecting?").
At least this behaviour is better than a hung connection in the middle of a session.
		</para>
		<note>
Most of the discussion below describes the old behaviour on bringing down a persistent service.
		</note>
	</listitem>
</itemizedlist>
<para>
You should understand the consequences of using persistence if you plan to use it in production.
The ideal approach from a theoretical point of view is to rewrite the application
so that data is propagated to all realservers immediately (or at least before the
client initiates a new SSL session), 
allowing the LVS to run in non-persistent mode.
Rewriting your application is difficult,
but if you're in production with a secure (SSL) site,
you're already spending money.
Despite us using every opportunity to exhort people to rewrite their applications,
we find that most people don't and continue to use persistence. 
</para>
<para>
Alternatives to persistence include
</para>
<itemizedlist>
	<listitem>
	ftp - move the ftp server out of the LVS -
	<link linkend="ftp_secure">ftp is difficult to secure</link>
	</listitem>
	<listitem>
squids - use the <link linkend="DH">dh scheduler</link>,
which is designed for squids and which was developed to overcome
the deficiencies of using persistence for squids.
See Note in the DH section: Jezz Palmer
found that he got better performance for squids with persistence.
	</listitem>
	<listitem>
	using persistent <xref linkend="LVS-HOWTO.fwmark"/> to forward
multiport services as found in an e-commerce site (<emphasis>i.e.</emphasis> 80, 443).
	</listitem>
	<listitem>
<xref linkend="L7_ratz"/> in an L4 friendly manner
(<emphasis>i.e.</emphasis> to save state on the realserver).
	</listitem>
</itemizedlist>
	<section id="lvs_persistence">
	<title>LVS persistence</title>
	<para>
LVS persistence makes a client connect to the same realserver for
<emphasis>different</emphasis> tcpip connections.
The LVS persistant connection is at the layer 4 protocol level.
	</para>
	<para>
LVS persistence is rarely needed and has some pitfalls (as explained below).
It's useful when state must be maintained on the realserver,
<emphasis>e.g.</emphasis> for https key exchanges,
where the session keys are held on the realserver
and the client must always reconnect with that realserver to maintain the session.
	</para>
	<para>
LVS persistence has two consequences
	</para>
	<itemizedlist>
		<listitem>
		<para>
A client making a new tcpip connection, within the timeout period (usually 5-10mins),
will be sent to the same realserver as on the previous connection.
The new tcp connection will reset the timer.
A connect request made past the timeout period will be treated
as a new connection and will be assigned a realserver by the scheduler.
The default timeout varies with LVS release,
but is in the 300-600sec range.
		</para>
		<para>
When implementing LVS persistence,
there are problems in recognising a client
as the same client returning for another connection.
While the application can recognise a returning client by
state information <emphasis>e.g.</emphasis> cookies
(which we don't encourage, see below for better suggestions),
at layer 4, where LVS operates, only the IPs and port numbers are available.
If it's left to the application to recognise the client
(<emphasis>e.g.</emphasis> by a cookie), it may be too late, the client
may be on the wrong realserver and the ssl connection is refused.
For LVS persistence, the client is recognised by its IP (CIP) or
in recent versions of ip_vs, by CIP:dst_port
(<emphasis>i.e.</emphasis> by the CIP and the port being forwarded by the LVS).
If only the CIP is used to schedule persistence, then the entries
in the output of <command>ipvsadm</command> will be of the form VIP:0
(<emphasis>i.e.</emphasis> with port=0),
otherwise the output of <command>ipvsadm</command> will be of the form VIP:port.
		</para>
		<para>
Recognising the client is simple enough for machines on static IPs,
but people on dial-up links
		</para>
		<itemizedlist>
			<listitem>
come up on a different IP for each dial-up session.
If the phone line drops during a session
the client will reappear with a different IP
(but probably coming from the same class C network)
			</listitem>
			<listitem>
if they are coming through a proxy (like AOL),
they will come from different IPs
(again probably in the same class C network)
for different tcipip connections,
within a single session
(<emphasis>i.e.</emphasis> requests for hits for a web page may come from several IPs).
(for more info see <link linkend="persistence_granularity">persistence granularity</link>).
			</listitem>
		</itemizedlist>
		<para>
The solution to this is to set a netmask (<emphasis>e.g.</emphasis> /24) for persistence and
to accept any IPs in this netmask as the same client.
The downside is that if a significant fraction of your clients are from AOL,
they will appear to be a single client
and will all be beating on one realserver,
while the other realservers are near idle.
		</para>
		<para>
			<note>
For regular http, you don't care how many different
IP(s) the client uses to request its hits for a single webpage
and you don't need persistence.
			</note>
		</para>
		</listitem>
		<listitem>
		<para>
When all ports (VIP:0) are scheduled to be persistent, then
requests by a client for services on different ports
(<emphasis>e.g.</emphasis> to VIP:telnet, to VIP:http)
will go to the same realserver.
This is useful when the client needs access to multiple ports
to complete a session.
Useful multi-port connections are
		</para>
		<itemizedlist>
			<listitem>
			20,21 for active ftp
			</listitem>
			<listitem>
			21 and a high port for passive ftp
			</listitem>
			<listitem>
			port 80,443 for an e-commerce site
			</listitem>
		</itemizedlist>
		<para>
A side effect is that once persistence is set for all ports,
requests by the client to any port,
not just the ones you think the client is interested in,
will be forwarded to the realserver.
(The client will get a "connection refused" if the realserver
is not listening on the other forwarded ports.)
For security (to stop port scans etc),
you'll have to filter requests to the other ports.
		</para>
		<para>
The ports won't neccessarily be paired in the way you want
<emphasis>e.g.</emphasis> in the (admittedly unlikely) event that you
have an ftp and e-commerce setup on the same LVS, both
ftp and e-commerce requests will go to the same realserver.
What you'd like is for the e-commerce (80,443) requests to
be scheduled independantly of the ftp (20,21) requests.
In this way your ftp requests will go to one realserver while
your requests to the e-commerce site will go to a
different realserver.
Its simpler administratively
to have different services (ftp, http/https) on a different lvs.
		</para>
		<para>
The all ports (VIP:0) approach is quite crude, and was
a first attempt at bundling together connect requests
for multiple services from a client.
This side effect (of persistence activating all ports),
does not arise if multiport services are forwarded by
a persistent fwmark.
To bundle services see
<ulink url="LVS-HOWTO.fwmark.html">
fwmark </ulink> (http://www.austintek.com/LVS/LVS-HOWTO/HOWTO/LVS-HOWTO.fwmark.html)
- in particular
<ulink url="LVS-HOWTO.fwmark.html#fwmark_persistence_granularity">
persistence granularity with fwmark </ulink>
(http://www.austintek.com/LVS/LVS-HOWTO/HOWTO/LVS-HOWTO.fwmark.html#fwmark_persistence_granularity).
		</para>
		</listitem>
	</itemizedlist>
	<para>
Note: the persistence timeout is the elapsed time,
between different tcpip connections,
for the client to be recognised as a returning client.
You still have the same <link linkend="tcpip_idle_timeout">idle timeout</link>
within a tcpip connection as for other services.
	</para>
	<para>
Wensong Zhang <emphasis>wensong (at) gnuchina (dot) org</emphasis> 11 Jan 2001
	</para>
	<blockquote>
The working principle of persistence in LVS is as follows:
		<itemizedlist>
			<listitem>
	a persistent template is used to keep the persistence
        between the client and the server.
			</listitem>
			<listitem>
	when the first connection from a client, the LVS box
	will select a server according to the scheduling algorithm,
	then create a persistent template and the connection entry.
	the control of the connection entry is the template.
			</listitem>
			<listitem>
	The late connections from the clients will be forwarded
	to the same server, as long as the template doesn't expire.
	The control of their connection entries are the template.
			</listitem>
			<listitem>
	If the template has its controlled connections, it won't
	expire.
			</listitem>
			<listitem>
	If the template has no controlled connections, it expires
	in its own time.
			</listitem>
		</itemizedlist>
	</blockquote>
	<para>
malcolm <emphasis>lists (at) netpbx (dot) org</emphasis>
	</para>
	<blockquote>
What the maximum setting for the persistence timeout?
The Docs say its unlimited but I don't believe that :-).
	</blockquote>
	<para>
Horms 25 Aug 2006 
	</para>
	<para>
ipvsadm may have some other limit due to signedness issues and the like.
But in the kernel it is stored as an unsigned int, which represents
seconds. So any value between 0 and (2^32)-1 seconds is valid, which 
is potentially a rather long time.
	</para>
	</section>
	<section id="persistent_scheduling">
	<title>Scheduling looks different under persistence</title>
	<para>
In a normal (non-persistent) LVS, if you connect to VIP:telnet with rr scheduling,
you will connect to each realserver in turn.
This is because the director is scheduling each tcpip connection as separate items.
When you logout of your telnet session and telnet to the VIP again,
the director sees a new tcpip connection and schedules it round robin
style <emphasis>i.e.</emphasis> to the next realserver in the <command>ipvsadm</command> table.
	</para>
	<para>
However, if you then make the LVS persistent,
the director schedules each CIP as a separate item.
Repeated telnet tcpip connections (logins and logouts)
to the VIP (within the persistence timeout period)
will be regarded as the same scheduling item,
since they are coming from the same client,
and will all be sent to the same realserver.
Even though rr scheduling is in effect,
you will be connected to the same realserver.
To test that the scheduler is round-robin'ing under persistence,
you will need to login from several different clients
(<emphasis>i.e.</emphasis> with different IPs), or
after the persistence timeout has expired.
	</para>
	<para>
If two services are scheduled as persistent (here telnet, http), they
are scheduled independantly. Here I have only 1 client (so it
isn't a good test) and I connect twice by telnet and then twice
by http.
Scheduling is within the blocks setup by the `<command>ipvsadm</command> -A` command (here starting
at "TCP ...".
Here there are two blocks, scheduled separately.
	</para>
<programlisting><![CDATA[
ipvsadm
IP Virtual Server version 0.9.4 (size=4096)
Prot LocalAddress:Port Scheduler Flags
  -> RemoteAddress:Port           Forward Weight ActiveConn InActConn
TCP  lvs.mack.net:http rr persistent 360
  -> RS2.mack.net:http            Route   1      0          2
  -> RS1.mack.net:http            Route   1      0          0
TCP  lvs.mack.net:telnet rr persistent 360
  -> RS2.mack.net:telnet          Route   1      0          2
  -> RS1.mack.net:telnet          Route   1      0          0
]]></programlisting>
	<para>
Doing the same test a bit later, I found all connections going to the other realserver.
	</para>
	<blockquote>
		<blockquote>
Will the timeout variable set on persistent connection 
affect an open socket that's open for several days streaming data?
		</blockquote> 
		<para>
Horms 2005/02/22
		</para>
		<para>
No. The persistance timeout has no effect whatsoever on the timeout
of open connections. They have their own timeouts which are generally
in line with those of TCP.
		</para>
		<blockquote>
Will another connection from the 
same client go to a different realserver while there's an open 
socket with streaming data?
		</blockquote>
		<para>
Not if you use persistance. If you use persistance, and either there is
a connection open, or the persistance timeout has not elapsed since the
last connection was closed, then a subsequent connection from the same
end-user will go to the same real-server.
		</para>
		<para>
For those who care, this is all controlled by the expiry of
connection entries and persistace templates by <filename>ip_vs_conn_expire()</filename>.
		</para>
	</blockquote>
	</section>
	<section id="persistent_and_non_persistent">
	<title>Persistent and regular (non-persistent) services together on the same realserver.</title>
	<para>
If you setup both a non-persistent service (for testing, say telnet)
and persistence on the same VIP, then all services will be
persistent <emphasis>except</emphasis> telnet, which will be scheduled
independantly of the persistent services. In this case
connections to VIP:telnet would be scheduled by rr (or whatever)
and you would connect with all realservers in rotation, while
connections to VIP:http will go to the same realserver.
	</para>
	<para>
Example:
If you setup a 2 realserver LVS-DR LVS with persistence,
	</para>
<programlisting><![CDATA[
director:/etc/lvs# ipvsadm -A -t VIP -p 360 -s -rr
director:/etc/lvs# ipvsadm -a -t VIP -R rs1 -g -w 1
director:/etc/lvs# ipvsadm -a -t VIP -R rs2 -g -w 1
]]></programlisting>
	<para>
giving the <command>ipvsadm</command> output
	</para>
<programlisting><![CDATA[
director:/etc/lvs# ipvsadm
IP Virtual Server version 0.2.5 (size=4096)
Prot LocalAddress:Port Scheduler Flags
  -> RemoteAddress:Port          Forward Weight ActiveConn InActConn
TCP  lvs2.mack.net:0 rr persistent 360
  -> RS2.mack.net:0              Route   1      0          0
  -> RS1.mack.net:0              Route   1      0          0
]]></programlisting>
	<para>
then (as expected) a client can connect to any service on the
realservers (always getting the same realserver).
	</para>
	<para>
If you now add an entry for telnet to both realservers,
(you can run these next instructions before or after the
3 lines immediately above)
	</para>
<programlisting><![CDATA[
director:/etc/lvs# ipvsadm -A -t VIP:telnet -s -rr
director:/etc/lvs# ipvsadm -a -t VIP:telnet -R rs1 -g -w 1
director:/etc/lvs# ipvsadm -a -t VIP:telnet -R rs2 -g -w 1
]]></programlisting>
	<para>
giving the <command>ipvsadm</command> output
	</para>
<programlisting><![CDATA[
director:/etc/lvs# ipvsadm
IP Virtual Server version 0.2.5 (size=4096)
Prot LocalAddress:Port Scheduler Flags
  -> RemoteAddress:Port          Forward Weight ActiveConn InActConn
TCP  lvs2.mack.net:0 rr persistent 360
  -> RS2.mack.net:0              Route   1      0          0
  -> RS1.mack.net:0              Route   1      0          0
TCP  lvs2.mack.net:telnet rr
  -> RS2.mack.net:telnet         Route   1      0          0
  -> RS1.mack.net:telnet         Route   1      0          0
]]></programlisting>
	<para>
the client will telnet to both realservers in turn as
would be expected for an LVS serving only telnet, but
all other services (ie !telnet) go to the same first
realserver. All services but telnet are persistent.
	</para>
	<para>
The director will make persistent all ports except those
that are explicitely set as non-persistent. These two
sets of <command>ipvsadm</command> commands do not overwrite each other.
Persistent and non-persistent connections can be made
at the same time.
	</para>
	<para>
Julian
	</para>
	<blockquote>
This is part of the LVS design. The templates used for
persistence are not inspected when scheduling packets
for non-persistent connections.
	</blockquote>
	<para>
Examples:
	</para>
	<itemizedlist>
		<listitem>
ftp (LVS-NAT): connections to both ftp ports
for passive ftp is handled by the module ip_masq_ftp.
You don't need to add persistence for ftp with LVS-NAT.
		</listitem>
		<listitem>
ftp (LVS-DR or LVS-Tun): you need persistence on the
realservers. Run the first set of commands above.
		</listitem>
		<listitem>
ftp and http (LVS-NAT): persistence not needed (ip_masq_ftp
handles the ftp ports for active and passive ftp).
		</listitem>
		<listitem>
ftp and http (LVS-DR or LVS-Tun): persistence needed
to handle the two port protocol ftp.
If you just have one entry in the <command>ipvsadm</command> table
(persistence to VIP:0)
then a client connecting to the http service of the LVS will always
get the same realserver (this may not be a great problem). 
If you want to make the http service non-persistent
but leaving all other services persistent,
then run then add a non-persistent entry for http.
		</listitem>
		<listitem>
http and https (all forwarding methods): Normally an
https connection is made after the client has made
selections on an http connection when data is stored
on the realserver for the client. In this case the
realserver should be made persistent for all services.
		</listitem>
	</itemizedlist>
	<para>
Note: making realserver connections persistent allows
_all_ ports to be forwarded by the LVS to the realservers.
An open, persistently connected realserver then is a
security hazard. You should have filter rules on the
director to block all services on the VIP
except those you want forwarded to the realservers.
	</para>
	</section>
	<section id="persistence_tracing">
	<title>Tracing connections: where will the client connect next?</title>
	<para>
You can trace your system in the following way. For example:
	</para>
<programlisting><![CDATA[
[root@kangaroo /root]# ipvsadm -ln
IP Virtual Server version 1.0.3 (size=4096)
Prot LocalAddress:Port Scheduler Flags
  -> RemoteAddress:Port          Forward Weight ActiveConn InActConn
TCP  172.26.20.118:80 wlc persistent 360
  -> 172.26.20.91:80             Route   1      0          0
  -> 172.26.20.90:80             Route   1      0          0
TCP  172.26.20.118:23 wlc persistent 360
  -> 172.26.20.90:23             Route   1      0          0
  -> 172.26.20.91:23             Route   1      0          0

[root@kangaroo /root]# ipchains -L -M -n
IP masquerading entries
prot expire   source               destination          ports
TCP  02:46.79 172.26.20.90         172.26.20.222        23 (23) -> 0
]]></programlisting>
	<para>
Although there is no connection, the template isn't expired.
So, new connections from the client 172.26.20.222
will be forwarded to the server 172.26.20.90.
	</para>
	<para>
For 2.4 kernels
	</para>
<programlisting><![CDATA[
director:/etc/lvs# ipvsadm -Lc
or
director:/etc/lvs# ipvsadm -Lcn
]]></programlisting>
	<para>
This shows the state of the connection (ESTABLISHED, FIN_WAIT) and the time
left till persistence timeout.
	</para>
	</section>
	<section id="bringing_down_persistent_services" xreflabel="bringing down persistent services">
	<title>Bringing down persistent services.</title>
		<note>
This is the behaviour before late 2004.
		</note>
		<section>
		<title>Clearing the table</title>
		<para>
If a client is connected (persistently) to a realserver and the
ipvsadm table is cleared (<command>ipvsadm -C</command>) then the connection will hang.
If you then reinstall the original <command>ipvsadm</command> rules for that service,
the connection will work again (and you'll see the correct entries
in ActiveConn and InActConn). Wensong (a bit below) explains why the
code doesn't clear the entry, but only removes the pointer to the entry.
		</para>
		<para>
Ratz
		</para>
		<para>
In new versions of ip_vs (look for it Sep 2002 or later)
you can affect the behaviour of ip_vs towards the connection when
the <command>ipvsadm</command> table is cleared with a <link linkend="sysctl">sysctl</link>.
Details are in
<ulink url="http://www.linux-vs.org/docs/sysctl.html">
the sysctl document http://www.linux-vs.org/docs/sysctl.html</ulink>.
<emphasis>e.g.</emphasis>
		</para>
		<itemizedlist>
			<listitem>
				<para>
			net.ipv4.vs.expire_nodest_conn=0
				</para>
				<para>
maintain entry in table
(but silently drop any packets sent), allowing service to continue
if the <command>ipvsadm</command> table entries are restored.
				</para>
			</listitem>
			<listitem>
				<para>
	net.ipv4.vs.expire_nodest_conn=1
				</para>
				<para>
expire the entry in table
immediately and inform client that connection is closed. This is the
expected behaviour by some people when running `<command>ipvsadm</command> -C`
				</para>
			</listitem>
		</itemizedlist>
		<para>
However if you have some client at the other end buying $1M of your
software with his credit card, you want to be nice to them.
The nice way of deleting a service is to set the weight to zero
(when no new connections will be allowed to that realserver)
and then wait for the current connections to
disconnect/expire before deleting them
(use some script to monitor the number of connections).
Since the client can stay connected
for hours (for some services) you can't predict when you'll
be able to bring your server down.
		</para>
		</section>
		<section id="time_to_clear_persistent_connections">
		<title>time to clear quiescent persistent connections</title>
		<para>
In a normal (non-persistent) tcp connection, after setting a service to weight=0,
the <command>ipvsadm</command> connection (hash) table will clear FIN_WAIT time 
(with Linux, about 2 mins)
after the last client disconnects.
With persistent connection, the connection table doesn't clear till the persistence timeout
(set with ipvsadm) time after the last client disconnects.
This time defaults to about 5mins but can be much longer.
Thus you cannot bring down a realserver offering a persistent service,
till the persistence timeout has expired - clients who have connected in
recently can still reconnect.
		</para>
		<para>
Tim Cronin wrote:
		</para>
		<blockquote>
			<para>
if you're using pasv you need persistence....
			</para>
<programlisting><![CDATA[
/sbin/ipvsadm -A -t 172.24.1.240:ftp -p
#forward ftp to realserver 192.168.1.20 using LVS-NAT (-m), with weight=1
/sbin/ipvsadm -a -t 172.24.1.240:ftp -r 192.168.1.20:ftp -m -w 1
]]></programlisting>
			<para>
if I change the weigh of the .20 RIP to 0 and rerun the script
my connections continue to go that server even when I zeroed and clear
the table.
			</para>
		</blockquote>
		<para>
Julian 1 Nov 2002
		</para>
		<para>
	Because the virtual service is marked persistent. In such case
RSs with weight 0 can continue to accept _new_ conns.
		</para>
		</section>
		<section id="resetting_timeout">
		<title>Resetting timeout</title>
		<para>
The persistence timeout is not reset to the original timeout on each
new tcpip connection, it is incremented by TIME_WAIT.
		</para>
		<para>
unknown (possibly Julian)
		</para>
		<para>
Yes, as implemented, the persistence timeout guarantees
affinity starting from the first connection. 
It lasts _after_ the last connection from this "session" is terminated. 
There is still no option to say "persistence time starts for each connection",
it could be useful.
		</para>
		<para>
Terry Green, 7 Feb 2003
		</para>
		<blockquote>
Agree completely - however, I expected the template record to be reset
to the session persistence time, not to the value of IP_VS_S_TIME_WAIT
		</blockquote>
		<para>
Julian Anastasov 2003-02-08 2:21:35
		</para>
		<para>
        The persistence timeout is used only once: when the
first connection from this client is established. The current
meaning is the persistent time to cover period of time after
the client appears for first time. It is extended if there are
still active connections. Then there are 3 (or more) options:
		</para>
		<itemizedlist>
			<listitem>
extend it again with the persistent time 
			</listitem>
			<listitem>
extend it with 2mins
			</listitem>
			<listitem>
use the persistence time after the last connection from client
terminates
			</listitem>
		</itemizedlist>
		<para>
The second option is implemented, as it was expected from
other users :)
		</para>
		<para>
A long time ago my opinion was that it is good the persistent
time to be used when the last connection terminates (3 above).
This can be a config option, if someone wants to implement it.
		</para>
		<para>
unknown (Julian?)
		</para>
		<para>
Maybe you see it 20 seconds after the 2-minute cycle
is restarted. It is "reset" only when its timer expires, not when
the controlled connections expire.
		</para>
		<para>
Terry
		</para>
		<blockquote>
Nope - perhaps I wasn't clear... I was watching <command>ipvsadm -Lc</command>
every second.
I did the tests originally and saw the template record being reset to 2
minutes if it expired with an active connection (even though the
persistence setting for the connection was NOT 2 minutes).   Then I did
another connect from the client, and the template record was reset again
to 2 minutes (not the persistence setting again), suggesting the
template record data structure had somehow had it's persistence time
reset from the original setting to 2 minutes.
		</blockquote>
		<para>
Julian
		</para>
		<para>
        Well, then it is not set to 1:40 but to 2:00 as expected.
		</para>
		<para>
Terry
		</para>
		<blockquote>
Then, to prove to myself that my reading of the source was accurate, I
hacked the source to make IP_VS_TIME_WAIT 2*50*HZ instead of 2*60*HZ,
and with the newly compiled kernel, the template record started being
reset to 100 seconds when it expired with an active connection.
		</blockquote>
		<para>
Julian
		</para>
		<para>
True, your reading is accurate :) I now see why it was 1:40
		</para>
		<para>
Terry
		</para>
		<blockquote>
My expectation would have been that the template record's timer would
get reset to the session persistence value rather than to IP_VS_TIME_WAIT.
		</blockquote>
		<para>
Julian
		</para>
		<para>
You can do it in your source tree or to implement it for other
users as config option. I don't know what the other people think.
		</para>
		<para>
Ratz and another poster on 12 Aug 2004 like resetting the timeout
to the persistence value.
		</para>
		</section>
		<section id="persistence_independant_of_scheduler">
		<title>Persistence is independant of scheduler</title>
		<para>
The scheduler determines which realserver gets the next connection.
With persistence, the same realserver gets the next connection.
		</para>
		<para>
Horms 13 Sep 2004 
		</para>
		<para>
Persistance opperates independant of the scheduler.
It does not matter if you use the RR, WLC, DH or any
other type of scheduler, it always works the same way.
That is, it looks up a persistance template and if it
finds one, then it uses it, else it asks the scheduler what to do.
		</para>
		<para>
In other words, if there was a connection from a given end-user,
and the persistance timeout has not expired, subsequent connections
from the same end-user (masked with the persistance netmask) will
go to the same realserver. As this lookup occurs _before_ a
call to the scheduler, it is not affected by quirks in any scheduler.
		</para>
		<para>
Brett
		</para>
		<blockquote>
I have an LVS director that uses wrr with 3600 of
persistence for two realservers. I noticed that
connections going through a firewall from my internal
network tend to get locked into one of my realservers
but usually doesn't go to the other realserver unless
all of the connections have expired to the first realserver.
		</blockquote>
		<para>
Ratz 10 Aug 2004
		</para>
		<para>
Correct.
		</para>
		<blockquote>
From what I understood with LVS is it's support to use
the source IP for persistence but I wasn't sure if it
also used a source port. 
		</blockquote>
		<para>
No, it doesn't. The persistent template is created as follows:
		</para>
<programlisting><![CDATA[
{proto,} caddr, 0, vaddr, vport, daddr, dport>
]]></programlisting>
		<para>
As you can see, the cport is set to 0 globally.
		</para>
		<para>
Horms
		</para>
		<para>
The source IP address is used, but the source port is not.
This is because successive connections from the same host will
almost certainly have a different ephemereal source port.
There is no parameter in LVS to change this behaviour.
Though off the top of my head it would seem like a simple
hack to alter this if you needed to for some reason.
		</para>
		<blockquote>
Would using a different scheduler or a kernel upgrade
(with a new lvs version) work around this?
		</blockquote>
		<para>
Horms
		</para>
		<para>
Not likely.
		</para>
		<para>
Ratz
		</para>
		<para>
You would need to tweak 
<filename>../net/ipv4/ipvs/ip_vs_core.c:ip_vs_sched_persist()</filename>.
		</para>
		</section>
	</section>
	<section id="new_persistence">
	<title>Forcing a break in a persistent connection: expire_quiescent_template - Horms sysctl for quiescing persistent connections</title>
	<para>
Horms <emphasis>horms (at) verge (dot) net (dot) au</emphasis> 12 Apr 2004
	</para>
	<para>
<ulink url="http://marc.theaimsgroup.com/?l=linux-virtual-server&amp;m=107752118509922&amp;w=2">
Expire Quiescent Template</ulink>.
Here's the writeup.
	</para>
	<blockquote>
		<para>
This patch adds a proc entry to tell LVS to expire persistance templates
for quiescent server. As per the documentation patch below:
		</para>
		<para>
expire_quiescent_template - BOOLEAN
		</para>

<programlisting><![CDATA[
0 - disabled (default)
not 0 - enabled

When set to a non-zero value, the load balancer will expire
persistant templates when the destination server is quiescent. This
may be useful, when a user makes a destination server quiescent by
setting its weight to 0 and it is desired that subsequent otherwise
persistant connections are sent to a different destination server.
By default new persistant connections are allowed to quiescent
destination servers.

If this feature is enabled, the load balancer will expire the
persistance template if it is to be used to schedule a
new connection and the destination server is quiescent.
]]></programlisting>
	</blockquote>
	<para>
This patch was written to allow loadbalancing of https, with failover. 
However it can be used to force a break of a persistent connection. 
With persistent connection and the weight of a realserver set to 0, 
any new connections will go to other realservers, 
but existing connections will stay till they timeout or the client
disconnects an active session (whichever is longest).
Experience on the mailing list shows that this could be a long time.
Misconfigured clients stay connected forever.
This patch forces the client's connection to break. 
The client probably will not be happy about this, 
but then you may not want to wait 24hrs to do maintenance either.
	</para>
	<para>
Graeme Fowler <emphasis>graeme (at) graemef (dot) net</emphasis> 19 Jul 2007 
	</para>
	<para>
<filename>/proc/sys/net/ipv4/vs/expire_quiescent_template</filename>
ensures that when a realserver's
weight is changed to 0 (ie. it is set to "quiescent"), rather than
removed from the pool of realservers, existing persistent sessions on
that realserver are expired from the persistence template.
	</para>
	<para>
Where you have persistence set on a virtual service, setting the weight
to 0 usually results in no new sessions being forwarded to that
realserver *but* existing sessions will continue to be handled until
they are closed. It's the "graceful" way of taking a server down for
maintenance, for example.
If you remove a realserver from the pool, with expire_quiescent_template
set to 1, those sessions expire immediately.
	</para>
	<para>
Additionally, setting <filename>expire_nodest_conn=1</filename> also helps by removing
persistent entries when a realserver is removed from the pool. Without
this, persistent entries will hang until they timeout and get redirected
to another realserver.
	</para>
	<blockquote>
are their any problems caused by setting both <filename>expire_nodest_conn</filename> and 
<filename>expire_quiescent_template</filename>?
	</blockquote>
	<para>
None that I can think of directly; however if a healthcheck fails
because something goes awry (local intervening network conditions,
transient load on director, something like that) then a realserver could
well be quiescent or removed briefly - in which case all established
persistent sessions will be terminated. This may not be desirable in the
case of a condition which is resolved in a few seconds.
	</para>
	<para>
I guess careful tuning of healthchecks along with good network design
would be the way to not trigger it, but that's outside the scope of this
discussion :)
	</para>
	<para>
Kit Gerrits <emphasis>kitgerrits (at) gmail (dot) com</emphasis> 18 Dec 2008
	</para>
	<para>
I am setting up a LVS-NAT cluster for a bunch of webservers.
I am using persistence with the expire_nodest_conn setting in my sysctl.conf
If I open a connection to the webserver VIP and then kill the webserver that
served me (trac-test2),
I would expect to get served by its brother (trac-test1).
Instead, I get the following:
	</para>
<programlisting><![CDATA[
Firefox can't establish a connection to the server at 10.100.77.250. (that's
the VIP)
]]></programlisting>
	<para>
Even by hand I am getting nowhere:
	</para>
<programlisting><![CDATA[
H:\>telnet 10.100.77.250 80
Connecting To 10.100.77.250...Could not open connection to the host, on port 80:
 Connect failed

/var/log/messages reports:
Dec 18 16:56:12 lvs-test1 nanny[5261]: shutting down 192.168.201.22:80 due to connection failure
]]></programlisting>
	<note>Joe: he's using nanny</note>
<programlisting><![CDATA[

[@lvs-test1 ~]$ sudo /sbin/ipvsadm
IP Virtual Server version 1.2.1 (size=4096)
Prot LocalAddress:Port Scheduler Flags
  -> RemoteAddress:Port           Forward Weight ActiveConn InActConn
TCP  trac-test-pub.rdc.local:http wlc persistent 300
  -> trac-test2.rdc.local:http    Masq    0      0          1
  -> trac-test1.rdc.local:http    Masq    500    0          0
]]></programlisting>
	<para>
Graeme Fowler <emphasis>graeme (at) graemef (dot) net</emphasis> 18 Dec 2008
	</para>
	<para>
Yep. That's a quiescent server, not a "nodest_conn" - the latter meaning
a connection destined for a server no longer in the pool.
You need to set the "expire_quiescent_template" sysctl to 1 instead.
	</para>
	<para>
Nicola Pero <emphasis>nicola (at) brainstorm (dot) co (dot) uk</emphasis> 25 Nov 2004 
	</para>
	<blockquote>
		<para>
Has anyone been able to setup ldirectord to load balance two HTTPS servers
with failover ?
		</para>
		<para>
The two real HTTPS servers are stateless (except for the SSL info in the
web servers); there are few concurrent users (up to 10), but instant
switchover in case of failure is essential.
		</para>
		<para>
Anyway, the problem we have is that when one of the two HTTPS servers goes
down, the load balancer detects it but all clients connected to the server
which is down keep being sent to it.  Changing 'persistent', 'quiescent',
timeouts etc didn't seem to have any effect on this!
		</para>
		<para>
Our case is also complicated by the fact that in certain cases we might
decide that a realserver should not be used even if HTTPS is still
running fine on the server.  That might happen if the application sitting
behind the HTTPS has a problem.  We've got a URL on the realserver which
can be checked to know if the realserver is OK to be used or not.  
Checking those seems to be working fine!  The problem is with the
realserver being marked as down, and all requests still being sent to it!
		</para>
		<para>
Keep in mind this is not a typical web farm, there are few concurrent
users (most often 0 or 1), but it's critical that the web application is
always available.
		</para>
	</blockquote>
	<para>
Malcolm Turnbull Nov 25, 2004 
	</para>
	<para>
you definately want quiescent=no (in ldirectord).
	</para>
	<para>
Horms 26 Nov 2004
	</para>
	<para>
Or use this patch.
http://www.in-addr.de/pipermail/lvs-users/2004-February/011018.html
	</para>
	<para>
The patch just makes persistent sessions behave sensibly(tm) when
a realserver is made quiescent. 
This isn't specific to HTTPS at all, 
but I think it is the problem that the user is seeing. 
The other solution is not to make the realservers quiescent, 
and just removed them instead.
	</para>
	<para>
<ulink url="http://www.in-addr.de/pipermail/lvs-users/2004-February/011018.html">
2.4 patch</ulink>
(http://www.in-addr.de/pipermail/lvs-users/2004-February/011018.html),
<ulink url="http://article.gmane.org/gmane.linux.network/18906">2.6 patch</ulink>
(http://article.gmane.org/gmane.linux.network/18906).
	</para>
	<para>
The Existing behaviour.
	</para>
	<para>
When a realserver is marked as quiescent (by setting the weight to zero)
no additional connections will be allocated to that realserver
by the scheduler (the LVS connection allocator, not the cpu scheduler,
the packet scheduler, or your secretary).
	</para>
	<para>
This works quite well, unless the scheduler is bypassed for some reason.
As it happens this occurs only if a virtual service is marked
as persistant and there is a persistant-template in existance - that
is, recently there was prior connection from the same end-user.
	</para>
	<para>
In this case the presance of the persistant-template is sufficient
for additional connections to be sheduled, despite the fact that the
server is marked as quiescent. Though the connections have
to be from an end-user (IP address/netmask) that was forwarded
to the realserver in question within the persistant timeout.
	</para>
	<para>
My patch allows this behaviour to be changed, by expiring the templates
when a real-server is marked as quiescent. Thus the scheduler gets
called, and the behaviour is the same as for non-persistant service,
which is generally what people expect/want.
	</para>
	<para>
Joe
	</para>
	<blockquote>
and just rip out the connections?
	</blockquote>
	<para>
By removing a realserver you break all the connections and
remove all the persitant templates. So no further connections
are forwared whatsoever. Actually, no further packets are forwarded.
Unfortunatelly, this breaks connections that are in progress.
	</para>
	<blockquote>
		<para>
So what happens in the following case:
		</para>
		<para> 
You've filled your shopping cart under http, then you go to
https to give your credit card info, which usually takes
at least 3 webpages (fill in your credit card and shipping info, 
click send, get confirmation page, click accept, get final
page for printing). Let's say while you're
reviewing the confirmation page, the realserver goes down and the
LVS removes it by running ipvsadm. The tcpip state of the
client is ESTABLISHED and the client has the SSL session ID.
The LVS has to cache the credit card info somewhere to
make it available to the new realserver.
When the user hits the accept button, the browser presumably
is going to get a tcpip reset from the new realserver. Does
the browser just handle it and attempt to make a new 
tcpip connection? From what you say above, the browser will
find that its SSL session ID is invalid and it will do the 
long handshake. Once that happens the client will hopefully
be SSL connected to a realserver that knows about the credit
card transaction already underway.
		</para>
	</blockquote>
	<para>
In the situation you describe above the main factors in determining
if it would work or not are 
	</para>
	<itemizedlist>
		<listitem>
			<para>
how do the realservers store their data?
			</para>
			<para>
if some sort of shared storage is used, say for 
example NFS, and the transaction is not in some half broken state, then
it should be ok, though there might be a race in there
			</para>
		</listitem>
		<listitem>
			<para>
will the client's browser reconnect 
(either automatically or by the user hitting reload)?
			</para>
			<para>
the answer is generally yes. 
			</para>
		</listitem>
	</itemizedlist>
	<para>
What I am trying to say is it really boils down to an interaction
between the end-user's browser and the real-servers web-application.
The LVS magic in between neither hinders nor helps the situation, 
other than allowing the end-user to connect to a different-realserver
if/when a reload occurs.
	</para>
	<para>
And the SessionID shouldn't really come into it. Because if it
is still valid, it will be used, and if it is invalid it will be
discarded and a full handshake will be performed. Sure, it might take
an extra few moments, and possible the real-server might be a bit
overloaded if a lot of reconnects of this nature occur simultaneously,
but the success (or failure) of the SSL handshake should not be
affected.
	</para>
	<blockquote>
I had thought that the keys are in memory 
and you can't move the keys/session data from one machine to another. 
	</blockquote>
	<para>
That is not the case, let me elaborate.
(I wrote an SSL implementation once so I know this one :)
	</para>
	<para>
SSL makes use of public key encryption (<emphasis>e.g.</emphasis> RSA) and 
private key encryption (<emphasis>e.g.</emphasis> DES, AES) as well as a host
of other techniques to make communications more secure.
In a nutshell public key encryption - which is slow but
does not require any prior agreement of keys - is used
to negotiate a key that is used for private key encryption -
which is fast, but requires a key to be negotiated. 
This key negotiation phase is part of the SSL handshake.
	</para>
	<para>
It turns out, 
particularly for small transfers as are typical on the web, 
that the public key encryption negotiation phase of the handshake
is quite expensive. 
To alleviate this the server may (almost always will)
give the client a Session ID during the course of the handshake. i
If the client reconnects it _may_ offer this Session ID and _if_ the server
recognises it then an abridged version of the handshake is performed
which relies on cryptographic information that both the client and 
server have cached.
	</para>
	<para>
Observe:
	</para>
	<itemizedlist>
		<listitem>
If the client does not offer a Session ID, 
the long handshake is performed.
		</listitem>
		<listitem>
If the server does not recognise the Session ID - 
perhaps because it has expired, 
perhaps because it is a different machine,
perhaps because the Session ID is bogus - 
the long handshake is performed.
		</listitem>
		<listitem>
Also, if the client tries to guess a Session ID and guesses
one that the server knows about, 
unless the cached key information it holds matches, 
the handshake will fail and the session will terminate. 
Guessing the cryptographic information is usually difficult at best, 
though it depends what cipher suite 
(combination of cryptographic algorithms) 
was used for the original session. 
Thus, DoS issues aside, guessing Session IDs is typically of little value.
It is the second point above that allows failover of SSL servers to work.
The server is actually allowed to cache the Session Id for as long as it
wants, including discarding it immediately. This is catered for by
falling back to the long handshake if the Session ID is not matched.
		</listitem>
	</itemizedlist>
	<para>
Stephane Klein 
	</para>
	<blockquote>
I have an LVS using persistence.
All is working well until I stop a real server.
The director continue to send requests to the real server which was stopped.
<command>ipvsadm -Lcn</command> confirms that the request 
is still sent to the stopped real server.
	</blockquote>
	<para>
Horms  2005/03/22
	</para>	
	<para>
The problem here is that persistance still takes effect even
after the real server is removed (I assume you have quiescent=1).
You can change this behaviour by running.
	</para>
<programlisting><![CDATA[
echo 1 > /proc/sys/net/ipv4/vs/expire_quiescent_template
]]></programlisting>
	<para>
The effect of this is that the persistance templates
are expired when a connection is made quiescent. And
thus no additional connections will be directed to
the real server in question.
	</para>
	<para>
Pitscheider, Oswald <emphasis>Oswald (dot) Pitscheider (at) siag (dot) it</emphasis> 5 Sep 2008
	</para>
	<para>
I have some trouble with a LVS on CentOS 5.1 with kernel 2.6.18-92.1.10.el5.
When both real servers are up, everything works fine, but when I shut down one of them, the LVS blocks for a few minutes.
After that time, the LVS seems to work well, but when I start the real server, every connection is routed to only one real
server.
My configuration includes:
	</para>
<programlisting><![CDATA[
virtual_server 10.150.50.187 80 {
    delay_loop 20
    lb_algo rr
    lb_kind NAT
    nat_mask 255.255.255.0
    protocol TCP
    real_server 10.150.54.10 80 {
        weight 1
        inhibit_on_failure
        TCP_CHECK {
           connect_timeout 3
           connect_port 80
        }
    }
    real_server 10.150.54.12 80 {
        weight 1
        inhibit_on_failure
        TCP_CHECK {
           connect_timeout 3
           connect_port 80
        }
    }
}

]]></programlisting>
	<para>
After restarting keepalived, everything works fine.
When I set weight to 0 before the server goes down, I have no problems.
	</para>
	<para>
Graeme
	</para>
	<para>
Your problem is being caused because you're quiescing the realserver
(ie. setting weight to 0 by using "inhibit on failure") instead of
removing it from the pool.
	</para>
	<para>
When the weight is 0, clients with connections which have not yet
reached a protocol timeout will reconnect to the same realserver to
continue the connection - this is very common, for example, for a
webserver with Keepalives turned on.
	</para>
	<para>
If you remove "inhibit on failure" your LVS will run as you expect, but
you may also need to set the sysctl:
	</para>
<programlisting><![CDATA[
net.ipv4.vs.expire_nodest_conn = 1
]]></programlisting>
	<para>
That ensures existing connections to realservers which have been removed
from the pool are expired immediately.
	</para>
	<para>
Oswald
	</para>
	<blockquote>
I've tried the LVS with this changes having a little succeed, 
but there is still the problem that if I remove a real server, 
requests to the server are responded very slowly.
From them moment, when the real server is removed from the pool, 
some requests have to wait seconds for an answer.
After a minute, the LVS works as it should.
I've tested the LVS using jmeter with 25 threats.
	</blockquote>
	<para>
Graeme
	</para>
	<para>
This is fairly predictable, from your configuration and from the way TCP
works.
	</para>
	<para>
Each realserver is checked every 20 seconds (delay_loop 20). If you stop
Apache just as the check is done successfully, requests will stall for
20 seconds until the next check (because the server isn't responding).
	</para>
	<para>
If a request arrives fractionally after the successful check, the server
isn't responding, then the client will retry at the following intervals:
	</para>
<programlisting><![CDATA[
 -0.002  RS1 Check succeeds
 -0.001  RS1 Apache stopped
  0.000  Request arrives at RS1
  3.000  retry 1 to RS1
  9.000  retry 2 to RS1
 19.998  RS1 Check fails
         keepalived removes RS1 from pool
 21.000  retry 3 sent to RS2
]]></programlisting>
	<para>
Note however that it may take a short period for keepalived to do the
server removal, which may overlap with retry 3 - and the next delay to
retry 4 is another 24 seconds (3, 6, 12, 24 and so on) which takes you
towards 45 seconds altogether.
	</para>
	<para>
And depending on the way jmeter is configured, alongside your webserver
config, this will mean a minimum of 20 seconds (and likely much longer)
delay between you dropping the webserver and the clients recovering.
	</para>
	<para>
It is perfectly permissible to bring down the delay_loop as much as you
or your app server can tolerate. For fast failover you need a short
delay. I would argue that for most web clients, 20 seconds is perfectly
acceptable but that can depend entirely on what you're trying to
achieve.
	</para>
	<para>
Try "delay_loop 1" and see what you get. What you will get, possibly,
are a lot of log entries - but you should get very fast recovery.
	</para>
	</section>
	<section id="realserver_crash_on_sticky_connection" xreflabel="realserver crash on sticky connection">
	<title>what if a realserver holding a persistent (sticky) connection crashes</title>
	<para>
An explanation of the problem:
	</para>
	<itemizedlist>
		<listitem>
			<para>
normal (non-persistent) connection to a service (<emphasis>e.g.</emphasis> httpd).
			</para>
			<para>
If the server crashes while your tcpip connection is open, that connection will hang
(it will eventually time out). The client will notice some icon showing that the
browser is continuing to look for the page.
The director will notice that the realserver has died and will remove the
realserver from the ipvs table by first setting its weight to 0.
This will stop any new connections, but allow current connections to continue
(and eventually exit). Since the current connections are hung,
the director will assume they have exited after the time of the tcp timeouts.
Once the connection table for that realserver is empty, the entries for
the realserver are removed from the ipvs table.
Eventually the browser will timeout
or the user will reload, this establishing a new tcpip connection, whereupon
the LVS will connect the user to a working realserver
(the dead one not being sent any new connections).
The connection with the original realserver was lost (or hung).
The persistence of the connection is the tcpip connection - any new
tcpip connection will be sent to a new realserver.
			</para>
			<para>
Clients are used to connections on the internet hanging and will not realise
that a realserver died on them.
The behaviour of ip_vs here gives a satisfactory behaviour as far as the
client is concerned.
			</para>
			<para>
				<note>
If the service was telnet, the client would have a hung session and would
have to close out their window and reconnect.[C
This is not satisfactory, but there's no way to transfer a
tcpip connection to a new machine.
				</note>
			</para>
		</listitem>
		<listitem>
			<para>
persistent connection to a service (<emphasis>e.g.</emphasis> https) with -p 600
(10 mins timeout).
			</para>
			<para>
Everything is the same as for the non-persistent connection, except the criteria
for terminating the user session.
			</para>
			<para>
If you have set a persistence timeout on the director of 10mins, then the
director is saying "no matter what happens, I will connect this client
to that realserver for all tcpip connection requests for the next 10mins
(even if the realserver is dead)".
The director is guaranteeing that the realserver will be up for the
next 10mins and the persistence extends beyond any single tcpip connection
to cover new tcpip connections in the timeout period.
If the director sets weight=0 for a realserver (<emphasis>e.g.</emphasis>
if it has crashed), then new tcpip connections from the client will
still be sent to the same (dead) realserver.
			</para>
			<para>
The behaviour of ipvs, which satisfactorily removes realservers when the
granularity is a tcpip connection, doesn't work when the LVS session
can cover many tcpip connections.
			</para>
		</listitem>
	</itemizedlist>
	<para>
Ben Hollingsworth 
	</para>
	<blockquote>
 OK, so I've got my setup nailed down pretty well.  This is pair of squid
 web proxies on a 2-host LVS running UltraMonkey / HB 2.0.7-8 on RHEL4
 (2.6.9).  I'm struggling with one more thing, though.  With
 quiescent=true, if I shut down squid on one box, connections from new
 hosts fail over to the other box just fine, but connections from
 persistent hosts keep going to the same, dead box.  I realize this is as
 intended.  If I set quiescent=false, all client communication with the
 dead box ceases immediately, which includes cutting off active
 connections at the knees.  That's not an issue if the squid actually
 dies.  However, most of our failovers will be due to my own planned
 maintenance.  In that case, I'd like to allow existing connections
 (which may be lengthy downloads) to finish before sending new requests
 (even from persistent clients) to the live box.  I can't find any way to
 do this without hacking the kernel to match a 2-yr-old patch that Horms
 published (assuming that even applies to my setup).  Most of the info
 about this seems to have been written three years ago.  Is there a way
 to make this work without a custom compile?
	</blockquote> 
	<para>
Adrian Chapela <emphasis>achapela (dot) rexistros (at) gmail (dot) com</emphasis> 12 Mar 2007
	</para>
	<para>
OK, to solve the problem there are two variables:
	</para>
	<itemizedlist>
		<listitem>
<filename>/proc/sys/net/ipv4/vs/expire_nodest_conn</filename>: 
to expire connections before the protocol timeout. This is to solve the problem
when a server goes down. For example in the UDP protocol the protocol timeout is too high.
		</listitem>
		<listitem>
<filename>/proc/sys/net/ipv4/vs/expire_quiescent_template</filename>: 
(see <xref linkend="new_persistence"/>) this variable I think is the variable to solve your problem. With this
you timeout your persistent template when a server goes down.
		</listitem>
	</itemizedlist>
	<para>
I don't know what them makes exactly but the first solve my problems. You could make a test.
	</para>
	<para>
Janusz Krzysztofik <emphasis>jkrzyszt (at) tis (dot) icnet (dot) pl</emphasis> 12 Mar 2007
	</para>
	<para>
I have one solution, but it works only in case of transparent proxy setup. 
Instead of persistance, use lblc scheduler (without persistance). lblc itself 
gives you some kind of persistance of 6 minutes or more. If 6 minutes is not 
enough for you, please look here: 
http://kb.linuxvirtualserver.org/wiki/Talk:Locality-Based_Least-Connection_Scheduling
	</para>
	<para>
-----------------------------------------------------------------
	</para>
	<para>
The material below is older,
from when the persistence code was at an earlier stage of development.
None of this code exists anymore.
	</para>
	<para>
Ted Pavlic <emphasis>tpavlic_list (at) netwalk (dot) com</emphasis>
	</para>
	<blockquote>
		<para>
Is this a bug or a feature of the PCC scheduling...
		</para><para>
A person connects to the virtual server, gets direct routed to a
machine. Before the time set to expire persistent connections,
that real machine dies. mon sees that the machine died, and
deletes the realserver entries until it comes back up.
		</para><para>
But now that same person tries to connect to the virtual server
again, and PCC *STILL* schedules them for the non-existent real
server that is currently down. Is that a feature? I mean -- I can
see how it would be good for small outages... so that a machine
could come back up really quick and keep serving its old
requests... YET... For long outages those particular people will
have no luck.
		</para>
	</blockquote>
	<para>
Wensong
	</para><para>
You can set the timeout of template masq entry into a small
number now and the connection will expire soon.
	</para><para>
Or, I will add some codes to let each realserver entry keep a
list of its template masq entries, remove those template masq
entries if the realserver entry is deleted.
	</para>
	<blockquote>
To me, this seems most sensible. Lowering the timeouts has other effects,
affecting general session persistence...
	</blockquote>
	<para>
I agree with this. This was what I was hoping for when I sent the
original message. I figure, if the server the person was
connecting to went down, any persistence wouldn't be that useful
when the server came back up. There might be temporary files in
existence on that server that don't exist on another server, but
otherwise... FTP or SSL or anything like that -- it might as well
be brought up anew on another server.
	</para><para>
Plus, any protocol that requires a persistent connection is
probably one that the user will access frequently during one
session. It makes more sense to bring that protocol up on another
server than waiting for the old server to come back up -- will be
more transparent to the user. (Even though they may have to
completely re-connect once)
	</para><para>
So, yes, deleting the entry when a realserver goes down sounds
like the best choice. I think you'll find most other load
balancers do something similar to this.
	</para>
	<para>
mike <emphasis>mike (at) bizittech (dot) com</emphasis> 28 Sep 2003
	</para>
	<blockquote>
		<para>
I am using LVS-DR to balance 4 MS servers.
Due to the nature of the web application
and the user behavior I had to set the connection timeout
to 30 min.
		<note>
	Joe: he does not specify whether he is using persistence
and this is the
persistence timeout from <xref linkend="persistent_setup"/>
or the <xref linkend="tcpip_idle_timeout"/>.
Presumably it is the persistence timeout.
		</note>
In case of  failure of one of the realservers users need to be
forced to connect to a different server.
That means the lvs tables need to cleared
as far as connections from clients to the failed box,
so that any reconnect trail will open new connection to one of functioning servers .
I am using ldirectord to startup and monitor.
		</para>
		<para>
I am using
ldirectord to poll the realserver for the result of an asp page.
In case of failure it turns the weight to 0 on the ipvs rule.
No new connections will be sent to the dead realserver but in every retry of
the clients still tries to connect to the dead realserver
until the timeout of that connection.
This is the expected behaviour according to lvs documentation.
		</para>
	</blockquote>
	<para>
Joao Clemente <emphasis>jpcl (at) rnl (dot) ist (dot) utl (dot) pt</emphasis>
	</para>
	<blockquote>
How do you delete the entry of the realserver?
	</blockquote>
	<para>
Mike
	</para>
	<blockquote>
		<para>
Basically I'm using a similar rule to the one used to insert the virtual
servers into lvs.
It's something like this (I can't be 100% exact as I don't have access to my
lvs box from home)
		</para>
<programlisting><![CDATA[
/sbin/ipvsadm -d -t $VIP:PORT -r $REALSERVER
]]></programlisting>
	</blockquote>
	<para>
Matthew Crocker <emphasis>matthew (at) crocker (dot) com</emphasis> 28 Sep 2003
	</para>
	<para>
Don't set the weight to 0, remove the realserver from the LVS table
when it fails.  When you remove the realserver from the table you also
remove the information from the persistence table.  Setting the weight
to 0 is normally used for orderly shutdown of a realserver for
maintenance.
	</para>
	<note>
Joe: the entries for the current connections to the realserver stay in the
ip_vs hash table until they timeout, even though they are no longer
displayed in the default output of <command>ipvsadm</command>.
These current connections can't be used with a dead realserver.
	</note>
	<para>
Peter Nash <emphasis>peter.nash (at) changeworks (dot) co (dot) uk</emphasis> 29 Sep 2003
	</para>
	<para>
I'm using LVS-NAT with persistence controlled by ldirectord.  I've found
that the "quiescent=" line in ldirectord.cf controls the behaviour you are
looking for.  If "quiescent=no" then when a realserver fails it's LVS
entries are removed from the table and clients immediately failover to an
alternate server.  If "quiescent=yes" then when a realserver fails it's
entries remain in the LVS tables but the weight is set to 0 and clients
will continue to try to connect to that server until the persistence
expires.  The default setting (on my installation) was "yes" and I had to
change this to get the behaviour I wanted.
	</para>
	<para>
Rommel, Florian <emphasis>Florian (dot) Rommel (at) quartal (dot) com</emphasis> 28 Sep 2003
	</para>
	<para>
in your <filename>ldirectord.cf</filename>,
add this line at the top (above your virtual section)
	</para>
<programlisting><![CDATA[
quiescent = no
]]></programlisting>
	<para>
it deletes the server entry from the table
automatically if the server fails.
Once the server is back up it'll add it automatically.
If that line is not set, the default is yes,
which just sets the server to weight 0 and that leaves the connections persistant.
I had to look for a while to find that little line.
	</para>
	<para>
Mike
	</para>
	<blockquote>
Thanks Florian Rommel and peter nash. That was it.
	</blockquote>
	<para>
<emphasis>vilsalio (atO eupmt (dot) es</emphasis>
	</para>
	<blockquote>
I don't know how I can remove the persistence when one of
my realservers crash, without waiting for expiration of the timeout.
	</blockquote>
	<para>
ratz 27 Nov 2003
	</para>
	<para>
Please refer to the <xref linkend="sysctl"/>.
<filename>/proc/sys/net/ipv4/vs/expire_nodest_conn</filename> should do what you want.
	</para>
	<para>
Patrick Kormann <emphasis>pkormann (at) datacomm (dot) ch</emphasis>
	</para>
	<blockquote>
 I have the following problem: I have a direct routed 'cluster' of  4
 proxies.  My problem is that even if the proxy is taken out of the list of real
 servers, the persistent connection is still active, that means, that proxy
 is still used.
	</blockquote>
	<para>
Andres Reiner
	</para>
	<blockquote>
	<para>
Now I found some strange behaviour using 'mon' for the
high-availability. If a server goes down it is correctly removed from
the routing table. BUT if a client did a request prior to the server's
failure, it will still be directed to the failed server afterwards. I
guess this got something to do with the persistent connection setting
(which is used for the cold fusion applications/session variables).
	</para><para>
In my understanding the LVS should, if a routing entry is deleted, no
longer direct clients to the failed server even if the persistent
connection setting is used.
	</para><para>
Is there some option I missed or is it a bug ?
	</para>
	</blockquote>
	<para>
Wensong Zhang wrote:
	</para>
	<para>
No, you didn't miss anything and it is not a bug either. :)
	</para>
	<para>
In the current design of LVS, the connection won't be drastically
removed but silently drop the packet once the destination of the
connection is down, because monitering software may marks the server
temporary down when the server is too busy or the monitering software
makes some errors. When the server is up, then the connection continues.
If server is not up for a while, then the client will timeout. One thing
is gauranteed that no new connections will be assigned to a server when
it is down. When the client reestablishs the connection (<emphasis>e.g.</emphasis> press
 reload/refresh in the browser), a new server will be assigned.
	</para>
	<para>
<emphasis>jacob (dot) rief (at) tis (dot) at</emphasis> wrote:
	</para>
	<blockquote>
Unfortunately I have the same problem as Andres (see below)
If I remove a realserver from a list of persistent
virtual servers, this connection never times out. Not even
after the specified timeout has been reached.
	</blockquote>
	<para>
Wensong
	</para><para>
The persistent template won't timeout until all its connections
timeout. After all the connections from the same client connection
expires, new connections can be assigned to one of the remaining
servers. You can use "ipchains -M -L -n" (or netstat -M) to check the connection
table (for 2.4.x use cat /proc/net/ip_conntrack).
	</para>
	<blockquote>
	<para>
Only if I unset persistency the connection 
will be redirected onto the remaining realservers. 
Now if I turn on persistency again, a prevoiusly
attached client does not reconnect anymore - it seems as
if LVS remembers such clients. It does not even help, if I delete
the whole virtual service and restore it immediately, in the
hope to clear the persistency tables.
	</para>
<programlisting><![CDATA[
director:/etc/lvs# ipvsadm -D -t <VIP>; ipvsadm -A -t <VIP> -p; ipvsadm -a -t <VIP> -R <alive realserver>
]]></programlisting>
	<para>
And it also does not help closing the browser and restarting it.
I run LVS in masquerading mode on a 2.2.13-kernel patched with ipvs-0.9.5.
Would'nt it be a nice feature to flush the persistent client
connection table, and/or list all such connections?
	</para>
	</blockquote>
	<para>
Wensong
	</para>
	<para>
There are several reasons that I didn't do it in the current code. One
is that it is time-consuming to search a big table (maybe one million
entries) to flush the connections destined for the dead server; the
other is that the template won't expire until its connection expire,
the client will be assigned to the same server as long as there is a
connection not expired. Anyway, I will think about better way to solve
this problem.
	</para>
	</section>
	<section id="time_constant">
	<title>Load Balancing time constant is longer with persistence</title>
	<para>
(This is from a thread on
<ulink url="http://marc.theaimsgroup.com/?l=linux-virtual-server&amp;m=103407779310426&amp;w=2">
'Preference' instead of 'persistence'</ulink> started by
Martijn Klingens on 2002-10-08.)
	</para><para>
Load balancing occurs with a time constant of the connection to the LVS.
For a non-persistent connection like http, with FIN_WAIT=2mins, loads will
balance on a time scale longer than 2mins.
At shorter time scales, the loads will not be balanced.
For persistence with a persistence time out of 30mins,
load balancing will require times greater than 30mins
(like several hours).
	</para><para>
This problem is related to the unbalance caused by <link linkend="proxy_farm">proxy farms</link>
(<emphasis>e.g.</emphasis> AOL).
	</para>
	</section>
	<section id="NONE">
	<title>The tcp NONE flag</title>
	<para>
Malcolm Turnbull <emphasis>malcolm (at) loadbalancer (dot) org</emphasis> 2005/04/26
	</para>
	<blockquote>
		<para>
What does the TCP flag NONE mean?
When I make a connection through LVS to a real server and look in the 
connection table I normally get
		</para>
<programlisting><![CDATA[
TCP 17:24 ESTABLISHED 173.19.13.214:1736 173.19.15.175:80 173.19.12.243:80 
]]></programlisting>
		<para>
And everything including persistence works as expected
But when I connect using a bit of javascript from IE(client side) I get :
		</para>
<programlisting><![CDATA[
TCP 17:24 NONE 173.19.13.214:0 173.19.15.175:80 173.19.12.243:80 
]]></programlisting>
	</blockquote>
	<para>
Francois JEANMOUGIN <emphasis>Francois (dot) JEANMOUGIN (at) 123multimedia (dot) com</emphasis> 
	</para>
	<para>
This is the way LVS is manages persitence, by creating a NONE connection in
the connection table.
	</para>
	<blockquote>
		<para>
And the first connection gets a 404 error, further refreshes work fine, 
and then persistence doesn't seem to work? 
Do connections with a status of NONE not get put is the persistence table? 
The javascript is refreshing a page from the server every 1 minute.
If you set the javascript to go every 10mins you get far more 404 errors.
		</para>
	</blockquote>
	<para>
This looks strange. Your persistence timeout seems to be about 20min 
(the time to timeout is just after the string "TCP"), 
so 1min or 10min should be the same. 
I would suspect a problem in the js itself.
Look at your server error_log.
	</para>
	<blockquote>
		<para>
This post (http://www.in-addr.de/pipermail/lvs-users/2005-February/013235.html)
sugested droping all TCP NONE packets as they weren't required.
		</para>
	</blockquote>
	<para>
Your servers do not receive NONE TCP connections, they are created
locally and are just here for perstence management purposes.
	</para>
	</section>
	<section id="green">
	<title>Resetting the persistence timeout counter (persistence behaviour for short timeout values)</title>
	<para>
Terry Green <emphasis>tgreen (at) mitra (dot) com</emphasis> 2003-02-06
	</para>
	<blockquote>
	<para>
the LVS-HOWTO states:
	</para>
	<blockquote>
With persistent connection, the connection table doesn't clear till the persistence
timeout (set with ipvsadm) time after the last client disconnects.
	</blockquote>
	<para>
This appears to be not quite true.
(In the following tests I'm using Kernel 2.4.19 with patch 1.0.7)
	</para>
	<para>
Testing/Observations
- using a port 80 definition with 5 minute persistence
(keepalived being used to do the configs).
	</para>
<programlisting><![CDATA[
# ipvsadm
  IP Virtual Server version 1.0.7 (size=16384)
  Prot LocalAddress:Port Scheduler Flags
     -> RemoteAddress:Port           Forward Weight ActiveConn InActConn
  TCP  devlivelink:http rr persistent 300
     -> devlivelink2:http            Route   1      0          0
     -> devlivelink1:http            Route   1      0          0
  TCP  devlivelink:https rr persistent 300
     -> devlivelink2:https           Route   1      0          0
     -> devlivelink1:https           Route   1      0          0
]]></programlisting>
	<para>
I start a connection to the web server for purposes of downloading a large file
(which will take more than 5 minutes).
Every time I connect from the client,
I see the connection template timeout reset to 5 minutes,
as you would expect from the persistence timeout value (300sec).
	</para>
<programlisting><![CDATA[
# ipvsadm -Lc
  TCP 04:59  NONE        greenblade.mitra.com:0 devlivelink:http devlivelink1:http
  TCP 00:03  FIN_WAIT    greenblade.mitra.com:51330 devlivelink:http devlivelink1:http
  TCP 00:02  FIN_WAIT    greenblade.mitra.com:51329 devlivelink:http devlivelink1:http
]]></programlisting>
	<note>
	<para>I've shortened the TCP timeouts for purposes of testing using IPVS
connection entries with <command>ipvsadm --set 5 4 0</command>
	</para>
	</note>
	<para>
However, if the template record is allowed to expire, it will be kept because
there's still an active connection, but it's time will be reset to IP_VS_S_TIME_WAIT
constant (defaulted to 2 minutes in <filename>ip_vs_conn.c</filename>)
rather than to the persistence time set for this session.
Further,
the data structure for the connection template appears to have been corrupted,
as any further connections from the client reset the
template time to 2 minutes,
instead of the original persistence time.
	</para>
	<para>
To verify this, I changed line 317 of ip_vs_conn.c from
	</para>
<programlisting><![CDATA[
# ipvsadm -Lc
        [IP_VS_S_TIME_WAIT]     =       2*60*HZ,
    to
        [IP_VS_S_TIME_WAIT]     =       2*50*HZ,
]]></programlisting>
	<para>
and recompiled the kernel
	</para>
	<para>
Rerunning the tests, I see the connection template record being reset to 1:40
instead of 2:00. Here's the IPVS connection entries (output of <command>ipvsadm -Lc</command>)
as time progresses.
	</para>
<programlisting><![CDATA[
pro expire state      source                     virtual          destination
TCP 04:50 NONE        greenblade.mitra.com:0     devlivelink:http devlivelink2:http
TCP 00:05 ESTABLISHED greenblade.mitra.com:51356 devlivelink:http devlivelink2:http

TCP 04:49 NONE        greenblade.mitra.com:0     devlivelink:http devlivelink2:http
TCP 00:04 ESTABLISHED greenblade.mitra.com:51356 devlivelink:http devlivelink2:http

TCP 04:48 NONE        greenblade.mitra.com:0     devlivelink:http devlivelink2:http
TCP 00:04 ESTABLISHED greenblade.mitra.com:51356 devlivelink:http devlivelink2:http

TCP 04:47 NONE        greenblade.mitra.com:0     devlivelink:http devlivelink2:http
TCP 00:05 ESTABLISHED greenblade.mitra.com:51356 devlivelink:http devlivelink2:http

.
.

TCP 00:02 NONE        greenblade.mitra.com:0     devlivelink:http devlivelink2:http
TCP 00:04 ESTABLISHED greenblade.mitra.com:51356 devlivelink:http devlivelink2:http

TCP 00:01 NONE        greenblade.mitra.com:0     devlivelink:http devlivelink2:http
TCP 00:05 ESTABLISHED greenblade.mitra.com:51356 devlivelink:http devlivelink2:http

(here being reset to 1:40)

TCP 01:39 NONE        greenblade.mitra.com:0     devlivelink:http devlivelink2:http
TCP 00:05 ESTABLISHED greenblade.mitra.com:51356 devlivelink:http devlivelink2:http

TCP 01:38 NONE        greenblade.mitra.com:0     devlivelink:http devlivelink2:http
TCP 00:05 ESTABLISHED greenblade.mitra.com:51356 devlivelink:http devlivelink2:http
]]></programlisting>
	</blockquote>
	<para>
Julian
	</para>
	<para>
        Yes, as implemented, the persistence timeout guarantees
afinity starting from the first connection. It lasts _after_ the
last connection from this "session" is terminated. There is still
no option to say "persistence time starts for each connection",
it could be useful.
	</para>
	<para>
Terry
	</para>
	<blockquote>
Agree completely.
However, I expected the template record to be reset to the session
persistence time, not to the value of IP_VS_S_TIME_WAIT.
	</blockquote>

	<para>
Julian
	</para>
	<para>
        The persistence timeout is used only once: when the
first connection from this client is established. The current
meaning is the persistent time to cover period of time after
the client appears for first time. It is extended if there are
still active connections. Then there are 3 (or more) options:
	</para>
	<orderedlist>
		<listitem>
extend it again with the persistent time
		</listitem>
		<listitem>
extend it with 2mins
		</listitem>
		<listitem>
use the persistence time after the last connection from client
terminates
		</listitem>
	</orderedlist>

	<para>
        The second option is the one implemented,
as we found it was the behaviour the users expected :)
A long time ago my opinion was that it is better to use
the persistence time when the last connection terminates (item 3 above).
We could make this a config option if anyone wants it.
	</para>
	<para>
        May be you see the value 20 seconds after the 2-minute cycle
is restarted. It is "reset" only when its timer expires, not when
the controlled connections expire.
	</para>

	<para>
Terry
	</para>
	<blockquote>
	<para>
Nope - perhaps I wasn't clear... I was watching <command>ipvsadm -Lc</command> every second.
I did the tests originally and saw the template record being reset to 2 minutes if it
expired with an active connection
(even though the persistence setting for the connection was NOT 2 minutes).
Then I did another connect from the client,
and the template record was reset again to 2 minutes (not the persistence setting again),
suggesting the template record data structure had somehow had it's persistence time
reset from the original setting to 2 minutes.
	</para>
	<para>
Then, to prove to myself that my reading of the source was accurate, I hacked the
source to make IP_VS_TIME_WAIT 2*50*HZ instead of 2*60*HZ, and with the newly
compiled kernel, the template record started being reset to 100 seconds when it
expired with an active connection.
	</para>
	<para>
My expectation would have been that the template record's timer would get reset to
the session persistence value rather than to IP_VS_TIME_WAIT.
	</para>
	</blockquote>

	<para>
True, your reading is accurate :) I now see why it was 1:40
	</para>
	<para>
Joe - other people have found this behaviour too
	</para>
	<para>
<emphasis>chulmin2 (at) hotmail (dot) com</emphasis> 2003-02-11
	</para>
	<blockquote>
	<para>
I have set the persistence timeout to 30s
	</para>
<programlisting><![CDATA[
ipvsadm -A -t 211.1.1.1:80 -p 30
]]></programlisting>
	<para>
after I connected, I confirmed the settings
	</para>

<programlisting><![CDATA[
# ipvsadm -Lc
TCP 00:30.00 NONE        211.1.1.2:0     211.1.1.1:http 192.168.1.3:http
TCP 02:00.00 TIME_WAIT   211.1.1.2:40929 211.1.1.1:http 192.168.1.3:http
]]></programlisting>
	<para>
But after 30s the timeout returns to 2 mins.
	</para>
<programlisting><![CDATA[
TCP 02:00.00 NONE        211.1.1.2:0     211.1.1.1:http 192.168.1.3:http
   ~~~~~~~~~~
TCP 01:30.00 TIME_WAIT   211.1.1.2:40952 211.1.1.1:http 192.168.1.3:http
]]></programlisting>
	</blockquote>

	<para>
	Here's Terry's summary:
	</para>
	<blockquote>
	<para>
I observed the same behavior,
and traced it down to the scenario where the template record times out
with valid connection records still counting down.
In this case, the template record is reset to 2 minutes
(actually, to the value of the IP_VS_S_TIME_WAIT constant).
When this happens, the data structure record representing
the template connection also gets altered,
because any further connections from the client reset the
template record to 2 minutes (NOT the original session persistence time).
	</para>
	<para>
The replies I got from Julian suggested that this behavior was intended,
(and thus, I would suggest, the documentation is slightly inaccurate).
I didn't pursue it too far,
as I this only showed up when I was using really short persistence times for testing purposes.
I don't expect it will happen too often or have too much
impact when using a more practical session timeout time.
	</para>
	</blockquote>
	</section>
	<section id="persistent_e-commerce"
xreflabel="why you don't want persistence for your e-commerce site: why you should rewrite your application">
	<title>Why you don't want persistence for your e-commerce site: why you should rewrite your application</title>
	<para>
Malcolm Turnbull <emphasis>Malcolm.Turnbull (at) crocus (dot) co (dot) uk</emphasis> 18 Sep 2002
	</para>
	<para>
The main problem with using persistence for session variable tracking is that
the only thing you are gaining by using LVS is increased performance.
You are not getting any high availability <emphasis>i.e.</emphasis> if your realserver falls
over during a persistent SSL session, you loose your shopping basket
(or whatever).
	</para>
	<para>
Anyone using ASP/IIS will be well used to the service restarting all the
time due to the 64MB ASP memory limit in IIS5 (wonder if they'll
raise this in .net)
	</para>
	<para>
My wife always leaves web sites open  for things like holidays/hotels
etc so that when I come home I can see it...
Often as soon as I click anything I loose the session.. :-(
	</para>
	<para>
Bad design.
To save money on re-coding.. code it properly in the first place.
	</para>
	<para>
Joe Stump <emphasis>joe (at) joestump (dot) net</emphasis> 22 Nov 2002 (replying to another thread)
	</para>
	<blockquote>
What Joe is trying to get at here (and this would apply to you PHP session
users out there as well) is that your realservers should have access to
your session files. The simple solution is a shared drive (under windows) or
an NFS mount (under *NIX). Other solutions include NetApps, SANs, etc. The
problem Devendra was having is that the session files exist independantly on
each of the realservers. When a realserver dies or is taken out of the
RAIC all of the session files on that realserver are gone. If they were in
a central location where all servers had access they wouldn't die.
	</blockquote>
	<para>
Joe
	</para>
	<blockquote>
I've sat on https sites for more that 30mins of inactivity. Also I've
had the modem line drop on me in the middle of filling in forms on
badly written websites (eg registering a domainname),
- when I come back, I have a new IP. I expect
anyone who wants to do internet business to handle these problems seamlessly.
	</blockquote>
	<para>
Roberto Nibali <emphasis>ratz (at) tac (dot) ch</emphasis> 10 Sep 2002
	</para>
	<para>
Exactly and most of the time you've got non-technical stakeholders or managers
in the back that will rip your head of if that happens.
	</para>
	<blockquote>
Persistence only gets you so far here, since memory requirements
limit you to the number of connections maintained.
	</blockquote>
	<para>
Yes, memory and timeout constraints combined in a linear fashion.
	</para>
	<blockquote>
Ratz's idea (in the HOWTO) is to redesign the application. He can do that.
Not everyone can. He maintains state data on the servers with a database.
	</blockquote>
	<para>
Everyone can, and the other people can work with Tomcat's internal
state replication module to do that. But it's slow
last time I tested it (1 year ago) and tends to have nasty locking issues.
	</para>
	<blockquote>
	<para>
Alternately in php3 you could write the url that the client moved to
on the next click to would contain the state information (functions
the same as cookies).
	<note>
Joe Dec 2003: I thought this was the solution for quite a while.
However I now find that since all the data is encoded in a long
string as part of the URL, the client can manipulate it, making
the data at the client and server different. You do not want
this to happen.
	</note>
If you can't rewrite the application, then you'll
risk loosing some customers and I would say that LVS is not for you.
	</para>
	<para>
DoS problems are difficult for everybody. With persistence it's just worse.
	</para>
	</blockquote>
	<para>
DoS problems are not to be solved on the LVS box.
	</para>
	<para>
Matthias Krauss 10 Sep 2002
	</para>
	<blockquote>
what is the maximum timeout value
	</blockquote>
	<para>
Joe
	</para>
	<para>
There is no maximum value. However the
connection underneath will timeout eventually, and
you will start to use a lot of memory with a large number
of connections.
	</para>
	<para>
Julian
	</para>
	<blockquote>
Note that setting 0 as RS weight is assumed as "stopped
temporary". The existing connections continue to work. It is
assumed that the RS weight is set to 0 some time before deleting
the RS. By this way we give time for all connections/sessions
to terminate gracefully. Sometimes weight 0 can be used from
health checks as a step before deleting the RS. Such two-step
realserver shutdown can avoid temporary unavailability of the
realserver. Graceful stop. At least, the health checks can
choose whether to stop the RS before deleting it.
	</blockquote>
	<para>
Roberto Nibali <emphasis>ratz (at) tac (dot) ch</emphasis> 13 Sep 2002
	</para>
	<para>
It's also useful to introduce a service level window for maintainance work. If
you have a service level agreement with only a few minutes downtime a year and you need to
exchange the HD of one RS you can quiesce that particular RS about 1 hour before
the maintainance work and if you have a resonable low or most of the time even
no active connection rate, you unplug the cable, shutdown the server and fix the
problem. Then you put it back in, set the weight&gt;0 and off you go.
	</para>
	<blockquote>
If the RS is deleted the traffic for existing conns is
stopped (and if expire_nodest_conn sysctl var is set the conn entries
are even deleted). Of course, if for some connections we don't see packets
these conns can remain in the table until their timer is expired.
	</blockquote>
	<para>
Bobby Johns <emphasis>bobbyj (at) freebie (dot) com</emphasis> 13 Sep 2002
	</para>
	<para>
When you add in the persistence problem I suspect you're doing something
that's a bad idea.  I suspect the reason you need persistence (or think you
do) is because you're storing state or session information locally on each
web server.  Although it may work, it's a weak design for a web app.  If
you want a high performance solution, use a common server with something
like MySQL on it to hold the session or state information.  If you're
nervous about the single point of failure on the database box, add a
replicated sever behind it.  Keeping state info on each web server is just
a weak solution in a highly-available high-performance
environment.  Hardware is pretty cheap in comparison.
	</para>
	<para>
I would suggest 2 LVS servers running HA between them, 2 or more web
servers, and 2 session/state db servers running replicated.  Bang for the
buck, it's a good solution and gives you a pretty resilient, robust, and
scalable system.  The system you are trying to implement now will hammer
33% of your user sessions if you have a web server failure and ALL of them
if you have an LVS server failure.  With the proper monitoring and HA, no
single machine failure will hammer your users in the system I suggest.  For
the price of 6 or 7 Linux servers boxes, you have what people used to pay
more than $100K for just a few years ago.
	</para>
	</section>
	<section id="more_on_e-commerce">
	<title>more about e-commerce sites: we used to think memory was the problem - it isn't</title>
	<para>
The original idea of persistence was to allow for connections like
https sessions.
This solved the problem of keeping the client's connection
on the same realserver. However it doesn't work well.
	</para>
	<para>
The first problem is that it uses a lot of memory.
The default timeout for LVS persistence is somewhere around 360secs,
while the default timeout for a regular LVS connection via LVS-DR is TIME_WAIT
(about 1 minute).
This means that LVS persistent connections will stay in the LVS connection
table for 6 times longer for persistent connection.
As a consequence the hash table (and memory requirements)
will be 6 times larger for the same number of connections/sec.
Make sure you have enough memory to hold the increased table size if you're
using persistent connections.
If the persistence is being used to hold state (<emphasis>e.g.</emphasis> shopping cart),
then you must allow a long enough timeout for the client to surf to another
site for a better price, make a cup of coffee, think about it and then
go find their credit card. This is going to be much longer than any reasonable
timeout for LVS persistence and the state information will have to be held
on a disk somewhere on the realservers and you'll have to allow for the client
to appear on a different realserver later with their credit card information.
	</para>
	<para>
The next problem is that 
<link linkend="persistent_e-commerce">persistence doesn't allow for failover</link>.
	</para>
	<para>
The memory problem really isn't as bad as was originally thought.
Here's some exchanges on the mailing list which talk about the real problems.
	</para>
	<para>
Joe 18 Sep 2002
	</para>
	<blockquote>
The conventional LVS wisdom is that it's not a good
idea to build an LVS e-commerce website in which https
is persistent for long periods.
The initial idea was that a long timeout allows
the customer to have a cup of coffee or surf to
other websites while thinking about their on-line
purchase.
	</blockquote>
	<para>
Julian 18 Sep 2002
	</para>
	<para>
	Yes, if your site uses persistence for HTTP/HTTPS then
you better to use cookies (not LVS). If you don't care
for the HTTPS persistence (any realserver can serve
connections from one client "session") then you create
normal service. In such case your care for the backend DB.
	</para>
	<blockquote>
		<para>
The problem with this approach is that the amount
of memory use is expected to be large and the director
will run out of memory. We've been telling people
to rewrite their application so that state is maintained
on the realservers allowing the customer to take an
indefinite time to complete their purchase.
Currently 1G of memory costs about an hour of programmer's time
(+ benefits, + office rental/heating/airconditioning/equipment
+ support staff). Since memory is cheap compared to the cost
of rewriting your application, I was wondering if brute
force might just be acceptable.
I can't find any estimates of the numbers involved in the HOWTO
although similar situations have been discussed on the mailing
list <emphasis>e.g.</emphasis>
		</para>
		<para>
http://marc.theaimsgroup.com/?l=linux-virtual-server&amp;m=99200010425473&amp;w=2
		</para>
		<para>
there the calculation was done to see how long a director would
hold up under a DoS. The answer was about 100secs for 128M memory
and 100Mbps link to the attacker doing a SYN flood.
I'm not running one of these web
sites and I don't know the real numbers here. Is amazon.com
or ebay connected by 100Mbps to the outside world?
		</para>
		<para>
What you can do with 1G of memory on the director?
Each connection requires 128bytes. 1G/128 is 8M customers
online at any one time. Assuming everyone buys something
this is 1500 purchases/sec. You'd need the population of
a large town just to handle shipping stuff at this rate.
I doubt if any website at peak load has
8M simultaneous customers.
		</para>
		<para>
However you only have 64k ports on each realserver to
connect with customers allowing only have 64k
customers/realserver.
		</para>
	</blockquote>
	<para>
	Note that the port limit is only between
two IPs. You still can reuse one port for many connections
if the two connections don't have same ends (IP and port).
	</para>
	<blockquote>
		<para>
How much memory  do you need on
the director to handle a fully connected realserver?
		</para>
		<para>
64k x 128 = 8M
		</para>
		<para>
Let's say there are 8 realservers. How much memory
is needed on the director?
		</para>
		<para>
8 x 8M = 64M
		</para>
		<para>
this is not a lot of memory. So the problem isn't
memory but realserver ports AFAIK
		</para>
	</blockquote>
	<para>
	No, you don't waste realserver ports for connections
from client to the LVS. But using many sockets in realserver
hurts.  Memory for sockets is a problem, sometimes the sockets can reserve
huge buffers for data.
	</para>
	<blockquote>
		<para>
What is the minimum throughput of customers assuming
they all take 4000 sec (66 mins) to make their
purchase?
		</para>
		<para>
8 x 64k/4000 = 64 purchases/sec
		</para>
		<para>
You're still going to need a hire a few people to pack and
ship all this stuff. If people use only take 6mins
for their purchase, you'll be shipping 640 packages/sec.
		</para>
		<para>
Assuming you make $10/purchase at 64 purchases/sec, that's
$2.5G/yr.
		</para>
		<para>
So with 64M of memory, 8 realservers, 4000sec persistence
timeout, and a margin of $10/purchase I can make a profit
of $2.5G/yr.
		</para>
		<para>
It seems memory is not the problem here, but realserver
ports (or being able to ship all the items you sell).
		</para>
		<para>
Let's look at another use of persistence - for squids
(despite the arrival of the -DH scheduler, some people
prefer persistence for squids).
		</para>
		<para>
Here you aren't limited by shipping and handling of purchases.
Instead you are just shipping packets to the various target
httpd servers on the internet. You are still limited to
64k clients/realserver. Assume you make persistence = 256secs
(anyone client who is idle for that time is not interested
in performance). This means that the throughput/realserver is
256hits/sec. This isn't great. I don't know what throughput
to expect out of a squid, but I suspect it's a lot more.
		</para>
	</blockquote>
	<para>
Ratz
	</para>
	<para>
Well, it depends what you want to offer. If it's an online shop like
amazon.com you certainly want to store the generated cookie or whatever
it is on a central DB cluster where every RS can connect to and request
for the ID if it doesn't already have one.
	</para>
	<para>
The memory is a completely different layer. It's about software engineering and
not about saving money. Yes, you can probably kill the problem temporary
by adding more memory but a broken application framework remains a
broken application framework.
	</para>
	<para>
Plus, normally when you do build an e-commerce site, you have a customer
that has outsourced this task to your company. So you do a C-requirement
and a feasability study to provide the customer with a proper cost
estimation. Now you build the application and it is built in a broken
way so that you need to either fix it or add more RAM in our case. The
big problem here is:
	</para>
	<itemizedlist>
		<listitem>
you might have a strict SLA that doesn't permit this
		</listitem>
		<listitem>
you change the C-requirements and thus you need a new test phase
		</listitem>
		<listitem>
the customer gets upset because she spent big bucks on you
		</listitem>
	</itemizedlist>
	<para>
It's lack of engineering and a typical situation of plain incompetence:
When you earnestly believe you can compensate for a lack of skill by
doubling your efforts, there's no end to what you can't do.
	</para>
	<para>
But all this also depends on the situation. I don't think we can give
people a generalised view of how things have to be done. One might argue
that people come to this project because of monetary constraints and
they sure do not care about the application if the problem is solved by
putting more RAM into the director.
	</para>
	<para>
I for example rather spend a few bucks on good hardware and a lot of RAM
for the RS because they need to carry the execution weight of the
application. The director is just a more or less intelligent router.
	</para>
	<para>
pb (who has 1GB of memory and who wants to increase his persistence time to 60mins)
	</para>
	<blockquote>
Wwe handle 1 million
messages a day, and 20,000+ webmail users, thus
125,000 messages per hour send/recv in 8 hour work
day.  
Would changing 15 to 60min Persistance on the LVS take
up a lot of memory and processing (CPU/load) overhead?
We're running 1gb of memory and dual pentium III.
	</blockquote>
	<para>
Malcolm Turnbull <emphasis>malcolm (at) loadbalanceri (dot) org</emphasis> 27 Apr 2004
	</para>
	<para>
I would think it would be fine, 1 GB should handle almost 8 million 
connections in the timeout period i.e. 60 mins (or 2mins with no 
persistence).
	</para>
	<para>
Horms <emphasis>horms (at) verge (dot) net (dot) au</emphasis> 27 Apr 2004
	</para>
	<para>
I think Malcom is on the money here.
Keep in mind that each connection entry / persistance timeout
consumes something like 128bytes (actually, it might be a bit bigger
now, but it is still in that ball-park). You can do the maths
(actually you should, my brain has already checked out for the day),
but if you are getting 100 connections/s, for an hour, each from
a unique host, then you are still only going to end up using about 
45Mb of memory for persistance entries. I doubt that will hurt you.
I would also be supprised if you are getting connections from
360,000 unique hosts per hour :-)
	</para>
	<para>
Joe
	</para>
	<para>
for 4 realservers that's 40k messages/hr. I don't know
how many tcp connections are required for a message transfer,
but let's say it's 1. You have 15mins persistence,
so 10k connections will be in existance at any one time.
	</para>
	<para>
For memory for the ipvs hash table:
At 128bytes/connection, that's 1.28M of memory for the
ipvsadm hash table. You have quite a margin with memory.
	</para>
	<para>
For disk and network I/O:
	</para>
	<para>
Let's say the average e-mail is 10kB. Each realserver
is processing (10k messages/(15*60) secs) * 10kB = 0.1MBytes/sec.
Your disks and network also have large margins of safety.
	</para>
	<blockquote>
 The
 error just a couple random people are having with
 WEBMAIL is "invalid session ID" as though they lost
 their connection to the realserver (actually a
 "message director") they were on.  But I don't know if
 it is the "message directors" fault, or LVS. 
	</blockquote>
	<para>
have no idea, but I don't see any heavy load here. 
Are the clients timing out after 15mins and attempting to 
continue their session? WOuldn't the app/client know 
that the session has been closed and to go through
the whole login procedure again? I don't know much
about your app I'm sorry.
	</para>
	<para>
nothing here addresses the issue of persistence timeout.
This is determined by how long you allow the client
to be disconnected before you propagate to all realservers,
the state changes in the realserver that occured in the last 
connection. 
	</para>
	</section>
	<section id="persistence_windows_realservers">
	<title>persistence with windows realservers</title>
	<para>
With unix realservers, we've been encouraging developers to 
rewrite the application (see <xref linkend="L7_ratz"/>),
to save client state in a failover safe fashion
(<emphasis>i.e.</emphasis> in a place accessable by all realservers).
Previously you would ask the client to accept a cookie or
save the client state on the realserver to which the client connects
(but where the state will be lost if the realserver fails).
Rewriting the application is possible with unix,
which gives you access to the primitives and you can
build the application any way you want
(provided that you have enough time and you
understand the primitives well enough).
	</para>
	<para>
With Windows, you aren't given access to the primitives,
but instead are given access to an API.
If Windows has already coded up the function you want
and you are happy to use that, then it's easy.
If you want something else, you're SOL.
	</para>
	<para>
devendra orion <emphasis>dev_orion (at) yahoo (dot) com</emphasis> 22 Nov 2002
	</para>
	<blockquote>
I need to enable loadbalancing on our curent director
M/c (LVS-NAT enabled). We are currently having 3
realservers serving same website and need to be
loadbalanced. The website is hosted on w2k and
uses IIS session Mgmt (no cookies). Only problem is we
need to keep this session alive for basically 8 hrs as
our clients access the application continuously.
How can I configure the loadbalancer to keep the
connection persistence to same server after successful
client login?
	</blockquote>

	<para>
Joe (giving the party line)
	</para>
	<blockquote>
The best solution is not to use persistence, but to re-write
the application, so that the state information is stored
in a place accessable to all realservers. In this way,
if one realserver fails, the session with the client can continue.
	</blockquote>
	<para>
Alex Kramarov <emphasis>alex (at) incredimail (dot) com</emphasis> 22 Nov 2002
	</para>
	<blockquote>
	<para>
I continuously hear on this list suggestions to rewrite applications to use
other session management means then the one that comes with IIS. As a
Windows/Unix developer/administrator (you can mix and match any one of the 2
groups ;), i would really like to say, that usually this is not that easy in
the IIS environment, especially if you try to tell this to windows only
developers, that don't know anything else then the MS way to do things. The
best they can hope is to wait for the upcoming IIS 6 release, that includes
session management that is meant to use in webfarms (db based), or to try
some non microsoft (still proprietary) solutions, that try to do the same,
like frameWERKS framework, that functions as a drop in replacement for the
IIS session components.
	</para>
	<para>
I am not saying this to start a MS war on the list, but only to tell, that
when an ms inclined person hears that he should "re-write the application" -
95% chance that this will be his last try to use lvs for his solutions. on
the other hand, saying that there is a such and such solution that can help
him will probably be considered...
	</para>
	</blockquote>
	<para>
(Alex has given an explanation of <link linkend="IIS_session_management">
IIS session management</link> below).
	</para>

	<para>
Tim Cronin <emphasis>tim (at) 13-colonies (dot) com</emphasis> 22 Nov 2002
	</para>
	<blockquote>
We use IIS /w sessions and vls_nat and use wlc /w persistance.
The presistance time must match the iis.session.timeout.
We haven't had any problems, but we only have a 20min session.
	</blockquote>

	</section>
	<section>
	<title>messing with the <command>ipvsadm</command> table while your LVS is running</title>
	<para>
This is an example of persistence with <xref linkend="LVS-HOWTO.fwmark"/>.
	</para>
	<para>
Bowie Bailey
	</para>
	<blockquote>
		<para>
If I start a service with:
		</para>
<programlisting><![CDATA[
ipvsadm -A -f 1 -s wlc -p 180
]]></programlisting>
		<para>
and then change the persistence flag
(setting the persistence granularity netmask to /24 with the -M option) to
		</para>
<programlisting><![CDATA[
ipvsadm -E -f 1 -s wlc -p 180 -M 255.255.255.0
]]></programlisting>
		<para>
how does that affect the connections that have already been made?
		</para>
	</blockquote>
	<para>
Julian 30 Jul 2001
	</para><para>
The connections are already established. But the persistence
is broken and after changing the netmask you can expect the next
connections to be established to another realservers (not to the same
as before the change).
	</para><para>
(also see <link linkend="persistence_granularity">persistence netmask</link>).
	</para>
	<blockquote>
If IP address 1.2.3.4 was connected to RIP1 before I changed the persistence
 and then 1.2.3.5 tries to connect afterwards, would he be sent to RIP1, or
 would it be considered a new connection and possibly be sent to either
 server since the mask was 255.255.255.255 when the first connection
 happened?
	</blockquote>
	<para>
New realserver will be selected.
	</para>
	<para>
unknown
	</para>
	<blockquote>
	<para>
Let's say: I have 1000 http requests (A) through a firewall of a customer
(so in fact all requests have the same Source IP for Loadbalancer,
because of NAT) and then one request (B) from the Intranet and then
again 1000 Request (C) from that firewall, what does LB do?
I have three Realservers r1, r2, r3 (ppc with rr)
	</para>
<programlisting><![CDATA[
a) A to r1, B to r2, C to r1 (because of SourceIP) [Distribution:2000:1:0.0000001]
b) A to r1, B to r2, C to r3 (because r3 is free) [Distribution:1000:1:1000]
c) A to r1, B to r2, C to r2 (due to the low load of r2) [Distribution:1000:1000:0.000001]
A to r1 && r2 && r3 (depending on source port),
B to r1 || r2 || r3,
C to r1 && r2 && r3 [Distribution: 667:667:666]
]]></programlisting>
	</blockquote>
	<para>
Ratz <emphasis>ratz (at) tac (dot) ch</emphasis> 12 Sep 1999
	</para><para>
If C reachs the load balancer before all the 1000 requests
of A expire, then the requests of C will be sent to r1,
and the distribution is 2000:1:0.
	</para><para>
If all the requests of A expires, the requests of C will
be forwarded to a server that is selected by a scheduler.
	</para><para>
BTW, persistent port is used to solve the connection
affinity problem, but it may lead to dynamic load
imbalance among servers.
	</para>

	<para>
Jean-Francois Nadeau
	</para>
	<blockquote>
I will use LVS to load balance web servers (Direct Routing and WRR algo).
I use persitency with a big timeout (10 minutes).
Many of our clients are behind big proxies and I fear this will
unbalance our cluster because of the persitent timeout.
	</blockquote>
	<para>
Wensong
	</para>
	<para>
persistent virtual services may lead to the load imbalance among
servers. Using some weight adapation approaches may help avoid that some
servers are overloaded for a long time. When the server is overloaded,
decrease its weight so that connections from new clients won't be sent
to that server. When the server is underloaded, increase its weight.
	</para>

	<blockquote>
Can we alter directly /proc/net/ip_masquerade ?
	</blockquote>

	<para>
No, it is not feasible, because directly modifying masq entries will
break the established connection.
	</para>
	</section>
	<section id="persistence_for_multiport_services">
	<title>Persistence for multiport services</title>
	<para>
Persistence was originally used to handle multiport services
(<emphasis>e.g.</emphasis> ftp/ftp-data, http/https).
While persistence is still the best method for
<xref linkend="ftp"/> with LVS-DR, LVS-Tun,
http/https is better handled by
<link linkend="fwmark_persistence_granularity">persistence granularity with fwmark</link>.
	</para>
	</section>
	<section id="proxy_farm" xreflabel="proxy farm">
	<title id="persistence_granularity">Proxy services, <emphasis>e.g.</emphasis> AOL</title>
	<para>
Clients from AOL or T-online access the internet via proxies.
Because of the way proxies can work, a client can come from one IP
for one connection (eg port 80) and from another IP for the next
connection (eg port 443) and will appear to be two different clients.
Since there is no relation between the CIP and the indentity
of the client, LVS cannot loadbalance by CIP.
Usually these two connections will come from the same /24 netmask.
Lars wrote the persistence granularity patch for LVS, which
allows LVS to loadbalance all clients from a netmask as one group.
If you set the netmask for persistence to /24
(with the -M option to <command>ipvsadm</command>) and all clients
from the same class C network will be sent to the same realserver.
This will mean that clients from AOL appear as a single (very active)
client, and will likely take up all capacity on one realserver,
leading to unbalance in load on the realservers.
This is as good as we can do with LVS.
	</para>
	<para>
Wensong
	</para>
	<para>
If you want to build a persistent proxy cluster, you just need set a
LVS box at the front of all proxy servers, and use the persistent port
option in the <command>ipvsadm</command> commands. BTW, you can have a look at
wwwcache.ja.net/JanetServices/PilotServices.html "how to
build a big JANET cache cluster using LVS" (link dead, May 2002).
	</para>
	<para>
If you want to build a persistent web service but some proxy farms are
non-persistent at client side, then you can use the persistent
granularity so that clients can be grouped, for example you use
255.255.255.0 mask, the clients from the same /24 network will go to
the same server.
	</para>
	<para>
Jeremy Johnson <emphasis>jjohnson (at) real (dot) com</emphasis>
	</para>
	<blockquote>
how does LVS handles a single client that uses
multiple proxies... for instance aol, when an aol user attempts to connect
to a website, each request can come from a different proxy so, how/if does
LVS know that the request is from the same client and bind them to the same
server?
	</blockquote>
	<para>
Joe
	</para>
	<para>
if this is what aol does then each request will be independant and will
not neccessarily go to the same realserver. Previous discussions about aol
have assumed that everyone from aol was coming out of the same IP
(or same class C network).
Currently this is handled by making the connection persistant and all
connections from aol will go to one realserver.
	</para>
	<para>
Michael Sparks <emphasis>zathras (at) epsilon3 (dot) mcc (dot) ac (dot) uk</emphasis>
	</para>
	<blockquote>
		<para>
If ISP user (eg AOL) has a proxy array/farm then the requests are _likely_
to come from two possibilities:
		</para>
		<itemizedlist>
		<listitem>
A single subnet (if using an L4/L7 switch that rewrites ether frames,
     or using several NAT based L4/L7 switches)
		</listitem>
		<listitem>
A single IP (If using the common form of L4/L7 switch)
		</listitem>
	</itemizedlist>
	<para>
The former can be handled using a subnet mask in the persistance settings,
the latter is handled by normal persistance.
	</para>
	<para>
*However* In the case of our proxy farm neither of these would work
since we have 2 subnet ranges for our systems - 194.83.240/24 and
194.82.103/24, and an end user request may come out of each subnet totally
defeating the persistance idea... (in fact dependent on our clients
configuration of their caches, the request could appear to come from the
above two subnets or the above 2 subnets and about 1000 other ones as
well)
	</para>
	<para>
Unfortunately this problem is more common that might be obvious, due to
the NLANR hierarchy, so whilst persistance on IP/subnet solves a large
number of problems, it can't solve all of them.
	</para>
	</blockquote>
	<para>
Billy Quinn <emphasis>bquinn (at) ifleet (dot) com</emphasis> 05 Jun 2001
	</para>
<blockquote>
	<para>
I've come to conclusion that I need an expensive (higher layer) load balancer
node , which load balances port 80 (using persistence because of
sessions) to 3 realservers which each run an apache web server, and
tomcat servlet engine. Each of the 3 servers is independent and no tomcat
load balancing occurs.
	</para>
	<para>
This has worked great for about a year, while we only had to support
certain IP address ranges. Now, however, we have to support clients using
AOL and their proxy servers, which completely messes up the session handling
in tomcat. In other words, one client comes from multiple different IP
addresses based on which proxy server it comes through.
	</para>
	<para>
It seems the thing to do is to adjust the persistence granularity.
However, if I adjust the netmask, all of our internal network traffic will go to one server, which
kind of defeats the purpose.
	</para>
	<para>
What I'm concluding is, that I'll need to change the network architecture
(since we are all on one subnet), or buy a load balancer which will look at
the actual data in the packets (layer 7?).
	</para>
	</blockquote>
	<para>
Joe
	</para>
	<para>
There has been comments by people dealing with this problem (not many),
but they seem to be still able to use LVS.
We don't hear of anyone who is having lots of trouble with this,
but it could be because no-one on this
list is dealing with AOL as a large slice of their work.
	</para>
	<para>
If 1/3 of your customers are from AOL you could sacrifice one server to them,
but it's not ideal. If all your customers are from AOL, I'd say we can't help
you at the moment.
	</para>
	<blockquote>
My concern with that would be anyone else doing proxying ... now or in the
future . I would not be opposed to routing all of the AOL customers to one
server for now though . I guess we could have to deal with each case of
proxying individually. I wonder how many other ISP's do proxying like that
	</blockquote>
	<para>
How many different proxy IPs do AOL customers arrive on the internet from?
How many will appear from multiple IP's in the same session and how big
is the subnet they come from? (/24?)
	</para>
	<blockquote>
Good question, I'm not sure about that one. The customer that reported the
problem seemed to be coming from about 2-4 different IP addresses (for the
same session ).
	</blockquote>
	<para>
If AOL customers come from at least 3 of these subnets and you have 3 servers,
then you can use LVS as a balancer.
	</para>
	<para>
Peter Mueller <emphasis>pmueller (at) sidestep (dot) com</emphasis>
	</para>
	<blockquote>
		<para>
Over here we also need layer-7 'intelligent' balancing with our
apache/jakarta setup.  We utilize two tiers of 'load-balancing'.  One is the
initial LVS-DR round-robin type setup, while the second layer is our own
creation, layer-7.  Currently we round-robin the first connection to one
server, then that server calls a routine that will ask the second-tier
layer-7 java monitor boxes which box to send the connection to.  (If for
some reason the second layer is down, standard round-robin occurs).
		</para>
		<para>
We're about 50% done with migration from cisco LD (yuck!) to LVS-DR.  After
the migration is fully complete the goal is to have the two layers
interacting more efficiently and hopefully merged into one 'layer'
eventually.. for example, if we tell our java-monitor second-tier
controllers to shutdown a server, the first tier will then mark the node out
of service automatically.
		</para>
		<para>
PS - we found the added layer-7 intelligent balancing to be about 30-50% (?)
added effectiveness to cisco round robin LD.. I think the analogy of a hub
versus a switch works fairly well here..
		</para>
	</blockquote>
	<para>
Chris Egolf <emphasis>cegolf (at) refinedsolutions (dot) net</emphasis>>
	</para>
	<blockquote>
		<para>
We're having the exact same problem with WebSphere cookie-based sessions.
I was testing this earlier today and I think I've solved this particular
problem by using fwmarks.
		</para>
		<para>
Basically, I'm setting everything from our internal network with one FWMARK
and everything else with another.  Then, I setup the <command>ipvsadm</command> rules with the
default client persistence for our internal network(/32) and a class C
netmask granularity (/24) for everything from the outside to deal w/ the AOL
proxy farms.
		</para>
		<para>
Here's the iptables script I'm using to set the marks:
		</para>
<programlisting><![CDATA[
iptables -F -t mangle
iptables -t mangle -A PREROUTING  -p tcp -s 10.3.4.0/24 -d $VIP/32 \
--dport 80 -j MARK --set-mark 1
iptables -t mangle -A PREROUTING  -p tcp -s ! 10.3.4.0/24 -d $VIP/32 \
--dport 80 -j MARK --set-mark 2
]]></programlisting>
		<para>
Then, I have the following rules setup for ipvsadm:
		</para>
<programlisting><![CDATA[
director:/etc/lvs# ipvsadm -C
director:/etc/lvs# ipvsadm -A -f 1 -s wlc -p 2000
director:/etc/lvs# ipvsadm -a -f 1 -r $RIP1:0 -g -w 1
director:/etc/lvs# ipvsadm -a -f 1 -r $RIP2:0 -g -w 1

director:/etc/lvs# ipvsadm -A -f 2 -s wlc -p 2000 -M 255.255.255.0
director:/etc/lvs# ipvsadm -a -f 2 -r $RIP1:0 -g -w 1
director:/etc/lvs# ipvsadm -a -f 2 -r $RIP2:0 -g -w 1
]]></programlisting>
		<para>
FWMARK #1 doesn't have a persistent mask specified, so each client on the
10.3.4.0/24 network is seen as an individual client.  FWMARK #2 packets are
seen as a class C client network to deal with the AOL proxy farm problem.
(for more on persistent netmask see the section in fwmark on
<link linkend="fwmark_persistence_granularity">fwmark persistence granularity</link>).
		</para>
		<para>
Like I said, I just did this today, and based on my limited testing, I think
it works.  I'm thinking about maybe setting a whole bunch of rules to deal
w/ each of the published AOL cache-proxy server networks
(http://webmaster.info.aol.com/index.cfm?article=15&amp;sitenum=2), but I think
that would be too much of an administrative nightmare if they change it.
		</para>
		<para>
The ktcpvs project implements some level of
layer-7 switching by matching URL patterns, but we need the same type of
cookie based persistence for our WebSphere realservers.  Hopefully, it
won't be too long before that gets added.
		</para>
	</blockquote>
	<para>
Matthias Krauss <emphasis>MKrauss (at) hitchhiker (dot) com</emphasis> 2003-01-30
	</para>
	<blockquote>
I turned on our lvs and it didnt
take long for the phone rings from AOL people.
The are switching
between proxys with the result that the targed web
will is different - we need it persitant.
	</blockquote>
	<para>
	Lars
	</para>
	<para>
The persistency netmask feature might help you,
in exchange for lower granularity of the load balancing
(but it shouldn't matter).
However, all AOL users will then likely hit the same webserver.
It just goes on to show that IP addresses are unsuitable to identify a single
user ;-) Real fix would be to use layer7 switching based on the URL or a
cookie, even; alternatively, you could make your application less dependent on
persistence, for example by storing your session data in a global cache/db,
which would also make it easier for you to preserve sessions when a single
webserver fails.
	</para>
	<blockquote>
		<para>
I have now the persistency netmask feature up and it seems to work fine.
All the sender networks are forwarded to 1 RIP and the load share on all RIP's is
nearly equal.
The AOL users are still complaining and I've got the impression
that aol has different netmasks on their proxies.
I found a
list at http://webmaster.info.aol.com/proxyinfo.html and used
this info for my fwmarks.
Here's my iptables list
		</para>
<programlisting><![CDATA[
#mark all packets from these networks to VIP:80 with fwmark=3
director:/etc/lvs# iptables -t mangle -A PREROUTING -p tcp -s  64.12.0.0/16 -d $VIP/32 --dport 80 -j MARK --set-mark 3
director:/etc/lvs# iptables -t mangle -A PREROUTING -p tcp -s  153.163.0.0/16 -d $VIP/32 --dport 80 -j MARK --set-mark 3
director:/etc/lvs# iptables -t mangle -A PREROUTING -p tcp -s  195.93.0.0/16 -d $VIP/32 --dport 80 -j MARK --set-mark 3
director:/etc/lvs# iptables -t mangle -A PREROUTING -p tcp -s  198.81.0.0/16 -d $VIP/32 --dport 80 -j MARK --set-mark 3
director:/etc/lvs# iptables -t mangle -A PREROUTING -p tcp -s  198.81.16.0/21 -d $VIP/32 --dport 80 -j MARK --set-mark 3
director:/etc/lvs# iptables -t mangle -A PREROUTING -p tcp -s  198.81.26.0/26 -d $VIP/32 --dport 80 -j MARK --set-mark 3
director:/etc/lvs# iptables -t mangle -A PREROUTING -p tcp -s  202.67.0.0/16 -d $VIP/32 --dport 80 -j MARK --set-mark 3
director:/etc/lvs# iptables -t mangle -A PREROUTING -p tcp -s  205.188.0.0/16 -d $VIP/32 --dport 80 -j MARK --set-mark 3
]]></programlisting>
		<para>
and for <command>ipvsadm</command> apply
<xref linkend="fwmark_persistence_granularity"/>.
		</para>
<programlisting><![CDATA[
#forward all packets with fwmark=3 with rr scheduler.
director:/etc/lvs# ipvsadm -A -f 3 -s rr -p 3600 -M 255.255.255.0
director:/etc/lvs# ipvsadm -a -f 3 -r $RIP1 -g -w 100
]]></programlisting>
		<para>
Of course their is no balancing anymore for the above nets, but
fortunately we don't have many aol customers.
		</para>
		<para>
Alternately, we found a optional way by using p3p http headers which
aol offers/describe under http://webmaster.info.aol.com/headers.html
			<note>
P3P is W3C's Platform for Privacy Policy.
		</note>
		</para>
	</blockquote>
	<para>
Here's another set of postings from Dec 2003, this time using fwmark to
aggregate all the traffic from AOL. As with above, all connections from
the proxy servers (<emphasis>i.e.</emphasis> all of AOL) will all go to one
realserver.
	</para>
	<para>
Francois JEANMOUGIN <emphasis>Francois (dot) JEANMOUGIN (at) 123multimedia (dot) com</emphasis> 30 Dec 2003
	</para>
	<blockquote>
		<para>
For AOL clients, I need to use persistent connections.
AOL make the IPs rotate very fast using several /8 or /16.
Here's the list of AOL IPs for their clients
	 	</para>
<programlisting><![CDATA[
64.12.0.0 - 64.12.255.255
152.163.0.0 - 152.163.255.255
172.128.0.0 - 172.191.255.255
195.93.0.0 - 195.93.63.255
195.93.64.0 - 195.93.127.255
198.81.0.0 - 198.81.31.255
202.67.64.0 - 202.67.95.255
205.188.0.0 - 205.188.255.255
]]></programlisting>
		<para>
Can I handle this with fwmark?
		</para>
	</blockquote>
	<para>
Matthias Krauss <emphasis>MKrauss (at) hitchhiker (dot) com</emphasis> 30 Dec 2003
	</para>
	<para>
Here's the list of
<ulink url="http://webmaster.info.aol.com/proxyinfo.html">
AOL proxies</ulink>
(http://webmaster.info.aol.com/proxyinfo.html).
	</para>
<programlisting><![CDATA[
#The proxy list from above

AOLPROXYS="64.12.96.0/19 152.163.188.0/21 152.163.189.0/21 152.163.194.0/21
152.163.195.0/21 152.163.197 152.163.201.0/21 \
152.163.204.0/21 152.163.205.0/21 152.163.206.0/21 152.163.207.0/21
152.163.213.0/21 152.163.240.0/21 \
152.163.248.0/22  152.163.252.0/23 195.93.32.0/22 195.93.48.0/22
195.93.64.0/19  198.81.0.0/22 198.81.8.0/23 \
198.81.16.0/21 198.81.26.0/23 202.67.64.0/21 205.188.178.0/21
205.188.192.0/21 205.188.193.0/21 205.188.195.0/21 \
205.188.196.0/21 205.188.197.0/21 205.188.198.0/21 205.188.199.0/21
205.188.200.0/21 205.188.201.0/21 \
205.188.208.0/21 205.188.209.0/21"

for aolproxys in $AOLPROXYS
do
  iptables -t mangle -A PREROUTING -p tcp -s $aolproxys -d VirtualIP/32 \
 --dport 80 -j MARK --set-mark 1
done

#-M is persistence netmask.
#It may not be needed since the netmask is already in the iptable command above
ipvsadm -A -f 1 -s wrr -p 3600 -M 255.255.255.0
ipvsadm -a -f 1 -r RealIP -g
#=> All listed AOL traffic is now going to VIP of machine with RealIP
]]></programlisting>
	<blockquote>
		<para>
I think you could concatenate some /21.
Regarding both whois and AOL technical contact, I deduced :
		</para>
<programlisting><![CDATA[
AOLPROXYS="64.12.0.0/16 152.163.0.0/16 172.128.0.0/10 195.93.0.0/17 198.81.0.0/19 202.67.64.0/19 205.188.0.0/16"
]]></programlisting>
		<para>
Here's is my entry for the fwmark rule in <filename>keepalived.conf</filename>.
Note the string "fwmark 1" which replaces "VIP port" as used in the standard setup.
(Presumably "fwmark 1" is just a string which is passed to <command>ipvsadm</command>.)
		</para>
<programlisting><![CDATA[
virtual_server fwmark 1 {
    delay_loop 20
    lb_algo rr
    lb_kind DR
    persistence_timeout 1800
    persistence_granularity 255.255.255.0
    protocol TCP
    virtualhost www.toto.com
    real_server 172.16.1.4 80 {
        weight 1
        HTTP_GET {
            url {
              path /index.jsp
            }
            connect_port 8083
            connect_timeout 10
            nb_get_retry 5
            delay_before_retry 20
        }
    }
}

#And here is it for the "standard users" :

virtual_server $VIP 80 {
    delay_loop 20
    lb_algo rr
    lb_kind DR
    persistence_timeout 1800
    persistence_granularity 255.255.255.0
    protocol TCP
    virtualhost www.toto.com
    real_server 172.16.1.4 80 {
        weight 1
        HTTP_GET {
            url {
              path /index.jsp
            }
            connect_port 8083
            connect_timeout 10
            nb_get_retry 5
            delay_before_retry 20
        }
    }
    real_server 172.16.1.5 80 {
        weight 1
        HTTP_GET {
            url {
              path /index.jsp
            }
            connect_port 8083
            connect_timeout 10
            nb_get_retry 5
            delay_before_retry 20
        }
    }
}
]]></programlisting>
		<para>
So, in one file, you have both you're load balancing and you're HA settings.
Of course, you need to configure iptables by yourself.
Also, it doesn't do anything on the realservers
(but on the realservers, I just need to configure the VIPs and noarpctl things,
which is easy).
		</para>
<programlisting><![CDATA[
# ipvsadm -Ln

FWM 1 rr persistent 1800 mask 255.255.255.0
  -> 172.16.1.4:80                Route   1     0          0
]]></programlisting>
	</blockquote>
	<para>
For an example of using fwmark with <command>keepalived</command>,
see <filename>./doc/samples/keepalived.conf.fwmark</filename>
in the source directory.
	</para>
	<para>
Casey Zacek <emphasis>cz (at) neospire (dot) net</emphasis> 2005/04/08
	</para>
	<para>
Here's the 
<ulink url="http://webmaster.info.aol.com/proxyinfo.html">
current aol proxy list</ulink>
(http://webmaster.info.aol.com/proxyinfo.html), in a more raw format, 
but it changes occasionally 
(I just had to update my list when I went looking for them):
	</para>
	<note>
Joe: most of these are <emphasis>not</emphasis> class C
	</note>
<programlisting><![CDATA[
64.12.96.0/19

149.174.160.0/20

152.163.240.0/21
152.163.248.0/22
152.163.252.0/23
152.163.96.0/22
152.163.100.0/23

195.93.32.0/22
195.93.48.0/22
195.93.64.0/19
195.93.96.0/19
195.93.16.0/20

198.81.0.0/22
198.81.16.0/20
198.81.8.0/23

202.67.64.128/25

205.188.192.0/20
205.188.208.0/23
205.188.112.0/20
205.188.146.144/30

207.100.112.0/21
207.200.116.0/23
]]></programlisting>
	</section>
	<section id="key_exchanges">
	<title>key exchanges (SSL)</title>
	<para>
Persistence is required for SSL services, as keys are cached.
	</para>
	<para>
Francis Corouge wrote:
	</para>
	<blockquote>
		<para>
I made a LVS-DR lvs. All services work well,
but with IE 4.1 on secured connection, pages are received randomly.
when you make several requests, sometime the page is displayed,
but sometimes a popup error message is displayed
		</para>
<programlisting><![CDATA[
IE can't open your Internet Site <url>
An error occured with the secured connexion.
]]></programlisting>
		<para>
I did not test with other versions of IE, but netscape works fine.
It works when I connect directly to the realserver
(realserver disconnected from the LVS, and the VIP on the
realserver allowed to arp).
		</para>
	</blockquote>
	<para>
Julian
	</para>
	<para>
Is the https service created persistent
<emphasis>i.e.</emphasis> using <command>ipvsadm</command> -p ?
I assume the problem is in the way SSL is working: cached
keys, etc. Without persistence configured, the SSL connections break
when they hit another realserver.
It may be in the way the bugs are encoded.
It also depends on the how the how the
SSL requests are performed (which we don't know).
	</para>
	<para>
Notes from Peter Kese,
who implemented the first persistence (pcc)
(this is probably from 1999).
	</para>
	<para>
The PCC scheduling algorithm might
produce some imbalance of load on realservers. This happens
because the number of connections established by clients might
vary a lot. (There are some large companies for example, that use
only one IP address for accessing the internet. Or think about
what happens when a search engine comes to scan the web site in
order to index the pages.) On the other hand, the PCC scheduler
resolves some problems with certain protocols (<emphasis>e.g.</emphasis> FTP) so I
think it is good to have it.
	</para>
	<para>
and a comment about load balancing using pcc/ssl. (the problem:
once someone comes in from aol.com to one of the realservers, all
subsequent connections from aol.com will also go to the same
server) -
	</para>
	<para>
Lars (who about this time implemented persistence granularity, so this
might be from 1999 too).
	</para>
	<para>
Lets examine what happens now with SSL session comeing in from a
big proxy, like AOL. Since they are all from the same host, they
get forwarded to the same server - *thud*.
	</para>
	<para>
Now, SSL carries a "session id" which identifies all requests
from a browser.  This can be used to separate the multiple SSL
sessions, even if coming in from one big proxy, and load balance
them.
	</para>
	<para>
(unknown)
	</para>
	<blockquote>
SSL connections will not come from the same port, since the clients open
many of them at once, just like with normal http.
So would we be able to differentiate all the people coming from aol by
the port number?
	</blockquote>
	<para>
No. A client may open multiple SSL connections at once, which
obviously will not come from the same port - but I think they
will come in with the same SSL id.
	</para>
	<blockquote>
But like I said: really hard to get working, and even harder to get right ;-)
	</blockquote>
	<para>
Wensong
	</para>
	<para>
No, not really! As I know, the PCC (Persistent Client Connection)
scheduling in the LVS patch for kernel 2.2 can solve connection
affinity problem in SSL.
	</para>
	<para>
When a SSL connection is made (crypted with server's public key),
port 443 for secure Web servers and port 465 for secure mail
server, a key (session id) must be generated and exchanged
between the server and the client. The later connections from the
same client are granted by the server in the life span of the SSL
key.
	</para>
	<para>
So, the PCC scheduling can make sure that once SSL "session id"
is exchanged between the server and the client, the later
connections from the same client will be directed to the same
server in the life span of the SSL key.
	</para>
	<para>
However, I haven't tested it myself. I will download ApacheSSL
and test it sometime. Anyone who have tested or are going to test
it, please let me know the result, no matter it is good or bad.
:-)
	</para>
	<para>
(a bit later)
	</para>
	<blockquote>
I tested LVS with servers running Apache-SSL.
LVS uses the VS patch for kernel 2.2.9, and uses
the PCC scheduling. It worked without any problem.
	</blockquote>
	<para>
SSL is a little bit different.
	</para>
	<para>
In use, the client will send a connection request to the server.
The server will return a signed digital certificate. The client
then authenticates the certificate using the digital signature
and the public key of the CA.
	</para>
	<para>
If the certificate is not authentic the connection is dropped. If
it is authentic then the client sends a session key (such as a)
and encrypts the data using the servers public key. This ensures
only the server can read it since decrypting requires knowing the
server private key.  The server sends its session key (such as b)
and encrypts with its private key, the client decrypt it with
server's public key and get b.
	</para>
	<para>
Since both the client and the server get a and b, they can
generate the same session key based on a and b. Once they have
the session key, they can use this to encrypt and decrypt data in
communication. Since the data sent between the client and server
is encrypted, it can't be read by anyone else.
	</para>
	<para>
Since the key exchange and generating is very time-consuming, for
performance reasons, once the SSL session key is exchanged and
generated in a TCP connection, other TCP connections can also use
this session key between the client and the server in the
life-span of the key.
	</para>
	<para>
So, we have make the connections from the same client is sent to
the same server in the life-span of the key. That's why the PCC
scheduling is used here.
	</para>
	</section>
	<section id="about_longer_timeouts">
	<title>About longer timeouts</title>
	<para>
felix k sheng <emphasis>felix (at) deasil (dot) com</emphasis> and Ted Pavlic
	</para>
	<blockquote>
		<para>
2. The PCC feature....can I set the permanent connection for something
else than the default value ( I need to maintain the client on the same server
for 30 minutes at maximum) ?
		</para>
		<para>
If people connecting to your application will contact your web server at
least once every five minutes, setting that value to five minutes is fine.
If you expect people to be idle for up to thirty minutes before contacting
the server again, then feel free to change it to thirty minutes. Basically
remember that the clock is reset every time they contact the server again.
Persistence lasts for as long as it's needed. It only dies after the amount
of seconds in that value passes without a connection from that address.
		</para>
		<para>
So if you really want to change it to thirty minutes, check out
ip_vs_pcc.h -- there should be a constant that defines how many seconds to
keep the entry in the table. (I don't have access to a machine with IPVS on
it at this location for me to give you anything more precise)
		</para>
	</blockquote>
	<para>
I think this 30 minute idea is a web specific time out period.
That is, default timeout's for <link linkend="cookie">cookies</link> are 30 minutes,
so many web sites use that value as the length of a given web "session".
So if a user hits your site, stops and does nothing for 29
minutes, and then hits your site again, most places will consider
that the same session - the same session cookies will still be in
place.  So it would probably be a nice to have them going to the
same server.
	</para>
	</section>
	<section id="passive_ftp_persistence">
	<title>passive ftp and persistence</title>
	<para>
Wensong
	</para>
	<para>
Since there are many messages about passive ftp problem and
sticky connection problem, I'd better send a separate message to
make it clear.
	</para><para>
In LinuxDirector (by default), we have assumed that each network
connection is independent of every other connection, so that each
connection can be assigned to a server independently of any past,
present or future assignments. However, there are times that two
connections from the same client must be assigned to the same
server either for functional or for performance reasons.
	</para><para>
FTP is an example for a functional requirement for connection
affinity.  The client establishs two connections to the server,
one is a control connection (port 21) to exchange command
information, the other is a data connection (usually port 20)
that transfer bulk data. For active FTP, the client informs the
server the port that it listens to, the data connection is
initiated by the server from the server's port 20 and the
client's port. LinuxDirector could examine the packet coming from
clients for the port that client listens to, and create any entry
in the hash table for the coming data connection. But for passive
FTP, the server tells the clients the port that it listens to,
the client initiates the data connection connectint to that port.
For the LVS-Tunneling and the LVS-DRouting, LinuxDirector is only
on the client-to-server half connection, so it is imposssible for
LinuxDirector to get the port from the packet that goes to the
client directly.
	</para><para>
SSL (Secure Socket Layer) is an example of a protocol that has
connection affinity between a given client and a particular
server.  When a SSL connection is made, port 443 for secure Web
servers and port 465 for secure mail server, a key for the
connection must be chosen and exchanged. The later connections
from the same client are granted by the server in the life span
of the SSL key.
	</para><para>
Our current solution to client affinity is to add persistent
client connection scheduling in LinuxDirector. In the PCC
scheduling, when a client first access the service, LinuxDirector
will create a connection template between the give client and the
selected server, then create an entry for the connection in the
hash table. The template expires in a configurable time, and the
template won't expire if it has its connections. The connections
for any port from the client will send to the server before the
template expires. Although the PCC scheduling may cause slight
load imbalance among servers, it is a good solution to connection
affinity.
	</para>
	<para>
The configuration example of PCC scheduling is as follows:
	</para>
<programlisting><![CDATA[
director:/etc/lvs# ipvsadm -A -t <VIP>:0 -s pcc
director:/etc/lvs# ipvsadm -a -t <VIP>:0 -R <your server>
]]></programlisting>
	<para>
BTW, PCC should not be considered as a scheduling algorithm in
concept. It should be a feature of virtual service port, the port
is persistent or not. I will write some codes later to let user
to specify whether port is persistent or not.
	</para>
	</section>
	<section id="port_0">
	<title>The Persistence Template (about port 0)</title>
	<note>
Information about a persistent connection is stored in the Persistence Template.
The essential difference between the Persistence Template and a hash table
entry is that the source port from the client is marked as 0 
(<emphasis>i.e.</emphasis>CIP:0).
Thanks to Karl Kopper for off-line discussions which got me started here.
	</note>
	<para>
Horms 06 May 2004
	</para>
	<para>
A persistance template is just like a connection entry.
It uses the same data structure. It is stored in
the same hash table. The only difference is that the source
port is set to 0 (<emphasis>i.e.</emphasis> CIP:0) 
so that the data can be identified as a persistance
template. This means that it will never match a hash-table lookup
for a connection entry. And a connection entry will never
match a lookup for a persistance template which is made in
the scheduling code.
	</para>
	<para>
The purpose of a persistance template is, in a nutshell, to 
effect persistance. When a connection is started for a persistant
virtual service, the persistance template is looked up. If it 
exists then it is used - that is the connection will be forwarded
to the same realserver as the previous corresponding connection.
Otherwise the connection is scheduled, just like a connection for 
a non-persistant virtual service, and the persistance template is
created.
	</para>
	<para>
Like connection entries, persistance templates have timeouts.
Actually, again, it is handled by the same code. The only difference
is that for persistance templates, the timeout is set by the
persistance timeout configured using ipvsadm. Whereas for connection
entries the timeout depends on the connection's state.
	</para>
	<blockquote>
Let's say I make VIP:https persistent. There will be an entry in
the hash table for VIP:https and another entry for VIP:0 in the
persistence template. 
	</blockquote>
	<para>
No. When a connection from an enduser with CIP1 comes in then a
persistance template will be created for CIP:0 (a port that doesn't
exist). A Connection entry will
also be made for CIP:ephemeral_source_port (<emphasis>i.e.</emphasis>
the real port &gt;1023 that the client is coming from).
	</para>
	<blockquote>	
How does ipvsadm know to make only VIP:https persistent?
	</blockquote>
	<para>
I am not sure that I understand what you are getting at here.
When you configure a virtual service using ipvsadm you can mark 
it as persistant. This sets a flag in the kernel for the virtual service
that is checked by the LVS scheduler so it knows whether to treat
the connection as persistant or not.
	</para>
	<blockquote>
what happens if you use ipvsadm to enter persistence on all
ports (ie VIP:0). Now you have a connection table entry with VIP:0 
and a persistence template entry with CIP:0 and VIP:0?
	</blockquote>
	<para>
I could check the code, but I don't really think there is a problem at
all. The virtual service entry may have VIP:0, but the connecion
entry (and persistance tepmpate) that is created will have VIP:XXX,
where XXX is the destination port for the connection, which will be
the same as the destination port in the connection.
	</para>
	<para>
All the connection entries and persistance templates are stored in a
hash table. To retrieve an entry from the hash table, first the hash key
is generated (how is not particularly relevant here) and then that
bucket is searched for the matching entry. A match checks various values
including the source port.  As the following property is true, a
persistance template can never be confused with a connection entry:
	</para>
<programlisting><![CDATA[
Persistance Template: Source Port = 0
Connection Entry:     0 > Source Port > 2^16-1
]]></programlisting>
	<para>
In other words. If you are looking for a persistance template then
your search will always be for something with Source Port = 0.
But if you are looking for a connection entry you will always
be looking for something with Source Port != 0.
	</para>
	<para>
Thus there is no ambiguity, despite both types of entries using
the same data structure and being stored in the same hash table.
	</para>
<programlisting><![CDATA[
New Connection comes in
look up Virtual Service
is Virtual Service persistant?
   No  -> call Scheduler to allocate a RealServer for the Connection.
          use result from Scheduler to create Connection Entry
   Yes -> does Persistance Template exist?
          No  -> call Scheduler to allocate a RealServer for the Connection.
                 use result from Scheduler to create Persistance Template.
          now Persistence Template exists.
          nothing special to do.
          use Persistance Template to create Connection Entry
forward packet using Connection Entry
]]></programlisting>
	<para>
Just think of persistence templates as special connection entries. 
Special entries effect which realserver
subsequent connections from a given end user are allocated to.
Rather than effecting which server packets for a current connection
are sent to.
	</para>
	<para>
Timeouts just handle how long a connection entry or persistance template
are valid for. Else they would live in the kernel forever.
	</para>
	<para>
Guy Waugh, Nov 18, 2003
	</para>
	<blockquote>
		<para>
In my LVS-NAT system (IPVS-1.0.9 + ldirectord), I have an Oracle server on
the inside (web-db1) that primarily services the two realservers within the
LVS. However, I also have a webserver (www1) on the VIP side of the network
whose apache processes make Oracle connections through to the Oracle server
on the inside of the LVS. To allow this, I have the Oracle listener service
(port 1521) as an LVS service, with persistence set to 25200 seconds (7
hours).
		</para>
		<para>
I'm noticing a couple of different types of connections from www1 to the
Oracle listener port on the VIP: one with a source port of 0, and one with
a random source port, like so (the VIP is 'learn'):
 		</para>
<programlisting><![CDATA[
[root@lvs1 gwaugh]# ipvsadm -Lc
IPVS connection entries
pro expire state       source    virtual     destination
TCP 419:41 NONE        www1:0    learn:152   web-db1:1521
TCP 01:38  TIME_WAIT   www1:2509 learn:1521  web-db1:1521
TCP 01:43  TIME_WAIT   www1:2560 learn:1521  web-db1:1521
]]></programlisting>
		<para>
Connections with a source port of 0 take on the persistence of 25200
seconds (as I have specified in ldirectord.cf), but connections out of a
non-zero source port take on a persistence of 15 minutes (900 seconds). I
see from
http://www.austintek.com/LVS/LVS-HOWTO/HOWTO/LVS-HOWTO.persistent_connection.html
that:
		</para>
		<itemizedlist>
			<listitem>
For LVS persistence, the client is recognised by its IP (CIP) or in
recent versions of ip_vs, by CIP:dst_port (i.e. by the CIP and the port
being forwarded by the LVS). If only the CIP is used to schedule
persistence, then the entries in the output of ipvsadm will be of the form
VIP:0 (i.e. with port=0), otherwise the output of ipvsadm will be of the
form VIP:port.
			</listitem>
		</itemizedlist>
		<para>
Can anyone tell me why I get both types of connections (source port 0 and
source port non-zero)? Perhaps the 'source port 0' connection is some sort
of 'master' connection, and the 'source port non-zero' connections are some
sort of 'slave' connections?
 		</para>
		<para>
What I'm really wondering is if it is possible to effectively make the
persistence for this connection infinite? Perhaps I shouldn't use LVS to do
this, but should use iptables instead...?
 		</para>
		<para>
The problem underlying all this is that some apache processes on www1 seem
to lose their Oracle connection over time, so any client hitting www1 who
happens to get serviced by an apache process that has lost its Oracle
connection gets Oracle connection errors all over the page. I see from
http://www.austintek.com/LVS/LVS-HOWTO/HOWTO/LVS-HOWTO.services.single-port.html#tcpip_idle_timeout
that one can set TCP idle timeouts for connections with ipvsadm - perhaps
this is what I should be doing?
		</para>
	</blockquote>
	<para>
Horms 18 Nov 2003
	</para>
	<para>
I think that you are confused between the concept of persistance and
connection-timeouts. Persistance effects which realserver LVS will
choose for new connections. If persistance is in effect and the
persistant-timeout has not expired then the same realserver will
be used for subsequent connections from the same CIP. But in
your case you only have one realserver so persistance is a moot point.
	<para>
	</para>
You are correct in asserting that the CIP:0 entry you see
is a master entry. Actually in the code it is refered to as a template.
When a new connection comes in LVS looks for VIP:Vport+CIP:0. If it is present
then it will use the attached RIP:Rport. If not it just chooses
one of the available realservers as per the scheduling algorithm
that is in effect. But again this is a moot point, as you only have
one realserver.
	</para>
	<para>
The CIP:0 entry does not acctually represent
a connection at all. Just a template for creating new connections. Its
timeout should be set to the persistance-timeout each time the template
is used to create a new connection.
	</para>
	<para>
The other entries are the connections themselves. Their timeouts
are set by the various timeouts that can be manipulated through
/proc/sys/net/ipv4/vs/timeout_*. This is where the value of
900 seconds comes from. __It has nothing to do with persistancy__
	</para>
	<para>
As per the HOWTO entry you listed above, some of these values can
also be manipulated using <command>ipvsadm --set</command>
	</para>
	</section>
	<section id="persistent_clients_behind_a_proxy">
	<title>persistent clients behind a proxy or nat box</title>
	<para>
Jan Bruvoll 15 Aug 2005
	</para>
	<blockquote>
		<para>
I need to take a realserver out from one of my VS configs temporarily,
and I have tried doing this by setting the weight of this particular
realserver to 0. However, nothing is happening - the server is still
receiving connections as before I made the adjustment.
However, since I issued the
command the number of active connections has actually increased, much in
line with the distribution across the other servers in the same group,
leading me to think that the config hasn't kicked in at all (the number
of connections still seems very much like a weight of 5 is still active...)
I've tried setting the persistence for this particular
group to 5 seconds, without any noticeable effect.
		</para>
	</blockquote>
	<para>
Joe
	</para>
	<para>
Once they're connected they're connected, it doesn't matter what the timeout is.
Still the number of connections shouldn't increase after you've changed the
weight to 0.
	</para>
	<blockquote>
Hm ok - my reasoning for doing that is that these clients are relatively
long-lived SSL-based connection from an in-house application to our
server park - and that by setting the persistence to 5 seconds, only
connections that "come back" within 5 seconds of disconnecting from this
particular server (for whatever reason - Apache timeout, client
disconnection, network problems, etc.) would be directed to the same
server - if not, they would then hopefully be directed to one of the
servers with weight>0
	</blockquote>
	<para>
Horms
	</para>
	<para>
This is a fairly simple problem, that is unfortunately difficult to
explain. Let me try:
	</para>
	<para>
When you set a real server to be quiescent (weight=0), this means that
no new connections will be allocated to that real server using the
scheduler. However, if you have persistance in effect (which you do),
and a new connection is recieved from a end-user that recently made a
connection, then that connection will be allocated to the same
real server as the previous connection. The trick is, this process
by-passes the scheduler, and thus by-passes quiescence.
	</para>
	<para>
So, for a persistant service a new connection is processed a bit like this:
	</para>
<programlisting><![CDATA[
if (same end-user as a recent connection)
        use the real-server of that connection
else
        choose non-quiecent real-server using scheduler
]]></programlisting>
	<para>
Obviously this is a bit of a problem, for the reason you describe in
your email. In implementation terms the problem is that when
a connection for a persistant service is scheduled, a persistant
template is created, with a timeout of the persitant timeout.
This template is then used to select the real-server for
subsequent connections from the same end-user. It stays
in effect until its timeout expires. And its timeout is
renewed everytime a packet is recieved for an associated
connection. Which means in the case of quiesence, as long
as end-users that have active persistance templates keep
connecting or sending packaets within the persistance timeout,
the real-server will keep having connections.
	</para>
	<para>
The solution to this is quite simple. The patch at the URL below, which
has been included in recent kernel versions, adds
<filename>expire_quiescent_template</filename> to <filename>/proc</filename>
(see <xref linkend="new_persistence"/>). By default it is set to 0, which
gives the behaviour discribed above, the historical behaviour of LVS
(which I might add can be desirable in some situations). However, if you
set it to 1, then connection templates associated with a quiesced
real-server are expired, at lookup time.  Which, in a nutshell means
that the "if" condition above will always fall through the the "else"
clause, and thus quiescence is not by-passed.
	</para>
	<para>
To effect this change just run the following as root
	</para>
<programlisting><![CDATA[
echo 1 > /proc/sys/net/ipv4/vs/expire_quiescent_template
]]></programlisting>
	<para>
The change effect new connections immediately.
	</para>
	<para>
Or, on systems that have sysctl, add the following 
http://archive.linuxvirtualserver.org/html/lvs-users/2004-02/msg00224.html to
<filename>/etc/sysctl.conf</filename>
and run
	</para>
<programlisting><![CDATA[
sysctl -p net/ipv4/vs/expire_quiescent_template= 1
]]></programlisting>
	<para>
This will also take effect immediately, and has the advantage that
the change will be persistant across reboots.
	</para>	
	<para>
Jan
	</para>
	<blockquote>
		<para>
Let me just check if I
understand this correctly (using our current set-up):
		</para>
		<para>
Our original persistence was set to 360 seconds, intended to be
longer than the expected recurring request frequency of our application,
which checks with our server cluster every 300 seconds ("ish").
If I keep the original persistence, any client already known to the
cluster requesting data from the cluster again -before- the 360 seconds
expire of that particular client "id", will trigger a persistence
counter reset for this client
		</para>
	</blockquote>
	<para>
Horms
	</para>
	<para>
Yes. The request could be opening a fresh connection. Or it could be
the end-user sending (for any LVS forwarding meachism) or recieving (in
the case of LVS-NAT) data for an existing connection.
You can see the persistance teplates, and the progress of their
timeouts, in amongst other connection entries if you run <command>ipvsadm -Lcn</command>.
The persistance entries are the one with a client port of 0.
	</para>
	<para>
Jan
	</para>
	<blockquote>
		<para>
However,
if the weight for a particular real-server is set to 0, no -new-
clients should be allocated to this realserver
		</para>
	</blockquote>
	<para>
Horms
	</para>
	<para>

Yes, where new clients are one without a persistance template entry.
	</para>
	<para>
Jan
	</para>
	<blockquote>
		<para>
and any clients not "coming back" within the 360 seconds should be
removed from the persistence map, and any new requests from same clients
after being removed should be allocated to one of the other realservers
		</para>
	</blockquote>
	<para>
Horms
	</para>
	<para>
Yes. Though "going away" basically means no packets for existing
connections, and no attempt to open a new connection.
	</para>
	<para>
Jan
	</para>
	<blockquote>	
		<para>
since writing, I tried resetting the persistence manually to 5
seconds, in order to try and flush the persistence "map" quicker. This
hasn't had any perceivable effect, as the number of connections to this
server as I am writing now, still reflects the original weight (some 18
hours after setting the weight to 0).
		</para>
	</blockquote>
	<para>
Horms
	</para>
	<para>
Ok, obviously waiting 18 hours for connections to flush is impractical.
What you are seeing is probably the result of either a bug in lvs,
or very entusiastic end-users (i know they are just programmes, but hey),
that send packets or recieve packets from the virtual service (and thus
the real servers) at least once every 5 seconds.
Some examintion of what is happening should
shed some light on this: <command>watch -n 1 ipvsadm -Lcn</command>
	</para>
	<para>
Jan
	</para>
	<blockquote>
		<para>
how can it be that the number of active connections actually
increases on the realserver whose weight is 0?
		</para>
	</blockquote>
	<para>
Horms
	</para>
	<para>
This is quite possible if a known (i.e. has a persistance template
because it has sent or received data within the last 5 seconds (your
timeout)) end-user opens a second connection, and no connections are
closed. I'm not sure if this is actually what is happening, again
ipvsadm -Lcn may help to show what is going on.
	</para>
	<para>
What you are seeing is a bit strange, and hopefully you can diagnose
exactly what is going on. But please consider setting 
<filename>/proc/sys/net/ipv4/vs/expire_quiescent_template</filename> to 1, as
it should give behaviour that better suits your needs.
	</para>
	<para>
Jan
	</para>
	<blockquote>
		<para>
Dawning suspicion here - if a connection some time ago triggered the
creation of a persistance template, with the 360 seconds template, that
template would actually stick around for as long as this client comes
back to access the cluster - i.e. if I change the persistance of the
virtualserver to, say, 5 seconds, that would only apply to -new-
connections from clients previously "unknown" to the cluster, and the
already existing template could only expire if the client goes away for
more than 360 seconds, the original timeout?
		</para>
		<para>
Actually, I've given this some thought and I think I understand why this
number can increase - it is ip address specific only, so if new clients
appear from behind an ip that is currently "active", i.e. has a
persistance template allocated to it, these would also be allocated to
the already quiesced server. So, although I have assigned a weight of 0,
the persistence templates wouldn't expire until all traffic subsides and
goes away for longer than \$persistence seconds after the last
connection closed. Cumbersome, but at least I can understand what's
going on.
		</para>
	</blockquote>
	<para>
Joe
	</para>
	<para>
a bunch of different clients are coming out of a NAT box? like the AOL
<xref linkend="proxy_farm"/> problem?
	</para>
	<blockquote>
Well - similar, but not as acute a scale. In this case we're talking
about a client talking HTTPS to our servers, and several users behind
the same broadband connection (typically at home), or several users
behind the same leased line at work, could be connecting - and thus get
caught in the same "bucket".
	</blockquote>
	<para>
Horms
	</para>
	<para>
Good point, yes I am pretty sure that is how it works.
	</para>
	<blockquote>
		<para>
While I am at it; this seems a little odd, given that I have never set
anything but persistances of either 360 seconds or 5 seconds:
		</para>
<programlisting><![CDATA[
app-2 ~ # ipvsadm -Lcn|grep 10.42.0.202|grep x.y.z.w
TCP 01:02  NONE        x.y.z.w:0   ext-ip:443 10.42.0.202:443
TCP 10:32  ESTABLISHED x.y.z.w:4254 ext-ip:443 10.42.0.202:443
]]></programlisting>
		<para>
How should i interpret that ~10 minutes expire timeout? (I have "worse"
ones too, all the way up to close to 20 minutes)
		</para>
	</blockquote>
	<para>
Horms
	</para>
	<para>
I'm not sure, but its probably not a problem as once the
connection changes out of the ESTABLISHED state, a fresh timeout
will be assigned.
	</para>
	</section>
	<section id="rogue_clients_hidden_behind_persistence">
	<title>Rogue clients hidden by persistence</title>
	<para>
Leon Keijser <emphasis>errtu (at) gmx (dot) net</emphasis> 14 Dec 2005
	</para>
	<blockquote>
		<para>
This morning when i did a 'ipvsadm -ln' i saw something weird:
		</para>
<programlisting><![CDATA[
rpzlvs01 root # ipvsadm -ln
IP Virtual Server version 1.2.1 (size=4096)
Prot LocalAddress:Port Scheduler Flags
  -> RemoteAddress:Port           Forward Weight ActiveConn InActConn
TCP  192.168.50.10:3389 wlc persistent 43200
  -> 192.168.50.12:3389           Route   1      912        0         
  -> 192.168.50.15:3389           Route   1      22         0         
  -> 192.168.50.13:3389           Route   1      22         0         
  -> 192.168.50.16:3389           Route   1      21         0         
  -> 192.168.50.11:3389           Route   1      20         1         
  -> 192.168.50.18:3389           Route   1      21         0         
  -> 192.168.50.17:3389           Route   1      624        0         
TCP  192.168.50.120:1494 wlc persistent 43200
  -> 192.168.50.121:1494          Route   1      2          0         
  -> 192.168.50.122:1494          Route   1      3          0         
TCP  192.168.51.202:22 wlc
  -> 127.0.0.1:22                 Local   1      0          0        
]]></programlisting>
		<para>
912 and 624 connections? 
When I check on the realserver, everything seems normal. 
I have 8 clients on one server, 30 on another, 
but maybe this is because LVS is thinking it already
has 900+ connections, and shouldn't route anyone to there anymore.
The logfiles don't show anything abnormal either. 
		</para>
	</blockquote>
	<para>
Graeme Fowler <emphasis>graeme (at) graemef (dot) net</emphasis>
	</para>
	<para>
You're using persistence, which is probably a clue...
What does <emphasis>ipvsadm -Lnc</emphasis> tell you? i
That'll list the connections out so 
you should be able to see which clients are causing you the problem. 
You can grep the output for "ESTABLISHED" and/or "NONE" to see the 
active and persistent entries respectively.
	</para>
	<blockquote>
Yep. I saw 2 IP's that occur several times (okay, several hundred times)
	</blockquote>
	<para>
bear in mind that they may not be *your* clients. This could in 
theory at least be caused by something rogue.
	</para>
	<blockquote>
Unfortunately they are my clients. And they are the linux-based thin clients I deployed
as a side project. Turned out that they were hardcoded to use one of our
domain controllers (which died yesterday night), and kept trying to connect
to the cluster.
	</blockquote>
	<para>
I'd guess you have a machine (or more than one) in your client base 
which is broken in some way. Which way I'll leave to you to find, but 
as these are RDP connections and the most likely clients are Windows 
machines...
	</para>
	<blockquote>
Found them. Fixed them. 
	</blockquote>
	</section>
	<section id="really_long_persistence">
	<title>Long (1 day) persistence to windows terminal servers</title>
	<para>
Here I summarise a lengthy exchange with 
Joseph T. Duncan <emphasis>duncan (at) engr (dot) orst (dot) edu</emphasis>
starting at 
http://marc.theaimsgroup.com/?l=linux-virtual-server&amp;m=115706140606154&amp;w=2 
on 30 Aug 2006.
Joseph uses <xref linkend="duncan_snmp"/> to monitor his LVS. 
	</para>
	<para>
Joseph's realservers are windows boxes at a university
which serve any window app at all (<emphasis>e.g.</emphasis> statistics, word processing). 
Undergraduate students are mostly interactive doing homework, 
while faculty and grad students start lengthy jobs and return later.
	</para>
	<para>
The user can 
	</para>
	<itemizedlist>
		<listitem>
logout of the real server, real server then closes all of their applications, stops their desktop
session from running and correctly does a finack packet exchange ending the session.
		</listitem>
		<listitem>
			<para>
'disconnect' (a windows option) from the realserver, 
the realserver puts their session in a disconnected state. 
Their desktop and application are still running. 
a finack packet exchange happens ending that tcp connection. 
After 10 minutes (adjustable) the realserver auto-logs off any 'disconnected'
sessions, shuts the applications down and kills the desktop. 
This is called a clean disconnect.
			</para>
			<para>
if the client reconnects in this 10 minute window, the director should point them back at their
disconnected session. the real server will then give them their running desktop and applications
back.
			</para>
			<para>
if the client reconnects after the 10 minute window, the director should balance them as a new
session since they no longer have a desktop+applications running on any realserver 
			</para>
		</listitem>
		<listitem>
			<para>
The client shuts down and/or closes inappropriately the real server sits there, leaves the desktop
and applications active. now here is were weirdness happens.
			</para>
			<itemizedlist>
				<listitem>
In testing, if the client computer is a linux box and is still accessible, 
the realserver will close out the connection
(broken connection tcp handshake attempt? handled correctly?)
				</listitem>
				<listitem>
In testing, if the client computer is any of windows xp workstations my department maintains, 
iis still accessible or becomes accessible later 
(reboot, powered down and then back on later, etc), 
the realserver will close out the connection 
(broken connection tcp handshake attempt? handled correctly?)
				</listitem>
				<listitem>
					<para>
If the client computer is the weird 1/3 of my customer's home/office/whatever computer 
(ones with who knows what on them, or how they are configured) 
the desktop+apps just sit there running on the realserver and with no closing of the connection. 
There is an idle session autologout after x time setting on the realservers
(here 1day) and
the realserver kills off the active session (but idle connection) desktop+applications.
					</para>
					<para>
These clients are the troublesome ones, because if they login a few times, 
they will wind up with a active but idle desktop+application session on each realserver.
Two bad things happen.
					</para>
					<itemizedlist>
						<listitem>
applications can be running full bore (think long batch type jobs.. and use a 100% of a cpu, 
user processes are limited to a single cpu on the realservers, 
with 4 cpus avalible per real server) this isn't bad, 
but come finals week, each user could be eating up a cpu.
						</listitem>
						<listitem>
last write wins.. if a client had something open in the orphaned session on a realserver. 
Then gets a new desktop session on an different realserver, 
makes changes to a document, logs out correctly,
then the orphaned session dies/closes.. 
they might loose work, or have their windows profile corrupted.
						</listitem>
					</itemizedlist>
					<para>
The terminal server session/application does not know weather a disconnect is clean or not. 
All it does is start recording idle time from the last keyboard/mouse input received
Applications running inside the terminal server session (<emphasis>e.g.</emphasis> m$ word) 
usually have no idea whether they're running on a desktop or a terminal server.
					</para>
					<para>
I could make the active but idle timeout on the realservers much lower,
but that would lead to unhappy proffessors that stay logged in overnight.
					</para>
					<para>
It's not easy to look for idle sessions (to kill them).
I don't know how to test for an idle connection on the director.
There is a windows management tool that reports idle time, 
but I am not aware of mib/snmp way to export that information.
There are some wireless labs behind a nat-proxy and they
all come out on the same 10.x.x.x IP, so you can't test
for multiple connections from the same IP.
					</para>
				</listitem>
			</itemizedlist>
		</listitem>
	</itemizedlist>
	<para>
Microsoft has a built in "network load balancing" based purely on network traffic between boxes. 
To make it more robust, they have something called "session directory" that up an
authentication/identification will redirect an incoming comm to the approprate box 
in the "network load balanceing cluster"
	</para>
	<para>
This style of load balanceing is fine for certain applications, 
and is closer to an L7 approach as your session location is determined by your login/id, 
instead of your IP.
	</para>
	<para>
This method relies on lots of bandwidth. 
Each box participating in a "network load balanceing" setup receives a copy of everything 
and has to pick out what it's going to proccess... 
(all machines participating get a fake slaved mac address and ip shared
between them)(shared mac address being m$'s solution to the arp problem?? i dunno)
	</para>
	<para>
However for terminal servers it is no good.. 
I need to account for %free cpu and %free memory as important metics. 
(<emphasis>e.g. </emphasis> with 1 realserver at 400% load (4xcpu@100%) 
and 30kbs network traffic with 4 users, 
another realserver with 80% load and 900kbs traffic with 10 users,
I would want new users to land on the lower cpu load server, 
as I am not really bandwidth bound till I get above 1gb/sec.
The windows way does not take any cpu/memory metrics into account.
	</para>
	<para>
When there is no LVS (<emphasis>i.e.</emphasis> a single terminal server,
if a user had a dirty exit then either at 1 day of idle time
they were killed off or if they reconnected, they got their session back.
Thus I need persistence of a little more than 1 day with LVS, 
to make sure they reconnect with their last realserver.
	</para>
	</section>
</section>
<section id="LVS-HOWTO.filter_rules" xreflabel="Running a firewall on the director">
<title>LVS: Running a firewall on the director: Interaction between LVS and netfilter (iptables).</title>
	<note>
		<para>
May 2004: This chapter has been rewritten. 
Before the arrival of the <xref linkend="antefacto_patches"/>, 
it was not possible to run arbitary 
<filename>iptables</filename> 
rules for ip_vs controlled packets on a director. 
Hence you couldn't run a firewall on the director
and we told people to put their firewall on a separate box.
Julian then took over writing the code 
and now it is possible to run a firewall on the director.
The code is now called <xref linkend="ipvs_nfct"/> and is still beta, 
so keep us informed of how it works.
In previous writeups, I misunderstood how the code worked,
and made some incorrect statements.
Hopefully this rewrite fixes the misinformation I propagated.
		</para>
		<para>
For one of many introductions to netfilter see
<ulink url="http://gnumonks.org/~laforge/presentations/netfilter-lk2000/netfilter.ps.gz">
The netfilter framework in Linux 2.4</ulink>
(http://gnumonks.org/~laforge/presentations/netfilter-lk2000/netfilter.ps.gz).
		</para>
		<para>
According to Ratz (18 Apr 2006), NFCT causes a 20% throughput drop on a GbE inbound service.
		</para>
	</note>
	<section id="start_with_no_filter_rules" xreflabel="start with no filter rules">
	<title>Start with no filter rules</title>
	<para>
Although this chapter is about applying <command>iptables</command> rules to directors,
be aware that you don't need filter rules to set up an LVS.
Misconfiguring the filter rules may cause strange effects.
Make sure for testing that you can turn your filter rules on and off.
Here's a cautionary tale.
	</para>
	<para>
Sebastiaan Tesink <emphasis>maillist-lvs (at) virtualconcepts (dot) nl</emphasis> 14 Jul 2006
	</para>
	<para>
On one of our clusters we have problems with ipvs at the moment. Our
cluster is built with 2 front-end failover ipvs-nodes (managed with
ldirectord), with 3 Apache back-end nodes, handling both http as well as
https. So all the traffic on a virtual ip on port 80 or 443 of the
front-end servers is redirected to the backend webservers.
	</para>
	<para>
Two weeks ago, we were running a 2.6.8-2-686-smp Debian stable kernel,
containing ipvs 1.2.0. We experienced weekly (6 to 8 days) server
crashes, which caused the machines to hang completely without any
log-information whatsoever. These crashes seemed to be related to IPVS,
since all our servers have the exact same configuration, except for the
additional ipvs-modules on the front-end servers. Additionally, the same
Dell SC1425 servers are used for all servers.
	</para>
	<para>
For this reason we upgraded our kernel to 2.6.16-2-686-smp (containing
ipvs 1.2.1) on Debian stable, which we installed from backports
(http://www.backports.org). There aren't any crashes on these machines
anymore. However, there are two strange things we noticed since this
upgrade. First of all, the number of active connections has increased
dramatically, from 1,200 with a 2.6.8-2-686-smp kernel, to well over
30,000 with the new kernel. We are handling the same amount of traffic.
	</para>
<programlisting><![CDATA[
# ipvsadm -L
IP Virtual Server version 1.2.1 (size=4096)
Prot LocalAddress:Port Scheduler Flags
  -> RemoteAddress:Port           Forward Weight ActiveConn InActConn
TCP  XXX.net wlc persistent 120
  -> apache1:https                  Route   10     2          0
  -> apache2:https                  Route   10     25         0
  -> apache3:https                  Route   10     14         0
TCP  XXX.net wlc persistent 120
  -> apache1:www                    Route   10     10928      13
  -> apache2:www                    Route   10     11433      6
  -> apache3:www                    Route   10     11764      10
]]></programlisting>

	<para>
We are using the following IPVS modules:
ip_vs
ip_vs_rr
ip_vs_wlc
	</para>
	<para>
Secondly, Internet Explorer users are experiencing problems exactly
since the upgrade to the new ipvs version. With Internet Explorer, an
enormous amount of tcp-connections is opened when visiting a website.
Users are experiencing high loads on their local machines, and crashing
Internet Explorers. With any version of FireFox this is working fine
by the way. Nevertheless, this started exactly since our IPVS upgrade.
	</para>
	<note>
Note IE/IIS breaks tcpip rules to make loading fast 
(see <ulink url="http://grotto11.com/blog/slash.html?+1039831658">
What makes IE so fast http://grotto11.com/blog/slash.html?+1039831658</ulink>
	</note>
	<para>
Sebastiaan Tesink <emphasis>sebas (at) virtualconcepts (dot) nl</emphasis> 19 Jun 2007
	</para>
	<para>
The solution to this
problem was relatively easy, but we only discovered it recently.
Basically, this problem was caused by the firewall, which contained
"state checks". We used to have the following iptable rule:
	</para>
<programlisting><![CDATA[
iptables -A INPUT -m state --state NEW -p tcp --dport 80 -j ACCEPT
]]></programlisting>
	<para>
While using IP_VS, this caused connections to be denied by the firewall. Therefore we changed this to:
	</para>
<programlisting><![CDATA[
iptables -A INPUT -p tcp --dport 80 -j ACCEPT
]]></programlisting>
	<para>
which leads to a more balanced view on the number of active versus inactive connections in the load balancer. Hopefully this is some useful information to get your documentation even better.
	</para>
	</section>
	<section id="filter_rules_intro">
	<title>Introduction</title>
	<para>
For 2.4.x kernels (and beyond), LVS was rewritten as a netfilter module, 
rather than as a piece of stand-alone kernel code.
Despite initial expectations by Rusty Russel that LVS could
be written as a loadable netfilter module, 
it turned out not to be possible to write LVS 
completely within the netfilter framework.
As well, there was a minor performance penalty (presumably in latency)
for LVS as a netfilter module compared to the original version.
This penalty has mostly gone with rewrites of the code.
	</para>
	<para>
The problem was in connection tracking, which among
other things allows the machine to determine if a
packet belongs to a RELATED or ESTABLISHED connection.
As well connection tracking helps with multiport protocols like FTP-NAT.
The ip_vs controlled packets take a different path
through the routing code than do non-LVS packets. 
The netfilter connection tracking doesn't know about the
ip_vs controlled packets.
Even if it did know about them, 
netfilter conntrack was considered too slow to use for LVS.
	</para>
	<para>
For LVS-DR and LVS-Tun, where the reply packets
do not go through the director, 
netfilter is not able to connection tracking on these packets at all.
The <xref linkend="antefacto_patches"/> were written to
allow connection tracking of ip_vs controlled packets for LVS-NAT.
Connection tracking for ip_vs with LVS-DR or LVS-Tun was not attempted.
The ipvs_nfct code now allows conntrack for LVS-DR and LVS-Tun.
        </para>
        <para>
Julian
        </para>
        <para>
You can (and always have been able to) use firewall rules
that match by device, proto, port or IP,
without using <xref linkend="ipvs_nfct"/>.
        </para>
	<para>
Julian 16 Mar 2007 
	</para>
	<para>
	The NFCT patch is not a way to use iptables NAT rules, it just
provides iptables -m state support for IPVS packets.
	</para>
	<para>
	snat_reroute is only for IPVS packets. I just added some information
in HOWTO.txt (http://www.ssi.bg/~ja/nfct/HOWTO.txt). SNAT: translate
source address. Reroute: call output routing for 2nd time (saddr=VIP),
first was the normal input routing for saddr=RIP.
	</para>
	</section>
	<section id="path_of_an_ip_vs_packet" xreflabel="path of an ip_vs packet">
	<title>Path of an ip_vs controlled packet</title>
	<para>
Horms <emphasis>horms (at) verge (dot) net (dot) au</emphasis> 19 May 2004
	</para>
	<para>
here is my understanding of the way that the Netfilter Hooks
and LVS fit together.
	</para>
	<figure align="right">
	<title>
Interaction of LVS with Netfilter
	</title>
	<mediaobject align="center">
		<imageobject>
			<imagedata fileref="images/nf-lvs.png" format="png"
					scalefit="0"
					align="right"
					srccredit="Horms (C) 2004">
			</imagedata>
		</imageobject>
		<textobject>
<phrase>interactions between netfilter and LVS.</phrase>
		</textobject>
		<caption>
			<para>
The location of LVS hooks into the netfilter framework on the director.
			</para>
			<para>
Packets travel from left to right. A packet coming from the client
enters on the left and exits on the right heading for the realserver.
A reply from the realserver (in the case of LVS-NAT) enters on the left 
and exits on the right heading for the client. 
For normal LVS-DR and LVS-Tun
operation (see the <xref linkend="martian_modification"/>),
reply packets do not go through the director.
			</para>
			<itemizedlist>
				<listitem>
for incoming packets the path is:

<programlisting><![CDATA[
PREROUTING -> LOCAL_IN -> POSTROUTING
]]></programlisting>
				</listitem>
				<listitem>
for outgoing packets (only LVS-NAT):

<programlisting><![CDATA[
PREROUTING -> FORWARD -> POSTROUTING
]]></programlisting>
				</listitem>
				<listitem>
for incoming ICMP:

<programlisting><![CDATA[
PREROUTING -> FORWARD -> POSTROUTING
]]></programlisting>
				</listitem>
			</itemizedlist>
		</caption>
	</mediaobject>
	</figure>
	<para>
When the director receives a packet,
it goes through PREROUTING where Routing decides
that the packet is local 
(usually because of the presence
of the VIP on a local interface). 
The packet is then sent to LOCAL_IN.
On the inbound direction, LVS hooks into LOCAL_IN. 
Modules register with a priority, the lowest priority
getting to look at the packets first.
LVS registers itself with a higher priority than iptables rules,
and thus iptables will get the packet first and then LVS.
	</para>
	<blockquote>
	<para>
Mike McLean <emphasis>mikem (at) redhat (dot) com</emphasis> 21 Oct 2002
	</para>
	<para>
	On the director, filter rules intercept packets before ip_vs sees them,
otherwise <xref linkend="LVS-HOWTO.fwmark"/> would not work
	</para>
	</blockquote>
	<para>
If LVS gets the packet and decides to forward it to a realserver,
the packet then magically ends up in the POSTROUTING chain.
	</para>
	<para>
LVS does not look for ingress packets in the FORWARD chain.
The only time that the FORWARD chain comes into play with LVS
is for return packets from realservers when LVS-NAT is in use.
This is where the packets get unNATed. Again LVS gets the
packets after any iptables FORWARDing rules.
	</para>
	<para>
<filename>ip_vs_in</filename> attaches to the LOCAL_IN hook.
For a packet to arrive at LOCAL_IN, the dst_addr has to
be an IP on a local interface (any interface <emphasis>e.g.</emphasis> eth0). 
The result of this requirement (that dst_addr is an IP on a local interface)
is that you still need the VIP on the director,
when accepting packets for LVS by VIP-less methods like fwmark or 
transparent proxy. (It would be nice to remove the requirement
for this otherwise non-functional VIP.) 
	</para>
	<para>
There are ways around the requirement for a local IP,
but they may create other problems as well.
	</para>
	<itemizedlist>
		<listitem>
move ip_vs_in from the LOCAL_IN hook to the PREROUTING hook. 
I tried that briefly once and it seemed to work. 
		</listitem>
		<listitem>
			<para>
play with routing rules to deliver the packet locally
<emphasis>e.g.</emphasis> <xref linkend="routing_intro"/> or Matt wrote:
			</para>
<programlisting><![CDATA[
http://marc.theaimsgroup.com/?l=linux-virtual-server&m=104265930914084&w=2

ip rule add prio 100 fwmark 1 table 100
ip route add local 0/0 dev lo table 100
]]></programlisting>
			<para>
or perhaps
			</para>
<programlisting><![CDATA[
VIP=10.0.0.1/32
ip rule add prio 100 to $VIP table 100
ip route add local 0/0 dev lo table 100
]]></programlisting>
			<para>
But I haven't tested either much.
There is an oblique reference to this on
http://www.linuxvirtualserver.org/docs/arp.html.
			</para>
		</listitem>
	</itemizedlist>
	<para>
If packets for the VIP (on say eth0) started arriving on another
interface (say eth1) due to dynamic routing, 
then LVS wouldn't care - the packet still arrives at LOCAL-IN. 
<filename>rp_filter</filename> would probably need to be disabled, 
and perhaps a few other routing tweaks, but fundamentally 
if the director could route the traffic (<emphasis>i.e.</emphasis>
get the packets), then LVS could load balance it. 
	</para>
	</section>
	<section id="netfilter_filtering" xreflabel="how to filter with netfilter">
	<title>how to filter with netfilter</title>     
	<note>
netfilter has several families of rules, <emphasis>e.g.</emphasis> NAT and filter. 
The filter rules filter, but do not alter, packets. 
Not all <filename>iptables</filename> commands are filter rules. 
	</note>
	<para>
For some background on filtering with netfilter, 
see the 
<ulink url="http://www.netfilter.org/documentation/HOWTO/netfilter-hacking-HOWTO.html">
Linux netfilter Hacking HOWTO</ulink>
(http://www.netfilter.org/documentation/HOWTO/netfilter-hacking-HOWTO.html).
Although <filename>iptables</filename> rules can be applied at any chain,
the filter rules are only applied at the LOCAL_IN, FORWARD and LOCAL_OUT
(see 
<ulink url="http://www.netfilter.org/documentation/HOWTO/netfilter-hacking-HOWTO-3.html#ss3.2">
Packet Selection: IP Tables</ulink>
http://www.netfilter.org/documentation/HOWTO/netfilter-hacking-HOWTO-3.html#ss3.2).
	</para>
	<para>
Horms: LOCAL_IN and LOCAL_OUT in the kernel correspond, more or less,
to INPUT and OUTPUT in <command>iptables</command>.
	</para>
	<para>
Since any packet only traverses one of these three chains, 
for any packet then, there is <emphasis>one and only one</emphasis> place 
to filter it. This is a change from <filename>ipchains</filename>, 
when you could filter a packet in several chains.
You can't filter in the other chains even if you want to.
	</para>
	<para>
Julian
	</para>
	<para>
by design you can filter only in these chains because
<filename>iptable_filter</filename> registers only there:
	</para>
<programlisting><![CDATA[
+ Netfilter hooks
  + LOCAL_IN Tables with different priority
    + filter
      + Chains
        - INPUT (and other chains used with -j CHAIN_NAME)
    + mangle
      + Chains
        - INPUT
]]></programlisting>
	<para>
we have hooks (places in the kernel stack) where each
table module attaches its chains with rules for packet matching.
It is a tree with multiple levels of lists.
Filtering never worked in the other chains.
Table "filter" has only chains INPUT, FORWARD
and OUTPUT, each used in the corresponding hook.
	</para>
	<para>
Horms
	</para>
	<para>
You can see how many packets and bytes a rule is effecting by running
	</para>
<programlisting><![CDATA[
iptables -t nat -L -v -n
iptables -L -v -n
]]></programlisting>
	</section>
	<section id="ipvs_nfct" xreflabel="ipvs netfilter connection tracking module, ipvs_nfct">
	<title>ipvs_nfct, netfilter connection tracking for ipvs</title>
	<para>
For some information on netfilter connection tracking (nfct) see
<ulink url="http://www.netfilter.org/documentation/HOWTO/netfilter-hacking-HOWTO.html">
Linux netfilter Hacking HOWTO</ulink>
(http://www.netfilter.org/documentation/HOWTO/netfilter-hacking-HOWTO.html).
	</para>	
	<para>
May 2004: Because ipvs changes the path of LVS controlled packets,
netfilter is not able to connection track them.
For LVS-NAT (and for LVS-DR/Tun when using the <filename>forward_shared</filename>
flag for the <xref linkend="martian_modification"/>),
packets in both directions go through the director, 
so it is possible to write replacement conntrack code
(<emphasis>e.g.</emphasis> <xref linkend="antefacto_patches"/>).
	</para>
	<para>
For LVS-DR, LVS-Tun, the return packets go directly from
the realserver to the client and do not go through the director.
You can infer the state of the connection using the same
mechanism (timeouts) by which the LVS-DR/LVS-Tun director has always
made decisions on the state of the connection 
(where connections are listed as ActiveConn and InActConn by <command>ipvsadm</command>).
There <filename>ip_vs</filename> assumes that connections
are setup and terminated in a normal manner.
The first implementations of <filename>ipvs</filename>
used the standard ivp4 timeouts to declare a state transition.
More recent implementations allow for a private set of timeout values 
for the ip_vs controlled connections (see <xref linkend="security_proc_filesystem"/>).
	</para>
	<para>
Joe - 29 Jan 2003
	</para>
	<blockquote>
There were some incompatibilities between LVS and netfilter
when running a director and firewall on the same box with 2.4.x?
	</blockquote>
	<para>
Julian
	</para>
	<para>
Yes, LVS and Netfilter use their own (separate) connection tracking
implementations.
The situation hasn't changed since I explained it January 2002.
If we are going to fix this, then changes in Netfilter
are required too, mostly in the routing usage. LVS has some
requirements for the connection state which are not present in
netfilter. I don't think it is good to move LVS to Netfilter
conntracking. And I still don't have enough time to think
about such big changes for LVS.
	</para>
	<para>
May 2004: Julian has written the <filename>ipvs_nfct</filename> module, 
which among other things, fakes the connection tracking for LVS-DR and LVS-Tun.
	</para>
	<para>
Julian's ipvs_nfct code
for LVS for 2.4 and 2.6 kernels are on his
<ulink url="http://www.ssi.bg/~ja/nfct/">
Netfilter Connection Tracking Support</ulink>
page (http://www.ssi.bg/~ja/nfct/).
This page is accessed from
<ulink url="http://www.ssi.bg/~ja/">Julian's software page</ulink>
(http://www.ssi.bg/~ja/) through "Linux IPVS tools and extensions:
IPVS Netfilter connection tracking support").
Because of the small demand for this functionality, this
code is one of Julian's lower priority projects.
	</para>
	<para>
Julian's HOWTO that comes with his patches states that the return
packets have to go through the director. In fact the patch works
for all LVS forwarding methods, but really is only useful for
LVS's in which the replies return through the director.
	</para>
	<para>
Julian
	</para>
	<para>	
I've uploaded the 2.6 
version of the NFCT patches, but they aren't tested.
ipvs_nfct matchs conntrack state
for IPVS connections, <emphasis>e.g.</emphasis> 
NEW, ESTABLISHED, RELATED.
	</para>
	<note>
Julian doesn't have a setup to test most of his code.
Any untested code from Julian that I've tried has worked first time.
	</note>
	<para>
The only problem is with the netfilter's non-official tcp window
tracking patch (which I haven't tested) that only works for NAT (I suspect).
Maybe some of the checks done in the tcp window
tracking patch require a bidirectional stream, so possibly it doesn't
work for the unidirectional LVS-DR or LVS-TUN connections,
<emphasis>i.e.</emphasis> when the director doesn't see the reply packets. 
In all other cases (LVS-NAT or bidirectional DR/TUN with forward_shared=1) 
	</para>
	<para>
For LVS-NAT, ip_vs forwards packets in both directions in the director.
For LVS-DR and LVS-TUN the replies are visible to the Netfilter firewall 
on the director if is the default gw for the realservers
(for LVS-DR this requires the <xref linkend="LVS-DR_director_default_gw"/>
or forward_shared patch).
Even if these reply packets are not part of the ipvs stream, 
they are forwarded, since forward_shared=1. 
For the Netfilter firewall, there is no difference in the forwarding method.
In all cases the incoming traffic is handled in LOCAL_IN and the replies in
FORWARD.
	</para>
	<para>
	IPVS always knows the conn state
(NEW/RELATED/ESTABLISHED), it is simply exported to
the netfilter conntracking. 
	</para>
	<para>
	The patch works for cases when the replies don't
go through the director, but in this case it is not very useful.
The main purpose of the patch is to match reply packets. 
For the request packets, the conntrack entry is confirmed, 
which can speedup the packet handling (I hope).
IPVS without NFCT drops the conntrack entry for each packet 
and allocates the conntrack entry again for the next packet.
	</para>
	<para>
With ipvs_nfct, each skb comes with skb->nfct attached. 
ipvs-nfct preserves this NFCT struct,
while the default IPVS drops it on skb free.
	</para>
	<para>
Joe
	</para>
	<blockquote>
      Your NFCT HOWTO with date 10 Apr 2004 (but internal date Sep 2003)
says that NFCT works for LVS-NAT and forward shared LVS-DR etc, but doesn't
say anything about LVS-DR, LVS-Tun
	</blockquote>
	<para>
non-NAT methods if forward_shared flag is used
	</para>
	<blockquote>
      I assume NFCT provides perfect conntrack for LVS when the replies
go through the director and hence you can you use all iptables commands
(eg ESTABLISHED). I assume RELATED will need helpers.
	</blockquote>
	<para>
        Yes, I'm just not sure for FTP for DR/TUN because ip_vs_ftp
is not used (for LVS-DR, ftp requires persistence). 
IIRC, without creating NF expectations we can not expect
to match FTP-DATA as RELATED.
	</para>
	<blockquote>
      For LVS-DR etc, your reply above seems to indicate that NFCT provides
conntrack for LVS-DR too, however your NFCT HOWTO doesn't mention it.
	</blockquote>
	<para>
        Yes, it does not mention for any restrictions but the
source has '- support for all forwarding methods, not only NAT'.
It is still beta software. As yet there hasn't been a lot
of interest in the code.
	</para>
	<blockquote>
       Is it OK to have a firewall on the director yet?
	</blockquote>
	<para>
        Yes, for simple ipchains-like rules. I can't be sure for more
advanced filtering rules that play with conntrack specific
data but if you use only device names, IPs, protos and ports
it should work.
ipvs works perfectly with netfilter as far as 
iptables filter rules are concerned.
	</para>
	<blockquote>
can the LVS director
now (with ipvs_nfct) can have any iptables command run on it, as if it were
a regular linux router?
Can I now expect to run any iptables command on an ipvs
virtual service stream and have it work like on a normal
linux box with an normal tcp/udp stream?
	</blockquote>
	<para>
Maybe not because the IPVS packets do not use the same
path through the network stack as other non-IPVS packets.
I can not guarantee complete compatibility
<emphasis>e.g</emphasis> you can do very
wrong things with using some NAT rules, for example, DNAT.
<filename>ipvs_nfct</filename> when added to ipvs gives you the ability to use
<filename>-m state</filename> and nothing more.
Now we can use <filename>-m state</filename>, with plain IPVS you can not
use <filename>-m state</filename>.
	</para>
	<blockquote>
what doesn't work with LVS-DR/Tun?
	</blockquote>
	<para>
	We support <filename>-m state</filename> for DR and TUN too. 
The only thing that doesn't work for DR and TUN is FTP-DATA.
	</para>
	<para>
Stephane Klein 26 Aug 2004
	</para>
	<blockquote>
		<para>
I installed your <filename>ipvs-nfct-2.4.26-1.diff</filename> patch,
I enabled the CONFIG_IP_VS_NFCT and recompiled the kernel.
Here are my rules to enable http service:
		</para>
<programlisting><![CDATA[
$IPTABLES -A INPUT -i eth1 -p tcp -m multiport -d $VIP --destination -port 80,21 -m state --state NEW -j RULE_2
$IPTABLES -A RULE_2 -j LOG --log-level info --log-prefix "RULE 2 -- > ACCEPT"
$IPTABLES -A RULE_2 -j ACCEPT
$IPTABLES -A FORWARD -p tcp -m state --state R,E -j ACCEPT
]]></programlisting>
	</blockquote>
	<para>
Julian
	</para>
	<para>
All out->in traffic passes INPUT (not FORWARD as in
netfilter), you can not allow only NEW packets. FORWARD is passed only for 
in->out traffic for NAT. Some iptables examples can be found at
<ulink url="http://www.ssi.bg/~ja/nfct/">the NFCT page</ulink>
(http://www.ssi.bg/~ja/nfct/").
You can also read about the netfilter hooks LVS uses here:
<ulink url="http://www.ssi.bg/~ja/LVS.txt">my LVS page</ulink>
(http://www.ssi.bg/~ja/LVS.txt).
	</para>
	<para>
"Vince W." <emphasis>listacct1 (at) lvwnet (dot) com</emphasis> 12 Feb 2005
	</para>
	<para>
How I successfully compiled 2.6.9 and .10 FC3 kernels withip_vs_nfct
 patch and GCC 3.4.2
	</para>
	<para>
As a followup of sorts to my previous posts, "Error building 2.6.10 
kernel with ip_vs_nfct patch - does anyone else get this?", I figured 
out what the problem was, and with some advice from Julian Anastasov, 
was successful getting kernels compiled with the ip_vs_nfct patch.
This was the error message I would get previously, at the modules stage 
of the kernel build:
	</para>
<programlisting><![CDATA[
 CC [M]  net/ipv4/ipvs/ip_vs_proto_ah.o
 CC [M]  net/ipv4/ipvs/ip_vs_nfct.o

net/ipv4/ipvs/ip_vs_nfct.c: In function `ip_vs_nfct_conn_drop':
include/linux/netfilter_ipv4/ip_conntrack.h:248: sorry, unimplemented: 
inlining failed in call to 'ip_conntrack_put': function body not available
net/ipv4/ipvs/ip_vs_nfct.c:385: sorry, unimplemented: called from here
make[3]: *** [net/ipv4/ipvs/ip_vs_nfct.o] Error 1
make[2]: *** [net/ipv4/ipvs] Error 2
]]></programlisting>
	<para>
The system in question is Fedora Core 3, which sports version 3.4.2 of 
the GNU C compiler (and everything in the release is built with it).
The kernel source I was using is the kernel-2.6.10-1.741_FC3.src.rpm.  I 
had added the ip_vs_nfct and nat patches to the kernel build spec file, 
inserted the "CONFIG_IP_VS_NFCT=y" kernel config option line between the 
"CONFIG_IP_VS_FTP=m" and "CONFIG_IPV6=m" lines of each kernel arch/type 
*.config file, and built the kernel.
	</para>
	<para>
As it turns out, others have seen problems compiling code which contain 
external inline functions with GCC 3.4.2, not just people trying to use 
ip_vs_nfct.  I found one such instance where the user documented that by 
removing "inline" from the function declaration, they were able to 
compile successfully.
	</para>
	<para>
Since ip_conntrack_put is declared and exported as an inline-type 
function in include/linux/netfilter_ipv4/ip_conntrack.h, this seems to 
cause a problem for ip_vs_nfct making use of the function.  I asked 
Julian what he thought about this idea, and  he suggested that "inline" 
may need to be removed from ip_conntrack_put's declaration in 
net/ipv4/netfilter/ip_conntrack_core.c also, since this is where the 
function is exported. Armed with this idea, I modified both 
ip_conntrack.h and ip_conntrack_core.c to remove "inline" from the 
function, and created a patch which I then added to the .spec and kernel 
build.
	</para>
	<para>
The kernel compiled successfully and ran.  My firewall script worked, 
and ip_vs_nfct did its job.  Unfortunately, I discovered several uptime 
hours later when the box kernel panicked that there is a known spinlock 
problem in the 2.6.10 kernel - somewhere in the filesystem/block device 
drivers code.  I say known because comments exist in later iterations of 
the 2.6.10 kernel spec changelog which indicate that steps were taken to 
increase the verbosity of output when this specific kernel panic 
occurs.  I do not know if it is an issue with the upstream 2.6.10 
sources or not, but at least I knew it wasn't because of ip_vs_nfct.
	</para>
	<para>
At any rate, I have been successful building 2.6.9 FC3 kernels with 
Julian's 2.6.9 ip_vs_nfct patches, and not seeing the spinlock "not 
syncing" kernel panics I saw building with any Fedora Core 3 2.6.10 
kernel .src.rpm sources I tried building with. It's been up for 3 days 
now on the box running this kernel, and it is functioning exactly as 
desired.  ...which also means it's gonna be time to update my 
<ulink url="http://www.lvwnet.com/vince/linux/Keepalived-LVS-NAT-Director-ProxyArp-Firewall-HOWTO.html">
keepalived Stateful Firewall/LVS Director HOW-TO document from 2003</ulink>
(http://www.lvwnet.com/vince/linux/Keepalived-LVS-NAT-Director-ProxyArp-Firewall-HOWTO.html)
soon...
	</para>
	<para>
Specifically, I used the 2.6.9-1.681_FC3 .src.rpm file, including 
Julian's two patches (ip_vs_nfct and also the nat patch) and the one 
shown below to remove "inline" from the ip_conntrack_put function.
	</para>
	<para>
If anyone else is interested in building kernels using Julian's patches 
and you have GCC 3.4.2 (or newer, I'm sure...) you may be interested in 
this small patch to remove "inline" from ip_conntrack.h and 
ip_conntrack_core.c.  I'll attach it to this post, and also post the 
text of it here:
	</para>
<programlisting><![CDATA[
diff -urN ../linux-2.6.10/include/linux/netfilter_ipv4/ip_conntrack.h 
./include/linux/netfilter_ipv4/ip_conntrack.h
--- 
../linux-2.6.10/include/linux/netfilter_ipv4/ip_conntrack.h 2004-12-24 
16:35:28.000000000 -0500
+++ ./include/linux/netfilter_ipv4/ip_conntrack.h   2005-02-07 
06:48:57.260570933 -0500
@@ -245,7 +245,9 @@
}

/* decrement reference count on a conntrack */
-extern inline void ip_conntrack_put(struct ip_conntrack *ct);
+/* vince: try this without inline:
+extern inline void ip_conntrack_put(struct ip_conntrack *ct); */
+extern void ip_conntrack_put(struct ip_conntrack *ct);

/* find unconfirmed expectation based on tuple */
struct ip_conntrack_expect *
diff -urN ../linux-2.6.10/net/ipv4/netfilter/ip_conntrack_core.c 
./net/ipv4/netfilter/ip_conntrack_core.c
--- ../linux-2.6.10/net/ipv4/netfilter/ip_conntrack_core.c  2004-12-24 
16:33:47.000000000 -0500
+++ ./net/ipv4/netfilter/ip_conntrack_core.c    2005-02-07 
06:48:16.702522768 -0500
@@ -77,7 +77,9 @@

DEFINE_PER_CPU(struct ip_conntrack_stat, ip_conntrack_stat);

-inline void
+/* vince: try this without inline:
+inline void */
+void
ip_conntrack_put(struct ip_conntrack *ct)
{
   IP_NF_ASSERT(ct);
]]></programlisting>
	<para>
If anyone else cares to comment on whether removing "inline" from 
either/both of these places is good/bad, or what performance impact this 
may have, please do tell.  But it is working well for me so far.
	</para>
<programlisting><![CDATA[
--Boundary_(ID_Kepw1VtyitIN0uRSqVWEDA)
Content-type: text/plain; name="linux-2.6.10-ip_conntrack_put-no-inline.diff"
Content-disposition: inline;
 filename="linux-2.6.10-ip_conntrack_put-no-inline.diff"
Content-transfer-encoding: 7bit

diff -urN ../linux-2.6.10/include/linux/netfilter_ipv4/ip_conntrack.h ./include/linux/netfilter_ipv4/ip_conntrack.h
--- ../linux-2.6.10/include/linux/netfilter_ipv4/ip_conntrack.h	2004-12-24 16:35:28.000000000 -0500
+++ ./include/linux/netfilter_ipv4/ip_conntrack.h	2005-02-07 06:48:57.260570933 -0500
@@ -245,7 +245,9 @@
 }
 
 /* decrement reference count on a conntrack */
-extern inline void ip_conntrack_put(struct ip_conntrack *ct);
+/* vince: try this without inline:
+extern inline void ip_conntrack_put(struct ip_conntrack *ct); */
+extern void ip_conntrack_put(struct ip_conntrack *ct);
 
 /* find unconfirmed expectation based on tuple */
 struct ip_conntrack_expect *
diff -urN ../linux-2.6.10/net/ipv4/netfilter/ip_conntrack_core.c ./net/ipv4/netfilter/ip_conntrack_core.c
--- ../linux-2.6.10/net/ipv4/netfilter/ip_conntrack_core.c	2004-12-24 16:33:47.000000000 -0500
+++ ./net/ipv4/netfilter/ip_conntrack_core.c	2005-02-07 06:48:16.702522768 -0500
@@ -77,7 +77,9 @@
 
 DEFINE_PER_CPU(struct ip_conntrack_stat, ip_conntrack_stat);
 
-inline void 
+/* vince: try this without inline:
+inline void */
+void 
 ip_conntrack_put(struct ip_conntrack *ct)
 {
 	IP_NF_ASSERT(ct);

]]></programlisting>
	</section>
	<section id="conntrack_with_ftp" xreflabel="conntrack with ftp">
	<title>LVS-NAT netfilter conntrack example with ftp</title>
	<para>
Julian Anastasov <emphasis>ja (at) ssi (dot) bg</emphasis> 19 May 2004
	</para>
	<para>
	For users of ipvs-nfct I would recommend the following rules.
The example is for ftp by LVS-NAT to VIP=192.168.1.100. 
Access to all other ports on the VIP is denied.
	</para>
<programlisting><![CDATA[
# turn on conntrack and load helper modules
echo 1 > /proc/sys/net/ipv4/vs/conntrack

# module to correctly support connection expectations for FTP-DATA
modprobe ip_conntrack_ftp
# module to detect ports used for FTP-DATA
# (May 2004, has a kernel bug which hasn't been fixed)
# `modprobe ip_nat_ftp` is optional and ip_nat_ftp needs a fix:
# http://marc.theaimsgroup.com/?l=linux-netdev&m=108220842129842&w=2
# if ip_nat_ftp is used together with ipvs_nfct for FTP NAT.
modprobe ip_nat_ftp
# Restrict LOCAL_IN access
# accept packets to dport 21 and related and established connections.
# the related connections are determined by the ftp helper module
# drop all other packets
iptables -A INPUT -p tcp -d 192.168.1.100 --dport 21 -j ACCEPT
iptables -A INPUT -p tcp -d 192.168.1.100 -m state --state RELATED,ESTABLISHED - j ACCEPT
iptables -A INPUT -p tcp -d 192.168.1.100 -j DROP

# Restrict FORWARD access
# accept only related, established. drop all others
iptables -A FORWARD -m state --state RELATED,ESTABLISHED -j ACCEPT
iptables -A FORWARD -j DROP
]]></programlisting>
	<para>
	Without NFCT support it is difficult to filter in INPUT
for FTP-DATA packets but for http/https where the VPORT is known
it is not difficult. The same difficulties are IN FORWARD for
the NAT replies. This is where ipvs-nfct wins - you have only a small
number of rules.
	</para>
	<para>
	Traffic to the VIP is first filtered by iptables in INPUT and
then scheduled from IPVS. IPVS in 2.6 causes the scheduled out->in
packets (after any LVS-NAT translations) to appear in the LOCAL_OUT hook
where they can be filtered again.
	</para>
	<para>
	IPVS works always after the filter rules. It is easy
when you know the ports but for FTP-DATA it is not possible,
you have to specify input devices and IPs for which you
grant access for forwarding. You overcome such problems with
ipvs-nfct.
	</para>
	<para>
Ratz 03 Aug 2004 
	</para>
	<para>
LVS-NAT with the NFCT patch will work for 2.4.x and 2.6.x kernels 
regarding filtering, if you don't use fwmark
	</para>
	<para>
LVS-DR will most probably not work with 2.6.8 and above kernels 
regarding filtering since the tcp window tracking patch has been merged 
to the vanilla tree; however there is a relaxation sysctl that could 
revert the strict TCP window and sequence number checking to the 
loosly-knitted one (aka: non-existant) as previously found in vanilla 
Linux kernels.
	</para>
	</section>
	<section id="tcpdump"><title>tcpdump is LVS compatible</title>
	<para>
You can use <filename>tcpdump</filename> to debug your 
<filename>iptables</filename> rules on your running director.
<filename>tcpdump</filename> makes a copy of packets for its own use.
<filename>tcpdump</filename> gets a copy of the packets before netfilter
(on the way in) and after netfilter (on the way out).
You should see all packets with <filename>tcpdump</filename> 
as if netfilter and LVS didn't exist.
	</para>
	<para>
Joe 16 Mar 2001
	</para>
	<blockquote>
		<para>
I'm looking at packets after they've been accepted by TP
and I'm using (among other things) <filename>tcpdump</filename>.
		</para>
		<para>
Where in the netfilter chain does tcpdump look at incoming
and outgoing packets? When they are put on/received from
the wire? After the INPUT, before the OUTPUT chain...?
		</para>
	</blockquote>
	<para>
Julian
	<para>
	</para>
Before/after any netfilter chains. Such programs hook at
packet level before/after the IP stack just before/after the packet
is received/must be sent from/by the device. They work for
other protocols. tcpdump is a packet receiver just like the
IP stack is in the network stack.
	</para>
	<note>
	<para>
If you are using twisted pair ethernet through a hub/switch,
your NIC will only see the packets to/from it. Thus
tcpdump running on the director will not see packets from
the realserver to the client in LVS-DR.
In the days when people used coax for ethernet,
all machines saw all packets on a segment.
	</para>
	</note>
	</section>
	<section id="writing_filter_rules">
	<title>Writing Filter Rules</title>
	<para>
If you're writing your own rules, start off with a quiet
machine, log all packets  and then access one of the services. Write
rules to accept the packets you want and keep logging the rest. Try another
service... Deny all packets that you know aren't needed for your LVS.
	</para>
	<para>
You can probably accept all packets that have both
src_addr and dst_addr in the RIP network.
As well machines might need access to outside services
(<emphasis>e.g.</emphasis> ntp, dns).
Realservers that are part of <xref linkend="3-Tier_lvs"/> LVSs, will
also require rules to allow them to access outside services.
	</para>
	<para>
Joe (on changing from writing ipchains rules for ip_vs for 2.2,
to writing iptables rules for ip_vs for 2.4)
	</para>
	<blockquote>
I see packets only in the INPUT and OUTPUT chains, but not in FORWARD
or in lvs_rules chains.
	</blockquote>
	<para>
Ratz 21 May 2001
	</para>
	<para>
If you're dealing with netfilter,
packets don't travel through all chains anymore. Julian once wrote
something about it:
	</para>
<programlisting><![CDATA[
packets coming from outside to the LVS do:

        PRE_ROUTING -> LOCAL_IN(LVS in) -> POST_ROUTING

packets leaving the LVS travel:

        PRE_ROUTING -> FORWARD(LVS out) -> POST_ROUTING
]]></programlisting>
	<para>
From the iptables howto:
	</para>
	<blockquote>
		<para> 
COMPATIBILITY WITH IPCHAINS
		</para>
		<para>
This iptables is very similar to ipchains  by  Rusty  Russell.
The  main  difference is that the chains INPUT and
OUTPUT are only traversed  for  packets  coming  into  the
local  host  and  originating  from the local host respectively.
Hence every packet only passes through one of the
three  chains;  previously  a  forwarded packet would pass
through all three.
		</para>
	</blockquote>
	<para>
When writing filter rules (<emphasis>e.g.</emphasis> iptables), keep in mind
	</para>
	<itemizedlist>
		<listitem>
write the rules in trees. If a packet has to traverse many rule tests
before it is accepted/rejected, then throughput will decrease. If many packets
traverse a rule set, then you should attempt to shorten the path through the rules,
possibly by breaking the rule set into several branches.
		</listitem>
		<listitem>
Ratz has shown that you can have 200-500 rules in a branch before throughput
is affected
(see <ulink url="http://www.tac.ch/home/archive/pdf/pf-speed-test.pdf">pf-speed-test.pdf</ulink>).
		</listitem>
	</itemizedlist>
	<para>
"K.W." <emphasis>kathiw (at) erols (dot) com</emphasis>
	</para>
	<blockquote>
can I run my ipchains firewall and LVS (piranha in this case) on the
same box? It would seem that I cannot, since ipchains can't understand
virtual interfaces such as eth0:1, etc.
	</blockquote>
	<para>
Brian Edmonds <emphasis>bedmonds (at) antarcti (dot) ca</emphasis> 21 Feb 2001
	</para>
	<para>
I've not tried to use ipchains with alias interfaces,
but I do use aliased IP addresses in my incoming rulesets,
and it works exactly as I would expect it to.
	</para>
	<para>
Julian
	</para>
	<blockquote>
I'm not sure whether piranha already supports kernel 2.4, I have to check it.
ipchains does not understand interface aliases even in Linux 2.2.
Any setup that uses such aliases can be implemented without using them.
I don't know for routing restrictions that require using aliases.
	</blockquote>
	<para>
I have a full ipchains firewall script, which works (includes port
forwarding), and a stripped-down ipchains script just for LVS, and they
each work fine separately. When I merge them, I can't reach even just
the firewall box. As I mentioned, I suspect this is because of the
virtual interfaces required by LVS.
	</para>
	<blockquote>
	<para>
	LVS does not require any (virtual) interfaces. LVS never
checks the devices nor any aliases. I'm not sure what is the port
forwarding support in ipchains too. Is that the support provided
from ipmasqadm: the portfw and mfw modules? If yes, they are not
implemented (yet). And this support is not related to ipchains
at all. Some good features are still not ported from Linux 2.2 to
2.4 including all these autofw useful things. But you can use LVS
in the places where use ipmasqadm portfw/mfw but not for the autofw
tricks. LVS can perfectly do the portfw job and even to extend it
after the NAT support: there are DR and TUN methods too.
	</para>
	</blockquote>
	<para>
Lorn Kay <emphasis>lorn_kay (at) hotmail (dot) com</emphasis>
	</para>
	<blockquote>
	<para>
I ran into a problem like this when adding firewall rules to my LVS ipchains
script. The problem I had was due to the order of the rules.
	</para>
	<para>
Remember that once a packet matches a rule in a chain it is kicked out of
the chain--it doesn't matter if it is an ACCEPT or REJECT rule(packets may
never get to your FWMARK rules, for example, if they do not come before your
ACCEPT and REJECT tests).
	</para>
	<para>
I am using virtual interfaces as well (eg, eth1:1) but, as Julian points
out, I had no reason to apply ipchains rules to a specific virtual interface
(even with an ipchains script that is several hundred lines long!)
	</para>
	</blockquote>
	<para>
unknown
	</para>
	<blockquote>
	<para>
FWMARKing does not have to be a part of an ACCEPT rule.
If you have a default DENY policy and then say:
	</para>
<programlisting><![CDATA[
/sbin/ipchains -A input -d $VIP -j ACCEPT
/sbin/ipchains -A input -d $VIP 80 -p tcp -m 3
/sbin/ipchains -A input -d $VIP 443 -p tcp -m 3
]]></programlisting>
	<para>
To maintain persistence between port 80 and 443 for https, for example, the
packets will match on the ACCEPT rule, get kicked out of the input chain
tests, and never get marked.
	</para>
	</blockquote>
	</section>
	<section id="antefacto_patches" xreflabel="Antefacto patches">
	<title>The Antefacto Netfilter Connection Tracking patches</title>
	<para>
<emphasis>The Problem:</emphasis>
Because of the incompatibilities between netfilter and LVS,
it is not possible (in general) to have <filename>iptables</filename>
firewall rules running on the director 
(the firewall must be on a separate machine).
	</para>
	<para>
The first code (the Antefacto patches) were written by Ben North for 2.4 kernels,
when he worked for (the now defunct) Antefacto.
The code was then (Jun 2003) taken over by Vinnie
<emphasis>listacct1 (at) lvwnet (at) com</emphasis>
and now (Apr 2004) being ported by Julian who calls them
the "netfilter connection tracking" (nfct) patches.
	</para>
	<para>
The original Antefacto patches
allowed a firewall on directors in an LVS where the packets from
the realservers return through the director (LVS-NAT,
and LVS-DR with the forward_shared flag when the director
is the default gw for the realservers). This restriction
is required so that the director has full information about
the connection (in LVS-DR and LVS-Tun, the director makes
guesses about the state of the connection from timeout values).
	</para>
	<para>
Documentation for the Antefacto code is at
<ulink url="http://www.lvwnet.com/vince/linux/Keepalived-LVS-NAT-Director-ProxyArp-Firewall-HOWTO-beta.html">
setting up an LVS-NAT Director (running keepalived) to function as a
stateful firewall, which also happens to use proxy-arp</ulink>.
The code is at
<ulink url="http://www.lvwnet.com/vince/files/ipvs/linux-2.4.19-ipvs-1.0.7-antefacto.patch.tar.bz2">
Antefacto patch for 2.4.19/1.0.7</ulink>
and
<ulink url="http://www.lvwnet.com/vince/files/ipvs/linux-2.4.20-ipvs-1.0.8-antefacto.patch.tar.bz2">
Antefacto patch for 2.4.20/1.0.8</ulink>
	</para>

		<section id="netfilter_patches_2.4">
		<title>The problem:director can't be firewall as well</title>
		<para>
John P. Looney <emphasis>john (at) antefacto (dot) com</emphasis>  Apr 12, 2002
		</para>
		<blockquote>
		<para>
We modified ip_vs to get it to play nicely with iptables on the same box,
so you don't need a seperate firewall/vpn box.
		</para>
		<para>
The patches weren't accepted to the main branch, as the changes were considered
non-mainstream, and they were made from 0.8.2 version, which was a little
old then. Have a look at;
		</para>
		<para>
http://www.in-addr.de/pipermail/lvs-users/2002-January/004585.html
		</para>
		<para>
From memory (I didn't do the kernel work), the ip_vs connection tracking
tables and the netfilter connection tracking tables were not always in
synch. So, you couldn't statefully firewall an ip_vs service. There is a
readme included somewhere in that thread.
		</para>
		<para>
We've just done a product release. One of our aims is to reimplement
these changes in the 1.0.x branch, if someone hasn't already done so. When
that's done, we'll post those patches to the list also.
		</para>
		</blockquote>
		<para>
Here's the original posting from Ben North.
		</para>
<programlisting><![CDATA[
Ben North             Software Engineer
a n t e f a c t o     t: +353 1 8586008
www.antefacto.com     f: +353 1 8586014
181 Parnell Street - Dublin 1 - Ireland
]]></programlisting>
		<para>
		<note>Feb 2003: Antefacto no longer exists.
You should be able to contact Ben at <emphasis>ben (at) redfrontdoor (dot) org</emphasis>.
		</note>
		</para>
		<blockquote>
		<para>
We've been working with the LVS code for the past while, and we
wanted to allow the use of Netfilter's connection-tracking
ability with LVS-NAT connections.  There was a post on the
mailing list a couple of weeks ago asking about this, and my
colleague Padraig Brady mentioned that we had developed a
solution.
		</para>
		<para>
I've now had time to clean up the patches, and I attach a
README, and two patch files.  One is for the Linux kernel, and
one is to the LVS code itself.  Any comments, get in touch.  We
have done a fair amount of testing (overnight runs with many
tens of thousands of connections), with no problems.
		</para>
		<para>
Many thanks for the great piece of work.  Hope the patches are
useful and will be considered for inclusion in future releases
of LVS.  I notice that 1.0.0 is going to arrive soon; the
attached patches might be better applied to a Linux-kernel-style
1.1 "development" branch.
		</para>
		</blockquote>
		<para>
Vinnie <emphasis>listacct1 (at) lvwnet (dot) com</emphasis> 04 May 2003
		</para>
		<para>
Well I haven't tried to crash the firewall/Director or anything, but to sum
it up, the firewall box is doing its job now just as well as it was before I
started dinking around with LVS/IPVS.  It is letting traffic come IN that I
have IPVS virtual services for, and letting it be FORWARDED to the Real
Servers.  It's not getting in the way of IPVS connections in progress, nor
does it appear to be letting traffic through which is NOT related to
connections already in progress.
		</para>
		<para>
Ratz
		</para>
		<blockquote>
Guys, I hope you _do_ realize that not even netfilter has a properly
working connection tracking. Without the tcp-window-tracking patch,
netfilter allows you to send arbitrary packets through the stack. It's a
well-known fact and even the netfilter homepage at some point mentioned it.
		</blockquote>
		<para>
Point taken.  But that's not an IPVS or Antefacto problem.
		</para>
		<blockquote>
I take it that you didn't do any tests of the patch or netfilter in
general with a packet generator (where you can modify every last bit of
an skb).
		</blockquote>
		<para>
No, I can't say that I have.  Perhaps you would be willing to put some of
that expertise you have to work?
		</para>
		<blockquote>
And, to your interest, LVS _does_ have sort of connection state tracking.
		</blockquote>
		<para>
I am aware of that.  But the point about all of this (and the reason that
the folks who actually wrote the Antefacto patch did so) is that IPVS works
independently of netfilter's connection tracking.  So Netfilter doesn't have
a CLUE about all those connections going on (or not going on) to IPVS-based
services and RealServers.
		</para>
		<para>
But if you want your LVS Director to also be your main firewall, that means
you have to be able to tell your firewall box, in ways that you can
communicate your wishes with iptables commands, what kind of traffic you
want to allow to go in/out of your LVS.  But that's pretty hard to do since
IPVS unmodified doesn't bother to let netfilter in on the loop of what it's
doing.
		</para>
		<para>
The antefacto patch allows netfilter and IPVS to communicate about all that
traffic going through your LVS, so that at the iptables ruleset level, it is
possible to write rules that work for your LVS.
		</para>
		<para>
If netfilter's connection tracking is broken, then it's broken -- IPVS,
Antefacto, or not.
		</para>
		</section>
		<section id="patches_for_netfilter">
		<title>the patches</title>
		<para>
Following patches, Copyright (C) 2001--2002 Antefacto Ltd,
181 Parnell St, Dublin 1, Ireland, released under GPL, and then
Ben's documentation on the patch.
		</para>
		<para>
First the 
<ulink url="files/antefacto_kernel.diff">patch to the kernel sources</ulink>
(http://www.austintek.com/WWW/LVS/LVS-HOWTO/HOWTO/files/antefacto_kernel.diff)
		</para>

		<para>
And second, the 
<ulink url="files/antefacto_lvs.diff">patch to the LVS sources</ulink> 
(http://www.austintek.com/LVS/LVS-HOWTO/HOWTO/files/antefacto_lvs.diff)
(made against 0.8.2 so may need some clean-up).
		</para>
		</section>
		<section id="netfilter_patch_explanation">
		<title>Making LVS work with Netfilter's connection tracking</title>
		<para>
The two attached patches modify the kernel and the ipvs modules
in such a way that ipvs NAT connections are correctly tracked by
the Netfilter connection-tracking code.  This means that
firewalling rules can be put in place to allow incoming
connections to a virtual service, and then by allowing
ESTABLISHED and RELATED packets to pass the FORWARD chain, we
achieve stateful firewalling of these connections.
		</para>
		<para>
For example, if director 4.3.2.1 is offering a virtual service
on TCP port 8899, we can do
		</para>
<programlisting><![CDATA[
iptables -A INPUT -p tcp -d 4.3.2.1 --dport 8899 -m state --state NEW,ESTABLISHED,RELATED
iptables -A FORWARD -p tcp -m state --state ESTABLISHED,RELATED
]]></programlisting>
		<para>
and get the desired behaviour.  Note that the second rule (the
one in the FORWARD chain) covers all virtual services offered by
the same director, so if another service is offered on port
9900, the complete set of rules required would be
		</para>
<programlisting><![CDATA[
iptables -A INPUT -p tcp -d 4.3.2.1 --dport 8899 -m state --state NEW,ESTABLISHED,RELATED
iptables -A INPUT -p tcp -d 4.3.2.1 --dport 9900 -m state --state NEW,ESTABLISHED,RELATED
iptables -A FORWARD -p tcp -m state --state ESTABLISHED,RELATED
]]></programlisting>
		<para>
<emphasis>i.e.</emphasis>, one rule in the INPUT chain is required per virtual
service, but the rule in the FORWARD chain covers all virtual
services.
		</para>
		<para>
<emphasis role="bold">Patches required</emphasis>
		</para>
		<itemizedlist>
			<listitem>
			<para>
			<emphasis role="bold">Patch to main kernel source</emphasis>
			</para>
			<para>
There is a small change required to the kernel patch.  The stock
kernel patch which comes with the ip_vs distribution just adds a
few EXPORT_SYMBOL()s to ksyms.c.  For the Netfilter
connection-tracking functionality, we need a bit more.  The
files affected, and reasons, are:
			</para>
			<para>
			<filename>ip_conntrack_core.c: init_conntrack():</filename>
    Mark even more clearly that the newly-created
    connection-tracking entry is not in the hash tables.  This
    change isn't strictly necessary but makes assertion-checking
    easier.
			</para>
			<para>
			<filename>ip_conntrack_standalone.c:</filename>
  Export the symbol __ip_conntrack_confirm().  I didn't really
  like the idea of exporting a symbol starting with
  double-underscore, but nothing too bad seems to have happened.
  The function seems to take care of reference-counting, so I
  think we're OK here.
			</para>
			<para>
			<filename>ip_nat_core.c: ip_nat_replace_in_hashes(): </filename>
(new function)
    Exported wrapper round replace_in_hashes() which deals with
    the locking on ip_nat_lock.
			</para>
			<para>
			<filename>ip_nat_standalone.c:</filename>
  Export the new ip_nat_replace_in_hashes() function.
			</para>
			<para>
			<filename>ip_nat.h:</filename>
  Declare the new ip_nat_replace_in_hashes() function.
			</para>
			<para>
More explanation below.
			</para>
			</listitem>
			<listitem>
			<para>
			<emphasis role="bold">Patch to ip_vs code</emphasis>
			</para>
			<para>
			<filename>ip_vs_app.c: skb_replace():</filename>
    Copy debugging information across to the new skb, if
    debugging is enabled.  This is a separate issue to the
    main connection-tracking patch, but was causing spurious
    warnings about which hooks a skb had passed through.
			</para>
			<para>
			<filename>ip_vs_conn.c:</filename>
  Include some netfilter header files.
  Declare a new function ip_vs_deal_with_conntrack().
			</para>

			<para>
			<filename>ip_vs_nat_xmit():</filename>
    Code to make sure that Netfilter's connection-tracking entry
    is correct.
			</para>
			<para>
			<filename>ip_vs_deal_with_conntrack():</filename>  (new function)
    The guts of the new functionality.  Changes the data inside
    the Netfilter connection-tracking entry to match the actual
    packet flow.
			</para>
			<para>
			<filename>ip_vs_core.c: route_me_harder():</filename>  (new function)
    Copied from ip_nat_standalone.c.  Code to re-make the
    routing decision for a packet, treated as locally-generated.
			</para>
			<para>
  			<filename>ip_vs_out():</filename>
    Separate from the connection-tracking code changes, don't
    send ICMP unreachable messages.  This has been discussed on
    the list recently and I think the consensus was that this
    change is OK.  The sysctl method would be better though, so
    ignore this bit.
			</para>
			<para>
    Also call route_me_harder() to decide whether the outbound
    packet needs to be routed differently now it is supposed to
    be coming from the director machine itself.
			</para>
			<para>
  			<filename>ip_vs_in():</filename>
    When checking if a packet might be trying to start a new
    connection, check that it has SYN but not ACK.  Previously,
    the only check was that it had SYN set.
			</para>
			<para>
    If there is a new connection being attempted, check for
    consistency between Netfilter's connection-tracking table
    and LVS'.  More explanation of this bit below.
			</para>
			<para>
			<filename>ip_vs_ftp.c:</filename>
  Include the Netfilter header files.

  Declare new function ip_vs_ftp_expect_callback().
			</para>
			<para>
  <filename>ip_vs_ftp_out():</filename>
    Once we have noticed that a passive data-transfer connection
    has been negotiated at application level, tell Netfilter to
    expect this connection and so treat it as RELATED.
			</para>
			<para>
  <filename>ip_vs_ftp_in():</filename>
    Once we have noticed that an active data-transfer connection
    has been negotiated at application level, tell Netfilter to
    expect this connection and so treat it as RELATED.
			</para>
			<para>
  <filename>ip_vs_ftp_expect_callback():</filename>  (new function)
    When the RELATED packet arrives (for a data-transfer
    connection), update Netfilter's connection-tracking entry
    for the connection.
			</para>
			</listitem>
		</itemizedlist>
			<section id="general_connection">
			<title>General connections (<emphasis>i.e.</emphasis> not FTP)</title>
			<para>
Each entry in Netfilter's connection-tracking table has two
tuples describing source and destination addresses and ports.
One of these tuples is the ORIG tuple, and describes the
addressing of packets travelling in the "original" direction,
i.e., from the machine that initiated the connection to the
machine that responded.  The other is the REPLY tuple, which
describes the addressing of packets travelling in the "reply"
direction, i.e., from the responding machine to the initiating
machine.  Normally, the REPLY tuple is just the "inverse" of the
ORIG tuple, i.e., has its source and destination reversed.  But
for LVS connections, this is not the case.  This is what causes
the problem when using the unmodified Netfilter code with IPVS
connections.  Actually, it's one of the things that causes
trouble.
			</para>
			<para>
The following is roughly what happens with the unmodified code
for the start of a TCP connection to a virtual service.  Suppose
we have
			</para>

<programlisting><![CDATA[
   +--------+
   | Client |
   +--------+
     (CIP)       <-- Client's IP address
       |
       |
  { internet }
       |
       |
     (VIP)       <-- Virtual IP address
  +----------+
  | Director |
  +----------+
     (PIP)       <-- (Director's Private IP address)
       |
       |
     (RIP)       <-- Real (server's) IP address
 +-------------+
 | Real server |
 +-------------+
]]></programlisting>

			<para>
Then the client sends a packet to the VIP:VPORT; say
			</para>

<programlisting><![CDATA[
CIP:CPORT -> VIP:VPORT
]]></programlisting>
			<para>
Netfilter on the director makes a note of this packet, and sets
up a temporary connection-tracking entry with tuples as follows:
			</para>
<programlisting><![CDATA[
ORIG:  CIP:CPORT -> VIP:VPORT
REPL:  VIP:VPORT -> CIP:CPORT
]]></programlisting>
			<para>
(the "src-ip:src-port -> dest-ip:dest-port" notation is
hopefully clear enough).  We will call a connection-tracking
entry a "CTE" from now on.
			</para>
			<para>
LVS notices (in ip_vs_in(), called as part of the LOCAL_INPUT
hook) that VIP:VPORT is something it's interested in, grabs the
packet, re-writes it to be addressed
			</para>
<programlisting><![CDATA[
CIP:CPORT -> RIP:RPORT
]]></programlisting>
			<para>
and sends it on its way by means of ip_send().  As a result, the
POST_ROUTING hook gets called, and ip_vs_post_routing() gets a
look at the packet.  It notices that the packet has been marked
as belonging to LVS, and calls the (*okfn), sending the packet
to the wire without further ado.
			</para>
			<para>
When it has been transmitted, the reference count on the CTE
falls to zero, and it is deleted.  (This is a mild guess but I
think is right.)  Normally, CTEs avoid this fate because
__ip_conntrack_confirm() is called for them, either via
ip_confirm() as a late hook in LOCAL_IN, or through ip_refrag()
called as a late hook in POST_ROUTING.  "Confirming" the CTE
involves linking it into some hash tables, and ensuring it isn't
deleted.
			</para>
			<para>
So this is the first problem --- the CTE is not "confirmed".
			</para>
			<para>
Suppose we confirmed the connection.  Then when the Real Server
replies to this packet, it sends a packet addressed as
			</para>
<programlisting><![CDATA[
RIP:RPORT -> CIP:CPORT
]]></programlisting>
			<para>
to the director (because the Director is the router for such
packets, as seen by the Real Server).  Then the
connection-tracking code in Netfilter on the director tries to
look up the CTE for this packet, but can't find one.  The CTE we
/want/ it to match says
			</para>
<programlisting><![CDATA[
ORIG:  CIP:CPORT -> VIP:VPORT
REPL:  VIP:VPORT -> CIP:CPORT
]]></programlisting>
			<para>
with no mention of the RIP:RPORT.  So this reply packet gets
labelled as "NEW", whereas we wanted it to be labelled as
"ESTABLISHED".
			</para>
			<para>
So as well as confirming the CTE, we also need to alter the
REPLY tuple so that it will match the
			</para>
<programlisting><![CDATA[
RIP:RPORT -> CIP:CPORT
]]></programlisting>
			<para>
packet the Real Server sends back.  Then everything will work.
			</para>
			<para>
These two things are what the ip_vs_deal_with_conntrack()
function does.  Luckily there is a ip_conntrack_alter_reply()
function exported by Netfilter, which we can use.  Then we can
also call the newly-exported __ip_conntrack_confirm() to confirm
the connection.  (We need to do the reply altering first because
__ip_conntrack_confirm()ing the CTE uses the addresses in the
ORIG and REPLY tuples to place the CTE in the hash tables, and
we want it placed based on the /new/ reply tuple.)
			</para>
			<para>
There is a slight complication in that the NAT code in Netfilter
gets confused if addressing tuples change, so we need to tell
the NAT code to re-place the CTE in its hash tables.  This is
done with the newly-exported ip_nat_replace_in_hashes()
function.
			</para>
			<para>
The ip_vs_deal_with_conntrack() function is called from the
ip_vs_nat_xmit() function, since this whole problem only applies
to LVS-NAT.  It is only called if the CTE is unconfirmed.
			</para>
			<para>
<emphasis role="bold">Hacking round a possible race</emphasis>
			</para>
			<para>
When testing this, we found that very occasionally there would
be a problem when the Netfilter CTE timed out and was deleted.
The code would fail an assertion: the CTE about to be deleted
was not linked into the hash chain it claimed it was.  This
would happen after a few tens of thousands of connections from
the same client to the same virtual service.
			</para>
			<para>
We tracked this down to the above ip_vs_deal_with_conntrack()
code being called for a CTE which already existed and was
already confirmed.  Doing this moved the CTE to a different hash
chain and broke things.
			</para>
			<para>
The only explanation I could come up with is that there is a
race in the ip_vs code.  The ip_vs code doesn't set up one timer
per connection entry.  Instead, it uses a kernel timer to do
some work every second.  I didn't look into this too deeply, but
it looked like the following is a possibility.
			</para>
			<para>
If the slow-timer code decides that a LVS connection should be
expired, there seems to be a window where a packet can arrive
and update that connection, meaning that it should no longer be
expired.  But it is anyway.  There are more details; supplied on
request.  But if somebody who knows the timer code could check
whether the above is a possibility, and fix it if so, that would
be good.
			</para>
			<para>
The workaround detects if the CTE is already confirmed, and
deletes it and also drops the packet if so.  Higher levels in
the stack take care of retransmitting so nothing too drastic
goes wrong.
			</para>
			<para>
Later, we noticed the workaround being triggered much more often
than we'd expect, and it turned out that incoming packets with
the SYN and ACK bits both set were being treated as potentially
starting new connections, whereas SYN/ACK packets are in fact a
response to a connection initiated by the director itself.  So
we tightened the test to be
			</para>
<programlisting><![CDATA[
((h.th->syn && !h.th->ack) || (iph->protocol != IPPROTO_TCP))
]]></programlisting>
			<para>
instead of
			</para>

<programlisting><![CDATA[
(h.th->syn || (iph->protocol!=IPPROTO_TCP))
]]></programlisting>
			<para>

	which is how it is in the original LVS code.  This doesn't seem
to have caused any nasty side effects.
			</para>
			<para>
Note that this only happened when an FTP virtual service was
configured, because of the code in ip_vs_service_get() which
allows a "wild-card" match for incoming FTP data connections.
			</para>
			</section>
			<section id="netfilter_ftp_connections">
			<title>FTP connections</title>
			<para>
The other main change is to the LVS FTP module.  We add code to
the two functions ip_vs_ftp_out() and ip_vs_ftp_in(), to deal
with passive and active data transfers respectively.  The basic
idea is the same for both types of transfer.
			</para>
			<para>
By keeping an eye on the actual traffic going between the client
and the FTP server, we can tell when a data transfer is about to
take place.  For a passive transfer, the ip_vs_ftp module looks
out for the string "227 Entering Passive Mode" followed by the
address and port the server will listen on.  For an active
transfer, the client transmits the "PORT" command followed by
the address and port the client will listen on.
			</para>
			<para>
Once we have detected that a data transfer is about to take
place, we add code to tell Netfilter's connection-tracking code
to /expect/ the data connection.  Then, packets belonging to the
data connection will be labelled "RELATED" and can be allowed by
firewall rules.  There is an exported function
ip_conntrack_expect_related(), which we call.  The only
difference between the set-up for passive and active transfers
is that for passive transfers we don't know the port the client
will connect from, so have to specify the source port as "don't
care" by means of its mask.
			</para>
			<para>
The ip_conntrack_expect_related() function allows us to specify
a callback function; we use ip_vs_ftp_expect_callback() (new
function in this patch).  ip_vs_ftp_expect_callback() works out
whether the new connection is for passive or active, modifies
the REPLY tuple, and confirms the CTE.
			</para>
			<para>
I've just noticed that I modify the reply tuple directly instead
of calling ip_conntrack_alter_reply().  Can't see any good
reason for this, so should probably change the code to use
ip_conntrack_alter_reply() instead.  Might not have time to test
that change here, so will leave it alone for now.
			</para>
			<para>
So to run a virtual FTP service, load the extra ip_vs_ftp
module, but /not/ the ip_conntrack_ftp or ip_nat_ftp modules.
It is very likely that the ip_vs_ftp module would not cooperate
very well with those two modules, so if you want to run
a non-virtual FTP service /and/ load-balance a virtual FTP
service on the same machine, more work might be required.
			</para>
			<para>
<emphasis role="bold">route_me_harder()</emphasis>
			</para>
			<para>
We call this function to possibly re-route the packet, because
we were using policy routing (iproute2).  This allows routing
decisions to depend on more than just the destination IP address
of the packet.  In particular, a routing decision can be
influenced by the source IP address of the packet, and by the
fact that the packet should be treated as originating with the
local machine.  The call to route_me_harder() re-makes the
routing decision in light of the new state of the packet.  It
could be removed (or disabled via a sysctl) if the overhead was
too annoying in an application which didn't require this extra
flexibility.
			</para>
			<para>
<emphasis role="bold">Additional #defines</emphasis>
			</para>
			<para>
There are additional #defines available to add
assertion-checking and various amounts of debugging to the
output of the new code.
			</para>
			<para>
#define BN_ASSERTIONS to include extra code which checks various
things are as they should be.  This adds a small amount of
overhead (sorry, haven't measured it) but caught some problems
in development.
			</para>
			<para>
#define BN_DEBUG_FTP to emit diagnostic and tracing information
from the modified ip_vs_ftp module.  Again, was useful during
development but probably not useful in production.
			</para>
			<para>
#define BN_DEBUG_IPVS_CONN to emit diagnostic and tracing
information from the new code which handles Netfilter's CTEs.
Same comments apply: useful while I was working on it, but
probably not in actual use.
			</para>
			</section>
		</section>
	</section>
	<section id="design_of_netfilter_module">
	<title>The design of LVS as a netfilter module, pt1</title>
	<para>
Tao Zhao <emphasis>taozhao (at) cs (dot) nyu (dot) edu</emphasis> 11 Jul 2001
	</para>
	<blockquote>
The source code of LVS adds ip_vs_in()
to netfilter hook NF_IP_LOCAL_IN to change the destination of packets. As
I understand, this hook is called AFTER routing decisions have reached.
So how can it forward the packet to the new assigned destination without
routing?
	</blockquote>
	<para>
Henrik Nordstrom <emphasis>hno (at) marasystems (dot) com</emphasis>
	</para>
	<para>
Instead of rewriting the packet inside the normal packet flow of Linux-2.4,
IPVS accepts the packet and constructs a new one, routes it and sends it
out.. This approach does not make much sense for LVS-NAT within the netfilter
framework, but fits quite well for the other modes.
	</para>
	<para>
Julian
	</para>
	<para>
	LVS does not follow the netfilter recommendations. What happens
if we don't change the destination (<emphasis>e.g.</emphasis>DR and TUN methods
which don't change the IP header). When such packet hits the routing
the IP header fields are used for the routing decision.
Netfilter can forward only by using NAT methods.
	</para>
	<para>
	LVS tries not to waste CPU cycles in the routing cache.
You can see that there is output routing call involved but there is a
optimization you can find even in TCP - the destination cache. The
output routing call is avoided in most of the cases. This model is
near the one achieved in Netfilter, i.e. to call only once the input
routing function (2.2 calls it twice for DNAT). I'm now testing a
patch for 2.2 (on top of LVS) that avoids the second input routing
call and that can reroute the masqueraded traffic to the right gateway
when many gateways are used and mostly when these gateways are on
same device. The tests will show how different is the speed between
this patched LVS for 2.2 and the 2.4 one (one CPU of course).
	</para>
	<para>
	We decided to use the LOCAL_IN hook for many reasons. May be
you can find more info for the LVS integration into the Netfilter
framework by searching in the
<ulink url="http://marc.theaimsgroup.com/?l=linux-virtual-server&amp;m=98296653726641&amp;w=2">
LVS mail list archive</ulink> for "netfilter".
	</para>
	<para>
Julian 29 Oct 2001
	</para>
	<para>
        IPVS uses only the netfilter's hooks. It uses own connection
tracking and NAT. You can see how LVS fits into the framework on the
<ulink url="http://marc.theaimsgroup.com/?l=linux-virtual-server&amp;m=98296653726641&amp;w=2">mailing list archive</ulink>.
	</para>
	<para>
Ratz
	</para>
	<blockquote>
I see that the <filename>defense_level</filename> 
is triggered via a <filename>sysctrl</filename>
and invoked in the <filename>sltimer_handler</filename> 
as well as the <filename>*_dropentry</filename>. 
If we push those functions on level higher and introduce a metalayer
that registers the <filename>defense_strategy</filename> 
which would be selectable via <filename>sysctrl</filename> 
and would currently contain <filename>update_defense_level</filename> 
we had the possibility to register other defense strategies like 
<emphasis>e.g.</emphasis> limiting threshold. 
Is this feasible? I mean instead of calling 
<filename>update_defense_level()</filename>
and <filename>ip_vs_random_dropentry()</filename> in the 
<filename>sltimer_handler</filename> we just
call the registered <filename>defense_strategy[sysctrl_read]</filename> function. 
In the existing case the <filename>defense_strategy[0]=update_defense_level()</filename> 
which also merges the <filename>ip_vs_dropentry</filename>. 
Do I make myself sound stupid? ;)
	</blockquote>
	<para>
        The different strategies work in different places and it is
difficult to use one hook. The current implementation allows they to
work together. But may be there is another solution considering how
LVS is called: to drop packets or to drop entries. There are no many
places for such hooks, so may be it is possible something to be done.
But first let's see what kind of other defense strategies will come.
	</para>
	<blockquote>
Yes, the project got larger and more reputation than some of us
initially thought. The code is very clear and stable, it's time
to enhance it. The only very big problem that I see is that it
looks like we're going to have to separate code paths one patch
for 2.2.x kernels and one for 2.4.x.
	</blockquote>
	<para>
Yes, this is the reality. We can try to keep the things not
to look different for the user space.
	</para>
	<blockquote>
 This would be a pain in the ass if we had two versions of ipvsadm. IMHO the
 userspace tools should recognize (compile-time) what kernel it
 is working with and therefore enable the featureset. This will
 of course bloat it up in future the more feature-differences we
 will have regarding 2.2.x and 2.4.x series.
	</blockquote>
	<para>
        Not possible, the sockopt are different in 2.4
	</para>
	<para>
Joe (I think)
	</para>
	<blockquote>
Could you point me to a sketch where I could try to see how the
control path for a packet looks like in kernel 2.4? I mean some-
thing like I would do for 2.2.x kernels:
	</blockquote>
	<para>
Julian (I think)
	</para>
	<para>
        I hope there is a nice ascii diagram in the netfilter docs,
but I hope the info below is more useful if you already know what
each hook means.
	</para>
<programlisting><![CDATA[
           ----------------------------------------------------------------
           |            ACCEPT/                              lo interface |
           v           REDIRECT                  _______                  |
   --> C --> S --> ______ --> D --> ~~~~~~~~ -->|forward|----> _______ -->
       h     a    |input |    e    {Routing }   |Chain  |     |output |ACCEPT
       e     n    |Chain |    m    {Decision}   |_______| --->|Chain  |
       c     i    |______|    a     ~~~~~~~~        |     | ->|_______|
       k     t       |        s       |             |     | |     |
       s     y       |        q       |             v     | |     |
       u     |       v        e       v            DENY/  | |     v
       m     |     DENY/      r   Local Process   REJECT  | |   DENY/
       |     v    REJECT      a       |                   | |  REJECT
       |   DENY               d       --------------------- |
       v                      e -----------------------------
      DENY
]]></programlisting>
	<para>
Ratz (I think)
	</para>
	<blockquote>
The biggest problem I see here is that maybe the user space daemons
don't get enough scheduling time to be accurate enough.
	</blockquote>
	<para>
That is definitely true. When the CPU(s) are busy
transferring packets the processes can be delayed. So, the director
better not spend many cycles in user space. This is the reason I
prefer all these health checks to run in the realservers but this
is not always good/possible.
	</para>
	<blockquote>
 No, considering the fact that not all RS are running Linux. We would
 need to port the healthchecks to every possible RS architecture.
	</blockquote>
	<para>
Yes, this is a drawback.
	</para>
	<para>
unknown (Ratz ?)
	</para>
	<blockquote>
Tell me, which scheduler should I take? None of the existing ones
gives me good enough results currently with persistency. We have
to accept the fact, that 3-Tier application programmers don't
know about loadbalancing or clustering, mostly using Java and this
is just about the end of trying to load balance the application
smoothly.
	</blockquote>
	<para>
WRR + load informed cluster software. But I'm not sure in
the the case when persistency is on (it can do bad things).
	</para>
	<blockquote>
		<para>
I currently get some values via an daemon coded in perl on the RS,
started via xinetd. The LB connects to the healthcheck port and
gets some prepared results. He then puts this stuff into a db and
starts calculating the next steps to reconfigure the LVS-cluster to
smoothen the imbalance. The longer you let it running the more data
you get and the less adjustments you have to make. I reckon some
guy showing up on this list once had this idea in direction of
fuzzy logic. Hey Julian, maybe we should accept the fact that the
wlc scheduler also isn't a very advanced one:
		</para>
<programlisting><![CDATA[
loh = atomic_read(&least->activeconns)*50+atomic_read(&least->inactconns);
]]></programlisting>
		<para>
What would you think would change if we made this 50 dynamic?
		</para>
	</blockquote>
	<para>
        Not sure :) I don't have results from experiments with wlc :)
You can put it in /proc and to make different experiments, for example :)
But warning, ip_vs_wlc can be module, check how lblc* register /proc
vars.
	</para>
	</section>
	<section id="ipvs_for_netfilter" xreflabel="design of ipvs for netfilter">
	<title>The design of LVS for Netfilter and Linux 2.4, pt2</title>
	<para>
The
<ulink url="http://www.ssi.bg/~ja/LVS.txt">most recent version of
Julian's writeup of LVS and Netfilter (NF)</ulink> is on the LVS website.
Here is the version available in Jun 2002.
	</para>
		<section>
		<title>TODO:</title>
		<para>
- redesign  LVS to  work in  setups with  multiple default  routes (this
requires  changes in the kernels,  calling ip_route_input with different
arguments).  The end goal: one routing call in any direction (as before)
but do correct routing in in->out direction. The problems:
		</para>
		<itemizedlist>
			<listitem>
			<para>
fwmark   virtual  services   and  the  need   for  working  at
prerouting.   Solution: hook at PREROUTING  after the filter and
do  there connection  creation (after QoS,  fwmark setup).  Hook
at  prerouting, listen  for traffic  for established connections
and  call ip_route_input  with the right  arguments (possibly in
the  routing chain). Goal: always pass  one filter chain in each
direction  (FORWARD).  The fwmark  is  used only  for connection
setup and then is ignored.
			</para>
			</listitem>
			<listitem>
hash  twice the NAT  connections in same  table (at prerouting
we can see both requests and replies), compare with cp->vaddr to
detect the right direction
			</listitem>
		</itemizedlist>
		<para>
- help from Netfilter to redesign the kernel hooks:
		</para>
		<itemizedlist>
			<listitem>
ROUTING  hook (used  from netfilter's NAT,  LVS-DR and in->out
LVS-NAT)
			</listitem>
			<listitem>
fixed  ip_route_input to do source routing with the masquerade
address as source (lsrc argument)
			</listitem>
			<listitem>
more control over what to walk in the netfilter hooks?
			</listitem>
		</itemizedlist>
		<para>
- different  timeouts  for each  virtual server  (more control  over the
connection timeouts)
		</para>
		<para>
- Allow LVS to be used as NAT router/balancer for outgoing traffic
		</para>
		</section>
		<section>
		<title>CURRENT STATE:</title>
		<para>
Running variants:
		</para>
		<itemizedlist>
			<listitem>
1. Only lvs - the fastest
			</listitem>
			<listitem>
2. lvs + ipfw NAT
			</listitem>
			<listitem>
3. lvs + iptables NAT
			</listitem>
		</itemizedlist>
		<para>
Where is LVS placed:
		</para>
<programlisting><![CDATA[
LOCAL_IN:100 ip_vs_in

FORWARD:99 ip_vs_forward_icmp
FORWARD:100 ip_vs_out

POST_ROUTING:NF_IP_PRI_NAT_SRC-1 ip_vs_post_routing
]]></programlisting>
		<para>
The chains:
		</para>
		<para>
The out->in LVS packets (for any forwarding method) walk:
		</para>
<programlisting><![CDATA[
pre_routing -> LOCAL_IN -> ip_route_output or dst cache -> POST_ROUTING


	LOCAL_IN
	ip_vs_in	-> ip_route_output/dst cache
			-> mark skb->nfcache with special bit value
			-> ip_send -> POST_ROUTING

	POST_ROUTING
	ip_vs_post_routing
			- check skb->nfcache and exit from the
			chain if our bit is set
]]></programlisting>
		<para>
The in->out LVS packets (for LVS/NAT) walk:
		</para>
<programlisting><![CDATA[
pre_routing -> FORWARD -> POST_ROUTING

	FORWARD (check for related ICMP):
	ip_vs_forward_icmp	-> local delivery -> mark
				skb->nfcache -> POST_ROUTING

	FORWARD
	ip_vs_out		-> NAT -> mark skb->nfcache -> NF_ACCEPT

	POST_ROUTING
	ip_vs_post_routing
			- check skb->nfcache and exit from the
			chain if our bit is set
]]></programlisting>
		<para>
Why LVS is placed there:
		</para>
		<para>
- LVS  creates  connections after  the  packets are  marked,  i.e. after
PRE_ROUTING:MANGLE:-150   or  PRE_ROUTING:FILTER:0.  LVS   can  use  the
skb->nfmark as a virtual service ID.
		</para>
		<para>
- LVS must be after PRE_ROUTING:FILTER+1:sch_ingress.c - QoS setups.  By
this way the incoming traffic can be policed before reaching LVS.
		</para>
		<para>
- LVS  creates connections after  the input routing  because the routing
can  decide to deliver locally packets  that are marked or other packets
specified  with  routing rules.  Transparent  proxying handled  from the
netfilter NAT code is not always a good solution.
		</para>
		<para>
- LVS  needs to  forward packets  not looking  in the  IP header (direct
routing  method), so calling  ip_route_input with arguments  from the IP
header only is not useful for LVS
		</para>
		<para>
- LVS is after any firewall rules in LOCAL_IN and FORWARD
		</para>
		</section>
		<section>
		<title>Requirements for the PRE_ROUTING chain</title>
		<para>
Sorry,  we  can't  waste  time  here.  The  netfilter connection
tracking  can mangle packets  here and we  don't know at  this time if a
packet  is  for our  virtual service  (new  connection) or  for existing
connection  (needs lookup in the LVS connection table). We are sure that
we  can't make decisions whether to create new connections at this place
but  lookup for existing connections  is possible under some conditions:
the packets must be defragmented, etc.
		</para>
		<para>
There  are so  many nice modules  in this  chain that can  feed LVS with
packets (probably modified)
		</para>
		</section>
		<section>
		<title>Requirements for the LOCAL_IN chain</title>
		<para>
The conditions when sk_buff comes:
		</para>
		<para>
- ip_local_deliver() defragments the packets (ip_defrag) for us
		</para><para>
- the incoming sk_buff can be non-linear
		</para><para>
- when the incoming sk_buff comes only the read access is guaranteed
		</para><para>
What we do:
		</para><para>
- packets  generated  locally are  not  considered because  there  is no
known  forwarding method  that can  establish connection  initiated from
the director.
		</para><para>
- only TCP, UDP and related to them ICMP packets are considered
		</para><para>
- the  protocol header must  be present before making  any work based on
fields from the IP or protocol header.
		</para><para>
- we  detect  here  packets  for the  virtual  services  or  packets for
existing  connections  and then  the transmitter  function for  the used
forwarding method is called
		</para><para>
- the NAT transmitter performs the following actions:
		</para>
		<blockquote>
			<para>
	We  try to make  some optimizations for  the most of the
	traffic  we see:  the normal  traffic that  is not  bound to any
	application  helper, i.e.  when the  data part  (payload) in the
	packets is not written or even not read at all. In such case, we
	change the addresses and the ports in the IP and in the protocol
	header  but we  don't make any  checksum checking  for them.  We
	perform  incremental checksum update after the packet is mangled
	and  rely on the realserver  to perform the full check (headers
	and payload).
			</para><para>
		If  the connection  is bound to  some application helper
	(FTP  for example) we always  perform checksum checking with the
	assumption  that  the  data  is  usually  changed  and  with the
	additional   assumption  that  the   traffic  using  application
	helpers  is low. To perform such  check the whole payload should
	be  present in the provided sk_buff. For this, we call functions
	to  linearize  the  sk_buff  data  by  assembling  all  its data
	fragments.
			</para><para>
		Before  the addresses  and ports  are changed  we should
	have  write  access to  the packet  data (headers  and payload).
	This  guarantees that  the packet data  should be  seen from any
	other  readers unchanged.   The copy-on-write  is performed from
	the  linearization function for the  packets that were with many
	fragments.  For all other packets we should copy the packet data
	(headers  and  payload) if  it is  used  from someone  else (the
	sk_buff  was  cloned).   The packets  not  bound  to application
	helpers  need  such write  access  only for  the  first fragment
	because  for  them  only the  IP  and the  protocol  headers are
	changed  and we guarantee  that they are  in the first fragment.
	For  the packets using application  helpers the linearization is
	already done and we are sure that there is only one fragment. As
	result, we need write access (copy if cloned) only for the first
	fragment.   After the application helper is called to update the
	packet data we perform full checksum calculation.
			</para>
		</blockquote>
		<para>
- the DR transmitter performs the following actions:
		</para>
		<blockquote>
		Nothing special, may be it is the shortest function. The
	only  action is to reroute the  packet to the bound realserver.
	If  the  packet  is fragmented  then  ip_send_check()  should be
	called to refresh the checksum.
		</blockquote>
		<para>
- the TUN transmitter performs the following actions:
		</para>
		<blockquote>
		Copies  the packet  if is already  referred from someone
	else  or when there is no space for the IPIP prefix header.  The
	packet  is  rerouted  to  the real  server.   If  the  packet is
	fragmented  then ip_send_check() should be called to refresh the
	checksum in the old IP header.
		</blockquote>
		<para>
- if  the packets must  leave the box  we send them  to POST_ROUTING via
ip_send  and return  NF_STOLEN.  This  means that  we remove  the packet
from  the LOCAL_IN chain before reaching priority LAST-1.  The LocalNode
feature just returns NF_ACCEPT without mangling the packet.
		</para>
		<blockquote>
			<para>
	In  this chain  if a  packet is  for LVS  connection (even newly
created)  the LVS calls  ip_route_output (or uses  a destination cache),
marks  the packet as a LVS property (sets bit in skb->nfcache) and calls
ip_send()    to   jump   to   the   POST_ROUTING   chain.    There   our
ip_vs_post_routing  hook must  call the  okfn for  the packets  with our
special nfcache bit value (Is skb->nfcache used after the routing calls?
We rely on the fact that it is not used) and to return NF_STOLEN.
			</para><para>
	One  side effect: LVS can forward packet even when ip_forward=0,
only  for  DR  and  TUN  methods. For  these  methods  even  TTL  is not
decremented nor data checksum is checked.
			</para>
		</blockquote>
		</section>
		<section>
		<title>Requirements for the FORWARD chain</title>
		<para>
	LVS  checks  first  for  ICMP  packets  related  to  TCP  or UDP
connections.   Such  packets are  handled as  they  are received  in the
LOCAL_IN  chain - they are localy  delivered. Used for transparent proxy
setups.
		</para><para>
	LVS  looks in  this chain for  in->out packets but  only for the
LVS/NAT  method. In any  case new connections are  not created here, the
lookup is for existing connections only.
		</para><para>
	In  this chain  the ip_vs_out function  can be  called from many
places:
		</para><para>
	FORWARD:0 - the  ipfw  compat mode  calls ip_vs_out  between the
forward  firewall and  the masquerading.  By  this way LVS  can grab the
outgoing  packets for its connection  and to avoid they  to be used from
the netfilter's NAT code.
		</para><para>
	FORWARD:100  - ip_vs_out  is registered after  the FILTER=0.  We
can  come here twice if the ipfw compat module is used because ip_vs_out
is  called once from FORWARD:0 (fw_in) and after that from pri=100 where
LVS always registers the ip_vs_out function.  We detect this second call
by  looking in the skb->nfcache bit value.   If the bit is set we return
NF_ACCEPT.   In fact, the second ip_vs_out  call is avoided if the first
returns NF_STOLEN and after calling the okfn function.
		</para><para>
The  actions we perform  are the same  as in the  LOCAL_IN chain for the
NAT  transmitter with the exception that we should call ip_defrag(). The
other  difference is that we have write access to the first fragment (it
is not referred from someone else) after ip_forward() calls skb_cow().
		</para>
		</section>
		<section>
		<title>Requirements for the POST_ROUTING chain</title>
		<para>
	LVS marks the packets for debugging and they appear to come from
LOCAL_OUT  but this  chain is not  traversed. The  LVS requirements from
the  POST_ROUTING chain include  the fragmentation code  only.  But even
the  ICMP  messages are  generated and  mangled  ready for  sending long
before the POST_ROUTING chain: ip_send() does not call ip_fragment() for
the  LVS packets  because LVS returns  ICMP_FRAG_NEEDED when  the mtu is
shorter.
		</para><para>
	LVS  makes MTU checks  when accepting packets  and selecting the
output device. So, the ip_refrag POST_ROUTING hook is not used from LVS.
		</para><para>
	The  result is: LVS must hook POST_ROUTING as first (may be only
after  the ipfw compat  filter) and to return  NF_STOLEN for its packets
(detected by checking the special skb->nfcache bit value).
		</para>
		<para>
The Netfilter hooks:
		</para>
<programlisting><![CDATA[
Priorities:
        NF_IP_PRI_FIRST = INT_MIN,
        NF_IP_PRI_CONNTRACK = -200,
        NF_IP_PRI_MANGLE = -150,
        NF_IP_PRI_NAT_DST = -100,
        NF_IP_PRI_FILTER = 0,
        NF_IP_PRI_NAT_SRC = 100,
        NF_IP_PRI_LAST = INT_MAX,


PRE_ROUTING (ip_input.c:ip_rcv):
	CONNTRACK=-200, ip_conntrack_core.c:ip_conntrack_in
	MANGLE=-150, iptable_mangle.c:ipt_hook
	NAT_DST=-100, ip_nat_standalone.c:ip_nat_fn
	FILTER=0, ip_fw_compat.c:fw_in, defrag, firewall, demasq, redirect
	FILTER+1=1, net/sched/sch_ingress.c:ing_hook

LOCAL_IN (ip_input.c:ip_local_deliver):
	FILTER=0, iptable_filter.c:ipt_hook
	LVS=100, ip_vs_in
	LAST-1, ip_fw_compat.c:fw_confirm
	CONNTRACK=LAST-1, ip_conntrack_standalone.c:ip_confirm

FORWARD (ip_forward.c:ip_forward):
	FILTER=0, iptable_filter.c:ipt_hook
	FILTER=0, ip_fw_compat.c:fw_in, firewall, LVS:check_for_ip_vs_out,
		masquerade
	LVS=99, ip_vs_forward_icmp
	LVS=100, ip_vs_out

LOCAL_OUT (ip_output.c):
	CONNTRACK=-200, ip_conntrack_standalone.c:ip_conntrack_local
	MANGLE=-150, iptable_mangle.c:ipt_local_out_hook
	NAT_DST=-100, ip_nat_standalone.c:ip_nat_local_fn
	FILTER=0, iptable_filter.c:ipt_local_out_hook

POST_ROUTING (ip_output.c:ip_finish_output):
	FILTER=0, ip_fw_compat.c:fw_in, firewall, unredirect,
		mangle ICMP replies
	LVS=NAT_SRC-1, ip_vs_post_routing
	NAT_SRC=100, ip_nat_standalone.c:ip_nat_out
	CONNTRACK=LAST, ip_conntrack_standalone.c:ip_refrag


CONNTRACK:
	PRE_ROUTING, LOCAL_IN, LOCAL_OUT, POST_ROUTING

FILTER:
	LOCAL_IN, FORWARD, LOCAL_OUT

MANGLE:
	PRE_ROUTING, LOCAL_OUT

NAT:
	PRE_ROUTING, LOCAL_OUT, POST_ROUTING
]]></programlisting>
		</section>
	</section>
	<section id="example_ip_table_script">
	<title>Example ip_tables filter scripts</title>
	<para>
A simple firewall installation script is
<ulink url="http://muse.linuxmafia.org/gshield.html">gshield</ulink>.
	</para>
	<para>
This script below by Tim Cronin, was written before <xref linkend="ipvs_nfct"/> became available.
	</para>
	<para>
Tim Cronin <emphasis>tim (at) 13-colonies (dot) com</emphasis> 14 Feb 2003
	</para>
<programlisting><![CDATA[
# ipvsadm
IP Virtual Server version 1.0.6 (size=1048576)
Prot LocalAddress:Port Scheduler Flags
  -> RemoteAddress:Port           Forward Weight ActiveConn InActConn
TCP  xx.xx.xx.xx:http wlc persistent 1200
  -> 192.168.1.25:http            Masq    1      0          2
TCP  xx.xx.xx.xx:http wlc persistent 1200
  -> 192.168.1.20:http            Masq    2      16         11
  -> 192.168.1.10:http            Masq    3      17         23
]]></programlisting>
	<para>
This 
<ulink url="files/tim_cronin.sh">script</ulink>
(http://www.austintek.com/LVS/LVS-HOWTO/HOWTO/files/tim_cronin.sh)
has been running reliably in production for 6 months.
The link at the top of the script is a good starting point to understand how it works.
Note that the default config generates copious logs.
The IP addresses have been changed to protect the innocent server.
I had problems with the syn flag hence the section ignoring stuff going
to the vips.
	</para>
	</section>
	<section id="netfilter_speed">
	<title>performance hit on director with iptables/netfilter</title>
	<para>
Dant <emphasis>dan (at) id-confirm (dot) com</emphasis>
	</para>
	<blockquote>
I setup an intrusion detection system (IDS) on the director, and I had a simple test on
the director by connectting the mean-service-time, HitRatio .. which cost me
dual weeks. And I found that snort does not affect the performance.
	</blockquote>
	<para>
ratz 16 Nov 2005
	</para>
	<para>
Depends on the configuration, it's actually quiet easy to kill Snort
with some advanced ruleset and above L4 checks.
	</para>
	<blockquote>	
as both
snort and iptables use libpcap library to scratch packets,
	</blockquote>
	<para>
iptables does not use libpcap, to my avail, so I'm not sure I understand
your question.
	</para>
	<blockquote>
does it mean the
iptables will not affect the director's performance ? or am I right before
when using snort?
	</blockquote>
	<para>
iptables is the user space part of netfilter, which is in the kernel. So
no, iptables will not hurt performance, but netfilter certainly does,
depending on the usage, amount of rules and your hardware configuration.
	</para>
	<blockquote>
I'm running several highly loaded LVSs, these days I found that there are
so many malicious scans, so I want to ban them all by portsentry. And we
also confused by by ddos :-/
	</blockquote>
	<para>
Portsentry only mitigates the problem, doesn't solve it. Also, it's not
something that should be implemented on the LVS. Also having a NIDS on
the director is a bit suboptimal, since a IDS should at best not be
detectable and should also be in read-only mode. Either put a second box
between the networks you need to sniff, preferrably in bridge mode or
modify your network cables by removing the TX part, so only receiving is
possible. Both suggestions don't work well with a director.
	</para>
	<para>
On the modifying-network-cables-for-IDS part: http://www.snort.org/docs/tap/
	</para>
	<blockquote>
While we're touching on this subject here, what kind of a NIDS do people
use inside an LVS setup, and how can it be implemented?  
	</blockquote>
	<para>
There's nothing special about LVS that would require a different 
approach to NIDS, so this is more a general question off how to deploy 
IDS; and this, I'm afraid, is subject to personal views. I don't know on 
which level you plan on deploying IDS, but a good starter is the Snort 
documentation corner, which can be found at: http://www.snort.org/docs/
Especially interesting is the IDS load balancer. I've talked to Marty 
about load balancing traffic to multiple IDS nodes to share the load in 
2001 I think, however I don't remember what our consensus was.
	</para>
	<para>
Other than that you'd have to be a bit more specific. I'd be glad to 
help, although I've left the IDS field 2-3 years ago. One of the reason 
is that with the Basel II and the Sarbanes-Oxley acts 
(http://www.aicpa.org/sarbanes/index.asp)
you barely 
can't allow yourself anymore to "lose" data, which in the sense of IDS 
translates to either "false positives" or "true negatives". Since the 
two items mentioned are a general issue of IDS systems, that require 
highly skilled personnel, other means to acquire the demanded level of 
security quality management have to be found, for example: reliable 
logging and monitoring, on top of a well-thought and implemented 
security policy.
	</para>
	</section>
	<section id="gratuitous_icmp">
	<title>Long sessions through LVS DR director terminated by icmp-host-prohibited (ICMP type 3 code 10)</title>
	<note>
This problem was found in the normal operation of an LVS.
The problem is with netfilter, not LVS.
Netfilter is gratuitously sending icmp packets in an ESTABLISHED connection.
We don't know what the problem is about (yet).
It's here in case someone else finds it too.
	</note>
	<para>
Klaas Jan Wierenga <emphasis>k (dot) j (dot) wierenga (at) home (dot) nl</emphasis> 13 Mar 2007
	</para>
	<para>
I have a problem where sometimes some long standing mp3 streaming sessions over HTTP are terminated because the LVS-DR
director sends an "ICMP type 3 code 10 - host unreachable" packet to the client (which is the source of the mp3 stream).
When this happens the client stops sending packets for 15 minutes 15 minutes (the TCP idle session timeout of LVS?) before
it reconnects on the same ports. The 15 minutes seems to be related to the connection timing out of the LVS connection
table.
	</para>
	<para>
When this happens the real servers are all fine, load is not heavy and ldirectord is able to perform it's checks. In fact
nothing shows in the ldirectord.log so the real servers are all available.
This is quite a long post, I've tried to include all relevant details.
	</para>
	<para>
My setup: ISP router -> LVS Director -> Local switch -> Realserver[123] -> ISP router
	</para>
	<para>
Directions I've looked into so far and questions I've asked myself:
	</para>
	<orderedlist>
		<listitem>
enabled "quiescent=yes" to maybe not terminate existing connection, but this is not the problem I think because the real
servers are all available when this happens.
		</listitem>
		<listitem>
Where is this ICMP packet generated in linux/net/ipv4/ipvs/* source files? Answer: nowhere!, at least not with type 3
code 10
		</listitem>
		<listitem>
Could it be that this ICMP packet is generated by some sort of denial-of-service defense code that I'm unaware of?
		</listitem>
		<listitem>
			<para>
Where is this specific ICMP packet (HOST_UNREACH_ANO) genererated in the kernel?
			</para>
			<para>
Answer: net/ipv4/netfilter/ipt_REJECT.c:                send_unreach(*pskb, ICMP_HOST_ANO);
			</para>
	<para>
So it appears that netfilter (iptables?) is sending it. Why?
This could be due to the firewall rule:
	</para>
<programlisting><![CDATA[
REJECT     all  --  anywhere             anywhere            reject-with icmp-host-prohibited
]]></programlisting>
	<para>
But why is this sent on an existing, established and active connection? Or is there some TCP timeout because the director
only sees incoming packets on the connection? Maybe this rings a bell with someone.
	</para>
		</listitem>
		<listitem>
			<para>
Maybe the client is not behaving correctly by not continuing to send data after receiving ICMP host unreachable? TCP/IP
Illustrated Vol1 [Stevens] says on page 317, 21.10 ICMP Errors:
			</para>
			<para>
"A received host unreachable or network unreachable is effectively ignored, since these two errors are considered transient.
... It could be that an intermediate router has gone down and it can take the routing protocols a few minutes to stabilize
on an alternative route.. During this period either of these two ICMP errors can occur, but the must not abort the
connection. Instead, TCP keeps trying to send the data that caused the error, although it may eventually time out."
			</para>
		</listitem>
	</orderedlist>
	<para>
Later...
	</para>
	<para>
A while ago I posted about a problem I was having with long mp3 streaming sessions which were terminated because the
streaming LVS cluster (managed by me) was sending icmp-host-prohibited on an established connection to the client which was
causing the connection to be terminated.
	</para>
	<para>
Initially I suspected the LVS director but after some investigation I found out that it never sends icmp-host-prohibited.
The only other possibility was netfilter sending it.
The relevant parts of my initial iptables was (<filename>/etc/sysconfig/iptables</filename>):
	</para>
<programlisting><![CDATA[
*filter
:FORWARD ACCEPT [0:0]
:INPUT ACCEPT [0:0]
:RH-Firewall-1-INPUT - [0:0]
:OUTPUT ACCEPT [0:0]
-A FORWARD -j RH-Firewall-1-INPUT
-A INPUT -j RH-Firewall-1-INPUT
-A RH-Firewall-1-INPUT -i lo -j ACCEPT
-A RH-Firewall-1-INPUT -p icmp -m icmp --icmp-type any -j ACCEPT
-A RH-Firewall-1-INPUT -m state --state RELATED,ESTABLISHED -j ACCEPT
-A RH-Firewall-1-INPUT -p tcp -m state -m tcp --dport 80 --state NEW -j ACCEPT
-A RH-Firewall-1-INPUT -j REJECT --reject-with icmp-host-prohibited
COMMIT
]]></programlisting>
	<para>
After I changed the port 80 rule to the one below effectively disabling connection tracking on port 80 the problem
disappeared.
	</para>
<programlisting><![CDATA[
-A RH-Firewall-1-INPUT -p tcp --dport 80 -j ACCEPT
]]></programlisting>
	<para>
Initially I made this iptables change on the LVS director, but then the realservers would send 
<filename>icmp-host-prohibited</filename>
sometimes on established connections, 
after also changing iptables on the realservers did the problem go away.
	</para>
	<para>
It is still unclear to me why netfilter would decide to send icmp-host-unreachable on established connection when connection
tracking is active. Maybe someone on the netfilter list can shed some light on this.
	</para>
	<para>
Still later... did you ever find a better solution?
	</para>
	<para>
Klaas Jan Wierenga <emphasis>k (dot) j (dot) wierenga (at) home (dot) nl</emphasis> 26 Jun 2007
	</para>
	<para>
Not really. It appears to be a netfilter problem because when I changed my
firewall rules (<filename>/etc/sysconfig/iptables</filename>) 
to disable connection tracking, the problem went away.
	</para>
<programlisting><![CDATA[
# Don't do connection tracking on port 80 and 8000, 
# because sometimes it results in dropped connections due to ICMP_HOST_UNREACHABLE messages
#
#-A RH-Firewall-1-INPUT -p tcp -m state -m tcp --dport 80 --state NEW -j ACCEPT
#-A RH-Firewall-1-INPUT -p tcp -m state -m tcp --dport 8000 --state NEW -j ACCEPT
-A RH-Firewall-1-INPUT -p tcp --dport 80 -j ACCEPT
-A RH-Firewall-1-INPUT -p tcp --dport 8000 -j ACCEPT
]]></programlisting>
	</section>
	<section id="stateful_filtering_LVS-NAT">
	<title>stateful filtering: LVS-NAT</title>
	<note>
Laurentiu didn't know about Siim Poder's patch for stateful LVS-NAT filtering 
about 2 months previously

FIXME: write up Siim's patch and link this to it.
	</note>
	<para>
Laurentiu C. Badea (L.C.) <emphasis>lc (at) waat (dot) com</emphasis> 10 Sep 2008 
	</para>
	<para>
This is my solution to the problem I found of 
the last FIN-ACK eaten by iptables.
I had a simple LVS-NAT configuration where LVS lives on a gateway:
The kernel is 2.6.20 with ipvsadm 1.24 (Fedora 5).
	</para>
<programlisting><![CDATA[
  CIP - VIP/LVS - RIP
]]></programlisting>
	<para>
LVS does run iptables but fairly open, INPUT allows all incoming traffic for the VIP, OUTPUT allows NEW,ESTABLISHED,RELATED
states and FORWARD is open (for what it's worth, I think ipvs does not go through there at all). So that worked fine.
	</para>
	<para>
Until I noticed the real server has many connections in FIN_WAIT2 state. They have the same timeout as TIME_WAIT so I was gonna
let it go, but then I looked at the client and all of them were in LAST_ACK state. The client kept resending FIN-ACKs, none of
which made it to the server at all. On the LVS, ipvsadm -Lc shows connections in TIME_WAIT state so it did get them.
	</para>
	<para>
Well, long story short, the OUTPUT chain blocked *only* that FIN-ACK packet for some odd reason. I was sure that ipvs is
shortcircuiting iptables and bypassing OUTPUT, but I guess I misinterpreted the little map in the HOWTO. All the other packets
matched the "NEW" rule. This would would have ended up as INVALID probably. I am now adding rules to allow all OUTPUT towards
the RIPs, stateless.
	</para>
<programlisting><![CDATA[
This is how it looked from the network side:
Incoming traffic to LVS (CIP->VIP)
  0.016862  CIP -> VIP HTTP HEAD / HTTP/1.1
  0.017193 VIP -> CIP  [ACK] Seq=1 Ack=117 Win=5888 Len=0
  0.021949 VIP -> CIP  [TCP segment of a reassembled PDU]
  0.022173 VIP -> CIP  [FIN, ACK] Seq=195 Ack=117 Win=5888 Len=0
  0.034046  CIP -> VIP [ACK] Seq=117 Ack=195 Win=6912 Len=0
 *0.046042  CIP -> VIP [FIN, ACK] Seq=117 Ack=196 Win=6912 Len=0*
the above packet does not make it, beyond here retransmits only
  0.250217 VIP -> CIP  [FIN, ACK] Seq=195 Ack=117 Win=5888 Len=0
  0.260110  CIP -> VIP [FIN, ACK] Seq=117 Ack=196 Win=6912 Len=0
  0.267333  CIP -> VIP [TCP Dup ACK 11#1] [ACK] Seq=118 Ack=196 Win=6912 Len=0 SLE=195 SRE=196
  0.705855  CIP -> VIP [FIN, ACK] Seq=117 Ack=196 Win=6912 Len=0

Coming out the other end towards RIP:
  0.016847  CIP -> RIP HTTP HEAD / HTTP/1.1
  0.017119 RIP -> CIP  [ACK] Seq=1 Ack=117 Win=5888 Len=0
  0.021873 RIP -> CIP  [TCP segment of a reassembled PDU]
  0.022115 RIP -> CIP  [FIN, ACK] Seq=195 Ack=117 Win=5888 Len=0
  0.034021  CIP -> RIP [ACK] Seq=117 Ack=195 Win=6912 Len=0
only two retransmits seen:
  0.250147 RIP -> CIP  [FIN, ACK] Seq=195 Ack=117 Win=5888 Len=0
  0.267312  CIP -> RIP [TCP Previous segment lost] [ACK] Seq=118 Ack=196 Win=6912 Len=0 SLE=195 SRE=196
]]></programlisting>
	<para>
The current setup seems to work except for a minor annoyance - the 
netfilter conntrack table still has the connections, when I would have 
expected that to be almost empty, given that LVS steals the packets from 
nf. The connections display as UNREPLIED and originating on the RIP:80 
so they aren't "real" but I'm curious which packets from the real server 
triggered them.
	</para>
	<para>
A blanket ACCEPT rule on outgoing traffic doesn't seem very secure for a 
firewall, and in my case there's a firewall in front of the LVS.
	</para>
	<para>
Outgoing FORWARDed traffic is not the one allowed though, it is the 
traffic originating on the LVS machine itself, the OUTPUT chain in the 
main table which is usually left open anyway.
	</para>
	<para>
Since then I have noticed the INPUT chain would have blocked the same 
packet in the same configuration, so both INPUT and OUTPUT need to have 
a stateless ACCEPT on that tcp port for the LVS to work.
	</para>
	</section>
	<section id="stateful_filtering_LVS-DR">
	<title>stateful filtering: LVS-DR</title>
	<note>
Because the director cannot see the reply packets from the realserver, 
the standard netfilter stateful filtering can't be used with LVS-DR (or LVS-Tun).
	</note>
	<para>
Thomas Pedoussaut <emphasis>thomas (at) pedoussaut (dot) com</emphasis> 22 Apr 2008
	</para>
	<para>
For one of my dozen of services ( a straight TCP connection), the 
TCP-FIN packets that are arriving on the load balancer are never passed 
to the real server.
I activated the logs of iptable and could see the FIN packets being dropped.
No idea why the FIN are dropped and not the other ones. I obviously have 
the  --state ESTABLISHED,RELATED -j ACCEPT in my iptable rules.
	</para>
	<para>
I had a quick look at <filename>/proc/net/ip_conntrack</filename> before, during and after 
the connection but nothing specific to that connection seems to be 
inserted (the module is loaded and other traffic gets tracked).
	</para>
	<para>
It even happen when I close the client connection within seconds of 
creation, so I don't think timeouts are involved.
My issue is that the application in backend doesn't deal with timeouts, 
so never initiate the closing of the connection.
	</para>
	<para>
Later...
	</para>
	<para>
Basically, all packets (SYN and non-SYN) are allowed by the "--state 
NEW" iptables but not by the ESTABLISHED,RELATED, because the director 
never sees the replies from the real server and so never creates a 
conntrack for that connection.
When a FIN packet arrives, it is not validated as a --state NEW, because 
it's flag FIN is activated and so, that particular packet is dropped.
	</para>
	<para>
So the solution is to change the iptables rule
	</para>
<programlisting><![CDATA[
from
-A RH-Firewall-1-INPUT -m state --state NEW -m tcp -p tcp --dport $VPORT -j ACCEPT
to
-A RH-Firewall-1-INPUT -m tcp -p tcp --dport $VPORT -j ACCEPT
]]></programlisting>
	</section>
</section>
<section id="LVS-HOWTO.cluster_friendly_applications" xreflabel="cluster friendly applications">
<title>LVS: Cluster friendly versions of applications that need to maintain state</title>
	<section id="L7_ratz" xreflabel="rewriting your e-commerce application">
	<title>rewriting your application/service</title>
	<para>
Complicated websites can be hard to run under LVS (<emphasis>e.g.</emphasis> websites
with servlets).
The problem is that the website has been written with the assumption that all functions
on the website will always be together on the same machine.
This was a reasonable assumption not so long ago, but now with
customers wanting high availability (and possibly high throughput),
this assumption is no longer valid. The assumption will be invalid
if the client writes to the server (see <xref linkend="many_reader_single_writer"/>)
or if the server maintains state information about the client
(see <xref linkend="cookie"/>.
Often people setting up an LVS hope that LVS can look inside the
packets for content and direct the packet to an appropriate realserver.
LVS can't do this.
In all cases, this simplest, most robust solution is to rewrite the
application to run in a high availability environment.
Administratively this sort of proposal is not well received by
management, who don't like to hear that their expensive web application
was not properly written.
Management will likely be more receptive to canned solutions from glib
sales people, who will tell management that an L7 loadbalancer is
a simple solution (it is, but it is also slow and expensive).
	</para>
	<para>
Roberto Nibali <emphasis>ratz (at) tac (dot) ch</emphasis> 19 Apr 2001
	</para>
	<para>
LVS is a Layer4 load balancer and can't do content based (L7) load balancing.
	</para>
	<para>
You shouldn't try to solve this problem by changing the TCP Layer to provide a
solution which should be handled by the Application Layer. You should never
touch/tweak TCP settings out of the boundaries given in the various RFC's and
their implementations.
	</para>
	<para>
If your application passes a cookie to the client, these are
the general approaches:
	</para>
	<itemizedlist>
		<listitem>
	buy an L7 load balancer (and don't use LVS).
		</listitem>
		<listitem>
		<para>
Set a very high persistency timeout and hope it is higher than the period
a client will wait to come back after he found his credit card, or look
at other sites, or have a cup of coffee.
		</para>
		<para>
This is not a good solution.
		</para>
		<itemizedlist>
			<listitem>
Increased persistency timeout increases the number of
concurrent connections possible, which increases the amount of memory
required to hold the connection table.
A persistency timeout of 30min, with clients connecting at 500 connections/s
you would need a memory pool of at least: 30*60*128*500/(1024*1024) = 109 MBytes.
With the standard timeout of 300 seconds, you'd only need 109/6 = 18 Mbytes.
			</listitem>
			<listitem>
Long persistency times are incompatible with the DoS defense strategies
employeed by <link linkend="DoS">secure_tcp</link>.
			</listitem>
		</itemizedlist>
		</listitem>
		<listitem>
		<para>
Have a 2-tier architecture where you have the application directly on
the webserver itself and maybe helped by a database. The problem of the cookies
storage is not solved however. You have to deal with the replication
problem. Imagine following setup:
		</para>
<programlisting><![CDATA[
                       ---->  Web1/App -->
                     /                    \
  Clients  ----> director ->  Web2/App ---> DB Server
                     \                    /
                       ---->  Web3/App -->
]]></programlisting>
		<para>
Cookies are generated and stored locally on each WebX server. But if you have
a persistency timeout of 300s (default LVS setting) and the client had his cup
of coffee while entering his visa numbers, he would get to a new server. This
new server whould then ask the client to reauthenticate.
There are solutions to this <emphasis>e.g</emphasis>
		</para>
		<itemizedlist>
			<listitem>
NFS export a dedicated cookie directory over the back-interfaces.
Cookies are quickly distributed among the servers.
			</listitem>
			<listitem>
			<para>
the application is written to handle cookie replication
and propagation between the WebX servers (you have at least 299 seconds time to
replicate the cookie on all web servers. This should be enough even
for distributing over serial line and do a crosscheck :)
			</para>
			<para>
This does not work (well) for geographically distributed webserver.
			</para>
			</listitem>
		</itemizedlist>
		</listitem>
		<listitem>
		<para>
3-Tier architecture
		</para>
<programlisting><![CDATA[
                       -->  Web1 --
                     /              \
  Clients  ----> LVS ---->  Web2 ----> Application Server <---> DB Server
                     \              /
                       -->  Web3 -->
]]></programlisting>
		<para>
The cookies are generated by the application server and either stored there or
on the database server. If a request comes in, the LVS assigns the request f.e
to Web1 and sets the persistency timeout. Web1 does a short message exchange
with the application server which generates the sessionID as a cookie and
stores it. The webserver sends the cookie back and now we are safe. Again this
whole procedure has t_pers_timeout (300 seconds normally) amout of time. Let's
assume the client times out (has gone for a cup of coffee).
When he comes back normally on a Layer4 load balancer he will be
forwarded to a new server, (say Web2). The CGI script on Web2
does the same as happened originally on Web1:
it generates a cookie as sessionID.
But the application server will tell the script that there is already a
cookie for this client and will pass it to Web2.
In this way we have unlimited persistency based on cookies but limited
persistency for TCP.
		</para>
		<para>
Advantages
		</para>
		<itemizedlist>
			<listitem>
set your own persistency timeout values
			</listitem>
			<listitem>
TCP state timeout values are not changed.
			</listitem>
			<listitem>
table lookup is faster
			</listitem>
			<listitem>
it's cheaper than buying an L7 load balancer
			</listitem>
		</itemizedlist>
		<para>
Disadvantages:
		</para>
		<itemizedlist>
			<listitem>
more complex setup, more hardware
			</listitem>
			<listitem>
you have to write some software
			</listitem>
		</itemizedlist>
		</listitem>
		<listitem>
If a separate database is running on each webserver, use
replication to copy the cookie between servers. (You have 300 secs
to do this). This was also mentioned by Ted Pavlic in connection
with <link linkend="databases">databases</link>.
		</listitem>
	</itemizedlist>
	</section>
	<section id="session_data" xreflable="session data">
	<title>Session Data, maintaining state in a cluster, from Andreas Koening</title>
	<para>
Andreas J. Koenig <emphasis>andreas.koenig (at) anima (dot) de</emphasis> 2001-06-26
	</para>
	<itemizedlist>
		<listitem>
			<para>
What are sessions?
			</para>
			<para>
When an application written on top of a stateless protocol like HTTP
has a need of stateful transactions, it typically writes some data to
disk between requests and retrieves these data again on the subsequent
request. This mechanism is known as session handling. The session data
typically get written to files or databases. Each followup-request
sends some sort of token to the server so that the application can
retrieve the correct file or correct record in the database.
			</para>
		</listitem>
		<listitem>
			<para>
The old-fashined way to identify sessions
			</para>
			<para>
At the time when every webserver was a single PC, the session token
identified a filename or a record in a database and everything was OK.
When an application that relies on this mechanism is ported to a
cluster environment, it stops working unless one deteriorates the
cluster with a mechanism called persistence. Persistence is a quick
and dirty way to get the old-fashioned token to work. It's not a very
clever way though.
			</para>
		</listitem>
		<listitem>
			<para>
Why persistence is bad
			</para>
			<para>
Persistence counteracts two purposes of a cluster: easy maintainance
by taking single machines out at any time and optimized balancing
between the members of a cluster. Above that, persistence consumes
memory on the load balancers.
			</para>
		</listitem>
		<listitem>
			<para>
How to do it better
			</para>
			<para>
Recall that there is a token being sent back and forth anyway, that
identifies a filename or a database record. Extend this token to
unambiguously point to the machine where the session data were created
and install a session server on each host that delivers session data
within the cluster to any of the peers on request. From that moment
you can run your application truely distributed, you can take single
machines out for maintainance any time: you turn their weight to 0 and
wait for maybe an hour or three, depending on how long you want your
sessions to last. You get better balancing, and you save memory on the
balancer. Note, that unlike with a dedicated session server, you do
not create a single point of failure with this method.
			</para>
		</listitem>
	</itemizedlist>
	</section>
	<section id="single_session">
	<title>Single Session</title>
	<para>
Related to the concept of persistent connection 
(whether implemented with LVS persistence or any other method)
is the concept of <emphasis>single session</emphasis>.
The client must appear to have only one session, 
as if the server is one machine.
You must be able to recognise the client
when they make multiple connections
and data written on one realserver must
be visible on another realserver.
Also see <xref linkend="distributed_filesystems"/>.
	</para>
	<para>
K Kopper 7 Jun 2006
	</para>
	<para>
Let's say you are running Java applications (aka Java
Threads) inside of a Java container (virtual machine)
you should be able to tell the container itself how
you want it to store session information (like a
shopping cart). The method of storage can therefore
automatically make the session information from one
cluster node (real server) available to all cluster
nodes via a file sharing technique, multicasting to
all the nodes, or by storing data on a database server
(on a backend HA pair). If you are five pages deep
into a shopping cart, for example, and the real server
crashes it won't be a problem if you land on a new
real server with your next click of "submit" and it
can pull up your session information.
	</para>
	<para>
Check out 7-2 (page 64) of this document for the
Oracle approach:
http://download-west.oracle.com/otn_hosted_doc/ias/preview/web.1013/b14432.pdf
	</para>
	<para>
Or for the JBOSS way using multicasting via JGroups:
http://www.jgroups.org/javagroupsnew/docs/index.html
	</para>
	<para>
Building an Oracle OC4J container that is highly
available on the HA backend to store session
information for a cluster works and seems like a good
sound approach to me. The multicast way raises many
doubts in my mind (especially if you need to lock the
session information for any reason).
	</para>
	<para>
Dan Baughman <emphasis>dan.baughman () gmail ! com</emphasis> 2006-05-09 
	</para>
	<para>
Internally, lvs must make decisions about where to send what
connection request, right?  I want to implement a hash table to keep track
of where previous connections from an ip went, and send them to the same server.
Any sort of timeout is optional.  Once an ip gets a server it can always get
that same server.  I had previously thougth of giving the session a timeout,
but now I'm leaning towards just having it maintain the hash forever, and
I'll just restart the director deamon every night at  2 am (or never).
Basically we are going to cluster some cold fusion servers and I don't want
to pay the 10 grand Adobe wants for an enterprise license to do what we
want.  We have a lot of app's deployed that use a cookie stored on the
client in conjunction with the user's ip to access server side session
data.  To reimplement the apps we've deployed to access a db instead of the
session data would be considerable.
Looking at the persistent option, that seems to be exactly what I'm looking for.
	</para>
	<para>
K Kopper <emphasis>karl_kopper (at) yahoo (dot) com</emphasis> 6 Jun 2006 
	</para>
	<para>
To share files on the real servers and ensure that all
real servers see the same changes at the same time a
good NAS box or even a Linux NFS server built on top
of a SAN (using Heartbeat to failover the NFS server
service and IP address the real servers use to access
it) works great. If you run "legacy" applications that
perform POSIX-compliant locking you can use the
instructions at http://linux-ha.org/HaNFS to build
your own HA NFS solution with two NFS server boxes and
a SAN (only one NFS server can mount the SAN disks at
a time, but at failover time the backup server simply
mounts the SAN disks and fails over the locking statd
information). Of course purchasing a good HA NAS
device has other benefits like non-volatile memory
cache commits for faster write speed.
	</para>
	<para>
If you are building an application from scratch then
your best bet is probably to store data using a
database and not the file system. The database can be
made highly available behind the real servers on a
Heartbeat pair (again with SAN disks wired up to both
machines in the HA pair, but only one server mounting
the SAN disks where the database resides at a time).
Heartbeat comes with a Filesystem script that helps
with this failover job. If your applications store
state/session information in SQL and can query back
into the database at each request (a cookie, login id,
etc.) then you will have a cluster that can tolerate
the failure of a real server without losing session
information--hopefully just a reload click on the web
browser for all but the worst cases (like "in flight:
transactions).
	</para>
	<para>
With either of these solutions your applications do
not have to be made cluster-aware. If you are
developing something from scratch you could try
something like Zope Enterprise Objects (ZEO) for
Python, or in Java (JBOSS) there is JGroups to
multicast information to all Java containers/threads,
but then you'll have to re-solve the locking problem
(something NFS and SQL have a long track record of
doing safely). But you were just asking about file
systems and I got off topic . . .
	</para>
	<para>
Christian Bronk <emphasis>chbr (at) webde (dot) de</emphasis> 02 Jun 2006
	</para>
	<para>
As long as you want AOL customers on your site, 
you will need single session server for your cluster
(any sort of database will do). 
Every request from AOL comes from an different proxy-IP 
and even setting a persitence-netmask will not fix that.
	</para>
	<para>
malcolm <emphasis>lists (at) netpbx (dot) org</emphasis> 02 Jun 2006
	</para>
	<para>
The SH scheduler gives exactly the same kind of response as persistence 
and it's layer 4 based on source hash...
Their are hundreds of session implementations for web servers, it's one 
of the first things web programmers should learn (i.e. INSERT INTO 
sessiontable.....)
LVS doesn't do L7 because L7 should be done by your app 
(<emphasis>i.e.</emphasis> that's what L7 is for.)
	</para>
	<para>
Martijn Grendelman, 2 Jun 2006
	</para>
	<para>
I couldn't get the SH scheduler to work 
(at the time not understanding the weight parameter) 
and I set up an Msession server for "session clustering" and used the RR scheduler. 
This setup works perfectly and is still in use today.
However, since Msession is hopelessly outdated, and its successor 
(Mcache) doesn't seem to get off the ground, and I haven't found any 
workable (open source) alternatives, I would really like have another 
look at LVS persistence of some sort.
	</para>
	<para>
Martijn Grendelman <emphasis>martijn () grendelman ! net</emphasis> 2006-05-10 12:09:28 
	</para>
	<para>
A centralized session manager would be nice, but I for one haven't been 
able to find a decent solution for use with PHP. I don't know about 
other systems or APIs.
Msession is dead (I still have it running, but any attempt to build a 
stable daemon on an up-to-date system failed time after time) and its 
successor (MCache) seems to have died before it even got to beta.
Other projects I have looked at (http://www.vl-srm.net/, for example) 
are also dead, or just aren't suitable (Memcached).
I use Msession for a shared hosting cluster. The main advantage is, that 
Msession has a PHP extension, so it doesn't require any PHP client 
code.  I need this, because I don't want to implement any dirty hacks 
based on "auto_prepend_file" or something like that, which I would need 
if I'd put my sessions in MySQL.
Well, you can always buy Zend Platform, which features Session 
Clustering, but some of us don't have the $$$.
Any suggestions for alternatives?
	</para>
	<para>
mike <emphasis>mike503 (at) gmail (dot) com</emphasis> 6 Jun 2006
	</para>
	<para>
IMHO storing data in blobs is a horrible idea.
	</para>
	<para>
If you are coding an application, I'd suggest checking out MogileFS.
If this is for general purpose web hosting, where you need a normal
POSIX filesystem to access, then that won't do. But for applications,
it seems like a great idea (and from what small amount I read about
the Google FS, it actually has a couple of the same traits)
	</para>
	<para>
As far as session management, a central session manager such as
msession would work, or just roll your own off a database - it's
simple in PHP (that is what I do) - then use DB
failover/replication/etc. software to handle the DB
clustering/failover.
	</para>
	<para>
mike <emphasis>mike503 () gmail ! com</emphasis> 2006-05-09 
	</para>
	<para>
not sure how long you want to track the information, but you might be
able to handle this with iptables and firewall marks. then you can
group requests by any sort of iptables-configurable tracking (by
port(s), ip ranges, etc...) - also i think there's a persistence
configuration option in ldirectord (or is it keepalived, i always get
them confused - or maybe both.)
	</para>
	<para>
I don't understand the need though for session persistence like this;
I'd expect a centralized session manager (msession for instance) or
just using a central database for the information would suffice.
that's how I've been doing it, not sure why everyone has all these
unique requirements to make sure they can persist sessions across IP
addresses and AOL proxies and such. seems overkill, I've never had a
problem. 
	</para>
	<para>
mike <emphasis>mike503 (at) gmail (dot) com</emphasis> 10 May 2006
	</para>
	<para>
It's very simple to make your own which uses only a single database
table in mysql. I used to use msession, but it had some overhead it
seemed like, and a database-driven one was less "thick" - the other
good thing about writing your own session handler is that you can call
other things on session start or close, etc.
I'd suggest using that (a mysql one)
I'll try giving you mine though, also:
	</para>
<programlisting><![CDATA[
### SQL:

CREATE TABLE `session` (
 `ID` varchar(32) character set utf8 NOT NULL default '',
 `uid` int(10) unsigned NOT NULL default '0',
 `data` mediumtext character set utf8 NOT NULL,
 `accessed` int(10) unsigned NOT NULL default '0',
 PRIMARY KEY  (`ID`),
 KEY `accessed` (`accessed`)
) ENGINE=MyISAM DEFAULT CHARSET=utf8

### cron script (run it every so often, i have it set to 5 minutes -
otherwise there is no garbage collection - it will remove sessions
that are over 1800 seconds old.

$expiry = time() - 1800;
db_query("DELETE FROM session WHERE accessed < $expiry");

### the session PHP functions

function session_close() {
       return true;
}

function session_die($id) {
       db_query("DELETE FROM session WHERE ID='$id'");
       return true;
}

function session_gc($maxlifetime) {
       return true;
}

function session_open($path,$name) {
       return true;
}

function session_read($id) {
       $dchk = db_query("SELECT data FROM session WHERE ID='$id'");
       if(db_numrows($dchk) == 1) {
               if(!isset($_SESSION['row'])) { $_SESSION['row'] = 1; }
               list($data) = db_rows($dchk);
               return base64_decode($data);
       } else {
               return "";
       }
       db_free($dchk);
       return true;
}

function session_write($id,$data) {
       $data = base64_encode($data);
       if(!isset($_SESSION['row'])) {
               db_query("INSERT IGNORE INTO session
(ID,data,accessed) VALUES('$id','$data',UNIX_TIMESTAMP(NOW()))");
       } else {
               db_query("UPDATE session SET
data='$data',accessed=UNIX_TIMESTAMP(NOW()) WHERE ID='$id'");
       }
       return true;
}

### configuration in each script (common include)

ini_set("session.use_only_cookies","1");
ini_set("session.gc_probability","0");
ini_set("session.cookie_domain","yourdomain.com");
session_set_save_handler("session_open", "session_close",
"session_read", "session_write", "session_die", "session_gc");
session_start();
register_shutdown_function('session_write_close')
]]></programlisting>
	</section>
	<section id="IIS_session_management">
	<title>IIS session management: how it works</title>
	<para>
Alex Kramarov <emphasis>alex-lvs (at) incredimail (dot) com</emphasis> 22 Nov 2002
	</para>
	<para>
Microsoft's COM model is similar to the CORBA model.
Generally, you have components, <emphasis>i.e.</emphasis>
code that can be used from other applications.
The concept is similar to using
shared libraries, but still a little different.
You can create an instance of the component
and use in a simple fashion with asp
(the IIS scripting language IIS).
Every time a new user calls for a asp file,
a new session component is created,
and can be accessed through asp scripting.
This component can store data like a perl hash (session(valuename) = value).
The data is stored in the memory space of the IIS process.
Each session has a unique identifier that is remembered along with the data,
and this identifier is maintained during the session by a cookie.
On subsequent access by a client,
the server looks up the data stored for this session,
and makes it available as members of the session component.
	</para>
	<para>
a simple sample - access autorisation (this code goes on top of a pages you
would like to secure):
	</para>

<programlisting><![CDATA[
' check if this user has identified already

If Session("UserID") <> "" Then
 'check some conditions.
 'if check successful
    Session("UserID") = "approved"
 'else do not allow to proceed showing the page
    response.write "authorization failed"
    response.end
End If
]]></programlisting>

	<para>
There are components available that will replace the default session
component with one that will store the session data in a shared db, and only
minimal modification to the code are required, if any.
Generally the session component is an implicit component the server provides.
You could use your own component that does the same thing,
and the only thing you would
have to do is to initialize an instance and give it the unique identifier of
the user, like this (purely fictional code)
	</para>

<programlisting><![CDATA[
mySession = CreateObject("my.own.session.component")
mySession.setUniqueId = server.request("some data, a cookie or other parameter").
]]></programlisting>

	<para>
When writing code for MS servers, one almost never deals with files,
since the interface provided by MS for that purpose is very cumbersome,
and on Windows, file locking problems are very severe issue.
With Unix, you can write a cgi that manipulates files,
reads and writes to and from a dozen files while running.
You would be crazy to that on windows.
All data you want to store can be more or less conveniently stored
using the session object if this is a per user data, or in the application
object (more or less the same idea), which retains data through the life of
the application (from the start to the stop of the http service). All data
is in memory, hence, it is fast.
Long term data is always stored in databases.
I believe that the difference in perspective comes from the fact,
that in unix,
you can have a bare bones system because of your security requirements,
and then you want to write a small script that uses and stores some data,
so you open some files and do that.
On windows, you CANNOT HAVE a bare bones system.
From the initial install, you already have some file
based db structure (comparable to db3),
and all the database connectivity libraries,
which you cannot remove,
unless you are a windows guru and you start deleting system libraries one by one.
(You would be crazy
to do that, since there is absolutely no documentation what
each of the thousands of library files, which are installed by default, do.)
All these libraries are a security risk, as is proven by all the buffer
overflow vunerabilities.
But since windows developers regard DB connectivity as a standard
component of their OS, they use it.
(This is a marketing strategy of MS, to sell their MS bloated sql server).
	</para>
	<para>
why doesn't the application doesn't keep it's own
state?:
	</para>
	<para>
IIS assigns a unique identifier to be used in
session management the first time a user accesses an asp file (even if you
need it for only 1% of the pages on your site).
This is completely transparent to the developer,
and saves time in the development process.
Writing apps where state is conserved manually
(without sessions), is not as easy as it looks,
and the mechanism provided by IIS is certainly convenient.
Coding using "the Microsoft Way" for IIS took me 4 hours to learn, going
through microsoft developer network articles.
It is simple if you don't stray from the dictated path,
but the second you do stray,
it's hard to push something not designed by MS into
their framework, and people are afraid of that.
	</para>

	<para>
IIS 6 includes the option to make the server session
object store data in an odbc database, but it is still not released.
3rd party components that should do the task are commercially
available, like the frameWerks session component, and it is pretty cheap, at
149$.
	</para>
	<para>
I also believe that not a lot of sites need and use several realservers to
serve a simple logical site, so this was never such an issue, till recently.
Now, microsoft woke up to the fact and writing their own
implementation for the IIS 6, which will undoubtedly require the use the MS
sql server.
	</para>

	<para>
Mark Weaver <emphasis>mark (at) npsl (dot) co (dot) uk</emphasis> 23 Nov 2002
	</para>
	<blockquote>
	<para>
The default ASP (= MS web scripting) sessions simply use a cookie and stores
session state in server memory.  The session is a dictionary object, and you
just store a bunch of key-value pairs.  Since the standard session object
stores data in memory, it is not a lot of use for /robust/ load balancing.
	</para><para>
.NET adds a component that stores session in a database.  Such a component
is pretty trivial to write, we have had one for a number of years.  Storing
on disk is a good option when there is no database, but since most of the
sites that we have are pretty dynamic (i.e. most pages are generated from
database calls), storing the session state in the DB is a good bet.  I can
probably release the source code for this if anyone is interested.
	</para>
	</blockquote>
	</section>
	<section id="persistent_setup" xreflabel="setting up with persistence">
	<title>Maintaining state with persistence</title>
	<para>
You can setup persistence several ways
	</para>
	<itemizedlist>
		<listitem>
Use port 0 (<emphasis>i.e.</emphasis> all ports)
with persistency feature (read the ipvsadm man page).
All ports are persistent. A client after connecting to
a particular realserver for one service, will (within the timeout period)
be connected to the same realserver for all services.
This will allow intruders to forward packets for any ports to
the realservers, so you will need to write filter rules that block
all ports but the ones that you want serviced by the realservers.
		</listitem>
		<listitem>
In practice only 1 or a small number of ports (<emphasis>e.g.</emphasis>
http/https, smtp/pop) will ever be used in a persistent manner and
you can set persistence for a particular port (<emphasis>e.g.</emphasis> https)
while other services are not persistent. The client will
(within the timeout period) be sent to the same realserver
for the persistent port, while being serviced by all realservers
for the other LVS'ed ports.
		</listitem>
		<listitem>
			<para>
For sophisticated setups (<emphasis>e.g.</emphasis> shopping carts
where the client who has been filling his cart on :http, needs to
give his credit card details on :https), you should use
persistent fwmarks with the <xref linkend="fwmark_persistent_patch"/>.
fwmarks and persistent fwmarks scale well with large numbers of services
and (once you understand fwmarks) make it easy to setup shopping cart LVSs.
			</para>
			<note>
Shopping cart applications have to maintain state.
Usually state is maintained by sending the customer a cookie.
These are instrusive 
and a security risk
(I turn them off on my browser).
If you're going to
use cookies in your application, you should at least test that the client accepts
them, otherwise the client will not be able to accumulate objects in their shopping cart.
We encourage you to rewrite the application (see <xref linkend="L7_ratz"/>)
so that state is maintained on the realserver(s) in a way that is available
to all realservers (<emphasis>e.g.</emphasis> on a replicated
database) (see <xref linkend="session_data"/>. 
You have the time of the persistence timeout to
make this information available to the other realservers.
			</note>
			<para>
Having told you that you can setup a shopping cart with
persistent fwmarks, please read <xref linkend="persistent_e-commerce"/>.
			</para>
		</listitem>
	</itemizedlist>
	<para>
One of the problems with persistence is removing a service
(<emphasis>e.g.</emphasis> you just want it removed or the realserver has crashed).
Even after the weight has been set in <command>ipvsadm</command> to 0,
the service is still in the <command>ipvsadm</command> table and will
stay there till the end of the client's timeout period.
If the realserver has crashed, the client's connection will hang.
You would like to have preserved the client's state information
in your database, and give the client a new realserver.
This problem has now been addressed with the LVS sysclt
(see <xref linkend="sysctl"/> and
<xref linkend="bringing_down_persistent_services"/>).
For older material on the topic see <xref linkend="realserver_crash_on_sticky_connection"/>.
	</para>
	<para>
The following examples here use telnet and http.
You aren't likely to want to make these persistent in practice.
They are used because the clients are simple to use in tests.
You'll probably only want to make ftp or https persistent,
but not much else.
	</para>
	<para>
Setup persistence on VIP,
default persistence timeout
(default timeout value varies a bit with ipvs versions, but it's about 10mins),
port not specified (all ports made persistent).
Telnet'ing to the VIP from one machine,
you will always connect to the same realserver.
	</para>

<programlisting><![CDATA[
director:/etc/lvs# ipvsadm -A -t lvs -p
director:/etc/lvs# ipvsadm -a -t lvs -r rs1 -g
director:/etc/lvs# ipvsadm -a -t lvs -r rs2 -g
director:/etc/lvs# ipvsadm
IP Virtual Server version 0.9.4 (size=4096)
Prot LocalAddress:Port Scheduler Flags
  -> RemoteAddress:Port           Forward Weight ActiveConn InActConn
TCP  lvs.mack.net:0 wlc persistent 360
  -> RS2.mack.net:0               Route   1      0          0
  -> RS1.mack.net:0               Route   1      0          0
]]></programlisting>

	<para>
Here's setting up with a specified persistence timeout (here 600secs),
setting persistence granularity (the -M option) to a netmask of /24,
and round robin scheduling.
	</para>
	<note>
If you make the timeout &gt; 15mins (900 sec), you'll also
need to change the <xref linkend="tcpip_idle_timeout"/>.
	</note>

<programlisting><![CDATA[
director:/etc/lvs# ipvsadm -A -t lvs -p 600 -s rr -M 255.255.255.0
director:/etc/lvs# ipvsadm -a -t lvs -r rs1 -g
director:/etc/lvs# ipvsadm -a -t lvs -r rs2 -g
director:/etc/lvs# ipvsadm
IP Virtual Server version 0.9.4 (size=4096)
Prot LocalAddress:Port Scheduler Flags
  -> RemoteAddress:Port           Forward Weight ActiveConn InActConn
TCP  lvs.mack.net:0 rr persistent 600 mask 255.255.255.0
  -> RS2.mack.net:0               Route   1      0          0
  -> RS1.mack.net:0               Route   1      0          0
]]></programlisting>

	<para>
Note: only a timeout value can follow "-p". Thus you can have any of
	</para>

<programlisting><![CDATA[
director:/etc/lvs# ipvsadm -A -t VIP -p
director:/etc/lvs# ipvsadm -A -t VIP -p 600
director:/etc/lvs# ipvsadm -A -t VIP -s rr -p
]]></programlisting>
	<para>
but you can't have
	</para>
<programlisting><![CDATA[
director:/etc/lvs# ipvsadm -A -t VIP -p -s rr
]]></programlisting>
	<para>
You can setup persistence by port
	</para>
<programlisting><![CDATA[
director:/etc/lvs# ipvsadm -A -t lvs:80 -p
director:/etc/lvs# ipvsadm -a -t lvs:80 -r rs1 -g
director:/etc/lvs# ipvsadm -a -t lvs:80 -r rs2 -g
director:/etc/lvs# ipvsadm
IP Virtual Server version 0.9.4 (size=4096)
Prot LocalAddress:Port Scheduler Flags
  -> RemoteAddress:Port           Forward Weight ActiveConn InActConn
TCP  lvs.mack.net:http wlc persistent 360
  -> RS2.mack.net:http            Route   1      0          0
  -> RS1.mack.net:http            Route   1      0          0
]]></programlisting>
	</section>
	<section id="how_others_maintain_state">
	<title>How others maintain state</title>
	<para>
We spend lot of time telling people not to use cookies to maintain state.
I thought I should do a reality check, to see what people are using that's working.
	</para>
	<para>
Malcolm Turnbull <emphasis>malcolm (at) loadbalancer (dot) org</emphasis> 12 May 2004
	</para>
	<blockquote>
		<para>
I've been involved with a mid sized ecommerce company for about 4 years 
and we've had very few problems using cookies for state (stored in a 
single backend db.) Its fast and easy.
If the odd customer doesn't have cookies turned on then they are no 
great loss.
		</para>
		<para>
Putting the sessionid in the URL <emphasis>i.e.</emphasis> GET is ugly and slightly less secure.
I guess you could POST it on every page but would that be slower than 
cookie? (I think so)
		</para>
	</blockquote>
	<note>
Joe: Having session data in the URL allows the user (or man in the middle) to manipulate it.
This is not secure.
	</note>
	<para>
Joe 11 May 2004 14:23:02 -0400
	</para>
	<blockquote>
		<para>
With the security hazards of cookies, I have them turned off.
Usually the application (<emphasis>e.g.</emphasis> mailman) 
runs a cookie test on me and tells me to turn on cookies.
I've been trying to register for the Ottawa Linux Symposium for about 2months,
and they've been having trouble with their registration software. 
Finally they ask me if I've got cookies turned on. I say "of course not". 
They don't do a cookie test and there's no notice on the web page
that I need cookies turned on.
		</para>
	</blockquote>
	<para>
Jacob Coby <emphasis>jcoby (at) listingbook (dot) com</emphasis> 11 May 2004
	</para>
	<blockquote>
		<para>
We aren't an ecommerce site, but we do require some sort of 
login/authentication to use our site.
		</para>
		<para>
We haven't worried about cookies either, at least, until the past 4 months or so.  
It seems that the latest and 
greatest anti-virus software and pop-up blockers disable cookies (among 
other things that they have no business doing). Rumor has it that new 
versions of IE will disable cookies by default. A good portion of IE6 
users won't accept cookies unless your site publishes a P3P of some sort.
We get appx. 4000 people/day (9000 logins/day), and we were getting up 
to 10 cookie related problems a day to the helpdesk. I'd estimate that 
there were at probably 2-10x more that who had problems, but who never reported 
it. In 3 years of requiring cookies, we had only one nasty email about 
our requirement to have cookies enabled.
		</para>
		<para>
At any rate, we now use a different system to autheticate a user.  We 
pass in a sid per page, and use cookies, IP address, browser ident, and 
other metrics to authenticate the user.  Sensitive areas of the site 
(such as those requiring a credit card) also use SSL.
All session data is stored in a single database, as a serialized PHP 
array. There can be up to 1/2 MB of session data, and part of the 
session data persists between logins, so it doesn't make sense for us to 
put session data in the cookie or to store it on the webservers.
		</para>
		<para>
The sid + (cookie, IP, browser ident) is only used to authenticate the user. 
The session data itself stores all sorts of things, such as temporary 
user prefs, some of the things the user looked at, a bit of caching to 
cut down on subsequent db queries, things like that.  Only part of that 
session data persists between logins, but it has to be stored somewhere 
between pages.
		</para>
		<para>
Our situation is a little different from your average e-commerce store. 
We can't just identify a shopping cart + items by a unique sid.  We 
need the session data to act as a ram drive of sorts for data that needs 
to be quickly accessed, multiple times per page.
		</para>
		<para>
All of that temp data is stored in an array, and serialize()'d.  PHP's 
serialize is pretty compact, but it still expands out.  For example, a 
simple int value of the login timestamp looks like:
		</para>
<programlisting><![CDATA[
s:8:"login_ts";i:1084802982;
]]></programlisting>
		<para>
The 1/2mb is the MAXIMUM we allow to store.  Typical is more in the 
3-10kb range.  Average size over 49627 rows of session data is 3134b 
right now.
		</para>
		<blockquote>
Joe: What's going to happen to your session data when IE6 disallows cookies?
		</blockquote>
		<para>
It'll still work.  The sid cookie is only one of several hints we can 
use to authenticate the user.
		</para>
		<para>
Malcolm Turnbull <emphasis>malcolm (at) loadbalancer (dot) org</emphasis> 17 May 2004
		</para>
		<blockquote>
If your page is formated correctly with a PICS-Label  IE6 will accept 
the cookie by default.
		</blockquote>
		<note>
			<para>
For reference info about PICS Labels see
<ulink url="http://www.w3.org/TR/REC-PICS-labels-961031">
PICS Label Distribution Label Syntax and Communications Protocols v1.1</ulink>
(http://www.w3.org/TR/REC-PICS-labels-961031).
For a sample HOWTO see
<ulink url="http://256.com/gray/docs/pics/">
How To Label Your Pages with PICS Meta Tag</ulink>
(http://256.com/gray/docs/pics/).
These labels appear to be part of the so far futile effort
to filter webpages for children. 
Here's a webpage by the people fronting this effort
<ulink url="http://www.icra.org/webmasters"> Information
for webmasters</ulink>.
			</para>
			<para>
They want you to rate your own website
(people with obnoxious content are always honest, right?).
If the ICRA expect this approach to succeed, 
then why do we have spam?
The politicians are no help of course.
One of them has a bill to stop google 
from inserting advertisements into their gmail service,
since this requires reading people's (private)
e-mail. This bill would also stop programs
from filtering web content. 
We have a long way to go.
			</para>
		</note>
		<para>
POST is marginally slower than GET if you look at the HTTP spec.  There 
is an additonal request header per variable.  GET is only *very 
slightly* less secure.  POST, and cookies are of equal security levels, 
and they're all trivial to send using command line tools.
		</para>
	</blockquote>
	<para>
Joe
	</para>
	<blockquote>
until recently I'd thought that putting the session data into the URL
(rather than a cookie) was the way to go, till someone pointed out that
the user could manipulated the URL. In that case, could the session id
be put in a long enough string in the URL such that any attempt to alter
it would result in an invalid string?
	</blockquote>
	<para>
Jacob
	</para>
	<blockquote>
		<para>
There is an upper limit on the GET string IE will send.  Somewhere 
around 1 or 2 kb.  When it hits the limit, if you use javascript to 
submit the form, it'll error out.  If you just use a 
		</para>
<programlisting><![CDATA[
<input type="submit">
]]></programlisting>
		<para>
it'll just not work.  For sites that will never hit that 
limit, passing in the session data would work.
However, there should still be checks to authenticate the user, mostly 
to prevent problems when they share links with friends.
One solution to the user modifying the string is to pass in a public key:
		</para>
<programlisting><![CDATA[
Kpu = public key
Kpr = private key
md5 = standard MD5 sum algo
session = your serialized session data

Kpu = md5(md5(session + Kpr) + md5(Kpr)) 
(or some variation, 
see the HTTP RFC for an example with the HTTP DIGEST authentication)
]]></programlisting>
		<para>
Then you can authenticate that the session data hasn't been modified by 
checking your computed Kpu against the Kpu that was passed in from the 
GET/POST. If they match, the session data probably hasn't been 
modified. If they don't, there is a very good chance the data was 
either corrupted in transit or corrupted by the user.
		</para>
		<para>
It's only as strong as the Kpr used and whatever the collision 
probability of the md5 algorithm.
		</para>
	</blockquote>
	<para>
Horms 21 May 2004
	</para>
	<para>
Is there anything to stop a cookie or post from being manipulated
by an end user? Sure, it might be margionally more difficult
as you would probably need some (command like) tool, rather than
just changing the URL directly in your given browser. 
But it should still be trivial.
I rarely write web pages. But if I was to do something like this
I would make the string in the URL a hash (md5, sha1 or something like
that), which should make guessing a valid string rather difficult.
I would do the same in a cookie or a post. I would imagine something
like this is pretty common practice.
	</para>
	<para>
nick garratt <emphasis>nick-lvs (at) wordwork (dot) co (dot) za</emphasis> 12 May 2004
	</para>
	<blockquote>
This discussion happens every so often on the list and, as always, I 
feel the need to mention the <filename>msession</filename> session service which we have 
been using very reliably for years
from <ulink url="http://www.mohawksoft.com/devel/msession.html">Mohawk Software</ulink>
(http://www.mohawksoft.com/devel/msession.html).
It's light-weight, fast and depending on the scripting language you 
use (we're using php4) it is very easy to implement.
	</blockquote>
	<para>
Matthew Smart <emphasis>msmart (at) smartsoftwareinc (dot) com</emphasis> 25 Jun 2007
	</para>
	<para>
The problem I have is that all clients from a given location get 
directed to the same realserver. Since the majority of clients are 
located in the same office, we are not getting a good load balance.
I disabled persistence, moved 
sessions into mysql, and am relying on mysql's replication to ensure 
that all servers have the session data.
We have state info stored server side in a PHP session.  
Client side there is a cookie that holds a session id only (no state).  
We are working on ways to replicate the server side session 
info across N real servers.  
I think relying on mysql will work in the short term. 
Just have to test it under load to see how it behaves. 
I can see an issue if mysql replication gets behind on a server, 
but that is not an LVS issue...
	</para>
	</section>
</section>
<section id="LVS-HOWTO.squid_realservers">
<title>LVS: Squid Realservers (poor man's L7 switch)</title><para>
One of the first uses for LVS was to increase throughput of webcaches.
A <link linkend="JWCS">550MHz PIII director can handle 120Mbps throughput</link>.
			</para><para>
A scheduler (-dh = destination hash) specially designed for webcaches is described
in the section on
<xref linkend="LVS-HOWTO.ipvsadm"/>
is in LVS derived from code posted to the
LVS mailing list by Thomas Proell (about Oct 2000).
			</para><para>
This section was written by <emphasis>andreas (dot) koenig (at) anima (dot) de</emphasis> Andreas J. Koenig
and was posted to the mailing list.
			</para><para>
An often lamented shortcoming of LVS clusters is that the realservers
have to be configured to work identically. Thus if you want to build
up a service with many servers that need to be configured differently
for some reason, you cannot take advantage of the powerful LVS.
			</para><para>
The following describes an LVS topology where not all servers in the
pool of available servers are configured identical and where
loadbalancing is content-based.
			</para><para>
The goal is achieved by combining the features of Squid and LVS. The
workhorses are running Apache, but any HTTP server would do.
			</para>
	<section id="squid_terminology">
	<title>Terminology</title>
	<para>
Before we start we need to introduce a bit of Squid terminology.
A redirector (http://www.squid-cache.org/Doc/FAQ/FAQ-15.html)
is a director that examines the URL and request method of an
HTTP and is enabled to change the URL in any way it needs.
An accelerator (http://www.squid-cache.org/Doc/FAQ/FAQ-20.html)
plays the role os a buffer and cache.
The accelerator handles a relatively big amount of slow
connections to the clients on the internet
with a relativly small amount of memory.
It passes requests through to any number of back-end servers.
It can be configured to cache the results of the back-end servers
according to the HTTP headers.
	</para></section>
	<section><title>Preview</title><para>
In the following example installation,
we will realize this configuration (real IP addresses anonymized):
			</para><para>
<programlisting><![CDATA[
VIP                10.0.0.62

LVSdirector        10.0.0.2
LVS_hot_standby    10.0.0.3

Squid1             10.0.0.5:80
Squid2             10.0.0.7:80   # Same box as Webserver2

Webserver1         10.0.0.6:81
Webserver2         10.0.0.7:81   # Same box as Squid2
Webserver3         10.0.0.8:81
Webserver4         10.0.0.9:81

]]></programlisting>
			</para><para>
Note that a squid and a webserver can coexist in a single box,
that's why we have put Squid2 and Webserver7 into a single machine.
			</para><para>
Note also that squids can cache webserver's
output and thus reduce the work for them.
We dedicate 24 GB disk to caching in Squid1 and 6 GB disk in Squid2.
			</para><para>
And finally note that several squids can exchange digest
information about cached data if they want.
We haven't yet configured for this.
			</para><para>
Strictly speaking, a single squid can take the role of an LVSdirector,
but only for HTTP.
It's slower, but it works.
By accessing one of the squids in our setup directly,
this can be easily demonstrated.
	</para></section>
	<section><title>Let's start assembling</title><para>
I'd suggest, the first thing to do is to setup
the four apache on Webserver1..4.
These servers are the working horses for the whole cluster.
They are not what LVS terminology calls realservers though.
The realservers according to LVS are the Squids.
			</para><para>
We configure the apaches completely stardard.
The only deviation from a standard installation here is that we specify
			</para><para>
<programlisting><![CDATA[
    Port 81
]]></programlisting>
			</para><para>
in the httpd.conf. Everything else is the default configuration file
that comes with apache. In the choice of the port we are, of course,
free to choose any port we like. It's an old habit of mine to select
81 if a squid is around to act as accelerator.
			</para><para>
We finish this round of assembling with tests that only try to access
Webserver1..4 on port 81 directly. For later testing, I recommend to
activate the printenv CGI program that comes with Apache:
			</para><para>
<programlisting><![CDATA[
chmod 755 /usr/local/apache/cgi-bin/printenv
]]></programlisting>
			</para><para>
This program shows us, on which server the script is running
(SERVER_ADDR) and which server appears as the requesting site
(REMOTE_ADDR).
	</para></section>
	<section><title>One squid</title><para>
Next we should configure one Squid box. The second one will mostly be
a replication of the first, so let's first nail that first one down.
			</para><para>
When we compile the squid 2.3-STABLE4, we need already decide about
compilation options. Personally I like the features associated with
this configuration:
			</para><para>
<programlisting><![CDATA[
./configure --enable-heap-replacement --disable-http-violations \
            --enable-cache-digests    --enable-delay-pools
]]></programlisting>
			</para><para>
We can build and install squid with these settings. But before we
start squid, we must go through a 2700 lines configuration file and
set lots of options. The following is a collection of diffs between
the squid.conf.default and my squid.conf with comments in between.
			</para><para>
<programlisting><![CDATA[
--- squid.conf.default  Mon Aug 14 12:04:33 2000
+++ squid.conf  Mon Aug 14 14:34:35 2000
@@ -47 +47 @@
-#http_port 3128
+http_port 80
]]></programlisting>
			</para><para>
Yes, we want this squid on port 80 because from outside it looks like
a normal HTTP server.
<programlisting><![CDATA[
@@ -54 +54 @@
-#icp_port 3130
+icp_port 0
]]></programlisting>
			</para><para>
In the demo installation I turned ICP off, but I'll turn it on again
later. ICP is the protocol that the squids can use to exchange sibling
information about what they have on their disks.
			</para><para>
<programlisting><![CDATA[
@@ -373 +373 @@
-#cache_mem  8 MB
+cache_mem 700 MB
]]></programlisting>
			</para><para>
This is the memory reserved for holding cache data. We have 1 GB total
physical memory and 24 GB disk cache. To manage the disk cache, squid
needs about 150 MB of memory (estimate 6 MB per GB for an average
object size of 13kB). Once you're running, you can use squid's
statistics to find out *your* average object size. I usually leave 1/6
of the memory for the operating system, but at least 100 MB.
			</para><para>
<programlisting><![CDATA[
@@ -389,2 +389,2 @@
-#cache_swap_low  90
-#cache_swap_high 95
+#cache_swap_low  94
+#cache_swap_high 96
@@ -404 +404 @@
-#maximum_object_size 4096 KB
+maximum_object_size 8192 KB
]]></programlisting>
			</para><para>
Please refer to squid's docs for these values.
			</para><para>
<programlisting><![CDATA[
@@ -463,0 +464,5 @@
+cache_dir ufs /var/squid01 5600 16 256
+cache_dir ufs /var/squid02 5600 16 256
+cache_dir ufs /var/squid03 5600 16 256
+cache_dir ufs /var/squid04 5600 16 256
+
]]></programlisting>
			</para><para>
You do not need bigger disks, you need many disks to speed up squid.
Join the squid mailing list to find out about the efficiency of
filesystem tuning like "noatime" or Reiser FS.
			</para><para>
<programlisting><![CDATA[
@@ -660 +665 @@
-#redirect_program none
+redirect_program /usr/local/squid/etc/redirector.pl
]]></programlisting>
			</para><para>
This is the meat of our usage of squid. This program can be as simple
as you want or as powerful as you want. It can be implemented in any
language and it will be run within a pool of daemons. My program is
written in perl and looks something like the following:
			</para><para>
<programlisting><![CDATA[
    $|=1;
    while (<>) {
      chomp;
      my($url,$host,$ident,$method) = split;
      my @redir = $url =~ /\bh=([\d,]+);?/ ?
                 split(/,/,$1) : (6,7,8,9); # last components of our IP numbers
      my $redir = $redir[int rand scalar @redir];
      $url =~ s/PLACEHOLDER:81/10.0.0.$redir\:81/i;
      print STDOUT "$url\n";
    }
]]></programlisting>
			</para><para>
This is ideal for testing, because it allows me to request a single
backend server or a set of backend servers to choose from via the CGI
querystring. A request like
			</para><para>
    http://10.0.0.62/cgi-bin/printenv?h=6
			</para><para>
will then be served by backend apache 10.0.0.6.
			</para><para>
<programlisting><![CDATA[
@@ -668 +673 @@
-#redirect_children 5
+redirect_children 10
]]></programlisting>
			</para><para>
The more complex the redirector program is, the more processes should
be allocated to run it.
			</para><para>
<programlisting><![CDATA[
@@ -674 +679 @@
-#redirect_rewrites_host_header on
+redirect_rewrites_host_header off
@@ -879 +884 @@
-#replacement_policy LFUDA
+replacement_policy LFUDA
@@ -1168 +1173 @@
-acl Safe_ports port 80 21 443 563 70 210 1025-65535
+acl Safe_ports port 80 81 21 443 563 70 210 1025-65535
@@ -1204 +1209 @@
-http_access deny all
+http_access allow all
]]></programlisting>
			</para><para>
For all of the above changes, please refer to the squid.conf.default.
			</para><para>
<programlisting><![CDATA[
@@ -1370,2 +1375,3 @@
-#httpd_accel_host hostname
-#httpd_accel_port port
+# we will replace www.meta-list.net:81 with our host of choice
+httpd_accel_host PLACEHOLDER
+httpd_accel_port 81
]]></programlisting>
			</para><para>
As we are redirecting everything through the redirector, we can fill
in anything we want. No real hostname, no real port is needed. The
redirector program will have to know what we chose here.
			</para><para>
<programlisting><![CDATA[
@@ -1377 +1383 @@
-#httpd_accel_with_proxy off
+httpd_accel_with_proxy on
]]></programlisting>
			</para><para>
If we want ICP working (and we said, we would like to get it working),
we need this turned on.
			</para><para>
We're done with our first squid, we can start it and test it. If you
send a request to this squid, one of the backend servers will answer
according to the redirect policy of the redirector program.
			</para><para>
Basically, at this point in time we have a fully working content based
redirector. As already mentioned, we do not really need LVS to
accomplish this. But the downside of this approach is:
			</para><para>
- we are comparatively slow: squid is not famous for speed.
			</para><para>
- we do not scale well: if the bottleneck is a the squid, we want LVS
  to scale up.
	</para></section>
	<section><title>Another squid</title><para>
So the next step in our demo is to build another squid. This is very
trivial given that we have already one. We just copy the whole
configuration and adjust a few parameters if there are any differences
in the hardware.
	</para></section>
	<section>
	<title>Combining pieces with LVS</title>
	<para>
The rest of the story is to read the appropriate docs for LVS. I have
used Horms's Ultra Monkey docs and there's nothing to be added for this
kind of setup. Keep in mind that only the squids are to be known by
the LVS box. They are the "realservers" in LVS terminology. The apache
back end servers are only known to the squids' redirector program.
	</para>
	</section>
	<section><title>Problems</title><para>
It has been said that LVS is fast and squid is slow, so people
believe, they must implement a level 7 switch in LVS to have it
faster. This remains to be proofed.
			</para><para>
Squid is really slow compared to some of the HTTP servers that are
tuned for speed. If you're serving static content with a hernel HTTP
daemon, you definitely do not want to lose the speed by running it
through a squid.
			</para><para>
If you want persistent connections, you need to implemented them in
your redirector. If you want to take dead servers out of the pool, you
must implement it in your redirector. If you have a complicated
redirector, you need more of them and thus need more ressources.
			</para><para>
In the above setup, ldirectord monitors just the two squids. A failure
of one of the apaches might go by unnoticed, so you need to do
something about this.
			</para><para>
If you have not many cacheable data like SSL or things that need to
expire immediately or a high fraction of POST requests, the squid
seems like a waste of resources. I'd say, in that case you just give
it less disk space and memory.
			</para><para>
Sites that prove unviewable through Squid are a real problem (Joe
Cooper reports there is a stock ticker that doesn't work through
squid). If you have contents that cannot be served through a squid,
you're in big trouble--and as it seems, on your own.
	</para></section>
</section>
<section id="LVS-HOWTO.performance" xreflabel="LVS performance and kernel tuning">
<title>LVS: Performance and Kernel Tuning</title>
	<para>
We are now (2006) in an era where the CPU is no longer rate determining in an LVS director.
	</para>
	<para>
Ratz 20 Feb 2006 
	</para>
	<para>
The processor never is an issue regarding LVS unless your 
NIC is so badly designed that the CPU would need to take over the packet 
processing ;)
	</para>
	<section id="performance_articles">
	<title>Performance Articles</title>
	<para>
(a non-LVS article on
<ulink url="http://www.kegel.com/c10k.html">Configuring large scale unix clusters</ulink>
by Dan Kegel.)
	</para>
	<para>
The article
<ulink url="http://www.linuxvirtualserver.org/Joseph.Mack/performance/single_realserver_performance.html">performance data for a single realserver LVS</ulink>,
shows how to test the network links with netpipe and
how to determine the effects of LVS on latency and throughput.
Note the effect of the LVS code on system performance is the difference
between the performance with the director box just forwarding packets as a router
to the realservers and the director box acting as an LVS director.
If you find that the director is causing the throughput to decrease,
you first have to determine if the slowdown is due to the hardware/OS
or due to ip_vs.
It is possible that the PCI bus or your network cards
cannot handle the throughput when the box us just forwarding packets.
Several articles have been published about the performance of LVS,
by people who did not differentiate the effects of the ip_vs code
from slowdown caused by the hardware that the ip_vs code was running on.
	</para>
	<para>
Pat O'Rourke has done some
<ulink url="http://www.linuxvirtualserver.org/performance/lvs.ps.gz">performance tests</ulink>
on high end machines.
	</para>
	<para>
Padraig Brady <emphasis>padraig (at) antefacto (dot) com</emphasis> 29 May 2002, measured 60usec
latency for normal forwarding and 80usec latency for forwarding as a director
on his setup.
	</para>
	<para>
Ted Pavlic was running 4 realservers with 1016 (4 x 254) RIPs way back (1999?).
	</para>
	<para>
Jeremy Kusnet (1 Oct 2002) is running a setup with 53 VIPs, 8 services/VIP,
6 realservers, (53*8*6 = 2688) RIPs.
	</para>
	<para>
unknown:
	</para>
	<blockquote>
 Has anyone on this list use LVS to load balance firewalls?
 If so, what kind of limitations did you see with regard to 
 Mbps and kpps?
	</blockquote>
	<para>
Peter Mueller <emphasis>pmueller (at) sidestep (dot) com</emphasis> 30 Dec 2004
	</para>
	<para>
Yes, see the list archives.
The limit is in the PCI bus.  
If you are pushing the limit of the LVS PCI bus
then it won't help to use LVS.
	</para>
	<para>
Anyway, I have not gotten more than 100kpps unless using NAPI.  Some people
report getting up to 1.2mpps (!) a few years ago with intel gigabits, 64-bit
66mhz individual cards and buses.  These figures are with 64 byte packets.
There was a post on quagga archive recently about this, check there for more
details.
	</para>
	<blockquote>
Did you run into any issues with stateful connections and how many
simultaneous connections did it handle?
	</blockquote>
	<para>
I'm sure if you run iptables on a router it will drop your numbers, probably
by a lot.
	</para>
	</section>
	<section id="rule_of_thumb" xreflabel="rule of thumb">
	<title>Estimating throughput: Rule of Thumb</title>
	<para>
People on the LVS mailing list have found that a 400MHz director will saturate a 100Mbps ethernet link.
	</para>
	<para>
Somewhere else I read that you need 1Hz of CPU for every bps of I/O. 
So 100Mbps ethernet (two directions) will need a 200MHz machine. 
	</para>
	<para>
In the old days, I measured 50Mbps throughput with a 75MHz director, indicating
that you need a 150MHz CPU to saturate a 100Mbps link.
	</para>
	</section>
	<section id="8000pps" xreflabel="8000pps">
	<title>Estimating throughput: 100Mbps FE is really 8000packets/sec ethernet</title>
	<para>
If you are just setting up an LVS to see if you can set one up,
then you don't care about performance.
When you want to put one on-line for other people to use,
you'll want to know the expected performance.
	</para>
	<para>
On the assumption that you have tuned/tweeked your farm of realservers
and you know that they are capable of
delivering data to clients at a total rate of bits/sec or packets/sec,
you need to design a director capable of routing this number of
requests and replies for the clients.
	</para>
	<para>
First some background information on networking hardware.
At least for Linux (the OS I've measured, see
<ulink url="http://www.linuxvirtualserver.org/Joseph.Mack/performance/single_realserver_performance.html">
performance data for single realserver LVS</ulink>),
a network rated at 100Mbps is not 100Mbps all the time.
It's only 100Mbps when continuously carrying packets of mtu size (1500bytes).
A packet with 1 bit of data takes as long to transmit as a full mtu sized packet.
If your packets are &lt;ack&gt;s, or 1 character packets from
your telnet editing session or requests for http pages and images,
you'll barely reach 1Mbps on the same network.
On the
<ulink url="http://www.linuxvirtualserver.org/Joseph.Mack/performance/single_realserver_performance.html">
performance page</ulink>,
you'll notice that the hit rate increases
as the size of the hit targets (in bytes) gets smaller.
Hit rate is not neccessarily a good indicator of network throughput.
	</para>
	<para>
A possible explanation for the ethernet rate being a function only
of the packet rate is in an article on
<ulink url="http://sd.wareonearth.com/~phil/jumbo.html">
Gigabit Ethernet Jumbo Frames</ulink>
(look for the section &quot;Local performance issues&quot;)
(also see <link linkend="jumbo_frames">jumbo frames</link>).
Each packet requires an interrupt and the per-packet processing overhead
sets the limit for TCP performance.
This has resulted in a push for larger (jumbo) packets with Gigabit ethernet
(<emphasis>e.g.</emphasis> 64kB, a whole NFS frame).
The original problem was that the MTU size chosen for 100Mbps
ethernet (1500bytes) is the same as for 10Mbps ethernet.
This was so that packets traversing the different types of ethernet
would not have to be fragmented and defragmented.
However the side effect was that the packets are too small for 100Mbps ethernet
and you can double your ethernet throughput by doubling your packet size.
	</para>
	<para>
Tcpip can't use the full 100Mbps of 100Mbps network hardware,
as most packets are paired (data, ack; request, ack).
A link carrying full mtu data packets and their corresponding &lt;ack&gt;s, will
presumably be only carrying 50Mbps.
A better measure of network capacity is the packet throughput.
An estimate of the packet throughput comes from the network capacity
(100Mbps)/mtu size(1500bytes) = 8333 packets/sec.
	</para>
	<para>
Thinking of a network as 100Mbps rather than <emphasis>ca.</emphasis>8000packets/sec
is a triumph of marketing.
When offered the choice, everyone will buy network hardware rated at
100Mbps even though this capacity can't be used with your protocols,
over another network which will run continuously at 8000packets/sec for all protocols.
Only for applications like ftp will near full network capacity be reached
(then you'll be only running at 50&percnt; of the rated capacity as
half the packets are &lt;ack&gt;s).
I notice (Jun 2005) that switch speficiations
<emphasis>e.g.</emphasis>
<ulink url="http://www.netgear.com/products/details/FS516.php">Netgear FS516</ulink>
(http://www.netgear.com/products/details/FS516.php)
are quoted in packets/sec rather than bytes/sec.
	</para>
	<para>
A netpipe test
(realservers are 75MHz pentiums and can't saturate the 100Mbps network)
shows that some packets must be "small".
Julian's <link linkend="show_traffic">show_traffic script</link>
shows that for small packets (&lt;128bytes), the throughput is constant
at 1200packets/sec. As packets get bigger (upto mtu size), the packet
throughput decreases to 700packets/sec, and then increases to 2600packets/sec
for large packets.
	</para>
	<para>
The constant throughput in packets/sec is a first order
approximation of of tcpip network throughput and is the
best information we have to predict director performance.
	</para>
	<para>
In the case where a client is in an exchange of small packets (&lt;mtu size)
with a realserver in a LVS-DR LVS, each of the links
(client-director, director-realserver, realserver-client) would be saturated
with packets, although the bps rate would be low. This is the typical
case for non-persistent http when 7 packets are required for the setup
and termination of the connection, 2 packets are required for data passing
(eg the request GET /index.html and the reply) and an &lt;ack&gt; for each of these.
Thus only 1 out of 11 packets is likely to be near mtu size, and throughput will
be 10&percnt; of the rated bps throughput even though the network is saturated.
	</para>
	<para>
The first thing to determine then is the rate
at which the realservers are generating/receiving packets.
If the realservers are network limited,
i.e. the realservers are returning data in memory cache
(eg a disk-less squid) and have 100Mbps connections,
then each realserver will saturate a 100Mbps link.
If the service on the realserver requires disk or CPU access,
then each realserver will be using proportionately less of the network.
If the realserver is generating images on demand (and hence is
compute bound) then it may be using very little of the network
and the director can be handling packets for another realserver.
	</para>
	<para>
The forwarding method affects packet throughput.
With LVS-NAT all packets go through the director in both directions.
As well the LVS-NAT director has to rewrite incoming
and reply packets for each realserver.
This is a compute intensive process
(<link linkend="2.4_NAT">but less so for 2.4 LVS-NAT</link>).
In a LVS-DR or LVS-Tun LVS, the incoming packets are just forwarded
(requiring little intervention by the director's CPU) and
replies from the realservers return to the client directly
by a separate path (via the realserver's default gw)
and aren't seen by the director.
	</para>
	<para>
In a network limited LVS, for the same hardware,
because there are separate paths for incoming
and returning packets with LVS-DR and LVS-Tun,
the maximum (packet) throughput is twice that of LVS-NAT.
Because of the rewriting of packets in LVS-NAT,
the load average on a LVS-NAT director will be higher than for a
LVS-DR or LVS-Tun director managing twice the number of packets.
	</para>
	<para>
In a network bound situation, a single realserver will saturate
a director of similar hardware.
This is a relatively unusual case for the LVS's deployed so far.
However it's the situation where replies are from data in the
memory cache on the realservers (eg squids).
	</para>
	<para>
With a LVS-DR LVS, the realservers have their own connection to the internet,
the rate limiting step is the NIC on the director
which accepts packets (mostly &lt;ack&gt;s) from the clients.
The incoming network is saturated for packets but is only carrying low bps traffic,
while the realservers are sending full mtu sized
packets out their default gw (presumably the full 100Mbps).
	</para>
	<para>
The information needed to design your director then is
the number of packets/sec your realserver farm is delivering.
The director doesn't know what's in the packets (being an
L4 switch) and doesn't care how big they are
(1 byte of payload or full mtu size).
	</para>
	<para>
If the realservers are network limited, then the director
will need the same CPU and network capacity as the total
of your realservers. If the realservers are not network
limited, then the director will need correspondingly less capacity.
	</para>
	<para>
If you have 7 network limited realservers with 100Mbps NICs, then
they'll be generating an average of 7x8000 = 50k packets/sec.
Assuming the packets arrive randomly the standard deviation for
1 seconds worth of packets is +/- sqrt(50000)=200 (ie it's small
compared to the rate of arrival of packets).
You should be able to connect these realservers to a 1Gbps NIC
via a switch, without saturating your outward link.
	</para>
	<para>
If you are connected to the outside world by a slow connection (eg T1 line),
then no matter how many 8000packet/sec realservers you have,
you are only going to get 1.5Mbps throughput
(or half that, since half the packets are &lt;ack&gt;s).
	</para>
	<para>
Note: The carrying capacity of 100Mbps network of 8000packets/sec
may only apply to tcpip exchanges.
My 100Mbps network will carry 10,000 SYN packets/sec when tested
with Julian's <link linkend="testlvs">testlvs</link> program.
	</para>
	<para>
Wayne <emphasis>wayne (at) compute-aid (dot) com</emphasis> 03 Apr 2001
	</para>
<blockquote>
The performance page calculates the ack as 50&percnt; or so of the
total packets. I think that might not accurate, since in the
twist-pair and full duplex mode, ack and request are travelling
on two different pairs. Even in the half duplex mode, the packets
for two directions are transmit over two pairs, one for send, one
for receive, only the card and driver can handle them in full
duplex or half duplex mode. So the packets would be 8000
packets/sec all the times for the full duplex cards.
</blockquote>
	<para>
Joe: presumably for any particular connection, the various
packets have to be sent in order and whether they are
travelling over one or two pairs of cables would not matter.
However multiple connections may be able to make use
of both pairs of wires.
	</para>
	<para>
Unfortunately we only can approximately predict the performance of
an LVS director. Still the best estimates come from comparing with
a similar machine.
	</para>
	<para>
The
<ulink url="http://www.linuxvirtualserver.org/Joseph.Mack/performance/single_realserver_performance.html">
performance page
</ulink>
shows that a 133MHz pentium director can handle 50Mbps throughput.
With 2.2 kernel LVS-NAT, the load average on the director is unusably high,
but with LVS-DR, the director has a low load average.
	</para>
	<para>
Statements on the website indicate that a 300MHz pentium
LVS-DR director running a 2.2.x kernel can handle
the traffic generated by a 100Mbps link to the clients.
(A <link linkend="JWCS">550MHz PIII can direct 120Mbps</link>.)
	</para>
	<para>
Other statements indicate that single CPU high end (800MHz) directors
cannot handle 1Gbps networks.
Presumably multiple directors or SMP directors will be needed for Gbps networks.
(also see the section on <xref linkend="FAQ:smp_doesnt_help"/>.)
	</para>
	<para>
From: Jeffrey A Schoolcraft <emphasis>dream (at) dr3amscap3 (dot) com</emphasis> 7 Feb 2001
	</para>
	<blockquote>
	<para>
I'm curious if there are any known DR LVS bottlenecks?  My company had the
opportunity to put LVS to the test the day following the superbowl when we
delivered 12TB of data in 1 day, and peaked at about 750Mbps.
	</para>
	<para>
In doing this we had a couple of problems with LVS (I think they were with
LVS). I was using the latest lvs for 2.2.18, and ldiretord to keep the
machines in and out of LVS.  The LVS servers were running redhat with an
EEPro100.  I had two clusters, web and video.  The web cluster was a couple of
1U's with an acenic gig card, running 2.4.0, thttpd, with a somewhat
performance tuned system (parts of the C10K).  At peak our LVS got slammed
with 40K active connections (so said ipvsadmin).  When we reached this number,
or sometime before, LVS became in-accessible.  I could however pull content
directly from a server, just not through the LVS.  LVS was running on a single
proc p3, and load never went much above 3% the entire time, I could execute
tasks on the LVS but http requests weren't getting passed along.
	</para>
	<para>
A similar thing occurred with our video LVS.  While our realservers aren't
quite capable of handling the C10K, we did about 1500 a piece and maxed out at
about 150Mbps per machine. I think this is primarily modem users fault.  I
think we would have pushed more bandwidth to a smaller number of high
bandwidth users (of course).
	</para>
	<para>
I know this volume of traffic choked LVS.  What I'm wondering is, if there is
anything I could do to prevent this.  Until we got hit with too many
connections (mostly modems I imagine) LVS performed superbly.  I wonder if we
could have better performance with a gig card, or some other algorithm (I
started with wlc, but quickly changed to wrr because all the rr calculations
should be done initially and never need to be done again unless we change
weights, I thought this would save us).
	</para>
	<para>
Another problem I had was with ldirectord and the test (negotiate, connect).
It seemed like I needed some type of test to put the servers in initially,
then too many connections happened so I wanted no test (off), but the servers
would still drop out from ldirectord.  That's a snowball type problem for my
amount of traffic, one server gets bumped because it's got too many
connections, and then the other servers get over-loaded, they'll get dropped
to, then I'll have an LVS directing to localhost.
	</para>
	<para>
So, if anyone has pushed DR LVS to the limits and has ideas to share on how to
maximize it's potential for given hardware, please let me know.
	</para>
	</blockquote>
	</section>
	<section id="jumbo_frames">
	<title>Jumbo frames</title>
	<para>
All users of ethernet should understand the effects of MTU size on packet throughput
and why <link linkend="jumbo_frames">you need jumbo frames</link>.
The problem is that the MTU=1500bytes was designed for the original
implementation of ethernet at 3Mbps.
The clock speed was upped to 10Mbps for commercial release,
but the MTU was not changed, presumably not to change the required buffer size.
When 100Mpbs ethernet arrived,
the MTU was maintained for backward compatibility on mixed 10/100 networks.
The MTU is 30 times too small for 100Mbps and 300 times too small for 1Gbps ethernet.
	</para>
	<para>
Joe 26 Apr 2002 (posting to the beowulf mailing list)
	</para>
	<blockquote>
I know that jumbo frames increase throughput rate on GigE and was
wondering if a similar thing is possible with regular FE.
	</blockquote>
	<para>
Donald Becker <emphasis>becker (at) scyld (dot) com</emphasis> 26 Apr 2002
	</para>
	<para>
I used to track which FE NICs support oversized frames. Jumbo frames
turned out to be so problematic that I've stopped maintaining the table.
	</para>
	<blockquote>
the MTU of 1500 was chosen for 10Mbps ethernet and was kept
for 100Mbps and 1Gbps ethernet for backwards compatibility
on mixed networks. However MTU=1500 is too small
for 100Mbps and 1Gbps ethernet. In Gbps ethernet jumbo frames
(ie bigger MTU) is used to increase throughput.
	</blockquote>
	<para>
Yup, 1500 bytes was chosen for interactive response on original
Ethernet.  (Note: originally Ethernet was 3Mbps, but commercial
equipment started at 10Mbps.)
The backwards compatibility issue is severe.  The only way to
automatically support jumbo frames is using the paged autonegotiation
information, and there is no standard established for this.
	</para>
	<para>
Jumbo frame *will* break equipment that isn't expecting oversized
packets.  If you detect a receive jabber (which is what a jumbo frame
looks like), you are allowed (and _should_) disable your receiver for a
period of time.  The rationale is that a network with an on-going
problem is likely to be generating flawed packets that shouldn't be
interpreted as valid.
	</para>
	<blockquote>
	<para>
With netpipe I found that throughput on FE was approx linear with
increasing MTU upto the max=1500bytes. I assume that there
is no sharp corner at 1500 and if in principle larger
frames could be sent, then throughput should also increase
for FE. (Let's assume that the larger packets will
never get off the LAN and will never need to be fragmented).
	</para>
	<para>
I couldn't increase the MTU above 1500 with ifconfig or ip link.
I found that the MTU seemed to be defined in
	</para>
<programlisting><![CDATA[
linux/include/if_ether.h
as
ETH_DATA_LEN and ETH_FRAME_LEN
]]></programlisting>
	<para>
and increased these by 1500, recompiled the kernel and net-tools
and rebooted. I still can't install a device with MTU>1500
	</para>
	<para>
VLAN sends a packet larger than the standard MTU, having an
extra 4 bytes of out of band data. The VLAN people have
problems with larger MTUs. Here's their mailing list
	</para>
	<para>
http://www.WANfear.com/pipermail/vlan/
	</para>
	<para>
where I found the following e-mails
	</para>
	<para>
<programlisting><![CDATA[
http://www.WANfear.com/pipermail/vlan/2002q2/002385.html
http://www.WANfear.com/pipermail/vlan/2002q2/002399.html
http://www.WANfear.com/pipermail/vlan/2002q2/002401.html
]]></programlisting>
	</para>
	<para>
which indicate that the MTU is set in the NIC driver and
that in some cases the MTU=1500 is coded into the hardware
or is at least hard to change.
	</para>
	</blockquote>
	<para>
Most of the vLAN people don't initially understand the capability of the
NICs, or why disabling Rx length checks is a Very Bad Idea.
There are many modern NIC types that have explicit VLAN support, and
VLAN should only be used with those NICs.  (Generic clients do not
require VLAN support.
	</para>
	<blockquote>
I don't know whether regular commodity switches (eg Netgear
FS series) care about packet size, but I was going to
try to send packets over a cross-over cable initially.
	</blockquote>
	<para>
Hardware that isn't expecting to handle oversized frames might break in
unexpected ways when Rx frame size checking is disabled.  Breaking for
every packet is fine.  Occasionally corrupting packets as a counter
rolls over might never be pinned on the NIC.
	</para>
	<para>
The driver also comes into play.  Most drivers are designed to receive
packets into a single skbuff, assigned to a single descriptor.  With
jumbo frames the driver might need to be redesigned with multiple
descriptors per packet.  This adds complexity and might introduce new
race conditions.  Another aspect is that dynamic Tx FIFO threshold
code is likely to be broken when the threshold size exceeds 2KB.  This
is a lurking failure -- it will not reveal itself until the PCI is very
busy, then Boom...
	</para>
	<para>
Most switches very much care about packet size.  Consider what happens
in store-and-forward mode.
	</para>
	<para>
All of these issues can be fixed or addressed on a case-by-case basis.
If you know the hardware you are using, and the symptoms of the
potential problems, it's fine to use jumbo frames.  But I would never
ship a turn-key product or preconfigured software that used jumbo frames
by default.  It should always require expertise and explicit action for
the end user to turn it on.
	</para>
	<para>
Josip Loncaric <emphasis>josip (at) icase (dot) edu</emphasis> 29 Apr 2002
	</para>
	<blockquote>
	<para>
The backwards compatibility issue is severe
	</para>
	<para>
Jumbo frames are great to reduce host frame procesing overhead, but,
unfortunately, we arrived at the same conclusion: jumbo frames and
normal equipment do not mix well.  If you have a separate network where
all participants use jumbo frames, fine; otherwise, things get messy.
	</para>
	<para>
Alteon (a key proponent of jumbo frames) has some suggestions: define a
normal frame VLAN including everybody and a (smaller) jumbo frame VLAN;
then use their ACEswitch 180 to automatically fragment UDP datagrams
when routing from a jumbo frame VLAN to a non-jumbo frame VLAN (TCP is
supposed to negotiate MTU for each connection, so it should not need
this help).  This sounds simple, but it requires support for 802.1Q VLAN
tagging in Linux kernel if a machine is to participate in both jumbo
frame and in non-jumbo frame VLAN.  Moreover, in practice this mix is
fragile for many reasons, as Donald Becker has explained...
	</para>
	<para>
One of the problems I've seen involves UDP packets generated by NFS.
When a large UDP packet (jumbo frame MTU=9000) is fragmented into 6
standard (MTU=1500) UDP packets, the receiver is likely to drop some of
these 6 fragments because they are arriving too closely spaced in time.
If even one fragment is dropped, the NFS has to resend that jumbo UDP
packet, and the process can repeat.  This results in a drastic NFS
performance drop (almost 100:1 in our experience).  To restore
performance, you need significant interrupt mitigation on the receiver's
NIC (<emphasis>e.g.</emphasis> receive all 6 packets before interrupting), but this can hurt
MPI application performance.  NFS-over-TCP may be another good solution
(untested!).
	</para>
	<para>
We got good gigabit ethernet bandwidth using jumbo frames (about 2-3
times better than normal frames using NICs with Alteon chipsets and the
acenic driver), but in the end full compatibility with existing
non-jumbo equipment won the argument: we went back to normal frames.
The frame processing overhead does not seem as bad now that CPUs are so
much faster (2GHz+), even with our gigabit ethernet, and particularly
not with fast ethernet.
	</para>
	<para>
However, if we had a separate jumbo-frame-only gigabit ethernet network,
we'd stick to jumbo frames.  Jumbo frames are simply a better solution
for bulk data transfer, even with fast CPUs.
	</para>
	</blockquote>
	</section>
	<section id="network_latency">
	<title>Network Latency</title>
	<para>
Network latency in an LVS is determined by the internet and is beyond
the control of the person setting up the LVS.
In a beowulf, the network is local and latency is important.
Here's a posting from
the beowulf mailing list about latency and throughput for small packets
on Gbps (GigE) ethernet.
	</para>
	<para>
Richard Walsh <emphasis>rbw (at) ahpcrc (dot) org</emphasis> 07 Mar 2003
	</para>
	<para>
In the limit of a 1 byte message, the inverse of the latency
is the worst-case bandwidth for repeatedly sending 1 byte. On a GigE
system with a latency of say 50 usecs your worst case bandwidth
is 20 KB/sec :-(. This is mostly a hardware number. If you add in
other contributors to the latency things get worse. As message size
shrinks latency eventually dominates the transfer time ... the larger
the latency the sooner this happens. Under the heading of "everything
is just another form of something else", the distinction between latency
and bandwidth gets muddy as latency grows relative to message size.
	</para>
	<para>
On the other hand, if you can manage your message sizes, keep the
latency piece a small percentage of the message transit time, and have
good bandwidth you may not care what the latency is.  Pushing up data volumes
per node imply larger surfaces to communicate which imply larger messages.
These transfers can be hidden behind compute cycles.  Of course, one
has to worry about faster processors shrinking compute cycles.
	</para>
	</section>
	<section id="mixed_gigE_FE">
	<title>Mixture of 100Mbps and GigE ethernet</title>
	<para>
Jeremy Kusnetz
	</para>
	<blockquote>
		<para>
 We are planning on upgrading the network our realservers to gigE to
 support a gigE connection to our NFS server.  I need to have gigE on the
 realservers due to potential buffering issues losing NFS udp packets
 coming from the NFS server.
		</para>
		<para>
 Now that the realservers will be on gigE, I can see a potential of the
 realservers sending data to the director faster then the director's
 internal 100mb connection can handle and start buffering packets on the
 swtich.  Because of that I'm planning on putting a gigE interface on the
 internal connection of the director, but leaving a 100mb nic connecting
 the director to the outside routers.  Now the director would be buffering
 data coming in at gigE speeds and sending out the data at 100mb speeds.
 Am I going to have any problems on the director doing this kind of
 buffering?  I figure it could probably handle it better then the switch
 could.  Am I right?
		</para>
	</blockquote>
	<para>
Ryan Leathers <emphasis>ryan (dot) leathers (at) globalknowledge (dot) com</emphasis> 29 Mar 2004
	</para>
	<para>
TCP is your friend.  Even if you had Jumbo frames enabled and large
payloads its extremely unlikely that TCP would fail to sufficiently
throttle the delivery rate before you would bump into a hard buffer.
TCP is decoupled from the underlying transports.  While this is
inefficient in obvious ways it is also presicely what protects us from
situations like the one you describe.  The down side is that TCP doesn't
really get with the program until a problem BEGINS to happen.
GigE on your director will reduce some of the switching burden, but
ultimately, its TCP's behavior which will throttle end-to-end traffic
within the tolerable capacity of your infrastructure.
If top performance is of concern you might consider traffic shaping on
the realservers for egress traffic.
	</para>
	<blockquote>
Unfortunately we have some UDP protocols we are load balancing, namely DNS
and radius.  I'm not too worried about TCP traffic, but I am worried about
losing UDP packets.
Maybe I should keep the interconnects between the realservers and the
director   100DB like it is now, but do NFS on a separate network off of
the gigE cards.
	</blockquote>
	</section>
	<section id="nics_and_switches">
	<title>NICs and Switches, 100Mbps (FE) and 1Gbps (GigE)</title>
	<para>
(Apr 2002)
	</para>
	<para>
If you are going into production,
you should test that your NICs and switch works well with the hardware in your node.
Give it a good exercising with a
<ulink url="http://www.scl.ameslab.gov/netpipe/">netpipe</ulink> test.
(see the
<ulink url="http://www.linuxvirtualserver.org/Joseph.Mack/performance/single_realserver_performance.html">performance page</ulink>
where the netpipe test is used).
Netpipe will determine the network latency,
the maximum throughput and whether the hardware behaves properly under stress.
Latency determines system speed for processes transferring
small packets over a small number of hops
(usually one hop), while maximum throughput determines your system behaviour
for large numbers of MTU sized packets.
	</para>
	<para>
The <ulink url="http://www.beowulf.org">beowulfers</ulink>
have done the most to find out which network hardware is useful at high load.
You can look through the whole beowulf mailing list archive
after downloading it.
Unfortunately there is no online keywork search
like we have on the LVS mailing list (thanks to Hank).
Beowulfers are interested in both latency and throughput.
If your LVS is sending packets to clients on the internet, your latency
will be determined by the internet. If your connection to your clients
is through a T1 line, your maximum throughput will also be determined
by the internet.
The beowulfers use either 100Mbps FE or for high throughput, myrinet.
They don't use 1Gbps ethernet as it doesn't scale and is expensive.
	</para>
	<para>
Network performance is expensive. In a beowulf with myrinet, half the
cost of the hardware is in the networking.
The difference between a $100k beowulf and a $5M Cray, which has the
same number, type and speed of commodity DEC Alpha CPUs,
is the faster interconnects in the Cray.
With a Cray supercomputer, you aren't buying fast CPUs
(Cray doesn't make its CPUs anymore,
they're using the same CPUs that you can buy in a desktop machine),
what you're buying is the fast onboard networking between the CPUs.
	</para>
		<section id="100Mbps">
		<title>100Mbps</title>
		<para>
Martin Seigert at Simon Fraser U posted
<ulink url="http://www.sfu.ca/acs/cluster/nic-test.html">Benchmarks for various NICS</ulink>
to the beowulf mailing list.
The conclusion was that for fast CPUs
(<emphasis>i.e.</emphasis>600MHz, which can saturate 100Mbps ethernet)
the 3c95x and tulip cards were equivelent.
		<note>
		<para>
from a posting on the beowulf mailing list: "the tulip is the ne2k of the late 90's".
(I use them when I can - Joe).
		</para>
		</note>
For slower CPUs (166MHz) which cannot saturate 100Mbs ethernet,
the on-board processing on the 3Com hards allowed marginally better throughput.
		</para>
		<para>
I use Netgear FA310TX (tulip), and eepro100 for single-port NICs.
The related FA311 card seems to be Linux incompatible (postings
to the beowulf mailing list), currently (Jul 2001) requiring a driver from Netgear
(this was the original situation with the FA310 too).
I also use a quad DLink DFE-570TX (tulip) on the director.
I'm happy with all of them.
		</para>
		<para>
The eepro100 has problems as Intel seems to change the hardware
without notice and the linux driver writers have trouble handling
all the versions of hardware.
One kernel (2.2.18?) didn't work with the eepro100.
and new kernels seem to have problems occasionally.
I bought all of my eepro100's at once
and presumably they are identical and presumably the bugs have been worked out for them.
There have been a relatively large number of posting of people with
<link linkend="eepro100_problems">eepro100 problems</link> on the LVS mailing list.
You should expect continuing problems with this card,
which will be incrementally solved by kernel patches.
		</para>
		</section>
		<section id="100Mbps_switches">
		<title>100Mbps switches</title>
		<para>
These are now cheap.
The parameters that determine the performance of a switch are
		</para>
		<itemizedlist>
			<listitem>
			<para>
the backplane bandwidth
			</para>
			<para>
This is the total rate of packet or bit throughput that the switch can handle
through all ports at once.
If you have an 8 port 100Mbps switch, you need a backplane bandwidth of
400Mbps to allow all 4 pairs of ports to talk at the same time.
			</para>
			<para>
A hub is just a switch that only allows one pair of ports to talk at a time.
			</para>
			</listitem>
			<listitem>
			<para>
cut through, store and foward
			</para>
			<para>
At low packet throughput a switch will &quot;cut through&quot;, <emphasis>i.e.</emphasis>
after decoding the dst_lladdr (the MAC address of the target) on the packet,
it will switch the packet through to the appropriate port before the rest
of the packet has arrived at the switch. This will ensure low latency for
packet transfer. You can test switch latency by replacing the
switch with a cross-over cable.
			</para>
			<para>
When the packet throughput exceeds the backplane bandwidth, the switch
can store packets till there is space on the link layer. This is called
&quot;store and forward&quot;
			</para>
			<para>
What you want to know is whether the switch does cut through and/or store and forward,
and if it does both, when the change over occurs.
			</para>
			</listitem>
			<listitem>
			<para>
large packet handling
			</para>
			<para>
You want to know what the switch does with packets larger than the standard
1500byte MTU.
			</para>
			</listitem>
		</itemizedlist>
		<para>
Unfortunately the suppliers of commodity switches, Netgear, 3COM and HP are
less than forthcoming on their specs.
		</para>
		<para>
(Apr 2002, <ulink url="http://www.extremenetworks.com/">Extreme Networks</ulink>,
quote backplane, which they call &quot;switch fabric&quot;,
bandwidth for their products, which include GigE switches. Sep 2002 - they've removed
the webpage.)
		</para>
		<para>
Netgear gives the most information
(and has the cheapest switches) and I bought my switch from them,
as a way of supporting their efforts here.
Someone I know who buys a lot of switches said he had some Netgear switches arrive DOA.
They were returned without problem,
but manufacturers should be shipping working boxes.
3COM gives less information than Netgear,
while HP just wants to know whether you are using the device at home or at a business
and they'll tell you which box you need.
I started seeing advertisements for Dell switches in Sept 2001,
at lower prices than for Netgear,
but the Dell website didn't acknowlege that they existed
and a contact at Dell couldn't find specs for them.
The Dell switches appeared to be rebadged equipment from another networking company.
None of these suppliers give the above neccessary information -
they aren't selling switches, they're selling
&quot;productivity enhancement solutions&quot;.
		</para>
		<para>
I'm happy with my Netgear FS series switch, but then I haven't
tested it with 100Mbps simultaneously on all ports.
		</para>
		<para>
Since the price of a switch rises exponentially with its backplane
bandwidth (required for more ports),
an often suggested solution (which I haven't tested),
is to divide your network into smaller groupings of computers,
connected by 2 layers of switches (this will increase
your network latency, since now two hops may be required).
		</para>
		</section>
		<section id="JWCS">
		<title>550MHz CPU saturates 100Mbps ethernet</title>
		<para>
Martin Hamilton <emphasis>martin (at) net (dot) lut (dot) ac (dot) uk</emphasis>  Nov 14 2001
		</para>
		<blockquote>
		<para>
we (JWCS) also use LVS on our home institutional caches.
These are somewhat smaller scale, <emphasis>e.g.</emphasis> some 10m URLs/day at the moment
for Loughborough's campus caches vs. 130m per day typically on the
JANET caches.  The good news is that LVS in tunnelling mode is happily
load balancing peaks of 120MBit/s of traffic on a 550MHz PIII.
		</para><para>
Folk in ac.uk are welcome to contact us at
<emphasis>support (at) wwwcache (dot) ja (dot) net</emphasis> for
advice on setting up and operating local caches.
I'm afraid we can only provide this to people on the JANET network,
like UK Universities and Colleges.
		</para>
		</blockquote>
		</section>
		<section id="GigE_NICS">
		<title>1Gbps (GigE) NICs</title>
		<para>
Here's a
<ulink url="http://www.cs.uni.edu/&#126;gray/gig-over-copper/">
review of GigE over copper wire</ulink>.
All current (May 2002) GigE NICs support jumbo frames and are cheap (US$100).
The best latency (SysConnect SK9821 NIC) is 50usecs. While this is nice,
I'm getting 150usec on a pair of 100Mbps ethernet cards
connected between a 133MHz pentium 1 and a dual 180MHz Pentium Pro
at a fraction of the cost.
The SysConnect card can deliver 900Mbps with jumbo frames.
		</para>
		<para>
Here's the
(http://www.scd.ucar.edu/nets/docs/reports/HighSpeed/ - link dead Jul 2004)
NCAR High Performance Networking Tests which gives
background info on fast networks (ATM and GigE). The main point
for us is that the jumbo frame formats are proprietary and non-iteroperable
(we need a standard here).
		</para>
		</section>
		<section id="GigE_switches">
		<title>1Gbps (GigE) switches</title>
		<para>
While GigE NICs are cheap, the switches are still expensive.
The suppliers of commodity GigE switches are even less forthcoming
with their specs than they are for their 100Mbps switches.
		</para>
		<para>
(Note: Apr 2002, I just found "http://www.extremenetworks.com/products/products.asp
which quote backplane, which they call &quot;switch fabric&quot;,
bandwidth for their products, which include GigE switches. Note: Oct 2002, link is dead.)
		</para>
		<para>
It seems that the manufactureres would rather you figure out the specs yourself.
Netgear is selling a 24 port GigE switch (according to a vendor),
but all you can find on the Netgear website (Apr 2002) is a 100Mbps switch with 4 GigE ports.
Some of the vendors want you to figure out the existance of their boxes too.
		</para>
		<para>
Here's my estimate of commodity GigE switch specs:
		</para>
		<para>
A 24 port cisco 6000 series GigE chassis (no added boards) costs
US$60k, has a backplane bandwidth of 32Gbps and supports jumbo frames.
The commodity switches (<emphasis>e.g.</emphasis> 24 port HP4108) costs US$6k and
<emphasis role="bold">do not</emphasis> support jumbo frames.
On the assumption that the backplane bandwidth is what you're paying for,
then the spec on the HP box is 3Gbps <emphasis>i.e.</emphasis> only 3 pairs of
ports on your 24 port box can be active at once.
This box is not much more than a hub,
something the manufacturers would not want you to know.
		</para>
		<para>
You need jumbo frames and you can't have them.
It is pointless going to GigE unless you have jumbo frames.
These switch specs explain why GigE scales so badly and why beowulfers
would rather stay with 100Mbps than spend any money on GigE.
		</para>
		<para>
For some performance data see
<ulink url="http://www.osc.edu/~pw/emp/switch.html">Gigabit ethernet TCP switch
performance</ulink>.
		</para>
		</section>
	</section>
	<section id="bonding">
	<title>Ethernet,NIC Bonding</title>
	<para>
This has not proven reliable or easy to setup, at least in the hands of the Beowulfers.
Make sure your LVS is working properly before trying ethernet bonding.
	</para>
	<para>
Craig Ward
	</para>
	<blockquote>
Are there any known issues with bonding NICs and LVS?
I've got a setup with 4 boxes, all 4 are web servers and 2 are directors.
The VIP is being brought up on bond0:0 fine, but I can't ping this
from any machine and its not showing in the arp table on my windows
client. Strangely, if I manually bring up an ip on bond0:0 that is NOT
the the VIP I can ping it fine.
I'm wondering if any of the noarp rules on the each director, used for
when they are slave directors, is somehow "stuck" and it's not arping
for the VIP whatever interface it's on?
	</blockquote>
	<para>
Brad Hudson <emphasis>brad (dot) hudson (at) gmail (dot) com</emphasis> 5 Nov 2005 
	</para>
	<para>
Here is how I use bonding:
	</para>
<programlisting><![CDATA[
$node = IPVS server
$real = real server
$fip = front end ip
$fvip = front end vip
$bip = back end ip
$bvip = back end vip
]]></programlisting>
	<orderedlist>
		<listitem>
$node has eth1 and eth3 bonded together on $fip as bond0
		</listitem>
		<listitem>
$fvip sits on bond0:0 and accepts all incoming requests for load balancing
		</listitem>
		<listitem>
$node has eth0 and eth2 bonded together on $bip as bond1
		</listitem>
		<listitem>
$bvip sits on bond1:0 and talks to all real servers where each $real has a gateway of $bvip
		</listitem>
	</orderedlist>
	<para>
FYI: $node is also in failover cluster #1 and all real servers are in load
balanced cluster #2
	</para>
	</section>
	<section id="eepro100_problems">
	<title>NIC problems - eepro100</title>
		<section id="counter_overflows">
		<title>counter overflows</title>
		<para>
(This is from 1999 I think)
		</para>
		<para>
linux with an eepro100 can't pass more than 2^31-1 packets. This
may not still be a problem.
		</para>
		<para>
Jerry Glomph Black <emphasis>black (at) real (dot) com</emphasis> Subject: 2-billion-packet bug?
		</para>
		<blockquote>
		<para>
I've seen several 2.2.12/2.2.13 machines lose their network connections after
a long period of fine operation.   Tonight our main LVS box fell off the net.  I
visited the box, it had not crashed at all.   However, it was not communicating
via its (Intel eepro100) ethernet port.
		</para>
		<para>
The evil evidence:
		</para>
<programlisting><![CDATA[
eth0      Link encap:Ethernet  HWaddr 00:90:27:50:A8:DE
          inet addr:172.16.0.20  Bcast:172.16.255.255  Mask:255.255.0.0
          UP BROADCAST RUNNING MULTICAST  MTU:1500  Metric:1
          RX packets:15 errors:288850 dropped:0 overruns:0 frame:0
          TX packets:2147483647 errors:1 dropped:0 overruns:0 carrier:0
          collisions:0 txqueuelen:100
          Interrupt:10 Base address:0xd000
]]></programlisting>
		<para>
Check out the TX packets number!  That's 2^31-1.
Prior to the rollover, In-and-out packets were roughly equal.
I think this has happened to non-LVS systems as well, on 2.2 kernels.
ifconfigging eth0 down-and-up did nothing.  A reboot (ugh) was necessary.
		</para>
		</blockquote>
		<para>
It's still happening 2yrs later. This time the counter stops, but the
network is still functional.
		</para>
		<para>
Hendrik Thiel <emphasis>thiel (at) falkag (dot) de</emphasis> 20 Nov 2001
		</para>
		<blockquote>
		<para>
using lvs with eepro100 cards (kernel 2.2.17)
and encountered a TX packets value stopping at 2147483647 (2^32-1)
thats what ifconfig tells...the system still runs fine ...
		</para>
		<para>
it seems to be a ifconfig Bug.
Check out the TX packets number! That's 2^31-1.
		</para>
<programlisting><![CDATA[
eth0 Link encap:Ethernet HWaddr 00:90:27:50:A8:DE
inet addr:172.16.0.20 Bcast:172.16.255.255 Mask:255.255.0.0
UP BROADCAST RUNNING MULTICAST MTU:1500 Metric:1
RX packets:15 errors:288850 dropped:0 overruns:0 frame:0
TX packets:2147483647 errors:1 dropped:0 overruns:0 carrier:0
collisions:0 txqueuelen:100
Interrupt:10 Base address:0xd000
]]></programlisting>
			<para>
Simon A. Boggis
			</para>
			<blockquote>
			<para>
Hmmm, I have a couple of eepro100-based linux routers -
the one thats been up the longest is working fine
(167 days, kernel 2.2.9) but the counters are
jammed - for example, `ifconfig eth0' gives:
			</para>
<programlisting><![CDATA[
eth0 Link encap:Ethernet HWaddr 00:90:27:2A:55:48
inet addr:138.37.88.251 Bcast:138.37.88.255 Mask:255.255.255.0
IPX/Ethernet 802.2 addr:8A255800:0090272A5548
UP BROADCAST RUNNING MULTICAST MTU:1500 Metric:1
RX packets:2147483647 errors:41 dropped:0 overruns:1 frame:0
TX packets:2147483647 errors:13 dropped:0 overruns:715 carrier:0
Collisions:0
Interrupt:15 Base address:0xa000
]]></programlisting>
			<para>
BUT /proc/net/dev reports something more believable:
			</para>
<programlisting><![CDATA[
hammer:/# cat /proc/net/dev
Inter-| Receive | Transmit
face |bytes packets errs drop fifo frame compressed multicast|bytes packets errs drop fifo colls carrier compressed
eth0:2754574912 2177325200 41 0 1 0 0 0 2384782514 3474415357 13 0 715 0 0 0
]]></programlisting>
			<para>
Thats RX packets: 2177325200 and TX packets: 3474415357
compared to : 2147483647 from ifconfig eth0
			</para>
			</blockquote>
		</blockquote>
		<note>
		<para>
From Purrer Wolfgang <emphasis>www (dot) purrer (dot) at</emphasis> 24 Apr 2003:
If Donald Becker's drivers aren't helping, you can always get the
<ulink url="http://appsr.intel.com/scripts-df/support_intel.asp">drivers from Intel</ulink>.
(Joe - it's an appalingly designed site).
		</para>
		</note>
		</section>
		<section id="new_drivers">
		<title>new drivers</title>
		<para>
Andrey Nekrasov
		</para>
		<blockquote>
		<para>
After I changed to kernel 2.4.x with "arp hidden patch"
		</para>
<programlisting><![CDATA[
eepro100: wait_for_cmd_done timeout!
]]></programlisting>
		<para>
I haven't had any problems before with NIC Intel EEPRO/100.
		</para>
		</blockquote>
		<para>
Julian 4 Feb 2002
		</para>
		<para>
        This problem happens not only with LVS.
Search the web or linux-kernel:
http://marc.theaimsgroup.com/?t=100444264400003&amp;r=1&amp;w=2
		</para>
		</section>
		<section id="2.4.18">
		<title>Kernel 2.4.18</title>
		<para>
Peter Mueller <emphasis>pmueller (at) sidestep (dot) com</emphasis> 22 May 2002
		</para>
		<blockquote>
2.4.18 has an eepro100 bug in it.
Looking in dejanews, there is a slow down under some circumstances. You
should use the driver from 2.4.17.
		</blockquote>
		</section>
		<section id="eepro_bonding">
		<title>bonding with eepro100</title>
		<para>
Roberto Nibali <emphasis>ratz (at) drugphish (dot) ch</emphasis> 07 Nov 2003
		</para>
		<para>
The eepro100 never really worked well for me in conjunction with
bonding. I also use the e100/e1000 drivers as suggested by Brian.
		</para>
		<para>
Also note that the bonding architecture has gotten a major (actually
huge) overhaul during between the 2.4.21 and 2.4.23-preX phase. Among them
is the possibility to set and change the MAC and the MTU in ALB/TBL
modes, fixed arp monitoring, better 802.3ad support and proper locking.
You might wanna play with some of the newer 2.4.23-pre kernels or at
least with 2.4.22 if the problem persists, then again it's highly
time-consuming to follow latest ("stable") development kernels currently.
		</para>
		</section>
	</section>
	<section id="tulip">
	<title>NIC problems - tulip</title>
	<para>
(Joe, Nov 2001 I don't know if this is still a problem,
we haven't heard any more about it and haven't had any other
tulip problems, unlike the <link linkend="eepro100_problems">eepro100</link>.)
	</para>
	<para>
John Connett <emphasis>jrc (at) art-render (dot) com</emphasis> 05 May 1999
	</para>
	<blockquote>
		<para>
Any suggestions as to how to narrow it down?  I have an Intel
EtherExpress PRO 100+ and a 3COM 3c905B which I could try instead of the
KNE 100TX to see if that makes a difference.
		</para>
		<para>
A tiny light at the end of the tunnel!  Just tried an Intel EtherExpress
PRO 100+ and it works!  Unfortunately, the hardware is fixed for the
application I am working on and has to use a single Kingston KNE 100TX NIC ...
		</para>
		<para>
Some more information.  The LocalNode problem has been observed
with both the old style (21140-AF) and the new style (21143-PD)
of Kingston KNE 100TX NIC.  This suggests that there is a good
chance that it will be seen with other "tulip" based NICs.  It
has been observed with both the "v0.90 10/20/98" and the "v0.91
4/14/99" versions of tulip.c.
		</para>
		<para>
I have upgraded to vs-0.9 and the behaviour remains the same: the
EtherExpress PRO 100+ works; the Kingston KNE 100TX doesn't work.
		</para>
		<para>
It is somewhat surprising that the choice of NIC should have this
impact on the LocalNode behaviour but work successfully on
connections to slave servers.
		</para>
		<para>
Any suggestions as to how I can identify the feature (or bug) in
the tulip driver would be gratefully received.  If it is a bug I
will raise it on the tulip mailing list.
		</para>
	</blockquote>
	</section>
	<section id="quad_cards">
	<title>dual/quad ethernet cards, IRQ sharing problems</title>
	<blockquote>
any recommendations?
	</blockquote>

	<para>
Ratz 04 Dec 2002:
We're using Adaptec Quadboards (Adaptec ANA-62044, 64-bit PCI) and they work
like a charm.
You can stick in 6 of those on a Intel Serverboard and have 24 NICs.
We're however testing the new Intel Quadboards that will officially be available
on Q1 2003.
We chose Adaptec because in the past we've had bad experiences with badly
broken DLink hardware.
This mostly concerned their switches.
But once a product
sheds bad light on the decision you will hardly convince yourself that the rest
of the product line works correctly, IMHO.
	</para>
	<blockquote>Are IRQ-sharing lockups a thing of the past?
	</blockquote>

	<para>
P3-600's:
I very well remember and we have delivered a few such packet filters without any
major problems.
	</para>

	<para>
ASUS P*B-*: never had a single problem. Ok, we
use a 2.2.x kernel with some enhancements of mine (not IRQ routing related).
There should be no problem.
	</para>

	<blockquote>
the boards in this era that I used had this problem, and guides like
Anandtech and tomshardware advised to configure the BIOS to have each PCI slot
be a set IRQ.
	</blockquote>

	<para>
Do _not_ do that! Linux will choose an IRQ for the PCI slot and depending on
whether the board has SCSI or IDE the IRQ wired routing on the local APIC is
different. Forcing an IRQ on a specific PCI slot makes ASUS boards with older
firmware releases go banana when assigning the IRQ routing, especially those
with a onboard SCSI chip. There you have a reversed initialisation phase. Also
if you're using the PCI-sharing option from the BIOS make sure to enable PCI-2.x
compliancy and use an up-to-date BIOS release. And last but not least: All this
doesn't work if you use Realtek-chipset based NICs. They are fundamentally
flawed when it comes to IRQ sharing. Nowadays this is solved however and you can
use this el-cheapo NIC.
	</para>

	<para>
Nowadays you can look into the motherboard booklet and see the wiring. If you
intend to put in an additional SCSI card you need to make sure that the routing
is separated. In most 5 to 6 PCI-slot boards, you could for example select slot
1 and 2 for separation since they are not routed over the same chip. It's
depending on the bridge however.
	</para>
	<para>
This all changes if you have a SMP board (how could it be any different of
course :)). There you need to distinguish every single motherboard factorisation
to know how to solve the eventual problem of deplaced IRQ sharing. It will very
much depend on the PCI chipset support in the kernel (in Windows world this
would be the busmaster driver).
	</para>

	<blockquote>
Ok..  so IRQ sharing is FIXED in 99% of situations now?  I can take 2 quad
cards from different manufacturer's and put them in the same box and they
will work on the same IRQ (from the BIOS perspective)?
	</blockquote>

	<para>
This is not said. All 4 ports of a single quadboard will have the same IRQ but
if you put in a second quadboard from a different vendor your machine might just
end up using different IRQ. Interport IRQ routing on a single quadboard is
almost always shared. Also you need to take into account that this can change if
you enable local APIC on UP or APIC in general for SMP boards. There you most
propably end up with less probability of shared IRQs. However you end up with
bigger problems with certain Intel boards based on the 440GX+/440LX+ chipset.
	</para>

	<blockquote>
So SCSI needs to be a seperate IRQ from the rest?  Don't share SCSI.  What
about Firewire or USB2 or ... ;)
	</blockquote>

	<para>
I'm not that much into firewire and USB2, since having a packet filter or high
traffic node with quadboards normally implies in not having the need for any
firewire or USB2 devices. YMMV.
	</para>

	<blockquote>
Have you looked at the AMD bus at all?
	</blockquote>
	<para>
If you're going SMP then yes, pay a 200 bucks more and get a decent board with
EMP and MCE support via console (UART). I have looked at the AMD boards but in
our lab we've found them to be less ready to work properly with the rest of our
hardware then Intel based boards. I wish support for AMD boards in Linux would
be better but this is just a matter of time.
	</para>
	</section>
	<section id="flakey_switch">
	<title>Flakey Switch</title>
	<para>
Here a user tracked down a poor performance problem,
to a possible flakey switch,
when serving <xref linkend="windows_media_server"/>.
	</para>
	<para>
Mark Weaver <emphasis>mark (at) npsl (dot) co (dot) uk</emphasis> 23 Mar 2004
	</para>
	<blockquote>
		<para>
 The test client is using the Windows Media Load Simulator.  This just makes a
 lot of connections and streams back data.  The average stream only gets up
 to about 35Mbit.  At this point, CPU usage on the director is ~20% (which
 would seem to indicate that I should be able to get a lot more out of it).
 CPU on the test box is at about 25% and on the media server at 4%.
		</para>
		<para>
 The problematic part is that the director begins dropping about 10% of
 externally originated packets at this level of load.  I wouldn't say any
 machine involved is stressed here, but pinging the external IP of the
 director gives that huge loss.  This noticeably affects say, SSH, on the
 director or TS to the media server.  This is constrasted with pinging the
 external IP of the test box, which gives 0% loss.
		</para>
		<para>
 I would therefore conclude that this is an issue with the director, but I'm
 not sure what.  My next guess would be to try swapping the VIA NIC for
 another 3com one, but could it really be that bad? I can't see it being an
 issue with the cisco switch (test box and director are both connected to
 it); the cisco router (same), or the d-link switch (not involved in ping to
 director), so I'm at a loss as to what else to conclude.
		</para>
		<para>
I trundled my self down the the hosting centre to do some
further testing.  It turns out that when plugging a couple of test clients
directly into the switch in front of the director, I can get 90Mbits
sustained load out of it using around 40% CPU on the director, nearly 100%
CPU on both test clients, 5% CPU on the WMS machine, and ~1.5k concurrent
connections.  Fantastic!
		</para>
		<para>
The issue then, appears to be either the cisco switch or the cable
connecting it; there is nothing else left to test.  I did swap the NICs out
for eepros (but the problem still persists when stressing through the cisco
kit).  Safe to say, I'm very, very impressed by this!
		</para>
	</blockquote>
	</section>
	<section id="performance_testing_tools">
	<title>performance testing tools</title>
		<section id="polygraph" xreflabel="polygraph">
		<title>Web Polygraph</title>
		<para>
Dennis Kruyt, 9 Jan 2002
		</para>
		<blockquote>
I am looking for software for testing my lvs webservers with
persistant connection. With normal http benchmarking tools all request
come from one IP, but I want to simulate a few hundred connections from
different IPss with persistant connections.
		</blockquote>
		<para>
Joe Cooper <emphasis>joe (at) swelltech (dot) com</emphasis> 09 Jan 2002
		</para>
		<para>
<ulink url="http://www.web-polygraph.org">Web Polygraph</ulink>
is a benchmarking framework originally designed for web
proxies. It will generate thousands of IPs on the client box
if you request them.  It does not currently have a
method to test existing URLs, as far as I know (it provides its own
realserver(s) and content, so that data is two-sided).
It currently works very well for stress-testing an LVS balancer, but for
the realservers themselves it probably needs a pretty good amount of
coding.  The folks who developed it will add features for pretty good
rates, particularly if the new features fit in with their future plans.
It does have some unfortunate licensing restrictions, but is free to
get, use and modify for your own internal purposes.
		</para>
		</section>
		<section id="getmeter">
		<title>getmeter</title>
		<para>
Alexandre Cassen <emphasis>Alexandre (dot) Casseni (at) wanadoo (dot) fr</emphasis> 13 Jan 2003
(2008, Alexandre is now at <emphasis>Alexandre (dot) Cassen (at) free (dot) fr</emphasis>)
		</para>
		<para>
<ulink url="http://www.vergenet.net/~acassen/">getmeter</ulink>:
Simple tool for emulating a multi-threaded web browser. The
code works for a HTTP/1.1 webserver. The purpose of this tool is to
monitor webserver response time. It implements HTTP/1.1 GET
using a realtime multi-threaded design, dealing with an url pool to
perform global page reponse time (page and first level elements response
time). It
		</para>
		<orderedlist>
			<listitem>
connects to a webserver (HTTP or SSL),
			</listitem>
			<listitem>
creates 2 multi-threaded persistent connections to this webserver,
			</listitem>
			<listitem>
performs a GET HTTP/1.1 on the url specified,
			</listitem>
			<listitem>
parses the html content returned and creates an element pool
			</listitem>
			<listitem>
performs GET HTTP/1.1 on each element.
			</listitem>
			<listitem>
for each GET, mesure the response time.
			</listitem>
			<listitem>
print the global reponse time for the page requested.
			</listitem>
		</orderedlist>
		<para>
An extension can use MRTG or RRDTOOL to graph the output.
		</para>
		</section>
	</section>
	<section id="max_realservers">
	<title>Max number of realservers</title>
	<blockquote>
what is the maximum number of servers I
can have behind the LVS without any risk of failure?
	</blockquote>
	<para>
Horms <emphasis>horms (at) vergenet (dot) net</emphasis> 03 Jul 2001
	</para>
	<para>
LVS does not set artificial limits on the number of servers that you can
have. The real limitations are the number of packets you can get through
the box, the amount of memory you have to store connection information and
in the case of LVS-NAT the number of ports available for masquerading.
These limitations effect the number of concurrent connections you can
handle and your maximum through-put. This indirectly effects how many
servers you can have.
	</para>
	<para>
(also see the section on <link linkend="port_range">port range limitations</link>.)
	</para>
	</section>
	<section id="minimum_hardware">
	<title>FAQ: What is the minimum hardware requirements for a director</title>
	<para>
Enough for the machine to boot,<emphasis>i.e</emphasis> 386CPU, 8M memory, no hard disk,
10Mbps ethernet.
	</para>
	</section>
	<section id="FAQ:how_fast">
	<title>FAQ: How fast/big should my director be?</title>
	<para>
There isn't a simple answer.
	</para>
	<para>
The speed of the director is determined by the packet throughput from/to the
clients and not by the number of realservers.
From the mailing list, 3-500MHz UMP directors running 2.2.x
kernels with the ipvs patch can handle 100Mbps throughput.
We don't know what is needed for 1Gpbs throughput, but postings on the mailing
list show that top end UMP machines (eg 800MHz) can't handle it.
	</para>
	<para>
For the complicated answer, see the rest of this section.
	</para>
	<para>
Horms 12 Feb 2004
	</para>
	<para>
If you only want to use LVS to load balance 100Mb/s Ethernet
then any machine purchased in the last few years should easily be able to
do that. End of conversation :-)
	</para>
	<para>
If you want to go to 1Gb/s Ethernet then things get more
interesting. At that point here are the things to watch out for:
	</para>
	<itemizedlist>
		<listitem>
 Make sure your machines have a nice fast PCI bus.
   These days most machines seem to have 66Mhz/64bit or 100Mhz/64bit
   slots so you are fine. Back when 33Mhz/32bit was standard
   this was a bit more problematic.
		</listitem>
		<listitem>
Buy good NICs that have well maintaineddrivers.
		</listitem>
		<listitem>
Use UP not SMP. Unless you really need SMP on the machine
   for some reason, then the locking overhead is greater than
   the gain of an extra CPU when using LVS. This is particularly
   true when handling small connections, where the TCP handshake
   becomes significant. (That was on 2.4, not sure about 2.6, though
   I assume that it still holds)
		</listitem>
		<listitem>
CPU isn't really much of an issue. If you can purchase a CPU
   these days that is too slow to run LVS, even up to 1Gb/s then
   I would be very surprised. Certainly anything over a 1GHz PII should
   be fine.
		</listitem>
		<listitem>
			<para>
Memory. First understand that LVS has no internal limits
   on the number of connections it can handle, so you are only
   bound by your system resources. Here is the equation. For each
   connection you have in LVS's connection table you need about
   128bytes. Connections will stay in the table for 120 seconds after
   a connection is closed. So if your peak is, say 300 connections/s,
   then you need about 300*120*128=4608000bytes=4Mbytes of memory for
   the connection table, which I think you will agree isn't much.
   If you are using persistance then an extra entry (template) will
   be created per end-user (masked by the persistance netmask) and
   these will stay around for the duration of the persistance timeout.
   You can do the maths there. But the bottom line is that
   unless you are expecting an extremely high number of connections,
   then you don't need much memory.
   			</para>
			<para>
   Obviously you will need memory for other things like the OS,
   monitoring tools etc... But I think that 256Mb of RAM should
   be more than enough.
			</para>
		</listitem>
	</itemizedlist>
	</section>
	<section id="FAQ:smp_doesnt_help" xreflabel="SMP doesn't help">
	<title>SMP doesn't help, but 64 bit does</title>
	<para>
LVS is kernel code. In particular the network code is kernel code.
Kernel code is only SMP in 2.4.x kernels (user space SMP started in 2.0.x kernels).
To take advantage of SMP for LVS then you
must be running a 2.4.x kernel.
	</para>
	<para>
Horms (06 Apr 2003): SMP doesn't help for kernel code at high load -
	</para>
	<para>
Some things that you may want to consider are: Using a non SMP kernel -
there is actually more overhead in obtaining spinlocks than the
advantage you get from multile CPUs if you are only doing LVS. If you
only have one processor you should definately use a non-SMP kernel. You
may also want to consider using NAPI with the ethernet driver and if you
really want to use SMP then setting up affinity for the two NICS with
different processors is probably a good idea.
	</para>
	<para>
Dusten Splan <emphasis>Dusten (at) opinionsurveys (dot) com</emphasis> 12 May 2003
	</para>
	<blockquote>
		<para>
Is LVS smp aware?
I have dual 1.1Ghz processors, dual 1000BaseT Ethernet, with 2.4.20 compiled
as an smp and with the lvs sources compiled in, set up as a one
nic one network DR unit with wrr and it is working very nicely. It is
pushing about 50Mbps at peek and is only using about 15% on average of the
processing power when doing a vmstat. Now here's the question - when doing a
vmstat the numbers look like this
(this is a snapshot when we are doing about 30Mbps):
		</para>
<programlisting><![CDATA[
 0  0  0      0 474252  22496 352428    0    0     0     0 25769  3248  0 11 89
 0  0  0      0 474252  22496 352428    0    0     0     0 25816  3194  0 12 88
 0  0  0      0 474252  22496 352428    0    0     0     0 24526  2772  0 11 89
 0  0  0      0 474252  22496 352428    0    0     0     0 24714  2939  0  9 91
 0  0  0      0 474252  22496 352428    0    0     0     0 25404  3081  0  8 92
 0  0  0      0 474252  22496 352428    0    0     0     0 25238  2996  0 11 89
 0  0  0      0 474252  22496 352428    0    0     0     0 24872  2960  0 10 90
 0  0  0      0 474252  22496 352428    0    0     0     0 24760  2850  0  7 93
 0  0  0      0 474252  22496 352428    0    0     0     0 25341  2984  0 10 90
 0  0  0      0 474252  22496 352428    0    0     0     0 24689  2743  0  8 92
]]></programlisting>
		<para>
now if I look at top I get.
		</para>
<programlisting><![CDATA[
27 processes: 26 sleeping, 1 running, 0 zombie, 0 stopped
CPU0 states:   0.0% user  20.0% system    0.0% nice   0.0% iowait  80.0% idle
CPU1 states:   0.1% user   1.0% system    0.0% nice   0.0% iowait  98.4% idle
Mem:  1032948k av,  558912k used,  474036k free, 0k shrd, 22496k buff, 188192k active, 189740k inactive
Swap:  522104k av,       0k used,  522104k free, 352428k cached
]]></programlisting>
		<para>
When doing more traffic the load on cpu0 increases and nothing is happing on
cpu1.
My question is why am I not seeing this processor usage distributed over
both processors.  I know that on a Sun box the network card is stuck to a
single processor and will not use the other processors.
		</para>

		<para>
Here's a sample of what mpstat has
to say about the hole thing.
		</para>

<programlisting><![CDATA[
[root@www99 root]# mpstat -P ALL 1 10;
Linux 2.4.20 (www99)    05/14/2003

03:10:05 PM  CPU   %user   %nice %system   %idle    intr/s
03:10:06 PM  all    0.00    0.00   12.00   88.00  19841.00
03:10:06 PM    0    0.00    0.00   23.00   77.00  19748.00
03:10:06 PM    1    0.00    0.00    1.00   99.00    100.00
]]></programlisting>
	</blockquote>
	<para>
Horms
	</para>
	<para>
LVS really should utilise both CPUs.
As you note the 2.4 kernels are multithreaded. LVS should
take advantage of this. It definately bears further investigation.
	</para>
	<para>
The problem with performance
is that in multithreading the kernel a lot of spinlocks were introduced.
From the testing that I was involved in, its seems that the overhead
in obtaining these locks is greater than the advange of having
access to a second CPU. That is in the case of using the box only
as an LVS Linux Director. If you are doing lots of other things
as well then this may not be the case.
I would suggest that if you are building a machine that will
act primarily as an LVS ldirectord, then a non-SMP kernel should
give you the best performance.
	</para>
	<para>
This however, does not answer, and is not particularly relevant
to your problem. Sorry.
	</para>

	<para>
Wensong
	</para>
	<para>
The major LVS processing is run inside the softirqs in the kernel
2.4. The softirqs (even the same) can run parallely on the two CPUs or
more inside the kernel 2.4. So, the LVS in the kernel 2.4 should take
advantage of SMP. We spent a lot of efforts keeping the locking
granularity of LVS small too.
	</para>
	<para>
As for Dusten's problem, I am not sure why one CPU is 80% idle and the
other is always 100% idle. From the mpstat output, almost all the
interrupts go to the first CPU. Is it possible that 20% CPU cycles have
been spent handling interrupts at the first CPU?
	</para>
	<para>
Michael Brown <emphasis>michael_e_brown (at) dell (dot) com</emphasis> wrote on 26 Dec 2000
	</para>
	<blockquote>
		<para>
I've seen significant improvements using dual and quad processors
with 2.4. Under 2.2 there are improvements but not astonishing ones.
Things like 90&percnt; saturation of a Gig link using quad processors.
70&percnt; using dual processors and 55&percnt; using a single processor
under 2.4.0test.
		</para>
		<para>
I haven't had much of a chance to do a full comparison of 2.2 vs 2.4,
but most evidence points to &gt;100&percnt; improvement for network
intensive tasks.
		</para>
	</blockquote>
	<para>
only one CPU can be in the kernel with 2.2. Since LVS is
all kernel code, there is no benefit to LVS by using SMP with 2.2.x.
Kernel 2.[3-4] can use multiple CPUs. While standard (300MHz pentium)
directors can easily handle 100Mbps networks, they cannot handle
an LVS at Gbps speeds. Either SMP directors with 2.4.x kernels
or multiple directors (each with a separate VIP all pointing
to the same realservers) are needed.
	</para>
	<para>
Since LVS-NAT requires computation on the director (to rewrite the
packets) not needed for LVS-DR and LVS-Tun, SMP would
help throughput.
	</para>
	<para>
Joe
	</para>
	<blockquote>
		<para>
If you're using LVS-NAT then you'll need a machine that can handle the full
bandwidth of the expected connections. If this is T1, you won't need much
of a machine. If it's 100Mbps you'll need more (I can saturate 100Mbps
with a 75MHz machine). If you're running LVS-DR or LVS-Tun you'll need
less horse power. Since most LVS is I/O I would suspect that SMP won't
get you much. However if the director is doing other things too,
then SMP might be useful
		</para>
	</blockquote>
	<para>
Julian Anastasov <emphasis>uli (at) linux (dot) tu-varna (dot) acad (dot) bg</emphasis>
	</para>
	<para>
        Yep, LVS in 2.2 can't use both CPUs. This is not a LVS limitation.
It is already solved in the latest 2.3 kernels: softnet. If you are using
the director as realserver too, SMP is recommended.
	</para>
	<para>
Pat O'Rourke <emphasis>orourke (at) mclinux (dot) com</emphasis> 03 Jan 2000
	</para>
	<blockquote>
		<para>
 In our
<ulink url="http://www.linuxvirtualserver.org/performance/lvs.ps.gz">performance tests</ulink>
 we've been seeing
 an SMP director perform significantly worse than a uni-processor one
 (using the same hardware - only difference was booting an SMP kernel
 or uni-processor).
		</para>
		<para>
 We've been using a 2.2.17 kernel with the 1.0.2 LVS patch and bumped
 the send / recv socket buffer memory to 1mb for both the uni-processor
 and SMP scenarios.  The director is an Intel based system with 550
 mhz Pentium 3's.
		</para>
		<para>
In some tests I've done with FTP, I have seen
 *significant* improvements using dual and quad processors using 2.4. Under
 2.2, there are improvements, but not astonishing ones.
		</para>
		<para>
 Things like 90% saturation of a Gig link using quad processors, 70% using
 dual processors and 55% using a single processor under 2.4.0test. Really
 amazing improvements.
		</para>
		<para>
Michael E Brown <emphasis>michael_e_brown (at) dell (dot) com</emphasis> 26 Dec 2000
		</para>
		<blockquote>
			<para>
What are the percentage differences on each processor configuration
 between 2.2 and 2.4?  How does a 2.2 system compare to a 2.4 system on the
 same hardware?
			</para>
		</blockquote>
		<para>
 I haven't had much of a chance to do a full comparison of 2.2 vs 2.4, but
 most of the evidence on tests that I have run points to a > 100%
 improvement for *network intensive* tasks.
		</para>
		<para>
 In our experiments we've been seeing
 an SMP director perform significantly worse than a uni-processor one
 (using the same hardware - only difference was booting an SMP kernel
 or uni-processor).
		</para>
	</blockquote>
	<para>
Kees Hoekzema <emphasis>kees (at) tweakers (dot) net</emphasis> 10 Jun 2008 
	</para>
	<para>
Yes it is true that for LVS it does not really matter, but LVS is not always
the only thing running on a system, in my case I also let it run a DNS
server and it has a lot of iptables rules. At the moment we are doing around
60 mbit/s and my stats are:
	</para>
<programlisting><![CDATA[
$ mpstat -P ALL 1 10 
Average:     CPU   %user   %nice    %sys %iowait    %irq   %soft  %steal %idle    intr/s
Average:     all    0.23    0.00    0.69    0.13    0.48    2.93    0.00 95.54  11772.75
Average:       0    0.10    0.00    0.30    0.40    0.00    0.00    0.00 99.20   1000.30
Average:       1    0.30    0.00    1.01    0.10    0.00    0.00    0.00 98.59      0.00
Average:       2    0.10    0.00    0.41    0.00    0.62    1.24    0.00 97.62   2941.92
Average:       3    0.31    0.00    1.04    0.00    1.35   10.77    0.00 86.54   7830.64
]]></programlisting>
	<para>
(a quadcore xeon was just a little bit more expensive than a singlecore cpu
at the time we bought the servers).
	</para>
	<para>
Also you can have different cpu's handle the interrupts:
	</para>
$ cat /proc/interrupts
<programlisting><![CDATA[
            CPU0       CPU1       CPU2       CPU3
1274:        220    4719154 2977300793          0   PCI-MSI-edge      eth1
1275:        244    3649053          0 1213052367   PCI-MSI-edge      eth0
]]></programlisting>
	<para>
With the speed of the current cpu's however I think it does not really
matter if you have a single or multi-core cpu, they all can handle gbit/s of
	data.
	</para>
	<para>
64 bit is helpful if you don't want stuff like /proc/net/dev overflowing (4
gbyte/5 minutes=16 Mpbs of traffic, so if you get above that, and you
try to use those statistics, the counter may overflow before you read it
again)
	</para>
	</section>
	<section id="squid_hints">
	<title>Performance Hints from the Squid people</title>
	<para>
There is information on the Squid site about tuning a squid box for performance.
I've lost the original URL, but here's one about
<ulink url="http://www.squid-cache.org/Doc/FAQ/FAQ-11.html#ss11.4">file descriptors</ulink>
and another
(link dead Mar 2004 http://www.devshed.com/Server_Side/Administration/SQUID/) by Joe Cooper
(occasional contributor to the LVS mailing list) that also addresses the FD_SETSIZE
problem (<emphasis>i.e.</emphasis> not enough filedescriptors).
The squid performance information should apply to an LVS director.
For a 100Mbps network, current PC hardware on a director can
saturate a network without these optimizations.
However current single processor hardware cannot saturate 1Gpbs network,
and optimizations are helpful.
The squid information is as good a place to start as any.
	</para>
	<para>
Here's some more info
	</para>
	<para>
 Michael E Brown <emphasis>michael_e_brown (at) dell (dot) com</emphasis> 29 Dec 2000
	</para>
	<blockquote>
		<para>
 How much memory do you have? How fast of network links? There are some
 kernel parameters you can tune in 2.2 that help out, and there are even
 more in 2.4. From the top of my head,
		</para>
		<itemizedlist>
			<listitem>
<filename>/proc/sys/net/core/*mem*</filename> - tune to your memory spec.
The defaults are
 not optimized for network throughput on large memory machines.
			</listitem>
			<listitem>
2.4 only /proc/sys/net/ipv4/*mem*
			</listitem>
			<listitem>
For fast links, with multiple adapters (Two gig links, dual CPU) 2.4
 has NIC-->CPU IRQ binding. That can really help also on heavily loaded
 links.
			</listitem>
			<listitem>
 For 2.2 I think I would go into your BIOS or RCU (if you have one) and
 hardcode all NIC adapters (Assuming identical/multiple NICS) to the same
 IRQ. You get some gain due to cache affinity, and one interrupt may
 service IRQs from multiple adapters in one go, on heavily loaded links.
			</listitem>
			<listitem>
 Think "Interrupt coalescing". Figure out how your adapter driver turns
 this on and do it. If you are using Intel Gig links, I can send you some
 info on how to tune it. Acenic Gig adapters are pretty well documented.
			</listitem>
		</itemizedlist>
		<para>
 For a really good tuning guide, go to spec.org, and look up the latest TUX
 benchmark results posted by Dell. Each benchmark posting has a full list
 of kernel parameters that were tuned. This will give you a good starting
 point from which to examine your configuration.
		</para>
		<para>
 The other obvious tuning recommendation: Pick a stable 2.4 kernel and use
 that. Any (untuned) 2.4 kernel will blow away 2.2 in a multiprocessor
 configuration. If I remember correctly 2.4.0test 10-11 are pretty stable.
		</para>
	</blockquote>
	<para>
Some information is on
	</para>
	<para>
http://www.LinuxVirtualServer.org/lmb/LVS-Announce.html
	</para>
	<para>
only one CPU can be in the kernel with 2.2. Since LVS is
all kernel code, there is no benefit to LVS by using SMP with 2.2.x.
Kernel 2.[3-4] can use multiple CPUs. While standard (300MHz pentium)
directors can easily handle 100Mbps networks, they cannot handle
an LVS at Gbps speeds. Either SMP directors with 2.4.x kernels
or multiple directors (each with a separate VIP all pointing
to the same realservers) are needed.
	</para>
	<para>
Since LVS-NAT requires computation on the director (to rewrite the
packets which is not needed for LVS-DR and LVS-Tun), SMP would
help throughput.
	</para>
	<para>
Joe
	</para>
	<blockquote>
		<para>
 If you're using LVS-NAT then you'll need a machine that can handle the full
 bandwidth of the expected connections. If this is T1, you won't need much
 of a machine. If it's 100Mbps you'll need more (I can saturate 100Mbps
 with a 75MHz machine). If you're running LVS-DR or LVS-Tun you'll need
 less horse power. Since most LVS is I/O I would suspect that SMP won't
 get you much. However if the director is doing other things too,
 then SMP might be useful
		</para>
	</blockquote>
	<para>
Julian Anastasov <emphasis>uli (at) linux (dot) tu-varna (dot) acad (dot) bg</emphasis>
	</para>
	<para>
        Yep, LVS in 2.2 can't use both CPUs. This is not a LVS limitation.
It is already solved in the latest 2.3 kernels: softnet. If you are using
the director as realserver too, SMP is recommended.
	</para>
	<para>
Pat O'Rourke <emphasis>orourke (at) mclinux (dot) com</emphasis> 03 Jan 2000
	</para>
	<blockquote>
		<para>
 In our
<ulink url="http://www.linuxvirtualserver.org/performance/lvs.ps.gz">performance tests</ulink>
 we've been seeing
 an SMP director perform significantly worse than a uni-processor one
 (using the same hardware - only difference was booting an SMP kernel
 or uni-processor).
		</para>
		<para>
 We've been using a 2.2.17 kernel with the 1.0.2 LVS patch and bumped
 the send / recv socket buffer memory to 1mb for both the uni-processor
 and SMP scenarios.  The director is an Intel based system with 550
 mhz Pentium 3's.
		</para>
		<para>
In some tests I've done with FTP, I have seen
 *significant* improvements using dual and quad processors using 2.4. Under
 2.2, there are improvements, but not astonishing ones.
		</para>
		<para>
 Things like 90% saturation of a Gig link using quad processors, 70% using
 dual processors and 55% using a single processor under 2.4.0test. Really
 amazing improvements.
		</para>
		<para>
Michael E Brown <emphasis>michael_e_brown (at) dell (dot) com</emphasis> 26 Dec 2000
		</para>
		<blockquote>
What are the percentage differences on each processor configuration
 between 2.2 and 2.4?  How does a 2.2 system compare to a 2.4 system on the
 same hardware?
		</blockquote>
		<para>
 I haven't had much of a chance to do a full comparison of 2.2 vs 2.4, but
 most of the evidence on tests that I have run points to a > 100%
 improvement for *network intensive* tasks.
		</para><para>
 In our experiments we've been seeing
 an SMP director perform significantly worse than a uni-processor one
 (using the same hardware - only difference was booting an SMP kernel
 or uni-processor).
		</para>
	</blockquote>
	<para>
Joe: here's a posting from the Boewulf mailing list, about increasing
the number of file descriptors/sockets. It is similar to the postings
on the squid webpages (mentioned above).
	</para>
	<para>
Yudong Tian <emphasis>yudong (at) hsb (dot) gsfc (dot) nasa (dot) gov</emphasis>
30 Sep 2003
	</para>
	<para>
The number of sockets a process can open is limited by
the number of file descriptors (fds). Type "ulimit -n"
under bash to get this number, which usually 1024 by
default.
	</para>
	<para>
You can increase this number if you wish. Google
"increase Linux file descriptors" you will find many examples,
like this one:
http://support.zeus.com/faq/zws/v4/entries/os/linuxfd.html
	</para>
	<para>
If you want to be really sure, you can compile and run the
following c program to get the number, which is the output
plus 3 (stdout, stdin and stderr):
	</para>

<programlisting><![CDATA[
/*
# test how many fd you have
$Id$
*/

int main(int argc, char *argv[])
{

 int i = 0;

 while( tmpfile()){ i++; }
 printf("Your free fds: %d\n", i);

}
/*** end of program ***/
]]></programlisting>

	<para>
If you are running a TCP server and want to test how many clients
that server can support, you can run the following perl program
to test:
	</para>
<programlisting><![CDATA[
#!/usr/bin/perl
# Test the max number of tcp connections a server can support
# $Id: testMaxCon.pl,v 1.1 2003/06/23 19:10:41 yudong Exp yudong $
# usage: testMaxCon.pl IP port

use IO::Socket::INET;

@ARGV == 2 or die "Usage: testMaxCon.pl svr_ip svr_port\n";

my ($ip, $port) = @ARGV;

my $i = 0;

do {
  $i++;
  $socket[$i] = IO::Socket::INET->new(PeerAddr => $ip,
                                      PeerPort => $port,
                                      Proto => "tcp",
                                      Timeout => 6,
                                      Type => SOCK_STREAM);
} while ($socket[$i]);

print "Max TCP connections supported for this client: ", $i-1, "\n";
## end of program
]]></programlisting>
	<para>
  Of course for this test you have to make sure you have more fds
to use than the server.
	</para>
	<para>
Brian Barrett <emphasis>brbarret (at) osl (dot) iu (dot) edu</emphasis>
02 Oct 2003
	</para>
	<para>
On linux, there is a default per-process limit of 1024 (hard and soft
limits) file descriptors.  You can see the per-process limit by running
limit (csh/tcsh) or ulimit -n (sh).  There is also a limit on the total
number of file descriptors that the system can have open, which you can
find by looking at <filename>/proc/sys/fs/file-max</filename>.
On my home machine, the max
file descriptor count is around 104K (the default), so that probably
isn't a worry for you.
	</para>
	<para>
There is the concept of a soft and hard limit for file descriptors.
The soft limit is the "default limit", which is generally set to
somewhere above the needs of most applications.  The soft limit can be
increased by a normal user application up to the hard limit.  As I said
before, the defaults for the soft and hard limits on modern linux
machines are the same, at 1024.  You can adjust either limit by adding
the appropriate lines in <filename>/etc/security/limits.conf</filename>
(at least, that
seems to be the file on both Red Hat and Debian).  In theory, you could
set the limit up to file-max, but that probably isn't a good idea.  You
really don't want to run your system out of file descriptors.
	</para>
	<para>
There is one other concern you might want to think about.  If you ever
use any of the created file descriptors in a call to select(), you have
to ensure all the select()ed file descriptors fit in an FD_SET.  On
Linux, the size of an FD_SET is hard-coded at 1024 (on most of the
BSDs, Solaris, and Mac OS X, it can be altered at application compile
time).  So you may not want to ever set the soft limit above 1024.
Some applications may expect that any file descriptor that was
successfully created can be put into an FD_SET.  If this isn't the
case, well, life could get interesting.
	</para>
	<para>
AlberT <emphasis>AlberT (at) SuperAlberT (dot) it</emphasis>
02 Oct 2003
	</para>
	<para>
from man setrlimit:
	</para>
	<blockquote>
		<para>
getrlimit  and  setrlimit  get  and set resource limits respectively.  Each
resource has an
       associated soft and hard limit, as defined by the rlimit structure (the
rlim  argument  to
       both getrlimit() and setrlimit()):
		</para>

<programlisting><![CDATA[
            struct rlimit {
                rlim_t rlim_cur;   /* Soft limit */
                rlim_t rlim_max;   /* Hard limit (ceiling
                                      for rlim_cur) */
            };
]]></programlisting>
		<para>
       The  soft  limit is the value that the kernel enforces for the
corresponding resource.  The
       hard limit acts as a ceiling for the soft limit: an unprivileged
process may only  set  its
       soft  limit  to  a value in the range from 0 up to the hard limit, and
(irreversibly) lower
       its hard limit.  A privileged process may make arbitrary changes to
either limit value.
		</para>
		<para>
       The value RLIM_INFINITY denotes no limit on a resource (both in the
structure  returned  by
       getrlimit() and in the structure passed to setrlimit()).
		</para>
		<para>
 RLIMIT_NOFILE
              Specifies a value one greater than the maximum file descriptor
number  that  can  be
              opened  by  this  process.   Attempts  (open(), pipe(), dup(),
etc.)  to exceed this
              limit yield the error EMFILE.
		</para>
	</blockquote>
	</section>
	<section id="conntrack_filling_tables">
	<title>realservers filling conntrack tables (LVS-DR)</title>
	<para>
Wiboon Warasittichai <emphasis>wiboon (dot) w (at) psu (dot) ac (dot) th</emphasis> 08 Jun 2007 
	</para>
	<para>
I set up 2 directors IP 192.168.96.11 (active/standby) with 4 real 
servers (squid) for a week ago.
I noticed in dmesg output in the realservers 
	</para>
<programlisting><![CDATA[
ip_conntrack: table full, dropping packet.
ip_conntrack: table full, dropping packet.
]]></programlisting>
	<para>
So I restart iptables.
Then, ip_conntrack goes below 65536 max.
	</para>
<programlisting><![CDATA[
[root@proxy5-in ~]# cat /proc/slabinfo | grep conn
ip_conntrack_expect      0      0     92   42    1 : tunables  120   60 8 : slabdata      0      0      0
ip_conntrack         20723  20723    232   17    1 : tunables  120   60 8 : slabdata   1219   1219    120
]]></programlisting>
	<para>
But within a day, it reached max ip_conntrack again.
I checked with <command>cat /proc/net/ip_conntrack | grep UNREPLIED</command>
which showed many lines with ESTABLISHED and UNREPLIED.
	</para>
<programlisting><![CDATA[
tcp      6 419803 ESTABLISHED src=192.168.96.11 dst=192.168.192.7 
sport=8080 dport=56055 packets=1 bytes=601 [UNREPLIED] src=192.168.192.7 
dst=192.168.96.11 sport=56055 dport=8080 packets=0 bytes=0 mark=0 use=1
]]></programlisting>
	<para>
I think it's because the squid realservers directly send answer back 
from internet to client and then client send FIN to director, isn't it?
Do IPVS/DR have any configurations to get rid of these ip_conntrack?
Do I need to unload module ip_conntrack on all squid boxes?
	</para>
	<para>
Graeme Fowler <emphasis>graeme (at) graemef (dot) net</emphasis> 08 Jun 2007
	</para>
	<para>
Ideally you have to unload the module. 
Why do you have the conntrack module loaded in the first
place?
An alternative method, if you absolutely must keep the conntrack rules
in place, is to explicitly use the NOTRACK target on packets destined
for the Squid service.
On the realserver, as an example:
	</para>
<programlisting><![CDATA[
iptables -t raw -I PREROUTING -p tcp --dport 3128 -j NOTRACK
iptables -I INPUT -p tcp -m tcp --dport 3128 -j ACCEPT
]]></programlisting>
	<para>
The first line will remove tracking from packets destined for TCP port
3128 on the realserver.
	</para>
	</section>
	<section id="conntrack">
	<title>Conntrack, effect on throughput</title>
	<note>
	<para>
I can't figure out if this should belong in the performance or the netfilter
section - any suggestions?
	</para>
	</note>
	<para>
Conntrack is part of netfilter. It keeps track of connections and
knows the relationship of a packet to existing connections.
This enables filtering to reject or allow packets <emphasis>e.g.</emphasis>
a packet appearing to be part of a passive ftp connection
is only valid after a call to setup a passive ftp connection.
For a tutorial on conntrack, see the links inside
<ulink url="http://www.sns.ias.edu/~jns/wp/2006/01/24/iptables-how-does-it-work/">
Iptables - How Does It Work?</ulink>
(http://www.sns.ias.edu/~jns/wp/2006/01/24/iptables-how-does-it-work/)
by James Stephens.
	</para>
	<blockquote>
	<para>
Rodger Erickson <emphasis>rerickson (at) aventail (dot) com</emphasis> 17 Dec 2001
	</para>
	<para>
Does anyone have any comments they can make on the effect of
conntrack on LVS performance?
The LVS device I'm using also has to do some DNAT and SNAT, which
require conntrack to be enabled.
	</para>
	</blockquote>
	<para>
Julian:
We need to port the 2.2 masquerade to 2.4 :)
LVS reused some code from 2.2 but much of it is removed and
I'm not sure it can be added back easily. It would be better to redesign
some parts of Netfilter for 2.5 or 2.7 :) You can use the ipchains
compat module. But may be it does not work for FTP and is broken
at some places.
	</para>
	<para>
The best approach might be to test the slowdown when using both LVS
and conntracking and if it's not fast enough, buy faster hardware. It will take
less time :) You can test the slowdown with some app or even with
testlvs.
	</para>
	<blockquote>
	<para>
patrick edwards
	</para>
	<para>
My lvs works with no problem.  However with in a matter
of an hour or two my bandwidth drops to virtually nothing and the CPU load
goes ballistic. I have a 100Mbit internal network, but at times i'm lucky
to see 50Kps.
	</para>
	</blockquote>
	<para>
Christian Bronk <emphasis>chris (at) isg (dot) de</emphasis> 15 Jan 2002:
For our 2.4 kernel test servers, it turned out that ipchains
under kernel 2.4 does full connection-tracking and makes the
system slow. Try to use iptables or the arp-patch instead.
	</para>

	<blockquote>
	<para>
Fabrice <emphasis>fabrice (at) urbanet (dot) ch</emphasis> 17 Dec 2001
	</para>
	<para>
When I ran testlvs, with conntrack enabled
on the client machine (the one that runs testlvs), I had a mean of
about 2000 SYN/s. When I removed thoses modules (there are
many conntracks) I reached 54'000 SYN/s!
	</para>
	</blockquote>
	<para>
Julian Anastasov <emphasis>ja (at) ssi (dot) bg</emphasis> 22 Dec 2001:
I performed these tests with 40K SYN/s incoming
(director near its limits),
LVS-NAT, 2.4.16, noapic, SYN flood from testlvs with -srcnum 32000
to 1 realserver.
	</para>
	<itemizedlist>
		<listitem>only IPVS 0.9.8
able to send the 40K/sec (same as incoming), 3000 context switches/sec

		</listitem>
		<listitem>
		<para>
after modprobe ip_conntrack hashsize=131072
		</para>
		<para>
10-15% performance drop, 500 context switches/sec
		</para>
		</listitem>
		<listitem>
after modprobe iptable_nat (no NAT rules)
5% performance drop, same number of context switches/sec

		</listitem>
		<listitem>
Additional test: -j DNAT instead of IPVS
<programlisting><![CDATA[
# modprobe ip_conntrack hashsize=131072
# modprobe iptable_nat
# cat /proc/sys/net/ipv4/ip_conntrack_max
1048576
]]></programlisting>


Tragedy: 1000P/s out, director is overloaded.
		</listitem>
	</itemizedlist>
	<para>
I looked into the ip_conntrack hashing, it is not perfect
for incoming traffic between two IPs, but note that testlvs uses
different IPs, so after little tuning, it seems that the DNAT's
problem is not the bad hash function.
Maybe I'm missing some NF tuning parameters.
	</para>

	<blockquote>
	Andy Levine:

Is it absolutely necessary to have IP Connection tracking turned on in
the kernel if we are using LVR_DR?  We are experiencing performance hits
with the connection tracking code (especially on SMP boxes) and would
like to take it out of our kernel.
	</blockquote>

	<para>Wensong:25 Dec 2002:
if you have performance problem you can remove it. LVS uses its own
simple and fast connection tracking for performance reasons, instead of
using netfilter connection tracking. So, it will not affect LVS, if
netfilter conntrack modules are not loaded.
LVS/NAT should work too without the conntrack modules.
	</para>
	</section>
	<section id="pre-emptible_kernels">
	<title>Don't use the preemptible/preemptable/preemptive kernels</title>
        <note>
the different versions of the word in the title is for searching.
	</note>
	<para>
Brian Jackson
	</para>
	<blockquote>
Just as a little experiment, since I have enjoyed my preemptible/low
latency patches, I decided to test my lvs cluster with the patches. The
results were interesting.
	</blockquote>
	<para>
Roberto Nibali <emphasis>ratz (at) tac (dot) ch</emphasis> 10 Sep 2002
	</para>
	<para>
Preemptible kernels don't buy you anything on a server, it's simply speaking for
a desktop machine where you'd like to listen to mp3 (non-skipping of course) and
compile the kernel. Low latency for tcpip as needed for LVS
is incompatible with the concept of preemptible kernels,
in that of the network stack runs in softirqs and get's worked around by
the kernel scheduler. If your driver generates a lot of IRQs for RX buffer
dehooking, the scheduler must be invoked to get those packets pushed in the TCP
stack or you loose packets. As long as you don't run X and some number crunching
software on the realservers, preemtible kernels hurt TCP/IP stack performance IMHO.
	</para>
	</section>
	<section id="9.6G">
	<title>9.6Gbps served using LVS-DR with gridftp</title>
	<para>
Horms 24 Nov 2005
	</para>
	<para>
This information comes from Dan Yocum, slightly reformated and forwarded
with permission.
Note that while the cluster was pushing 9.6Gbps, the linux director was
doing a negilgable ammount of work, which seems to indicate that LVS
could push a great deal more traffic given sufficient real-servers and
end-users.
	</para>
	<blockquote>
		<para>
On Mon, Nov 21, 2005 at 01:51:27PM -0600, Dan Yocum wrote:
		</para>
		<para>
Just a quick update on the LVS-DR server I used for for our bandwidth 
challenge last week at SuperComputing:  The director saw an increase of 
around 120Kbps when we ran our bandwidth challenge tests.  At times the 
aggregate bandwidth out of the 21 real servers was around 9.6Gbps, so 
the amount of traffic on the director was negligible.  There were 41 
clients grabbing the data from the servers, each machine ran a gridftp 
client with 16 parallel streams.  Packet size was standard (1500), so no 
jumbo frames.
		</para>
		<para>
The URL for the mrtg graphs are here:
http://m-s-fcc-mrtg.fnal.gov/~netadmin/mrtg/mrtg-rrd.cgi/s-s-fcc1-server/s-s-fcc1-server_3_3.html
		</para>
		<para>
The test occurred on Wed of last week in the last half of the day.
		</para>
	</blockquote>
	<para>
Sure, no problem.  One of the BWC participants put a page up here if 
you're interested in the details of the other participants:
http://www-iepm.slac.stanford.edu/monitoring/bulk/sc2005/hiperf.html
	</para>
	</section>
</section>
<section id="LVS-HOWTO.monitoring_lvs">
<title>LVS: Monitoring</title>
	<section id="load_level">
	<title>CPU usage/load level on the director?</title>
	<para>
Michael McConnell:
	</para>
	<blockquote>
Top doesn't display CPU usage of ipchains or ipvsadm.
vmstat doesn't display CPU usage of ipchains or ipvsadm.
	</blockquote>
	<para>
Joe
	</para>
	<blockquote>
<command>ipchains</command> and <command>ipvsadm</command>
are user tools that configure the kernel.
After you've run them, they go away and the kernel does it's new
thing (which you'll see in "system").
Unfortunately for some reason
that no-one has explained to me "top/system" doesn't see everything.
I can have a LVS-DR director which is running 50Mbps on a 100Mpbs link
and the load average doesn't get above 0.03 and system to be
negligable. I would expect it to be higher.
	</blockquote>
	<para>
Julian 10 Sep 2001
	</para>
	<para>
	Yes, the column is named "%CPU", i.e. the CPU spend for
one process related to all processes. As for the load average, it is
based on the length (number of processes except the current one) of
the queue with all processes in running state. As we know, LVS does
not interract with any processes except the ipvsadm. So, the normal
mode is the LVS box just to forward packets without spending any CPU
cycles for processes. This is the reason we want to see load average 0.00
	</para>
	<para>
	OTOH, vmstat reads /proc/stat and there are the counters
for all CPU times. Considering the current value for jiffies (the
kernel tick counter) the user apps can see the system, the user and
the idle CPU time. LVS is somewhere in the system time. For more
accurate measurement for the CPU cycles in the kernel there are some
kernel patches/tools that are exactly for this job - to see what time
takes the CPU in some kernel functions.
	</para>
	</section>
	<section id="monitoring_ipvsadm">
	<title>LVS throughput at the director with ipvsadm</title>
	<para>
The number of active/inactive connections are available from
the output of <command>ipvsadm</command>.
	</para>
	<para>
Julian 22 May 2001
	</para>
	<para>
Conns is a counter and is incremented when a new connection is created.
It is <emphasis>not</emphasis> incremented when a client re-uses a port to make a new connection
(Joe, - the default with Linux).
	</para>
<programlisting><![CDATA[
director:/etc/lvs# ipvsadm
IP Virtual Server version 0.2.12 (size=16384)
Prot LocalAddress:Port Scheduler Flags
  -> RemoteAddress:Port             Forward Weight ActiveConn InActConn
TCP  lvs2.mack.net:0 rr persistent 360
  -> RS2.mack.net:0                 Route   1      0          0
  -> RS1.mack.net:0                 Route   1      0          0
TCP  lvs2.mack.net:telnet rr
  -> RS2.mack.net:telnet            Route   1      0          0
  -> RS1.mack.net:telnet            Route   1      0          0
]]></programlisting>
	<para>
You can monitor connections with 
<link linkend="snmp">snmp</link>.
	</para>
	
	<para>
Dennis Kruyt <emphasis>d (dot) kruyt (at) zx (dot) nl</emphasis> 30 Jun 2004
	</para>
	<blockquote>
I use <ulink url="http://anakin.swiss-support.net/~romeo/lvs-snmp/">lvs-snmp</ulink>
(http://anakin.swiss-support.net/~romeo/lvs-snmp/)
and <ulink url="http://www.raxnet.net/products/cacti/">cacti</ulink>
to graph the connections.
	</blockquote>
	<para>
AJ Lemke 
	</para>
	<blockquote>
I am running a 2 node lvs-cluster and was wonder if the list could recommend
a traffic monitoring program.
My LVS is the frontend for a reverse proxy cache and I would like to know
the traffic that each VIP is handling.
I need to know the data rates on a per ip basis.  I use mrtg at the switch
level but I need to have more granularity, hence the need for per IP basis. 
	</blockquote>
	<para>
Kjetil Torgrim Homme <emphasis>kjetilho (at) ifi (dot) uio (dot) no</emphasis>
11 Jul 2004
	</para>
	<para>
<ulink url="http://www.linpro.no/projects/munin/">munin</ulink>
(http://www.linpro.no/projects/munin/)
has a plugin for this.  
you can get the numbers you need with ipvsadm
	</para>
<programlisting><![CDATA[
# ipvsadm -L -t smtp:smtp --stats
Prot LocalAddress:Port               Conns   InPkts  OutPkts  InBytes OutBytes
  -> RemoteAddress:Port
TCP  smtp.uio.no:smtp              1508879 38457326        0   10461M        0
  -> mail-mx6.uio.no:smtp           374117  9490846        0    2664M        0
  -> mail-mx3.uio.no:smtp           377646  9961956        0    2543M        0
  -> mail-mx2.uio.no:smtp           378502  9288837        0    2707M        0
  -> mail-mx1.uio.no:smtp           378614  9715687        0    2546M        0
# ipvsadm -L -t smtp:smtp --rate
Prot LocalAddress:Port                 CPS    InPPS   OutPPS    InBPS   OutBPS
  -> RemoteAddress:Port
TCP  smtp.uio.no:smtp                    7       85        0    20480        0
  -> mail-mx6.uio.no:smtp                1       17        0     1126        0
  -> mail-mx3.uio.no:smtp                1       17        0     2023        0
  -> mail-mx2.uio.no:smtp                2       26        0     6681        0
  -> mail-mx1.uio.no:smtp                2       25        0    10650        0
]]></programlisting>
	</section>
	<section id="monitoring_proc">
	<title>Monitoring: LVS director throughput statistics from the /proc system (originally /proc/net/ip_vs_stats)</title>
	<para>
Cyril Bouthors:
	</para>
	<blockquote>
Where can I get the info originally in /proc/net/ip_vs_stats and removed since 0.9.4?
	</blockquote>
	<para>
Wensong Zhang <emphasis>wensong (at) gnuchina (dot) org</emphasis> 20 Nov 2001
	</para>
	<para>
for global stats <filename>/proc/net/ip_vs_stats</filename>
	</para>
	<para>
You can get per-service statistics by
	</para>
<programlisting><![CDATA[
ipvsadm -Ln --stats -t|u|f service-address
]]></programlisting>
	<para>
If you want to program to get statistics info, use libipvs.
Here's the writeup that went with the original code.
	</para>
	<blockquote>
		<para>
Packet throughput (in 64-bit integers) is in /proc/net/ip_vs_stats or
/proc/net/ip_masq/vs_stats. The counters are not resetable, you have to keep
the previous reading and substract. Output is in hexadecimal.
		</para>
<programlisting><![CDATA[
kernel 2.4:#cat /proc/net/ip_vs_stats
kernel 2.2:#cat /proc/net/ip_masq/vs_stats
]]></programlisting>
		<para>
Here's the statistics
		</para>
<programlisting><![CDATA[
director:# more /proc/net/ip_vs_stats
TotalConns   InPkts  OutPkts          InBytes         OutBytes
      98F9 13945999 13609E49        613AD3B2F       4F90FE6F9E

Virtual Service
Pro VirtService      Conns   InPkts  OutPkts          InBytes         OutBytes
TCP C0A8026E:0000        4       12        0        00000043B        000000000
TCP C0A8026E:0017        7      3A9        0        00000C3A5        000000000
Real Service
Pro VirtService   RealService      Conns   InPkts  OutPkts          InBytes         OutBytes
TCP C0A8026E:0000 C0A8010C:0000        4       14        0        0000004B4        000000000
TCP C0A8026E:0000 C0A8010B:0000        1        3        0        0000000B4        000000000
TCP C0A8026E:0017 C0A8010C:0017        4       A2        0        00000232A        000000000
TCP C0A8026E:0017 C0A8010B:0017        4      32A        0        00000A827        000000000
]]></programlisting>
		</blockquote>
	<para>
Joe
	</para>
	<blockquote>
Can I zero out these counters if I want to get rates,
or should I store the last count?
	</blockquote>
	<para>
Ratz, May 2001
	</para>
	<para>
There was a recent (2 months ago) talk about zeroing in-kernel counters
and I'm not so sure if all the kernel hacker gurus agreed but:
	</para>
	<para>
<emphasis>You must not zero a counter in the kernel!</emphasis>
	</para>
	<para>
I didn't really understand the arguments against or pro zeroing counters
so I'm not a big help here, but if others agree we certainly can add this
feature. It would be <command>ipvsadm</command> -Z as an analogy to ip{chains|tables}. BTW,
we are proud of haveing 64-bit counters in the kernel :)
	</para>
	<para>
Storing ... there are different approaches to this (complexity order):
	</para>
	<itemizedlist>
		<listitem>
Use a script that extracts the info and writes it flat to a file
		</listitem>
		<listitem>
		<para>
Use MRTG or rrdtool since I reckon you wanted to use the stats to
generate some graphics anyway.
These tools handle the problem for you.
		</para>
		<para>
MRTG requires SNMP, but you can have a slightly modified snmpd.conf
and execute a script that parses /proc/net/ip_masq/vs_stats and writes it
into a file. The advantage of this over the first one is, that you can write
the current number into one file and mrtg will know how to draw the graph.
		</para>
		<para>
I give you an example:
		</para>
		<para>
We have a customer named plx. Now he has only one service and 2 realserver.
We extended the snmpd.conf with following lines:
		</para>
<programlisting><![CDATA[
exec lbsessions /bin/sh /opt/tac/snmp/lbsessions
exec lbsessions.plx.total /bin/sh /opt/tac/snmp/lbsessions.plx.total
exec lbsessions.plx.web-web1 /bin/sh /opt/tac/snmp/lbsessions.plx.web-web1
exec lbsessions.plx.web-web2 /bin/sh /opt/tac/snmp/lbsessions.plx.web-web2
]]></programlisting>
		<para>
The scripts are awk scripts that get the information accordingly to
the service or the realserver. You can then do a table walk of the OID
1.3.6.1.4.1.2021.8 to see what your values are:
		</para>
<programlisting><![CDATA[
snmpwalk $IP $COMMUNITY .1.3.6.1.4.1.2021.8
]]></programlisting>
		<para>
Example output if everything is ok:
		</para>
<programlisting><![CDATA[
enterprises.ucdavis.extTable.extEntry.extNames.1 = lbsessions
enterprises.ucdavis.extTable.extEntry.extNames.2 = lbsessions.plx.total
enterprises.ucdavis.extTable.extEntry.extNames.3 = lbsessions.plx.web-web1
enterprises.ucdavis.extTable.extEntry.extNames.4 = lbsessions.plx.web-web2
enterprises.ucdavis.extTable.extEntry.extCommand.1 = /bin/sh /opt/tac/snmp/lbsessions
enterprises.ucdavis.extTable.extEntry.extCommand.2 = /bin/sh /opt/tac/snmp/lbsessions.plx.total
enterprises.ucdavis.extTable.extEntry.extCommand.3 = /bin/sh /opt/tac/snmp/lbsessions.plx.web-web1
enterprises.ucdavis.extTable.extEntry.extCommand.4 = /bin/sh /opt/tac/snmp/lbsessions.plx.web-web2
enterprises.ucdavis.extTable.extEntry.extResult.1 = 0
enterprises.ucdavis.extTable.extEntry.extResult.2 = 0
enterprises.ucdavis.extTable.extEntry.extResult.3 = 0
enterprises.ucdavis.extTable.extEntry.extResult.4 = 0
enterprises.ucdavis.extTable.extEntry.extOutput.1 = 292
enterprises.ucdavis.extTable.extEntry.extOutput.2 = -1
enterprises.ucdavis.extTable.extEntry.extOutput.3 = -1
enterprises.ucdavis.extTable.extEntry.extOutput.4 = -1
]]></programlisting>
		<para>
Here you see that the total amount of sessions of the load balancer
serving about 8 customers is 292 currently and that customer plx has
no connections so far.
		</para>
		</listitem>
		<listitem>
Write a <link linkend="snmp">MIB</link> for LVS stats.
		</listitem>
	</itemizedlist>
	</section>
	<section id="monitoring_tools">
	<title>MRTG family: Intro</title>
	<para>
There are a family of monitoring tools descended from MRTG. These
now include RRDtool (a descendant of MRTG, written by the same author,
Tobias Oetiker) and wrappers around RRDtool like lrrd (which have spawned
their own family of programs, <emphasis>e.g.</emphasis> cricket,
to monitor and graph just about anything you like).
lrrdtool can/does use nagios.
	</para>
	<blockquote>
		<para>
Laurie Baker <emphasis>lvs (at) easytrans (dot) com</emphasis> 20 Jan 2004
		</para>
		<para>
Nagios is a monitoring tool previously known as Netsaint.
		</para>
	</blockquote>
	<para>
I've read the documentation for mrtg and several of its descendants
and haven't been about to figure
out how they work enough to get them going. While the syntax of all of the
commands is available, there is no global picture of how they are used
to make a working set of programs.
I saw Tobias give a talk at Usenix one year about MRTG and while I knew
what it did, I didn't know how to set it up.
Some people have got these packages going,
presumably needing less documenation that I do. I'd like a worked example
of how a single simple variable (<emphasis>e.g.</emphasis> the contents of
<filename>/proc/loadavg</filename>) is sampled and plotted. The accompanying
packages needed (<emphasis>e.g.</emphasis> SNMP, php, gd...) are not described.
While a competent sysadmin will be able to work out what is missing from
the output of the crashes, it would be better to prepare ahead of time for the
packages needed, so that you can plan the time for the install and
won't have to stop for lack of information that
you could have handled ahead of time.
	</para>
	</section>
	<section id="LVSGSP">
	<title>MRTG family: LVSGSP</title>
	<note>
This was the first attempt to produce a graphical monitoring tool for LVS.
It doesn't seem to be under active developement anymore (Apr 2004) and
people are now using rrdtool (or ganglia which uses rrdtool) (see below).
	</note>
	<note>
		<para>
Alexandre has a new address <emphasis>Alexandre (dot) Cassen (at) free (dot) fr</emphasis>
and moved his pages to
<ulink url="http://www.lnxos.net/">Alexandre's open source code</ulink>
(http://www.lnxos.net/).
The links below to Alexandre's pages are dead. 
You can find files here 
<ulink url="http://www.austintek.com/LVS/LVS-HOWTO/HOWTO/files/lvsgsp-0.0.4.tar.gz">lvsgsp-0.0.4.tar.gz</ulink> 
(http://www.austintek.com/LVS/LVS-HOWTO/HOWTO/files/lvsgsp-0.0.4.tar.gz).
		</para>
		<para>
alex <emphasis>alshu (at) tut (dot) by</emphasis> 20 May 2008
has provided 
<ulink url="http://www.austintek.com/LVS/LVS-HOWTO/HOWTO/files/lvsgsp_newscripts.tar.bz2">lvsgsp_newscripts.tar.bz2</ulink> 
(http://www.austintek.com/LVS/LVS-HOWTO/HOWTO/files/lvsgsp_newscripts.tar.bz2) 
that he uses with lvsgsp.
		</para>
	</note>
	<para>
Alexandre Cassen <emphasis>alexandre (dot) cassen (at) wanadoo (dot) fr</emphasis>,
the author of
<ulink url="http://www.linuxvirtualserver.org/&#126;acassen/">keepalived</ulink>
has produced a package,
<ulink url="http://www.linuxvirtualserver.org/&#126;acassen/">LVSGSP</ulink>
that runs with
<ulink url="http://people.ee.ethz.ch/&#126;oetiker/webtools/mrtg/">MRTG</ulink>
to output LVS status information.
Currently
<ulink url="http://www.linuxvirtualserver.org/&#126;acassen/lvsgsp/">
active and inactive connections are plotted</ulink> (html/png).
	</para>
	<para>
The LVSGSP package includes directions for installing and a sample
mrtg.cfg file for monitoring one service. The mrtg.cfg file can be
expanded to multiple services
	</para>
<programlisting><![CDATA[
WorkDir: /usr/local/mrtg
IconDir: /usr/local/mrtg/images/

# VS1 10.10.10.2:1358
Target[VS1]: `/usr/local/bin/LVSGSP 10.10.10.2 1358`
Directory[VS1]: LVS
MaxBytes[VS1]: 150
.
.

# VS2 10.10.10.2:8080
Target[VS2]: `/usr/local/bin/LVSGSP 10.10.10.2 8080`
Directory[VS2]: LVS
MaxBytes[VS2]: 150
.
.
]]></programlisting>
	<para>
A note from Alexandre
	</para>
	<blockquote>
Concerning the use of MRTG directly onto the director, we must take care
of the computing CPU time monopolised by the MRTG graph generation. On a
very overloaded director, the MRTG processing can degrade LVS
performance.
	</blockquote>
	</section>
	<section id="MRTG">
	<title>MRTG</title>
	<para>
Peter Nash <emphasis>peter (dot) nash (at) changeworks (dot) co (dot) uk</emphasis>
18 Nov 2003
	</para>
	<para>
I'm using a perl script to pull LVS statistics from my directors into MRTG
using the ucd-snmp-lvs module.  I'm sure this could be easily modified to
work with RRDTool.  I'm no perl programmer so I'm sure there are better
ways to do this but it's been working for me for the last 3 months.  Since
my MRTG runs on a remote server (not the directors) using SNMP gives me
the remote access I need.  The main problem to overcome was that the
"instance number" of a particular "real service" is dependent on the order
in which the services are added to the IPVS table.  If you are using
something like ldirectord to add/remove services then this order can vary,
so the script has to solve this problem.  I also had a few problems
getting the ucd-snmp-lvs module to compile with net-snmp on my RH8
directors but that was probably down to my lack of knowledge, I got there
in the end!
	</para>
	<para>
The MRTG call to the script is as follows (director names, SNMP community
and IP addresses are "dummies"):
	</para>
<programlisting><![CDATA[
Target[lvs-1]: `/home/agents/snmpipvsinfo.pl director1 communitystring
123.123.123.123 80 bytes` + `/home/agents/snmpipvsinfo.pl director2
communitystring 123.123.123.123 80 bytes`
]]></programlisting>
	<para>
This aggregates the results from both primary and backup director so it
doesn't matter which one is "active".  The script returns zeros if the
requested service is not currently in the LVS table on the target
director.
	</para>

<programlisting><![CDATA[
#!/usr/bin/perl

#
============================================================================
# LVS Stats info script for mrtg
#
#    File:      snmpipvsinfo.pl
#
#    Author:    Peter Nash 17/06/03
#
#    Version:   1.0
#
#    Purpose:   Uses SNMP to get the IPVS stats on an LVS director.
#               Needs to find the correct instance in the lvsServiceTable to
#               match a given virtual server (the instance number
#               depends on the order in which services are added).
#
#    Usage:     ./snmpipvsinfo.pl director community service_ip service_port [conn|packets|bytes]
#
#    Notes:     The instance number of a given service in the LVS table
#               depends on the order in which the services are added to the table.
#               For example, if a monitoring service such as ldirectord is used
#               to add/remove services to LVS then the instance number of a service
#               will be based on the polling sequence of ldirectord.  As services are
#               added or removed the instance numbers of existing services may
#               change.  Therefore this script has to determine the current SNMP
#               instance number for each LVS service every time it is run.
#               In addition to the director address and SNMP community if takes the
#               service IP and service PORT as parameters to identify a specific
#               service.  The last option determines the static to return.
#               Output is in MRTG compatible format.
#
============================================================================

$director=shift;
$community=shift;
$service_ip=shift;
$service_port=shift;
$mode=shift;
$instance="";

# First we need to find the LVS instance for this service
# Get all service addresses
@addresses=`snmpwalk -v 2c -c $community -m LVS-MIB $director
lvsServiceAddr`;
# Get all the service ports
@ports=`snmpwalk -v 2c -c $community -m LVS-MIB $director lvsServicePort`;

# Now for each service check to see if both address and port match
foreach $i (0 .. $#addresses) {
  ($address,)=splitnamevalue($addresses[$i]);
  ($port,$thisinstance)=splitnamevalue($ports[$i]);
  if ( $address =~ /$service_ip/ ) {
    if ( $port =~ /$service_port/ ) {
      $instance=$thisinstance;
    }
  }
}

# Now we've got the instance for the service get the requested data

if ( $instance eq "") {
  # If the instance does not exist return zero's (i.e. this may be the
backup director)
  $param1="0: = 0";
  $param2="0: = 0";
} else {
  if ( $mode eq "conn" ) {
    $param1=`snmpget -v 2c -c $community -m LVS-MIB $director lvsServiceStatsConns.$instance`;
    $param2=`snmpget -v 2c -c $community -m LVS-MIB $director lvsServiceStatsConns.$instance`;
  } elsif ( $mode eq "packets" ) {
    $param1=`snmpget -v 2c -c $community -m LVS-MIB $director lvsServiceStatsInPkts.$instance`;
    $param2=`snmpget -v 2c -c $community -m LVS-MIB $director lvsServiceStatsOutPkts.$instance`;
  } elsif ( $mode eq "bytes" ) {
    $param1=`snmpget -v 2c -c $community -m LVS-MIB $director lvsServiceStatsInBytes.$instance`;
    $param2=`snmpget -v 2c -c $community -m LVS-MIB $director lvsServiceStatsOutBytes.$instance`;
  } else {
    $param1="";
    $param2="";
    print "Error in mode parameter";
  }
}

# Get the uptime
$uptime=`snmpwalk -v 2c -c $community $director sysUpTime.0`;
$uptime =~ s/.*\)\s+(\w+)/$1/;
($value1,)=splitnamevalue($param1);
($value2,)=splitnamevalue($param2);
print "$value1\n";
print "$value2\n";
print "$uptime";
print "LVS $mode\n";


sub splitnamevalue {
    $namevalue=shift;
    chomp($namevalue);
    ($index,$value)=split(/ = /, $namevalue);
    $index =~ s/.*\.([0-9]{1,6})$/$1/;
    $value =~ s/.*:\s+(\w+)/$1/;
    return $value,$index;
}
]]></programlisting>
	</section>
	<section id="RRDtool">
	<title>MRTG family: RRDtool</title>
	<para>
Salvatore D. Tepedino <emphasis>sal (at) tepedino (dot) org</emphasis>
21 Nov 2003
	</para>
	<para>
I posted the new version on my site:
<ulink url="http://tepedino.org/lvs-rrd/">http://tepedino.org/lvs-rrd/</ulink>.
The new version has a lot of code cleanup, much more flexibility in the
coloring, a command line arg so you can just graph traffic to one port
(ie: just port 80 traffic), and the update script has been changed
slightly to remove a redundant loop (Thanks Francois! If I do something
that obviously silly again, you can smack me!) and the removal of the
need to specify what type of LVS yours is (Route, Masq, etc). Now it
should collect data on all servers in the LVS.
Next step is to figure out how to graph specific services (VIP/Port
combinations instead of just specific ports)...
	</para>
	<note>
Jun 2006. tepedino.org is not on the internet. The last entry in the  
<ulink url="http://www.archive.org">wayback machine</ulink>
is 10 Feb 2005. Leon Keijser e-mailed me 
<ulink url="http://www.austintek.com/WWW/LVS/LVS-HOWTO/HOWTO/files/lvs-rrd-v0.7.tar.gz">
lvs-rrd-v0.7.tar.gz</ulink>
(http://www.austintek.com/WWW/LVS/LVS-HOWTO/HOWTO/files/lvs-rrd-v0.7.tar.gz)
which has a Changelog of Jan 2006.
	</note>
	<note>
Sebastian Vieira <emphasis>sebvieira (at) gmail (dot) com</emphasis> 10 Nov 2006
	</note>
	<para>
For those interested, the website of lvs-rrd is back up again at its usual
address: http://tepedino.org/lvs-rrd/
	</para>
	<para>
Joe: I contacted Sal off-list, to find there'd been problems at the ISP.
He's back, with the same e-mail address etc. v0.7 is still his latest code.
If the server goes down again, you can contact him
<emphasis>sal (dot) tepedino (at) gmail (dot) com</emphasis>.
	</para>
	<para>
21 Jan 2004
	</para>
	<para>
This new version allows you to graph connections to a specific VIP or
realserver or VIP port or RS Port or any combination of those via
command line options.
It also adds in adds an option flip the graph for people with more
inactive than active connections.
Also it can spit out an HTML page for the specific graphs it created so
a simple one line php page (included) can run the script and display the
output.
	</para>
	<note>
Joe: various people (including Francois Jeanmougin) have started sending
patches to Salvatore.
	</note>
	<para>
17 Jan 2004
	</para>
	<para>
This new version allows you to graph connections to a specific VIP or
realserver or VIP port or RS Port or any combination of those via
command line options.
It also adds in adds an option flip the graph for people with more
inactive than active connections (you can have either the ActiveConn
or InActConn plotted in the negative region below the X-axis).
Also it can spit out an HTML page for the specific graphs it created so
a simple one line php page (included) can run the script and display the
output.
	</para>
	<para>
Joe - Jan 2004: lvs-rrd worked straight out of the box for me.
You first install
<ulink url="http://people.ee.ethz.ch/~oetiker/webtools/rrdtool/">
rrdtool from http://people.ee.ethz.ch/~oetiker/webtools/rrdtool/</ulink>
with the standard <command>./configure ; make ; make install</command>.
The rrdtool executables are standard ELF files (not perl scripts as I thought).
<filename>rrdtool</filename> has the libraries it needs (<filename>zlib</filename>,
	</para>
<programlisting><![CDATA[
director:/usr/local/rrdtool-1.0.45/bin# ldd rrdtool
libm.so.6 => /lib/libm.so.6 (0x40017000)
libc.so.6 => /lib/libc.so.6 (0x4003a000)
/lib/ld-linux.so.2 => /lib/ld-linux.so.2 (0x40000000)
]]></programlisting>
	<para>
<filename>gd</filename>) so you don't need any recursive downloading.
Then you follow Salvatore's "Setup" instructions and you'll soon have
gifs showing the activity on your LVS.
	</para>
	<para>
The filenames that Salvatore uses for his databases are derived from the
<command>ipvsadm</command> (hex) information in <filename>/proc/net/ip_vs</filename>.
Thus one of my rrd files is <filename>lvs.C0A8026E.0017.C0A8010C.0017.rrd</filename>
representing VIP:port=192.168.2.110:23, RIP:port=192.168.1.12:23.
You don't have to look at these files (they're binary rrd database files) and naming
them this way was easier than outputting the IP in dotted quad with perl.
Salvatore supplies utilites (which he grabbed off the internet)
to convert the IP:ports between dotted quad and hex.
	</para>
<programlisting><![CDATA[
#/bin/bash
# from the internet, modified by Salvatore Tepedino and Joseph Mack
#
#IP is output in dotted quad
#run this in the directory with the lvs.*.rrd files.
#The files will have a name like
#lvs.C0A8026E.0017.C0A8010C.0017.rrd
#
#here's an example run
#   # ls
#   lvs.C0A8026E.0017.C0A8010C.0017.rrd
#   # ./ip_hex2quad.sh
#   192.168.2.110.0.23.192.168.1.11.0.23
#
#-----------------------
for file in lvs*rrd
do
        #echo $file
        IP=$(echo $(echo $file | tr a-z A-Z | sed 's/LVS\.//;s/\.RRD//;s/\.//g;s/\(..\)/;\1/g;s/^/i
base=16/' | bc) | sed 's/ /./g')
        echo $IP
done
#----------------------------
]]></programlisting>
<para>
and
</para>
<programlisting><![CDATA[
#/bin/bash
#ip_quad2hex.sh
#$1 is IP in dotted quad format
#converts dotted quad IP to hex

#------------------------
for i in `echo $1 | sed 's/\./ /g'`;do echo $i |awk '{printf "%02X", $1}';done;echo
#------------------------
]]></programlisting>
	<para>
Tore Anderson <emphasis>tore (at) linpro (dot) no</emphasis> 07 Dec 2003
	</para>
	<para>
There is also LRRD.
Plugins for monitoring ipvsadm output are already included, for an
demonstration you could take a look at "screenshot" pages at
<ulink url="http://linpro.no/projects/lrrd/example/runbox.com/cujo.runbox.com.html">
http://linpro.no/projects/lrrd/example/runbox.com/cujo.runbox.com.html</ulink>
	</para>
	<note>
Joe: Tore is one of the <filename>lrrd</filename> developers.
	</note>
	<para>
After getting Salvatore's code running, I reviewed the <filename>lrrd</filename>
docs and tutorials to realise that there never was any hope of me understanding
them without outside help.
The docs are written for data coming from snmp, and I assumed that snmp was the only
way of getting data.
As Salvatore's code shows, <filename>rrdtool</filename> can use data from anywhere:
if you can retreive/fetch/get your data in a script
and send it as a parameter to rrdtool,
then you can store and graph it with <filename>rrdtool</filename>.
	</para>
	<para>
taqu <emphasis>taqumd (at) gmail (dot) com</emphasis> 25 Nov 2008
	</para>
	<para>
Hi, I recently created another LVS graphing tool.
This scripts parse <command>ipvsadm -L -n --stats --exact</command> and generate
the following graphs:
<ulink url="http://sourceforge.jp/projects/lvs-stats">Project Home</ulink> 
(http://sourceforge.jp/projects/lvs-stats) 
<ulink url="http://sourceforge.jp/projects/lvs-stats/wiki/FrontPage">Screen Shot</ulink>
(http://sourceforge.jp/projects/lvs-stats/wiki/FrontPage)
	</para>
	</section>
	<section id="cacti">
	<title>MRTG family: cacti</title>
	<para>
<filename>cacti</filename> is another <filename>rrdtool</filename>
based monitoring tool, which has been adapted for lvs.
	</para>
	<para>
Bruno Bonfils <emphasis>asyd (at) debian-fr (dot) org</emphasis> 26 Jan 2004
	</para>
	<para>
If there are some of you who running cacti in order to monitor LVS
cluster, you'll probably interest by my xml data query and the associate
template. Both are available on
<ulink url="http://www.asyd.net/cacti/">http://www.asyd.net/cacti/</ulink>.
	</para>
	</section>
	<section id="ganglia">
	<title>MRTG family: Ganglia (incl. INSTALL)</title>
		<section id="ganglia_intro">
		<title>ganglia intro</title>
		<para>
Karl Kopper <emphasis>karl (at) gardengrown (dot) org</emphasis> 03 Dec 2003
		</para>
		<para>
Another cool tool for monitoring the Real Servers is <filename>Ganglia</filename>.
(With version 2) you run gmond monitoring daemons on each RS and a single gmetad daemon to
poll the gmonds on a server (that is running Apache) outside the cluster.
Then with the Ganglia Web Frontend you get great color graphs that help you
to find "hot spots". You can then write your own gmetric script to create
your own custom graph for anything happening on the Real Servers (I suppose
you could cull the Apache logs for "GET" operations--check out the Gmetric
Script Repository).
Incidentally, you can also add the gexec program to submit batch jobs (like
cron jobs) to the least loaded realserver or to all nodes simultaneously.
		</para>
<programlisting><![CDATA[
Ganglia Page:
http://ganglia.sourceforge.net/

Sample Ganglia page:
http://meta.rocksclusters.org/Rocks-Network/

Gmetric Script Repository:
http://ganglia.sourceforge.net/gmetric/
]]></programlisting>
		<note>
			<para>
<filename>ganglia</filename> is designed for beowulfs.
It produces nice colored graphs which managers love
and I'm sure lots of beowulfs have been sold because of it.
However there is a catch 22 with using it.
The compute nodes on a beowulf run synchronously,
calculating a subset of a problem.
At various points in a calculation, results from
the compute nodes need to be merged and all compute
nodes halt till the merge finishes.
The merge cannot start till all nodes have finished
their part of the calculation and if one node is delayed
then all the other nodes have to wait.
It is unlikely that the ganglia monitoring jobs will run
synchronised to the timeslice on each compute node.
Thus in a large beowulf (say 128 nodes), it will be
likely that one of the compute nodes will have run
a ganglia job and the other 127 will have to wait for this
node to complete its subset of the main calculation.
So while ganglia may produce nice graphs for managers,
it is not compatible with large or heavily loaded beowulfs.
			</para>
			<para>
None of this affects an LVS, where jobs on each realserver
run independantly. Ganglia should be a good monitoring
tool for LVSs.
			</para>
		</note>
		</section>
		<section id="ganglia_install">
		<title>ganglia install</title>
		<para>
<ulink url="http://ganglia.sourceforge.net/">ganglia</ulink> 
is a package for monitoring parameters on a set of nodes, 
forwarding the data to a display node where the data
is displayed as a set of graphs. 
By default ganglia displays such things as load_average,
memory usage, disk usage, network bandwidth. 
Instructions in the documentation show
how to add graphs of your own parameters. 
The data on the display node is stored by
<ulink url="http://www.rrdtool.com/">rrdtool</ulink>.
		</para>
		<note>
The documentation was not clear to me and the installation took
several attempts before I got a working setup.
These notes are written on the 3rd iteration of an install,
It's possible that I handled something in an earlier iteration
that I forgot about.
		</note>
		<para>
Ganglia has the ability to use
<ulink url="http://www.theether.org/gexec/">gexec</ulink> by Brent Chun,
a tool to remotely execute commands on other nodes
(like <command>rsh</command> and <command>ssh</command>).
You can configure ganglia to run with or without <command>gexec</command>.
Unfortunately I couldn't get <command>gexec</command> to run properly on Linux
and on contacting the author (Mar 2004) I find that gexec was developed under
another OS (*BSD ?) and because of problems with the Linux pthread
implementation, doesn't work on Linux. He's working on fixes.
		</para>
		<para>
Karl Kopper <emphasis>karl (at) gardengrown (dot) org</emphasis> 11 Apr 2004
		</para>
		<blockquote>
			<para>
Matt Massie of the Ganglia project tried to pull the <command>gexec</command>
code into the
new Ganglia distro but failed due to this pthreads problem as I
understand it, but if you download the old gexec and authd packages
directly from Brent's (old) web page I don't think they have the
pthreads problem. Well, actually, there is a problem we've had with
gexec when you try to run a command or script on all nodes (the -n 0
option) that we've never fully examined. The problem causes the -n 0
option to be so unreliable we don't use. The "-n 1" option works fine
for us (we use it for all production cron jobs to select the least
loaded cluster node).
			</para>
			<para>
For the moment you might be better off using the same ssh keys on all
cluster nodes and writing a script (this is the way I like to do it now
when I have to reliably run a command on all nodes). The great thing
about gexec, though, is that it will run the command at the same time on
all nodes--the ssh method has to step through each node one at a time
(unless, I supposed you background the commands in your script). Hmmm...
Theres an idea for a new script...
			</para>
		</blockquote>
		<para>
		<note>
gexec has similar functionality to
<ulink url="http:/www.netfort.gr.jp/~dancer/software/dsh">
dancer's shell - dsh</ulink> which uses ssh or rsh as transport
layer. Using ssh as a transport layer has its own problems - you
need passphrase-less login when using ssh for dsh, but you
need passphrase enabled login for users starting their sessions.
		</note>
		</para>
		<para>
There are 3 types of nodes in ganglia
		</para>
		<itemizedlist>
			<listitem>
				<para>
monitored nodes:
				</para>
				<para>
these will be your realserver and director(s) (<emphasis>i.e.</emphasis> all machines in the LVS).
These nodes run <command>gmond</command>, the ganglia monitoring demon,
which exchanges data with other monitored nodes by multicast broadcasts.
<command>gmond</command> also exchanges data with the relay nodes.
				</para>
			</listitem>
			<listitem>
				<para>
relay nodes:
				</para>
				<para>
these run <command>gmetad</command>.
For large setups (<emphasis>e.g.</emphasis> 1024 nodes),
<command>gmetad</command> collects data
from <command>gmond</command> in tree fashion and
feeds the data to the GUI node (which is also running <command>gmond</command>).
<command>gmetad</command> like <command>gmond</command>
exchanges data by multicast broadcasts.
				</para>
				<para>
I didn't quite figure out what was going on here and since I
only had a small LVS, I just ran <command>gmetad</command> on the
GUI node.
				</para>
				<para>
I assume if you had (say) 8 LVS's running and one GUI machine,
that <command>gmond</command> would be running on all nodes
and that <command>gmetad</command> would be running on
				</para>
				<itemizedlist>
					<listitem>
at least one node that was guaranteed to be up in each LVS.
For an LVS with a failover pair of directors,
<command>gmetad</command> would run on both directors.
					</listitem>
					<listitem>
the GUI node.
					</listitem>
				</itemizedlist>
				<para>
I didn't figure out how to set up a <command>gmetad</command> node,
if it wasn't also the GUI node.
From <filename>gmetad.conf</filename>,
it would appear that each <command>gmetad</command>
keeps its own set of rrd database files
(presumably these are duplicates of the set on the GUI node).
Presumably you should keep the rrd database files in
the same location as for the GUI node (for me in <filename>DocumentRoot/ganglia/rrds/</filename>),
just to keep things simple, but I don't know.
				</para>
				<para>
<command>gmetad</command> is not happy if you shut it down while <command>gmond</command>
is running, so I modified the gmetad init file to first shutdown gmond.
				</para>
			</listitem>
			<listitem>
				<para>
node with the GUI:
				</para>
				<para>
this node collects the data
with <command>gmetad</command>, stores it with rrdtool,
and displays it in a webpage using the php files
in <filename>gmetad-webfrontend</filename>.
This machine requires apache (I used apache-2.x.x) and php4.
				</para>
				<para>
On an LVS with a single director, the node with the GUI
will likely be the director.
In an LVS with an active/backup pair of directors,
you would probably have both directors run <command>gmetad</command>
and have the GUI running (with <command>gmetad</command>)
on an administrative machine.
				</para>
			</listitem>
		</itemizedlist>
		<para>
If you like using <command>netstat -a</command> and <command>route</command>
rather than their <command> -n</command> counterparts, then you can add the following -
		</para>
<programlisting><![CDATA[
/etc/services

#from ganglia
gmond           8649/tcp        # gmond
gmond           8649/udp        # gmond
gmetad_xml      8651/tcp        # gmetad xml port
gmetad_int      8652/tcp        # gmetad interactive port
]]></programlisting>
		<para>
		</para>
<programlisting><![CDATA[
/etc/hosts

239.2.11.71     gmond_mcast
]]></programlisting>
		<para>
Ganglia is installed differently
depending on the role of the machine in the data path.
		</para>
		<itemizedlist>
			<listitem>
			<para>
<emphasis role="bold">machines being monitored</emphasis>: these run <command>gmond</command>.
			</para>
			<para>
<command>gmond</command> is found in the <filename>ganglia-monitor-core</filename>.
To run <command>gmond</command> you do not need rrdtool to be installed.
However compilation of <command>gmond</command> requires
<filename>/usr/lib/librrdtool.a</filename> and <filename>/usr/include/rrd.h</filename>.
Unless you already have these available,
you will first have to compile rrdtool on the monitored node.
After compilation of rrdtool, you don't have to install it,
just copy <filename>rrd.h</filename> and <filename>librrd.a</filename> to their target directory.
To compile rrdtool, you need to have perl installed to produce the rrd manpages
(I needed perl-5.8.0, perl-5.6.1 produced errors).
I couldn't see anyway in the Makefile of just producing <filename>librrd.a</filename>.
A <command>make lib; make lib_install</command> option would be nice here.
			</para>
			<para>
After installing <filename>librrd.a</filename> and <filename>rrd.h</filename>,
do the default <filename>ganglia-monitor-core</filename> install:
<command>./configure; make; make install</command>.
This will install
<command>/usr/bin/gmetric, /usr/bin/gstat</command> and <command>/usr/sbin/gmond</command>.
Set up the rc file <filename>gmond/gmond.init</filename> to start <command>gmond</command>
on boot.
Copy the default conf_file <filename>gmond/gmond.conf</filename> to <filename>/etc/</filename>
and although you will have to modify it shortly,
for now <emphasis role="bold">don't mess with it</emphasis>.
<command>gmond</command> does not need a conf file to start
and will assume the values in the default conf file if the conf file doesn't exist.
			</para>
			<para>
Now see if you can start <command>gmond</command>
- you should see 8 copies in the ps table.
There are several things that can go wrong at this stage,
even if <command>gmond</command> starts.
			</para>
			<para>
There is no log file for <command>gmond</command>.
To figure out problems, you turn on debug in
<filename>gmond.conf</filename>.
After doing this, <command>gmond</command> will not detach and
will send the debug output to the console.
			</para>
			<para>
				<warning>
Do not leave debug <emphasis>on</emphasis> through a reboot,
as the gmond rc file won't exit and the boot process will hang.
				</warning>
			</para>
			<itemizedlist>
				<listitem>
				<para>
<command>gmond</command> may not start.
				</para>
				<para>
I got the debug message "gmond could not connect to multicast channel"
when using an older (2.4.9) kernel, but not with a newer (2.4.20) kernel.
				</para>
				</listitem>
				<listitem>
If you have a multi-homed machine, <command>gmond</command> defaults to using eth1.
If the other machines aren't mulitcast accessable via eth1, you won't know:
<command>gmond</command> will happily broadcast out the wrong NIC,
but will never hear anything back.
If you watch the debug output, you will see messages about packets being sent out,
but none about packets being received.
When you've got the right NIC and <command>gmond</command> on other nodes
are sending packets, you'll also see notices of packets being received.
You should know which NIC that you want the <command>gmond</command>
packets to go out, so set this now.
				</listitem>
			</itemizedlist>
			<para>
If <command>gmond</command> is working properly,
you should have 8 copies of <command>gmond</command> in the ps table.
This node is ready to exchange information with other monitoring
nodes. Leave <filename>/etc/gmond.conf</filename> for now.
			</para>
			<para>
Here's <command>netstat</command> output for a monitored machine
(realserver) running <command>gmond</command>
			</para>
<programlisting><![CDATA[
realserver1:/src/mrtg/ganglia/ganglia-monitor-core-2.5.6# netstat -a | grep gm
tcp        0      0 *:gmond                 *:*                     LISTEN
udp        0      0 realserver1:32819       gmond_mcast:gmond       ESTABLISHED
udp        0      0 gmond_mcast:gmond       *:*

realserver1:/src/mrtg/ganglia/ganglia-monitor-core-2.5.6# netstat -an | grep 86
tcp        0      0 0.0.0.0:8649            0.0.0.0:*               LISTEN
udp        0      0 192.168.1.9:32819       239.2.11.71:8649        ESTABLISHED
udp        0      0 239.2.11.71:8649        0.0.0.0:*
]]></programlisting>
			<para id="nicless_mcast" xreflabel="multicast without IPs on NICs">
Not knowing much about multicast, I was surprised to find an IP:port in
the output of <command>netstat</command> when the IP (239.2.11.71) was
not configured on a NIC.
The
<ulink url="http://www.ibiblio.org/pub/Linux/docs/HOWTO/other-formats/html_single/Multicast-HOWTO.html">Multicast over TCP/IP HOWTO</ulink>
(http://www.ibiblio.org/pub/Linux/docs/HOWTO/other-formats/html_single/Multicast-HOWTO.html)
only discusses multicast which needs to be routed (<emphasis>e.g.</emphasis> MBONE)
and so all multicast IPs involved must be configured on NICs.
Here's an explanation by Alexandre, who
wrote Keepalived, which uses multicast in a similar fashion.
			</para>
			<para>
Alexandre Cassen <emphasis>Alexandre (dot) Cassen (at) wanadoo (dot) fr</emphasis>
11 Apr 2004
			</para>
			<blockquote>
				<para>
In mcast fashion, Class D address is not configured to NIC. you just join
or leave the Class D, so called the mcast group. For mcast you can consider
2 differents design, most of common applications using multicast are done
over UDP, but you can also create your own mcast protocol as VRRP or HSRP
does, that way you are using mcast at same layer as UDP without adding UDP
overhead. Since mcast is not connection oriented the both design UDP or
pure RAW protocol are allowed. This contrast with the new SCTP protocol
which add retransmission and connection oriented design in a one-to-many
design (called associations).
				</para>
				<para>
So in mcast you must distinguish the sending and the receiving source. if
using the UDP transport then you can bind sending/receiving points to
special IP. On RAW fashion, you bind directly to device. Keepalived/VRRP
operate at RAW implementing its own protocol, use a pair of
sending/receiving socket on each interface VRRP instances run.
				</para>
			</blockquote>
			</listitem>
			<listitem>
				<para>
<emphasis role="bold">machine with GUI:</emphasis>
				</para>
				<para>
You should have apache/php4 installed.
				</para>
				<para>
Compile/install <filename>rrdtool</filename> using all defaults
(files will go in <filename>/usr/local/rrdtool-x.x.x/</filename>).
Link rrdtool-x.x.x to rrdtool (so you can access
rrdtool files from <filename>/usr/local/rrdtool/</filename>).
Unless you want to do a custom configure for <filename>ganglia-monitor-core</filename>,
also copy <filename>librrd.a</filename> to <filename>/usr/lib/</filename>
and <filename>rrd.h</filename> to <filename>/usr/include/</filename>
(as you did for the <command>gmond</command> nodes).
				</para>
				<para>
Copy all the files from
<filename>gmetad-webfrontend</filename> to <filename>DocumentRoot/ganglia/</filename>.
Then <command>mkdir DocumentRoot/ganglia/rrds/</command>, the directory for the rrd database files.
Edit <filename>DocumentRoot/ganglia/conf.php</filename> - some of the entries
weren't obvious - here's some of my file:
				</para>
<programlisting><![CDATA[
$gmetad_root = "/usr/local/etc/httpd/htdocs/ganglia/";
$rrds = "$gmetad_root/rrds";
define("RRDTOOL", "/usr/local/rrdtool/bin/rrdtool");
]]></programlisting>
				<para>
Add <command>gmetad</command> to the <filename>ganglia-monitor-core</filename> install
by doing <command>./configure --with-gmetad; make; make install</command>.
You will get an extra file <filename>/usr/sbin/gmetad</filename>.
Install <filename>gmetad/gmetad.initd</filename> as the init file and
<filename>gmetad/gmetad.conf</filename> in <filename>/etc/</filename>.
				</para>
				<para>
Start up <command>gmetad</command>
when you should see 8 copies in the ps table.
My install worked fine (after a bit of iterative fiddling with the conf files),
so I don't know what you do if it doesn't work.
				</para>
				<para>
By now the conf files need some attention and some of the entries in the two
conf files must match up.
				</para>
				<itemizedlist>
					<listitem>
					<para>
match "name" in <filename>gmond.conf</filename>
with "data_source" in <filename>gmetad.conf</filename>
(<emphasis>e.g.</emphasis> "Bobs LVS cluster").
					</para>
					<para>
This string will be used as the name of a directory to store the rrd files,
so don't put any fancy characters in here (like an apostrophe)
- blanks in a directory name are already hard enough to deal with.
					</para>
					</listitem>
					<listitem>
					<para>
"location": is a 3-D array to order the nodes for
presentation in the "Physical View" page
(a 3-D array is required for large clusters,
where machines are located in 3-D,
rather than in a single rack).
					</para>
					<para>
If you don't specify location,
then "Physical View" will give you its own reasonable view
- a vertical stack of boxes summarising each node.
					</para>
					<para>
If you do specify location, then each machine will be put in a Rack according to the first number.
Machines with values 0,x,y, will be listed as being in "Rack 0"; machines with 1,x,y will be listed in Rack 1 etc.
					</para>	
					<para>
The second dimension in the array determines the vertical position
that ganglia puts the node in the rack.
You can number the nodes according to their physical location (I have two beowulf
master nodes in the middle of the rack, with 8 compute nodes above and 8 compute
nodes below them), or logical location (the two directors can be on the top of the
rack, with realservers below).
You could have your directors in Rack 0, and your realservers in Rack 1.
					</para>
					<para>
Nodes with higher number location will be placed on the "Physical View" page
above nodes with lower numbers.
Location 1,0,0 will be at the bottom of Rack 1, while location 1,15,0 will be above it.
If you thought node 0 was going to be at the top of a Rack, then you're sadly mistaken
(this order must be a Northerm hemispherism).
Presumably there is some connection between location and num_nodes, but I haven't figured
it out and in some cases I've left the default value of num_nodes and in some cases I've
put num_nodes=32 (larger than the actual number of nodes, in case of expansion).
					</para>
					<para>
Only having a 1-D LVS, I didn't use the 3rd dimension (left it as 0).
					</para>
					<para>
If two machines are given the the same location,
then only one of them will display in the summary
on the "Physical View" page.
					</para>
					</listitem>
					<listitem>
					<para>
trusted_hosts are only for data transfers between <command>gmetad</command> nodes
(I think) - leave them as defaults.
					</para>
					</listitem>
					<listitem>
					<para>
rrd_rootdir (which I set to DocumentRoot:/ganglia/rrds/) and setuid must match
or <command>gmetad</command> will exit with error messages telling you to fix it.
					</para>
					</listitem>
				</itemizedlist>
			</listitem>
			<listitem>
			<para>
restart <command>gmetad</command> and <command>gmond</command>
(if they haven't been cleanly restarted yet).
			</para>
			<para>
Here's netstat output for a machine GUI machine running
both <command>gmond</command> and <command>gmetad</command>
immediately after starting up the demons. (The connections
between localhost:highport and localhost:gmond come and go).
			</para>
<programlisting><![CDATA[
director:/src/mrtg/ganglia/ganglia-monitor-core-2.5.6# netstat -a | grep gm
tcp        0      0 *:gmond                 *:*                     LISTEN
tcp        0      0 *:gmetad_xml            *:*                     LISTEN
tcp        0      0 *:gmetad_int            *:*                     LISTEN
tcp        0      0 localhost.mack.ne:gmond localhost.mack.ne:33287 FIN_WAIT2
tcp        0      0 localhost.mack.ne:33287 localhost.mack.ne:gmond CLOSE_WAIT
udp        0      0 director.mack.net:32819 gmond_mcast:gmond       ESTABLISHED
udp        0      0 gmond_mcast:gmond       *:*

director:/src/mrtg/ganglia/ganglia-monitor-core-2.5.6# netstat -an | grep 86
tcp        0      0 0.0.0.0:8649            0.0.0.0:*               LISTEN
tcp        0      0 0.0.0.0:8651            0.0.0.0:*               LISTEN
tcp        0      0 0.0.0.0:8652            0.0.0.0:*               LISTEN
tcp        0      0 127.0.0.1:8649          127.0.0.1:33287         FIN_WAIT2
tcp        0      0 127.0.0.1:33287         127.0.0.1:8649          CLOSE_WAIT
udp        0      0 192.168.1.3:32819       239.2.11.71:8649        ESTABLISHED
udp        0      0 239.2.11.71:8649        0.0.0.0:*
]]></programlisting>
			<para>
surf to http:/my_url/ganglia.
You should see a page with graphs of activity for your nodes.
If you want the current information you have to Shift-reload,
unlike with <link linkend="RRDtool">lvs-rrd</link>,
where the screen will automatically fresh every 5 mins or so.
Presumably you can fiddle the ganglia code to accomplish this
too (but I don't know where yet).
			</para>
			</listitem>
		</itemizedlist>
		</section>
	</section>
	<section id="rrd_images" xreflabel="rrd images showing load balancing">
	<title>MRTG family: rrd images</title>
	<para>
These images are to show that an LVS does balance the load (here number
of connections) between the realservers.
	</para>
	<itemizedlist>
		<listitem>
		<para>
Salvatore D. Tepedino <emphasis>sal (at) tepedino (dot) org</emphasis> 25 Mar 2004.
		</para>
		<para>
		</para>
		<figure align="right">
		<title>
		LVS with 2 realservers, serving httpd, single day.
		</title>
		<mediaobject align="center">
			<imageobject>
				<imagedata fileref="images/lvs.All.All.All.All-day.gif" format="gif"
					scalefit="0"
					align="right"
					srccredit="Salvatore D Tepedino (C) 2004">
				</imagedata>
			</imageobject>
			<textobject>
<phrase>rrd graph of connections to an LVS with 2 realservers, serving httpd, single day.</phrase>
			</textobject>
			<caption>
			<para>
More images are at
<ulink url="http://www.tepedino.org/lvs-rrd/">Salvatore's lvs-rrd website</ulink>
(http://www.tepedino.org/lvs-rrd/).
			</para>
			<para>
To get this graph, first you'd need to run the update
script (included in the package) to generate the rrd files and start
collecting the data. After a little while you can run the graphing
script which will see the rrd files and generate the graphs based off
the data in them. The easiest way to use the script it to just extract
it into the web root of your director (which I figured that alot of
people have as ultimate failovers if all their realservers go down),
put in the cron tab (explained in the docs) wait a few minutes, then go
to the index.php page and you should see the beginnings of a graph. The
longer you let it (the cron job) run, the more data you've collected,
the more data in your graphs. You don't need to know how to use RRD to
use my script.
The 'All: All RS: All:All' in the script just means "All VIPs:All Ports;
RS: All Real servers: All ports". With the script you can select if you
want to graph just connections to a specific VIP or RS, or VIP port or
RS port, or any combination. Useful for large clusters.
			</para>
			<para>
My script generates the rrd line necessary to generate the graphs
(tepedino.org/lvs-rrd). If you run it in verbose mode, it will spit out
the rrd command line it uses to generate the graphs. If you like, I can
give you some help with RRD. It's not the most obvious thing in the
world to learn, but I had a lot of time on my hands when I decided to
learn it, so I got fairly decent at it.
			</para>
			</caption>
		</mediaobject>
		</figure>
		<para>
		<figure align="right">
		<title>
		LVS with 2 realservers, serving httpd, week, showing realserver failure.
		</title>
		<mediaobject align="center">
			<imageobject>
				<imagedata fileref="images/lvs.All.All.All.All-week_realserver_failure.gif" format="gif"
					scalefit="0"
					align="right"
					srccredit="Salvatore D Tepedino (C) 2004">
				</imagedata>
			</imageobject>
			<textobject>
<phrase>rrd graph of connections to an LVS with 2 realservers, serving httpd, week, realserver failuare.</phrase>
			</textobject>
			<caption>
			<para>
Note the failure of realserver 216.82.75.205, between 0600-1200 on thursday, 
with the other realserver picking up the load. 
			</para>
			</caption>
		</mediaobject>
		</figure>
		</para>
		</listitem>
		<listitem>
		<para>
Malcolm Turnbull <emphasis>malcolm (at) loadbalancer (dot) org</emphasis> 27 Mar 2004.
		</para>		
		<figure align="right">
		<title>
		LVS with 4 realservers, serving httpd, single day.
		</title>
		<mediaobject align="center">
			<imageobject>
				<imagedata fileref="images/RS1-daily.gif" format="gif"
					scalefit="0"
					align="right"
					srccredit="Malcolm Turnbull (C) 2004">
				</imagedata>
			</imageobject>
			<textobject>
<phrase>rrd graph of connections to an LVS with 4 realservers, serving httpd, single day.</phrase>
			</textobject>
			<caption>
			<para>
	More images are available at
<ulink url="http://www.loadbalancer.org/lbadmin/stats/chart.php">loadbalancer.org</ulink>
	(http://www.loadbalancer.org/lbadmin/stats/chart.php).
			</para>
			</caption>
		</mediaobject>
		</figure>
		</listitem>	
		<listitem>
		<para>
Karl Kopper <emphasis>karl (at) gardengrown (dot) org</emphasis> 2 Apr 2004
		</para>
		<para>
Here is an LVS serving telnet. The clients connect through to the realservers
where they run their applications. Although the number of connections
is balanced, the load on each realserver can be quite different.
Here's the <command>ipvsadm</command> output taken at the end of the time period shown.
		</para>

<programlisting><![CDATA[
# ipvsadm -L -t 172.24.150.90:23
Prot LocalAddress:Port Scheduler Flags
  -> RemoteAddress:Port           Forward Weight ActiveConn InActConn
TCP  cluster:23 wrr
  -> clnode7:23             Route       1      53         1
  -> clnode8:23             Route       1      38         0
  -> clnode2:23             Route       1      46         1
  -> clnode10:23            Route       1      49         0
  -> clnode9:23             Route       1      49         0
  -> clnode6:23             Route       1      35         1
  -> clnode5:23             Route       1      33         0
  -> clnode4:23             Route       1      36         0
  -> clnode3:23             Route       1      40         0
  -> clnode1:23             Local       1      42         0
]]></programlisting>
		<figure align="right">
		<title>
LVS with 10 realservers, serving telnet, load average for past hour, images of total cluster.
		</title>
		<mediaobject align="center">
			<imageobject>
				<imagedata fileref="images/ganglia1.gif" format="gif"
					scalefit="0"
					align="right"
					srccredit="Karl Kopper (C) 2004">
				</imagedata>
			</imageobject>
			<textobject>
<phrase>Ganglia graph of connections to an LVS with 10 realservers, serving telnet, 1 hr.</phrase>
			</textobject>
			<caption>
			<para>
The graphs above show total one minute load average for the LVS cluster.
When the load average on any individual box is greater
than 1 (for uniprocessor systems) the icon for the realserver
(the boxes at the bottom of the image) turns red.
			</para>
			</caption>
		</mediaobject>
		</figure>
		<figure align="right">
		<title>
LVS with 10 realservers, serving telnet, load average for past hour, for each realserver
and the cluster manager.
		</title>
		<mediaobject align="center">
			<imageobject>
				<imagedata fileref="images/ganglia2.gif" format="gif"
					scalefit="0"
					align="right"
					srccredit="Karl Kopper (C) 2004">
				</imagedata>
			</imageobject>
			<textobject>
<phrase>rrd graph of load on each of 10 realservers, serving telnet, 1 hr.</phrase>
			</textobject>
			<caption>
			<para>
The graphs above show the bottom-half of the Ganglia web page with
the one minute load average (for each realserver) for the past hour.
Note that the load average is quite different for each realserver.
Also shown is the cluster node manager (outside the LVS),
used by the realservers for authentication and print spooling.
			</para>
			</caption>
		</mediaobject>
		</figure>
		</listitem>
		<listitem>
		<para>
Magnus Nordseth <emphasis>magnus (at) ntnu (dot) no</emphasis> 05 Apr 2004
		</para>
		<figure align="right">
		<title>
		LVS with 3 quad processor realservers, serving https, single day, y-axis is cpu-idle
(all idle = 400%).
		</title>
		<mediaobject align="center">
			<imageobject>
				<imagedata fileref="images/textus-cpu-usage.gif" format="gif"
					scalefit="0"
					align="right"
					srccredit="Magnus Nordseth (C) 2004">
				</imagedata>
			</imageobject>
			<textobject>
<phrase>Ganglia graph of cpu-idle for LVS with 3 quadprocessor realservers, serving https, single day.</phrase>
			</textobject>
			<caption>
			<para>
The graph shows cpu-idle for three identical realservers running https.
Each realserver has 4 cpu's, thus maximum idle cpu is 400%.
The graph was created with in-house software.
			</para>
			</caption>
		</mediaobject>
		</figure>
		</listitem>
	</itemizedlist>
	</section>
	<section id="nagios">
	<title>Nagios</title>
	<para>
Nagios is mentioned elsewhere in this HOWTO by various posters as a monitoring tool.
	</para>
	<para>
anon
	</para>
	<para>
I'm interested with LVS to do some load balancing with HTTP. 
I'm testing LVS with VMWare (i'm simulating two Windows 2003 real servers).
Is there a way to do some load monitoring with windows realservers?  
I know the <link linkend="feedbackd"> feedbackd project</link>, but there's no win32 agent...
If LVS cannot do Load monitoring I will use bigip or other proprietary 
solution that could handle load monitoring.
	</para>
	<para>
Peter Mueller <emphasis>pmueller (at) sidestep (dot) com</emphasis>
11 Jul 2005
	</para>
	<para>
You can try using the Nagios windows agents and some shell scripts to
accomplish your goals.
Two Nagios Windows programs that I am aware of are:
http://nagios-wsc.sourceforge.net/ and
http://nsclient.ready2run.nl/
	</para>
	</section>
	<section id="snmp">
	<title>MIB/SNMP</title>
	<para>
A MIB has been written for LVS by Romeo Benzoni
<emphasis>rb (at) ssn (dot) tp</emphasis> (Nov 2001).
It's available as
	</para>
	<note>
Joe: there's a 64 bit problem with the net-snmp-lvs module that's been fixed. 
Make sure you're using at least the 0.0.4-2 module.
	</note>		
	<itemizedlist>
		<listitem>
<ulink url="http://anakin.swiss-support.net/&#126;romeo/lvs-snmp/">code and documentation</ulink>
(http://anakin.swiss-support.net/&#126;romeo/lvs-snmp/).
The latest (Mar 2002) is at
http://anakin.swiss-support.net/&#126;romeo/lvs-snmp/ucd-snmp-lvs-module-0.0.2.tar.bz2
(Joe: this seems to have disappeared).
		</listitem>
		<listitem>
(Joe: incase other links go dead):
<ulink url="http://www.austintek.com/LVS/LVS-HOWTO/HOWTO/files/net-snmp-lvs-module-0.0.4.tar.gz">net-snmp-lvs-module-0.0.4.tar.gz</ulink>,
<ulink url="http://www.austintek.com/LVS/LVS-HOWTO/HOWTO/files/net-snmp-lvs-module-0.0.4-1.EL4.src.rpm">net-snmp-lvs-module-0.0.4-1.EL4.src.rpm</ulink>,
<ulink url="http://www.austintek.com/LVS/LVS-HOWTO/HOWTO/files/net-snmp-lvs-module-0.0.4-2.EL4.src.rpm">net-snmp-lvs-module-0.0.4-2.EL4.src.rpm</ulink>
		</listitem>
		<listitem>
<ulink url="http://www.loadbalancer.org/download/SNMP/">Malcolm Turnbull's download/SNMP</ulink> 
(this directory includes net-snmp-5.3.0.1.tar.gz)
		</listitem>
		<listitem>
Jack Neely (who provided the updates):
<ulink url="http://install.linux.ncsu.edu/pub/yum/CLS/CLSTools.EL4/srpms/net-snmp-lvs-module-0.0.4-1.EL4.src.rpm">net-snmp-lvs-module-0.0.4-1.EL4.src.rpm</ulink>, and the updated version
<ulink url="http://install.linux.ncsu.edu/pub/yum/CLS/CLSTools.EL4/srpms/net-snmp-lvs-module-0.0.4-2.EL4.src.rpm">net-snmp-lvs-module-0.0.4-2.EL4.src.rpm</ulink>
(http://install.linux.ncsu.edu/pub/yum/CLS/CLSTools.EL4/srpms/net-snmp-lvs-module-0.0.4-2.EL4.src.rpm).
			<para>
Laurentiu C. Badea (L.C.) <emphasis>lc (at) waat (dot) com</emphasis> 26 Dec 2008
			</para>
			<para>
The new version is in the 4-2 src rpm (for reference it's at
http://archive.linuxvirtualserver.org/html/lvs-users/2008-10/msg00011.html). 
I have been using it with cacti for... well, since then.
			</para>	
			<para>
The source rpm says EL4 but it should compile on many rpm-based distros with "rpmbuild -bb $src.rpm". You can make a source
tar.gz by running "rpmbuild -bp $src.rpm" and then archiving the prepared sources from where they were unpacked.
			</para>
			<para>
Though, essentially, the "source" is the original net-snmp-lvs-module-0.0.4.tar.gz found in the HOWTO somewhere. The src rpm
packages it with the ipvsadm sources plus a few patches and automates the patch, build and install procedure.
			</para>
			<para>
from 4-1 to 4-2. This is the list of files in 4-2:
			</para>
<programlisting><![CDATA[
COPYING
ipvsadm-1.24-kernhdr-1.2.1.patch
ipvsadm-1.24.tar.gz
lvs-counter64.patch
net-snmp-lvs-module-0.0.4-2.6-kernel.patch
net-snmp-lvs-module-0.0.4-kernheaders.patch
net-snmp-lvs-module-0.0.4.tar.gz
net-snmp-lvs-module.spec
]]></programlisting>
		</listitem>
	</itemizedlist>
	<para>
Jack Neely <emphasis>jjneely (at) ncsu (dot) edu</emphasis> 1 Oct 2008
	</para>
	<blockquote>
		<para>
I've setup net-snmp-lvs in an attempt to move the monitoring of my
lvs/keepalived balancer into Cacti.  I've gotten most things working and
even have an RPM that folks might be interested in.  I've built this on
RHEL4 and 5 i386 (I believe it needs a bit of extra work for 64 bit
arches.)
http://install.linux.ncsu.edu/pub/yum/CLS/CLSTools.EL4/srpms/net-snmp-lvs-module-0.0.4-1.EL4.src.rpm
		</para>
		<para>
The values provided for the lvsServiceStatsInBytes attributes are not right.  
They don't seem to be bits or bytes.  
Cacti is graphing out my ssh service as doing terabytes of traffic per second.  
Running <command>snmpwalk ; sleep 2 ; snmpwalk</command> gives me the following:
		</para>
<programlisting><![CDATA[
SNMPv2-SMI::enterprises.8225.4711.17.1.13.2 = Counter64: 4927135724047695874
SNMPv2-SMI::enterprises.8225.4711.17.1.13.2 = Counter64: 4927141668282433538
]]></programlisting>
		<para>
Running <command>ipvsadm -L --stats</command> for the same firewall mark prints out the
in bytes service counter at 9737M.
		</para>
	</blockquote>
	<para>
Laurentiu C. Badea (L.C.) <emphasis>lc (at) waat (dot) com</emphasis> 02 Oct 2008 
	</para>
	<para>
I'm not sure 
why it's like this, but you just need to swap the two 32-bit fields 
around to get to the real value (which incidentally is the same as 
shifting >>32 when they are all zeroes).
	</para>
	<para>
Take for example 2670058611031409148 returned by SNMP for 2182G.
In hex (easier to work with than binary) it is 250df429 000001fc,
the real value is 000001fc 250df429 which is 2182465057833 or 2182G.
	</para>
	<para>
I just used the rates instead for the time being (just remember to 
change from COUNTER to GAUGE so cacti knows how it works).
	</para>
	<para>
I was looking at this last night. The problem was that ASN_COUNTER64 expects a "struct counter64" and is given a "long long"
(__u64) instead. The attached patch should correct this problem.
	</para>
<programlisting><![CDATA[
Fix the bad values returned for the 64-bit byte counters.

--- lvs.c.orig  2006-01-02 14:31:54.000000000 +0000
+++ lvs.c       2008-10-03 18:43:48.000000000 +0000
@@ -131,6 +131,17 @@
        }
 }
 
+/** set a counter64 snmp response field from a __u64 value
+
+**/
+static
+void netsnmp_set_var_counter64_value(netsnmp_variable_list *var, __u64 *val){
+       struct counter64 val64;
+       val64.high = *val >> 32;
+       val64.low = *val & 0xffffffff;
+       snmp_set_var_typed_value(var, ASN_COUNTER64, (u_char *)&val64, sizeof(val64));
+}
+
 /** returns the first data point within the lvsServiceTable table data.
 
     Set the my_loop_context variable to the first data point structure
@@ -271,10 +282,10 @@
                                snmp_set_var_typed_value(var, ASN_COUNTER, (u_char *) &stats->outpkts, sizeof(stats->outpkts));
                                break;
                            case COLUMN_LVSSERVICESTATSINBYTES:
-                               snmp_set_var_typed_value(var, ASN_COUNTER64, (u_char *) &stats->inbytes, sizeof(stats->inbytes));
+                               netsnmp_set_var_counter64_value(var, &stats->inbytes);
                                break;
                            case COLUMN_LVSSERVICESTATSOUTBYTES:
-                               snmp_set_var_typed_value(var, ASN_COUNTER64, (u_char *)&stats->outbytes, sizeof(stats->outbytes));
+                               netsnmp_set_var_counter64_value(var, &stats->outbytes);
                                break;
                            case COLUMN_LVSSERVICERATECPS:
                                snmp_set_var_typed_value(var, ASN_GAUGE, (u_char *) &stats->cps, sizeof(stats->cps)); @@ -434,10 +445,10 @@
                                snmp_set_var_typed_value(var, ASN_COUNTER, (u_char *) &stats->outpkts, sizeof(stats->outpkts));
                                break;
                            case COLUMN_LVSREALSTATSINBYTES:
-                               snmp_set_var_typed_value(var, ASN_COUNTER64, (u_char *) &stats->inbytes, sizeof(stats->inbytes));
+                               netsnmp_set_var_counter64_value(var, &stats->inbytes);
                                break;
                            case COLUMN_LVSREALSTATSOUTBYTES:
-                               snmp_set_var_typed_value(var, ASN_COUNTER64, (u_char *) &stats->outbytes, sizeof(stats->outbytes));
+                               netsnmp_set_var_counter64_value(var, &stats->outbytes);
                                break;
                            case COLUMN_LVSREALRATECPS:
                                snmp_set_var_typed_value(var, ASN_GAUGE, (u_char *) &stats->cps, sizeof(stats->cps));
]]></programlisting>
	<para>
Jack
	</para>
	<para>
a src.rpm:

<ulink url="http://install.linux.ncsu.edu/pub/yum/CLS/CLSTools.EL4/srpms/net-snmp-lvs-module-0.0.4-2.EL4.src.rpm">net-snmp-lvs-module-0.0.4-2.EL4.src.rpm</ulink>
(http://install.linux.ncsu.edu/pub/yum/CLS/CLSTools.EL4/srpms/net-snmp-lvs-module-0.0.4-2.EL4.src.rpm)
	</para>
	<para>
Laurentiu 
	</para>
	<para>
I would also create the necessary config and reload snmpd on 
install and uninstall, so it will "just work" immediately after install, 
something like this.
	</para>
<programlisting><![CDATA[
mkdir -p $RPM_BUILD_ROOT/etc/snmp
echo "dlmod lvs /usr/lib/libnetsnmplvs.so" > 
$RPM_BUILD_ROOT/etc/snmp/snmpd.local.conf

%files
...
%config(noreplace) /etc/snmp/snmpd.local.conf

%post
test $1 = 1 && chkconfig snmpd && service snmpd reload || true;

%postun
test $1 = 0 && chkconfig snmpd && service snmpd reload || true;
]]></programlisting>
	<note>
If you can't access the snmp information (get timeouts, or snmpwalk crashes)
	</note>
	<para>
Michael Moody <emphasis>michael (at) gsc (dot) cc</emphasis> 24 Sep 2008
	</para>
	<para>
Depending on distribution, check /var/log/messages for more info. 
I had a problem where snmpd was running as "other than root",
preventing the libnetsnmplvs from being able to access the ipvs tables.
	</para>
	<para>
Laurentiu C. Badea (L.C.) <emphasis>lc (at) waat (dot) com</emphasis> 12 Dec 2008 
	</para>
	<para>
Build the net-snmp-lvs-module rpm posted earlier and install it on your 
servers running snmpd, then you can access the LVS data via SNMP in 
cacti. You can whip up a quick graph using the snmp-oid template, or you 
can make a more elaborate graph template that can be attached to hosts.
	</para>
	<para>
For example, the OIDs you need for bandwidth per service are:
	</para>
<programlisting><![CDATA[
bytes in:  1.3.6.1.4.1.8225.4711.17.1.13.i
bytes out: 1.3.6.1.4.1.8225.4711.17.1.14.i
]]></programlisting>
	<para>
where "i" is the service index (1...number of LVS services defined).
You can use snmpwalk to find all the fields.
	</para>
	<para>
Jack Neely <emphasis>jjneely (at) ncsu (dot) edu</emphasis> 17 Dec 2008
	</para>
	<para>
In a similar vain...I'm using Cacti to graph services based on firewall
mark.  When a fwmark is removed I tell Cacti to reindex the LVS SNMP
data so each data source is still groking the right part of the SNMP
tree.  This does that...but (today at least) also edited the path to
the RRD for each data source to use the previous data source's RRD.  I
then became unhappy as I watched Cacti trash all my pretty graphs.
	</para>
	<para>
How do other folks handle this case when a service disappears from LVS
with Cacti?
	</para>
	</section>
	<section id="home_brew_snmp">
	<title>home brew MIB/SNMP</title>
	<para>
Ratz
	</para>
	<para>
The file <filename>linux/snmp.h</filename> represents the SNMP RFCs.
IPVS is not specified in an RFC, so adding this has no chance I believe.
	</para>
	<para>
If you want to generate your own MIB,
use one of the reserved sub trees of the MIB DB for 
such projects and peruse m2c. If you really plan on writing one, get 
back to us so we can sort out the header to freeze the API.
	</para>
	<para>
The simple approach we've been using for years:
	</para>
	<itemizedlist>
		<listitem>
Prepare the values through cronjobs by calling ipvsadm or parsing
proc-fs and write SNMP type values (u32, u64, char ...) into single
files <emphasis>e.g.</emphasis> <filename>/var/run/lvs_snmp/VIP1_act_conns.out</filename>.
		</listitem>
		<listitem>
			<para>
 Configure <filename>snmpd.conf</filename> to read out those files using <command>cat</command>, 
<emphasis>e.g.</emphasis>
			</para>
			<para>
    <command>exec VIP1_act_conns /bin/cat /var/run/lvs_snmp/VIP1_act_conns.out</command>
			</para>
		</listitem>
		<listitem>
Use snmpwalk and grep for <filename>VIP1_act_conns</filename> to get the OID and off you
    go monitoring those values.
		</listitem>
		<listitem>
Repeat for all values you would like to poll.
		</listitem>
	</itemizedlist>
	<para>
If you need up to date values (not recommended though) you can also 
directly call shell scripts using the exec directive.
	</para>
	<para id="duncan_snmp" xreflabel="SNMP">
Joseph T. Duncan <emphasis>duncan (at) engr (dot) orst (dot) edu</emphasis> 21 Aug 2006
	</para>
	<para>
Presently I collect CPU, Memory in USE, and Network traffic statics from my
windows terminal server "real servers" via snmp. I toss this information
into an rrd database for making pretty graphs along with usage parsed from
lvs stats. Finaly I take the CPU and Memory stats and use them to adjust my
weight tables. My script <ulink url="files/duncan_main.pl">duncan_main.pl</ulink>
for doing this is still in its infancy as I am
getting stuff ready for this fall term, but it should be fun to see how it
all works out. 
28 Dec 2006: Here's an update <ulink url="files/lvs_weight.pl">lvs_weight.pl</ulink>
	</para>
	</section>
	<section id="disk_monitoring" xreflabel="disk monintoring tools">
	<title>Disks</title>
	<para>
Monitoring disks is not directly an LVS problem, however since disks are the
most failure prone component of a computer, you need to have a plan to handle
disk failure (I pre-emptively change out my disks at the end of their warrantee
period, even if they're not giving problems).
	</para>
	<para>
	Linux J. Jan 2004, p 74 has an article on the
SMART tools for monitoring ATA and SCSI disks. Apparently for years now
IDE and SCSI disks have been using the Self Monitoring, Analysis and
Reporting Technology (SMART) standard to report low level errors
(<emphasis>e.g.</emphasis> disk read errors, there's dozens of tests).
This has been available in tools
like Maxtor's PowerMax (for windows). (VAX's and Cray's
continuously monitor and report disk errors - I've never known why this wasn't
available on other machines.) The current SMARTv2 spec has been around since
Apr 1996.
	</para>
	<para>
	Apparently these SMART tools have been available on Linux for a while
and run on mounted disks. The source code is at
<ulink url="http://smartmontools.sourceforge.net/">
http://smartmontools.sourceforge.net/</ulink>
	</para>
	<para>
	There are two components,
	</para>
	<itemizedlist>
		<listitem>
	smartd which reads a config file and runs in background monitoring
your disks and writing to syslogd (and/or e-mailing you)
		</listitem>
		<listitem>
	smartctl which runs various checks from the command line and
which you can run as a cron job to do an exhaustive (1hr long) check
(<emphasis>e.g.</emphasis> on Sun morning at 1am).
		</listitem>
	</itemizedlist>
	</section>
	<section id="output_gui">
	<title>Other output GUIs</title>
		<section id="procstatd" xreflabel="procstatd">
		<title>procstatd</title>
		<para>
A lightweight and simple webbased cluster monitoring tool designed for beowulfs
<ulink url="http://www.phy.duke.edu/brahma/">procstatd</ulink>, the latest
version was 1.3.4 (you'll have to look around on this page).
		</para>
		</section>
		<section id="OSCE">
		<title>OSCE</title>
		<para>
From Putchong Uthayopas <emphasis>pu (at) ku (dot) ac (dot) th</emphasis>
a heavyweight (lots of bells and whistles) cluster monitoring tool,
originally called KCAP which has a new incarnation as
http://www.opensce.org/ Open Scalable Cluster Environment (link dead Jun 2003).
		</para>
		</section>
	</section>
</section>
<section id="LVS-HOWTO.operation" xreflabel="Details of LVS operation">
<title>LVS: Details of LVS operation, Security, DoS</title>
	<section id="list_top_20_vunerabilities">
	<title>Top 20 security vunerabilities</title>
	<para>
See <ulink url="http://www.sans.org/top20/">list of top 10 windows and top 10 unix vunerabilities</ulink>
	</para>
	</section>
	<section id="top_75_security_tools">
	<title>Top 75 security tools from the people at <filename>nmap</filename></title>
	<para>
See <ulink url="http://www.insecure.org/tools.html">Top 75 Security Tools</ulink>
survey of May 2003, by polling the nmap mailing list.
	</para>
	</section>
	<section id="network_testing_with_abberant_packets" xreflabel="network testing with abberant packets">
	<title>Network Testing with Abberant Packets</title>
	<note>
This is not exactly DoS, but is from a thread on another mailing list.
	</note>
	<para>
Jeff The Riffer <emphasis>riffer (at) vaxer (dot) net</emphasis>
27 Feb 2007 
	</para>
	<para>
We used several tools to generate abberant behavior, rather than packet
replays. One was Core Impact, which actually exploits known holes and installs
agents. It can do TCP evasion techniques to a limited extant.
For abberant behavior, we found a nifty little open-source tool called isic,
which lets you generate all sorts of abnormal traffic:
	</para>
<programlisting><![CDATA[
http://www.mirrors.wiretapped.net/security/packet-construction/isic/
]]></programlisting>
	<para>
It has binaries to generate abnormal ethernet, UDP, TCP, IP, and ICMP traffic.
You can control percentages of the different abnormalities as well as volume
of traffic. It's VERY noisy and aggressive stuff, but great for seeing if you
can brign down a system.
You can also use to to generate a packet storm while trying to sneak in
through a more mundane attack amd trick your IDS/IPS route.
We had problems getting it compiled, but someone was able to find a Debian
package for it. The Debian package was converted to RPM using Alien and the
RPM worked great under SuSe 10.0.
	</para>
	<para>
Other than that we just used NMap and Nessus to generate varying levels of
traffic and alerts. Isic was very useful for us...
	</para>
	<para>
NMap/Nessus are to test how good IPS are to detect scanning.
We were doing a very comprehensive test so we made no assumptions about
capabilities of the products. NMap and Nessus by
themselves would not be sufficient.
	</para>
	<para>
The problem iwth replaying actual packet captures to test an IPS
is that it will be for whatever IP addresses
were in play when the capture is done, so that won't really work either. You
can muck around with the .cap file and change the IPs and MAC addresses but
it's an iffy solution.
	</para>
	<para>
Core Impact is really great. But it's commercial and expensive, so most folks
aren't going to have it. But, Metasploit is free and can do many of the same
things. Just not as easily.
	</para>
	</section>
	<section id="do_i_need_security">
	<title>Do I need security, really?</title>
	<para>
Malcolm Turnbull
	</para>
	<blockquote>
Assuming that you have an LVS loadbalancer running on a linux box
and this box is behing a firewall so that only ports 80 and 443 are
allowed from clients.
Do you really need to harden the loadbalancer firewall rules ?
What about SYN cookies?
	</blockquote>
	<para>
Ratz 01 Oct 2002
	</para>
	<para>
Yes, always. DROP ALL, accept TCP 80/443 only.
Especially if the packet filter in front and the LVS are running the
same OS :)
	</para>
	<para>
Nothing can prevent SYN flooding, you can only live better with it when
you have SYN cookies enabled.
With a wrongly set backlog queue size you
still face big penalty with SYN/RST attacks.
See <ulink url="http://cr.yp.to/syncookies.html">syncookies</ulink>.
	</para>
	<para>
Roberto Nibali <emphasis>ratz (at) tac (dot) ch</emphasis> 03 May 2001
	</para>
	<para>
It doesn't matter whether you're running an e-gov site or you mom's homepage.
You have to secure it anyway, because the webserver is not the only machine
on a net. A breach of the webserver will lead to a breach of the other
systems too.
	</para>
	<para>
Joe Sep 2005
	</para>
	<para>
As <ulink url="http://www.ranum.com/security/computer_security/editorials/dumb/">Marcus Ranum says</ulink>
(http://www.ranum.com/security/computer_security/editorials/dumb/)
"Worms aren't smart enough to realize that your web site/home network isn't interesting".
	</para>
	<para>
Joe 01 Oct 2002
	</para>
	<para>
Yes Virginia, you need security.
	</para>
	<para>
There's the technical level.
Can an intruder,
who gets beyond the firewall,
do any damage after getting access to the director,
the realservers?
If so, do you care?
Maybe you do, maybe you don't
- it will depend on what you have on those machines - if it's only
publically available (readonly) webpages, you're less concerned
than if you have customer business information on it.
	</para>
	<para>
Are there adjacent machines on the network,
that have more sensitive data than yours,
that could be attacked from your compromised machines?
You don't want to be an intermediate site to an attack on a expensive setup
in the next rack.
	</para>
	<para>
You may think that with a hardened front end,
backend machines need less protection.
However a new exploit we haven't thought about may be hop through a firewall
and land on one of the less protected machines behind it.
You should think about the damage that could occur if the attacker
gained root access to any of your machines.
LVS-DR is easier to protect in this case,
as packets from the attacker on a realserver
will be coming from the RIP,
while packets from the LVS'ed service will be coming from the VIP.
(If the realservers are in a <xref linkend="3-Tier_lvs"/> LVS,
then only the packets from the RIP on the realserver
to the external 3-Tier services should have routes.)
There should be no default gw on the realservers for packets from the RIPs.
Packets from the RIPs to 0:0 should be dropped (and logged).
The only allowed packets from the RIPs are those
needed for internal networking between the machine in the LVS
(<emphasis>e.g.</emphasis>local mailing of logs, updates to files).
These packets will have dst_addr as another machine on the RIP network.
On the director, there should be no default gw for packets
from the VIP (see <link linkend="Pearthree">routing for LVS-DR</link>).
The only way an attacker with root can send packets to the outside
world is by changing the routing tables (which you should be able to pickup).
	</para>
	<para>
But security is more than a technical thing.
How will your customers react if their website goes down,
gets defaced or has credit card info stolen?
You're going to have to explain that your actions were diligent
and the break-in was beyond anything that you could be expected to handle.
You then have to mollify them and make sure you keep the account.
You'll also have to explain to potential customers
why that humongous break-in that made it
to the front page of the NY Times for a week,
doesn't reflect poorly on you.
If these people are non-technical
(as most people with the money are)
this may be difficult.
	</para>
	<para>
It is just easier to make sure there never is a break-in.
Of course there's no end to the things you can do in this department,
so somewhere you'll have to decide what you're prepared to deal with upfront
at the keyboard and what your prepared to deal with at the backend,
after a break-in, face-to-face with an unhappy customer,
who is simultaneously dealing with his own unhappy customers.
To your client, you aren't a genius with a keyboard who understands computers.
Nope - you're the security guard they've hired to look after a warehouse
of their widgets and if you let someone get off with them,
they're not going to be terribly interested in your explanation
of why or how it happened.
	</para>
	<para>
I'd say the minimum for a production machine, exposed to the internet,
is a set of rules on each machine (director and realservers) that only allows
the packets needed for the LVS (by port, IP, proto) and drops the rest.
Every packet to and from a machine must be inspected by a filter rule.
Every rejected packet must be logged (at least till you find out where
they're coming from).
Routing should be designed to allow out, only the packets you want to go out
(outgoing packets are filtered by port and IP).
	</para>
	<para>
If you're being bombarded with malicious traffic (spam, DoS),
tcpdump is not a good diagnostic tool -
you will not be able to decipher the deluge.
Try <ulink url="http://www.snort.org/">snort</ulink>.
Here's an
<ulink url="http://www.unixreview.com/documents/s=1234/urm0106j/0106j.htm">
Introduction to Network-Based Intrusion Detection Systems Using Snort</ulink>.
	</para>
	<para>
Limit places where intruders can login (<emphasis>e.g.</emphasis> with xinetd).
For maintenance, don't login over the same networks that the LVS traffic
flows on (<emphasis>e.g.</emphasis>RIP network, outside network with VIP).
For maintenance/admin, only allow connection by ssh through a separate ethernet card
on a different set of wires and different network
(backed up with filter rules and xinetd),
or via the console.
	</para>
	</section>
	<section id="break_in">
	<title>What to do after a break-in, prevention strategies</title>
	<para>
In the early 1990's, a break-in was unusual and being a criminal act, 
some investigative body was notified (<emphasis>e.g.</emphasis> the police).
This being a new type of crime, usually the investigators had no idea how
to handle the situation.
At my work a multi cpu refrigerator sized mail server was compromised 
and the investigators swooped in and seized the server; 
<emphasis> not just the disk(s) - the whole server</emphasis>, 
and wheeled it out the door. 
We were told that the server would be returned on completion of
the investigations (and any trial if suspects were apprehended). 
On asking them when that might be, 
we were told that if they could not find any suspects, that the
machine would be returned when the case timed out, which would be 8yrs.
	</para>
	<para>
This was a big lesson to all involved.
The next break-in I was involved in, the machine wouldn't boot.
I reformatted the disk and
reinstalled the OS from CD and the user's files from backups.
When the investigators
arrived and asked to inspect the machine. 
I told them that the disk had been reformatted and offered them
the last tape backup. They didn't want it.
	</para>
	<para>
Subsequently I attended a talk by a /programmer/lawyer/cyber-investigator
from Washington DC, who worked for the US govt.
He told us that after a break-in we must not touch the machine
(it's tampering with evidence) and gave us a list of contacts.
At question time, 
I told him the story about the server being wheeled out the door
(which several people in the audience were familiar with),
and my reformatting of the disk on the machine I handled, 
at which he grew visibly angry.
I asked him if he expected us to call them if they
were going to take our hardware away
when they only needed to take a bitwise copy of the disks.
After all, the police don't seize your house after a burglary.
	</para>
	<para>
In his reply, it was clear that he recognised that such actions
by the investigators weren't optimal,
but as to what I should do next time, 
he only offered more standard party line and I decided 
that next time I wouldn't be calling anyone.
	</para>
	<para>
Following a set of Unix/Linux break-ins (Apr 2004), Stanford U put out
(link dead Jun 2004 http://securecomputing.stanford.edu/alerts/multiple-unix-6Apr2004.html)
&quot;Multiple Unix compromises on campus&quot;, describing their problems
and offering links to further pages (such as information on rootkits).
	</para>
	<para>
Unfortunately the current state of security is that much work is needed
to get it and much of the prevention work seems to be applying patches.
This is a lot of work and I can't imagine that it will prevent most break-ins.
I personally find tiresome the practice of forced passwd expiration every 3 months 
on the 30 accounts I have in several administrative fiefdoms.
I'm expected to keep them in my head when they 
are 8 char mixed uc/lc and contain at least 2 numbers.
Who are they kidding? I tape them to the edge of my monitor.
The article links to 
<ulink url="http://www.cert.org/tech_tips/root_compromise.html">
Steps for Recovering from a UNIX or NT System Compromise</ulink>
a CERT/AusCERT paper. 
It seems to have been written by people who like being
on committees and who want you to spend so much time securing your machine,
that you'll never be able to use it.
Unfortunately the people who make decisions about managing computers
have never dealt with a break-in and know nothing about security
will cover their asses (arses)
with a never ending round of patching. 
The result is that users have to suffer machines being rebooted 
from under them every 2 weeks 
(and loosing all the user settings), 
the SA never does anything useful
but when the inevitable break-in occurs
the manager can happily say to some committee 
"we did everything we could to prevent it".
	</para>
	<para>
My only interaction with CERT was not good.
One day (mid 1990s) I got vitriolic e-mail from a person announcing that 
he was one of the top AusCERT security experts, 
and that my map server 
(now at <ulink url="http://www.wm7d.net/azproj.shtml">AZ_PROJ map server</ulink>
and producing about 10,000 maps/yr)
was doing robotic attacks on his network.
If I didn't cease and desist immediately, a dire fate would befall me.
	</para>
	<para>
Now if there was some problem with my machine and I had come to the 
notice of CERT, I would expect a letter from CERT saying
	</para>
	<blockquote>
<programlisting><![CDATA[
Dear Sir,

	It has come to our notice that your machine (IP=xxx.xxx.xxx.xxx)
has been sending these packets (logs enclosed) to machines (n1...nx).
Since these aren't part of the expected packet stream, we're concerned
that there may be some problem. Do you know anything about this?

	This is a routine letter and indicates the beginning
of an investigation into a problem and can be tracked at
url/case_number. 

	Hopeing to hear from you.
	Thank you
	Your friendly CERT representative
]]></programlisting>
	</blockquote>
	<para>
I assumed I was talking to a crazed idiot.
	</para>
	<para>
The next day I got an even more vitriolic e-mail from the same guy, promising
me certain internet death if I didn't stop attacking his machines.
Somewhere in here, he sent me logs, whose relevance to the problem was not obvious
at the time.
	</para>
	<para>
Then I got e-mail from a user of my map generator saying that it had stopped
working for him and could I help. 
The map generator produced azimuthal equidistant projection maps in many formats,
including an X-client which could popup an X-window map on your screen
(there were instructions on setting xhost etc).
The user was having problems getting the X-display of my maps
going, when previously it had worked.
AFAIK, no-one was using the X-client and I had forgotten it was there
(everyone was generating gifs). 
Somehow (IPs?) I connected this user to the AusCERT expert.
I told the user what to do and then sent off e-mail to the CERT expert, 
giving the url of my map generator and telling him to go look at what it did.
	</para>
	<para>
This only inflammed the CERT security expert more and shortly thereafter
I got e-mail from an even higher level AusCERT uber-expert telling
me that I'd been listed as one of the biggest internet nasties
of all time and that no-one was ever going to get a packet in or out
of my machine ever again.
	</para>
	<para>
I explained to the uber-expert what my machine was doing and that 
that he was probably getting X-packets from my server and to go try it out
for himself.  
	</para>
	<para>
There was silence for a couple of days, and then a rash of apologies
from both CERT experts. 
There was no indication that they had learned anything from this
or would change their methods next time.
	</para>
	<para>
The fact that the top CERT experts in Australia don't
know an X-packet from a hole in the wall and are prepared to
declare internet death on someone without an investigation
(courteous or otherwise),
indicates that we shouldn't hold out much hope of CERT saving us from anything.
If CERT can save us from CERT, we should be thankfull.
	</para>
	</section>
	<section id="syncookies">
	<title>More about syncookies</title>
	<para>
anon
	</para>
	<blockquote>
humans usually do not establish SYN connection.
It is more likley to be Nimda or other worms.
If I can determine a threshold of simultenious SYN
connection that nimda usually creates, I will be able to drop packets
from specific source IP which meet the threshold.
	</blockquote>
	<para>
Roberto Nibali <emphasis>ratz (at) tac (dot) ch</emphasis>
06 Aug 2003
	</para>
	<para>
Search google using my name and syncookies for more information
on why syncookies have no measurable impact on reducing real DoS.
	</para>
	<para>
If you can _really_ figure out a metric for mutually exclusive TCP/SYN patterns
generated by existing worms and write it down in a mathematical formula which
has lower false positive rate than any TCP/QoS "defense" mechanism using
stochastic (timed) fairness approach, you need not worry about
money anymore. In fact influential people in the
Internet business might feel a sudden urge to talk to you! ;)
	</para>
	</section>
	<section id="can_rules_stop_the_intruder_hopping_to_other_machines">
	<title>Can filter rules stop the intruder hopping to other machines?</title>
	<para>
Malcolm Turnbull <emphasis>malcolm (dot) turnbull (at) crocus (dot) co (dot) uk</emphasis> 14 Feb 2003
	</para>
	<para>
Nope, if you're hacked they can just change your firewall rules...
One of my clients got hacked and the only way they found out was because
the hacker (possibly script kiddy) tried to flush the iptables rules,
therfore breaking all of the NAT rules therefore taking down the web site...
	</para>
	<para>
How did he get in: broke into IIS through common bug, installed a
trojan, used SSH to get from the web server to the firewall .. etc etc...
	</para>
	<para>
Even if you put the LVS behind a firewall (which I prefer) you still
need to open port 80... is it secure ? yes I think so hackers tend to
concentrate on application i.e. apache or IIS these days its much easier..
	</para>
	<para>
One other gotcha.. If your fallback server is localhost you are
obviously exposing your local apache installation !
	</para>
	<para>
Nate Carlson <emphasis>natecars (at) real-time (dot) com</emphasis>
	</para>
	<blockquote>
the firewall should be configured so untrusted hosts
(<emphasis>e.g</emphasis>the web server -- any box that isn't the box that
people are expected to log in from) can't connect to the SSH port
(or any other service) on the firewall.
	</blockquote>
	</section>
	<section id="where_filter_rules_act">
	<title>Where filter rules act</title>
	<para>
Joe - iptables (2.4 kernels) has no "iptables -C" to check your rules (at least
not yet - one is promised).
	</para>
	<para>
Ratz
	</para>
	<para>
If you're dealing with netfilter,
packets don't travel through all chains anymore.
Julian once wrote something about it:
	</para>
	<para>
packets coming from outside to the LVS do:
	</para>
<programlisting><![CDATA[
PRE_ROUTING -> LOCAL_IN(LVS in) -> POST_ROUTING
]]></programlisting>
	<para>
packets leaving the LVS travel:
	</para>
<programlisting><![CDATA[
PRE_ROUTING -> FORWARD(LVS out) -> POST_ROUTING
]]></programlisting>
	<para>
From the iptables howto: COMPATIBILITY WITH IPCHAINS
	</para>
	<para>
This iptables is very similar to ipchains by Rusty Russell.
The main difference is that the chains INPUT and
OUTPUT are only traversed for packets coming into the
local host and originating from the local host respectively.
Hence every packet only passes through one of the
three chains; previously a forwarded packet would pass
through all three.
	</para>
	<para>
Julian
	</para>
	<itemizedlist>
		<listitem>
		<para>
2.4 director:
		</para>
		<para>
Packets coming into the director (out->in):
		</para>
		<itemizedlist>
			<listitem>
NAT: INPUT -> input routing -> local: LVS/DEMASQ -> input routing -> forwarding -> OUTPUT
			</listitem>
			<listitem>
DR/TUN: INPUT -> input routing -> local: LVS -> output routing -> OUTPUT
			</listitem>
		</itemizedlist>
		<para>
packets leaving the LVS travel (in->out):
		</para>
		<itemizedlist>
			<listitem>
			<para>
NAT only: INPUT -> input routing -> FORWARD (-j MASQ) -> LVS/MASQ -> OUTPUT
			</para>
			</listitem>
		</itemizedlist>
		</listitem>
		<listitem>
		<para>
2.2 director:
		</para>
		<para>
INPUT in 2.2 is similar as PRE_ROUTING in 2.4, i.e. INPUT,
OUTPUT and FORWARD are the 2.2 firewall chains
		</para>
<programlisting><![CDATA[
input routing: ip_route_input()
output routing: ip_route_output()
forwarding: ip_forward()
local: ip_local_deliver()
]]></programlisting>
		</listitem>
	</itemizedlist>
	<para>
Matthew S. Crocker <emphasis>matthew (at) crocker (dot) com</emphasis> 31 Aug 2001
	</para>
	<blockquote>
How do I filter LVS? Does LVS grab the packets before or after iptables?
	</blockquote>
	<para>
Julian
	</para>
	<para>
LVS is designed to work after any kind of firewall rules.
So, you can put your ipchains/iptables rules safely.
If you are using iptables put them on LOCAL_IN, not on FORWARD.
The LVS packets do not go through FORWARD.
	</para>
	<note>
	<para>
Although LVS is compatible with any kind of filter rule (<emphasis>i.e.</emphasis>
ipchains, iptables), it has incompatibilities with netfilter
<emphasis>i.e.</emphasis> you maynot be able to have your firewall on the director.
For more info see the
<xref linkend="LVS-HOWTO.filter_rules"/>.
	</para>
	</note>
	<para>
Joe
	</para>
	<para>
If you are being attacked, it might be better to filter upstream (<emphasis>e.g.</emphasis>
the router or your ISP), to prevent the LAN from being flooded.
	</para>
	</section>
	<section id="proc_filesystem" xreflabel="/proc filesystem flags">
	<title>/proc filesystem flags for ipv4, <emphasis>e.g.</emphasis>rp_filter</title>
	<para>
You could wind up flipping a lot of these flags.
Explanations are available in the obscure section of the
<ulink url="http://en.tldp.org/HOWTO/Adv-Routing-HOWTO/lartc.kernel.obscure.html">
Adv Routing HOWTO
</ulink>.
In particular rp_filter and log_martians are used in
<xref linkend="LVS-DR_director_default_gw"/>.
For more information on <filename>rp_filter</filename> see
<ulink url="http://en.tldp.org/HOWTO/Adv-Routing-HOWTO/lartc.kernel.rpf.html">
Reverse Path Filtering
</ulink>.
	</para>
	</section>
	<section id="tcp_timeouts_dont_change_them">
	<title>tcp timeout values, don't change them (at least yet)</title><para>
The tcp timeout values have their values for good reason
(even if you don't know what they are), and realservers
operating as an LVS must appear as normal tcp servers to
the clients.
	</para>
	<para>
Wayne, 19 Oct 2001
	</para>
	<blockquote>
 I have a question about the 'IP_MASQ_S_FIN_TIMEOUT"
 values in "net/ipv4/ip_masq.c" for the 2.2.x
 kernel. What purpose is served by having the
 terminated masqueraded TCP connection entries
 remain in memory for the default timeout of 2
 minutes? Why isn't the entry freed immediately?
	</blockquote>
	<para>
Julian Anastasov <emphasis>ja (at) ssi (dot) bg 20 Oct 2001</emphasis>
	</para>
	<para>
Because the TCP connection is full-duplex.
The internal-end sends FIN and waits for the FIN from
external host. Then TIME_WAIT is entered.
	</para>
	<blockquote>
		<para>
Perhaps what I'm really asking is why there
is an mFW state at all.
		</para>
<programlisting><![CDATA[
[IP_MASQ_S_FIN_WAIT] = 2*60*HZ,
/* OUTPUT */
/* mNO, mES, mSS, mSR, mFW, mTW, mCL, mCW, mLA, mLI */
/*syn*/ {{mSS, mES, mSS, mSR, mSS, mSS, mSS, mSS, mSS, mLI }},
/*fin*/ {{mTW, mFW, mSS, mTW, mFW, mTW, mCL, mTW, mLA, mLI }},
/*ack*/ {{mES, mES, mSS, mES, mFW, mTW, mCL, mCW, mLA, mES }},
/*rst*/ {{mCL, mCL, mSS, mCL, mCL, mTW, mCL, mCL, mCL, mCL }},
};
/mFW
]]></programlisting>
	</blockquote>
	<para>
	This state has timeout corresponding to
the similar state in the internal end. The remote
end is still sending data while the internal side is
in FIN_WAIT state (after a shutdown). The remote end
can claim that it is still in established state not
seeing the FIN packet from internal side. In any case,
the remote end has 2 minutes to reply. It can even
work for longer time if each packet follows in these
two minutes not allowing the timer to expire. It
depends in what state is the internal end, FIN_WAIT1
or FIN_WAIT2. May be the socket in the internal end is
already closed.
	</para>
	<blockquote>
The only thing I can
 think of is if the other end of the TCP connection
 spontaneously issues a half close before the
 initiator sends his half close. Then it might
 be desirable to wait a while for the initiator
 to send his half close prior to disposing of
 the connection totally. What would be the
 consequences of using <command>ipchains -M -S</command> to set this
 value to, say, 1 second?
	</blockquote>
	<para>
	In any case, timeout values lower than those in
the internal hosts are not recommended. If we drop the
entry in LVS, the internal end still can retransmit
its FIN packet. And the remote end has two minutes to
flush its sending queue and to ack the FIN.
IMO, you should claim that the timer in FIN_WAIT state
should not be restarted on packets coming from remote end.
Anything else is not good because it can drop valid packets that
fit into the normal FIN_WAIT time range.
	</para>
	<para>
Jaroslav Libak 28 Nov 2006
	</para>
	<blockquote>
When I click refresh in firefox several times while viewing load
balanced page, I get a FIN_WAIT connection for every refresh. So I
set tcpfin parameter using ipvsadm to 15 seconds to get rid of them
fast (is this ok btw?, it was like 2 minutes before which I think is
way too long).
What is worse, I get "established" connection on the backup director (running
the syncd) for every refresh.  
I have read this is due to a simplification in the
synchronization code.
I'm using hash table size 2^20 (which doesn't limit the maximum
number of values in it, it just sets the number of rows, then each
row has a linked list). Doesn't it cause some slowdown in the LVS?
	</blockquote>
	<para>
Horms  29 Nov 2006
	</para> 
	<para>
There has long been a plan to allow the timeout values to be manipulated
from user space. I think it actually was possible using <filename>/proc</filename> at some
stage, but the code was removed for various (good) reasons. Then there
was a plan to implement the feature by extending the <filename>sysctl</filename> interface.
I suspect that this, or using <filename>sysfs</filename> is currently the prefered option
by the upstream kernel guys.
	</para>
	<para>
A really worthwhile contribution to LVS would be to complete this
code. I can find out from the upstream people what their prefered option
for implementing this is if you are interested in having a crack at it.
I don't imagine the code will be that hard.
	</para>
	<para>
I understand that your concern is memory preasure on the slave in
the case of a DoS attack. And it is true that the simplification
in the synchronisation protocol can exasabate that problem.
However, by doing it this way the synchronisatin traffic is actually
reduced, including in the case of a DoS attack. So expanding it
may actually just move the problem else where. 
	</para>
	<para>
Keeping in mind that a connection entry is in the vicintity of 128
bytes, it is my opinion that unless you have an extremely small ammount
of memory available on the system to start with, DoSing the machine in
this way is quite hard. I did try once, DoSing a box from istelf, and
basically the default timeouts were easily able to keep up with the DoS,
and I think the total memory used never exceded a few hundred Mb.
	</para>
	<para>
I would be very surprised if increasing the value would cause a
slowdown, it does however increase the memory required for the array that
forms the base of the hash - at 2^20 you are looking at order 2^20 = 1Mb
for the size of that array. For larger values, like 32 (=4Gb), this
starts to become rediculous. Decreasing it can, in theory, cause a
slowdown if you have a lot of connections. But in practice I don't think
it does unless you make it very small.
	</para>
	<para>
In short, 20 should be fine, though you can probably get
the same preformance with 16. 10 is probably a bit too small.
	</para>
	</section>
	<section id="security_proc_filesystem" xreflabel="tcp timeouts and the private copies of these timeouts for ipvs">
	<title>/proc file system settings for LVS: security and private copies of tcp timeouts for LVS connections (you can change these)</title>
	<para>
In LVS-DR, the director only sees the packets from the client going
to the realserver, but not the replies. After seeing a CLOSE,
the director puts the connection into InActConn and uses its value
of TIME_WAIT before assuming that the connection has dropped.
(In fact the director has no idea of the connection state of the
realserver, but these assumptions seems to work OK).
In the earlier versions of LVS, the director uses the standard
tcpip timeouts for its estimates of the connection state of the
realserver. In the newer versions of LVS (somewhere in 2.4.x), 
you can fiddle with a set
of private copies of the timeout values which ip_vs uses for
LVS connection tracking.
	</para>
	<para>
As well other ip_vs parameters (<emphasis>e.g.</emphasis> for security)
can be altered in <filename>/proc</filename>.
	</para>
	<para>
Roberto Nibali <emphasis>ratz (at) tac (dot) ch</emphasis> 03 May 2001
	</para>
	<blockquote>
	<para>
The load balancer is basically on as secure as Linux itself is.
<command>ipchains</command> settings don't affect LVS functionality
(unless by mistake you use the same mark for 
<command>ipchains</command> and <command>ipvsadm</command>).
LVS itself has some built-in security, mainly to try to
secure the realserver in case of a DoS attack.
There are several parameters you might want to set in the proc-fs.
	</para>
	<note>
		<para>
Ratz 10 Aug 2004
		</para>
		<para>
Those values below were used as kind of a defense mechanism in the ancient days.
I believe these are to be replaced by the same parameters 
exported through the ip_conntrack module.
Load ip_conntrack and walk the /proc/sys/net/ipv4/netfilter tree.
		</para>
	</note>
	<itemizedlist>
		<listitem>
/proc/sys/net/ipv4/vs/amemthresh
		</listitem>
		<listitem>
/proc/sys/net/ipv4/vs/am_droprate
		</listitem>
		<listitem>
/proc/sys/net/ipv4/vs/drop_entry
		</listitem>
		<listitem>
/proc/sys/net/ipv4/vs/drop_packet
		</listitem>
		<listitem>
/proc/sys/net/ipv4/vs/secure_tcp
		</listitem>
		<listitem>
		<para>
/proc/sys/net/ipv4/vs/debug_level
		</para>
		<para>
With this you select the debug level (0: no debug output, >0: debug
output in kernlog, the higher the number to higher the verbosity)
		</para>
		<para>
The following are timeout settings. For more information see
TCP/IP Illustrated Vol. I, R. Stevens.
		</para>
		</listitem>
		<listitem>
/proc/sys/net/ipv4/vs/timeout_close - CLOSE
		</listitem>
		<listitem>
/proc/sys/net/ipv4/vs/timeout_closewait - CLOSE_WAIT
		</listitem>
		<listitem>
/proc/sys/net/ipv4/vs/timeout_established - ESTABLISHED
		</listitem>
		<listitem>
/proc/sys/net/ipv4/vs/timeout_finwait - FIN_WAIT
		</listitem>
		<listitem>
/proc/sys/net/ipv4/vs/timeout_icmp - ICMP
		</listitem>
		<listitem>
/proc/sys/net/ipv4/vs/timeout_lastack - LAST_ACK
		</listitem>
		<listitem>
/proc/sys/net/ipv4/vs/timeout_listen - LISTEN
		</listitem>
		<listitem>
/proc/sys/net/ipv4/vs/timeout_synack - SYN_ACK
		</listitem>
		<listitem>
/proc/sys/net/ipv4/vs/timeout_synrecv - SYN_RECEIVED
		</listitem>
		<listitem>
/proc/sys/net/ipv4/vs/timeout_synsent - SYN_SENT
		</listitem>
		<listitem>
/proc/sys/net/ipv4/vs/timeout_timewait - TIME_WAIT
		</listitem>
		<listitem>
/proc/sys/net/ipv4/vs/timeout_udp - UDP
		</listitem>
	</itemizedlist>
	<para>
You don't want your director replying to pings from the outside world.
	</para>
	</blockquote>
	<para>
With the FIN timeout being about 1 min (2.2.x kernels),
if most of your connections are non-persistent http (only
taking 1 sec or so), most of your connections will be in the
InActConn state.
	</para>
	<para>
unknown
	</para>
	<blockquote>
will the info from loading ip_conntrack 
and walking the <filename>/proc/sys/net/ipv4/netfilter</filename>
tree 
be used
along with secure_tcp defense strategy as
<ulink url="http://www.linux-vs.org/docs/defense.html">LVS DoS defense strategy</ulink> 
(http://www.linux-vs.org/docs/defense.html) 
described to replace the timeouts mentioned.
	</blockquote>
	<para>
Ratz 12 Aug 2004
	</para>
	<para>
I don't know (I've been out of the development loop for about a year) 
but I rather think not since they look kind of orthogonal to the 
existing netfilter timers which only got added about 6 months or so ago. 
One of the issues in fiddling with those timers is that they influence 
too much of the rest of the stack.
	</para>
	<para>
I also don't think the documentation is up to date anymore, it should be 
adjusted to reflect the current state of operation. Like that it only 
confuses people who don't want or can't read the kernel code.
	</para>
	<para>
If you're interested, check out following path:
	</para>
<programlisting><![CDATA[
net/ipv4/ipvs/ip_vs_ctl.c:ip_vs_sysctl_defense_mode()
net/ipv4/ipvs/ip_vs_ctl.c:update_defense_level()
net/ipv4/ipvs/ip_vs_ctl.c:ip_vs_secure_tcp_set()
net/ipv4/ipvs/ip_vs_conn.c:"set state table, according to proc-fs value"
]]></programlisting>
	<para>
from there you set the TCP state transition table. If you have the 
secure_tcp sysctl set, the kernel will be dealing with the 
vs_tcp_states_dos state transition table, if you have it unset, it will 
be dealing with the normal vs_tcp_states table.
	</para>
	<para>
The related timer for the state transitions are vs_timeout_table{_dos}. 
In former days you could influence those timers via proc-fs. Nowadays we 
seem to switch to the *_dos timer model under attack according to the 
comment in the code. But this is not correct. It should read that as 
soon as the sysctrl for tcp_defense is set, we will also be using the 
*_dos table timers along with the vs_tcp_states_dos state transition table.
	</para>
	<para>
Conclusion: The disabled proc-fs values have been replace by a static 
hardcoded mapping of the timers for tcp_defense. I could imagine that 
not a lot of people really used to tweak those parameters anyway.
	</para>
	<para>
Hendrik Thiel, 20 Mar 2001
	</para>
	<blockquote>
		<para>
 we are using a lvs in NAT Mode and everything works fine ...
 Probably, the only Problem seems to be the huge number of  (idle)
 Connection Entries.
		</para>
		<para>
 <command>ipvsadm</command> shows a lot of InActConn (more than 10000 entries per
 Realserver)  entries.
<command>ipchains -M -L -n</command> shows that these connections last 2 minutes.
 Is it possible to reduce the time to keep the Masquerading Table
 small? <emphasis>e.g.</emphasis> 10 seconds ...
		</para>
	</blockquote>
	<para>
Joe
	</para>
	<para>
For 2.2 kernels, you can use <command>netstat -M</command> instead of 
<command>ipchains -M -L</command>. For 2.4.x kernels
use <command>cat /proc/net/ip_conntrack</command>.
	</para>
	<para>
Julian
	</para>
	<para>
One entry occupies 128 bytes. 10k entries mean 1.28MB memory.
This is not a lot of memory and may not be a problem.
	</para>
	<para>
For 2.2, to reduce the number of entries in the <command>ipchains</command> table, you
can reduce the timeout values.
You can edit the TIME_WAIT, FIN_WAIT values in ip_masq.c, or enable the
<ulink url="http://www.linuxvirtualserver.org/docs/defense.html">secure_tcp strategy</ulink>
and alter the proc values there.
FIN_WAIT can also be changed with ipchains.
	</para>
	<note>
	<para>
It is not a good idea to change the tcpip timeouts (particularly to save 1M).
	</para>
	</note>
	<para>
With the later versions of ip_vs (2.4.x), the director has its own copies
of the tcpip timeout values, and you can change them.
	</para>
	<para>
Francois JEANMOUGIN <emphasis>Francois (dot) JEANMOUGIN (at) 123multimedia (dot) com</emphasis> 10 May 2004
	</para>
	<para>
If you are concerned about the number of InActConn, 
you can reduce the
FIN_WAIT timeout in <filename>/proc/sys/net/ipv4/vs/timeout_finwait</filename>.
	</para>
	<para>
For 2.6.x versions of ip_vs (May 2004), the timeouts have not been implemented yet.
	</para>
	<para>
Julian 12 May 2004 
	</para>
	<para>
	IPVS for 2.6 has code to use different timeout tables but we
forgot to implement it fully. The intention was to implement
per protocol/service/app timeouts by adding some code to
libipvs and the kernel. It is not preferred to export so many values
via /proc interface, so now it is disabled until someone decides
to implement the above set/get controls.
	Only the timeout_* values in <filename>/proc</filename>are disabled, 
so now they do not
exist in 2.6. All other sysctls remain.
	</para>
	</section>
	<section id="timeout_by_service">
	<title>timeouts the same for all services</title>
	<para>
Alois Treindl <emphasis>alois (at) astro (dot) ch</emphasis>
	</para>
	<blockquote>
I have LVS-NAT configured so that ssh VIP connects me to
one particular realserver.
I would like to keep this ssh connection permanent,
(to observe the cluster during its operation).
This ssh connection times out with inactivity as expected.
Can this be changed, without affecting the timeout values of other LVS
services?
Alternately I can connect by ssh to each machine without using
LVS.
	</blockquote>
	<para>
Julian Anastasov <emphasis>ja (at) ssi (dot) bg</emphasis> 12 May 2001
	</para>
	<para>
	Currently, there are only global timeout values which are
not very useful for some boxes with mixed functions. The masquerading,
the LVS and its virtual services use same timeout values. The problem
is that there are too many timeouts.
	</para>
	<para>
	The solution would be to separate these timeouts, i.e. per
virtual service timeouts, separated from the masquerading. According
to the virtual service protocol it can serve the TCP EST and the UDP
timeout role. So this can be one value that will be specified
from the users. By this way the in->out ssh/telnet/whatever connections
can use their own timeout (1/10/100 days) and the external clients
will use the standard credit of 15 minutes. But may be it is too late
for 2.2 to change this model. Is one user specified timeout value enough?
	</para>
	</section>
	<section id="hash_table">
	<title>Director Connection Hash Table</title>
	<note>
Because the 2.0.x implementation of ip_vs was in the masquerading code,
this table used to be called the "IP masquerading table".
	</note>
	<note>
Joe: A regular table has room for N entries, with an index of range N.
A hash table is a table that has room for N entries, but 
stores entries for indices that have a range of M, where M&gt;N.
In the case of LVS, the connection hash table must store entries 
over the whole range of internet IPs, but only has (initially) 4096 (say) entries.
Algorithms exist which allow adding and deleting entries in hash
tables at speeds comparable to those in regular tables.
	</note>
	<para>
from Peter Mueller:
a general article on hashing
(http://www.citi.umich.edu/projects/linux-scalability/reports/hash.html, site gone Sep 2004)
	</para>
	<para>
The director maintains a hash table of connections marked with
	</para>
<programlisting><![CDATA[
<CIP, CPort, VIP, VPort, RIP, RPORT>
]]></programlisting>
	<para>
where
	</para>

	<itemizedlist>
		<listitem>
CIP:    Client IP address
		</listitem>
		<listitem>
CPort:  Client Port number
		</listitem>
		<listitem>
VIP:    Virtual IP address
		</listitem>
		<listitem>
VPort:  Virtual Port number
		</listitem>
		<listitem>
RIP:    RealServer IP address
		</listitem>
		<listitem>
RPort:  RealServer Port number.
		</listitem>
	</itemizedlist>
	<para>
The hash table speeds up the connection lookup and
keeps state so that packets belonging to a connection
from the client will be sent to the allocated realserver.
If you are editing the .config by hand look for CONFIG_IP_MASQUERADE_VS_TAB_BITS.
	</para>
	<warning>
		<para>
Do not even think of changing the LVS (hash) table size
unless you know a lot more about ip_vs than we do.
If you still want to change the hash table size,
at least read everything here first.
		</para>
	</warning>
	<para>
tao cui
	</para>
	<blockquote>
		<para>
In the output of <command>ipvsadm</command>
what does the "size" mean?
		</para>
<programlisting><![CDATA[
IP Virtual Server version 1.0.9 (size=4096)

or

IP Virtual Server version 1.0.9 (size=65536)
]]></programlisting>
	</blockquote>
	<para>
Horms 24 Dec 2003
	</para>
	<para>
This refers to the number of hash buckets in the IPVS connection table.
This is configured at compile time by setting CONFIG_IP_VS_TAB_BITS,
the default is 12.
	</para>
<programlisting><![CDATA[
size = 2^CONFIG_IP_VS_TAB_BITS

Thus CONFIG_IP_VS_TAB_BITS = 12 -> size = 4096
     CONFIG_IP_VS_TAB_BITS = 16 -> size = 65536
]]></programlisting>
	<para>
Note that this is the number of hash buckets, not the maximum
number of connections. A bucket can contain zero or more connections.
The maximum number of connections is only limited by the memory
available.
	</para>

	<para>
Janno de Wit
	</para>
	<blockquote>
How can I see if connectiontable is full? `dmesg` gives no output.
	</blockquote>
	<para>
Horms 07 Jan 2005
	</para>
	<para>
The connection table cannot become full. It is a hash table
and you can continue to add entries until you run out of memory,
at which time something very apparent should turn up in dmsg.
	</para>
	<para>
Ratz
	</para>
	<para>
The original poster actually has got a point :)
So what about this:
	</para>
	<note>
partial diff shown for brevity - Joe
	</note>
<programlisting><![CDATA[
diff -Nur linux-2.4.23-preX-orig/net/ipv4/ipvs/ip_vs_conn.c
linux-2.4.23-preX-ratz/net/ipv4/ipvs/ip_vs_conn.c
--- linux-2.4.23-preX-orig/net/ipv4/ipvs/ip_vs_conn.c   2003-11-03
17:26:50.000000000 +0100
+++ linux-2.4.23-preX-ratz/net/ipv4/ipvs/ip_vs_conn.c   2003-12-24
09:21:37.000000000 +0100
@@ -1519,7 +1519,7 @@

         IP_VS_INFO("Connection hash table configured "
-                  "(size=%d, memory=%ldKbytes)\n",
+                  "(hash buckets=%d, memory=%ldKbytes)\n",
                    IP_VS_CONN_TAB_SIZE,
                    (long)(IP_VS_CONN_TAB_SIZE*sizeof(struct
list_head))/1024);
         IP_VS_DBG(0, "Each connection entry needs %d bytes at least\n",

diff -Nur linux-2.4.23-preX-orig/net/ipv4/ipvs/ip_vs_ctl.c
linux-2.4.23-preX-ratz/net/ipv4/ipvs/ip_vs_ctl.c
--- linux-2.4.23-preX-orig/net/ipv4/ipvs/ip_vs_ctl.c    2003-11-03
17:26:50.000000000 +0100
+++ linux-2.4.23-preX-ratz/net/ipv4/ipvs/ip_vs_ctl.c    2003-12-24
09:22:47.000000000 +0100
@@ -1488,7 +1488,7 @@
         pos = 192;
         if (pos > offset) {
                 sprintf(temp,
-                       "IP Virtual Server version %d.%d.%d (size=%d)",
+                       "IP Virtual Server version %d.%d.%d (hash
buckets=%d)",
                         NVERSION(IP_VS_VERSION_CODE), IP_VS_CONN_TAB_SIZE);
                 len += sprintf(buf+len, "%-63s\n", temp);
                 len += sprintf(buf+len, "%-63s\n",
@@ -1942,7 +1942,7 @@
         {
                 char buf[64];

-               sprintf(buf, "IP Virtual Server version %d.%d.%d (size=%d)",
+               sprintf(buf, "IP Virtual Server version %d.%d.%d (hash
buckets=%d)",
                         NVERSION(IP_VS_VERSION_CODE), IP_VS_CONN_TAB_SIZE);
                 if (*len < strlen(buf)+1) {
                         ret = -EINVAL;
]]></programlisting>
	<para>
The default LVS <link linkend="hash_table">hash table</link>
size (2^12 entries) originally meant 2^12 simultanous connections.
These early versions of ipvs would crash your machine if you alloted too much
memory to this table.
	</para>
	<para>
Julian 7 Jun 2001
	</para>
	<blockquote>
This was because the resulting bzImage was too big.
Users selected a value too big for the hash table
and even the empty table (without linked connections)
couldn't fit in the available memory.
	</blockquote>
	<para>
This problem has been fixed in kernels&gt;0.9.9 with the connection
table being a linked list.
	<note>
Note: If you're looking for memory use with "top",
it reports memory allocated, not memory you are using.
No matter how much memory you have,
Linux will eventually allocate all of it as you continue to run
the machine and load programs.
	</note>
	</para>
	<para>
Each connection entry takes 128 bytes, 2^12 connections requires 512kbytes.
	<note>not all connections are active - some are waiting to timeout.
	</note>
	</para>
	<para>
As of ipvs-0.9.9 the hash table is different.
	</para>
	<para>
Julian Anastasov <emphasis>uli (at) linux (dot) tu-varna (dot) acad (dot) bg</emphasis>
	</para>
	<blockquote>
	<para>
With CONFIG_IP_MASQUERADE_VS_TAB_BITS we specify not the max
number of the entries (connections in your case) but the number of the
rows in a hash table. This table has columns which are unlimited. You can
set your table to 256 rows and to have 1,800,000 connections in
7000 columns average. But the lookup is slower. The lookup function
chooses one row using hash function and starts to search all these
7000 entries for match. So, by increasing the number of rows we want
to speedup the lookup. There is _no_ connection limit. It depends on the
free memory. Try to tune the number of rows in this way that the
columns will not exceed 16 (average), for example. It is not fatal if
the columns are more (average) but if your CPU is fast enough this is not
a problem.
	</para><para>
All entries are included in a table with (1 &lt;&lt; IP_VS_TAB_BITS)
rows and unlimited number of columns. 2^16 rows is enough. Currently,
LVS 0.9.7 can eat all your memory for entries (using any number of rows).
The memory checks are planned in the next LVS versions (are in 0.9.9?).
	</para>
	</blockquote>
	<para>
Julian 7 Jun 2001
	</para>
	<blockquote>
	<para>
	Here is the picture:
	</para>
	<para>
the hash table is an array of double-linked list heads, i.e.
	</para>
	<para>
struct list_head *ip_vs_conn_tab;
	</para>
	<para>
	In some versions ago ( &lt; 0.9.9? ) it was a static array, i.e.
	</para>
	<para>
struct list_head ip_vs_table[IP_VS_TAB_SIZE];
	</para>
	<para>
struct list_head is 8 bytes (d-linked list), the next and prev pointers
	</para>
	<para>
        In the second variant when IP_VS_TAB_SIZE is selected too high
the kernel crashes on boot. Currently (the first variant),
vmalloc(IP_VS_TAB_SIZE*sizeof(struct list_head)) is used to allocate
the space for the empty hash table for connections. Once the table
is created, more memory is allocated only for connections, not for the
table itself.
	</para>
	<para>
	In any case, after boot, before any connections are created,
the occupied memory for this empty table is IP_VS_TAB_SIZE*8 bytes.
For 20 bits this is (2^20)*8 bytes=8MB. When we start to create
connection they are enqueued in one of these 2^20 double-linked
lists after evaluating a hash function. In the ideal case you can
have one connection per row (a dream), so 2^20 connections. When I'm
talking about columns, in this example we have 2^20 rows and
average 1 column used.
	</para>
	<para>
	The *TAB_BITS define only
the number of rows (the power of 2 is useful to mask the hash function
result with the IP_VS_TAB_SIZE-1 instead of using '&percnt;' module operation).
But this is not a limit for the number of connections. When the
value is selected from the user, the real number of connections must
be considered. For example, if you think your site can accept
1,000,000 simultaneous connections, you have to select such number
of hash rows that will spread all connections in short rows. You
can create these 1,000,000 conns with TAB_BITS=1 too but then all
these connections will be linked in two rows and the lookup process
will take too much time to walk 500,000 entries. This lookup is
performed on each received packet.
	</para>
	<para>
	The selection of *TAB_BITS is entirely based on the
recommendation to keep the d-linked lists short (less than 20, not
500,000). This will speedup the lookup dramatically.
	</para>
	<para>
	So, for our example of 1,000,000 we must select table with
1,000,000/20 rows, i.e. 50,000 rows. In our case the min TAB_BITS
value is 16 (2^16=65536 >= 50000). If we select 15 bits (32768 rows)
we can expect 30 entries in one row (d-linked list) which increases
the average time to access these connections.
	</para>
	<para>
	So, the TAB_BITS selection is a compromise between the
memory that will use the empty table and the lookup speed in one
table row. They are orthogonal. More rows => More memory => faster
access. So, for 1,000,000 entries (which is an real limit for 128MB
directors) you don't need more than 16 bits for the conn hash table.
And the space occupied by such empty table is 65536*8=512KBytes.
Bits greater than 16 can speedup the lookup more but we waste too
much memory. And usually we don't achieve 1,000,000 conns with 128MB
directors, some memory is occupied for other things.
	</para>
	<para>
	The reason to move to vmalloc-ed buffer is because an 65536-row
table occupies 512KB and if the table is statically defined in the
kernel the boot image is with 512KB longer which is obviously very
bad. So, the new definition is a pointer (4 bytes instead of 512KB
in the bzImage) to the vmalloc'ed area.
	</para>
	<para>
Ratz's code adds limits per service while this sysctl can
limit everything. Or it can be additional strategy (oh, another one)
vs/lowmem. The semantic can be "Don't allocate memory for new connections
when the low memory threshold is reached". It can work for the
masquerading connections too (2.2). By this way we will reserve memory
for the user space. Very dangerous option, though.
	</para>
	</blockquote>
	<para>
Joe
	</para>
	<para>
what's dangerous about it?
	</para>
	<blockquote>
	<para>
One user process can allocate too much memory and to cause
the LVS to drop new connections because the lowmem threshold is reached.
	</para><para>
May be conn_limit is better or something like this:
	</para>
<programlisting><![CDATA[
if (conn_number > min_conn_limit && free_memory < lowmem_thresh)
         DROP_THIS_PACKET_FOR_NEW_CONN
]]></programlisting>
	</blockquote>
	<para>
why have a min_conn_limit in here? If you put more memory into the director,
hen you'll have to recompile your kernel. Is it because finding
conn_number is cheaper than finding free_memory?
	</para>
	<blockquote>
	<para>
	:) The above example with real numbers:
	</para>
<programlisting><![CDATA[
if (conn_number > 500000 && free_memory < 10MB) DROP
]]></programlisting>
	<para>
	<emphasis>i.e.</emphasis>don't allow the user processes to use memory that LVS
can use. But when there are "enough" LVS connections created we can
consider reserving 10MB for the user space and to start dropping
new connections early, i.e. when there are less than 10MB free memory.
If conn_number &lt;500000 LVS simply will hit the 0MB free memory point
and the user space will be hurted because these processes allocated
too much memory in this case.
	</para>
	<para>
But obtaining the "free_memory" may be costs CPU cycles. May be we can
stick with a snapshot on each second.
	</para>
	</blockquote>
	<para>
The number of valid connections shouldn't change dramatically
in 1 sec. However a DoS might still cause problems.
	</para>
	<blockquote>
	Yes, the problem is on SYN attack.
	</blockquote>
	<para>
Ratz
	</para>
	<blockquote>
max amount of concurrent connections: 3495.
We assume having 4 realservers equally load balance, thus we have to
limit the upper threshold per realserver to 873. Like this you would never
have a memory problem but a security problem.
	</blockquote>
	<para>
what's the security problem?
	</para>

	<blockquote>
SYN/RST flood. My patch will set the weight of the realserver to 0 in case the
upper threshold is reached. But I do not test if the requesting traffic is
malicious or not, so in case of SYN-flood it may be 99% of the packets causing
the server to be taken out of service. In the end we have set all server to
weight 0 and the load balancer is non-functional either. But you don't have
the memory problem :)
	</blockquote>
	<para>
And it hasn't crashed either.
	</para>
	<para>
Ratz
	</para>
	<blockquote>
I kinda like it but as you said, there is the amem_thresh, my approach
(which was not actually done because of this problem :) and now having
a lowmem_thresh. I think this will end up in a orthogonal semantic for
memory allocation. For example if you enable the amem_thresh the
conn_number &gt; min_conn_limit &amp;&amp; free_memory &lt;lowmem_thresh would never
be the case. OTOH if you set the lowmem_thresh to low the amem_thresh
is ineffective. My patch would suffer from this too.
	</blockquote>
	<para>
Julian Anastasov <emphasis>ja (at) ssi (dot) bg</emphasis> 08 Jun 2001
	</para>
	<blockquote>
	<para>
	lowmem_thresh is not related to amemthresh but when
amemthresh &lt;lowmem_thresh the strategies will never be activated.
lowmem_thresh should be less than amemthresh. Then the strategies
will try to keep the free memory in the lowmem_thresh:amemthresh range
instead of the current range 0:amemthresh
	</para><para>
Example (I hope you have memory to waste):
	</para><para>
lowmem_thresh=16MB (think of it as reserved for user processes and kernel)
amemthresh=32MB (when the defense strategies trigger)
min_conn_limit=500000 (think of it as 60MB reserved for LVS connections)
	</para><para>
	So, the conn_number can grow far away after min_conn_limit but
only while lowmem_thresh is not reached. If conn_number &lt;500000 and
free_memory &lt;lowmem_thresh we will wait the OOM killer to help us.
So, we have 2 tuning parameters: the desired number of connections
and some space reserved for user processes. And may be this is difficult
to tune, we don't know how the kernel prevents problems in VM before
activating the killer, i.e. swapping, etc. And the cluster software
can take some care when allocating memory.
	</para>
	</blockquote>

	<para>
Hayden Myers <emphasis>hayden (at) spinbox (dot) com</emphasis> 18 Mar 2002
	</para>
	<blockquote>
	<para>
There's also some info located in kernel help.  I posted it below for
convenience.
	</para><para>
Using a big ipvs hash table for virtual server will greatly reduce
conflicts in the ipvs hash table when there are hundreds of thousands
of active connections.
Note the table size must be power of 2. The table size will be the
value of 2 to the your input number power. For example, the default
number is 12, so the table size is 4096. Don't input the number too
small, otherwise you will lose performance on it. You can adapt the
table size yourself, according to your virtual server application. It
is good to set the table size not far less than the number of
connections per second multiplying average lasting time of connection
in the table.  For example, your virtual server gets 200 connections
per second, the connection lasts for 200 seconds in average in the
masquerading table, the table size should be not far less than
200x200, it is good to set the table size 32768 (2**15).
	</para><para>
Another note that each connection occupies 128 bytes effectively and
each hash entry uses 8 bytes, so you can estimate how much memory is
needed for your box.
	</para>
	</blockquote>
	<para>
Ratz: Leave the settings as a general rule.
	</para>
	<para>
Some people still want to change the hash table size
	</para>
	<para>
Daniel Burke 28 Jun 2002
	</para>
	<blockquote>
 In anticipation of our capacity requirements growing,
 we had decided it was necessary to increase the
 connection table size.  The value it was at was 16,
 based on our calculations we needed to bump it to 26
 to handle what were will be throwing at it.
	</blockquote>
	<para>
Julian
	</para>
	<para>
        It is insane to use 26. That means 2^26 * space for
2 pointers. On x86 it takes 512MB just for allocating
empty hash table with 2^26 d-linked lists. Refer to the
HOWTO for calculating the best hash table size according
to the number of connections. You can select the size (POWER)
in this way:
	</para><para>
2^POWER = AVERAGE_NUM_CONNS/10
	</para><para>
The magic value 10 in this case is the average number of
conns expected in one d-linked list, the lookup is slower
for more conns.
	</para><para>
Example:
	</para><para>
        POWER=16 => 65536 rows => 655360 conns, 10 on each row
	</para><para>
Joe - Wensong has stepped in to stop people from doing this anymore.
	</para><para>
Wensong
	</para><para>
Just added code that limits the input number from 8 to 20,
in order to prevent this configuring problem from happening again.
	</para>
	<para>
Ratz
	</para>
	<blockquote>
	<para>
I would love to know why people always want to increase the hash table size?
I remember that at one point we had a piece of code testing the hash table.
I think Julian and/or Wensong wrote it. Does anyone of you still have that code?
	</para>
	<para>
I'd say that the rehashing that would need to take
place would consume more CPU cycles than a yet-to-be-proven gain from increasing
the bucket size.
	</para>
	</blockquote>

	<para>
Horms <emphasis>horms (at) verge (dot) net (dot) au</emphasis> 17 Feb 2003
	</para>
	<para>
Agreed. To expand on this for the benefit of others.  The hash table is
just that. A hash. Each bucket in the hash can have multiple entries.
The implementation is such that each bucket is a linked list of entries.
	</para>
	<blockquote>
	<para>
Exactly. And around 2000 we tuned the hash generation function to have the best
balanced distribution over all buckets with a magic prime number which IIRC was
pretty exactly the golden ratio if you divided 2^32 through that number.
	</para>
<programlisting><![CDATA[
ratz@zar:~ > echo "(2^32)/2654435761" | bc -l
1.61803399392945414737
ratz@zar:~ >
]]></programlisting>
	<para>
We took the wisdom from Chuck Lever's paper
Linux Kernel Hash Table Behavior: Analysis and Improvements
(http://www.citi.umich.edu/techreports/reports/citi-tr-00-1.pdf, site down Sep 2004)
So once you have an evenly distributed hash
table the search for an entry is almost best case for all entries.
	</para>
	</blockquote>
	<para>
Thus there is no limit on the number of entries the hash table can hold
(other than the amount of memory available).  The only advantage of
increasing the hash table size is to reduce, statistically speaking, the
number of entries in each bucket.
	</para>
	<blockquote>
Which gains you almost nothing. The search is still ... left as an exercise to
all CS students here :)
	</blockquote>
	<para>
And thus the amount of hash table
traversal.  To be honest I think the gain is probably minimal even in
extreme circumstances.
	</para>
	<blockquote>
Especially since computing the hash value entry uses most of the times almost
the same amount of time as parsing the linked list.
	</blockquote>
	<para>
Anecdotally, a colleague of mine did a test on making the linked lists
reordering. So that the most recently used entry was moved to the front.
	</para>
	<blockquote>
Interesting approach. However I guess that the cache line probably already had
this entry. It would be interesting to see the amount of TLB flushes done by the
kernel depending on the amount of traffic and hash table size.
	</blockquote>
	<para>
He then pushed a little bit traffic through the LVS box (>700Mbit/s).
We didn't really see any improvement. Which would make me think that
hash table performance isn't a particular bottleneck in the current
code.
	</para>
	<para>
Jernberg, Bernt wrote:
	</para>
	<blockquote>
my throughput is 2Gb/s
	</blockquote>
	<para>
The tests that I was involved with with >700Mb/s of traffic
used a hash-table with 17bits. I am not entirely sure how
that number was derived as I did not do the tests myself.
But it would probably be a good start for you.
	</para>
	<para id="spinlocks" xreflabel="spinlocks">
You are probably going to see a bigger difference
by compiling a non-SMP kernel and eliminating spinlocks
than you will twiddling the hash-table bits.
I believe that by having an SMP kernel,
the overhead of spinlocks is significant under high load.
	</para>
	<para>
(For more on SMP/UMP with LVS, see comments by Horms on <xref linkend="FAQ:smp_doesnt_help"/>.)
	</para>
	<para>
Jernberg, Bernt
	</para>

	<blockquote>
I have deployed it at a customer sight which offers ftp,http and rsyc services.
They calculated that they will need 2^21 entries in the hash if it is supported.
	</blockquote>
	<para>
Ratz
	</para>
	<para>
Let me see (4 secs session coherency and 1/8 of the traffic are valid SYN
requests matching the template):
	</para>

<programlisting><![CDATA[
ratz@zar:~ > echo "l(4*2*1024*1024*1024/8)" | bc -l
20.79441541679835928251
ratz@zar:~ >
]]></programlisting>
	<para>
So yes, this would roughly be 21 bits. But now I ask you to read the nice
explanation of Horms in this thread on why you do not need to increase the
bucket size of the hash table to be able to hold 2**21 entries. You can
perfectly well use 17 bits which would give you a linked list depth (provided we
have an equilibrium in distribution over the buckets):
	</para>
<programlisting><![CDATA[
ratz@zar:~ > echo "2^21/2^17" | bc -l
16.00000000000000000000
ratz@zar:~ >
]]></programlisting>
	<para>
So lousy 16 entries for one bucket when using 17 bit. This is bloody _nothing_.
Let's take the worst case: You'd have maybe 32 entries which is still _nothing_.
Your CPU doesn't even fully awake to find an entry in this list :).
	</para>
	<para>
The amount of RAM you need to hold 2^21 templates entries for a session time of
4 seconds is roughly:
	</para>
<programlisting><![CDATA[
ratz@zar:~ > echo "4*(128*2^21)/1024/1024" | bc -l
1024.00000000000000000000
ratz@zar:~ >
]]></programlisting>
	<para>
1GB. So you're on the safe end. However if you plan on using persistency you'd
run out of memory pretty soonish.
	</para>
	<para>
Ratz
	</para>
	<blockquote>
I would love to know why people always want to increase the hash table size? I
remember that at one point we had a piece of code testing the hash table.
We used it to tweak the hash function.
	</blockquote>

	<para>
Julian, 17 Feb 2003
	</para>

	<para>
<ulink url="http://www.ssi.bg/~ja/hashlvs-0.1.tgz">hashlvs</ulink>
I created a script for easy testing. Currently, there are 2 hash
functions for tests. I don't remember for what LVS version the
hash_*.c files were created.
	</para>

	<para><emphasis>usage:</emphasis>
get copy of the conn table output (use real data) and feed it to
the scripts by specifying the used hash table size (in bits) and the
desired hash function method. The result is the expected access
time in pseudo units. Bigger access time means slower lookup.
	</para>

	</section>
	<section id="hash_table_timeouts">
	<title>Hash table connection timeouts</title>
	<blockquote>
How long are the connection entries held for ? (Column 8 of
<filename>/proc/net/ip_masquerade</filename> ?)
	</blockquote>
	<para>
Julian
	</para>
	<para>
The default timeout value for TCP session is 15 minutes, TCP session after
receiving FIN is 2 miniutes, and UDP session 5 minutes. You can use
<command>ipchains -M -S tcp tcpfin udp</command> to set your own time values.
	</para>
	<blockquote>
If we assume a clunky set of web servers being
balanced that take 3s to serve an object, then if the connection entries
are dropped immediately then we can balance about 20 million web requests
per minute with 128M RAM. If however the connection entries are kept for a
longer time period this puts a limit on the balancer.
	</blockquote>
	<para>
Yeah, it is true.
	</para>
	<blockquote>
<emphasis>e.g.</emphasis> (assuming column 8 is the thing I'm after!)
	</blockquote>
	<para>
Actually, the column 8 is the delta value in sequence numbers. The
timeout value is in column 10.
	</para>
	<blockquote>
<programlisting><![CDATA[
[zathras@consus /]$ head -n 1000 /proc/net/ip_masquerade | \
sed -e "s/  */ /g"|cut -d" " -f8|sort -nr|tail -n500|head -n1 8398
]]></programlisting>
		<para>
<emphasis>i.e.</emphasis> 
Held for about 2.3 hours, which would limit a 128Mb machine to balance
about 10.4 million requests per day. (Which is definitely on the low side
knowing our throughput...)
		</para>
	</blockquote>
	<para>
Horms <emphasis>horms (at) vergenet (dot) net</emphasis>
	</para>
	<para>
When a connection is recieved by an IPVS server and forwarded
(by whatever means) to a back-end server at what stage is
this connection entered into the IPVS table. It is before or
as the packet is sent to the back-end server or delayed
until after the 3 way handshake is complete.
	</para>
	<para>
Lars
	</para>
	<para>
The first packet is when the connection is assigned to a realserver, thus it
must be entered into the table then, otherwise the 3 way handshake would
likely hit 3 different realservers.
	</para>
	<para>
unknown
	</para>
	<para>
It has been alleged that IBMs Net Director waits until
the completion of the three way handshake to avoid the
table being filled up in the case of a SYN flood. To
my mind the existing SYN flood protection in Linux should
protect the IPVS table in any case and the connection
needs to be in the IPVS table to enable the 3 way handshake
to be completed.
	</para>
	<para>
Wensong
	</para>
	<para>
There is state management in connection entries in the IPVS table. The
connection in different states has different timeout value, for
example, the timeout of the SYN_RECV state is 1 minute, the timeout of
the ESTABLISHED state is 15 minutes (the default). Each connection
entry occupy 128 bytes effective memory. Supposing that there is 128
Mbytes free memory, the box can have 1 million connection entries. The
over 16,667 packet/second rate SYN flood can make the box run out of
memory, and the syn-flooding attacker probably need to allocate T3
link or more to perform the attack. It is difficult to syn-flood a
IPVS box. It would be much more difficult to attach a box with more
memory.
	</para>
	<blockquote>
I assume that the timeout is tunable, though reducing the
timeout could have implications for prematurely
dropping connections. Is there a possibility of implementing
random SYN drops if too many SYN are received as I believe
is implemented in the kernel TCP stack.
	</blockquote>
	<para>
Yup, I should implement random early drop of SYN entries long time ago as
Alan Cox suggested. Actually, it would be simple to add this feature into
the existing IPVS code, because the slow timer handler is activated every
second to collect stale entries. I just need to some code to that handler,
if over 90% (or 95%) memory is used, run drop_random_entry to randomly
tranverse 10% (or 5%) entries and drop the SYN-RCV entries in them.
	</para>
	<blockquote>
A second, related question is if a packet is forwarded to
a server, and this server has failed and is sunsequently
removed from the available pool using something like
ldirectord. Is there a window where the packet
can be retransmitted to a second server. This would
only really work if the packet was a new connection.
	</blockquote>
	<para>
Yes, it is true. If the primary load balaner fails over, all the
established connections will be lost after the backup takes over. We
probably need to investigate how to exchange the state (connection
entries) periodically between the primary and the backup without too
much performance degradation.
	</para>
	<blockquote>
If persistent connections are being used and a client is
cached but doesn't have any active connections does
this count as a connection as far as load balancing,
particularly lc and wlc is concerned. I am thinking
no. This being the case, is the memory requirement for each
client that is cached but has no connections 128bytes as
per the memory required for a connection.
	</blockquote>
	<para>
The reason that the existing code uses one template and creates different
entries for different connections from the same client is to manage the
state of different connections from the same client, and it is easy to
seemlessly add into existing IP Masquerading code. If only one template
is used for all the connections from the same client, the box receives a
RST packet and it is impossible to identify from which connection.
	</para>
	<blockquote>
We using Hash Table to record an established network connection.
How do we know the data transmission by one conection is over
and when should we delete it from the Hash Table?
	</blockquote>
	<para>
Julian Anastasov <emphasis>ja (at) ssi (dot) bg</emphasis> 24 Dec 2000
	</para>
	<para>
OK, here we'll analyze the LVS and mostly the MASQ transition
tables from net/ipv4/ip_masq.c. LVS support adds some extensions to
the original MASQ code but the handling is same.
	</para>
	<para>
First, we have three protocols handled: TCP, UDP and ICMP.
The first one (TCP) has many states and with different timeout values,
most of them set to reasonable values corresponding to the
recommendations from some TCP related rfc* documents. For UDP and ICMP
there are other timeout values that try to keep the both ends connected
for reasonable time without creating many connection entries for each
packet.
	</para>
	<para>
There are some rules that keep the things working:
	</para>
	<para>
- when a packet is received for an existing connection or when a new
connection is created a timer is started/restarted for this connection.
The timeout used is selected according to the connection state.
If a packet is received for this connection (from one of the both ends)
the timer is restarted again (and may be after a state change). If no
packet is received during the selected period, the masq_expire()
function is called to try to release the connection entry. It is
possible masq_expire() to restart the timer again for this connection
if it is used from other entries. This is the case for the templates
used to implement the persistent timeout. They occupy one entry
with timer set to the value of the persistent time interval. There
are other cases, mostly used from the MASQ code, where helper
connections are used and masq_expire() can't release the expired
connection because it is used from others.
	</para><para>
- according to the direction of the packet we distinguish two cases:
INPUT where the packet comes in demasq direction (from the world)
and OUTPUT where the packet comes from internal host in masq direction.
	</para><para>
masq. What does "masq direction" mean for packets that are
not translated using NAT (masquerading), for example, for
Direct Routing or Tunneling? The short answer is: there is no
masq direction for these two forwarding methods. It is explained
in the LVS docs. In short, we have packets in both directions
when NAT is used and packets only in one direction (INPUT) when
DR or TUN are used. The packets are not demasqueraded for DR and TUN
method. LVS just hooks the LOCAL_IN chain as the MASQ code is
privileged in Linux 2.2 to inspect the incoming traffic when the
routing decides that the traffic must be delivered locally. After some
hacking, the demasquerading is avoided for these two methods, of course,
after some changes in the packet and in its next destination - the
realservers. Don't forget that without LVS or MASQ rules, these packets
hit the local socket listeners.
	</para><para>
How are the connection states changed? Let's analyze for
example the masq_tcp_states table (we analyze the TCP states here,
UDP and ICMP are trivial). The columns specify the current
state. The rows explain the TCP flag used to select the next TCP
state and its timeout. The TCP flag is selected from masq_tcp_state_idx().
This function analyzes the TCP header and decides which flag (if many
are set) is meaningful for the transition. The row (flag index) in the
state table is returned. masq_tcp_state() is called to change ms->state
according to the current ms->state and the TCP flag looking in the
transition table. The transition table is selected according to
the packet direction: INPUT, OUTPUT. This helps us to react differently
when the packets come from different directions. This is explained later,
but in short the transitions are separated in such way (between INPUT
and OUTPUT) that transitions to states with longer timeouts are
avoided, when they are caused from packets coming from the world.
Everyone understands the reason for this: the world can flood us with
many packets that can eat all the memory in our box. This is the
reason for this complex scheme of states and transitions. The
ideal case is when there is no different timeouts for the different
states and when we use one timeout value for all TCP states as in UDP
and ICMP. Why not one for all these protocols? The world is not
ideal. We try to give more time for the established connections and
if they are active (i.e. they don't expire in the 15 mins we give them
by default) they can live forever (at least to the next kernel
crash^H^H^H^H^Hupgrade).
	</para><para>
How does LVS extend this scheme? For the DR and TUN method
we have packets coming from the world only. We don't use the OUTPUT
table to select the next state (the director doesn't see packets
returning from the internal hosts). We need to relax our INPUT rules
and to switch to the state required by the external hosts :( We
can't derive our transitions from the trusted internal hosts.
We change the state only based on the packets coming from the
the clients. When we use the INPUT_ONLY table (for DR and TUN)
the LVS expects a SYN packet and then an ACK packet from the client
to enter the established state. The director enters the established
state after a two packet sequence from the client without knowing
what happens in the realserver, which can drop the packets (if they
are invalid) or establish a connection. When an attacket sends
SYN and ACK packets to flood a LVS-DR or LVS-Tun director, many
connections are established state. Each each established
connection will allocate resources (memory) for 15 mins by default.
If the attacker uses many different source addresses for this
attack the director will run out of memory.
	</para><para>
For these two methods LVS introduces one more transition
table: the INPUT_ONLY table which is used for the connections created
for the DR and TUN forwarding methods. The main goal: don't enter
established state too easily - make it harder.
	</para><para>
Oh, maybe you're just reading the TCP specifications. There are
sequence numbers that the both ends attach to each TCP packet. And you
don't see the masq or LVS code to try to filter the packets according to
the sequence numbers. This can be fatal for some connections as the
attacker can cause state change by hitting a connection with RST
packet, for example (ES->CL). The only info needed for this kind of
attack is the source and destination IP addresses and ports. Such kind
of attacks are possible but not always fatal for the active connections.
The MASQ code tries to avoid such attacks by selecting minimal timeouts
that are enough for the active connections to resurrect. For example,
if the connection is hit by TCP RST packet from attacker, this
connection has 10 seconds to give an evidence for its existance
by passing an ACK packet through the masq box.
	</para><para>
To make the things complex and harder for the attacker to
block a masq box with many established connections, LVS extends
the NAT mode (INPUT and OUTPUT tables) by introducing internal
server driven state transitions: the secure_tcp defense
strategy. When enabled, the TCP flags in the client's packet can't
trigger switching to established state without acknowledgement from
the internal end of this connection. secure_tcp changes the
transition tables and the state timeouts to achieve this goal.
The mechanism is simple: keep the connection is SR state with
timeout 10 seconds instead of the default 60 seconds when the
secure_tcp is not enabled.
	</para><para>
This trick depends on the different
defense power in the realservers. If they don't implement SYN
cookies and so sometimes don't send SYN+ACK (because the incoming
SYN is dropped from their full backlog queue), the connection expires
in LVS after 10 seconds. This action assumes that this is a connection
created from attacker, since one SYN packet is not followed
by another, as part from the retransmissions provided from
the client's TCP stack.
	</para><para>
We give 10 seconds to the realserver to reply with
SYN+ACK (even 2 are enough). If the realserver implements SYN cookies
the SYN+ACK reply follows the SYN request immediatelly. But if there
are no SYN cookies implemented the SYN requests are dropped when the
backlog queue length is exceeded. So secure_tcp is by default useful
for realservers that don't implement SYN cookies. In this case the
LVS expires the connections in SYN state in a short time, releasing the
memory resources allocated from them. In any case, secure_tcp does
not allow switching to established state by looking in the clients packets.
We expect ACK from the realserver to allow this transition to EST
state.
	</para><para>
The main goal of the defense strategies is to keep the LVS
box with more free memory for other connections. The defense for the
realservers can be build in the realservers. But may be I'll propose
to Wensong to add a per-connection packet rate limit. This will help
against attacks that create small number of connections but send many
packets and by this way load the realservers dramatically. May be two
values: rate limit for all incoming packets and rate limit per
connection.
	</para><para>
The good news is that all these timeout values can be
changed in the LVS setup, but only when the secure_tcp strategy
is enabled. An SR timeout of 2 seconds is a good value for
LVS clusters when realservers don't implement SYN cookies:
if there is no SYN+ACK from the realserver then drop the entry
at the director.
	</para><para>
The bad news is of course, for the DR and TUN methods.
The director doesn't see the packets returning from the realservers
and LVS-DR and LVS-Tun forwarding can't use the internal server driven
mechanism. There are other defense strategies that help when
using these methods. All these defense strategies keep the
director with memory free for more new connections. There is no
known way to pass only valid requests to the internal servers.
This is because the realservers don't provide information to
the director and we don't know which packet is dropped or accepted
from the socket listener. We can know this only by receiving an ACK
packet from the internal server when the three-way handshake is
completed and the client is identified from the internal server
as a valid client, not as spoofed one. This is possible only for
the NAT method.
	</para>
	<para>
<emphasis>ksparger (at) dialtoneinternet (dot) net</emphasis> (29 Jan 2001) rephrases this
by saying the LVS-NAT is layer-3 aware.
For example, NAT can 'see' if a realserver responds to a packet it's been
sent or not, since it's watching all of the traffic anyway.  If the
server doesn't respond within a certain period of time, the director
can automatically route that packet to another server.
LVS doesn't support this right now, but, NAT would be the
more likely candidate to support it in
the future, as NAT understands all of the IP layer concepts, and DR
doesn't necessarily.
	</para>
	<para>
Julian
	</para>
	<para>
Someone must put back the realserver when it is alive. This
sounds like a user space job. The traffic will not start until we send
requests. We have to send L4 probes to the realserver (from the user
space) or to probe it with requests (LVS from kernel space)?
	</para>
	</section>
	<section id="hash_table_DoS">
	<title>Hash Table DoS</title>
	<para>
A posting (Jun 2003) on
<ulink url="http://slashdot.org/article.pl?sid=03/05/31/2157254&amp;mode=thread&amp;tid=126&amp;tid=172">Slashdot</ulink>
links to a paper on
<ulink url="http://www.cs.rice.edu/~scrosby/hash/CrosbyWallach_UsenixSec2003/index.html">
Denial of Service via Algorithmic Complexity Attacks</ulink>.
The article shows how to mount a DoS by attack on hash tables.
Access to entries in hash tables for most algorithms
is different for the average case 
(randomly sorted data where access time might be O(n log n))
and for the worst case 
(all in reverse order, where access time could be O(n^2)).
Programmers hope that real life data is not pathological.
If the attacker knows the hash algorithm 
(<emphasis>i.e.</emphasis> has the source code), 
then they may be able to construct
a worst case dataset for the hashing algorithm,
which will bring the server to its knees.
The paper discusses constructing attacks in which all data is entered
into one bucket of the hash table.
	</para>
	<para>
In the case of LVS, the hash table contents are (CIP:port, proto, VIP:port).
The client only has a small number of variables (the
port and proto they are sending from) from which to mount
an attack, the others being fixed (CIP, VIP:port).
	</para>
	<para>
Horms <emphasis>horms (at) verge (dot) net (dot) au</emphasis> 05 Jun 2003
	</para>
	<para>
Here is my take on this: LVS uses the following hash
	</para>
<programlisting><![CDATA[
(proto XOR CIP XOR (CIP>>IP_VS_CONN_TAB_BITS) XOR port) & IP_VS_CONN_TAB_MASK

where:
proto =  protocol (TCP=6, UDP=17)
CIP   =  source/client IP address (host byte order)
port  =  source port (host byte order)
IP_VS_CONN_TAB_BITS defaults to 8
IP_VS_CONN_TAB_MASK is (1 << IP_VS_CONN_TAB_BITS) - 1 thus the default is 0xff
]]></programlisting>
	<para>
(from here '^' will mean power)
	</para>
	<para>
The only inputs a user/client can effect are CIP and port.
	</para>
	<para>
I would say that it is quite easy for someone to set things
up so that they consistently hit the same bucket.
For instance by connecting from the same ip address
with different ports from the set (port % IP_VS_CONN_TAB_MASK) = n
(though we observe that each end-user only has
2^(16-IP_VS_CONN_TAB_BITS) = 256 such ports).
The client would need to use multiple source IP addresses.
	</para>
	<para>
The effect is that instead of n connections going into
2^IP_VS_CONN_TAB_BITS different buckets they will
go into one bucket. Thus LVS will have to do on average n/2 traversals
instead of n/2^(IP_VS_CONN_TAB_BITS+1) traversals.
	</para>
	<para>
The real effect is to amplify traversal times
by 2^IP_VS_CONN_TAB_BITS. Though it is worth remembering
that the larger IP_VS_CONN_TAB_BITS is then lower
2^(16-IP_VS_CONN_TAB_BITS) becomes, and thus
the greater the number of source IP addresses required becomes.
Though if it was a UDP bassed attack this might not be
an issue as the source IP could be spoofed.
	</para>
	<para>
This could become a problem if n became very large.
But how large? Traversal is actually pretty fast.
So I think that n would need to be quite large indeed
to have a noticable effect on LVS and larger still
to seriously degrade performance. Though I could be wrong.
	</para>
	<para>
As for solutions, it is a bit tricky AFAIK.
Perhaps using some component of the skb which
is static for a connection, but not directly
influenced by end users. But that may well
open up a whole new can of worms.
	</para>
	<para>
Ratz 05 Jun 2003
	</para>
	<para>
Theoretically we're susceptible to this sort of attack. Check out the
devastating effects on running Julian's <command>testlvs</command>
with certain parameters.
You can still enable the LVS DoS defense strategies though
(see <xref linkend="testing_DoS_strategies"/>).
	</para>
		<section id="testing_hash_code">
		<title>testing hash code</title>
		<para>
Julian, 14 Jun 2003
		</para>
		<para>
Maybe it is time to change the hash function used
for the table with connections. Today I played with some data
from my 2.2 director and fixed the tools that measure different
hash functions. I tested the default LVS function, one
that uses 2654435761 and the Jenkins hash that is present in
recent 2.4 and 2.5 kernels. We need some help from the math
perspective.
		</para>
		<para>
Here are some
<ulink url="http://www.ssi.bg/~ja/hashlvs-0.2.tgz">tools for testing the hash functions</ulink>
Look in <ulink url="http://www.ssi.bg/~ja/">Julian's LVS page</ulink>
for <filename>test.txt</filename> which contains short instructions for testing and
<filename>ipvs-1.0.9-hash1.diff</filename> test hash code for 2.4.21.
		</para>
		<para>
I created test patch against ipvs-1.0.9 (not tested). This is an
attempt to introduce randomness on IPVS load. As for the tests
with the different hash functions you can see my results and
of course to try them yourself. My conclusion is that 2654435761
is better and faster but I hope we will see other results.
		</para>
		</section>
	</section>
	<section id="exceeding_hash_table_size">
	<title>Hash table size, director will crash when it runs out of memory.</title>
	<para>
<blockquote><para>
Yasser Nabi
			</para><para>
IP Virtual Server version 0.9.0 (size=16777216)
</para></blockquote>
			</para><para>
Julian Anastasov <emphasis>ja (at) ssi (dot) bg</emphasis> 25 May 2001
			</para><para>
Too much, it takes 128MB for the table only. Use 16 bits for example.
			</para><para>
<blockquote><para>
Is this a hidden/undocumented problem with IPVS or it's just an observation of
memory waste ? (we use 18 bits in production)
</para></blockquote>
			</para><para>
<programlisting><![CDATA[
empty hash tables:

18 bits occupy 2MB RAM
24 bits occupy 128MB RAM
]]></programlisting>
			</para><para>
        If the box has 128MB and the bits are 24 the kernel crash is
mandatory, soon or later. And this is a good reason the virtual service
not to be hit. Expect funny things to happen on box with low memory
			</para><para>
<blockquote><para>
I forgot that not anyone uses 256Mb or more RAM on directors :)
</para></blockquote>
			</para><para>
        Yes, 256MB in real situation is ~1,500,000 connections, 128 bytes
each, 64MB for other things ... until someone experiments with SYN attack
			</para><para>
<blockquote><para>
However, for me it makes sense to use up to 66% of total memory for LVS,
especially on high-traffic directors (in the idea that the directors doesn't
run all the desktop garbage that comes with most distros).
</para></blockquote>
			</para><para>
        If the used bits are 24, an empty hash table is 128MB. For the
rest 128MB you can allocate 1048576 entries, 128 bytes each ... after
the kernel killed all processes.
			</para><para>
        Some calcs considering the magic value 16 as average bucket
length and for 256MB memory:
			</para><para>
For 17 bits:
			</para><para>
2^17=131072 => 1MB for empty hash table
			</para><para>
        131072*16=2097152 entries=256MB for connections
			</para><para>
For 18 bits:
			</para><para>
2^18=262144 => 2MB for empty hash table
			</para><para>
for each MB for hash table we lose space for 8192 entries but we speedup
the lookup.
			</para><para>
So, even for 1GB directors, 19 or 20 is the recommended value. Anything
above is a waste of memory for hash table. In 128MB we can put 1048576
entries. In the 24-bit case they are allocated for d-linked list heads.
			</para><para>
			</para><para>
Joe 6 Jun 2001
			</para><para>
what happens after the table fills up? Does ipvs handle new connect
requests gracefully (ie drops them and doesn't crash)?
			</para><para>
<blockquote><para>
Julian
			</para><para>
			</para><para>
	The table has fixed number of rows and unlimited number of
columns (d-lists where the connection structures are enqueued). The
number of connections allocated depends on the free memory.
			</para><para>
	Once there is no memory to allocate connection structure,
the connection requests will be dropped.
Expect crashes maybe at another place (usually user space) :)
			</para><para>
	I'm not sure what the kernel will decide in this situation but
don't rely on the fact some processes will not be killed. There is
a constant network activity and a need for memory for
packets (floods/bursts).
			</para><para>
	And the reason the defense strategies to exist is to
free memory for new connections by removing the stalled ones. The
defense strategy can be automatically activated on memory threshold.
Killing the cluster software on memory presure is not good.
			</para><para>
	So, the memory can be controlled, for example, by setting
drop_entry to 1 and tuning amemthresh. On floods it can be increased.
It depends on the network speed too: 100/1000mbit. Thresholds of
16 or 32 megabytes can be used in such situations, of course, when there
are more memory chips.
</para></blockquote>
			</para><para>
			</para><para>
<blockquote><para>
Roberto Nibali <emphasis>ratz (at) tac (dot) ch</emphasis>
			</para><para>
The director
never crashes because of exhaustion of memory. If he tries to allocate
memory for a new entry into the table and kmalloc returns NULL, we return,
or better drop the packet in processing and generate a page fault.
			</para><para>
You could use my <link linkend="threshold">treshhold limitation patch</link>.
You calculate how many connections you can sustain with your memory
by multiplying each connection entry with 128bytes and divide by the amount
of realserver and set the limitation alike. Example:
			</para><para>
128MByte, persistency 300s: max amount of concurrent connections: 3495.
We assume having 4 realservers equally load balance, thus we have to
limit the upper threshold per realserver to 873. Like this you would never
have a memory problem but a security problem.
</para></blockquote>
			</para><para>
Joe
			</para><para>
It would seem that we need a method of stopping the director hash table from
using all memory whether as a result of a DoS attack or in normal service.
Let's say you fill up RAM with the hash table and all user processes go
to swap, then there will be problems - I don't know what, but it doesn't
sound great - at a high number of connections I expect the user space processes
will be needed too. I expect we need to leave a certain amount for
user space processes and not allow the director to take more than a certain
amount of memory.
			</para><para>
It would be nice if the director didn't crash when the number of connections
got large. Presumably a director would be functioning only as a director and the
amount of memory allocated to user space processes wouldn't change a whole lot
(ie you'd know how much memory it needed).
	</para>
	</section>
	<section id="lvs_doesnt_swap">
	<title>The LVS code does not swap</title>
	<para>
Joe Feb 2001
	</para><para>
With sufficient number of connections, a director could
start to swap out its tables (is this true?)
In this case, throughput could slow to a crawl. I presume
the kernel would have to retrieve parts of the table to find
the realserver associated with incoming packets. I would
think in this case it would be better to drop connect
requests than to accept them.
			</para><para>
<blockquote><para>
Julian
			</para><para>
IMO, this is not true. LVS uses GFP_ATOMIC kind of allocations
and as I know such allocations can't be swapped out.
</para></blockquote>
			</para><para>
If it's possible for LVS to start the director to swap,
is there some way to stop this?
			</para><para>
<blockquote><para>
You can try with <link linkend="testlvs">testlvs</link> whether the LVS uses swap.
Start the kernel with LILO option mem=8M and with large swap area.
Then check whether more than 8MB swap is used.
</para></blockquote>
	</para></section>
	<section id="number_connections">
	<title>Other factors determining the number of connections</title>
	<para>
In earlier verions of LVS, you set the amount of
memory for the tables (in bytes).
Now you allocate a number of hashes, whose size can grow without limit,
allowing an unlimited number of connections.
Once the number of connections becomes sufficiently large,
then other resources will become limiting.
	</para>
	<itemizedlist>
		<listitem>
			<para>
out of memory.
			</para>
			<para>
The ipvs code doesn't handle this,
presumably the director will crash
(also see the <link linkend="threshold">threshold patch</link>).
Instead you handle this by brute force, adding
enough memory to accept the maximum number of connections
your setup will ever be asked to handle
(<emphasis>e.g.</emphasis> under a DoS attack).
This memory size can be determined by the multiplying the rate
at which your network connection
can push connect requests to the director,
by the timeout values, which are set by FIN_WAIT
or the persistence.
			</para><para>
			</para>
		</listitem>
		<listitem>
			<para>
			out of ports.
			</para>
			<para>
You can
<link linkend="port_range">expand the number of ports</link>
to 65k, but eventually you'll
<link linkend="65k_ports">reach the 65k port limit</link>.
			</para>
		</listitem>
	</itemizedlist>
	</section>
	<section id="port_range" xreflabel="port range">
	<title>Port range: limitations, expanding port range on directors</title>
	<para>
Sometimes client processes on the realservers need to connect with
machines on the internet
(see <link linkend="client_on_realserver">clients on realservers</link>.
	</para>
	<para>
Wayne <emphasis>wayne (at) compute-aid (dot) com</emphasis> Nov 5 2001
	</para>
	<blockquote>
Say you have a web page that has to
retrieve on-line ads from one of your advertiser (people
who pay you for showing their ads). If you have 50,000
visitors on your site, you will open 50,000 connections
between your web server and the ad server out there somewhere.
The masquerade limit is 4,096 per pair of IP addresses,
and 40,960 per LVS box.
In our case, the realserver is behind the LVS-NAT director,
which also functions as the firewall, so the realserver MUST use the
director to reach the ad servers.
	</blockquote>
	<para>
Usually the RIP is private (<emphasis>e.g.</emphasis>192.168/16)
and will have to be NAT'ed to the outside world.
This can be done with LVS-NAT or LVS-DR by adding
masquerading rules to the director's iptables/ipchains rules.
(With LVS-DR, you also have to
<link linkend="NAT_clients_in_LVS-DR">route the packets from the RIP</link>
 - this routing is setup by default with the configure script)
	</para><para>
Less often you want to use more ports on your LVS client machines.
	</para>
	<para>
Wang Haiguang
	</para>
	<blockquote>
My client machine it uses port numbers between 1024 - 4096.
After reaching 4096, it will loop back to 1024
and reuse the ports. I want to use more port nubmers
	</blockquote>
	<para>
<emphasis>michael_e_brown (at) dell (dot) com</emphasis> 06 Feb 2001
	</para>
<programlisting><![CDATA[
echo 1024 65000 > /proc/sys/net/ipv4/ip_local_port_range
/usr/src/linux/Documentation/networking/ip-sysctl.txt
]]></programlisting>
	<para>
While normal client processes use ports in order starting at
1024, masqueraded ports start at 61440 (2^16-2^12) for 2.2.x kernels
(see <link linkend="client_on_realserver">clients on realservers</link>).
The masquerading code does not
check if other processes are requesting ports and thus
port collisions could occur. It is assumed on a NAT
box that no other processes are initiating connections
(<emphasis>i.e.</emphasis> you aren't running a passive ftp server).
	</para>
	<para>
Horms 26 Jun 2007 
	</para>
	<para>
I beleive that there is a school of thought that source ports
should be randomised to mitigate certain classes of security threats.
	</para>
	<para>
Horms 17 May 2004
	</para>
	<para>
I am a bit rusty on 2.2. But the restricted port range for NAT'ed connections
with 2.2 sounds familiar.
I seem to recall you could change the range, but it required
changing a define in the kernel and recompiling. I think it was
changed to a /proc value in 2.4.
	</para>
	<note>
For 2.4.x kernels, the restriction to only use high ports is removed.
The NAT router uses ports starting at 1024.
	</note>
	<para>
Horms 17 May 2004
	</para>
	<para>
In 2.4
the ephemerial port range and the nat port range are the same. If this
is the case, which I guess it is, then it would seem likely there is
some sort of collision detectionion.
I took a look and this does not seem to be the case. I assume
the kernel has some other way of handling this. But I am not sure at
this moment. If you are interested try looking at tcp_v4_get_port()
and tcp_unique_tuple(). I'm not convinced that Michael Brown's comment
is correct at the moment, but I don't have the definitive answer either.
	</para>
	<para>
Wayne <emphasis>wayne (at) compute-aid (dot) com</emphasis> 14 May 2000,
	</para>
	<blockquote>
If running a load balancer tester, say the one from IXIA to
issue connections to 100 powerful web servers, would all the parameters
in Julian's description need to be changed, or it should not be a problem
for having many many connections from a single tester?
	</blockquote>
	<para>
Julian
	</para>
	<para>
There is no limit for the connections from the internal hosts.
Currently, the masquerading allows one internal host to create 40960
TCP connections. But the limit of 4096 connections to one external service
is still valid.
	</para><para>
If 10 internal hosts try to connect to one external
service, each internal host can create 4096/10 => 409 connections.
	</para><para>
For UDP the problem is sometimes worse. It depends on
the /proc/sys/net/ipv4/ip_masq_udp_dloose value.
	</para>
	<para>
Joe
	</para>
	<blockquote>
which is internal and which is external here? The client, the realservers?
	</blockquote>
	<para>
This is a plain masquerading so internal and external
refer to masquerading. These limits are not for the LVS connections,
they are only for the 2.2 masquerading.
	</para>
<programlisting><![CDATA[
			</para><para>
		 / 65095	Internal Servers
External Server:PORT	-  ...	 MADDR --------------------
		 \ 61000
]]></programlisting>
	<para>
When many internal clients try to connect to same external
real service, the total number of TCP connections from one MADDR
to this remote service can be 4096 because the masq uses only 4096
masq ports by default. This is a normal TCP limit, we distinguish
the TCP connections by the fact they use different ports, nothing
more. And the masq code is restricted by default to use the above
range of 4096 ports.
	</para><para>
In the whole masquerading table there is a space only for
40960 TCP, 40960 UDP and 40960 ICMP connections. These values can
be tuned by changing ip_masq.c:PORT_MASQ_MUL.
	</para>
	<para>
For 2.4 masquerading, all ports can be used for the masqueraded connections.
	</para>
	<para>
Wayne<emphasis>wayne (at) compute-aid (dot) com</emphasis> 1 Nov 2001
	</para>
	<blockquote>
		<para>
PORT_MASQ_MUL appears to serve only as a check to make sure the masquerading
facility does not hog all the memory, and that actually things would
still work no matter how large PORT_MASQ_MUL is, or even if the checks using
it are disabled. Is this true?
		</para>
		<blockquote>
			<para>
	Julian
			</para>
			<para>
	By multiplying this constant with the masq port range, you
define the connection limit for each protocol. This is related to the
memory used for masquerading. This is a real limit, but not for LVS
connections, because they are usually not limited by port collisions,
and LVS does not check this limit.
			</para>
		</blockquote>
		<para>
What about using more than the 32k range? What is the maximum
I could select?
		</para>
		<para>
Peter Mueller<emphasis>pmueller (at) sidestep (dot) com</emphasis>
		</para>
		<blockquote>
	You should be able to use about 60k, <emphasis>i.e.</emphasis> 1024-6100.
I hope you have lots of RAM :-)
		</blockquote>
	</blockquote>
	<para>
Julian continuing
	</para><para>
The PORT_MASQ_MUL
value simply determines the recommended length of one row in the
masq hash table for connections, but in fact it is involved in
the above connection limits. It is recommended that the busy masq
routers must increase this value. May be the 4096 masq port range
too. This involves squid servers behind masq router.
	</para><para>
	LVS uses another table without limits. For LVS setups the
same TCP restrictions apply but for the external clients:
	</para>
<programlisting><![CDATA[
	4999 \
Client	     - VIP:VPORT LVS Director
	1024 /
]]></programlisting>
	<para>
	The limit of client connections to one VIP:VPORT is limited
to the number of used client ports from same Client IP.
	</para><para>
	The same restrictions apply to UDP. UDP has the same port
ranges. But for UDP the 2.2 kernel can apply different restrictions.
They are caused from some optimizations that try to create one UDP
entry for many connections. The reason for this is the fact that
one UDP client can connect to many UDP servers while this is not
common for TCP.
	</para>
	<para>
Joe
	</para>
	<blockquote>
when you increase the port range, you need more memory. Is this
only because you can have more connections and hence will need
a bigger <command>ipvsadm</command> table?
	</blockquote>
	<para>
        Yes, the first need is for more masqueraded connections
and they allocate memory. LVS uses separate table and it
is not limited. We distinguish LVS-NAT from Masquerade. LVS-NAT (and
any other method) does not allocate extra ports, even for other
ranges. It shadows only the defined port. No other ports are
involved until masquerading is used.
	</para>
	<blockquote>
ipvs doesn't check port ranges and so collisions
can occur with regular services (ftp was mentioned). I would have
thought that a process needing to open a IP connnection would
ask the tcp code in the kernel for a connection and let that code
handle the assignment of the port.
	</blockquote>
	<para>
LVS does not allocate local ports. When the masquerade
is used to help with some protocol, the masquerade performs the
check (ftp for example).
	</para><para>
The port range has nothing to do with LVS. It helps the
masquerading to create more connections because there is fixed
limit for each protocol. But sometimes LVS for 2.2 uses ip_masq_ftp,
so may be only then this mport range is used.
	</para>
	<blockquote>
X-window connections are at 6000.. Will you be able to start
an X-session if these ports are in use by a director masquerading
out connections from the realservers?
	</blockquote>
	<para>
        If we put LVS (ipvsadm -A ) in front of this port 6000
then X sessions will be stopped. OTOH, masquerade does not select
ports in this range, the default is above 61000. So, any FTP
sessions will not disturb local ports, of course, if you don't
increase the mport range to cover the well defined server ports
such as X.
	</para>
	</section>
	<section id="director_ports" xreflabel="director ports">
	<title>Director does not have any ports (connections) open for an LVS connection</title>
	<para>
The director is just a router (admittedly with slightly different
rules than the standard layer 3 router). There are no connections
made (ports opened) between the client and the director, or between the realservers
and the director. 
The director does keep track of the packets passing through that are for
LVS'ed services (connection tracking) as part of updating the hash table
and for the server state synch demon.
	</para>
	<para>
Sebastien BONNET <emphasis>sebastien(dot) bonnet (at) experian (dot) fr</emphasis> 11 May 2004 
	</para>
	<para>
There's no "open" connection on the director, just tracked 
connections. The clients are not "connected" to the load balancer.
	</para>
	<para>
For the client,
assuming a client always uses a different port for an outgoing 
connection, it can roughly initiate 65K connections.
	</para>
	<para>
For the realserver, there's no real port limit for a daemon listening on a 
single port: it uses just one. The realserver can have connections to all ports
on all IPs, <emphasis>i.e.</emphasis> 256*256*256*256*(65536-1024) connections
(the realserver may run out of memory before it can make all these connections).
	</para>
	<para>
If there was no file descriptor limit nor memory constraint, a server 
could handle way more than the current "port limit" (65K) simultaneous 
connections.
	</para>
	</section>
	<section id="port_starvation" xreflabel="port starvation">
	<title>apps starved for ports</title>
	<para>
LVS Account, 27 Feb 2001
	</para>
	<blockquote>
		<para>
I'm trying to do some load testing of LVS using a reverse proxy cache server
as the load balanced app.  The error I get is from a load generating app..
Here is the error:
		</para>
<programlisting><![CDATA[
byte count wrong 166/151
]]></programlisting>
	</blockquote>
	<para>
Julian Anastasov <emphasis>ja (at) ssi (dot) bg</emphasis>
	</para>
	<para>
Broken app.
	</para>
	<blockquote>
		<para>
this goes on for a few hundred requests then I start getting:
		</para>
<programlisting><![CDATA[
Address already in use
]]></programlisting>
	</blockquote>
	<para>
App uses too many local ports.
	</para>
	<blockquote>
		<para>
This is when I can't telnet to port 80 any more... If I try to telnet to
10.0.0.80 80 I get this:
		</para>
<programlisting><![CDATA[
$ telnet 10.0.0.80 80
Trying 10.0.0.80...
telnet: Unable to connect to remote host: Resource temporarily unavailable
]]></programlisting>
	</blockquote>
	<para>
No more free local ports.
	</para>
	<blockquote>
If I go directly to the web server OR if I go directly to the IP of the
reverse proxy cache server, I don't get these errors.
	</blockquote>
	<para>
Hm, there are free local ports now.
	</para>
	<blockquote>
		<para>
I'm using a load balancing app that I call this way:
		</para>
<programlisting><![CDATA[
/home/httpload/load -sequential -proxyaddr 10.0.0.80 -proxyport
0  -parallel 120 -seconds 6000000 /home/httpload/url
]]></programlisting>
		<para>
upping the local port range has helped tremendously
		</para>
	</blockquote>
	</section>
	<section id="realserver_port_starvation">
	<title>realserver running out of ports</title>
	<para>
Here's a case where a realserver ran out of udp ports doing
DNS looksup while serving http.
	</para>
	<para>
Hendrik Thiel <emphasis>thiel (at) falkag (dot) de</emphasis>
	</para>
	<blockquote>
		<para>
I am using IP Virtual Server version 0.9.14 (size=4096).
We have 6 Realservers each.
		</para>
<programlisting><![CDATA[
-> RemoteAddress:Port   Forward Weight ActiveConn InActConn
-> server1:www          Masq    1      68         12391
]]></programlisting>
		<para>
Today we reached a new peak (very fast, few minutes) 30Mbps,
up from the normal 15Mbit/s.
Afterwards the following kernel messages (dmesg) showed up...
		</para>
<programlisting><![CDATA[
IP_MASQ:ip_masq_new(proto=UDP): could not get free masq entry (free=31894).
IP_MASQ:ip_masq_new(proto=UDP): could not get free masq entry (free=31894).
IP_MASQ:ip_masq_new(proto=UDP): could not get free masq entry (free=31888).
]]></programlisting>
	</blockquote>
	<para>
Julian Anastasov <emphasis>ja (at) ssi (dot) bg</emphasis> 20 Nov 2001 (heavily edited by Joe)
	</para>
	<para>
	It seems you are flooding a single remote host with UDP requests
from a realserver. Your service, www, is TCP and is not directly
connected to these messages.
You've reached the UDP limit per destination (4096),
there are still free UDP ports on the realserver for other destinations.
	</para>
	<para>
Hendrik
	</para>
	<blockquote>
		<para>
yes it's DNS, each realserver is a caching DNS.
		</para>
<programlisting><![CDATA[
resolv.conf
nameserver 127.0.0.1
nameserver external IP
]]></programlisting>
	</blockquote>
	</section>
	<section id="max_number_NICs">
	<title>Maximum number of NICs</title>
	<para>
This is not really an LVS question, but people want to know.
	</para>
	<para>
<emphasis>ntadmin (at) reachone (dot) com</emphasis>
	</para>
	<blockquote>
We are nearing 255 virtual interfaces on the external side of our LVS
system (Joe - presumably the number of VIPs).
Can somebody tell me if this is going to be a hard limit or if we
can go beyond 255 on one network card?
	</blockquote>
	<para>
Roberto Nibali <emphasis>ratz (at) tac (dot) ch</emphasis> 17 Dec 2003
	</para>
	<para>
No problem (proof of concept below):
	</para>
<programlisting><![CDATA[
# ip addr show dev lo | grep 'inet ' | wc -l
       1
# for ((i = 1; i < 255; i++)); do for ((j = 1; j < 4; j++)); do ip addr add
127.0.$j.$i/32 dev lo brd + label lo:$i-$j 1>/dev/null 2>&1; done; done
# ip addr show dev lo | grep 'inet ' | wc -l
     763
# for ((i = 1; i < 255; i++)); do for ((j = 1; j < 4; j++)); do ip addr del
127.0.$j.$i/32 dev lo brd + label lo:$i-$j 1>/dev/null 2>&1; done; done
# ip addr show dev lo | grep 'inet ' | wc -l
       1
]]></programlisting>
	</section>
	<section id="DoS">
	<title>DoS</title>
	<para>
LVS is vunerable to DoS by an attacker making repeated connection requests.
Each connection requires 128bytes of memory -
eventually the director will run out of memory.
This will take a while but an attacker has plenty of time if you're asleep.
As well with LVS-DR and LVS-Tun, the director doesn't have access to
the TCPIP tables in the realserver(s) which show whether a connection has closed
(see <link linkend="hash_table">director hash table</link>).
The director can only guess that the connection has really closed, and
does so using timeouts.
	</para>
	<para>
Roberto Nibali <emphasis>ratzi (at) tac (dot) ch</emphasis> 10 Sep 2002
	</para>
	<blockquote>
It's _impossible_ to differentiate between malicious and good traffic. End of
story. But you can rate limit incoming SYNs within ingress policy.
This was discussed about 2 years ago when the
secure_tcp and drop_packet stuff was about to be introduced.
	</blockquote>
	<para>
For information on DoS strategies for LVS see
<ulink url="http://www.linuxvirtualserver.org/docs/defense.html">DoS page</ulink>.
	</para>
	<para>
Laurent Lefoll <emphasis>Laurent (dot) Lefoll (at) mobileway (dot) com</emphasis> 14 Feb 2001
	</para>
	<blockquote>
If I am not misunderstanding something, the variable
<filename>/proc/sys/net/ipv4/vs/timeout_established</filename> 
gives the time a TCP connection can be
idle and after that the entry corresponding to this connection is cleared. My
problem is that it seems that sometimes it's not the case. For example I have a
system (2.2.16 and ipvs 0.9.15) with  
<filename>/proc/sys/net/ipv4/vs/timeout_established = 480</filename>, 
but the entries are created with a real timeout of 120. 
	</blockquote>
	<para>
Julian Anastasov <emphasis>ja (at) ssi (dot) bg</emphasis>
	</para>
	<para>
Read <ulink url="http://www.linuxvirtualserver.org/docs/defense.html">The secure_tcp defense strategy</ulink> where the timeouts are explained.
They are valid for the defense strategies only.
For TCP EST state you
need to read the ipchains man page.
	</para>
	<para>
For more explanation of the secure_tcp strategy also see the
<link linkend="hash_table">explanation of the director's hash table</link>.
	</para>
	<blockquote>
when I play with <command>ipchains -M -S > [value] 0 0</command>
the variable <filename>/proc/sys/net/ipv4/vs/timeout_established</filename> is modified
even when <filename>/proc/sys/net/ipv4/vs/secure_tcp</filename> is set to 0,
so I'm not using the secure TCP defense.
The "real" timeout is of course set to [value] when a new TCP connection appears.
So should I understand that timeout_established, timeout_udp,... are always
modified by  "<command>ipchains -M -S ....</command> whatever I use or not secure TCP defense but
if secure-tcp is set to 0, other variables give the timeouts to use? If so, are
these variable accessible or how to check their value?
	</blockquote>
	<para>
	<command>ipchains -M -S</command> modifies the two TCP and the UDP timeouts in
the two <filename>secure_tcp</filename> modes: off and on. 
So, ipchains changes the three timeout_XXX vars. 
When you change the <filename>timeout_*</filename> vars you change them for
<filename>secure_tcp=on</filename> only. 
Think for the timeouts as you have two sets: for the two <filename>secure_tcp</filename> modes: on and off. 
<command>ipchains</command> changes the 3 vars in the both sets. 
While <filename>secure_tcp</filename> is off, changing <filename>timeout_*</filename> does not
affect the connection timeouts. 
They are used when <filename>secure_tcp</filename> is on.
	</para>
	<note>
Joe: <command>ipchains 0 value 0</command>, where <filename>value=10</filename>, 
does not change the timeout values or number
of entries seen in <filename>InActConn</filename> 
or seen with <command>netstat -M</command>, 
or <command>ipchains -M -L -n</command>.
	</note>
	<para>
LVS has its own tcpip state table, when in <filename>secure_tcp</filename> mode.
	</para>
	<para>
carl.huang
	</para>
	<blockquote>
what are the <filename>vs_tcp_states[ ]</filename> and 
<filename>vs_tcp_states_dos[ ]</filename> elements in the
in <filename>ip_vs_conn</filename> structure for?
	</blockquote>
	<para>
Roberto Nibali <emphasis>ratz (at) tac (dot) ch</emphasis> 16 Apr 2001
	</para>
	<para>
The <filename>vs_tcp_states[]</filename> table is the modified state transition table for the
TCP state machine. The <filename>vs_tcp_states_dos[]</filename> is a yet again modified state
table in case we are under attack and <filename>secure_tcp</filename> is enabled. It is tigher
but not conforming to the RFC anymore. Let's take an example how you can
read it:
	</para>
<programlisting><![CDATA[
static struct vs_tcp_states_t vs_tcp_states [] = {
/*      INPUT */
/*        sNO, sES, sSS, sSR, sFW, sTW, sCL, sCW, sLA, sLI, sSA */
/*syn*/ {{sSR, sES, sES, sSR, sSR, sSR, sSR, sSR, sSR, sSR, sSR }},
/*fin*/ {{sCL, sCW, sSS, sTW, sTW, sTW, sCL, sCW, sLA, sLI, sTW }},
/*ack*/ {{sCL, sES, sSS, sES, sFW, sTW, sCL, sCW, sCL, sLI, sES }},
/*rst*/ {{sCL, sCL, sCL, sSR, sCL, sCL, sCL, sCL, sLA, sLI, sSR }},
]]></programlisting>
	<para>
The elements 'sXX' mean state XX, so for example, sFW means TCP state
FIN_WAIT, sSR means TCP state SYN_RECV and so on. Now the table describes
the state transition of the TCP state machine from one TCP state to
another one after a state event occured. For example: Take row 2 starting
with sES and ending with sCL. At the first, commentary row, you see the
incoming TCP flags (syn,fin,ack,rst) which are important for the state
transition. So the rest is easy. Let's say, you're in row 2 and get a fin
so you go from sES to sCW, which should by conforming to RFC and Stevens.
	</para>
	<para>
Short illustration:
	</para>
<programlisting><![CDATA[
/*           , sES,
/*syn*/ {{   ,    ,
/*fin*/ {{   , sCW,
]]></programlisting>
	<para>
It was some months ago last year when Wensong, Julian and I discussed
a security enhancement for the TCP state transition and after some
heavy discussion they implemented it. 
So the second table <filename>vs_tcp_states_dos[]</filename> was born. 
(look in the mailing list in early 2000).
	</para>
	</section>
	<section id="dos_mailing_list">
	<title>DoS, from the mailing list</title>
		<section id="syn_floods">
		<title>Malicious attacks (SYN floods)</title>
		<para>
LVS has been tested with a 100Mbit/sec syn-flooding attack by
Alan Cox and Wensong.
		</para>
		<para>
Each connection requires 128 bytes. A machine with 128M of free
memory could hold 1M concurrent connections. An average connection
lasts 300secs. Connections which just receive the syn packet are
expired in 30secs (starting ipvs 0.8 ). An attacker would have
to initiate 3k connections/sec (600Mbps) to maintain the memory
at the 128M mark and would require several T3 lines to keep up
the attack.
		</para>
		</section>
		<section id="dos_testing">
		<title>testing DoS</title>
		<para>
joern maier 22 Nov 2000
		</para>
		<blockquote>
I've got a problem protecting my LVS from SYN-flood attacks.
Somehow the <filename>drop_entry</filename> mechanism seems not to work.
Doing a SYN-flood with 3 clients to my LVS ( 1 director + 3 RS ) the system gets unreachable.
A single realserver under the same attack by those clients stays alive.
		</blockquote>
		<para>
Julian
		</para>
		<para>
You can't SYN flood the director with only 3 clients.
You need more clients
(or as an alternative, you can download <link linkend="testlvs">testlvs</link>
from the LVS web site).
What does <command>ipvsadm -Ln</command> show under attack?
How you activate <filename>drop_entry</filename>?
What does <command>cat drop_entry</command> show?
		</para>
		<blockquote>
all realservers have <filename>tcp_syncookies</filename> enabled (1),
<filename>tcp_max_syn_backlog=128</filename>,
the director is set <filename>drop_entry</filename> var to 1 
(<command>echo 1 > drop_entry</command>).
Before compiling the kernel, I set the table size to 2^20.
My Director has 256 MB and no other applications running.
		</blockquote>
		<para>
You don't need such a large table, really.
		</para>
		<para>
Francois JEANMOUGIN <emphasis>Francois (dot) JEANMOUGIN (at) 123multimedia (dot) com</emphasis>
04 Nov 2004
		</para>
		<blockquote>
			<para>
I'm currently facing a ddos syn-flood attack against my cluster. Fortunately,
those guys do not have enough machines to flood all my servers and the
service is still up and running. They seem to use spoofed source IPs (as
usual) so I can't even know where it comes from.
			</para>
			<para>
Anyway, It is now 24 hours they are playing like that, and I would like to
stop it. Do you have an idea? Don't tell me that I have to use iptables to
reduce the syn rate, I can't :). I have a lot of mobile clients, and the wap
gateways can send me a lot of valid syns.
			</para>
		</blockquote>
		<para>
Jacob Coby <emphasis>jcoby (at) listingbook (dot) com</emphasis> 04 Nov 2004 
		</para>
		<para>
You can try turning on tcp_syncookies:
http://www.mail-archive.com/focus-linux@securityfocus.com/msg00185.html
		</para>
<programlisting><![CDATA[
echo 1 > /proc/sys/net/ipv4/tcp_syncookies
]]></programlisting>
		<para>
I forgot to mention that I've had tcp_syncookies enabled on individual 
systems for about 3 years now with no problems.  I've had it enabled on 
every machine in a LVS-DR cluster for 6 months with no problems.
		</para>
		<blockquote>
			<para>
With testlvs and two clients, my LVS gets to a denial of service,
although <command>cat drop_entry</command> shows me a "1".
			</para>
<programlisting><![CDATA[
director:/etc/lvs# ipvsadm -Ln:
192.168.10.1:80 lc
192.168.1.4:80	Tunnel 	1	0	33246
192.168.1.3:80	Tunnel 	1	0	33244
192.168.1.2:80	Tunnel 	1	0	33246
]]></programlisting>
		</blockquote>
		<para>
run testlvs with 100,000 source addresses.
		</para>
		<blockquote>
			<para>
during the flooding attack the connection values stay around this size.
Using the SYN-flood tool with which I tried it before, ivsadm shows me
			</para>
<programlisting><![CDATA[
192.168.10.1:80 lc
192.168.1.4:80	Tunnel 	1	0	356046
192.168.1.3:80	Tunnel 	1	0	355981
192.168.1.2:80	Tunnel 	1	0	356013
]]></programlisting>
			<para>
so it shows me about ten times as many connections as your tool.
I took a look at the packets, both are quiet similar, they only differ in the
Windowsize (testlvs has 0, the other tool uses a size of 65534) and sequence
numbers (o.k. checksum as well)
			</para>
			<para>
I am activating drop entry like this:
			</para>
			<para>
I switch on my computer (director) and start linux with the LVS Kernel
			</para>
<programlisting><![CDATA[
cd /proc/sys/net/ipv4/vs
echo 1 > drop_entry
]]></programlisting>
		</blockquote>
		<para>
Julian
		</para>
		<para>
Maybe you need to tune amemthresh. 1024 pages (4MB) are too
low value. How much memory does "free" show under attack?
You can try with 1/8 RAM size for example.
The main goal of these defense strategies is to keep free memory in the director,
nothing more.
The defense strategies are activated according to the free memory size.
The packet rate is not considered.
		</para>
		<para>
joern maier
		</para>
		<blockquote>
That sounds all good to me, but what I'm really wondering about is, 
why has the <filename>drop_entry</filename> variable still a value of 1.
I thought it has to be 2 when my System is under attack?
To me it looks like LVS does not even think
it's under attack and therefore does not use the <filename>drop_entry</filename> mechanism.
		</blockquote>
		<para>
You are right. 
You forgot to specify when the LVS to think it is under attack. 
<filename>drop_entry</filename> switches automatically
from 1 to 2 when the free memory reaches <filename>amemthresh</filename>.
Do you know that your free memory is below 4MB?
See <ulink url="http://www.linuxvirtualserver.org/docs/defense.html">defense strategies</ulink>.
		</para>
		<para>
So, 1,000,000 entries created from the other tool uses
128MB memory. You have 256MB :) To reduce the amount
of memory the kernel sees, boot with <filename>mem=128MB</filename> (in lilo)
or set <filename>amemthresh</filename> to 32768 or 
run <link linkend="testlvs">testlvs</link>
with more source addresses (2,000,000).
I'm not sure if the last will help if the other tool you use does not
limit the number of spoofed addresses. But don't run testlvs with
less than -srcnum 2000000. If the setup allows rate > 33,333 packets/sec
LVS can create 2,000,000 entries that expire for 60 seconds (the
SYN_RECV timeout). Better not to use the -random option in testlvs
for this test.
		</para>
		<para>
So, you can test with such large values but make sure you
tune amemthresh in production with the best value for your director.
The default value is not very useful. You can test whether 1/8 is
a good value (8192 for 4K page size).
		</para>
		<para>
Sameer Garg <emphasis>sameer (dot) garg (at) gmail (dot) com</emphasis> 15 Apr 2008 
		</para>
		<blockquote>
			<para>
We have been experiencing D/Dos on http. The LVS is uneffected by the
D/Dos but the real servers are suffering. Beside the D/Dos the LVS is
currently handling 5 subdomains and approximately 10QPS.
			</para>
			<para>
We are using LVS-Tun configuration. Due to our distributed setup and
service provider limitation we can't put a perimeter firewall so we
are thinking of stopping them at or before the LVS.
			</para>
			<para>
At the director I have tuned the route flush and route garbage
collection variables but that is all I could figure out.After reading
the howto and the mailing list I have concluded  that it is possible
to use iptalbles with LVS-DR and LVS-NAT.  Is it advisable to put
iptables on the director in a LVS-TUN setup?
			</para>
			<para>
Unrelated question: Anybody using a opensource firewall Iptables/pf in
production for 100M connection?
			</para>
		</blockquote>
		<para>
Michael Schwartzkopff <emphasis>misch (at) multinet (dot) de</emphasis> 15 Apr 2008 
		</para>
		<para>
Yes. iptables is even nescessary if you take LVS descisions based on the mangle 
table.
I haven't seen any 100M setups in production, but shold be possible. Perhaps this helps:
http://lists.sans.org/pipermail/unisog/2005-August/025040.html
		</para>
		<para>
Bgs <emphasis>bgs (at) bgs (dot) hu</emphasis>
		</para>
		<para>
We use lvs+netfilter solution with ~Gbit/sec traffic and DDoS attack 
above gigabit. We had DDoS attacks in the 60k-100k bot range. You can 
handle these with a reasonable level of service, but if you want your 
users to experience just small hiccups a mitigator on the outmost layer 
with a good feedback from your system into the mitigator blacklist.
		</para>
		</section>
		<section id="dos_design">
		<title>on the design of the DoS preventer</title>
		<para>
Alan Cox <emphasis>alan (at) lxorguk (dot) ukuu (dot) org (dot) uk</emphasis>>
		</para>
		<para>
The biggest problem with load balancing, when you need to do this sort
of trickery (and its one the existing load balancing patches seem to have
is that if you store per connection state then a synflood will take out
your box (if you run out of ram) or run a delightfully efficient DoS
attack, if you don't.
The moment you factor time into your state tables you are basically well
and truly screwed.
		</para>
		<para>
Lars Marowsky-Bree <emphasis>lmb (at) teuto (dot) net</emphasis>> 8 Jun 1999
		</para>
		<blockquote>
			<para>
This can be solved with a hashtable, where you take the source ip as the key
and look up the server to direct the request. Since the hash table is fixed
size, we can do with fixed resources.
			</para><para>
Given a proper hash function, this scheme is _ideal_ for basic round-robin
and weighted round-robin with fixed weights and we should look at implementing
this. Keeping state if not necessary _is_ a bug.
			</para><para>
We are screwed however and can't do this if we want to do least-connections,
dynamic load-based balancing, add servers at a later time etc and still
deliver sticky connections (ie that connections from client A will stay on
server B until a timeout happens or server B dies).
			</para><para>
Basically, since we _need_ to keep state on a per-client basis for this we
can be screwed easily by bombarding us with a randomized source IP.
			</para><para>
Now - for all but the most simple load balancing, we NEED to keep state. So,
we need to weasle our way out of this mess somehow.
			</para><para>
One approach would be to integrate SYN cookies into the load-balancer itself
and only pass on the connection if the TCP handshake succeeded.
Now, there are
a few obvious problems with this: It is a very complex task. And, it still
screws us in the case of an UDP flood.
			</para><para>
"The easy way out" for TCP connections is to do this stuff in user space -
a load-balancing proxy, which connects to the backend servers. Problems with
this are that it isn't transparent to the backend servers anymore (all
connections come from the IP of the loadbalancer), it does not scale as well
(no direct routing approach etc possible), and we still did not solve UDP.
			</para><para>
I propose the following: We continue to maintain state like we always did.
But when we hit, lets say, 32,000 simulteanous connections, we go into "overload"
mode - that is, all new connections are mapped using the hash table like Alan
proposed, but we still search the stateful database first.
			</para><para>
There are a few problems with this too: It is not as fast as the pure hash
table, since we need to look into the stateful database before consulting the
hashtable. If weights change during overload mode, sticky connections can't
be easily guaranteed (I thus propose to NOT change weights during overload mode,
or at least ignore the changes with regard to the hashing).
			</para><para>
However, these are disadvantages which only happen under attack. At the
moment, we would simply crash, so it IS an improvement. It is a fully
transparent approach and works with UDP too. The effort to implement this
is acceptable. (if it were userspace I would give it a try sometime;)
			</para><para>
And if we implement this scheme for fixed loadbalancing, which someone else
definetely should, reusing the code here might not be that much of a problem.
			</para>
		</blockquote>
		</section>
		<section id="masq_table_timeouts">
		<title>Timeout in MASQ tables</title>
		<para>
Michael McConnell <emphasis>michaelm (at) eyeball (dot) com</emphasis> 08 Oct 2001
			</para><para>
the command
<programlisting><![CDATA[
#ipchains -L -M
]]></programlisting>
returns a list of masqueraded connections, <emphasis>i.e.</emphasis>
			</para><para>
<programlisting><![CDATA[
TCP  01:38.01 10.1.1.41           21.1.112.43         80 (80) -> 4052
TCP  01:38.08 10.1.1.41           21.1.112.43         80 (80) -> 4053
TCP  00:25.09 10.1.1.11           20.170.180.17       80 (80) -> 4430
]]></programlisting>
			</para><para>
If ipchains (kernel 2.2) has been set with a 10hr TCP timeout
			</para><para>
<programlisting><![CDATA[
ipchains -M -S 7200 0 0 (10 hour TCP timeout)
]]></programlisting>
			</para><para>
Now these connections remain (will populate the <command>ipvsadm</command> table)
for 10 hours.
Does anyone have any suggestions as to how to purge this table manually?
If I run out of ports, I get a DoS
(2 hr timeout, 30,000 TCP connections...DoS)
			</para><para>
			</para><para>
<blockquote><para>
Peter Mueller
			</para><para>
If you alter /proc/net/ip_masquerade, it will break
the established connection. Isn't that what you want to do?
</para></blockquote>
			</para><para>
No matter what I do I can not
seem to reset, clear or modify this manually.
			</para><para>
<blockquote><para>
if you do not like the prospect of altering directly perhaps try a shell
script:
			</para><para>
<programlisting><![CDATA[
#!/bin/sh
#hopefully this works and you won't shoot yourself in the foot...
ipchains -M -S 1 0 0
sleep 5
ipchains -M -S 7200 0 0
]]></programlisting>
</para></blockquote>
			</para><para>
Setting this Value only effects *NEW* connections, connections already set
are unaffected.
			</para><para>
Julian Anastasov <emphasis>ja (at) ssi (dot) bg</emphasis>>
			</para><para>
	Without a timeout values specific for each LVS virtual
service and another for the masqueraded connections it is difficult
to play such games. It seems only one timeout needs to be separated,
the TCP EST timeout. The reason that such support is not in 2.2 is
because nobody wants to touch the user structures. IMO, it can
be added for 2.4 if there are enough free options in <command>ipvsadm</command> but
it also depends on some implementation details.
			</para><para>
	If you worry for the free memory you can use some defense
<ulink url="http://www.linuxvirtualserver.org/docs/defense.html">the LVS DoS defense strategies</ulink>
<programlisting><![CDATA[
	echo 1 > drop_entry
]]></programlisting>
		</para>
		</section>
		<section id="BIG_IP">
		<title>BIG IP SYN Check and Dynamic Reaping</title>
		<para>
unknown 
		</para>
		<blockquote>
Is there anything like the 
<ulink url="http://www.f5.com/solutions/tech/security/">
BIG-IP syn check</ulink> 
(http://www.f5.com/solutions/tech/security/)
to prevent DoS?.
		</blockquote>
		<para>
Ratz 12 Aug 2004
		</para>
		<para>
For the RS or the director or both?
I think you are referring to those two marketing features:
		</para>
		<para>
SYN Check: One type of DoS attack is known as a SYN flood in which an 
attack is made for the purpose of exhausting a system's resources 
leaving it unable to establish legitimate connections. The BIG-IP 
system's SYN Check feature works to alleviate SYN flooding by sending 
cookies to the requesting client on the server's behalf and by not 
recording state information for connections that have not completed the 
initial TCP handshake. This unique feature ensures that servers only 
process legitmate connections and the BIG-IP SYN queue is not exhausted, 
and normal TCP communication can continue. The SYN Check feature 
complements the BIG-IP Dynamic Reaping feature, in that while the 
Dynamic Reaping handles established connection flooding, SYN Check 
addresses embryonic connection flooding to prevent the SYN queue from 
becoming exhausted.
		</para>
		<para>
Dynamic Reaping - The BIG-IP software contains two global settings that 
provide the ability to reap connections adaptively. Used to prevent 
denial-of-service (DoS) attacks, enterprises can specify a low-watermark 
threshold and a high-watermark threshold. The low-watermark threshold 
determines at what point adaptive reaping becomes more aggressive. The 
high-watermark threshold determines when non-established connections 
through the BIG-IP product will no longer be allowed. The value of this 
variable represents a percentage of memory utilization. Once memory 
utilization has reached this mark, connections are disallowed until the 
available memory has been reduced to the low-watermark threshold.
		</para>
		<para>
SYN Check can be enabled on the RS for all major Unices. For the rest
    we have to give in the fact that LVS is a software load balancer and
    does not have the possibilites a hardware load balancer has with
    regard to doing SYN cookies for other servers. Also limiting the
    backlog queue on a per socket basis definitely helps.
		</para>
		<para>
Dynamic Reaping could very well be brought into conjuction with our
TCP DoS defense mechanism. Read about it at:
<ulink url="http://www.linux-vs.org/docs/defense.html">LVS DoS defense</ulink>
(http://www.linux-vs.org/docs/defense.html).
		</para>
		<para>
I have tested F5 BigIP load balancers and I was able to flood the RS 
just as well as using LVS. SYN flooding cannot be prevented, it can only 
be rate limited. It's a flaw in the TCP protocol which we'll have to 
live with. There are a couple of defense mechanisms but non of them can 
really distinguish between malicious TCP/SYN and friendly TCP/SYN.
		</para>
		</section>
	</section>
	<section id="testing_DoS_strategies" xreflabel="testing DoS strategies">
	<title>Testing DoS Strategies with testlvs: Creating large numbers of InActConn</title>
		<section id="testlvs"><title>testlvs</title>
		<para>
testlvs (by Julian <emphasis>ja (at) ssi (dot) bg</emphasis>) is available on
<ulink url="http://www.ssi.bg/~ja/">Julian's software page</ulink>.
			</para><para>
It sends a stream of SYN packets (SYN flood) from a range of addresses
(default starting at 10.0.0.1) simulating connect requests from many clients.
Running testlvs from a client will occupy most of the resources of your
director and the director's screen/mouse/keyboard will/may lock up for the
period of the test.
To run testlvs, I export the testlvs directory (from my director)
to the realservers and the client and run everything off this exported
directory.
			</para><para>
<blockquote><para>
Fabrice <emphasis>fabrice (at) urbanet (dot) ch</emphasis> 11 Dec 2001
			</para><para>
I can reach 60K SYN/s with a mean of about 54K using a PIII 500MHz client.
			</para><para>
The load on the LVS-NAT director was a high (always 100%
system usage, and a swap between the ttys takes about 3-5 seconds).
That poor box couldn't handle the load and wasn't able to send back
packets (maybe only 10 per seconds). This means that the DoS was
successfull but it's only working during the flood, it won't brake any
services (thanks to Syn_Cookies).
</para></blockquote>
			</para><para>
Julian Anastasov <emphasis>ja (at) ssi (dot) bg</emphasis>
			</para><para>
	If you want to measure a maximal possible rate use -srcnum 10
or another small number to avoid beating the routing cache in the
director. If you need to test the defense strategies you need large
value in -srcnum. The default is too small for this, it avoids errors.
			</para><para>
<blockquote><para>
I think the only way to prevent the DoS in this case is to upgrade the
LVS box hardware :)
</para></blockquote>
			</para><para>
	Not always. LVS does not protect the realservers. The
result can be the output pipe loaded from replies on DoS attack.
You should try some ingress rate limiting, independent from LVS.
Of course, your hardware should not be blocked from such attacks,
you need faster MB+CPU if you care for such problems.
			</para><para>
<blockquote><para>
I looked with the vmstat 1 and 10, as Julian recommanded.
Shouldn't the values of the number of interruptions with "vmstat 10" be
10 times more than "vmstat 1"'s?
</para></blockquote>
			</para><para>
	No, they should be equal, up to 5% are good, they show
that the process scheduling really works. If you are under attack
and you can't handle it then the snapshots from vmstat 1 are delayed
and the results differ too much from the results provided for
longer time interval.
			</para><para>
<blockquote><para>
I got with vmstat 1: interrupts = ca. 400'000,  cpu sys = 100
and with vmstat 10: interrupts = ca. 60'000, cpu sys = 100
</para></blockquote>
			</para><para>
	Your director reached its limits. You should try to flood
it with slower client(s). When you see that the input packet rate is
equal to the successfully forwarded packets (received on the real
server) then stop to slow down the attack. You reach the maximal
packet rate possible to deliver to the realservers. On NAT you
should consider the replies, they are not measured with testlvs
tests. They will need may be the same CPU power.
		</para></section>
		<section id="show_traffic" xreflabel="show traffic script"><title>configure realserver</title><para>
The realserver is configured to reject packets with src_address 10.0.0.0/8.
			</para><para>
Here's my modified version of Julian's show_traffic.sh
which is run on the realserver to measure throughput.
Start this on the realserver before running testlvs on the client.
For your interest you can look on the realserver
terminal to see what's happening during a test.
			</para><para>
<programlisting><![CDATA[
#!/bin/sh
#show_traffic.sh
#by Julian Anastasov ja (at) ssi (dot) bg
#modified by Joseph Mack jmack (at) wm7d (dot) net
#
#run this on the realserver before starting testlvs on the client
#when finished, exit with ^C.
#
#suggested parameters for testlvs
#testlvs VIP:port -tcp -packets 20000
#where
#	VIP:port - target IP:port for test
#
#packets are sent at about 10000 packets/sec on my
#100Mbps setup using 75 and 133MHz pentium classics.
#
#------------------------------------------
# setup a few things
to=10		#sleep time
trap return INT #trap ^C from the keyboard (used to exit the program)
iface="$1"	#NIC to listen on

#------------------------------------------
#user defined variables

#network has to be the network of the -srcnet IP
#that is used by the copy of testlvs being run on the client
#(default for testlvs is 10.0.0.0)

network="10.0.0.0"
netmask="255.0.0.0"
#-------------------------------------------
function get_packets() {
	cat /proc/net/dev | sed -n "s/.*${iface}:\(.*\)/\1/p" | \
	awk '{ packets += $2} ; END { print packets }'
}

function call_get_packets() {
	while true
	do
		sleep $to
		p1="`get_packets "$iface"`"
		echo "$((($p1-$p0)/$to)) packets/sec"
		p0="$p1"
	done
}
#-------------------------------------------
echo "Hit control-C to exit"

#initialise packets at $iface
p0="`get_packets "$iface"`"

#reject packets from $network
route add -net $network netmask $netmask reject

call_get_packets

#restore routing table on exit
route del -net $network netmask $netmask reject
#-------------------------------------------
]]></programlisting>
		</para>
		</section>
		<section id="testlvs_configure_director">
		<title>configure director</title>
		<para>
			</para><para>
I used LVS-NAT on a 2.4.2 director, with
netpipe (port 5002) as the service on two realservers.
You won't be using netpipe for this test, ie
you won't need a netpipe server on the realserver
You just need a port that you can set up an LVS on and
netpipe is in my /etc/services, so the port shows up as a name
rather than a number.
			</para><para>
Here's my director
			</para><para>
<programlisting><![CDATA[
director:/etc/lvs# ipvsadm
IP Virtual Server version 0.2.6 (size=4096)
Prot LocalAddress:Port Scheduler Flags
  -> RemoteAddress:Port               Forward Weight ActiveConn InActConn
TCP  lvs2.mack.net:netpipe rr
  -> RS2.mack.net:netpipe             Masq    1      0          0
  -> RS1.mack.net:netpipe             Masq    1      0          0
]]></programlisting>
		</para>
		</section>
		<section id="testlvs_run_on_client">
		<title>run testlvs from client</title><para>
run testlvs (I used v0.1) on the client.
Here testlvs is sending 256 packets from 254 addresses (the default)
in the 10.0.0.0 network.
(My setup handles 10,000 packets/sec. 256 packets appears to be instantaneous.)
			</para><para>
<programlisting><![CDATA[
client: #./testlvs 192.168.2.110:5002 -tcp -packets 256
]]></programlisting>
			</para><para>
when the run has finished, go to the director
			</para><para>
<programlisting><![CDATA[
director:/etc/lvs# ipvsadm
IP Virtual Server version 0.2.6 (size=4096)
Prot LocalAddress:Port Scheduler Flags
  -> RemoteAddress:Port               Forward Weight ActiveConn InActConn
TCP  lvs2.mack.net:netpipe rr
  -> RS2.mack.net:netpipe             Masq    1      0          127
  -> RS1.mack.net:netpipe             Masq    1      0          127
]]></programlisting>
			</para><para>
(If you are running a 2.2.x director, you can get more information from
ipchains -M -L -n, or netstat -M. For 2.4.x use cat /proc/net/ip_conntrack.)
			</para><para>
This output shows 254 connections that have closed are are waiting to timeout.
A minute or so later, the InActConn will have cleared (on my machine, it's 50secs).
			</para><para>
If you send the same number of packets (256), from 1000 different addresses,
(or 1000 packets to 256 addresses),
you'll get the same result in the output of <command>ipvsadm</command> (not shown)
			</para><para>
<programlisting><![CDATA[
client: #./testlvs 192.168.2.110:5002 -tcp -srcnum 1000 -packets 256
]]></programlisting>
			</para><para>
In all cases, you've made 254 connections.
			</para><para>
If you send 1000 packets from 1000 addresses, you'd expect 1000 connections.
			</para><para>
<programlisting><![CDATA[
./testlvs 192.168.2.110:5002 -tcp -srcnum 1000 -packets 1000
]]></programlisting>
			</para><para>
Here's the total number of InActConn as a function
of the number of packets (connection attempts).
Results are for 3 consecutive runs,
allowing the connections to timeout in between.
			</para><para>
The numbers are not particularly consistent between runs
(aren't computers deterministic?). Sometimes the blinking
lights on the switch stopped during a test, possibly a result
of the tcp race condition (see the
<ulink url="http://www.linuxvirtualserver.org/Joseph.Mack/performance/single_realserver_performance.html">performance page</ulink>)
			</para><para>
<programlisting><![CDATA[
packets		InActConn
 1000		 356, 368, 377
 2000		 420, 391, 529
 4000		 639, 770, 547
 8000		 704, 903,1000
16000		1000,1000,1000
]]></programlisting>
			</para><para>
You don't get 1000 InActConn with 1000 packets (connection attempts).
We don't know why this is.
			</para><para>
<blockquote><para>
Julian
			</para><para>
I'm not sure what's going on. In my tests there are dropped packets
too. They are dropped before reaching the director, maybe from the input
device queue or from the routing cache. We have to check it.
</para></blockquote>
		</para>
		</section>
		<section id="dos_drop_entry">
		<title>InActConn with drop_entry defense strategy</title>
		<para>
repeating the control experiment above, but using the drop_entry strategy
(see <link linkend="DoS">the DoS strategies</link> for more information).
			</para><para>
director:/etc/lvs# echo "3" >/proc/sys/net/ipv4/vs/drop_entry
			</para><para>
<programlisting><![CDATA[
packets		InActConn, drop_entry=3
 1000		369,368,371
 2000		371,380,409
 4000		467,578,458
 8000		988,725,790
16000		999,994,990
]]></programlisting>
			</para><para>
The drop_entry strategy drops 1/32 of the entries every second,
so the number of InActConn decreases linearly during the timeout
period, rather than dropping suddenly at the end of the timeout
period.
		</para>
		</section>
		<section id="dos_drop_packet">
		<title>InActConn with drop_packet defense strategy</title>
		<para>
repeating the control experiment above, but using the drop_packet strategy
(see <link linkend="DoS">the DoS strategies</link> for more information).
			</para><para>
director:/etc/lvs# echo "3" >/proc/sys/net/ipv4/vs/drop_packet
			</para><para>
<programlisting><![CDATA[
packets		InActConn, drop_packet=3
 1000		338,339,336
 2000		331,421,382
 4000		554,684,629
 8000		922,897,480,662
16000		978,998,996
]]></programlisting>
			</para><para>
The drop_packet=3 strategy will drop 1/10 of the packets before sending them
to the realserver. The connections will all timeout at the same time
(as for the control experiment, about 1min), unlike for the drop_entry strategy.
With the variability of the InActConn number, it is hard to see the drop_packet
defense working here.
		</para>
		</section>
		<section id="dos_secure_tcp">
		<title>InActConn with secure_tcp defense strategy</title><para>
repeating the control experiment above, but using the secure_tcp strategy
(see <link linkend="DoS">the DoS strategies</link> for more information).
The SYN_RECV value is the suggested value for LVS-NAT.
			</para><para>
<programlisting><![CDATA[
director:/etc/lvs# echo "3" >/proc/sys/net/ipv4/vs/secure_tcp
director:/etc/lvs# echo "10" >/proc/sys/net/ipv4/vs/timeout_synrecv
]]></programlisting>
			</para><para>
<programlisting><![CDATA[
packets		InActConn, drop_packet=3
 1000		 338, 372, 359
 2000		 405, 367, 362,
 4000		 628, 507, 584
 8000		 642,1000, 886
16000		1000,1000,1000
]]></programlisting>
			</para><para>
This strategy drops the InActConn from the <command>ipvsadm</command> table after 10secs.
		</para>
		</section>
		<section id="dos_max_inactconn">
		<title>maximum number of InActConn</title>
		<para>
If you want to get the maximum number of InActConn, you need to run the
test for longer than the FIN timeout period (here 50secs).
2M packets is enough here.
As well you want as many different addresses used as possible.
Since testlvs is connecting from the 10.0.0.0/8 network,
you could have 254^3=16M connections.
Since only 2M packets can be passed before connections start
to timeout and the director connection table reaches a steady state
with new connections arriving and old connections timing out, there is
no point in sending packets from more that 2M source addresses.
			</para><para>
Note: you can view the contents of the connection table with
			</para><para>
2.2
<itemizedlist>
<listitem><para>netstat -Mn
</para></listitem><listitem><para>cat /proc/net/ip_masquerade
</para></listitem></itemizedlist>
			</para><para>
2.4
<itemizedlist>
<listitem><para>cat /proc/net/ip_vs_conn
</para></listitem></itemizedlist>
			</para><para>
			</para><para>
Here's the InActConn with various defense strategies. The InActConn is
the maximum number reachable, the scrnum and packets are the numbers
needed to saturate the director. The time of the test must exceed the timeouts.
InActConn was determined by running a command like this
			</para><para>
<programlisting><![CDATA[
client: #./testlvs 192.168.2.110:5002 -tcp -srcnum 1000000 -packets 2000000
]]></programlisting>
			</para><para>
and then adding the (two) entries in the InActConn column from the output
of ipvsadm.
			</para><para>
<programlisting><![CDATA[
kernel		DoS strategy   	InActConn	-srcnum	-packets (10k/sec)
SYN cookie
no		secure_tcp	13,400		200,000	200,000
		syn_recv=10
no		none		99,400		500,000 1,000,000
yes		non		70,400		1,000,000 2,000,000
]]></programlisting>
		</para>
		</section>
		<section id="limit_on_inactconn">
		<title>Is the number of InActConn a problem?</title>
		<para>
<blockquote><para>
edited from Julian
			</para><para>
The memory used is 128 bytes/connection and 60k connections
will tie up 7M of memory. LVS does not use system sockets.
LVS has its own connection table. The limit is the amount of
memory you have - virtually unlimited.
The masq table (by default 40960 connections per protocol).
is a separate table and is used only for LVS/NAT FTP
or for normal MASQ connections.
</para></blockquote>
			</para><para>
However the director
was quite busy during the testlvs test. Attempts to connect to other LVS'ed services
(not shown in the above <command>ipvsadm</command> table) failed. Netpipe tests run at the same
time from the client's IP (in the 192.168.1.0/24 network) stopped, but resumed
at the expected rate after the testlvs run completed (i.e. but before the InActConn
count dropped to 0).
		</para>
		</section>
		<section id="65k_ports">
		<title>port starved machines</title>
		<para>
Matthijs van der Klip <emphasis>matthijs (dot) van (dot) der (dot) klip (at) nos (dot) nl</emphasis> 10 Nov 2001
			</para><para>
used a fast (Origin 200) single client to generate generate
between 3000 and 3500 hits/connections per second to his LVS'ed
web cluster. No matter how many/few realservers in the cluster, he
could only get 65k connections.
			</para><para>
<blockquote><para>
Julian
			</para><para>
	You are missing one reason for this problem: the fact that
your client(s) create connections from limited number of addresses
and ports. Try to answer yourself from how many different client
saddr/sport pairs you hit the LVS cluster. IMO, you reach this
limit. I'm not sure how many test client hosts you are using. If the
client host is only one then there is a limit of 65536 TCP ports per
src IP addr. Each connection has expiration time according to its
proto state. When the rate is high enough not to allow the old entries
to expire, you reach a situation where the connections are reused,
i.e. the connection number showed from ipvsadm -L does not increase.
</para></blockquote>
		</para></section>
	</section>
	<section id="debugging_lvs">
	<title>Debugging LVS</title>
		<section>
		<title>new way</title>
		<para>
<programlisting><![CDATA[
echo x > /proc/sys/net/ipv4/debug_level
where 0&lt;x&lt;9
]]></programlisting>
		</para></section>
		<section><title>old way (may still work - haven't tested it)</title><para>
Is there any way to debug/watch the path between the director and the
realserver?
			</para><para>
<blockquote><para>
Wensong
			</para><para>
below the entry
			</para><para>
CONFIG_IP_MASQUERADE_VS_WLC=m
			</para><para>
in /usr/src/linux/.config, add the line
			</para><para>
CONFIG_IP_VS_DEBUG=y
			</para><para>
This switch affects ip_vs.h and ip_vs.c.
make clean in /usr/src/linux/net/ipv4 and rebuild the kernel and
modules.
</para></blockquote>
			</para><para>
(other switches you will find in the code are IP_VS_ERR IP_VS_DBG IP_VS_INFO )
			</para><para>
Look in syslog/messages for the output. The actual location of
the output is determined by /etc/syslog.conf. For instance
<programlisting><![CDATA[
kern.*                                          /usr/adm/kern
]]></programlisting>
sends kernel messages to /usr/adm/kern (re-HUP syslogd if
you change /etc/syslog.conf). Here's the output when LVS
is first setup with ipvsadm
<programlisting><![CDATA[
$ tail /var/adm/kern

Nov 13 17:26:52 grumpy kernel: IP_VS: RR scheduling module loaded.
]]></programlisting>
			</para><para>
(
Note CONFIG_IP_VS_DEBUG is not a debug level output, so you don't
need to add
			</para><para>
<programlisting><![CDATA[
*.=debug                                        /usr/adm/debug
]]></programlisting>
			</para><para>
to your syslog.conf file
)
			</para><para>
Finally check whether packets are forwarded successfully
through direct routing.
(also you can use tcpdump to watch packets between machines.)
			</para><para>
<blockquote><para>
Ratz <emphasis>ratz (at) tac (dot) ch</emphasis>
			</para><para>
Since some recent lvs-versions, extensive debugging can be enabled to get either
more information about what's exactly going on or to help you understanding the
process of packet handling within the director's kernel. Be sure to have
compiled in debug support for LVS (CONFIG_IP_VS_DEBUG=yes in .config)
			</para><para>
You can enable debugging by setting:
<programlisting><![CDATA[
echo $DEBUG_LEVEL > /proc/sys/net/ipv4/vs/debug_level
]]></programlisting>
where DEBUG_LEVEL is between 0 and 10.
			</para><para>
The do a tail -f /var/log/kernlog and watch the output flying by while
connecting to the VIP from a CIP.
			</para><para>
If you want to disable debug messages in kernlog do:
<programlisting><![CDATA[
echo 0 > /proc/sys/net/ipv4/vs/debug_level
]]></programlisting>
			</para><para>
If you run tcpdump on the director and see a lot of packets with the same ISN
and only SYN and the RST, then either
			</para><para>
<itemizedlist>
<listitem><para>you haven't handled the <xref linkend="LVS-HOWTO.arp_problem"/>
(most likely)
</para></listitem><listitem><para>you're trying to connect directly to the VIP from within the cluster itself
</para></listitem></itemizedlist>
</para></blockquote>
		</para>
		</section>
	</section>
	<section id="many_reader_single_writer">
	<title>realserver content: filesystem or database? (the many reader, single writer problem)</title>
	<para>
The client can be assigned to any realserver.
One of the assumptions of LVS is that all realservers have the same content.
This assumption is easy to fullfill for services like http, 
where the administrator updates the files on all realservers when needed.
For services like mail or databases, the client writes to storage on one realserver.
The other realservers do not see the updates unless something intervenes.
Various tricks are described elsewhere here for mailservers and databases.
These require the realservers to write to common storage (for mail
the mailspool is nfs mounted; for databases, the LVS client connects
to a database client on each realserver and these database
clients write to a single databased on a backend machine, or the
databased's on each realserver are capable of replicating).
	</para>
	<para>
One solution is to have a file system which can propagate changes to
other realservers. We have mentioned gfs and coda in several places
in this HOWTO as holding out hope for the future. People now have these
working.
	</para>
	<para>
Wensong Zhang <emphasis>wensong (at) gnuchina (dot) org</emphasis> 05 May 2001
	</para>
	<blockquote>
It seems to me that
<ulink url="http://www.coda.cs.cmu.edu">Coda</ulink>
is becoming quite stable. I have run coda-5.3.13
with the root volume replicated on two coda file servers for near two
months, I haven't met problem which need manual maintance until now. BTW,
I just use it for testing purposes, it is not running in production site.
	</blockquote>
	<para>
Mark Hlawatschek <emphasis>hlawatschek (at) atix (dot) de</emphasis> 2001-05-04
	</para>
	<blockquote>
we've had good experiences with the use of
<ulink url="http://www.redhat.com/software/rha/gfs/">GFS</ulink>.
We've used LVS with the GFS for about one year in older
versions and it worked quite stably. We successfully demonstrated the
solution with a newer version of GFS (4.0) at the CEBit 2001.
Several domains (i.e. http://www.atix.org) will be served by the new
configuration next week.
	</blockquote>
	<para>
Mark's slides from his
<ulink url="http://ace73.atix.de/downloads/santime/decus-hlawatschek-release.pdf">talk in German at DECUS in Berlin (2001)</ulink>
is available.
	</para>
	<para>
K Kopper <emphasis>karl_kopper (at) yahoo (dot) com</emphasis> 6 Jun 2006 
	</para>
	<para>
To share files on the real servers and ensure that all
real servers see the same changes at the same time a
good NAS box or even a Linux NFS server built on top
of a SAN (using Heartbeat to failover the NFS server
service and IP address the real servers use to access
it) works great. If you run "legacy" applications that
perform POSIX-compliant locking you can use the
instructions at http://linux-ha.org/HaNFS to build
your own HA NFS solution with two NFS server boxes and
a SAN (only one NFS server can mount the SAN disks at
a time, but at failover time the backup server simply
mounts the SAN disks and fails over the locking statd
information). Of course purchasing a good HA NAS
device has other benefits like non-volatile memory
cache commits for faster write speed.
	</para>
	<para>
If you are building an application from scratch then
your best bet is probably to store data using a
database and not the file system. The database can be
made highly available behind the real servers on a
Heartbeat pair (again with SAN disks wired up to both
machines in the HA pair, but only one server mounting
the SAN disks where the database resides at a time).
Heartbeat comes with a Filesystem script that helps
with this failover job. If your applications store
state/session information in SQL and can query back
into the database at each request (a cookie, login id,
etc.) then you will have a cluster that can tolerate
the failure of a real server without losing session
information--hopefully just a reload click on the web
browser for all but the worst cases (like ~Sin flight~T
transactions).
	</para>
	<para>
With either of these solutions your applications do
not have to be made cluster-aware. If you are
developing something from scratch you could try
something like Zope Enterprise Objects (ZEO) for
Python, or in Java (JBOSS) there is JGroups to
multicast information to all Java containers/threads,
but then you~Rll have to re-solve the locking problem
(something NFS and SQL have a long track record of
doing safely). But you were just asking about file
systems and I got off topic . . .
	</para>
	<para>
Brad Dameron <emphasis>brad (at) seatab (dot) com</emphasis> 7 Jun 2006 
	</para>
	<para>
I am using RedHat GFS with my SAN to do file sharing. Works great.
	</para>
	<note>
It's not clear what the following poster is doing. 
He may just be smb exporting a filesystem to the realserver. 
Here's more info on LVS'ing <xref linkend="samba"/>.
	</note>
	<para>
Kai Suchomel1 <emphasis>KAISUCH (at) de (dot) ibm (dot) com</emphasis> 12 Jun 2006
	</para>
	<para>
The Samba Service is responsible to share a SAN Filesystem.
Here especially GPFS. 
This File system is shared among all the Samba Services on the RS.
So that when the client connects to the VIP and the SAN Filesystem for the Client, 
it is transparent on which RS the connection will be established.
When the RS fails, after doing a reconnect, the Client can access the SAN
Filesystem over another RS.
I am trying to implement HA for Samba Filesharing.
	</para>
	<para>
Joe
	</para>
	<para>
What happens to the state
stored on the domain server (or whatever the LVS appears to
be to the windows clients), when the RS goes down? Are you
copying files between the LVS and the windows clients?
What are your windows clients using the LVS for?
So you have a single SAN exporting files to multiple
realservers? Why do you do this? Is this faster than having
the SAN export the files directly? Or are the realservers
doing something else as well? (or doesn't the SAN export
files to windows machines?)
	</para>
	<para>
Kai
	</para>
	<para>
The Realservers are responsible for the FIlesystem, here GPFS is used.
GPFS is IBMs Cluster Filessystem.
	</para>
	<para>
Joe: I guess we'll hear more later.
	</para>
	</section>
	<section id="IPSec">
	<title>Developement: Supporting IPSec on LVS</title>
	<para>
see <ulink url="http://www.ssi.bg/~ja/LVS_IPSEC.txt">
Julian's notes on developing code for IPSec over LVS</ulink>.
	</para>
	<para>
Farid Sawari has <xref linkend="sarwari"/> working with 2.4 and 2.6 LVS-NAT.
	</para>
	</section>
</section>
<section id="LVS-HOWTO.icmp">
<title>LVS: ICMP</title>
<note>
ICMP is an IP protocol for sending error messages between 2 hosts at the end of a segment.
ICMP messages are not propagated beyond the two hosts involved in the error condition. 
</note>
<para>
Sometime in 2000, code was added for LVS to handle ICMP.
For LVS'ed services, the director handles
<link linkend="ICMP_redirects">ICMP redirects</link>
and <link linkend="ICMP_redirects">MTU discovery</link>
delivering them to the correct realserver.
ICMP packets for non-LVS'ed services are delivered locally.
</para>
<para>
Setups where packets are not defragmented properly are difficult to diagnose: 
only large packets are affected and the setup will work for much of the time, 
but clients will see their connection hanging. 
The realservers can have large numbers of connections hung in FIN_WAIT.
We see this when packets are enlarged by encapsulation and then decapsulated 
before arriving at their destination, midway in their passage through the network,
and the en/de-capsulating mechanism doesn't send icmp need_defrag packets.
</para>
<itemizedlist>
	<listitem>
LVS-Tun: 
ipip encapsulation reduces the packet payload, sometimes requiring fragmentation. 
This is not handled properly by Linux. 
See <xref linkend="MTU"/>.
	</listitem>
	<listitem>
Weird Hardware: see <xref linkend="weird_hardware_VII"/>.
	</listitem>
</itemizedlist>
	<section id="ICMP_redirects">
	<title>MTU discovery and ICMP handling</title>
	<para>
joern maier 13 Dec 2000
	</para>
	<blockquote>
	<para>
What happens if an ICMP "host unreachable" messages
is send to the director because a client went down ?
Are the entrys from the connection table removed ?
	</para>
	</blockquote>
	<para>
Julian Anastasov <emphasis>ja (at) ssi (dot) bg</emphasis> Wed, 13 Dec 2000
	</para>
	<para>
No
	</para>
	<blockquote>
	<para>
Are the messages forwarded to the Realservers ?
	</para>
	</blockquote>
	<para>
Julian 13 Dec 2000
	</para>
	<para>
        Yes, the embedded TCP or UDP datagram is inspected and
this information is used to forward the ICMP message to the right
realserver. All other messages that are not related to existing
connections are accepted locally.
	</para>
	<para>
Eric Mehlhaff <emphasis>mehlhaff (at) cryptic (dot) com</emphasis> passed on more info
	</para>
	<para>
Theoreticaly, path-mtu-discovery happens on every new tcp
connection. In most cases the default path MTU is fine.  
It's weird cases (ethernet LAN conenctions with low MTU WAN
connections ) that point out broken path-MTU discovery.
<emphasis>i.e.</emphasis> for
a while I had my home LAN (MTU 1500) hooked up via a modem
connection that I had set MTU to 500 for. The minimum MTU in
this case was the 500 for my home, but there were many broken web
sites I could not see because they had blocked out the
ICMP-must-fragment packets on their servers. One can also see
the effects of broken path mtu discovery on FDDI local networks.
	</para>
	<para>
Anyway, here's some good web pages about it:
	</para>
<programlisting><![CDATA[
http://www.freelabs.com/&#126;whitis/isp_mistakes.html
http://www.worldgate.com/&#126;marcs/mtu/
]]></programlisting>
	<para>
What happens if a realserver is connected to a client which is no
longer reachable? ICMP replies go back to the VIP and will not
neccessarily be forwarded to the correct realserver.
	</para>
	<para>
Jivko Velev <emphasis>jiko (at) tremor (dot) net</emphasis>
	</para>
	<blockquote>
		<para>
Assume that we have TCP connections...and realserver is trying to
respond to the client, but it cannot reach it (the client is down,
the route doesn't exist anymore, the intermadiate gateway is
congested). In these cases your VIP will receive ICMP packets
dest unreachable, source quench and friends. If you dont route
these packets to the correct realserver you will affect performance
of the LVS. For example the realserver will continue to resend
packets to the client because they are not confirmed, and gateways
will continue to send you ICMP packets back to VIP for every
packets they droped. The TCP stack will drop these kind of
connections after his timeouts expired, but if the director
forwarded the ICMP packets to the appropriate realserver,
this will occur a little bit earlier, and will avoid overloading
the redirector with ICMP stuff.
		</para>
		<para>
When you receive a ICMP packet it contains the full IP header
of the packet that cause this ICMP to be generated + 64bytes of
its data, so you can assume that you have the TCP/UDP header too.
So it is possible to implement "Persitance rules" for ICMP packages.
		</para>
		<para>
Summary: This problem was handled in kernel 2.2.12 and earlier by
having the configure script turn off icmp redirects in the
kernel (through the proc interface). For 2.2.13 the ipvs patch
handles this. The configure script knows which kernel you are
using on the director and does the Right Thing (TM).
		</para>
	</blockquote>
	<para id="icmp_redirects" xreflabel="icmp redirects">
Joe: from a posting I picked off Dejanews by Barry Margolin
	</para>
	<blockquote>
		<para>
the criteria for sending a redirect are:
		</para>
		<orderedlist>
			<listitem>
The packet is being forwarded out the same physical
   interface that it was received from,
			</listitem>
			<listitem>
The IP source address in the packet is on the same
Logical IP (sub)network as the next-hop IP address,
			</listitem>
			<listitem>
The packet does not contain an IP source route option.
			</listitem>
		</orderedlist>
		<para>
Routers ignore redirects and shouldn't even be receiving them in
the first place, because redirects should only be sent if the
source address and the preferred router address are in the same
subnet. If the traffic is going through an intermediary router,
that shouldn't be the case.  The only time a router should get
redirects is if it's originating the connections (<emphasis>e.g.</emphasis> you do a
"telnet" from the router's exec), but not when it's doing normal
traffic forwarding.
		</para>
	</blockquote>
	<para>
unknown
	</para>
	<para>
Well, remember that ICMP redirects are just bandages to cover routing
problems. No one really should be routing that way.
	</para>
	<para>
ICMP redirects are easily spoofed, so many systems ignore them.
Otherwise they risk having their connectivity being disconnected on whim.
Also, many systems no longer send ICMP redirects because some people
actually want to pass traffic through an intervening system!  I don't know
how FreeBSD ships these days, but I suggest that it should ship with
ignore ICMP redirects as the default.
	</para>
	</section>
	<section id="icmp_redirects_for_lvs_nat">
	<title>LVS code only needs to handle icmp redirects for LVS-NAT and not for LVS-DR and LVS-Tun </title>
	<para>
Julian: 12 Jan 2001
	</para>
	<para>
	Only for LVS-NAT do the packets from the realservers hit
the forward chain, i.e. the outgoing packets. LVS-DR and LVS-Tun
receive packets only to LOCAL_IN, i.e. the FORWARD chain, where the
redirect is sent, is skipped. The incoming packets for LVS/NAT use
ip_route_input() for the forwarding, so they can hit the FORWARD chain
too and to generate ICMP redirects after the packet is translated.
So, the problem always exists for LVS/NAT, for packets in the both
directions because after the packets are translated we always use
ip_forward to send the packets to the both ends.
	</para>
	<para>
	I'm not sure but may be the old LVS versions used
ip_route_input() to forward the DR traffic to the realservers.
But this was not true for the TUN method. This call to ip_route_input()
can generate ICMP redirects and may be you are right that for the
old LVS versions this is a problem for DR. Looking in the Changelog
it seems this change occured in LVS version 0.9.4, near Linux 2.2.13.
So, in the HOWTO there is something that is true: there is no ICMP
redirect problem for LVS/DR starting from Linux 2.2.13 :) But the
problems remains for LVS/NAT even in the latest kernel. But this
change in LVS is not created to solve the ICMP redirect problem. Yes,
the problem is solved for DR but the goal was to speedup the forwarding
for the DR method by skipping the forward chain. When the forward
chain is skipped the ICMP redirect is not sent.
	</para>
	<para>
ICMP redirects and LVS:
(Joe and Wensong)
	</para>
	<para>
The test setups shown in this HOWTO for LVS-DR and LVS-Tun have the
client, director and realservers on the same network. In
production the client will connect via a router from a remote
network (and for LVS-Tun the realservers could be remote and all
on separate networks).
	</para>
	<para>
The client forwards the packet for VIP to the director, the
director receives the packet on the eth0 (eth0:1 is an alias of
eth0), then forwards the packet to the realserver through eth0.
The director will think that the packet came and left through the
same interface without any change, so an icmp redirect is send to
the client to notify it to send the packets for VIP directly to
the RIP.
	</para>
	<para>
However, when all machines are on the same network, the client
is not a router and is directly connected to the director, and
ignores the icmp redirect message and the LVS works properly.
	</para>
	<para>
If there is a router between the client and the director, and it
listens to icmp redirects, the director will send an icmp
redirect to the router to make it send the packet for VIP to the
realserver directly, the router will handle this icmp redirect
message and change its routing table, then the LVS/DR won't work.
	</para>
	<para>
The symptoms is that once the load balancer sends an ICMP
redirect to the router, the router will change its routing table
for VIP to the realserver, then all the LVS won't work. Since
you did your test in the same network, your LVS client is in the
same network that the load balancer and the server are, it
doesn't need to pass through a router to reach the LVS, you won't
have such a symptom. :)
	</para>
	<para>
Only when LVS/DR is used and there is only one interface to
receive packets for VIP and to connect the realserver, there is
a need to suppress the ICMP redirects of the interface.
	</para>
	<para>
Joe
	</para>
	<blockquote>
	<para>
The ICMP redirects is turned on in the kernel 2.2 by default.
The configure script turns off icmp redirects on the director
using sysctl
	</para>
<programlisting><![CDATA[
echo 0 > /proc/sys/net/ipv4/conf/eth0/send_redirects
]]></programlisting>
	</blockquote>
	<para>
(Wensong)
In the reverse direction, replies coming back from the realserver
to the client
	</para>
<programlisting><![CDATA[
                                  |<------------------------|
                                  |                  realserver
 client <--> tunlhost1=======tunlhost2 --> director ------->|
]]></programlisting>
	<para>
After the first response packet arrives from the realserver
at the tunlhost2, tunlhost2 will try to send the packet through
the tunnel. If the packet is too big, then tunlhost2 will
send an ICMP packet to the VIP to fragment the packet. In
the previous versions of ipvs, the director won't forward
the ICMP packet to (any) realserver. With 2.2.13 code has
been added to handle the icmp redirects and make the
director forward icmp packets to the corresponding servers.
	</para>
	<blockquote>
If the client has two connections to the LVS (say telnet and http)
each to 2 different realservers and the client goes down, the director
gets 2 ICMP_DEST_UNREACH packets. The director knows from the CIP:port
which realserver to send the icmp packet to?
	</blockquote>
	<para>
Wensong Zhang 21 Jan 2000
	</para>
	<para>
The director handles ICMP packets for virtual
services long time ago, please check the ChangeLog of the code.
	</para>
	<blockquote>
		<para>
ChangeLog for 0.9.3-2.2.13
		</para>
		<para>
The incoming ICMP packets for virtual services will be forwarded
to the right realservers, and outgoing ICMP packets from virtual
services will be altered and send out correctly. This is important
for error and control notification between clients and servers,
such as the MTU discovery.
		</para>
	</blockquote>

	<para>
Joe
	</para>
	<blockquote>
If a realserver goes down after the connection is established, will the
client get a dest_unreachable from the director?
	</blockquote>
	<para>
No. Here is a design issue. If the director sends an ICMP_DEST_UNREACH
immediately, all tranfered data for the established connection will be
lost, the client needs to establish a new connection. Instead, we
would rather wait for the timeout of connection, if the realserver
recovers from the temporary down (such as overloaded state) before the
connection expires, then the connection can continue. If the real
server doesn't recover before the expire, then an ICMP_DEST_UNREACH is
sent to the client.
	</para>
	<blockquote>
 If the client goes down after the connection is established, where do the
 dest_unreachable icmp packets generated by the last router go?
	</blockquote>
	<para>
If the client is unreachable, some router will generate an
ICMP_DEST_UNREACH packet and sent to the VIP, then the director will
forward the ICMP packet to the realserver.
	</para>
	<blockquote>
Since icmp packets are udp, are the icmp packets routed through the
director independantly of the services that are being LVS'ed. <emphasis>i.e.</emphasis> if the
director is only forwarding port 80/tcp, from CIP to a particular RIP,
does the LVS code which handles the icmp forward all icmp packets from the
CIP to that RIP. What if the client has a telnet session to one realserver
and http to another realserver?
	</blockquote>
	<para>
It doesn't matter, because the header of the original packet is
encapsulated in the icmp packet. It is easy to identify which
connection is the icmp packet for.
	</para>
	</section>
	<section id="icmp_checksum_errors">
	<title>ICMP checksum errors</title>
	<para>
(This problem pops up in the mailing list occasionally, <emphasis>e.g.</emphasis>
Ted Pavlic on 2000-08-01.)
	</para>
	<para>
Jerry Glomph Black
	</para>
	<blockquote>
		<para>
The kernel debug log (dmesg) occasionally gets bursts of
messages of the following form on the LVS box:
		</para>
<programlisting><![CDATA[
IP_MASQ:reverse ICMP: failed checksum from 199.108.9.188!
IP_MASQ:reverse ICMP: failed checksum from 199.108.9.188!
IP_MASQ:reverse ICMP: failed checksum from 199.108.9.188!
IP_MASQ:reverse ICMP: failed checksum from 199.108.9.188!
IP_MASQ:reverse ICMP: failed checksum from 199.108.9.188!
]]></programlisting>
		<para>
What is this, is it a serious problem, and how to deal with it?
		</para>
	</blockquote>
	<para>
Joe
	</para>
	<para>
I looked in dejanews. No-one there knows either and people
there are wondering if they are being attacked too. It appears
in non-LVS situations, so it probably isn't an LVS problem.
The posters don't know the identity of the sending node.
	</para>
	<para>
Wensong
	</para>
	<para>
I don't think it is a serious problem. If these messages are
generated, the ICMP packets must fail in checksum. Maybe the ICMP
packets from 199.108.9.188 is malformed for some unknown reason.
	</para>
	<para>
Here are some other reports
	</para>
	<para>
Hendrik Thiel <emphasis>thiel (at) falkag (dot) de</emphasis> 18 Jun 2001
	</para>
	<blockquote>
		<para>
I noticed this in dmesg and messages:
		</para>
<programlisting><![CDATA[
kernel: IP_MASQ:reverse ICMP:failed checksum from 213.xxx.xxx.xxx!
last message repeated 1522 times.
]]></programlisting>
		<para>
Is this lvs specific (using nat) ? or can this be an attack?
		</para>
	</blockquote>
	<para>
Alois Treindl <emphasis>alois (at) astro (dot) ch</emphasis>
	</para>
	<blockquote>
		<para>
I see those too
		</para>
<programlisting><![CDATA[
Jun 17 22:16:19 wwc kernel: IP_MASQ:reverse ICMP: failed checksum from 193.203.8.8!
]]></programlisting>
		<para>
not as many as you but every few hours a bunch.
		</para>
	</blockquote>
	<para>
Juri Haberland  <emphasis>juri (at) koschikode (dot) com</emphasis>
	</para>
	<blockquote>
From time to time I see them also on a firewall masquerading the companies
net. I always assumed it is a corrupted ICMP packet... Who knows...
	</blockquote>
	</section>
	<section id="icmp_timeouts">
	<title>ICMP Timeouts</title>
	<para>
Laurent Lefoll <emphasis>Laurent (dot) Lefoll (at) mobileway (dot) com</emphasis> 14 Feb 2001
	</para>
	<blockquote>
what is the usefulness of the ICMP packets that are sent when
new packets arrives for a TCP connection that timed out for in LVS box ? I
understand obviously for UDP but I don't see their role for a TCP connection...
	</blockquote>
	<para>
Julian
	</para>
	<para>
I assume your question is about the reply after ip_vs_lookup_real_service.
	</para>
	<para>
It is used to remove the open request in SYN_RECV state in the
realserver. LVS replies for more states and may be some OSes report
them as soft errors (Linux), others can report them as hard errors,
who knows.
	</para>
	<blockquote>
 it's about ICMP packets from a LVS-NAT director to the client.
 For example, a client accesses a TCP virtual service and then stops sending data
 for a long time, enough for the LVS entry to expire. When the client try to send
 new data over this same TCP connection the LVS box sends ICMP (port unreachable)
 packets to the client. For a TCP connection how do these ICMP packets
 "influence" the client ? It will stop sending packets to this expired (for the
 LVS box...) TCP connection only after its own timeouts, doesn't it ?
	</blockquote>
	<para>
By default TCP replies RST to the client when there is no
existing socket.
LVS does not keep info for already expired connections
and so we can only reply with an ICMP rather than sending a TCP RST.
(If we implement
TCP RST replies, we could reply TCP RST instead of ICMP).
	</para>
	<para>
What does the client do with this ICMP packet?
By default, the application does not listen for ICMP errors
and they are reported as soft errors after a TCP timeout
and according to the TCP state.
Linux at least allows the application to listen for such ICMP replies.
The application can register for these ICMP errors and
detect them immediately as they are received by the socket.
It is not clear whether it is a good idea to accept such
information from untrusted sources.
ICMP errors are reported immediately for some TCP (SYN) states.
	</para>
	</section>
	<section id="PMTUD" xreflabel="path MTU discovery">
	<title>PMTUD (path MTU discovery)</title>
	<para>
see <xref linkend="MTU"/>
	</para>
	</section>
	<section id="icmp_bug" xreflabel="icmp_bug">
	<title>Long sessions through LVS DR director terminated by icmp-host-prohibited (ICMP type 3 code 10)</title>
	<note>
Klaas's posting of a bug. We don't know what it's about yet.
	</note>
	<para>
Klaas Jan Wierenga <emphasis>k.j.wierenga (at) home (dot) nl</emphasis> 26 Mar 2007
	</para>
	<para>
I have a problem where sometimes some long standing mp3 streaming sessions over HTTP are terminated, 
because the LVS-DR director sends an ICMP type 3 code 10 - host unreachable (icmp-host-prohibited) 
packet to the client (the source of the mp3 stream). 
When this happens the client stops sending packets for 15 minutes 15 minutes 
(the TCP idle session timeout of LVS?)
	</para>
	<para>
Initially I suspected the LVS director but after some investigation I found
out that it never sends icmp-host-prohibited 
(not in <filename>linux/net/ipv4/ipvs/*</filename> source files).
The only other possibility was netfilter sending it
(found in <filename>net/ipv4/netfilter/ipt_REJECT.c: send_unreach(*pskb, ICMP_HOST_ANO</filename>).
But why is this sent on an existing, established and active connection?
	</para>
	<para>
The relevant parts of my initial iptables was (<filename>/etc/sysconfig/iptables</filename>):
	</para>
<programlisting><![CDATA[
*filter
:FORWARD ACCEPT [0:0]
:INPUT ACCEPT [0:0]
:RH-Firewall-1-INPUT - [0:0]
:OUTPUT ACCEPT [0:0]
-A FORWARD -j RH-Firewall-1-INPUT
-A INPUT -j RH-Firewall-1-INPUT
-A RH-Firewall-1-INPUT -i lo -j ACCEPT
-A RH-Firewall-1-INPUT -p icmp -m icmp --icmp-type any -j ACCEPT
-A RH-Firewall-1-INPUT -m state --state RELATED,ESTABLISHED -j ACCEPT
-A RH-Firewall-1-INPUT -p tcp -m state -m tcp --dport 80 --state NEW -j ACCEPT
-A RH-Firewall-1-INPUT -j REJECT --reject-with icmp-host-prohibited COMMIT
]]></programlisting>
	<para>
After I changed the port 80 rule to the one below effectively disabling
connection tracking on port 80 the problem disappeared.
	</para>
<programlisting><![CDATA[
-A RH-Firewall-1-INPUT -p tcp --dport 80 -j ACCEPT
]]></programlisting>
	<para>
Initially I made this iptables change on the LVS director, but then the
realservers would send icmp-host-prohibited sometimes on established
connections, after also changing iptables on the realservers did the problem
go away.
	</para>
	<para>
It is still unclear to me why netfilter would decide to send icmp-
host-unreachable on established connection when connection tracking is
active. Maybe someone on the netfilter list can shed some light on this.
	</para>

	<para>
later on following up:
26 Jun 2007 
	</para>
	<para>
I never figured it out.
It appears to be a netfilter problem because when I changed my
firewall rules (<filename>/etc/sysconfig/iptables</filename>) 
to disable connection tracking, the problem went away.
	</para>
<programlisting><![CDATA[
# Don't do connection tracking on port 80 and 8000 because sometimes it
# results in dropped connections due to ICMP_HOST_UNREACHABLE messages
#-A RH-Firewall-1-INPUT -p tcp -m state -m tcp --dport 80 --state NEW -j ACCEPT
#-A RH-Firewall-1-INPUT -p tcp -m state -m tcp --dport 8000 --state NEW -j ACCEPT
-A RH-Firewall-1-INPUT -p tcp --dport 80 -j ACCEPT
-A RH-Firewall-1-INPUT -p tcp --dport 8000 -j ACCEPT
]]></programlisting>
	</section>
</section>
<section id="LVS-HOWTO.failover" xreflabel="Failover">
<title>LVS: High Availability, Failover protection</title>
	<section id="failover_intro">
	<title>Introduction</title>
	<para>
In a production system you want to be able to do planned maintenance:
remove, upgrade, add or replace nodes, without interruption of service to the client.
Machines may crash, so a mechanism
for automatically handling this is required too.
Redundancy of services on the realservers is one of the useful features of LVS.
One machine/service can be removed from the functioning virtual server
for upgrade or moving of the machine and can be brought back on line later
without interruption of service to the client.
	</para>
	<para>
The most common problem found is loss of network access 
or extreme slowdown (or DoS).
Hardware failure or an OS crash (on unix) is less likely.
Spinning media (disks) fail near the end of the warrantee period 
(in my experience) - you should replace your disks preemptively.
The director(s) don't need hard disks.
I've run my director from 30M of files (including perl and full glibc)
pulled from my Slackware distribution.
Presumably a mini Linux distribution would be even smaller.
You should be able to boot off a floppy/cdrom/flash disk
and load all files onto a small ramdisk.
Logging information (<emphasis>e.g.</emphasis> for security) 
can be mailed/scp'ed at intervals
to a remote machine via a NIC used for monitoring 
(note: not one of the NIC's used to connect 
to the outside world or to the realservers).
Reconfiguring services on the fly with <command>ipvsadm</command> 
will not interrupt current sessions.
You can reasonably expect your director to stay up for a long time without
crashing and will not need to be brought down for servicing
any more than any other diskless router.
	</para>
	<para>
An alternative to flash memory is a cdrom
	</para>
	<para>
"Matthew S. Crocker" <emphasis>matthew (at) crocker (dot) com</emphasis> 14 May 2002
	</para>
	<blockquote>
My LVS servers are currently EXT2 but I'm either going to go with a
diskless server using netboot or a CD based server.  Our LVS is becoming
our firewall (using NAT) and I'd rather have it stay bullet proof.  CD
based if it gets compromised I just reboot it.
	</blockquote>
	<para>
The LVS code itself does not provide high availability.
Other software is used in conjunction with LVS to provide high availability
(<emphasis>i.e.</emphasis> to switch out a failed realserver/service or a failed director).
Several families of tools are available to automatically handle failout for LVS.
Conceptually they are a separate layer to LVS.
Some separately setup LVS and the monitoring layer.
Others will setup LVS for you and administratively the two layers are not separable.
	</para>
	<para>
Here's an article on the
<ulink url="http://www.codesta.com/knowledge/management/uptime_realities/index.jsp">
high cost of delivering high uptime computer service</ulink> by Steve Levin.
The author says that NASA runs on three 9's (99.9&percnt;) reliability.
For this level of reliability, the system has to handle all faults without human intervention.
	</para>
	<para>
There are two types of failures with an LVS.
	</para>
	<itemizedlist>
		<listitem>
			<para>
<link linkend="director_failure">director failure</link>
			</para>
			<para>
This is handled by having a redundant director available.
Director failover is handled in the
<ulink url="http://www.ultramonkey.org">Ultra Monkey Project</ulink>
by <ulink url="http://www.linux-ha.org/">heartbeat</ulink>.
Other code used for failover is
<link linkend="keepalived_vrrpd">vrrpd</link>
in <link linkend="keepalived_vrrpd">keepalived</link>.
			</para>
			<para>
The director maintains session information client IP, 
realserver IP, realserver port), and on failover 
this information must be available on the new director.
On simple failover, where a new director is just swapped in, 
in place of the old one, the session information 
is not transferred to the
new director and the client will loose their session.
Transferring this information is handled by the
<xref linkend="LVS-HOWTO.server_state_sync_demon"/>.
			</para>
			<para>
The <ulink url="http://keepalived.sourceforge.net/">keepalived project</ulink>
by Alexandre Cassen works with both Linux-HA and LVS.
<link linkend="keepalived_vrrpd">keepalived</link> watches the health of services.
It also controls failover of directors using <link linkend="keepalived_vrrpd">vrrpd</link>.
			</para>
		</listitem>
		<listitem>
			<para>
<xref linkend="LVS-HOWTO.realserver_failure"/>,
or failure of a service on a realserver
			</para>
			<para>
This is relatively simple to handle (compared to director failover).
			</para>
			<para>
An agent running on the director monitors the services on the realservers.
If a service goes down, that service is removed from the <command>ipvsadm</command> table.
When the service comes back up, the service is added back to the <command>ipvsadm</command> table.
There is no separate handling of realserver failure.
If the server catches on fire
(a concern of Mattieu Marc <emphasis>marc (dot) mathieu (at) metcelo (dot) com</emphasis>),
the agent on the director will just remove that realserver's
services from the <command>ipvsadm</command> table as they go down.
			</para>
			<para>
For LVS-DR, you cannot monitor a service running on the VIP on the realserver from
the director (since the director also has the VIP).
Instead you arrange for the service to bind to both the VIP and the RIP
(or to 0.0.0.0) and test the health of the service bound to the RIP,
as a proxy for the service running on the VIP.
			</para>
			<para>
You can monitor a tcp service by connecting to the ip:port.
Testing of udp services (<emphasis>e.g.</emphasis> DNS)
is a little more problematic.
			</para>
			<note>
The DNS monitor that comes with Mon does a functional test on the realserver,
asking it to retreive a known DNS entry.
			</note>
			<para>
Tim Hasson <emphasis>tim (at) aidasystems (dot) com</emphasis> 27 Jan 2004
			</para>
			<para>
The 
<ulink url="http://www.austintek.com/LVS/LVS-HOWTO/HOWTO/files/hasson_dns.patch">
attached patch 
</ulink>
(http://www.austintek.com/LVS/LVS-HOWTO/HOWTO/files/hasson_dns.patch)
gets around the problem with ldirectord not doing any udp
checks, by using Net::DNS to test if the DNS server is resolving.
You cannot simply just do a udp connect check, as udp is connectionless :)
That is why ldirectord will always keep all realservers on any udp service,
regardless of the service status.
So, you just basically install Net::DNS from cpan, and apply the attached
patch to /usr/sbin/ldirectord
You can change www.test.com in the patch or in ldirectord after you applied
the patch if you need to specify an internal domain or something else.
The patch applied to several ldirectord versions cleanly, including the latest
from ultramonkey heartbeat-ldirectord-1.0.4.rpm (I believe it was ldirectord
1.76)
			</para>
			<para>
The configure script monitors services with Mon.
Setting up mon is covered in <xref linkend="LVS-HOWTO.failover"/>
The configure script will set up mon for you. Mon was the first tool used
with LVS to handle failover. It does not handle director failover.
			</para>
			<para>
In the <ulink url="http://www.ultramonkey.org">Ultra Monkey Project</ulink>,
service failure is monitored by ldirectord.
			</para>
		</listitem>
	</itemizedlist>
	<para>
For service failure on the realserver or director failure (without the
<xref linkend="LVS-HOWTO.server_state_sync_demon"/>),
the client's session with the realserver will be lost.
This is no different to what would happen if you were using a single server instead of an LVS.
With LVS and failover however, the client will be presented with a new connection when they
initiate a reconnect.
Since only one of several realservers failed, only some of the clients
will experience loss of connection,
unlike the single server case where all clients loose their connection.
In the case of http, the client will not even realise that the server/service has failed,
since they get a new connection when clicking on a link.
For session oriented connections (<emphasis>e.g.</emphasis>https, telnet)
all unsaved data and session information will be lost.
	</para>
	<para>
If you have a separate firewall, it doesn't have to be Linux
	</para>
	<para>
Clint Byrum <emphasis>cbyrum (at) spamaps (dot) org</emphasis> 2005/22/05
	</para>
	<para>
Honestly, as good as LVS is for real server load balancing, for
firewalls I like OpenBSD with CARP and pfsync.
CARP+pfsync provides easy, scalable load balancing and HA for firewalls.
pf, the OpenBSD firewall, is very well written and nicely designed. Give
it a look, www.openbsd.com.
	</para>
	<note>
	<para>
Carp is available for Linux too.
	</para>
	</note>
	<para>
anon
	</para>
	<blockquote>
The part I do not understand is how to have a LVS cluster
failover without using HA. Since HA is limited to two nodes?
	</blockquote>
	<para>
There are several packages available to do failover
for LVS. Some of them overlap in functionality and
some of them are for different purposes. 
	</para>
	<para>
The LVS can have any number of realservers. 
Failover of realservers occurs by changing the <command>ipvsadm</command> table
on the director.
	</para>
	<para>
Director failover occurs by transfering the VIP to the backup director, 
bringing down the primary director, 
and by using the backup copy of the connection table 
(put there by the synch demon) on the backup director.
Once you've moved the VIP, 
the network needs to know that the VIP is associated with a new MAC address. 
To handle this, you can use Yuri Volobuev's <command>send_arp</command>
distributied with the Linux-HA package 
(make sure you understand how arp works: see <xref linkend="vip_devices"/>).
	</para>
	<para>
Director failover and realserver failover are logically separate, 
occur independantly and are done by different pieces of code 
<emphasis>e.g.</emphasis> MON only handles realserver failover.
	</para>
	<para>
Since both functionalities are required in a production LVS, 
some packages have them both. 
When configuring these packages you must remember that the director
failover parts are logically separate from the realserver failover parts.
	</para>
	<para>
Both keepalived and Linux-HA handle director
failover and to monitor the state of service(s)
on the realserver. Keepalived has both
functionalities in the same piece of code
and uses one configure script. Linux-HA
uses ldirectod to handle realserver failover.
I think now that you set up Linux-HA/ldirectord
with one configure script (not sure).
	</para>
	</section>
	<section id="spof" xreflabel="single point of failure">
	<title>Single Point of Failure (SPOF) - you can't protect against everything</title>
	<para>
Redundancy is a method to handle failure in unreliable components.
As a way of checking for unreliable components the concept of a 
"single point of failure" (spof) is used. 
However some components are much more reliable than others 
(<emphasis>e.g.</emphasis> a piece of multicored ethernet cable).
You can safely not replicate them.
Other components are much more expensive than others: it's expensive
to replicate them.
You are not looking for a fail-proof setup: you are looking for
a setup which has a failure rate and cost that the customer
can live with.
	</para>
	<para>
Mark Junk
	</para>
	<blockquote>
I want to setup a lvs cluster firewall but i have only one
ethernet cable from my isp...... So my question is how can i achieve
this. without introducing a single point of failure? Essentilly i need
to plug one cable into two boxes splitting at x
	</blockquote>
	<para>
Joe
	</para>
	<para>
a hub/switch.  
They have low failure rates.
	</para>
	<blockquote>
Yeah that would be a single point of failure though
	</blockquote> 
	<para>
Clint Byrum <emphasis>cbyrum (at) spamaps (dot) org</emphasis> 27 Oct 2004 
	</para>
	<para>
You're already dealing with the cable from your ISP failing, the ultra
redundant power going down, a meteor hitting the building, and their NOC
tech setting fire to the routers.
IMHO, If you really want to eliminate all SPOFs, you have to go
multisite. 
At some point while dealing with the problems of going multisite, it
just becomes ridiculous, and you have to ask yourself what your
clientelle really need in terms of uptime.
	</para>
	<para>
Sebastien BRIZE <emphasis>sebastien (dot) brize (at) libertysurf (dot) fr</emphasis>
	</para>
	<para>
A simple but expensive way is to use a couple of Routing Switches 
(L3/L4)  and double-attachement switches
using RSTP (Rapid Spanning Tree Protocol) for the Switches attachement 
and MRP (Metro Ring Protocol)
(or even RSTP) between both Routing switches.
	</para>
<programlisting><![CDATA[
  RS1 ------ RS2
   |          |
  S1          S2
   |          |
 FW1          FW2
]]></programlisting>
	<para>
RS1 and RS2 may be in different sites, and each equipment may have to power supply.  
This much more expensive than a cable though. 
	</para>
	<para>
Dana Price <emphasis>d (dot) price (at) rutgers (dot) edu</emphasis>
	</para>
	<blockquote>
I've got an Ultramonkey 3.0 LB-DR setup, with two 
directors.  I have heartbeat running over eth0 and a 
crossover on eth1.  Since both heartbeat links have to 
fail for a failover to occur, I'm concerned that something 
like a bad nic, cable, or switch will bring my web service 
down (say eth0 fails but the crossover eth1 is still up). 
Is there any way to define two heartbeat links in ha.cf 
but to have it failover if a designated one dies? That way 
the directors can still maintain state over the second 
link and I'd avoid the split-brained cluster that comes 
with only 1 HB link.
	</blockquote>
	<para>
Joe
	</para>
	<para>
this may be possible and someone else can give you the 
answer, but I'll talk about something else...
	</para>
	<para>
There's only so many things you can worry about, so you pick 
the ones that are most likely to go.
	</para>
	<para>
The most likely problem is your network connection will go 
down - this is usually out of your control.
	</para>
	<para>
Next is mechanical things like disks and fans, or connectors 
not making good contact. This is the problem you have to 
deal with (- see below). Make sure you have ready-to-go 
copies of your disks, just sitting on the shelf next to the 
machine. You can update them by putting them in an external 
USB case and plugging them in somewhere, whenever you change 
your machine. Disks are really cheap compared to the cost of 
the labor of replacing them, or the cost of downtime. As 
well, pre-emptively swap out disks at their warrantee date.
	</para>
	<para>
Possibly you have unreliable power. Where I live in the US, 
I get a 1 sec power bump once a week, when the power company 
must be changing the power feed with a mechanical switch. 
You need a UPS. Such things are unheard of in more advanced 
parts of the world, like Europe, where you can have a 
machine up for 400 days on the regular power without any 
interruptions and UPS are not needed at all.
	</para>
	<para>
I've never had a NIC just fail. I (accidently) kicked the 
BNC connector on one and it died. I killed another with 
electrostatic shock by _not_ touching the computer case 
before putting my fingers near the empty RJ-45 socket. 
That's it - NICs generally don't die and neither do 
switches. The tcpip stack never locks up, unless the whole 
OS is hosed and that doesn't happen a whole lot with Linux 
and if it does, then heartbeat is gone too.
	</para>
	<para>
The connectors/cables to a NIC are another thing. Make sure 
your cables are multistranded and not a single strand for 
each wire. Flexing of single strand wire at the connector 
leads to cracks that show up as intermittant connections. 
Single strand has become the default since the .com boom, 
but they're only tolerated in the commodity market where 
people would rather save 1% cost than have a reliable 
connection. Nowhere else in the electronic industry are they 
used. There's probably not too much problem if the cables 
are just laid out and plugged in and left there without 
movement till the computer is junked, but if you're 
rearranging your cables frequently, use multicored cables.
	</para>
	<para>
Heartbeat has been used with LVS for years and we haven't 
had anyone come up with a split brain yet. (Maybe it happens 
and people dont think it worth mentioning.)
	</para>
	<para>
I would say that a pair of NICs with a single crossover 
cable is probably the most reliable part of your set up. I 
wouldn't bother making it redundant.
	</para>
	</section>
	<section id="stateful_failover" xreflabel="statefull failover">
	<title>Stateful Failover</title>
	<para>
Anywhere that state information is required for continued LVS functioning,
failover will have to transfer the state information to the backup machine.
An LVS can have (some or all of) the following state information
	</para>
	<itemizedlist>
		<listitem>
			<para>
director: ip_vs connection table (displayed with ipvsadm):
<emphasis>i.e.</emphasis> which client is connected to which realserver.
			</para>
			<para>
The <xref linkend="LVS-HOWTO.server_state_sync_demon"/>.
will transfer this information to a backup director.
If this information is not transferred, the client will loose their
virtual service.
For http, this is not a problem, as the client will
get a new connection by hitting "refresh" on the browser.
			</para>
		</listitem>
		<listitem>
			<para>
realserver: ssl session keys
			</para>
			<para>
When setting up https as a service under LVS, https
is setup with persistence, so that the multiple tcp connections required
for an ssl session will all go to the same realserver.
			</para>
			<para>
	On realserver failover, these session keys are lost
and the client has to renegotiate the ssl connection.
Presumably other persistent information, which is much more important
(<emphasis>e.g.</emphasis> shopping cart or database),
is being stored on the LVS in a failover safe manner.
Compared to loss of the customer data,
loss of session keys is not a big deal
and we are not working on a solution for this.
			</para>
		</listitem>
		<listitem>
			<para>
realserver: persistent data <emphasis>e.g.</emphasis> shopping cart on e-commerce sites.
			</para>
			<para>
To allow customers to make purchases over an arbitary long period and for their
session to survive failover of the realserver to which they are connected,
their database information needs to be preserved
in a place where any realserver can get to it.
Originally this was done with cookies
(see the section on <xref linkend="cookie"/>),
but these are instrusive.
Cookies can be stolen or poisoned and many people turn them off
(clients shouldn't be allowing non-trusted machines to write anything on their computer).
All customer state information should instead be stored at the LVS site
(see the section on <xref linkend="LVS-HOWTO.persistent_connection"/>).
			</para>
			<para>
If you store persistent data on the virtual server,
you must write your application to survive failover of the realserver
and long timeouts. (The customer should be able to bring up information
about vacations and leave it on the screen for the spouse to inspect
when they come home. The spouse should be able to click to the next
piece of information without the application crashing.)
			</para>
		</listitem>
		<listitem>
			<para>
tcp state: filter rules on the director and/or realserver
			</para>
			<para>
This information is one level lower on the ISO network diagram
than is the ipvsadm connection information. 
Any particular client can make many tcp connections to a realserver.
			</para>
			<para>
The director is a router
(admittedly with slightly different rules than the normal routers)
and as such just forwards packets.
On failover, a director configured with no filter rules,
can be replaced with an identically configured
backup with no interuption of service to the client.
There will be a time in the middle of the changeover 
where no packets are being transmitted
(and possibly icmp packets are being generated), 
but in general once the new director is online, 
the connection between client and realserver
should continue with no break in established 
tcp connections between the client and the realserver.
			</para>
			<para>
If the director has only stateless filter rules, then the director
still appears as a stateless router and
director failover will occur without interruption of service.
			</para>
			<para>
With iptables, a router (<emphasis>e.g.</emphasis> an LVS director)
can monitor the tcp state of a connection, 
(<emphasis>e.g.</emphasis> NEW, RELATED, ESTABLISHED).
If stateful filter rules are in place 
(<emphasis>e.g.</emphasis> only accept packets
from ESTABLISHED connections) then after failover, 
the new director will be presented packets from tcp connections 
that are ESTABLISHED,
but of which it has no record.
The new director will REJECT/DROP these packets.
			</para>
			<para>
Harald Welte (of netfilter) is in the process of writing code 
for stateful failover of netfilter.
			</para>
			<para>
Ratz, 01 Jun 2004
			</para>
			<blockquote>
				<para>
He has actually done it
(http://cvs.netfilter.org/netfilter-ha/ link dead Feb 2005)
and we can expect it to 
surface the user's world in a couple of months for beta testing.
				</para>
				<para>
Each new rule has to find its place in the existing rule set
resulting in an n^^2 loading of rules.
It can take seconds for 50,000 rules to load.
This is also being worked on with the new pkttables, ct/nf-netlink and 
whatever else the nf guys come up with.
For large rule sets, use hipac <ulink url="http://www.hipac.org/">Hipac</ulink>
(http://www.hipac.org/).
				</para>
			</blockquote>
			<para>
Even though a highly available form of stateful netfilter is now  
available, it really doesn't affect LVS because
			</para>
			<itemizedlist>
				<listitem>
LVS controlled packets do not traverse the netfilter framework
in the normal manner and iptables is not aware of all of
the transfers of packets.
				</listitem>
				<listitem>
LVS does its own connection tracking. 
Untill early 2004, this was not particularly complete,
but Julian has beta grade code out now which should
satisfy most users 
(see <xref linkend="LVS-HOWTO.filter_rules"/>).
This code allows stateful tracking of LVS controlled
packets. 
				</listitem>
				<listitem>
Failover of tcp connection state is already handled by 
<xref linkend="LVS-HOWTO.server_state_sync_demon"/>.
Note that the synch demon only cares whether a
connection is ESTABLISHED and only copies
connections which are ESTABLISHED to the backup director.
Connections in FIN_WAIT etc will timeout on their own
and the backup director doesn't need to know about these
states on becoming the master director.
				</listitem>
			</itemizedlist>
			<para>
The situation on the realserver is a little different.
If a realserver fails, for most services,
there is no way to transfer the connection to a backup realserver
and the connection to the client is lost anyway.
In this case stateful filter rules on the director 
will not cause any extra problems with failover.
			</para>
		</listitem>
	</itemizedlist>
	<para>
Summary: statefull filter rules are allowed on the realservers anytime
you like. Statefull rules are allowed on the director only if you
use Julian's NFCT patches.
	</para>
	<para>
octane indice <emphasis>octane (at) alinto (dot) com</emphasis> 13 Apr 2006
	</para>
	<blockquote>
		<para>
Do you know if you can do something like carp+pfsync with linux+ipvs.
My goal is to have two director/firewall machines: a master and a backup,
Both sharing the same IP: VIP
I can handle the LVS part easily with keepalived and a VRRP method and same ruleset but it 
means that all the connections tracked by the firewall rules are lost when master comes down.
I first want a firewall with failover. _Then_ if it works, I would add director on top of it.
I want to use it under linux. So the carp/pfsync solution is not available..
The question is: the sync daemon is helpful with me to synchronize firewalls state or not?

		</para>
		<para>
I read then http://www.austintek.com/LVS/LVS-HOWTO/HOWTO/LVS-HOWTO.server_state_sync_demon.html
		</para>
		<blockquote>
			<para>
but I saw:"Note that the feature of connection synchronization is under 
experiment now, and there is some performance penalty when connection 
synchronization, because a highly loaded load balancer may need to multicast 
a lot of connection information. If the daemon is not started, the performance 
will not be affected. "
			</para>
			<para>
and from:
http://www.austintek.com/LVS/LVS-HOWTO/HOWTO/LVS-HOWTO.failover.html
			</para>
			<para>
 Honestly, as good as LVS is for real server load balancing, for firewalls I like 
OpenBSD with CARP and pfsync. CARP+pfsync provides easy, scalable load 
balancing and HA for firewalls. pf, the OpenBSD firewall, is very well written 
and nicely designed. Give it a look, www.openbsd.com. 
 Note 
Carp is available for Linux too. "
 yes carp is available for linux but not pfsync which is what I need.
			</para>
		</blockquote>
		<para>
I asked Julian about http://www.ssi.bg/~ja/nfct/
"Does it means that master firewall will
updates backup firewall with its conntrack
state?". His answer was "No".
Seems to be that there is no way to use a cluster
firewall with conntrack replication under linux.
		</para>
	</blockquote>
	<para>
Joe
	</para>
	<para>
no-one has posted that they've done it.
Any protocol that updates state 
information onto a backup machine is going to have overhead.
pfsync updates the firewall state (I believe) on the backup, 
but not the ipvs connection table. Even with carp, you still 
have to transfer the ipvs table.
The ipvs synch state demon only keeps track of the 
ipvs controlled connections, not the firewall state - it won't help you.
	</para>
	<para>
Ratz 20 Apr 2006
	</para>
	<para>
IPVS has not much to do with firewalling, you can achieve CARP+pfsync 
like setups using VRRP+ctsync under Linux.
	</para>
	<para>
Does ctsync not work? I know that you've also asked in the nf-failover 
ml. It's sort of maintained (there have been a couple of patches to 
ct_sync this year already) and it sort of works for the handful of 
people that actually use it. It had problems with tcp window tracking 
the last time I tried it but Krisztian and Harald are certainly more 
than happy to fix a couple of issues related to ctsync problems. People 
send in patches to ct_sync regularly to netfilter-devel and some even 
maintain out of tree kernel patches: http://vvv.barbarossa.name/files/ct_sync/
Please try out the available software and if this does not work, 
complain at netfilter-dev ml ;).
	</para>
	</section>
	<section id="director_failure">
	<title>Director failure</title>
	<para>
What happens if the director dies? The usual solution is duplicate
director(s) with one active and one inactive. If the active director
fails, then it is switched out.
Although everyone seems to want reliable service, in most cases
people are using the redundant directors in order to maintain service
through periods of planned maintenance rather than to handle boxes
which just fail at random times. At least no-one has admitted to a real
director failure in a production system.
	</para>
	<para>
Matthew Crocker <emphasis>matthew (at) crocker (dot) com</emphasis> 23 May 2002
	</para>
	<blockquote>
		<para>
I have a production LVS server running with 3 realservers handling
SMTP, POP3, IMAP for our QMAIL server.  We process about a million
inbound connections a day.  I've never had the primary LVS server crash
but I have shut it down on purpose (yanked the power cord) to test the
fail over.  Everything worked perfectly.
		</para>
		<para>
We use QMAIL-LDAP for our mail server and Courier-IMAP for the
IMAP server.  QMAIL saves mail in Maildir format on our NFS server
(Network Appliance F720) as a single qmail user.  All aliases,
passwords, mail quota information is stored in LDAP (openldap.org).  The
cluster is load balanced using LVS currently with Direct Routing but I'm
going to switch to NAT very soon.
		</para>
	</blockquote>
	<para>
Bradley McLean <emphasis>bradlist (at) bradm (dot) net</emphasis> 23 May 2002
	</para>
	<blockquote>
		<para>
We run a pair of load balancers in front of
5 real http/https webservers, using keepalived.
In earlier versions of LVS, a memory leak problem caused a
failover to occur about once every three days (might have been
0.9.8 with keepalived 0.4.9 + local patches).
We're on 1.0.2 and 0.5.6 now, with no problems, except that
we don't quite have an auto failback mechanism that works
correctly.
		</para>
		<para>
We preserve connections quite nicely during the failover
from the master to the backup, however once in that state,
if the master comes back up, it takes over without capturing
the connection states from the backup.  I believe that
Alexandre is close to solving this if he hasn't already;
frankly we've been concentrating on other pieces of our
infrastructure, and since we've had no failures since we
upgraded versions, we haven't been keeping up.
		</para>
		<para>
We're relatively small, serving up between .5 and 2.5
T1's worth of traffic.  The balancers are built from
Dell 2350s with 600Mhz PIII and 128MB, with DE570TX
quad tulip cards in each.
		</para>
		<para>
We run NAT, with an external interface that provides
a non-routable IP address (there's a separate firewall
up front before the web cluster), an internal interface
to our web servers, and internal interface to our
admin / backup network, and an interface on a crossover
cable to the other balancer used for connection sync
data.  We could consolidate some of these, but since
NICs are cheap, it keeps everything conceptually simple
and easy to sniff to prove it's clean.
		</para>
	</blockquote>
	<para>
Magnus Nordseth <emphasis>magnun (at) stud (dot) ntnu (dot) no</emphasis> 23 May 2002
	</para>
	<blockquote>
		<para>
We have been running lvs in a production site for about 8 months now, with
functional failover for the last 3.
		</para><para>
We use keepalived for failover and healthchecking. The setup consists of 4
realservers (dell 2550, dual pIII 933, 1Gb RAM) and 2 directors (pII
400). The main director has only been down for maintenance or demonstration
purposes. The site has about 2 million hits per day, and the servers are
pushing between 20 and 70 Gb of data each day.
		</para>
	</blockquote>
	<para>
Automatic detection of failure in
unreliable devices by other unreliable devices is not a simple problem.
Currently LVS director failure in an LVS is handled by code from the
<ulink url="http://www.linux-ha.org">Linux HA (High Availability) project</ulink>.
(Alexandre Cassen is working on code based on <command>vrrpd</command>, which will
also handle director failover).
The Linux HA solution is to have two directors and
to run a heartbeat between them. One director
defaults to being the operational director and the other takes
over when heartbeat detects that the default director has died.
	</para>
<programlisting><![CDATA[
                        ________
                       |        |
                       | client |
                       |________|
			   |
                           |
                        (router)
                           |
			   |
          ___________      |       ___________
         |           |     |  DIP |           |
         | director1 |-----|------| director2 |
         |___________|     |  VIP |___________|
               |     <- heartbeat->    |
               |---------- | ----------|
                           |
         ------------------------------------
         |                 |                |
         |                 |                |
     RIP1, VIP         RIP2, VIP        RIP3, VIP
   ______________    ______________    ______________
  |              |  |              |  |              |
  | realserver1  |  | realserver2  |  | realserver3  |
  |______________|  |______________|  |______________|
]]></programlisting>
	<para>
LVS is one of the major uses for the Linux HA code and several
of the Linux HA developers monitor the LVS mailing list.
Setup problems can be answered on the LVS mailing list.
For more detailed issues on the working of Linux HA, you'll be
directed to join the Linux HA mailing list.
	</para>
	<para>
Fake, heartbeat and mon are available at the
<ulink url="http://www.linux-ha.org/download/">Linux High Availability site</ulink>.
	</para>
	<para>
There are several overlapping families of code being developed by the Linux HA
project and the developers seem to contribute to each other's code.
The two main branches of Linux HA used for LVS are
<link linkend="UltraMonkey">UltraMonkey</link> and
<link linkend="keepalived_vrrpd">vrrpd/keepalived</link>.
Both of these have their own documentation and are not covered in this HOWTO.
	</para>
	</section>
	<section id="UltraMonkey">
	<title>UltraMonkey and Linux-HA</title>
	<para>
The <ulink url="http://www.ultramonkey.org">UltraMonkey project</ulink>
is a packaged version of LVS combined with Linux HA to
give director failure, written by Horms.
It uses LVS-DR and is designed to load balance on a LAN.
UltraMonkey uses Heartbeat from the Linux-HA project for failover
and ldirectord to monitor the realservers.
			</para><para>
Alternatively the
<xref linkend="LVS-HOWTO.Mueller-HA"/>
has been written by Peter Mueller.
This being functionally equivelent to the Ultra Monkey code.
			</para>
		<section id="two_box_ha_lvs">
		<title>Two box HA LVS</title>
		<para>
<blockquote><para>
Doug Sisk <emphasis>sisk (at) coolpagehosting (dot) com</emphasis> 19 Apr 2001
			</para><para>
Is it possible to create a two server LVS with fault tolerance?
It looks straight forward with 4 servers ( 2 Real and 2 Directors),
but can it be done with just two boxes, <emphasis>i.e.</emphasis> directors, each director being
a realserver for the other director and a realserver running localnode
for itself?
</para></blockquote>
			</para><para>
Horms
			</para><para>
Take a look at www.ultramonkey.org,
that should give you all the bits you need to make it happen.
You will need to configure heartbeat on each box,
and then LVS (ldirectord) on each box to have two realservers:
the other box, and localhost.
		</para>
		</section>
		<section id="heartbeat_synch_demon">
		<title>heartbeat and connection state synch demon</title>
		<para>
<blockquote><para>
Michael Cunningham <emphasis>m (dot) cunningham (at) xpedite (dot) com</emphasis>
			</para><para>
I have heartbeat running between two LVS directors.
It is working great. It can fail back and forth without
issues.
Now I would like to setup connection state synchronization
between the two directors. But I am two problems/questions.
Can I run the multicast connection sync over my 100 mbit
private lan link which is being used by heartbeat?
			</para><para>
How can I setup heartbeat to always run..
<programlisting><![CDATA[
director:/etc/lvs# ipvsadm --start-daemon=master --mcast-interface=eth1
]]></programlisting>
on the current master.. and
<programlisting><![CDATA[
director:/etc/lvs# ipvsadm --start-daemon=backup --mcast-interface=eth1
]]></programlisting>
on the current slave at all times?
			</para><para>
The master can run a script when it starts up/obtains resources
but I don't see anyway for the slave to run a script when it
starts up or releases resources.
</para></blockquote>
			</para><para>
Lars Marowsky-Bree <emphasis>lmb (at) suse (dot) de</emphasis> 02 Feb 2002
			</para><para>
The slave runs the resource scripts with the "stop" action when the resources
are released, so you could it add in there; anything you want to run before
the startup of heartbeat is separate from that and obviously beyond the
control of heartbeat.
			</para><para>
You are seeing the result of heartbeat's rather limited resource manager, I am
afraid.
		</para>
		</section>
		<section id="linux_ha_serial_connection">
		<title>serial connection problems with Linux-HA</title>
		<para>
"Radomski, Mike" <emphasis>Mike (dot) Radomski (at) itec (dot) mail (dot) suny (dot) edu</emphasis>  13 Mar 2002
		</para>
		<blockquote>
I am experiencing a strange problem with my LVS+Heartbeat cluster.  I have
two systems both running <command>ipvsadm</command> and heartbeat(serial and x-over Ethernet).
Every 10 hours I get a cpu spike (load of 1.1) on the primary system and
then a few minutes later I get the same spike on the secondary system.
The system sustains a load of ~1 for about 20 minutes and then returns to ~0.
Neither top nor ps are showing the active process causing the spike. The
spike lasts for about 20 minutes and then everything is fine.  The ipvsadm
piece still redirects and load balances with no viewable performance
problem.  Is there any thing I can do to track this problem down?
		</blockquote>
        	<para>
Lars
        	</para>
		<para>
A load of 1.1 doesn't mean a CPU spike; it might simply mean that there is a
zombie process for some reason. ps should show this (a process in D or Z
state); ps fax will show you a process tree so you can figure out where
it came from.
        	</para>
		<blockquote>
			<para>
It has been over 10 hours since the last
sustained spike.  I remember when setting up the heartbeat, the serial
connection was very slow and intermittent. If I cat'ed information to
the serial port, it would take about 30 seconds to reach the other end of
the null modem cable.  As per a suggestion on Google Groups, I tried to set
the serial port with the following:
			</para>
<programlisting><![CDATA[
/bin/setserial /dev/ttyS1 irq 0
]]></programlisting>
			<para>
This worked both with simple serial communication and heartbeat.  But I
found in the dmesg and the logs the following:
			</para>
<programlisting><![CDATA[
ttyS: 2 input overrun(s)
ttyS: 2 input overrun(s)
]]></programlisting>
			<para>
After shutting off the serial heartbeat, the over all load dropped
about .02. I have not seen the sustained spike since.
			</para>
		</blockquote>
        	<para>
Lars
        	</para>
		<para>
It is something in the kernel, because that is the only thing which
is not accounted for by anything else.
There are other options; if you boot the kernel with the "profile=3D2",
you can use readprofile to compare the patterns for 5 minutes during the events
and outside; remember to use "readprofile -r" to reset the profiling data
when doing so so the counters are clean and do NOT run top during the time,
because top traverses the /proc file system every second or so which greatly
obscures the profiling results.
         	</para>
		<para>
Paul Baker <emphasis>pbaker (at) where2getit (dot) com</emphasis> 14 Mar 2002
		</para>
		<para>
I had major reliability issues when I tried using the serial connection
with heartbeat. I attributed it to poor chipset design from Intel. My
load balancers are 1U's Celeron systems that use that crappy i810
chipset. Pretty much whenever there was any load on the server (such as
during rsync replication between the master and slave loadbalancers),
the serial connection would completely timeout. Which would cause
complete havoc on my lvs. The slave would then think the master was
down, and start to bring itself up as the director. Let me tell you from
experience, it really sucks when you have two directors fighting over
arp for the ip addresses of the lvs. So I just decided to bite the
bullet and switch from serial heartbeats to udp. I haven't had a problem
since.
		</para>
		</section>
	</section>
	<section id="keepalived_vrrpd">
	<title>Keepalived and Vrrpd</title>
	<para>
Alexandre Cassen <emphasis>alexandre (dot) cassen (at) wandadoo (dot) fr</emphasis>,
the co-author of
<ulink url="http://keepalived.sourceforge.net">keepalived</ulink>
(http://keepalived.sourceforge.net)
and the author of <link linkend="LVSGSP">LVSGSP</link>
has produced keepalived which sets up an LVS and monitors the
health of the services on the realservers
and has produced a vrrpd demon for LVS which enables director failover.
You build one executable <command>keepalived</command> which has
(optionally one or both of) the vrrpd and keepalived functions.
If you just want failover
between two nodes, you only need the vrrpd part of the
build.
	</para>
	<para>
(notes here produced from discussions with Alexandre).
Keepalived will
	</para>
	<itemizedlist>
		<listitem>
setup an LVS from scratch (services, forwarding method,
scheduler, realservers)
		</listitem>
		<listitem>
monitor the services on the realservers and failout dead services
on the realservers
		</listitem>
		<listitem>
failover machines (for LVS, this will be the directors)
		</listitem>
	</itemizedlist>
	<para>
There are examples of using keepalived/vrrpd
in a HOWTO for LVS-NAT and another HOWTO
for LVS-NAT with the director being
patched with the <xref linkend="LVS-HOWTO.filter_rules"/>.
to act as a firewall as well.
The options available
for the <filename>keepalived.conf</filename>
are available in <filename>doc/keepalived.conf.SYNOPSIS</filename>.
Sample <filename>keepalived.conf</filename> files are in
<filename>./doc/samples/keepalived.conf.*</filename> in the
source directory.
An elementary set of manpages are available.
	</para>
	<para>
The functionality for the <command>vrrpd</command> failover is similar to that for
<xref linkend="LVS-HOWTO.heartbeat"/>.
<command>vrrpd</command> adds IP(s) to ethernet card(s) with
<command>ip</command>, when the machine is in the master state
and removes them, when it is in the backup state.
On bringing up the IP(s), <command>vrrpd</command> sends
a gratuitous arp for the new location of the IP, flushing
the arp tables of other machines on the network.
This procedure leaves the arp tables unchanged for the other (unmoving)
IP(s) on the same interface.
	</para>
	<note>
		<para>
There is some confusion about patents connected to VRRP. 
Here is some info.
		</para>
		<para>
FreeBSD has 
<ulink url="http://pf4freebsd.love2party.net/carp.html">CARP</ulink>
(http://pf4freebsd.love2party.net/carp.html), 
the Common Address Redundancy Protocol, 
written to head-off possible problems with cisco claims that its 
<ulink url="http://software.newsforge.com/software/04/04/13/1842214.shtml">
patents on Hot Standby Router Protocol (HSRP)  
cover the same technical areas as VRRP</ulink>
(http://software.newsforge.com/software/04/04/13/1842214.shtml).
<link linkend="vrrp_patent">Alexandre has contacted cisco about this</link>.
CARP has been 
<ulink url="http://www.ucarp.org/">ported to Linux</ulink>
(http://www.ucarp.org/).
		</para>
		<para>
Alexandre Cassen <emphasis>acassen (at) freebox (dot) fr</emphasis> 9 Mar 2006
		</para>
		<para>
CARP is close to VRRP - they have the same Finite State Machine (FSM).
The patent on VRRP is not applicable to Keepalived 
since I made some assumptions that make the implemetation not as rfc 
compliant as other implemenations. 
The VRRP patent for linux implementation is not a problem. 
The CARP code, except the use of hash instead of IP address, and some
others cosmetics stuff, is VRRP like.
VRRP is an IETF standard. 
IMHO, what is important for such a protocol
is not re-inventing the FSM (by writing CARP), 
but stacking components around to make it
usefull (like sync_group, ....). 
VRRP adoption is already made and if
CARP doesn't bring new inovation concepts, 
this will slow down adoption.
		</para>
	</note>
	<para>
S.Mehdi Sheikhalishahi 2005-05-21
	</para>
	<blockquote>
Is there any comparsion between Load Balancing and HA Solutions?
What's the best for a firewall?
	</blockquote>
	<para>
Clint Byrum <emphasis>cbyrum (at) spamaps (dot) org</emphasis> 2005/22/05
	</para>
	<para>
as good as LVS is for real server load balancing, for
firewalls I like OpenBSD with CARP and pfsync.
CARP+pfsync provides easy, scalable load balancing and HA for firewalls.
pf, the OpenBSD firewall, is very well written and nicely designed. Give
it a look, www.openbsd.com.
	</para>
	<para>
Alexandre 31 Dec 2003
	</para>
	<blockquote>
Gratuitous ARP is well supported by routing equipment.
Only one packet is lost during takeover.
	</blockquote>
	<para>
In earlier versions of vrrpd, the vrrpd fabricated a software
ethernet device on the outside
of the director (for the VIP) and another for the inside of the
director (for the DIP) each with a MAC address from the private
range of MAC addresses
(<emphasis>i.e.</emphasis> will not be found on any manufactured NIC).
When a director failed, vrrpd would re-create the ethernet devices,
with the original IP and MACs, on the backup director.
Other machines would not have any changes in their arp tables
(the IP would move to another port on a switch/hub though)
and would continues to route packets to the same MAC address.
Unfortunately this didn't work out
	</para>
	<para>
Alexandre 31 Dec 2003
	</para>
	<blockquote>
We discussed this with Julian, and Jamal. The previous code
didn't handle the VMAC cleanly. It consisted of changing the interface MAC
address inside the kernel to fake the needed one... This is not clean and
not scalable since this restricted us to only one VMAC per interface
(multiple VMACs were not supported). Later Julian
produced his parp netlink patch that offers an arp reply from a VMAC.
This did not work, as all traffic stayed with the interface MAC.
Later, on the netdev ML, we discussed this with Julian and Jamal, and the
best solution was to provide a patch to the ingress/egress code to support
these VMAC operations. This code hasn't been written.
	</blockquote>
	<para>
<command>keepalived</command>
listens on raw:0.0.0.0:112, so you can include in <filename>/etc/services</filename>.
	</para>
<programlisting><![CDATA[
vrrpd           112/raw         vrrpd
]]></programlisting>
	<para>
Here's part of the output of <command>netstat -a</command> after starting
keepalived on a machine with two instances of <command>vrrpd</command>
(one for each interface) (there are no other machines running <command>vrrpd</command>
on the network).
	</para>
<programlisting><![CDATA[
director# netstat -a | grep vrrp
raw        0      0 *:vrrpd                 *:*                     7
raw        0      0 *:vrrpd                 *:*                     7
raw        0      0 *:vrrpd                 *:*                     7
raw        0      0 *:vrrpd                 *:*                     7
unix  2      [ ACC ]     STREAM     LISTENING     5443463 /tmp/.vrrp
unix  3      [ ]         STREAM     CONNECTED     5443487 /tmp/.vrrp
]]></programlisting>
	<para>
After starting keepalived on another director, note that one of the vrrpds
has received some packets.
	</para>
<programlisting><![CDATA[
director# netstat -a | grep vrrp
raw        0      0 *:vrrpd                 *:*                     7
raw        0      0 *:vrrpd                 *:*                     7
raw      264      0 *:vrrpd                 *:*                     7
raw        0      0 *:vrrpd                 *:*                     7
unix  2      [ ACC ]     STREAM     LISTENING     5456088 /tmp/.vrrp
unix  3      [ ]         STREAM     CONNECTED     5456118 /tmp/.vrrp
]]></programlisting>
	<para>
Although <command>netstat</command> only shows that vrrpd is bound
to 0.0.0.0:vrrpd, if you are wondering how to write your filter rules,
<command>vrrpd</command> is only bound to the NIC specified in
<filename>keepalived.conf</filename>.
VRRP advertisements are sent/received on this protocol socket, using multiplexing.
	</para>
	<para>
The src_addr of the multicast packet is the primary IP of the interface.
Multicast permits you to alter the src_addr (with <filename>mcast_src_ip</filename>)
if you want to hide the primary IP.
If you do this, the socket will still be bound to 0.0.0.0 according
to <command>netstat</command>
	</para>
	<para>
(Here is further info on <xref linkend="nicless_mcast"/>.)
	</para>
	<para>
Alexandre Dec 2003
	</para>
	<blockquote>
		<para>
VRRP is interface specific (like HSRP and others hot standby protocol).
and uses a socket pair for sending/receiving adverts.
The sockets are bound to the specified interface.
When you configure a VRRP instance on interface on eth0, VRRP
will create a raw vrrp-proto socket and bind the socket to interface eth0
(using bindtodevice kernel call). Then it joins the VRRP multicast group.
So this socket will receive VRRP adverts only on eth0. The same thing is
done for sending socket, vrrp proto sending socket is bound to interface
VRRP instance belong to.
Additionnaly if you have more than one VRRP instance on the same NIC
(for active/active setup) then they will share the same socket.
VRRP code will then demux the incoming VRRP adverts performing
a hash lookup according to the incoming VRRP advert VRID header field.
It performs a o(1) lookup (hash index based on VRRP VRID field).
If you run IPSEC-AH VRRP and normal VRRP on the same interface then the
code will create 2 sockets referring to each protocol (51 and 112). The rest
is the same: demux on a shared socket according to incoming VRRP VRID field.
		</para>
		<para>
VRRP is based on advert sending over multicast (advert interval determined
by <filename>advert_int</filename> in <filename>keepalived.conf</filename>
normally configured for 1 sec). This is an election
protocol. Master is the one with the highest priority.
When the master crashes, an election is held to find the next highest
higher priority VRRP master.
		</para>
	</blockquote>
	<para>
<command>keepalived</command> has the same split brain problem
as <xref linkend="LVS-HOWTO.heartbeat"/>.
heartbeat tries to beat this by having multiple communication
channels. <command>vrrpd</command> only has one channel.
	</para>
	<para>
There isn't a <command>keepalived status</command>, so you can't
programmatically determine the state of any machine.
You can look for the moveable IP with <command>ip addr show</command>.
You can also inspect the logs (look for "BACKUP" || "MASTER").
	</para>
	<note>
Unfortunately as with any failover setup,
failover is not guaranteed in the case of a sick machine.
If one machine is in an error state <emphasis>e.g.</emphasis>
<command>vrrpd</command> dies on the master machine, the logs
will show the last entry as MASTER (but it will be an old entry),
while another machine which takes over the master role, will have
a (current) entry as MASTER in the logs.
Presumably you could use <filename>notify_master</filename>,
<filename>notify_backup</filename> and <filename>notify_fault</filename>
to touch files which you could inspect later to determine the state
of the machines. This will have problems too in error states.
Inspection of IP(s) will also be meaningless in an error condition.
The current mechanism for handling machines in a dubious state
is to programmatically power cycle them
(a process called <emphasis>STONITH</emphasis>).
Hopefully the good machine reboots the sick machine.
	</note>
	<para>
There is no way to force a master-backup transition
(<emphasis>e.g.</emphasis> for testing).
However, you can relink <filename>keepalived.conf</filename> to a file with a
lower priority and re-HUP <command>keepalived</command>.
	</para>
	<para>
You can force a master-fault transition by downing the interface.
	</para>
	<para>
<command>vrrpd</command>
only works with PCI ethernet cards (all of which have an MII
transceiver) but not with ISA ethernet cards (which don't).
I have a machine with 3 ethernet cards, 1 PCI and 2 (identical) ISA.
<command>vrrpd</command>
works with the PCI card and one of the ISA cards
(making transitions on failover),
but not with the last ISA card (eth2) which <filename>vrrpd</filename>
detects as being in a FAULT condition
(but <command>vrrpd</command> doesn't execute the "to_fault" script).
	</para>
	<para>
Alexandre Cassen, 18 Jan 2004
	</para>
	<para>
In fact, ISA cards don't support MII since they don't have a MII transciver.
So media link detection will not work on your 3c509.
	</para>
	<para>
Joe
	</para>
	<blockquote>
I don't understand why the option "state MASTER|BACKUP" exists, since
whatever value I use there is overriden by the election which occurs about
3secs after vrrp comes up. It doesn't help with the split brain problem
(not much does).
	</blockquote>
	<para>
In fact this is just a kind of speed bootstrap strategy... But you are
right, an election follows anyway. And then you can have node
configured for BACKUP with a priority higher than a node configured for
MASTER.
	</para>
	<blockquote>
OK, I will set all states to MASTER and let them have an election.
	</blockquote>
	<para>
Behaviour on killing vrrpd
	</para>
	<blockquote>
If I kill <command>keepalived</command>,
I would like the machine to run the scripts in
"to_backup". At the moment I'm running the "to_backup"
scripts in the <filename>rc.keepalived stop</filename> init file
before it kills <command>vrrpd</command>.
After <command>vrrpd</command> is shut down,
a <command>vrrpd</command> on another
machine will become master and I would like the machine where
<command>vrrpd</command> has
been shutdown to be in the BACKUP configuration (not have the movable IPs
or point to the wrong default gw). I can't think of a reason why
<command>vrrpd</command>
should leave the machine in one state or another when it exits.
Has the
behaviour I see been chosen after some thought or is it just how it works
right now?
	</blockquote>
	<para>
Currently I have not implemented 'administration state forcing' that
overrides the runing <command>vrrp</command> FSM. I hope I will find time for this.
	</para>

	<para>
logs
	</para>
	<blockquote>
I would like the logs to show not only the state of <command>vrrpd</command>
on that machine,
but following an election or transition, I would like to know which other
machines were involved and what state they are in. At the moment the logs
don't tell me whether a machine became master because it won the election
or it didn't find any other machines. Is it possible to have more logging
info like this in a future version of keepalived?
I'd like to be able to look at a log file and see what state a machine
thinks it is in and what state it thinks all the other machines are in.
	</blockquote>
	<para>
In fact this is a VRRP spec. I mean, during election, if a node receives a
higher prio advert then it will transit to backup state, since this is
multicast design the master node will not hear remote 'old master'
transition, since it has won the election. The VRRP specs doesn't support
kind of LSA database like OSPF provides (each node knowing the state of the others).
I spoke with the IETF working group about this last year but
this features didn't receive much echo :). But this can be nice.... I like
this :) kind of admin command line requesting neighbor, ... this can be
usefull.
	</para>
	<para id="vrrp_patent">
Padraig Brady <emphasis>padraig (at) antefacto (dot) com</emphasis> 22 Nov 2001
	</para>
	<blockquote>
Haven't Cisco got patents on vrrpd?
What's the legal situation if someone wanted to deploy this?
	</blockquote>
	<para>
Michael McConnell <emphasis>michaelm (at) eyeball (dot) com</emphasis>
	</para>
	<para>
no - ftp://ftp.isi.edu/in-notes/rfc2338.txt
	</para>
	<para>
Andre
	</para>
	<para>
In short yes : http://www.ietf.org/ietf/IPR//VRRP-CISCO,
IBM too : http://www.ietf.org/ietf/IPR/NAT-VRRP-IBM
	</para>
	<para>
In fact there is 2 patents ((http://www.foo.be/vrrp/ link dead Feb 2005)
	</para>
	<itemizedlist>
		<listitem>
CISCO - http://www.delphion.com/details?pn=US06108300__
		</listitem>
		<listitem>
Nortel Network - http://www.delphion.com/details?pn=EP01006702A3
		</listitem>
	</itemizedlist>
	<para>
When you read this papers you can't find any OpenSource restriction...
All that I can see is the commercial product implementation... I plan to
post a message into the IETF mailing list to present the LVS work on VRRP
and to enlarge the debate on OpenSource implementation and eventual
licence...
	</para>
	<para>
9 Jan 2002
	</para>
	<para>
answer from Robert Barr, CISCO Systems
	</para>
	<blockquote>
		<para>
Cisco will not assert any patent claims against anyone for an
implementation of IETF standard for VRRP unless a patent claim is asserted
against Cisco, in which event Cisco reserves the right to assert patent
claims defensively.
		</para>
		<para>
I cannot answer for IBM, but I suspect their answer will be different.
		</para>
	</blockquote>
	</section>
	<section id="keepalived_router_failover">
	<title>Using keepalived to failover routers</title>
	<para>
<filename>vrrpd</filename> is a router failover demon protocol. 
While keepalived uses it to failover LVS, <filename>vrrpd</filename>
can be used independantly of LVS to failover a pair of routers.
	</para>
	<para>
Graeme Fowler <emphasis>graeme (at) graemef (dot) net</emphasis> 11 Sep 2007
	</para>
	<para>
config for the ACTIVE router looks like:
	</para>

<programlisting><![CDATA[
# keepalived.conf for HA "routers"

global_defs {
   notification_email {
      recipient@mail.domain
   }
   notification_email_from root@fqdn.of.machine
   smtp_server 1.2.3.4
   smtp_connect_timeout 60
   router_id router_1
}

vrrp_script check_running {
   script "/usr/local/bin/check_running"
   interval 10
   weight 10
}

vrrp_script always_succeed {
   script "/bin/date"
   interval 10
   weight 10
}

vrrp_script always_fail {
   script "/usr/local/bin/always_fail"
   interval 10
   weight 10
}

vrrp_instance ROUTER_1 {
    state MASTER
    smtp_alert
    interface eth0
    virtual_router_id 101
    priority 100
    advert_int 3
    authentication {
        auth_type PASS
        auth_pass whatever
    }
    virtual_ipaddress {
        1.1.1.1
    }
    track_script {
        check_running weight 20
    }
}

]]></programlisting>
	<para>
...the corresponding config for the BACKUP looks like:
	</para>
<programlisting><![CDATA[

# keepalived.conf for HA "routers"

global_defs {
   notification_email {
      recipient@mail.domain
   }
   notification_email_from root@fqdn.of.machine
   smtp_server 1.2.3.4
   smtp_connect_timeout 60
   router_id router_2
}

vrrp_script check_running {
   script "/usr/local/bin/check_running"
   interval 10
   weight 10
}

vrrp_script always_succeed {
   script "/bin/date"
   interval 10
   weight 10
}

vrrp_script always_fail {
   script "/usr/local/bin/always_fail"
   interval 10
   weight 10
}

vrrp_instance ROUTER_1 {
    state BACKUP
    smtp_alert
    interface eth0
    virtual_router_id 101
    priority 90
    advert_int 3
    authentication {
        auth_type PASS
        auth_pass whatever
    }
    virtual_ipaddress {
        1.1.1.1
    }
    track_script {
        check_running weight 20
    }
}
]]></programlisting>

	<para>
<emphasis>i.e.</emphasis> it differs in the "weight" stanza for the VRRP definition (90
instead of 100) and there are cosmetic differences to the name.
	</para>
	<para>
The "check_running" script is simply a wrapper round:
	</para>
<programlisting><![CDATA[
KILLALL -0 procname
]]></programlisting>
	<para>
if the result code ($?) is 0, it exits with 0. If not, it exits with 1.
	</para>
	<para>
If it exits with 1, the weight of the VRRP announcement is pulled down
by 20 - this makes sure that the critical process on this machine is up,
and if it isn't then we play a smaller part in the VRRP adverts (these
are derived from a pair of frontend mail servers).
	</para>
	</section>
	<section id="network_for_messages" xreflabel="network for messages">
	<title>monitoring/failover messages should stay internal to LVS</title>
	<para>
The LVS server state synch demon, vrrpd and heartbeat need to send messages between the backup and active
director.
You can send these over the RIP network, or via a dedicated network, 
but you shouldn't send these packets though the NIC that faces the internet (the one that has the VIP).
Reasons are
	</para>
	<itemizedlist>
		<listitem>
It allows outside people to hack your boxes.
		</listitem>
		<listitem>
The LVS (director, realservers), must appear as a single (highly available) server.
The clients must not be able to tell that the server is composed of serveral machines
working together. The clients must not be able to see heartbeat packets.
		</listitem>
	</itemizedlist>
	</section>
	<section id="parsing_problems_vrrpd" xreflabel="parsing problems with vrrpd">
	<title>Parsing problems with vrrpd config file</title>
	<para>
(Apr 2006, from several people). The parser is a little touchy.
	</para>
	<para>
This format is in the manpage and doesn't work.
	</para>
<programlisting><![CDATA[
vrrp_sync_group ACDDB_mysql_eins {
        group { vip_mysql_eins }
}

vrrp_sync_group ACDDB_mysql_zwei {
        group { vip_mysql_zwei }
}
]]></programlisting>
<para>
This works.
</para>
<programlisting><![CDATA[
vrrp_sync_group ACDDB_mysql_eins {
         group {
                 vip_mysql_eins
         }
}


vrrp_sync_group ACDDB_mysql_zwei {
         group {
                 vip_mysql_zwei
         }
}
]]></programlisting>
	<para>
This doesn't
	</para>
<programlisting><![CDATA[
MISC_CHECK { misc_path "/path/to/script" }
]]></programlisting>
	<para>
But this one does work.
	</para>

<programlisting><![CDATA[
MISC_CHECK {
   misc_path "/path/to/script"
}
]]></programlisting>

	</section>
	<section id="two_instances_vrrpd" xreflabel="two instances of vrrpd">
	<title>Two instances of vrrpd</title>
	<para>
It is possible to have two independant instances of vrrpd handing two VIPs, 
which can migrate independantly between directors.
	</para>
	<para>
Alexandre
	</para>
	<para>
you can have 2 VRRP VIPs active on different routers... then you have
a VRRP configuration with 2 instances. On Director1 one instance with
VIP1 in a MASTER state one instance for VIP2 in a BACKUP state. =>
symetry for Director2. both instances on the same interface with a
different router_id.
	</para>
	<para>
Alex <emphasis>alshu (at) tut (dot) by </emphasis>
	</para>
	<para>
   see http://keepalived.org/pdf/LVS-HA-using-VRRPv2.pdf
       http://keepalived.org/pdf/UserGuide.pdf
	</para>
	<para>
Graeme Fowler <emphasis>graeme@graemef (dot) net</emphasis> 27 Apr 2006
	</para>
	<para>
The router_id needs to be the same on each director for each vrrp_instance.
That value is sent out in the advertisement and is necessary for the pair
of directors to synchronise. You only need different priorities on your primary
and failover director. You can start up both as MASTER or BACKUP and let them decide
according to priority, what does what. Just make sure the router_id values
are the same for each instance. 
	</para>
	</section>
	<section id="ha_mysql" xreflabel="HA MySQL">
	<title>HA MySQL</title>
	<para>
Dominik Klein <emphasis>klein (dot) dominik (at) web (dot) de</emphasis> 25 Apr 2006
	</para>
	<para>
	<emphasis role="bold">Goal:</emphasis>
My goal is a HA MySQL database. As the MySQL cluster storage engine 
lacks several important features (like foreign keys <emphasis>e.g.</emphasis>), 
I cannot use a MySQL cluster. So now I use MySQL replication in a 
master-to-master-setup. As my clients are able to re-connect after a 
connection loss, but cannot connect to a different IP on connection 
loss, a VIP setup is the goal. So my clients only know the VIP(s), not 
the real IPs of the MySQL Servers.
	</para>
	<para>
<emphasis role="bold">Setup:</emphasis>
I have two machines. Each machine runs keepalived and MySQL. Each 
machine has 2 NICs. eth0 going to the switch, eth1 connecting SRV1 and SRV2.
My setup looks like this:
	</para>

<programlisting><![CDATA[
Intranet
|
|
##SWITCH##
|	|
|	|
|	|
SRV1---SRV2
]]></programlisting>

	<para>
Clients connect through the switch, replication is done over the direct 
gigabit connection between SRV1 and SRV2.
	</para>
<programlisting><![CDATA[
SRV1 IPs:
eth0 10.6.10.20
eth1 10.250.250.20
SRV2 IPs:
eth0 10.6.10.21
eth1 10.250.250.21
]]></programlisting>
	<para>
<emphasis role="bold">Virtual Services</emphasis>
I need two VIPs, as I want write-queries to go to SRV1, 
and read-queries to go to SRV2 - just as in a normal replication-setup, 
for loadbalancing-purposes. 
Note that it is not keepalived or LVS that does the loadbalancing here, 
as each virtual service only has one realserver and one sorry-server!
"Loadbalancing" is just writing-to-the-database-software connecting to 
one server, reading-from-the-database-software connecting to another server.
	</para>
<programlisting><![CDATA[
10.6.10.24:3306
SRV1 (MASTER state for this VIP)
Realserver: 127.0.0.1:3306
Sorryserver: 10.250.250.21:3306
SRV2 (BACKUP state for this VIP)
Realserver 10.250.250.20:3306
Sorryserver: 127.0.0.1:3306

10.6.10.240:3306
SRV1 (BACKUP state for this VIP)
Realserver 10.250.250.21:3306
Sorryserver: 127.0.0.1:3306
SRV2: (MASTER state for this VIP)
Realserver: 127.0.0.1:3306
Sorryserver: 10.250.250.20:3306
]]></programlisting>
	<para>
So this is basically the "localhost"-feature, plus one sorryserver per 
virtual service.
	</para>
	<para>
<emphasis role="bold">Failover</emphasis>
If one of the eth0 network connections fail, the VIP moves to the other 
director, but connections still get directed to the same MySQL server. 
So the MySQL-loadbalancing still works.
If MySQL fails on one machine, connections are redirected to the other 
server's eth1-IP (10.250.250.2[01]). In order to be able to route that 
back over the director it came from, there are ip-rules on each server:
	</para>
<programlisting><![CDATA[
------------------------------
- SVR1 ip rules and routing: -
------------------------------

cat /etc/iproute2/rt_tables
2 mysqlrouting
...

ip rule show
...
32765:  from 10.250.250.20 lookup mysqlrouting
...

ip route show table mysqlrouting
default via 10.250.250.21 dev eth1

Setup-steps for this:
echo "2 mysqlrouting" > /tmp/rt_tables
cat /etc/iproute2/rt_tables >> /tmp/rt_tables
cp /tmp/rt_tables /etc/iproute2/rt_tables
rcnetwork restart
ip rule add from 10.250.250.20 table mysqlrouting
ip route add default via 10.250.250.21 dev eth1 table mysqlrouting

------------------------------
- SVR2 ip rules and routing: -
------------------------------
cat /etc/iproute2/rt_tables
2 mysqlrouting
...

ip rule show
...
32765:  from 10.250.250.20 lookup mysqlrouting
...

ip route show table mysqlrouting
default via 10.250.250.20 dev eth1

Setup-steps for this:
echo "2 mysqlrouting" > /tmp/rt_tables
cat /etc/iproute2/rt_tables >> /tmp/rt_tables
cp /tmp/rt_tables /etc/iproute2/rt_tables
rcnetwork restart
ip rule add from 10.250.250.21 table mysqlrouting
ip route add default via 10.250.250.20 dev eth1 table mysqlrouting
]]></programlisting>

<para><emphasis role="bold">Configuration files</emphasis></para>

<programlisting><![CDATA[
------------------------------------
- keepalived configuration on SRV1 -
------------------------------------

! Configuration File for keepalived

global_defs {
    notification_email { foo@mydomain.com }
    notification_email_from keepalived@mydomain.com
    smtp_server 10.2.20.6
    smtp_connect_timeout 30
    lvs_id TEST-MYSQL-1
}

vrrp_sync_group test_mysql_one {
         group {
                 vip_mysql_one
         }
}

vrrp_sync_group test_mysql_two {
         group {
                 vip_mysql_two
         }
}

vrrp_instance vip_mysql_one {
     state MASTER
     interface eth0
     virtual_router_id 51
     priority 100
     advert_int 1
     authentication {
         auth_type PASS
         auth_pass 12345
     }
     virtual_ipaddress {
         10.6.10.24/24 brd 10.6.10.255 dev eth0
     }
}

vrrp_instance vip_mysql_two {
     state BACKUP
     interface eth0
     virtual_router_id 52
     priority 10
     advert_int 1
     authentication {
         auth_type PASS
         auth_pass 12345
     }
     virtual_ipaddress {
         10.6.10.240/24 brd 10.6.10.255 dev eth0
     }
}

virtual_server 10.6.10.24 3306 {
     delay_loop 6
# lb_algo is actually not important, as we have only one real_server
     lb_algo wlc
     lb_kind NAT
     nat_mask 255.255.255.0
     protocol TCP
     real_server 127.0.0.1 3306 {
         TCP_CHECK {
                 connect_port 3306
                 connect_timeout 30
         } #TCP_CHECK
     }
     sorry_server 10.250.250.21 3306
}

virtual_server 10.6.10.240 3306 {
     delay_loop 6
# lb_algo is actually not important, as we have only one real_server
     lb_algo wlc
     lb_kind NAT
     nat_mask 255.255.255.0
     protocol TCP
     real_server 10.250.250.21 3306 {
         TCP_CHECK {
                 connect_port 3306
                 connect_timeout 30
         } #TCP_CHECK
     }
     sorry_server 127.0.0.1 3306
}

------------------------------------
- keepalived configuration on SRV2 -
------------------------------------

! Configuration File for keepalived

global_defs {
    notification_email { foo@mydomain.com }
    notification_email_from keepalived@mydomain.com
    smtp_server 10.2.20.6
    smtp_connect_timeout 30
    lvs_id TEST-MYSQL-2
}

vrrp_sync_group ACDDB_mysql_one {
         group {
                 vip_mysql_one
         }
}

vrrp_sync_group ACDDB_mysql_two {
         group {
                 vip_mysql_two
         }
}

vrrp_instance vip_mysql_one {
     state BACKUP
     interface eth0
     virtual_router_id 51
     priority 100
     advert_int 1
     authentication {
         auth_type PASS
         auth_pass 12345
     }
     virtual_ipaddress {
         10.6.10.24/24 brd 10.6.10.255 dev eth0
     }
}

vrrp_instance vip_mysql_one {
     state MASTER
     interface eth0
     virtual_router_id 52
     priority 100
     advert_int 1
     authentication {
         auth_type PASS
         auth_pass 12345
     }
     virtual_ipaddress {
         10.6.10.240/24 brd 10.6.10.255 dev eth0
     }
}

virtual_server 10.6.10.24 3306 {
     delay_loop 6
# lb_algo is actually not important, as we have only one real_server
     lb_algo wlc
     lb_kind NAT
     nat_mask 255.255.255.0
     protocol TCP
     real_server 10.250.250.20 3306 {
         TCP_CHECK {
                 connect_port 3306
                 connect_timeout 30
         } #TCP_CHECK
     }
     sorry_server 127.0.0.1 3306
}

virtual_server 10.6.10.240 3306 {
     delay_loop 6
# lb_algo is actually not important, as we have only one real_server
     lb_algo wlc
     lb_kind NAT
     nat_mask 255.255.255.0
     protocol TCP
     real_server 127.0.0.1 3306 {
         TCP_CHECK {
                 connect_port 3306
                 connect_timeout 30
         } #TCP_CHECK
     }
     sorry_server 10.250.250.20 3306
}
]]></programlisting>
	<para>
As MySQL requires some specific configuration, I will briefly post the 
relevant parts, but not go into detail here, because it is actually OT 
for this list. Read the MySQL-Documentation for further detail, if you 
do not understand the configuration parts below:
http://dev.mysql.com/doc/refman/5.0/en/replication.html
	</para>

<programlisting><![CDATA[
-------------------------------
- MySQL configuration on SRV1 -
-------------------------------

log-bin=mysql-bin
log-slave-updates

server-id       = 5000

auto_increment_increment=2
auto_increment_offset=1

master-host     =   10.250.250.21
master-user     =   replication
master-password =   replication
master-port     =   3306

-------------------------------
- MySQL configuration on SRV1 -
-------------------------------

log-bin=mysql-bin
log-slave-updates

server-id       = 5001

auto_increment_increment=2
auto_increment_offset=2

master-host     =   10.250.250.20
master-user     =   replication
master-password =   replication
master-port     =   3306

]]></programlisting>
	<para>
On failover, there is no connection-sync, so every client has to 
re-connect. Connection-sync is imho not possible in this setup, as 
real-servers are different on SRV1 and SRV2.
	</para>
<programlisting><![CDATA[
]]></programlisting>
	<para>
This example is on VIP1:
If MySQL fails on SRV1, SRV2 will be used. When SRV1 comes back up, 
keepalived will immediately switch back to SRV1.
This will send clients to a mysql server, that may not have up-to-date-data.
As I could not find a way to define any delay before the real-server is 
added back in, I wrote a MySQL startscript I'll post (below). It blocks 
port 3306 on loop interface and so lets the healthcheck fail for local 
mysql, starts mysql, waits for the replication to get new data from SRV2 
and then unblock port 3306, so the healthcheck can pass again. After 
that successful healthcheck, the real-server is inserted by keepalived 
and clients should have up-to-date data.
	</para>
	<para>
Another thing one has to be aware of in such a setup is the fact, that 
the client will not get anything from SRV2, when SRV1 had crashed and 
comes back up. So socket connections to SRV2 will still be "thought of" 
as "OK".
In order to tell clients they are not OK, i additionaly set
wait_timeout 30
in my.cnf
	</para>
<programlisting><![CDATA[
#!/bin/bash
# /etc/init.d/rc.mysql
# This need some variables to be set according to your system
# And it does not yet feature any checks, i.e. if SRV2 MySQL is
# available etc.
# It just basically shall give an idea of what to do

# Make healthcheck fail
$IPTABLES -A INPUT -i lo -p tcp --dport 3306 -j REJECT

# start mysql
/usr/local/mysql/mysql.server start

# start values
READ_POS=1
EXEC_POS=2

$ECHO
$ECHO -n "Waiting for Replication "
while ( test "$READ_POS" != "$EXEC_POS" )
do
	# Pro text string processing :p
	# Be sure to check prpper values for READ_POS
	# and EXEC_POS
	# This worked for my MySQL 5.0.20, though
         POS=`$ECHO "show slave status\G"|$MYSQL $CONNECT_LOCAL|$GREP "Master_Log_Pos"|$GREP -o -E "[0-9]*$"`
         READ_POS=`$ECHO $POS | $CUT -d\  -f1`
         EXEC_POS=`$ECHO $POS | $CUT -d\  -f2`

         $ECHO -n .
	
	# Output every ~10 sec
         if ( test "`$ECHO $(($I%10))`" -eq "0" )
         then
                 $ECHO
                 $ECHO "READ_POS $READ_POS"
                 $ECHO "EXEC_POS $EXEC_POS"
         fi
         I=$(($I+1))
         $SLEEP 1
done

# Make healthcheck succeed
$IPTABLES -D INPUT -i lo -p tcp --dport 3306 -j REJECT

]]></programlisting>
	</section>
	<section id="1024_failover" xreflabel="failover of large numbers of VIPs">
	<title>Failover of large numbers (say 1024) of VIPs</title>
	<para>
The problem:
	</para>
	<para>
If you have a large number of VIPs, they can take a while
to failover. I got an e-mail from someone with 200 VIPs whose
setup takes 2-3mins to bring up 200 VIPs with 
<command>ifconfig</command>, on the director which is assuming the master role 
(and take them down on the one which is assuming the 
secondary role). 
I couldn't imagine Horms putting up with this so did some
tests to confirm the problem and e-mailed him. 
	</para>
	<para>
Ratz
	</para>
	<para>
No-one should be using <command>ifconfig</command> anymore. 
You're lucky if the ip address gets set up in the first place when you're in a hurry. 
So <command>ip addr add...</command> is the key 
or in <filename>linux-ha</filename> parlance, <command>IPaddr2</command>.
	</para>
	<para>
Christian Bronk <emphasis>chbr (at) webde (dot) de</emphasis> 27 Feb 2006 
	</para>
	<para>
when they still use <command>ifconfig</command> they have to serialize the startups, 
because with <command>ifconfig</command> you must have different alias interfaces.
If they then send two arp broadcasts with <command>send_arp</command> (with delay of 1s) 
the complete server takeover will last 3min.
To makes this faster they have to rewrite their code to use <command>ip</command> 
from the <filename>iproute2</filename> package and try to startup the IPs in parallel.
	</para>
	<para>
Joe
	</para>
	<para>
ISPs are quite restrictive about allocating blocks of IPs, 
so if you have a large number of IPs, they're likely all in the same block.
As a test (on a 200MHz machine) I ran a this loop of 4*252.
	</para>

<programlisting><![CDATA[
#!/bin/bash
ethernet=eth1
echo "up"

for j in `seq 0 3`
do
   for i in ` seq 2 254`
   do
     addr=176.0.${j}.${i}
     #ip addr add dev $ethernet ${addr}/32 brd + label ${ethernet}:n${i}ip${j} \
         && /usr/lib/heartbeat/send_arp $ethernet $addr 00:d0:b7:82:b3:c0 176.0.3.255 00:a0:cc:66:22:22 & 
     #ip addr add dev $ethernet ${addr}/32 brd + label ${ethernet}:n${i}ip${j} & 
     ip addr add dev $ethernet ${addr}/32 brd + label ${ethernet}:n${i}ip${j} 
   done
done

echo "down"

for j in `seq 0 3`
do
   for i in ` seq 2 254`
   do
     addr=176.0.${j}.${i}; 
     ip addr del dev $ethernet ${addr}/32 &
   done
done
]]></programlisting>
	<para>
Here's the times for 1008 addresses on a 200MHz machine 
(a bit slower than current production directors). 
Putting the processes into background doesn't help a lot.
Presumably forking is as expensive as send_arp.
	</para>

       <table>
	<title>Time,sec to bring 1008 IPs up and down on a 200MHz machine</title>
	<tgroup cols="2">
	<thead>
		<row>
			<entry>
			job type
			</entry>
			<entry>
			time,sec
			</entry>
		</row>
	</thead>
	<tbody>
		<row>
			<entry>
			ip addr
			</entry>
			<entry>
			12
			</entry>
		</row>
		<row>
			<entry>
			ip addr &amp;amp;
			</entry>
			<entry>
			10
			</entry>
		</row>
		<row>
			<entry>
			ip addr; send_arp
			</entry>
			<entry>
			30
			</entry>
		</row>
		<row>
			<entry>
			ip addr &amp;&amp; send_arp &amp;
			</entry>
			<entry>
			28
			</entry>
		</row>
	</tbody>
	</tgroup>
	</table>
	<para>
There are two solutions here: 
	</para>
	<itemizedlist>
		<listitem>
William Olson's dynamic routing
 		</listitem>
		<listitem>
Horms' method, where he only fails over 1 VIP with heartbeat and lets static routing
handle the other VIPs by routing through the failover VIP.
		</listitem>
	</itemizedlist>
	<para>
William Olson <emphasis>ntadmin (at) reachone (dot) com</emphasis>  24 Feb 2006 
	</para>
	<para>
In our previous load balancer configs (scripts then later <filename>ldirectord + HA</filename>)
we experienced the same time lags during failover situations(ex. Stopping
<filename>heartbeat</filename> on the master).  
Our systems were 700+mhz Dell servers w/at least 512mb ram.  
They operated in a Master/Backup pair(NAT), each with 2 nics(one
for external and one for internal network).
<filename>Haresources</filename> file was used to start and stop <command>ospfd</command> 
and run <command>IPaddr2</command> for each of the at least 200  VIPs.
You could literally count seconds between each VIP going up/send_arp and the next.
We have consequently switched to <command>keepalived</command> which has alleviated this
problem.
	</para>
	<para>
During a failover while tailing the messages file, you could watch each
successive <command>ip addr</command> and <command>send_arp (IPaddr2)</command>.  
Consequently, when a failover
would happen, all ips would be brought down on the former master almost
instantaneously and slooowly come back up on the backup, now master
director.  It seemed to me that the issue was being caused by the time it
took to actually execute the scripts in the <filename>haresources</filename> file, 
as using <command>ip addr</command> and <command>send_arp</command> 
directly gave time results that were very quick on these same systems.
 	</para>
	<para>
We're running <command>ospfd</command> on the directors and router(s).
It was an original requirement sent down by our network admin to have
dynamic routing on all internal routers.  These days, it just seems better
to go with what has been working rather than to redesign the whole system.
We could probably be just as well off without the ospfd part of the picture
however, it's working now and true to specification so it's pretty easy for
us to troubleshoot.
	</para>
	<para>
<command>ospfd</command> seemed like overkill to me when I was originally designing the
system, however the dictates of the net admin overrode my input.  Now we're
operating with an acceptable failover time so I'm inclined to stay with
<command>ospfd</command>.  
It's now working with <command>ospfd</command> running on the directors(always running
regardless of director state) and routers with <command>keepalived</command> 
managing the lvs and failover on the directors.
	</para>
	<para>
Initial tests of the new <command>keepalived</command> systems are resulting in 15sec or less
failover times independent of the number of IP addresses.
	</para>
	<note>
		<para>
Joe: dynamic routing can take 30-90sec to find new routes: see
<xref linkend="dynamic_routing"/>.
		</para>
	</note>

	<para>
Horms
	</para>
	<para>
The thing that takes time is heartbeat
sending out the gratuitous arp. If you combine this idea with
a fwmark virtual host (bunching all VIPs into one fwmark), then everything should be quite fast 
to failover. But even if you don' use a fwmark virtual host, things
should be quite snappy up to 1000 addresses or so.
(I made that number up :)
	</para>
	<para>
The <command>route</command> command used the format for setting a default route, except
you route a smaller set of addresses to an alternate place.
	</para>
	<para>
Or in other words:
	</para>
<programlisting><![CDATA[
ip route add $VNET/N via $VIP

or

route add $VNET netmask w.x.y.z gw $VIP
]]></programlisting>
	<para>
Of course you can have a bunch of these statements, 
if the addresses don't fit nicely into one address block.
Though its better to try and avoid having one per address.
	</para>
	<para>
Joe
	</para>
	<blockquote>
Do you mean "bunch all the VIPs into a single fwmark".
If so that was my first thought for a solution, but you 
can't route from outside to a fwmark, you still need all the 
IPs to have arp'ed and the router know where to send the 
packets to.
Or did you mean something else?
	</blockquote>
	<para>
Horms
	</para>
	<para>
"something else". :-)
	</para>
	<para>
fwmark is half the solution. It allows LVS to efficiently handle
a large number of virtual solutions. But its only half the solution
because you still need to get the packets to the linux director.
The other half of the solution is routing (Note: the halves
can be used by themselves if need be).
(For more info on the routing used, see <xref linkend="LVS-HOWTO.routing_to_VIP-less_director"/>)
With routing you don't need to ARP each individual VIP.
You just need to make sure that each box on the local network
knows that the VIPs go via the address that is being managed
by heartbeat (or other means like keepalived). 
	</para>
	<para>
Here is an example.
	</para>
	<para>
Lets say the network that the ldirectord lives on is 10.130.0.0/24.
And lets say you want 1024 virtual IP addresses, say in the block
10.192.0.0-10.195.0.0/22.
All you need to do is give heartbeat an address inside 10.130.0.0/24
to manage, say 10.130.0.192, and tell the gateway to route 10.130.0.0/24
via 10.130.0.192
Any host in the network will send packets for 10.192.0.0/23 to the
gateway, which will in turn redirect them to 10.130.0.192, which
is the linux-director and all is well.
Any host outside the network will also end up sending packets
via the gateway, and it will duly forward them to 10.130.0.192,
again the linux-director gets them and all is well.
When a failover occurs, as long as 10.130.0.192 is handled using
gratuitous arp (or whatever), then the gateway will know about it,
and packets for all of 10.192.0.0/23 will end up on the new
linux-director.
	</para>
	<para>
If the local network happend to include all the VIPs,
say because you had 10.0.0.0/8 on your LAN, then each host
would need to know to send 10.192.0.0/23 via 10.130.0.192, which
is a bit of a hassle, but still not a particularly big deal.
	</para>
	</section>
	<section id="vrrpd_setup">
	<title>Some vrrpd setup instructions</title>
	<para>
Alexandre CASSEN <emphasis>alexandre (dot) cassen (at) wanadoo (dot) fr</emphasis> 29 Jul 2002
(Alexandre is now at <emphasis>Alexandre (dot) Cassen (at) free (dot) fr</emphasis>)
	</para>
	<para>
Here is a detailed setup for LVS-HA using a VRRP setup.
	</para>
	<para>
1. Topology description
	</para>
	<para>
In a "standard" design, when you are playing with a LVS/NAT setup, then you
need 2 IP classes. Consider the following sketch :
	</para>
<programlisting><![CDATA[
                 +---------------------+
                 |      Internet       |
                 +---------------------+
                            |
                            |
                       eth0 | 192.168.100.254
                 +---------------------+
                 |       LVS Box       |
                 +---------------------+
                       eth1 | 192.168.200.254
                            |
              --------------+-------------
              |                          |
              | 192.168.200.2            | 192.168.200.3
         +------------+           +------------+
         | Webserver1 |           | Webserver2 |
         +------------+           +------------+
]]></programlisting>
	<para>
So you have 2 classes defining your both LVS-Box segments : 192.168.100.x
for WAN segment and 192.168.200.x for LAN segment.
	</para>
	<para>
For the LVS loadbalancing, we want to define a VIP 192.168.100.253 that
will loadbalance traffic on both 192.168.200.2 and 192.168.200.3.
	</para>
	<para>
For the LVS-Box HA we want to use VRRP setup to use a floating IP to handle
director takeover. When playing with LVS-NAT and VRRP, then you need 2 VRRP
instances, one for WAN segment and one for LAN segment. To make routing
path consitent then we need to define a VRRP synchronization group between
this both VRRP instances to be sure that both VRRP instances will have all
the time the same state.
	</para>
	<para>
2. VRRP Configuration description
	</para>
<programlisting><![CDATA[
vrrp_sync_group G1 {   # must be before vrrp_instance declaration
  group {
    VI_1
    VI_2
  }
}

vrrp_instance VI_1 {
    interface eth0
    state MASTER
    virtual_router_id 51
    priority 100
    authentication {
      auth_type PASS
      auth_pass nenad
    }
    virtual_ipaddress {
        192.168.100.253   # default CIDR mask is /32
    }
}

vrrp_instance VI_2 {
    interface eth1
    state MASTER
    virtual_router_id 52
    priority 100
    authentication {
      auth_type PASS
      auth_pass nenad
    }
    virtual_ipaddress {
        192.168.200.253
    }
}
]]></programlisting>
	<para>
This configuration will set IP 192.168.100.253 on eth0 and 192.168.200.253
on eth1
	</para>
	<para>
3. LVS Configuration description
	</para>
	<para>
In order to use HA, we use VRRP VIP as LVS VIP so the LVS configuration
will be :
	</para>
<programlisting><![CDATA[
virtual_server 192.168.100.253 80 {
    delay_loop 6
    lb_algo rr
    lb_kind NAT
    persistence_timeout 50
    protocol TCP
			</para><para>
    sorry_server 192.168.200.254 80
			</para><para>
    real_server 192.168.200.2 80 {
        weight 1
        HTTP_GET {
            url {
              path /testurl3/test.jsp
              digest 640205b7b0fc66c1ea91c463fac6334d
            }
            connect_timeout 3
            nb_get_retry 3
            delay_before_retry 3
        }
    }
			</para><para>
    real_server 192.168.200.3 80 {
        weight 1
        TCP_CHECK {
            connect_timeout 3   # By default connection port is service
port
        }
    }
}
]]></programlisting>
	<para>
=> VRRP IP 192.168.100.253 will loadbalance traffic to both realservers.
	</para>
	<para>
4. Realservers Configuration description
	</para>
	<para>
And finally, the only things missing in our configuration is the
realservers default gateway... This is why we define a VRRP instance for
LAN segment. So
	</para>
	<para>
Realservers default gateway MUST be : VRRP VIP LAN segment = 192.168.100.253
	</para>
	<para>
5. Keepalived sumup Configuration
	</para>
<programlisting><![CDATA[
! Configuration File for keepalived

global_defs {
   lvs_id lvs01
}

vrrp_sync_group G1 {   # must be before vrrp_instance declaration
  group {
    VI_1
    VI_2
  }
}

vrrp_instance VI_1 {
    interface eth0
    state MASTER
    virtual_router_id 51
    priority 100
    authentication {
      auth_type PASS
      auth_pass nenad
    }
    virtual_ipaddress {
        192.168.100.253   # default CIDR mask is /32
    }
}

vrrp_instance VI_2 {
    interface eth1
    state MASTER
    virtual_router_id 52
    priority 100
    authentication {
      auth_type PASS
      auth_pass nenad
    }
    virtual_ipaddress {
        192.168.200.253
    }
}

virtual_server 192.168.100.253 80 {
    delay_loop 6
    lb_algo rr
    lb_kind NAT
    persistence_timeout 50
    protocol TCP

    sorry_server 192.168.200.254 80

    real_server 192.168.200.2 80 {
        weight 1
        HTTP_GET {
            url {
              path /testurl3/test.jsp
              digest 640205b7b0fc66c1ea91c463fac6334d
            }
            connect_timeout 3
            nb_get_retry 3
            delay_before_retry 3
        }
    }

    real_server 192.168.200.3 80 {
        weight 1
        TCP_CHECK {
            connect_timeout 3   # By default connection port is service
port
        }
    }
}
]]></programlisting>
	<para>
6. Keepalived sumup Configuration on BACKUP node
	</para>
<programlisting><![CDATA[
! Configuration File for keepalived
global_defs {
   lvs_id lvs02
}
vrrp_sync_group G1 {   # must be before vrrp_instance declaration
  group {
    VI_1
    VI_2
  }
}
vrrp_instance VI_1 {   # We just change state & priority
    interface eth0
    state BACKUP
    virtual_router_id 51
    priority 50
    authentication {
      auth_type PASS
      auth_pass nenad
    }
    virtual_ipaddress {
        192.168.100.253
    }
}
vrrp_instance VI_2 {
    interface eth1
    state BACKUP
    virtual_router_id 52
    priority 50
    authentication {
      auth_type PASS
      auth_pass nenad
    }
    virtual_ipaddress {
        192.168.200.253
    }
}
virtual_server 192.168.100.253 80 {
    delay_loop 6
    lb_algo rr
    lb_kind NAT
    persistence_timeout 50
    protocol TCP
    sorry_server 192.168.200.254 80
    real_server 192.168.200.2 80 {
        weight 1
        HTTP_GET {
            url {
              path /testurl3/test.jsp
              digest 640205b7b0fc66c1ea91c463fac6334d
            }
            connect_timeout 3
            nb_get_retry 3
            delay_before_retry 3
        }
    }
    real_server 192.168.200.3 80 {
        weight 1
        TCP_CHECK {
            connect_timeout 3   # By default connection port is service port
        }
    }
}
]]></programlisting>
	<para>
7. LVS-HA scenario
	</para>
	<para>
Now run all this on your both director and simulate a crash by unplug the
wire on LVS1 eth0 for example.
	</para>
	<para>
Detecting this trouble, VRRP will takeover eth0 instance on LVS2 and sync
eth1 instance on LVS2. So all traffic will run throught LVS2.
	</para>
	<para>
This a typical active/passive scenario.
	</para>
	<para>
If you want to extend this configuration to an active/active configuration,
then you need to add MASTER VRRP instances on your LVS2. active/active
configuration consist of one realserver pool segmentation. This mean that
you create 2 realservers pools (in the same IP range) but with a different
default gateway that will be the new VRRP LAN VIP. => This part will be
described more indepth in the documents I will write soon :)
	</para>
	</section>
	<section id="vrrpd_broadcasts">
	<title>Filter rules for vrrpd broadcasts</title>
	<para>
If you want to filter (allow) the vrrpd broadcasts, here's the recipe
	</para>
	<para>
Sebastien BONNET <emphasis>sebastien (dot) bonnet (at) experian (dot) fr</emphasis>
	</para>
	<para>
It's PROTOCOL 112 (vrrp), not PORT 112. You also need protocol igmp (don't ask why).
You have to allow both incoming and outgoing adverts :
	</para>
<programlisting><![CDATA[
-A INPUT -j ACCEPT -i eth0 -p vrrp -s X.Y.Z.0/24 -d 224.0.0.0/8
-A INPUT -j ACCEPT -i eth0 -p igmp -s X.Y.Z.0/24 -d 224.0.0.0/8

-A OUTPUT -j ACCEPT -o eth0 -p vrrp -s X.Y.Z.0/24 -d 224.0.0.0/8
-A OUTPUT -j ACCEPT -o eth0 -p igmp -s X.Y.Z.0/24 -d 224.0.0.0/8
]]></programlisting>
	<para>
To be more precise, a tcpdump shows the multicast address is 224.0.0.18 if you want to be more restrictive.
Don't forget to allow the trafic needed by keepalived to test your real servers. 
In my case, it looks like this :
	</para>
<programlisting><![CDATA[
-A INPUT -j ACCEPT -i eth0 -p tcp --dport http  -m state --state NEW

-A OUTPUT -j ACCEPT -o eth0 -p tcp -m state --state NEW --dports http -d 10.11.0.0/16
]]></programlisting>

	<para>
Noc Phibee 
	</para>
	<blockquote>
For Vrrp protocol, how should I configure shorewall?
When my group changes state I want to restart Shorewall.
I have used the notify_*:
When my MASTER are dead, the BACKUP change state (good),
but when the MASTER are alive and gets the VIP, it runs
the same script (restart of shorewall).
Anyone have a idea why it doesn't immediately change the states?
	</blockquote>
	<para>
Graeme Fowler <emphasis>graeme (at) graemef (dot) net</emphasis> 23 Aug 2006 
	</para>
	<para>
You must allow packets from/to network 224.0.0.0/8
If you want to control this a bit more accurately, define mcast_src_ip in
your keepalived.conf for each defined vrrp_instance, and set your filters
accordingly.
Firstly it looks like the Master is receiving the announcements from the
Backup. This is good. The Backup is also receiving packets from the Master,
which is also good - this is why the Backup flip-flops from BACKUP to MASTER
to BACKUP state continuously.
	</para>
	<para>
However - something else is happening here, and I expect it's your Shorewall config.
Ignoring the Master machine for a moment, let me put forward a possible reason:
	</para>
	<para>
The Backup machine starts up, brings up keepalived, and goes into BACKUP
state. Shorewall is dropping packets at this point, so the Backup machine
goes to MASTER state, does things to Shorewall with the notify script, and
starts to accept packets. It then receives an advertisement from the Master
director, so it switches to BACKUP state, changes the Shorewall config back,
misses advertisement, switches to MASTER, changes the firewall, misses
advertisement, etc etc.
	</para>
	<para>
Assuming this is correct, there are several things you need to do:
	</para>
	<itemizedlist>
		<listitem>
Make sure the Shorewall config isn't dropping the packets you want (see
the suggestions above).
		</listitem>
		<listitem>
Put your notify* script actions into your vrrp_sync_group block instead
of the vrrp_instance. That way it'll only fire once, when the group changes
state, rather than one being fired off for every instance state change *and*
the group.
		</listitem>
	</itemizedlist>
	<para>
Graeme Fowler <emphasis>graeme (at) graemef (dot) net</emphasis> 09 Oct 2006
	</para>
	<para>
You need
	</para>
<programlisting><![CDATA[
iptables -I INPUT -d 224.0.0.0/8 -j ACCEPT
]]></programlisting>
	<para>
You need to explicitly accept multicast for this to work. 
You can make it more accurate by setting
the appropriate config option in your keepalived config to set the mcast_src_address, 
and then have a
corresponding rule to let that in.
	</para>
	</section>
	<section id="comparison_HA_vrrpd">
	<title>Vinnie's comparison between ldirectord/heartbeat and keepalived/vrrpd</title>
	<para>
Vinnie <emphasis>listacct1 (at) lvwnet (dot) com</emphasis> 26 Apr 2003
	</para>
	<para>
I set up both ldirectord and keepalived up to try them out and see which I liked better.  
The goal was to have a redundant pair of LVS(-NAT) directors 
which would also serve as the primary firewall/gateway 
for our external connection and DMZ hosts.  
My firewall scripts use heavy stateful inspection, 
<filename>iproute2</filename> ip utils to add/remove ip's and routes, 
and proxy arp.  
I did not want to lose any of the features of the firewall setup if at all possible.
	</para>
	<para>
These are my observations, but as others have said, both are being heavily
developed by their authors, and anything I say here could be obsolete in
short time.  I think they are both great packages.
	</para>
	<itemizedlist>
		<listitem>
		<para>
LDIRECTORD/HEARTBEAT
		</para>
		<para>
Using ldirectord, you need heartbeat to handle the failover/redundancy
capabilities.  The modular approach is a good idea, and they have developed
resource monitoring which goes well beyond just checking if a realserver
responds to a connection/request on a certain port/service.
		</para>
		<para>
I set up ldirectord first, on a single director, since this would get the
high availability of my realservers working.  I used my firewall script to
add the VIP's to the director (with iproute2 <command>ip</command> commands), and added a
section to the script to create the virtual services with ipvsadm commands.
  (I knew this wouldn't be necessary when/if I got heartbeat set up).
		</para>
		<para>
Ldirectord works quite well, and it apparently has the ability to do a basic
UDP check (since stopping named on one of the realservers causes ldirectord
to remove that RS from the 53/udp virtual service until named is started
back up).
		</para>
		<para>
I was disappointed to see that heartbeat (particularly the ipfail part) is
still written to use ifconfig and old-way ip "aliases" (ie, eth0:0, eth0:1,
etc.) to have multiple IP's on an interface.  2.2.x and ipchains is a bit
"passe" - 2.4.x and iptables has been stable/production for quite some time
now.  iptables does not like interface names with ":" in them, so you are
imposing pretty stiff limits on what kinds of firewall rule sets you can
write if you use old-style ip aliases.
		</para>
		<para>
Reading the mailing list archives, it looks like some users have started
submitting patches that will cause heartbeat to use the iproute utils to set
up the interfaces instead, but this had not been incorporated into the
latest-available beta (at that time, 1st half of Apr. '03), and I was not
sure if the modifications were comprehensive in scope, or just addressing
certain aspects.  (My programming skills are pretty weak).
		</para>
		<note>
Joe, Dec 2003, Linux-HA has been rewritten to use the Policy Routing tools.
		</note>
		<para>
This pretty much nixed any further looking into of heartbeat for me, so I
started looking at keepalived.
		</para>
		</listitem>
		<listitem>
		<para>
KEEPALIVED
		</para>
		<para>
Keepalived is an all-in-one package, which is written in C.
		</para>
		<para>
It uses 2.4-native netlink functions to set up interfaces, IP addresses, and
routes on 2.4 boxes, so it is no big deal to have multiple IP's on one
interface.  You can use iptables commands which match a single interface to
cover all the IP's on the interface, or you can add a -d one.of.my.vips to
make that rule match a single VIP, subnet, etc.
		</para>
		<para>
Keepalived uses VRRPv2 to handle director failover, it's really nice.  When
failover happens, the new master sends gratuitous arps out on the network,
so virtual services experience basically no interruption (especially since
keepalived also supports IPVS connection synchronization between directors).
		</para>
		<para>
There is currently an issue with HEAVY syslog activity when a pair of
directors are running (it logs the election process on both directors) but
Alexandre is working on that.
		</para>
		<para>
If you're running proxy-arp on the director, you can use keepalived's
ability to run scripts when a machine becomes master to send arping
unsolicited arps for the other hosts in your DMZ and your ISP's gateway, so
that the other hosts in your DMZ with routable IP's on their interfaces
(which only need the director as a router/firewall) are also updated with
the new master's MAC addresses.  Keepalived doesn't send gratuitous arp's
out for IP's it didn't take over, so this is needed for your DMZ hosts to
see the ISP's gateway, and also for the ISP's gateway to be apprised of the
new (remember, proxy arp!) MAC address of those other DMZ hosts.  (I am
currently working on a HOW-TO for this, which will apparently be added to
the keepalived online documentation, and also our website).
		</para>
		<para>
Keepalived currently does not support UDP connection check, but it is on
Alexandre's to-do list.
		</para>
		<para>
Also another feature (I haven't looked at yet) of keepalived is the
virtual_server_group capability, which allows you to group virtual services
together and have their health check pass/fail determined by a single
connection check - good for example if you have a stack of IP-based apache
virtual hosts on a realserver.  You probably don't really need to check each
virtual host's IP, and you don't want to flood the realserver with health
checks.
		</para>
		</listitem>
	</itemizedlist>
	<para>
I think they're both really great packages.  
If heartbeat were updated to use <filename>iproute2</filename> utils, 
instead of <command>ifconfig</command> and interface aliases to have multiple IP's per interface, 
it would be much more viable for people running strong iptables firewall rulesets, 
such as those who wish to use the director as a firewall/gateway.
	</para>
	<para>
Me personally, I'm going to keep running keepalived.
It also has a lower CPU overhead.
	</para>
	</section>
	<section id="active_active" xreflabel="Saru">
	<title>Saru: All directors active at the same time</title>
	<note>
saru is a proof of principle piece of code by Horms. 
It was done for one kernel and has not been maintained
through the subsequent kernels.
	</note>
	<para>
Horms has written code allowing all directors to be active at the same time
and an improved <command>syncd</command>.
The code is at 
<ulink url="http://www.ultramonkey.org/papers/active_active/">
http://www.ultramonkey.org/papers/active_active/</ulink>.
	</para>
	<para>
Horms 18 Feb 2004
	</para>
	<para>
Saru means monkey in Japanese.
It's the work I did in Japan on Ultra Monkey... well some of it anyway.
The kanji is in
<ulink url="http://www.ultramonkey.org/papers/active_active/active_active.shtml">
the original paper I wrote for Saru</ulink>
(http://www.ultramonkey.org/papers/active_active/active_active.shtml).
Here are the google links for looking up the meaning of "saru" in Japansese
	</para>
<programlisting><![CDATA[
http://www.google.co.jp/search?hl=ja&ie=UTF-8&oe=UTF-8&q=%E3%82%B5%E3%83%AB&btnG=Google+%E6%A4%9C%E7%B4%A2&lr=
http://www.google.co.jp/search?q=%E7%8C%BF&ie=UTF-8&oe=UTF-8&hl=ja&btnG=Google+%E6%A4%9C%E7%B4%A2&lr=
]]></programlisting>
	<para>
Horms <emphasis>horms (at) verge (dot) net (dot) au</emphasis> 16 Feb 2004
	</para>
	<para>
<filename>Saru</filename> has nothing to do with connection synchronisation, which is what
<command>syncd</command> does.
<filename>Saru</filename> provides a mechanism to allow you to have
Active-Active Linux Directors. Syncd (and other synchronisation daemons)
synchronise connections, allowing them to continue even if the Linux
Director that is handling them fails (assuming that there is another
Linux Director available for them to fail-over to). If you are using
Saru then you probably want to use connection synchronisation,
but the reverse is not necessarily true.
	</para>
	<para>
This
<ulink url="http://www.ultramonkey.org/papers/lvs_jan_2004/">paper</ulink>
(http://www.ultramonkey.org/papers/lvs_jan_2004/)
should cover how Connection Syncronisation and Active-Active
work together. It briefly covers the relevant parts of Alexanre's
syncd patches and how they interact with Saru (as I understand the
extensions anyway).
	</para>
	<para>
Here's a short explanation of Saru's working.
	</para>
	<para>
Francisco Gimeno <emphasis>kikov (at) kikov (dot) org</emphasis> 11 Nov 2006 
	</para>
	<para>
The directors:
	</para>
	<itemizedlist>
		<listitem>
All director nodes know about eachother
		</listitem>
		<listitem>
Each director has an ID ( for example, the MAC or the IP )
		</listitem>
		<listitem>
Each director node can elaborate a sorted list based on that ID
		</listitem>
		<listitem>
Heartbeat everywhere, so the list is dynamic list
		</listitem>
		<listitem>
The "view" of each node should be the same for each node (ie: all nodes 
should have the same list)
		</listitem>
		<listitem>
They should have a virtual-MAC.
Those requirements could be satisfied with a broadcast sync protocol (it could 
be similar to the WCCP, for example)
		</listitem>
	</itemizedlist>
	<para>
for each arriving packet 
	</para>
	<itemizedlist>
		<listitem>
Make a HASH with the parameters you want to keep the __affinity__ (like src 
IP, dst IP, ports, ...) to.
		</listitem>
		<listitem>
Calculate (HASH % numer_of_nodes) ( % := modulo )
		</listitem>
		<listitem>
If that value it's the order in the list for the node processing the packet, 
the packet is accepted, if not, discarded.
As every packet go to every director...
		</listitem>
	</itemizedlist>
	<para>
So one of the <emphasis role="bold">most important thing</emphasis> here, 
is that no director has to put 
the virtual-MAC in the wire, as every director has to receive the packet. Arp 
responses to the VIP should be the virtual-MAC, but it should be sent with a 
bogus-MAC. With that, the responsible to route packets to the VIP, will send 
the packets to that virtual-MAC. As the switch (L2) don't know the physical 
port associated to it, it sends the packet to all the active ports that 
hasn't a MAC associated which are the director's. If you use a HUB then, 
there will not be this kind of problems (who ownes a HUB nowadays?).
	</para>
	<para>
Horms 13 Nov 2006
	</para>
	<para>
It is only active-active for the linux-directors, and its not really
supposed to be active-active for a given connection, just for a given
virtual service. So different connections for the same virtual service
may be handled by different linux-directors.
	</para>
	<para>
The real trick, is that it isn't a trick at all. LVS doesn't terminate
connections, it just forwards packets like a router. So it needs to
know very little about the state of TCP (or other) connections. In fact,
all it really needs to know is already handled by the ipvs_sync code,
and that mainly just a matter of association connections with real
servers. Or in other words, the tuple enduser:port,virtual:port,real:port.
	</para>
	<para>
Ratz
	</para>
	<para>
I've read it now and I must say that you've pulled a nice trick :). I can envision that this
technique works very well in the range of 1-2 Gbit/s for up to 4 or so directors. For higher
throughput netfilter and the time delta between saru updating the quorum and the effective rule being
in place synchronised on all nodes might exceed the packet arrival interval. We/I could do a
calculation if you're interested, based on packet size and arrival on n-Gbit/s switched network.
You're setting rules for ESTABLISHED in your code to accept packets by lookup
of the netfilter connection tracking and while the kernel 2.4 does not care much about window size
and other TCP related settings, 2.6 will simply drop the in-flight TCP connection that is suddenly
sent to a new host. There are two solutions to overcome this problem for 2.6 kernel. 
One is fiddling
ip_conntrack_tcp_be_liberal, ip_conntrack_tcp_loose and sometimes ip_conntrack_tcp_max_retrans and
the other is checking out Pablo's work on netfilter connection tracking synchronisation.
	</para>
	</section>
	<section id="active_active_multipath">
	<title>Active/Active by multipath: random musings</title>
	<para>
Siim Poder <emphasis>windo (at) p6drad-teel (dot) net</emphasis> 09 May 2008 
	</para>
	<blockquote>
		<para>
Is anyone running active-active(-active...) LVS setups? Is it saru or
something else?
		</para>
		<para>
It's seems it should be possible to do it without saru by having
multipath route-capable router upstream dividing the traffic between all
the directors. If you can manage the routes with OSPF, it should be
possible to have active-active directors using more common protocols and
software with the added benefit of each director only receiving the
packets it ends up handling.
		</para>
	</blockquote>
	<para>
Joe
	</para>
	<para>
few of us have access to routers to try such experiments. 
So it's possible this would work, but few people would be able to implement it.
	</para>
	<para>
Graeme
	</para>
	<para>
I'm not (yet) but I may be doing so sometime this year. Current thinking
is (per your email) to run Quagga, Zebra, or ospfd (or something else)
on the directors themselves which will announce the VIPs into the local
network.
	</para>
	<para>
The local network devices will then work out the best path for traffic
flowing through them; OSPF is designed around a cost and hop-count model
so having multiple routes originated in different places should mean
"closest network wins" from a client perspective - although this is
untested!
	</para>
	<para>
The interesting part is how you make sure the traffic returns to the
clients. In the case of -DR this isn't really a problem, but using -NAT
could be difficult if the realservers can receive, and return, traffic
to either director.
	</para>
	<para>
By extension, you could split a cluster into two halves and have each in
a different physical and logical location using this model, but that
adds complexity at the backend if you're sharing file data and/or
databases. What that would give you is, for example, proper geographical
resilience such that if one location loses power, hey? Who cares? We'll
just talk to the other one instead!
	</para>
	<para>
And as an added bonus, if you have multiple equal-cost paths to
directors in the same location, OSPF can be made to (crudely, in some
cases) load-balance between them. This gives a bit more even-handed
loading but does add an extra thing to go wrong.
	</para>
	</section>
	<section id="wollman">
	<title>Server Load Balancing Registration Protocol</title>
	<para>
William V. Wollman <emphasis>wwollman (at) mitre (dot) org</emphasis>
	</para>
	<para>
  We have worked with LVS to implement something we call the Server Load
Balancing Registration Protocol.  It allows a server to plug into a
network with the LVS and register it services with the LVS.  The LVS is
then automatically configured to balance the services registered.  We
did not modify LVS directly but created a Java program that processes
the realserver registration messages and then automatically configures
the LVS.  The realserver requires the installation of a Java program to
build the registration messages and register its services.   One benefit
is plug and play SLB with minimal administration.  Another benefit is
controlled configuration management.
	</para>
	<para>
A paper is available for download that describes the work we completed
in a bit more detail.
If interested please download and read the article at
<ulink url="http://www.mitre.org/work/tech_papers/tech_papers_03/wollman_balancing/index.html">
http://www.mitre.org/work/tech_papers/tech_papers_03/wollman_balancing/index.html</ulink>.
	</para>
	</section>
	<section id="iproute2_failover">
	<title>using iproute2 to keep demons running during failover, while link is down</title>
	<para>
On failover, when the backup machine assumes the active role, it must
bring up IP(s) and possibly start demons listening on those IP(s).
With the <xref linkend="LVS-HOWTO.policy_routing"/> tools <emphasis>e.g.</emphasis>
<filename>iproute2</filename>, the backup machine can have the IP configured
with the demons listening, but with the link state down.
On failover you just change the linkstate to "up".
	</para>
	<para>
Roberto Nibali <emphasis>ratz (at) drugphishi (dot) ch</emphasis> 24 Dec 2003
	</para>
	<para>
This will keep all assigned IP addresses for the interface.
	</para>
<programlisting><![CDATA[
ip link set dev $intf down
]]></programlisting>
	<para>
This will remove (flush) all IP addresses from the interface.
	</para>
<programlisting><![CDATA[
ip addr flush dev $intf
]]></programlisting>
	<para>
However
	</para>
<programlisting><![CDATA[
ifconfig $intf down

means:

set link state of eth1 down _and_ flush the IP address of the alias named $intf.
]]></programlisting>
	<para>
Which is completely broken! With <command>ifconfig</command> you have no means to
distinguish between flushing IP addresses and setting a link state of a
physical interface. There's a huge difference routing wise. In the case
of setting the physical link layer to down, you do _not_ disable routing
table entries. In the case of flushing an IP address you _also_ remove
its routing table entry which can be annoying from a setup point of view
and definitely irritating from a security viewpoint.
	</para>
	<para>
The reason why it is important to have two states of interface setup can
for example be found in the security business. You set the link state to
down, set up all packet filter rules and then configure all IP addresses
and rules and routes. Then you start local daemons (and they will start
even if they need to bind and listen to non-local IP addresses because
the IP addresses and the routing is complete) _and_ after that you open
your gates by setting the link state to up.
	</para>
	</section>
</section>
<section id="LVS-HOWTO.dynamic_routing" xreflabel="Dynamic Routing">
<title>LVS: Dynamic Routing, multiple gateways, realservers in multiple LVSs, dead gateway detection</title>
<para>
Normally multiple routes are handled by routers. 
However you may not have access to the router tables for administrative reasons or
because someone wants to protect their turf (they don't want someone not in their
department poisoning their router tables).
Here we describe setting up multiple routes and how they can be used in an LVS.
</para>
	<section id="realservers_in_two_lvss">
	<title>Setting up multiple gateways: Realservers shared between two LVSs: <command>ip route append</command></title>
	<para>
If realservers are supplying services through two directors, then
the realservers need two default routes (one through each director).
This is allowed by the TCPIP RFCs but rarely implemented. 
You cannot add a 2nd default route with <command>ip route add</command>, 
you'll get an error saying that the route already exists. 
Instead you use the command <command>ip route append</command>. 
This was worked out by Posko (Malalon)
	</para>
	<para> 
	posko <emphasis>P (dot) Osko (at) elka (dot) pw (dot) edu (dot) pl</emphasis> 17 Apr 2002
	</para>
	<blockquote>
		<para>
I used <command>ip append</command> at home when I was testing
source address routing for RealServers. But when I started
working with my setup I found that I can't set up two default
routes for different addresses in one routing table (in Linux
it's by default table 'main' where all normal routes are stored)
because only one default route works at the same time
(the first added to route table).
So I decided to create separate route tables (named 201
and 202 in my setup) containing default route for each
alias using the following command:
		</para>
		<para>
<programlisting><![CDATA[
ip route add 0/0 src 192.168.1.2 via 192.168.1.1 table 201
]]></programlisting>
		</para>
		<para>
and route packets with source address from 192.168.1.2
according to this table (201)
		</para>
		<para>
<programlisting><![CDATA[
ip rule add from 192.168.1.2/25 table 201 prio 220
]]></programlisting>
		</para>
	</blockquote>
	<para>
Here are the details from Pawel Osko, Warsaw University of Technology,
Faculty of Electronics and Information Technology.
	</para>
	<para>
You can create two (or more) LVS-NAT directors using the
<xref linkend="LVS-HOWTO.policy_routing"/>.
The simplest setup is one RS working with two DIRs:
	</para>
<programlisting><![CDATA[
         --------
        | client |
         --------
            |
            |
         _________
        |         |
       DIR1      DIR2
        |         |
         ---------
            |
           RS
]]></programlisting>
	<para>
The first step is to create working setup with one DIR and one RS. In
my setup I'm using one NIC two Networks LVS-NAT.
Example (my) setup:
(You can use the Configure Script to set it up.)
	</para>
<programlisting><![CDATA[
DIR1:
VIP=A.B.C.70
DIRECTOR_VIP_DEVICE=eth0:110
DIRECTOR_INSIDEIP=192.168.1.1
DIRECTOR_DEFAULT_GW=A.B.C.126

RS:
RIP=192.168.1.2
GW=192.168.1.1
]]></programlisting>
	<para>
Now test it.
If everything is ok, set the second DIR, and change settings on RS:
	</para>
<programlisting><![CDATA[
DIR2:
VIP=A.B.C.71
DIRECTOR_VIP_DEVICE=eth0:110
DIRECTOR_INSIDEIP=192.168.2.1
DIRECTOR_DEFAULT_GW=A.B.C.126


RS:
RIP=192.168.2.2
GW=192.168.2.1
]]></programlisting>
	<para>
and test it.
	</para>
	<para>
Now you know for sure that your DIRs are set up properly and
your RS can work with both of them.
	</para>
	<para>
Step 2.
	</para>
	<para>
Keep directors working.
Delete addresses on network interface on RS (using `ip addr del` command
for example).
Add two addresses to NIC (I'm using eth0):
	</para>
<programlisting><![CDATA[
ip addr add 192.168.1.2/25 broadcast 192.168.1.127 dev eth0 label eth0:1
ip addr add 192.168.2.2/25 broadcast 192.168.2.127 dev eth0 label eth0:2
]]></programlisting>
	<para>
Check if everything is ok:
	</para>
<programlisting><![CDATA[
ip addr show
]]></programlisting>
	<para>
Each of addresses will work with other DIR. Now you must make packets
from eth0:1 go to DIR1 and from eth0:2 to DIR2. Source routing will be
used to do this.
	</para>
	<para>
Create rules for each IP:
	</para>
<programlisting><![CDATA[
ip rule add from 192.168.1.2/25 table 201 prio 220
ip rule add from 192.168.2.2/25 table 202 prio 220
]]></programlisting>
	<para>
where 201 and 202 are names of tables.
	</para>
	<para>
Add default routes for each IP:
	</para>
<programlisting><![CDATA[
ip route add 0/0 src 192.168.1.2 via 192.168.1.1 table 201
ip route add 0/0 src 192.168.2.2 via 192.168.2.1 table 202
]]></programlisting>
	<para>
You are done! Now all packets from 192.168.1.2 will go through DIR1
and packets from 192.168.2.2 through DIR2.
	</para>
	<para>
New RSs can be added now, simply follow instructions in Step 2 for new IPs.
You can also have more DIRs, just add more IPs on RS. I set up LVS-NAT
with four DIRs working with four RSs using mon to dect RS's failures and
everything works perfect (at last!).
	</para>
	</section>
	<section id="dead_gateway" xreflabel="dead gateway">
	<title>Connecting from clients through multiple parallel links: the dead gateway problem</title>
	<para>
This is not an LVS problem, just a normal routing problem.
You can have multiple default gateways in Linux.
The problem is knowing when one of them has died.
	</para>
	<para>
The &quot;Connected&quot; site has a
discussion of dead gateway detection
(http://www.freesoft.org/CIE/RFC/1122/56.htm, site gone 14 Sep 2004) 
derived from the RFCs.
The points raised are
	</para>
	<itemizedlist>
		<listitem>
active probes (<emphasis>e.g.</emphasis> pings) are expensive,
scale poorly and MUST NOT be used continuously to check the status
of a first-hop gateway.
When pings must be used, they MUST only be used when traffic is being
sent to the gateway.
		</listitem>
		<listitem>
other layers (above and below the IP layer) SHOULD be able to give advice
to the routing layer, when positive (gateway OK) or negative (gateway dead)
information is available.
		</listitem>
		<listitem>
Dead gateway detection is covered in some detail in RFC-816 [IP:11]. 
Experience to date has not produced a complete algorithm which is totally satisfactory,
though it has identified several forbidden paths and promising techniques. 
		</listitem>
	</itemizedlist>
	<para>
In case you're wondering, 
what they're really saying is that dead gateway detection 
was not built into the protocol and no satisfactory solution for its absence
has been found.
	</para>
	<para>
Ratz 22 Jan 2006 
	</para>
	<para>
According to RFC816 and RFC1122 there are multiple ways to perform DGD, 
however I've only seen about 3 of those in the wild:
	</para>
	<itemizedlist>
		<listitem>
                     Link-layer information that reliably detects and
                     reports host failures (e.g., ARPANET Destination
                     Dead messages) should be used as negative advice.
		</listitem>
		<listitem>

                     An ICMP Redirect message from a particular gateway
                       should be used as positive advice about that
                       gateway.
		</listitem>
		<listitem>
                      Packets arriving from a particular link-layer
                       address are evidence that the system at this
                       address is alive.  However, turning this
                       information into advice about gateways requires
                       mapping the link-layer address into an IP address,
                       and then checking that IP address against the
                       gateways pointed to by the route cache.  This is
                       probably prohibitively inefficient.
		</listitem>
	</itemizedlist>
	<para>
The Alteon switch does media detection and could also listen to special 
L2 PDU packets, including advertisements. Media detection under Linux is 
an often discussed and to date not resolved issue. For about 2 months 
starting last November, a couple of people on netdev have been working 
on proper link state propagation in the core kernel, the result will be 
seen in 2.6.17 ;). Other than that I suggest you use non-cheap but 
excellently supported NICs, like e1000 and check the media state using 
ethtool or write a netlink listener.
	</para>
	<para>
You are allowed to ping, but only if nothing else works for you (3.3.1.4):
	</para>
	<itemizedlist>
		<listitem>
                Active probes such as "pinging" (<emphasis>i.e.</emphasis>, using an ICMP
                  Echo Request/Reply exchange) are expensive and scale
                  poorly.  In particular, hosts MUST NOT actively check
                  the status of a first-hop gateway by simply pinging the
                  gateway continuously.
		</listitem>
		<listitem>
                 Even when it is the only effective way to verify a
                  gateway's status, pinging MUST be used only when
                  traffic is being sent to the gateway and when there is
                  no other positive indication to suggest that the
                  gateway is functioning.
		</listitem>
		<listitem>
                 To avoid pinging, the layers above and/or below the
                  Internet layer SHOULD be able to give "advice" on the
                  status of route cache entries when either positive
                  (gateway OK) or negative (gateway dead) information is
                  available.
		</listitem>
	</itemizedlist>
	<para>
Multiple routes to the internet is discussed in 
<ulink url="http://lartc.org/howto/lartc.rpdb.multiple-links.html">
Routing for multiple uplinks/providers</ulink>
(http://lartc.org/howto/lartc.rpdb.multiple-links.html)
and
<ulink url="http://linux-ip.net/html/adv-multi-internet.html">
Multiple Connections to the Internet</ulink>
(http://linux-ip.net/html/adv-multi-internet.html).
Julian (immediately below) has a dead gateway detection mechanism
and a working setup with dead gateway detection is shown at 
<ulink url="http://www.ssi.bg/~ja/nano.txt">
Nano-Howto to use more than one independent Internet connection.
by Christoph Simon</ulink>
(http://www.ssi.bg/~ja/nano.txt).
The author warns
	</para>
	<blockquote>
The setup of all this is not a question of 5 minutes
	</blockquote>
	<para>
Logu <emphasis>lvslog (at) yahoo (dot) com</emphasis> 5 Oct
	</para>
	<blockquote>
I have two isdn internet connection from two different isps.
I am going to put an lvs_nat between the users and these two links
so as to loadbalace the bandwidth.
	</blockquote>
	<para>
Julian
	</para>
	<para>
	You can use the Linux's multipath feature:
	</para>
<programlisting><![CDATA[
# ip ru
0:      from all lookup local
50:     from all lookup main
...
100:    from 192.168.0.0/24 lookup 100
200:    from all lookup 200
32766:  from all lookup main
32767:  from all lookup 253

# ip r l t 100
default  src DUMMY_IP
	nexthop via ISP1  dev DEV1 weight 1
	nexthop via ISP2  dev DEV2 weight 1

# ip r l t 200
default via ISP1 dev DEV1  src MY_IP1
default via ISP2 dev DEV2  src MY_IP2
]]></programlisting>
	<para>
	You can add my
<ulink url="http://www.ssi.bg/~ja/">dead gateway detection extension</ulink>
(for now only against 2.2)
	</para>
	<para>
	This way you will be able fully to utilize the both lines
for masquerading. Without this patch you will not be able to select
different public IPs to each ISP. They are named "Alternative routes".
Of course, in any case the management is not an easy task. It needs
understanding.
	</para>
	<para>
anon
	</para>
	<blockquote>
I currently have multiple adsl modems that connects to the internet.
	</blockquote>
	<para>
Alexandre Cassen <emphasis>alexandre (dot) cassen (at) wanadoo (dot) fr</emphasis> 11 Apr 2003
	</para>
	<para>
This is a routing design problem,
commonly accomplished done by loadbalancing default route at the routing level (netlink).
You add 2 default gateway with the same weight to provide outbound loadbalancing.
Since current linux kernel routing suffer lake of dead gateway detection,
you will need to apply Julian's "dead gateway detection" patch.
	</para>
	</section>
	<section id="dynamic_routing" xreflabel="Dynamic Routing to handle loss of routing in directors">
	<title>Dynamic Routing to handle loss of routing in directors</title>
	<para>
Here I show how use dynamic routing to handle routing following failure
of the link from a director to its default gw.
The director with the failed default route gets its
new routing information from the adjacent director,
which is assumed to have a functional route to the outside world.
	</para>
	<para>
After I got this to work,
I found out that you don't do dynamic routing if the interfaces
on two machines are in the same networks as shown here,
as happens with duplicate directors (or routers).
<programlisting><![CDATA[
-------network_A---------
      |         |
    host_1    host_2
      |         |
-------network_B---------
]]></programlisting>
In the case of common networks,
alternate routes are (usually) handled by multiple static routes with different weights
<emphasis>e.g.</emphasis>
<ulink url="http://www.lartc.org/howto/lartc.rpdb.multiple-links.html">
Routing for multiple uplinks/providers</ulink> in the Linux Advanced
Routing and Traffic Control HOWTO.
This section then is not exactly central to LVS failover
and unless you have some other reason to read about dynamic routing,
you may want to skip this section.
This was my first attempt at dynamic routing.
Even if you use dynamic routing, I won't be
surprised if there are better ways of doing it.
Suggestions welcome.
	</para>
	<para>
You use dynamic routing only if the hosts are connected to non-common networks,
as here, where host_1 is not connected to network_C, while host_2 (which is
connected to and can communicate with host_1) is.
<programlisting><![CDATA[
----network_A-----
      |
    host_1
      |
----network_B-----
      |
    host_2
      |
----network_C----
]]></programlisting>
Dynamic routing would be used by host_2 to send information about network_C to host_1 (etc).
	</para>
	<para>
I had previously been handling routing failure with scripts.
Script driven failover (where as well, you have to
reconfigure demons to listen to the moveable IP and
the router has to think that is has a new name),
requires the scripts to run in pairs
(<filename>to_up</filename> on one machine, and <filename>to_down</filename> on the
other).
The scripts have to be synchronized and have to run to completion on both machines.
If one machine becomes deranged and looses track of its state,
then scripts won't failover cleanly.
You should be able to down/crash/wedge any single NIC/route/disk/demon in
a failover router pair without loosing routing, no matter what.
I found that my scripts would often result in some hung state.
Perhaps better scripts would have handled it, but this would indicate
that functional scripts are difficult to write.
	</para>
	<para>
I was looking for other ways of handling routing failure,
when John Reuning posted on the mailing list that he
was using <filename>zebra</filename>.
I had not managed to even figure out how to setup
the <filename>.conf</filename> file last time I tried (several years ago)
as I found the docs inscrutable (some sections were blank).
Here's the posting from John Reuning,
which showed me how simple it was to configure zebra and
which started me off with dynamic routing.
	</para>
	<blockquote>
		<para>
John Reuning <emphasis>john (at) metalab (dot) unc (dot) edu</emphasis>
17 Feb 20004
		</para>
		<para>
I've included the <filename>.conf</filename> files below.
I didn't do anything crazy coming up with this stuff.
There were sample config files in the source
code, and I just copied what I needed.
		</para>
		<para>	
To make snmp work, these need to go in the snmpd config:
		</para>
<programlisting><![CDATA[
smuxpeer 1.3.6.1.4.1.3317.1.2.1 zebra
smuxpeer 1.3.6.1.4.1.3317.1.2.2 zebra_bgpd
]]></programlisting>
		<para>	
The one quirk I remember is that one of the daemons needs to start
before the other.  If zebra isn't running when bgpd starts up, it freaks
out.
		</para>
		<para>
<filename>bgpd.conf</filename>
		</para>
<programlisting><![CDATA[
! bgpd.conf
!
hostname bgpd
password xxxxxx
enable password xxxxxx
log syslog
!log stdout
!log file bgpd.log
smux peer .1.3.6.1.4.1.3317.1.2.2 zebra_bgpd
!
!bgp multiple-instance
!
router bgp 2
  bgp router-id 192.168.1.254
  neighbor 10.0.1.1 remote-as 2
  neighbor 192.168.2.1 remote-as 2
  neighbor 192.168.2.1 route-reflector-client
  neighbor 192.168.2.2 remote-as 2
  neighbor 192.168.2.2 route-reflector-client
!
line vty
!
]]></programlisting>
		<para>
<filename>zebra.conf</filename>
		</para>
<programlisting><![CDATA[
! zebra.conf
!
hostname director
password xxxxxx
enable password xxxxxx
log syslog
!log stdout
!log file zebra.log
!
smux peer .1.3.6.1.4.1.3317.1.2.1 zebra
!
]]></programlisting>
		</blockquote>
	<para>
I thought it would be better to handle the failover with
hardened and well tested demon(s) running on each machine,
that maintain communication,
and know what to do when one machine is in an arbitary fault state.
These demons then would run the minimum depth of the more fragile,
dependant scripts.
	</para>
	<para>
Zebra is a GPL package containing the common dynamic routing demons
(<command>ripd</command>, <command>bgpd</command>, <command>ospfd</command>).
Zebra runs on many platforms and uses a command
syntax close to that of cisco IOS (<emphasis>i.e.</emphasis> you can use
the cisco documentation if you're stuck). Useful documentation I found
	</para>
	<itemizedlist>
		<listitem>
A review on Zebra
by Mike Metzger (link dead Mar 2004, http://www.unixreview.com/documents/s=1350/urm001a/).
An introduction to setting up Zebra.
This didn't give me enough information to get going, but did tell me that someone
understood it and gave me hope that I would too.
		</listitem>
		<listitem>
<ulink url="http://www-106.ibm.com/developerworks/linux/library/l-emu/">Build a network
router on Linux</ulink> by Dominique Cimafranca and Rex Young
(http://www-106.ibm.com/developerworks/linux/library/l-emu/) -
a slightly more advanced introduction to Zebra.
This, together with the config files supplied by John Reuning (below),
contained enough information for me to get Zebra to do something.
		</listitem>
		<listitem>
The <ulink url="http://www.zebra.org/">Zebra documentation</ulink>
(http://www.zebra.org/) (this seems to be complete now - a few years back,
whole sections were blank).
		</listitem>
		<listitem>
<ulink url="http://www.cisco.com/pcgi-bin/Support/browse/index.pl?i=Technologies&amp;f=770">
Cisco documentation</ulink>
(http://www.cisco.com/pcgi-bin/Support/browse/index.pl?i=Technologies&amp;f=770).
After bootstrapping from the Cimafranca and Young article,
I could use the articles here
<emphasis>e.g.</emphasis>
Routing Information Protocol (RIP)
(link dead Mar 2004, http://www.cisco.com/univercd/cc/td/doc/cisintwk/ito_doc/rip.html),
Using the Border Gateway Protocol for Interdomain Routing
(link dead Mar 2004, http://www.cisco.com/univercd/cc/td/doc/cisintwk/ics/icsbgp4.html).
		</listitem>
		<listitem>
I was helped by Tom Brosnan and Steve Buchanan, networking people at my job.
		</listitem>
		<listitem>
After I got this working, I found
<ulink url="http://www.lartc.org/howto/lartc.dynamic-routing.html">
Dynamic routing - OSPF and BGP</ulink>
(http://www.lartc.org/howto/lartc.dynamic-routing.html)
in the Linux Advanced
Routing and Traffic Control HOWTO.
		</listitem>
	</itemizedlist>
	<para>
As with most computer documentation,
you already have to understand the topic in order to be able to read it.
Much documentation about dynamic routing
concerns the differences between RIP, BGP, OSPF,
and goes into details about convergence, horizons...
You don't need any of that right now.
All you need to know is that these 3 protocols move routing
information from one machine to another
and that the syntax of the commands for them is much the same.
For moving routing information within an AS, you use rip (the original protocol)
or ospf (the newer protocol).
For moving routing information between different ASs, you need bgp (I think).
	</para>
	<para>
To the LVS client, as far as routing is concerned,
an LVS appears to be a single leaf node.
For an LVS with one director,
all routing is to the director and the LVS really is a single leaf node.
When multiple directors are involved,
and the VIP hops between directors on failover,
the inbound routing can be handled at the arp level
(the director uses <command>send-arp</command> to update the location of the VIP).
For outbound routing
(<emphasis>i.e.</emphasis> packets from the VIP on the director to 0/0),
dynamic routing protocols can be used.
One place that dynamic routing could be used in an LVS,
is following failure of the link to 0/0,
a director does a failover and no longer having a route to 0/0,
has to route packets through the other director (see diagram below).
		<note>
I wanted the setup to run a router failover pair.
If you are using this to maintain outbound routing for an LVS,
you will only need this for LVS-NAT.
For LVS-DR and LVS-Tun, for security,
there should be no route from the VIP on the director to 0/0 -
see <xref linkend="Pearthree"/>.
		</note>
	</para>
	<para>
Normally with dynamic routing, the routers (here, the two directors)
are in contact with upstream routers (running a dynamic routing protocol),
who feed routing information to them.
The link state of the network (up||down)
can be inferred from the presence (or absence) of the routing advertisements.
With routing advertisements exchanged at 30-60 sec intervals,
it will take <command>ripd</command> about 3 mins to timeout a dead link.
<command>bgp</command> is a little faster and takes about a minute to timeout a dead link.
	</para>
	<para>
In the general case,
you may not be able to get dynamic routing information from upstream.
Some organisations are big and inflexible,
there maybe turf battles,
and the IT department will worry about getting bogus advertisements from you.
	</para>
	<para>
Where I live, network link failure
(or routing failure, which may appear as a link failure)
is the most common problem when maintaining service.
	</para>
		<note>
			<para>
Other problems, <emphasis>e.g.</emphasis> power failures occur more often,
but these can be handled by UPSs;
disk failures, which you have to plan for,
are handled by <xref linkend="disk_monitoring"/> and pre-emptive
disk replacement of working disks as they approach their warrantee expiration.
			</para>
		</note>
	<para>
Assuming that the two routers (directors) are both functional,
then failover after a routing/link
failure has to handle two problems
	</para>
	<itemizedlist>
		<listitem>
			<para>
detection of link/routing failure
			</para>
			<para>
A setup is needed that works without link (or routing) information from upstream machines.
In the absence of packets from an upstream machine, link (or routing) failure detection is difficult.
I will assume that this is being handled by the failover demon
(keepalived/vrrpd or Linux-HA).
			</para>
		</listitem>
		<listitem>
		<para>
reconfiguring the default gw
		</para>
		<para>
The director with a failed route to the outside,
has to route via the other director.
		</para>
		</listitem>
	</itemizedlist>
	<para>
Here's some info about the differences between routing via tables
(<emphasis>i.e.</emphasis> how you set up a leaf node) and routing
with dynamic routing protocols (<emphasis>i.e.</emphasis> on a router)
	</para>
	<itemizedlist>
		<listitem>
		<para>
<emphasis role="bold">leaf nodes:</emphasis> automatically route
to networks on interfaces.
All other packets are sent to a default gw.
The machine's view of the network is fixed
and it knows that it is at the edge of the internet.
		</para>
		</listitem>
		<listitem>
		<para>
<emphasis role="bold">routers:</emphasis> advertise networks and IPs.
Other routers pick up the messages and figure out the routing.
All routers see themselves in the middle of the internet,
with no idea where they are in it, or how big the internet is
(the Ptolemeic view of the network).
In particular, RIP and OSPF routers don't know about edges of ASs
or the existence of other ASs.
You don't explicitely set routes, rather you list the IPs of the
neighbors and then let the routing demons figure out the topology.
Except for border routers, the other routers (running RIP or OSPF)
don't know about an AS.
		</para>
		<note>
What you need to have your own AS,
depends on your clout and size in the networking world.
If you're a big governmental agency with offices throughout the country,
have thousands of networked computers,
route all your intra-agency's packets through clouds
(leased lines, where packets don't go onto the internet)
and route all your packets to the internet over multiple redundant links,
via local ISPs at each site, then you'll have your own AS.
Big ISPs will have an AS.
If you're a small organisation,
you'll have static links to your provider and you won't have an AS.
Small dial-up companies with just a few machines handling the traffic
have static links and don't even get routing advertisements from their ISPs.
Businesses usually are dealing with computers or networks, but not both.
If you're in a business that uses computers (<emphasis>e.g.</emphasis>
you're an applications programmer), then you won't have an AS.
If you even ask the question "what do I need to have an AS?",
then you aren't in the network business and you won't have one.
		</note>
		<para>
An AS is connected through border routers
(usually two or more for redundancy) to an ISP
which is connected to the internet backbone.
The border routers act as a default gw for the routers inside the AS
(and do so by the instruction "default route originate"
in their <filename>.conf</filename> file)
and appear as a "route of last resort" in
the routing tables of the inside machines.
		</para>
		<para>
If you want your own (private) AS, then use the private AS numbers 64512-65535
(the AS equivalent of 192.168.x.x IPs). Advertisements for these
ASs are not propagated.
		</para>
		<para>
After convergence, the routers within an AS will know the routes in the AS
and will know which machines to use as their default gw (gateway of last resort).
		</para>
		</listitem>
	</itemizedlist>
	<para>
Here's the setup for the demonstration with two
routers (directors), working as an active/backup pair,
running a dynamic routing protocol.
	</para>
	<note>
		<para>
<filename>dummy0</filename> is configured with an IP
in the Cimafranca paper, partly for their demonstration.
This IP allows you to ping the node
from the outside, as long as at least one hardware NIC is up.
Supposedly this IP is a convenience to be able to
identify a host (although I didn't have any need for it).
<filename>dummy0</filename> is chosen
as it is the interface least likely to go down.
cisco routers use lo for this IP,
but apparently the convention with Linux is to use dummy0.
		</para>
		<para>
The IPs on each dummy0 interface are in different networks.
If they are in the same network, you can't route to the
IP on dummy0 on adjacent machines.
		</para>
	</note>
	<para>
Here is the network during normal functioning
	</para>
<programlisting><![CDATA[
                    ______________    ______________
                   |              |  |              |
                   |    router    |  |    router    |
                   |______________|  |______________|
                    192.168.1.253     192.168.1.254
                          |                 |
                          |                 |
                          |                 |
                          |                 |
                          |                 |
                     192.168.1.1       192.168.1.2
                    ______________    ______________
                   |              |  |              |
10.0.1.1/24=dummy0-|    backup    |  |    active    |-dummy0=10.0.2.1/24
                   |______________|  |______________|
                          |                 |
                     192.168.2.1       192.168.2.2
                          |                 |
                           -----------------
                                   |
                              realservers
]]></programlisting>
	<para>
Here is the network immediately following link loss to the backup director's
default gw.
	</para>
	<itemizedlist>
		<listitem>
the backup director has <emphasis role="bold">no</emphasis> default gw.
		</listitem>
		<listitem>
the active director has a default gw.
		</listitem>
		<listitem>
The job of the dynamic routing demon is to let the backup director
know where the default gw is.
		</listitem>
	</itemizedlist>
<programlisting><![CDATA[
                    ______________    ______________
                   |              |  |              |
                   |    router    |  |    router    |
                   |______________|  |______________|
                    192.168.1.253     192.168.1.254
                          |                 |
                                            |
                          X                 |
                                            |
                          |                 |
                     192.168.1.1       192.168.1.2
                    ______________    ______________
                   |              |  |              |
10.0.1.1/24=dummy0-|    backup    |  |    active    |-dummy0=10.0.2.1/24
                   |______________|  |______________|
                          |                 |
                     192.168.2.1       192.168.2.2
                          |                 |
                           -----------------
                                   |
                              realservers
]]></programlisting>
	<para>
Here is the network after re-establishing the default route for the backup master node.
This takes about 25 secs with RIP.
	</para>
<programlisting><![CDATA[
                    ______________    ______________
                   |              |  |              |
                   |    router    |  |    router    |
                   |______________|  |______________|
                    192.168.1.253     192.168.1.254
                          |                 |
                                            |
                                            |
                           -----------------|
                          |                 |
                     192.168.1.1       192.168.1.2
                    ______________    ______________
                   |              |  |              |
10.0.1.1/24=dummy0-|    backup    |  |    active    |-dummy0=10.0.2.1/24
                   |______________|  |______________|
                          |                 |
                     192.168.2.1       192.168.2.2
                          |                 |
                           -----------------
                                   |
                              realservers
]]></programlisting>

	<note>
		<para>
You install the <filename>iproute2</filename> tools for zebra
to work <emphasis role="bold">and</emphasis>
and the CLI commands must be policy routing commands.
		</para>
		<para>
There are two series of network tools available with Linux
		</para>
		<itemizedlist>
			<listitem>
<command>ifconfig</command>, <command>route</command>; these are the old style commands.
			</listitem>
			<listitem>
<command>ip addr show</command>, <command>ip route show</command> from
the <filename>iproute2</filename> policy routing tools.
			</listitem>
		</itemizedlist>
		<para>
The routes/IPs added by rip/zebra are added by the <filename>iproute2</filename> tools.
The two series of commands are incompatible.
IPs (or routes) added by <filename>iproute2</filename>
may not be visible to <command>ifconfig</command> (or <command>route</command>).
Routes added by <command>ip route add</command>
may be visible to <command>route</command>
but aren't capable of being deleted by <command>route</command>.
All IP and route commands from the command line
must use the <filename>iproute2</filename> tools.
		</para>
	</note>
	<para>
If you like names rather than port numbers, add these to
<filename>/etc/services</filename>
	</para>
<programlisting><![CDATA[
#zebra
zebrasrv      2600/tcp            # zebra service
zebra         2601/tcp            # zebra vty
ripd          2602/tcp            # RIPd vty
ripngd        2603/tcp            # RIPngd vty
ospfd         2604/tcp            # OSPFd vty
bgpd          2605/tcp            # BGPd vty
ospf6d        2606/tcp            # OSPF6d vty
#
]]></programlisting>
	<para>
<filename>zebra.conf</filename>
	</para>
<programlisting><![CDATA[
!
! Zebra configuration saved from vty
!   2004/02/19 17:48:27
!
! hostname given at zebra prompt and passwd
hostname zebra
password zebra
!
! enable "enable" command and give passwd for it.
enable password zebra
!
! log to a file
log file /var/log/zebra.log
! alternatively, log to a facility
!log syslog
!log stdout
!
! turn on vtysh access
line vty
!
! the interfaces you want Zebra to know about
! (tell zebra about all of them)
interface lo
!
interface dummy0
!
interface tunl0
!
interface eth0
!
interface eth1
!---------------------------------
]]></programlisting>
	<para>
here's my
<ulink url="../contrib/rc.zebra">zebra init script</ulink>,
<ulink url="../contrib/rc.ripd">ripd init script</ulink>,
<ulink url="../contrib/rc.bgpd">bgpd init script</ulink>,
<ulink url="../contrib/rc.ospfd">ospfd init script</ulink>.
	</para>
	<para>
Now use the zebra shell (<command>vtysh</command> or <command>telnet localhost zebra</command>)
to install an IP on dummy0 (following the instructions of Cimafranca and Young).
		<note>
		<itemizedlist>
			<listitem>
these instructions will only work if dummy0 is in <filename>zebra.conf</filename>
			</listitem>
			<listitem>
the different prompts for bash, zebra, zebra in "enable" mode, zebra in "configure terminal"
mode, zebra in "configure interface" mode.
			</listitem>
		</itemizedlist>
		</note>
	</para>
	<para>
You can add the IP for dummy0 into <filename>zebra.conf</filename> with an editor
instead. You could also add the IP on bootup, but by adding the information to the
<filename>.conf</filename> file, the IP will only be present after you start up zebra.
	</para>
<programlisting><![CDATA[
director:/etc/zebra# /etc/rc.d/rc.zebra start
director:/etc/zebra# telnet localhost zebra
Trying 127.0.0.1...
Connected to localhost.
Escape character is '^]'.

Hello, this is zebra (version 0.94).
Copyright 1996-2002 Kunihiro Ishiguro.


User Access Verification

Password:
zebra> enable
Password:
zebra# configure terminal
zebra(config)# interface dummy0
zebra(config-if)# ip address 10.0.1.1/24
zebra(config-if)# quit
zebra(config)# write
Configuration saved to /etc/zebra/zebra.conf
zebra(config)# end
zebra# show run

Current configuration:
!
hostname zebra
password zebra
enable password zebra
log file /var/log/zebra.log
!
interface lo
!
interface dummy0
 ip address 10.0.1.1/24
!
interface tunl0
!
interface eth0
!
interface eth1
!
!
line vty
!
end
zebra# quit
Connection closed by foreign host.
director:/etc/zebra# cat zebra.conf
!
! Zebra configuration saved from vty
!   2004/02/24 17:51:02
!
hostname zebra
password zebra
enable password zebra
log file /var/log/zebra.log
!
interface lo
!
interface dummy0
 ip address 10.0.1.1/24
!
interface tunl0
!
interface eth0
!
interface eth1
!
!
line vty
!
]]></programlisting>
	<para>
Next time you start up <command>zebra</command>,
the new <filename>zebra.conf</filename> script will add the IP to dummy0 and the src route
(as if you'd run
<command>ip addr add 10.0.1.1/24 dev dummy0 brd +</command> from the command line).
	</para>
	<para>
Start up zebra on the second director and add an IP to dummy0 there (you can copy
the <filename>zebra.conf</filename> file here to the other director and change the
IP for dummy0).
	</para>
	<para>
Now you're going to start <command>ripd</command>.
Here's my <filename>ripd.conf</filename>
	</para>
<programlisting><![CDATA[
!
! Zebra configuration saved from vty
!   2004/03/01 14:38:03
!
hostname ripd
password zebra
enable password zebra
log file /var/log/ripd.log
!
interface lo
!
interface dummy0
!
interface tunl0
!
interface eth0
!
interface eth1
!
router rip
 network eth0
 network eth1
!
line vty
!
]]></programlisting>
	<para>
Here I add networks to the conf file from the zebra interface (you
could use an editor on the conf file too).
	</para>
<programlisting><![CDATA[
director:/etc/zebra# telnet 0 ripd
Trying 0.0.0.0...
Connected to 0.
Escape character is '^]'.

Hello, this is zebra (version 0.94).
Copyright 1996-2002 Kunihiro Ishiguro.


User Access Verification

Password:
ripd> enable
Password:
ripd# configure terminal
ripd(config)# router rip
ripd(config-router)# network 10.0.1.0/24
ripd(config-router)# network 192.168.1.0/24
ripd(config-router)# write
Configuration saved to /etc/zebra/ripd.conf
ripd(config-router)# show run
ripd(config-router)# show run

Current configuration:
!
hostname ripd
password zebra
enable password zebra
log file /var/log/ripd.log
!
interface lo
!
interface dummy0
!
interface tunl0
!
interface eth0
!
interface eth1
!
router rip
 network 10.0.1.0/24
 network 192.168.1.0/24
 network eth0
 network eth1
!
line vty
!
end
ripd(config-router)#  quit
ripd(config)# exit
ripd# exit
Connection closed by foreign host.
director:/etc/zebra#
]]></programlisting>
	<para>
Here's the <filename>ripd.conf</filename> I used for the demo.
	</para>
<programlisting><![CDATA[
! -*- rip -*-
!
! RIPd sample configuration file
!
! $Id: ripd.conf.sample,v 1.11 1999/02/19 17:28:42 developer Exp $
!
hostname ripd
password zebra
enable password zebra
!
! debug rip events
! debug rip packet
!
router rip
network 0.0.0.0/0
network 192.168.1.0/24
network 192.168.2.0/24
network eth0
network eth1
redistribute kernel
!
!default-information originate
!
log file /var/log/ripd.log
]]></programlisting>
	<para>
Make sure both routers have default routes.
	</para>
<programlisting><![CDATA[
backup:/etc/zebra: ip route add default via 192.168.1.253
active:/etc/zebra: ip route add default via 192.168.1.254
]]></programlisting>
	<para>
Activate debugging in zebra (so you will see notices of
rip updates on the screen) and then show the routes
	</para>
<programlisting><![CDATA[
backup:/etc/zebra# telnet 0 zebra
Trying 0.0.0.0...
Connected to 0.
Escape character is '^]'.

Hello, this is zebra (version 0.94).
Copyright 1996-2002 Kunihiro Ishiguro.


User Access Verification

Password:
zebra> enable
Password:
zebra# debug zebra packet
zebra# show ip route
Codes: K - kernel route, C - connected, S - static, R - RIP, O - OSPF,
       B - BGP, > - selected route, * - FIB route

K>* 0.0.0.0/0 via 192.168.1.253, eth1
R>* 10.0.1.0/24 [120/2] via 192.168.2.1, eth0, 00:07:44
C>* 10.0.2.0/24 is directly connected, dummy0
K * 127.0.0.0/8 is directly connected, lo
C>* 127.0.0.0/8 is directly connected, lo
K * 192.168.1.0/24 is directly connected, eth1
C>* 192.168.1.0/24 is directly connected, eth1
K * 192.168.2.0/24 is directly connected, eth0
C>* 192.168.2.0/24 is directly connected, eth0
]]></programlisting>
	<para>
The output shows that the backup router has a default route added by the kernel
(at the CLI above) and a route to 10.0.1.0 added by RIP,
which enables routing to 10.0.1.1 on the other machine.
(A similar view will be seen
by running <command>ip route show</command> at the CLI.)
The [120/2] indicates the administrative weight of the route [120]
and the number of hops [2].
	</para>
	<para>
Then do the following in order -
	</para>
	<itemizedlist>
		<listitem>
From another window,
remove the default route at the command prompt
(<command>ip route del default via 192.168.1.253</command>)
		</listitem>
		<listitem>
in the zebra window above, up arrow and rerun the
<command>show ip route</command> to show that the default
route has gone.
<programlisting><![CDATA[
zebra# show ip route
Codes: K - kernel route, C - connected, S - static, R - RIP, O - OSPF,
       B - BGP, > - selected route, * - FIB route

R>* 10.0.1.0/24 [120/2] via 192.168.2.1, eth0, 00:18:01
C>* 10.0.2.0/24 is directly connected, dummy0
K * 127.0.0.0/8 is directly connected, lo
C>* 127.0.0.0/8 is directly connected, lo
K * 192.168.1.0/24 is directly connected, eth1
C>* 192.168.1.0/24 is directly connected, eth1
K * 192.168.2.0/24 is directly connected, eth0
C>* 192.168.2.0/24 is directly connected, eth0
]]></programlisting>
		</listitem>
		<listitem>
watch in the zebra window for a RIP update
<programlisting><![CDATA[
zebra# 2004/03/02 21:21:54 ZEBRA: zebra message received [ZEBRA_IPV4_ROUTE_ADD] 14
]]></programlisting>
		</listitem>
		<listitem>
up arrow in the zebra window and rerun the
<command>show ip route</command> to show the new default
route.
<programlisting><![CDATA[
zebra# show ip route
Codes: K - kernel route, C - connected, S - static, R - RIP, O - OSPF,
       B - BGP, > - selected route, * - FIB route

R>* 0.0.0.0/0 [120/2] via 192.168.1.254, eth1, 00:00:03
R>* 10.0.1.0/24 [120/2] via 192.168.2.1, eth0, 00:18:31
C>* 10.0.2.0/24 is directly connected, dummy0
K * 127.0.0.0/8 is directly connected, lo
C>* 127.0.0.0/8 is directly connected, lo
K * 192.168.1.0/24 is directly connected, eth1
C>* 192.168.1.0/24 is directly connected, eth1
K * 192.168.2.0/24 is directly connected, eth0
C>* 192.168.2.0/24 is directly connected, eth0
]]></programlisting>
		</listitem>
	</itemizedlist>
	<para>
The new (x.x.x.254 rather than x.x.x.253) default gw is now installed
and this time it's installed by RIP (rather than the kernel).
Here's the view of the routing as shown from the CLI
	</para>
<programlisting><![CDATA[
backup:/etc/zebra# ip route show
10.0.1.0/24 via 192.168.2.1 dev eth0  proto zebra  metric 2 equalize
192.168.2.0/24 dev eth0  scope link
192.168.2.0/24 dev eth0  proto kernel  scope link  src 192.168.2.253
192.168.1.0/24 dev eth1  scope link
192.168.1.0/24 dev eth1  proto kernel  scope link  src 192.168.1.253
10.0.2.0/24 dev dummy0  proto kernel  scope link  src 10.0.2.253
127.0.0.0/8 dev lo  scope link
default via 192.168.1.254 dev eth1  proto zebra  metric 2 equalize
]]></programlisting>
	<para>
This time the default route is installed by zebra.
	</para>
	<para>
You can time the route failover: At 18:31 (min:sec since executing),
the new route has been up for 00:03 seconds.
The failover occurred at 18:01,
showing that the new route took ((31-3)-1)=27 seconds to appear
after failover.
	</para>
	<para>
The new default gw is the other director's default gw. I had initially
hoped that the new default gw would be an IP on the active director,
and that ICMP redirects would handle re-routing to the active director's default gw.
However this didn't work, although I though it would for a while.
Here's what happened.
	</para>
	<para>
If you activate the line
	</para>
<programlisting><![CDATA[
default-information originate
]]></programlisting>
	<para>
in <filename>ripd.conf</filename> on just the active director,
the active director, having a default route of its own,
will advertise that it is a default route.
If you then do the failover, the default route on the backup
director will be an IP on the active director.
(I thought I was home at this stage.)
Since you want to do this symmetrically,
you activeate the same line to <filename>ripd.conf</filename> on the backup director.
The problem (from talking to Steve Buchanan) is that the backup
director, if it's been told to advertise that it is the default route,
is not going to accept an advertisement from anyone else (like
the active director) declaring that they are the default gw instead.
After activating the option <filename>default-information originate</filename>,
then on failure of the link, the backup master node will
<emphasis role="bold">not</emphasis> accept the RIP update of
a default route and will not show a default route.
	</para>
	<para>
With dynamic routing then, after failover, the default route for the backup
router is the default route of the active router, and not an IP on the active
router.
Functionally these achieve the same result if there are no other
problems with the routing on the backup router.
	</para>
	</section>
	<section id="dynamic_gated" xreflabel="Using gated to dynamically route to two different networks">
	<title>Dynamic routing with gated: An LVS that connects to the outside world through two networks</title>
	<para>
Patrick LeBoutillier <emphasis>patl (at) fusemail (dot) com</emphasis> 26 May 2004 
	</para>
	<para>
Here is a "recipe" for creating LVS clusters with 
machines that support redundant networking.
	</para>
	<para>
Our production environment is fully redundant at the network level 
(each machine has two network interfaces, 
each connected to a different network). 
All machine are connected to both these networks 
and data can come from either network. 
On each machine, service run on a local network address 
and gated announces the route for these networks via both network interface.
My task was to create an LVS cluster of 2 such machines 
(each a potential director and realserver as well).
	</para>
	<para>
The network setup:
	</para>
<programlisting><![CDATA[
Network 1 is 192.168.10.0/24
Network 2 is 192.168.11.0/24

Machine 1:
  - eth0: 192.168.10.1
  - eth1: 192.168.11.1
  - local network on loopback (lo:real): 192.168.20.1/32

Machine 2:
  - eth0: 192.168.10.2
  - eth1: 192.168.11.2
  - local network on loopback (lo:real): 192.168.21.1/32

Virtual IP is 192.168.30.1
]]></programlisting>
	<para>
gated setup:
	</para>
	<para>
Have gated announce (and accept) the following routes:
	</para>
	<itemizedlist>
		<listitem>
			<para>
Machine 1:
			</para>
			<para>
  - announce 192.168.20.1/32
			</para>
			<para>
  - accept routes from 192.168.10.2 and 192.168.11.2
			</para>
		</listitem>
		<listitem>
			<para>
Machine 2:
			</para>
			<para>
  - announce 192.168.21.1/32
			</para>
			<para>
  - accept routes from 192.168.10.1 and 192.168.11.1
			</para>
		</listitem>
	</itemizedlist>
	<para>
These routes will be used by ldirectord to monitor the realservers.
	</para>
	<para>
Recipe
	</para>
	<orderedlist>
		<listitem>
			<para>
Install UltraMonkey as usual, but:
			</para>
			<para>
Make sure to configure ping nodes in both networks.
			</para>
			<note>
A "ping node" is a pingable IP that is used by the heartbeat 
<filename>ipfail</filename> plugin, to determine if a director
has lost network connectivity.
The "ping node" terminology is defined at
<ulink url="http://linux-ha.org/download/GettingStarted.html">
Getting Started with Linux-HA (heartbeat)</ulink>
(http://linux-ha.org/download/GettingStarted.html).
			</note>
			<para>
   - Create the virtual IP alias as 192.168.30.1
			</para>
			<para>
   - A virtual service definition in <filename>ldirectord.cf</filename> 
should look something like this:
			</para>
<programlisting><![CDATA[
     virtual=192.168.30.1:80
             real=192.168.20.1:80 gate
             real=192.168.21.1:80 gate
             service=http
             checkport=80
             request="/test.html"
             receive="test"
             scheduler=rr
             protocol=tcp
]]></programlisting>
			<para>
In a normal setup, heartbeat manages the virtual IP alias and brings it up
on the active director. If I understand correctly, an arp request is then
sent, making the other machines in the local network aware that the active
director is now the machine to be reached for the virtual IP.
			</para>
			<para>
In this setup we will tell heartbeat to leave the virtual IP alias alone
and have it tell gated to announce the route for the 192.168.30.1/32 
network instead. 
Therefore ONLY the active director will announce the routes to 
reach the virtual IP network.
			</para>
		</listitem>
		<listitem>
			<para>
Change your haresources line to something like this:
			</para>
<programlisting><![CDATA[
   node1.cluster.tld gated-toggle ldirectord
]]></programlisting>
		</listitem>
		<listitem>
			<para>
Place the following (or equivalent) code in a file called 
<filename>/etc/ha.d/resource.d/gated-toggle</filename>:
			</para>
<programlisting><![CDATA[
--------8<--------
#!/bin/bash
#
# This gated control script should only be called by heartbeat!
#
# start: RESTART gated with the original (non-director config)
# stop:  RESTART gated with the director config
#

# Source function library.
. /etc/rc.d/init.d/functions

# Source networking configuration.
. /etc/sysconfig/network

# Check that networking is up.
[ ${NETWORKING} = "no" ] && exit 0

gdc=/usr/sbin/gdc
gated=/usr/sbin/gated
prog=gated

if [ ! -f /etc/gated.conf -o ! -f $gdc ] ; then
        action $"Not starting $prog: " true
        exit 0
fi

PATH=$PATH:/usr/bin:/usr/sbin

RETVAL=0

start() {
        echo -n $"Starting $prog: "
        CFG=$1
        if [ "$CFG" != "" ] ; then
                RES='$2$3'                
RE="s/^(\s*\#+)(.*)(\#\s*heartbeat-toggle\s*)$/$RES/"
                /usr/bin/perl -p -e "$RE" /etc/gated.conf > $CFG
                daemon $gated -f $CFG
        else
                daemon $gated
        fi
        RETVAL=$?
        [ $RETVAL -eq 0 ] && touch /var/lock/subsys/gated
        echo
        return $RETVAL
}

stop() {
        # Stop daemons.
        action $"Stopping $prog" $gdc stop
        RETVAL=$?
        if [ $RETVAL -eq 0 ] ; then
                rm -f /var/lock/subsys/gated
        fi
        return $RETVAL
}

# See how we were called.
case "$1" in
  start)
        stop
        start "/etc/gated-heartbeat.conf"
        ;;
  stop)
        stop
        start
        ;;
  *)
        echo $"Usage: $0 {start|stop}"
        exit 1
esac

exit $RETVAL
-------->8--------
]]></programlisting>
			<para>
What this script does is:
			</para>
			<itemizedlist>
				<listitem>
					<para>
On resource acquisition: 
					</para>
					<para>
Copy the gated configuration file (<filename>/etc/gated.conf</filename>)
to another file (<filename>/etc/gated-heartbeat.conf</filename>), 
activate the route for the virtual IP
network and restart gated using the new file.
					</para>
				</listitem>
				<listitem>
					<para>
On resource loss: 
					</para>
					<para>
Restart gated using the original configuration.
					</para>
				</listitem>
			</itemizedlist>
			<para>
			<note>
gated must always be running and must start at boot time using the non-active
(default) config.
			</note>
			</para>
		</listitem>
		<listitem>
			<para>
Modify <filename>/etc/gated.conf</filename> accordingly. 
Here is the <filename>/etc/gated.conf</filename> file 
for machine 1:
			</para>
<programlisting><![CDATA[
--------8<--------
options syslog upto debug;

smux off;
bgp off;
egp off;
ospf off;

rip yes{
  interface all noripin noripout;
  interface eth0 ripin ripout version 2 multicast;
  interface eth1 ripin ripout version 2 multicast;
  trustedgateways 192.168.10.2 192.168.11.2 (...) # other routers in 
the network ;
};


static {
        192.168.20.1 masklen 32 interface 127.0.0.1 preference 0 retain;
        192.168.30.1 masklen 32 interface 127.0.0.1 preference 0 retain;
};

import proto rip{
  all;
};

# On exporte differentes affaires, en concordance avec le mode de 
fonctionnement (prod/releve)
export proto rip{
  proto static{
          host 192.168.20.1 metric 1;
#          host 192.168.30.1 metric 1; # heartbeat-toggle
  };
};
-------->8--------
]]></programlisting>
			<para>
The gated-toggle script will look for all lines ending with "# 
heartbeat-toggle" and turn them
on (or off) depending on the cluster state.
			</para>
		</listitem>
	</orderedlist>
	<para>
I suspect you could do something similar with zebra or 
some other routing software, 
as long you can restart it with a different config or 
(even better) change it's config dynamically 
(maybe you can dynamically change the config for gated, but I'm not 
aware of this).
	</para>
	</section>
	<section id="spanning_tree" xreflabel="spanning tree">
	<title>flapping stemming from convergence time for spanning tree</title>
	<para>
Shaun McCullagh <emphasis>shaun (dot) mccullagh (dot) marviq (dot) com</emphasis> 27 May 2004
	</para>
	<blockquote>
		<para>
I've encountered some flapping problems with Keepalived v1.1.1 (on RH 
Linux 7.3 Kernel 2.4.18-5) when used with  Cisco 2948 and C3548-XL switches.
Both Master and Backup PC's use 3COM 905C NICS. As an experiment I tried 
<command>ifconfig eth2 down</command> on the Backup system  to check it recovered from 
a FAULT state.  The system went into FAULT state as expected, but I when 
I  did <command>ifconfig eth2 up</command>, 
keepalived initially went to Backup state, 
then started oscillating between MASTER and BACKUP state.
		</para>
		<para>
I fixed the problem by increasing the advert_int to 35 seconds (on both 
Master and Backup system). The problem with this is when Keepalived is 
started
the VIPs obviously take much longer to start than if the advert_int is 
set to 5 seconds.
		</para>
		<para>
I'd grateful for suggestions as to what to investigate, as I quite like 
to set the advert_int back to 5 seconds
		</para>
	</blockquote>
	<para>
Graeme Fowler <emphasis>keepalived (at) graemef (dot) net</emphasis> 27 May 2004
	</para>
	<blockquote>
Hard set your switch speed/duplex settings for those ports, and use "mii-tool" 
(assuming it will support your cards) to do the same at the server end.
Cisco switches take up to 30 seconds to complete their autonegotiation - if 
they're hard set, they don't.
	</blockquote>
	<para>
Kjetil Torgrim Homme <emphasis>kjetilho (at) ifi (dot) uio (dot) no</emphasis> 27 May 2004 
	</para>
	<para>
it's not auto-negotiation which takes time, 
it's the spanning tree algorithm. 
It's required to wait for 30 seconds to discover loops in
the topology (nodes will only announce their presence so often).  
You can turn this off, 
with the configuration option <filename>spanning-tree portfast</filename>,
if you're certain the port will never be used to connect to switches. 
	</para>
	<para>
Graeme Fowler <emphasis>keepalived (at) graemef (dot) net</emphasis> 28 May 2004
	</para>
	<blockquote>
		<para>
Whoops! My mistake; indeed it is the spanning tree algorithm. I also ensure 
that I have "spanning-tree portfast" set on interfaces which I know will 
always be connected to hosts rather than switches (or in fact where I know 
that the port may connect to a switch which is not spanning tree capable).
		</para>
		<para>
One point of note though is that I have on occasion been bitten by interfaces 
which continually autonegotiate - whilst connectivity seems OK, the interface 
itself flaps wildly ever few seconds. Hence the comments about hard-setting 
port speeds :)
		</para>
	</blockquote>
	</section>
</section>
<section id="LVS-HOWTO.server_state_sync_demon" xreflabel="Server State Sync Demon">
<title>LVS: Server State Sync Demon, syncd (saving the director's connection state on failover)</title>
	<section id="server_state_sync_demon_intro">
	<title>Intro</title>
	<para>
For seemless director failover, all connection state information from
the failed director should be transferred/available to the new director.
This is a similar problem to backing up a hot database.
This problem had been discussed many times
on the mailing list without any code being produced.
Grabbing the bull by the horns, Ratz and Julian convened the
<ulink url="http://www.linuxvirtualserver.org/LVS-meetings.html">
Bulgarian Summit meeting in March 2001</ulink>
where a design was set for a server state sync demon
(look for links to photos of them working on the design).
	</para>
	</section>
	<section id="server_state_sync_demon_release_notice">
	<title>Release Notice</title>
	<para>
In ipvs-0.9.2 Wensong released a sync demon.
	</para>
	<blockquote>
		<para>
Wensong Zhang <emphasis>wensong (at) gnuchina (dot) org</emphasis> 20 Jun 2001
		</para>
		<para>
The ipvs-0.9.2 tar ball is available on the LVS website. The major change
is new connection sychronization feature.
		</para>
		<para>
Added the feature of connection synchroniztion from the primary
load balancer to the backup load balancers through multicast.
		</para>
		<para>
The ipvs syncmaster daemon is started inside the kernel on the
primary load balancers, and it multicasts the queue of connection
state that need synchronization. The ipvs syncbackup daemon is
started inside the kernel too on the backup load balancers, and it
accepts multicast messages and create corresponding connections.
		</para>
		<para>
Here is simple intructions to use connection synchronization.
		</para>
		<para>
On the primary load balancer, run
		</para>
<programlisting><![CDATA[
primary_director:# ipvsadm --start-daemon=master --mcast-interface=eth0
]]></programlisting>
		<para>
On the backup load balancers, run
		</para>
<programlisting><![CDATA[
backup_director:# ipvsadm --start-daemon=backup --mcast-interface=eth0
]]></programlisting>
		<para>
To stop the daemon, run
		</para>
<programlisting><![CDATA[
director:# ipvsadm --stop-daemon
]]></programlisting>
		<para>
Note that the feature of connection synchronization is under experiment
now, and there is some performance penalty when connection
synchronization, because a highly loaded load balancer may need to multicast
a lot of connection information. If the daemon is not started, the
performance will not be affected.
		</para>
	</blockquote>
	<note>
	<para>
There aren't a lot of people using the server state sync demon yet,
so we don't have much experience with it yet.
	</para>
	</note>
	<blockquote>
		<para>
Alexandre Cassen
<emphasis>alexandre (dot) cassen (at) wanadoo (dot) fr</emphasis> 9 Jul 2001
		</para>
		<para>
Using <command>ipvsadm</command> you start the sync daemon on to the master director.
So it send adverts to the backups servers using multicast: 224.0.0.81.
You need to start <command>ipvsadm</command> sync daemon on the backups servers too...
		</para>
		<para>
The master muliticasts messages to the backup load balancers in the following format.
		</para>
<programlisting><![CDATA[
       0                   1                   2                   3
       0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1
      +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+
      |  Count Conns  |   Reserved    |            Size               |
      +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+
      |                                                               |
      |                    IPVS Sync Connection (1)                   |
      +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+
      |                            .                                  |
      |                            .                                  |
      |                            .                                  |
      +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+
      |                                                               |
      |                    IPVS Sync Connection (n)                   |
      +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+
]]></programlisting>
		<para>
I have planned to add an ICV like in IPSEC-AH 
(with anti-replay and all strong dataexchange format) but I'm still very busy.
		</para>
	</blockquote>
	<para>
There is now a
<ulink url="http://www.linuxvirtualserver.org/docs/sync.html">sync demon write up</ulink>.
	</para>
	<note>
	<para>
From Lars Marowski-Bree <emphasis>lmb (at) suse (dot) de</emphasis>:
	</para>
	<para>
If you're using the <link linkend="scheduler">-sh and -dh schedulers</link>
then there is no state information to transfer ;-)
	</para>
	</note>
	<para>
If you're just setting up and have no connections and are checking
your setup, then the sync demon has no data to transfer and is silent
(<emphasis>i.e.</emphasis> it appears not to be working).
	</para>
	<para>
Sean Knox <emphasis>sean (dot) knox (at) sbcglobal (dot) net</emphasis> 2003-02-21
	</para>
	<blockquote>
	<para>
I've just installed ipvsadm and LVS on a new Debian 3.0 server.
Load balancing works fine, however, connection synchronization
doesn't; I confirmed this via tcpdump (no sync information being
multicast).
	</para>
	<para>
The problem is that the sync. daemon won't transmit unless it actually
has data (connection states) to send out.
If your IPVS state table is empty (<emphasis>i.e.</emphasis> no connections),
then you won't see any sync data being sent out.
I guessed this was the case after seeing
this entry in the kern.log:
	</para>
<programlisting><![CDATA[
kernel: IPVS: Each connection entry needs 120 bytes at least
]]></programlisting>
	</blockquote>
	<para>
combined effort of Sean Know and Bernt Jernberg, 25 Feb 2003
	</para>
	<blockquote>
On the backup director, the connection table is listed by running
<command>ipsvadm -Lcn</command>.
The backup director has no connections,
so <command>ipvsadm -L</command> will be empty
(<command>ipvsadm -L</command> is only relevant on the master).
	</blockquote>
	<para>
Carles Xavier Munyoz Baldo Oct 02, 2003
	</para>
	<blockquote>
		<para>
 I'm setting up a high availability LVS director with RedHat 8.0
 (kernel-2.4.20-20.8), ipvs-1.0.9 and keepalived.
 I'm running LVS with connection synchronisation enabled.
 When the master director faults, the backup director takes its role and all
 stablished connections works without interruption.
 GREAT !!!!! :-)
		</para>
		<para>
 The problem is, what to when the failed master is recovered?
 How may I copy the connection table of the backup director to the master
 director?
		</para>
	</blockquote>
	<para>
Horms <emphasis>horms (at) verge (dot) net (dot) au</emphasis> 03 Oct 2003
	</para>
	<para>
There are various ways to do this, here is the one I would suggest.
	</para>
	<orderedlist>
		<listitem>
			<para>
Read this post and patch by Alexandre Cassen
			</para>
<programlisting><![CDATA[
http://marc.theaimsgroup.com/?l=linux-virtual-server&m=105459391703228&w=2
]]></programlisting>
		</listitem>
		<listitem>
The patch was put into LVS 1.1.X but not 1.0.X
   so if you want that behaviour and you are using
   LVS 1.0.X (i.e. 2.4.X kernel) you will need to
   patch the code yourself.
		</listitem>
		<listitem>
			<para>
 You may want this patch too which fixes a small bug
   in Alexandre's code.
			</para>
<programlisting><![CDATA[
--- ipvs-1.0.10.syncd.orig/ipvs/ip_vs_core.c    2003-07-29
23:37:12.000000000 +0900
+++ ipvs-1.0.10.syncd/ipvs/ip_vs_core.c 2003-09-29 16:02:33.000000000 +0900
@@ -1132,7 +1132,7 @@
        /* increase its packet counter and check if it is needed
           to be synchronized */
        atomic_inc(&cp->in_pkts);
-       if (ip_vs_sync_state == IP_VS_STATE_MASTER &&
+       if (ip_vs_sync_state & IP_VS_STATE_MASTER &&
            (cp->protocol != IPPROTO_TCP ||
             cp->state == IP_VS_S_ESTABLISHED) &&
            (atomic_read(&cp->in_pkts) % 50 == sysctl_ip_vs_sync_threshold))
]]></programlisting>
		</listitem>
	</orderedlist>
	<blockquote>
With this patch, when I bring back the master director, the backup director
will notify it of the new connections but, what happens with the current
connections established in the backup director?
Are they notified to the recovered master director?
When the master directos takes the VIP, this stablished connections will
stop.
	</blockquote>
	<para>
No. If you wait a short time before the master takes over the VIP
then the connections will have been sychronised. Alternatevely
when the old master comes back up make it the stand-by. Presumably
some time will pass before another failover occurs and synchronisation
should have plenty of time to occur. If you are using heartbeat
then this is called nice_failback.
	</para>
	<blockquote>
Is there any way to copy all the connections table from the backup
director to the master director when it gets recovered from a previous
fault?
	</blockquote>
	<para>
No. It would be possible to add some sort of dump request.  But I don't
think this would be wise as if you have a lot of connections this could
take a while and thus impact load balancing - if you have a lot of
connections the linux director is probably already very busy.
	</para>
	</section>
	<section id="server_state_sync_demon_backup_expiry">
	<title> Expiration of Connection in Backup Director </title>
	<para>
ong cheechye Mar 14, 2003
	</para>
	<blockquote>
	<para>
I'm running Piranha over IPVS (ipvs-1.0.4.patch).
	</para>
	<para>
I notice that the connection expire time in the
primary director is much longer than the backup
director's (seen from ipvsadm -lc below). So when
director failover to backup, the connection in backup
director might have already expired and removed. Thus
the connection would not failover.
	</para>
	<para>
Is this the right thing to happen ? How ipvs determine
the expiry time of a connection ?
	</para>
	<itemizedlist>
		<listitem>In Primary Director
<programlisting><![CDATA[
[root@RADIXS root]# ipvsadm -lc
IPVS connection entries
pro expire state       source             virtual
      destination
TCP 14:42  ESTABLISHED 192.168.123.133:32861
vipserver:telnet   application:telnet
]]></programlisting>
		</listitem>
		<listitem>
In Backup Director
<programlisting><![CDATA[
[root@main ong]# ipvsadm -lc
IPVS connection entries
pro expire state       source             virtual
      destination
TCP 02:17  ESTABLISHED 192.168.123.133:32861
vipserver:telnet   application:telnet
]]></programlisting>
		</listitem>
	</itemizedlist>
	</blockquote>
	<para>
Horms
	</para>
	<para>
Ok, this is a little confusing. The expiry values are used in different
ways on the primary and the backup, so it doesn't really matter that
they aren't the same. Essentially what is going to happen
is that even if the connection expires in the backup, as soon
as some more packets arrive on the primary, the connection
will be updated on the backup and it will re-appear in
the backup's connection table.
	</para>
	<para>
Bonnet, Mar 14, 2003
	</para>
	<para>
You missed Ong's point. Imagine the following :
 	</para>
	<orderedlist>
		<listitem>
a telnet connection is established thru primary director
		</listitem>
		<listitem>
connection sync'ed to backup
		</listitem>
		<listitem>
no more telnet packets for a while
		</listitem>
		<listitem>
connection remove from backup (but still on primary)
		</listitem>
		<listitem>
primary failure
		</listitem>
		<listitem>
backup taking over
		</listitem>
		<listitem>
incoming packet for telnet session
		</listitem>
	</orderedlist>
	<para>
Ooops ! The backup director doesn't know this connection, whereas a few
seconds before the primary director did know it !
	</para>
	<para>
Horms
	</para>
	<para>
I guess that I did miss the point.
Of course once the connection times out on the
backup director failover of that connection is not going to work.
This timeout can be modified by changing IP_VS_SYNC_CONN_TIMEOUT
in ip_vs_sync.c. The default is 3 minutes.
	</para>
	<para>
It could be a /proc entry, but it isn't at the moment.
	</para>
	<para>
ong cheechye
	</para>
	<blockquote>
Ok. So connection will not failover if it has been idling
	</blockquote>
	<para>
Horms
	</para>
	<para>
Yes, if the connection has been idling for longer
than the timeout on the backup (3 minutes) it
will not failover.
	</para>
	<para>
Sebastian Vieira <emphasis>sebvieira (at) gmail (dot) com</emphasis> 15 Sep 2006 
	</para>
	<blockquote>
When I do a failover to the other
node <command>ipvsadm -l</command> shows zero connections. 
But client connections _are_ being
sync'd. 
When the original active director was down, 
i could connect through the backup director without any problem.
If i do a failback it shows all connections again.
It's not a big issue since LVS works as it should, but it would be handy
though. Is there something that can be done about this?
	</blockquote>
	<para>
Joe
	</para>
	<para>
I'm not sure what the expected behaviour is here, 
but the syncd only transfers enough information for
the backup director to take over as the active director - 
<emphasis>i.e.</emphasis> only the connection table and the
active connections (connections in FIN_WAIT etc aren't transferred). 
When you go back to the original director, you're probably seeing it's 
original connection count before failover.
	</para>
	<para>
Monty Ree  Jun 04, 2007 
	</para>
	<para>
I have a two director LVS-DR system like below.
	</para>
<programlisting><![CDATA[
LVS1
LVS-DR : linux kernel 2.6.18
web server : linux kernel 2.6.18(apache+php)
loadbalancing : sh(source hashing)
at realserver : just a little FIN_WAIT, TIME_WAIT
apache KeepAlive : on 

LVS2 
LVS-DR : linux kernel 2.6.21
web server : linux kernel 2.6.21(apache+java+php)
loadbalancing : sh(source hashing)
at realserver : lots of FIN_WAIT, TIME_WAIT
apache KeepAlive : on 
]]></programlisting>
	<para>
when I execute like below.
	</para> 
<programlisting><![CDATA[
# ipvsadm -L -n -c

TCP 14:22  ESTABLISHED 221.155.xx.xx:1995   xxx.x.xx.xx:80  xxx.x.xx.xx:80
]]></programlisting>
	<para>
here, 14:22 means expire time, right?
	</para>
	<para>
at LVS1, after some seconds, above packets (connection entry) disappear
but LVS2, doesn not.
	</para>
	<para>
Horms 4 Jun 2007 
	</para>
	<para>
Yes, 14:22 is the expiration time.
	</para>
	<para>
If you are using connection syncrhonisation and LVS1 is the master
and LVS2 is the backup, here is a rough sketch of what is likely
to be going on.
	</para>
	<para>
On LVS1 a connection is established and there is a series
of packets going between the real-server and the end-user
via the master linux-director. During this time the packets
are tracked using a connection entry in the ESTABLISHED state.
This has a time out of 15:00 minutes which is refreshed
each time a packet is received. For the connection
above that would seem to indicate that it has been idle for
38 seconds.
	</para>
	<para>
When the connection is shut down by either the real-server
or the end-user, the connectino entry moves into the CLOSE
state, with a much shorter timeout. If no more packets are
received (which usually the case, typically, there will only be more
packets if some arrive out of order), then the connection entry
disappears pretty quickly.
	</para>
	<para>
So far so good.
	</para>
	<para>
On LVS2 things are a bit different. It doesn't see the packets
sent by the real-server and the end-user. Rather it receives
connection information via the lvs sychronisation protocol.
These are sent out by LVS1. They are sent out once a connection
has seen 3 packets (the 3-way handshake is complete) and then
every 50th packet. There is also a 2s delay loop in there,
but thats not that important. It is this synchronisation information
that produces the entries that you see on LVS2. And they may be a
little out of date. But its not really that important, because
they are just there in case fail-over occurs, so that LVS2
will be able to forward packets for the connections that were
synchronized.
	</para>
	<para>
The precise details of the timeouts and the state of
these synchronised connections is not that important,
because while LVS2 is acting as a backup, they aren't used.
So other than consuming a very small ammount of memory, they
do no harm. And, if failover occurs, then the entries that
are used at that time are updated and follow the rules that
LVS1 was previously following. Just think of them as templates
with a timeout, rather than full fledged connection entries.
	</para>
	</section>
	<section id="synchd_in_sync">
	<title>Syncd boxes must have the same time</title>
	<para>
If the directors are being time updated by ntpdate from cron, rather than ntpd,
then after a power down, they may not be in time synchronisation
and won't accept messages from each other.
	</para>
	<para>
Nicklas
	</para>
	<blockquote>
After a total power outage today I'm having trouble getting the backup LVS
node to function properly. The backup node keeps transitioning to MASTER
state. I'm using keepalived. Things have worked flawless before the power
outage. The two LVS machines are also firewalls with appropriate rules
applied to pass through VRRP messages and such.
	</blockquote>
	<para>
Graeme Fowler <emphasis>graeme (at) graemef (dot) net</emphasis> 06 Nov 2008
	</para>
	<para>
Are you 100% sure the firewall rules or a network misconfiguration
aren't getting in the way?
The most common flaw that causes this is a rule or route on the nominal
master preventing it sending announcements, so the slave keeps
transitioning.
	</para>
	<para>
It's either that, or your system clocks are out of sync with each other.
If you're using ntpdate from cron, that time is
your problem.
	</para>
	<para>
Can you run a local NTP daemon on the directors which is configured
against two upstream time servers and only permits local clock slew?
That's what I do. The daemon approach means the time is slewed slowly,
rather than skewing several tens of seconds at a time.
	</para>
	<para>
Also, make sure the hardware clocks are sufficiently close together on
both systems (hwclock). If not, get the system times close and then do
"hwclock --systohc".
	</para>
	<para>
Joe: we didn't hear back, so we don't know the resolution of this problem.
	</para>
	</section>
	<section id="no_conntrack">
	<title>LVS and syncd do not use conntrack</title>
	<note>
May 2004: ipvs now uses conntrack. see <xref linkend="LVS-HOWTO.filter_rules"/>.
	</note>
	<para>
Horms 22 Oct 2003
	</para>
	<para>
IPVS does not use contrack!
You can examine the state of connections, including
those syncronised to a backup using <command>ipvsadm -L -c -n</command>
	</para>
	<para>
Carles Xavier Munyoz Baldo Oct 22, 2003
	</para>
	<blockquote>
But, which kind of connections will it synchronise?
All the connections passing througt the FORWARD chain or only the connections
directed to the realservers farm?
	</blockquote>
	<para>
All of the connections that have been forwarded to realservers by LVS.
	</para>
	<blockquote>
I'm building a high availability firewall using the ipvs sync daemons to
synchronise the MASTER FW network connections with the BACKUP FW.
Is this possible with ipvs or must I use another high availability software solution
for linux?
	</blockquote>
	<para>
Not really, unless you run all the connections through LVS.
	</para>
	</section>
	<section id="conn_sync" xreflabel="Connection Synchronisation">
	<title>Connection Synchronisation (TCP Fail-Over)</title>
	<para>
Wensong's original implementation of a synch demon would not failback after failover.
This code was modified by Julian so that failover could be followed by failback. 
It was still a master/slave arrangement, 
where the sync demon on the active director 
broadcasts connection table information to the sync demon on the backup director.
	</para>
	<para>
However if you have and ipvsadm hash table on all directors
(<emphasis>i.e.</emphasis> have the virtual services setup on all directors
with <command>ipvsadm</command>) including the backup directors, 
then it's possible to have an LVS where each director is broadcasting
the connections information for the virtual services it is handling 
and receiving connection data from the other
directors for the virtual services they are handling, 
then you have a peer-to-peer (p2p) synch demon.
	</para>
	<note>
For the synch demon, you only need to keep track of the 
connections in ESTABLISHED state.
The connections in TIME_WAIT etc, will disappear on their own
and you don't need to the other directors to take over a TIME_WAIT
state on failover.
	</note>
	<para>
If you can  arrange for all directors to have the same ipvsadm
hash table, and for some other mechanism to all directors to have
the same (arping) VIP, then you have a fully failover proof 
set of p2p directors. 
	</para>
	<para>
For detailed discussion on the design of such a <command>synchd</command> see 
Horms paper on <ulink url="http://www.ultramonkey.org/papers/conn_sync/">
Connection Synchronisation (TCP Fail-Over)</ulink>.
Horms combines this with <xref linkend="active_active"/> where
all directors are active.
	</para>
	<para>
Horms has virtualised the synchd function of LVS, by writing hooks
into LVS, which allows a synchd to be loaded as a module. Horms
has rewritten Wensong's implementation as a module and his p2p code
as a module and moved the user space controls into ipvsadm.
In principle then, anyone can write a synchd module and register
it with ipvs.
	</para>
	<para>
Unfortunately this code has not been accepted into LVS and is being maintained
separately by Horms. 
This is a bit of a nightmare to maintain and track with each version 
of LVS, so if you're going to use Horms code, be prepared for patching
and spelunking kernel code.
	</para>
	<para>
Horms <emphasis>horms (at) verge (dot) net (dot) au</emphasis> 28 Apr 2004
	</para>
	<blockquote>
		<para>
In 2.6 the code has been enhanced by Julian to allow a peer-to-peer setup.
The current 2.6 code allows you to run a a master or a backup sync
daemon. If you want p2p then you just run both - previously you could
only run one or the other. This is configured through ipvsadm.
		</para>
		<para>
For 2.4, I think Julian has the main patch on his web site.
However there was a minor patch contributed by me, that
is required for his patch to work. I am not sure if he incorporated
that. It is in the mailing list archive.
		</para>
		<para>
I abstracted the
sync deamon, which involved moving a bunch of code around
and adding an extra layer. This did not change the functionality
of the sync daemon at all. 
I modified the LVS core code, so that the sync code is
implemented by a series of hooks. The idea is that people
could implement these hooks however they liked. This could
be done in a kernel module that registered itself with LVS
when it is inserted into the kernel, or instructed to do
so from userspace.
		</para>
		<para>
Then I implemented a version of these hooks that implemented
Wensong's synch demon. These are registered when LVS is intialised.
So you get the existing behaviour.
		</para>
		<para>
Then I implemented another module to handle synchronisation differently.
It communicates with a user space daemon. When you insert this module
it registers itself as the sync hooks, unregistering
the default hooks. The reverse is true when your remove the module.
This is explained at some length here.
<ulink url="http://www.ultramonkey.org/papers/conn_sync/conn_sync.shtml#implementation">
Implementation of Connection Synchronisation</ulink>
		</para>
		<para>
Using it is explained in the man page.
To start the sync daemon you run
		</para>
<programlisting><![CDATA[
ipvsadm --start-daemon master
or 
ipvsadm --start-daemon backup
]]></programlisting>
		<para>
depending on if you want a master or backup sync daemon.
Using Julian's patches you run both on each node to
get the p2p behaviour.
		</para>
		<para>
To stop the sync daemon run
		</para>
<programlisting><![CDATA[
ipvsadm --stop-daemon
]]></programlisting>
		<para>
horms 24 Apr 2007
		</para>
		<para>
LVSSyncDaemonSwap is a script and its function is decribed in the
comment at the top of it.
		</para>
		<para>
Breifly. Prior to 2.4.27 only the master or backup sync daemon could
run but not both. 
So when a failover occurs the new active noce needs to stop
the backup sync deamon and start the master one. The reverse
action needs to occur when a node is running as standby. The purpose
of LVSSyncDaemonSwap is to make this switch.
If you have a newer kernel, just run both daemons on boot.
Incidently, the sync deamon doesn't have a way to flush connections,
so I recommend setting autofailback to off.
		</para>
		<para>
As of 2.4.27 the master and backup sync daemons can run simultaniously,
which is recommended, and thus if you have a newer kernel you don't need
LVSSyncDaemonSwap at all.
		</para>
		<para>
Graeme Fowler <emphasis>graeme (at) graemef (dot) net</emphasis> 09 Jun 2007
		</para>
		<para>
Look at your process list and check that you have two processes running:
		</para>
<programlisting><![CDATA[
ipvs_syncmaster
ipvs_syncbackup
]]></programlisting>
		<para>
If you do, you don't need LVSSyncDaemonSwap.
		</para>
		<para>
(back to Horms)
		</para>
		<para>
On my extremely long, and ever expanding my todo list I plan to put up my patches. 
I have made a start by updating them and getting them all together in my workspace. 
One of the problems is that the patches tend to conflict with each
other, or rely on each other (thankfully not both).
		</para>
		<para>
I quite like Rusty's kernel patches page I might go for something like
that. But to be honest, I fear the support burden. 
The patches that I have made available in the past
have resulted in much work for me.
Usually I just send my patches to the mailing list and forget about
them. But in the case of some of the more substantial work I have done,
they can be found at:
		</para>
<programlisting><![CDATA[
http://www.ultramonkey.org/papers/ and
http://www.ultramonkey.org/download/

In particular:

http://www.ultramonkey.org/papers/conn_sync/
http://www.ultramonkey.org/download/conn_sync/
http://www.ultramonkey.org/papers/active_active/
http://www.ultramonkey.org/download/active_active/
]]></programlisting>
		<para>
Julian's code resolves most of the major problems that I saw in the
original (current default 2.4) synchronsiation code. So, form a user
point of view, since his code is in the ipvs package, it should be easier to setup.
		</para>
		<para>
My user-space daemon is called <filename>ip_vs_user_sync_simple</filename>.
As the name suggests, the code is quite simple,
hopefully people can extend and customise it.
You can find it in http://www.ultramonkey.org/download/conn_sync/
Saru and the sync demon are independant code, but you should have a synch
demon if you're using multiple directors.
		</para>
	</blockquote>
	<para>
There are several different development branches of the syncd.
Here Horms is trying to get me straight on who wrote what, and
which functionality is in which branch.
	</para>
	<para>
Horms 27 May 2004
	</para>
	<blockquote>
		<para>
Wensong's implementation is in the kernel. So everyone who has a recent
(since 2001) version of LVS has it. 
		</para>
		<para>
Alexandre wrote some patches (independantly of me) that address most of
my concerns.  This
code, has to the best of my knowledge, been put into IPVS in the 2.6
kernel. Though as of which version I am not sure, possibly 2.6.0. The
patches, however, have not been merged into 2.4. 
		</para>
		<para>
There are two patches from Alexandre, I will address each of
them in turn. Though I have used neither of them extensively. I
believe both of these patches apply against the kernel. Which means 
Wensong's implementaiton of the synchronisation code.
		</para>
		<itemizedlist>
			<listitem>
				<para>
linux-2.4.26-ipvs_syncd.patch.gz  
     (This has been merged into 2.6.something)
				</para>
				<para>
     This adds two features
				</para>
				<itemizedlist>
					<listitem>
      You can run a master and backup sync daemon on the same host.
       This means that if you have two (or more) linux directors
       they can act as a master and bakckup. That is they can both
       send and recieve synchonisation traffic - though typically
       one machine will only do one of these at a time. This
       means that regardless of which machine is the active linux
       director connections will be synchronied and if a failover
       occurs those connections can continue. This addresses the problem
       that I discuss here (amongst other places)
       http://www.ultramonkey.org/papers/conn_sync/conn_sync.shtml#master_slave_problem
					</listitem>
					<listitem>
     It adds a SyncID field to the packet. This allows
       multiple LVS clusters to use synchonisation on the same
       multicast UDP port. Just set each cluster with a different
       SyncID and it will ignore packets whose SyncID doesn't match.
					</listitem>
				</itemizedlist>
			</listitem>
			<listitem>
				<para>
linux-2.6.4-ipvs_syncd_icv.patch.gz
    (This is only available for 2.6, presumably it relies
     on the patch above, which is in 2.6)
				</para>
				<para>
     This patch allows the synchronisation packets to be signed.
      At a quick glance, this is done using an HMAC digest and a
      shared secret. This should be both secure and fast.
      (Actually I have done the same thing but am not able to
      release the code).
				</para>
				<para>
      This protects against parties unknown injecting packets and
      possibly causing havoc on in the connection tables. This is
      pretty imporant if your linux directors will accept sync
      packets from parties unknown. Keeping in mind that UDP
      can be pretty easy to spoof, using packet filters
      to guard against this can be problematic (though not impossible).
				</para>
				<para>
      N.B: I didn't actually read Alexandre's paper, but as I mentioned
      I have implemented almost the same thing. So I am quite
      familiar with the concepts. 
				</para>
			</listitem>
		</itemizedlist>
		<para>
The stem code which you should patch is in the lvs tree, which means in the kernel.
The 2.6 code is a bit more advanced than the 2.4 code. Because it
has the first of Alexandre's patches, and possibly the second,
I have not checked.
		</para>
		<para>
The two main lots of patches are from Alexandre (discussed immediately above)
and mine (further up the page).
My patches move a lot of the code to user-space.
However, they are quite invasive, and probably not a whole lot better
than using the core code with Alexandre's patches if you
just want a functional syncd. If you 
want to hack then my approach should be better, as you can do
a lot of the work in userspace. 
		</para>
	</blockquote>
	<para>
"dingji" <emphasis>dingji (at) broadeasy (dot) com</emphasis> 2005-02-03 
	</para>
	<blockquote>
		<para>
according to Manual-8 there should be three files to configure the sync-daemon
		</para>
<programlisting><![CDATA[
/proc/sys/net/ipv4/vs/sync_msg_max_size 
/proc/sys/net/ipv4/vs/sync_frequency 
/proc/sys/net/ipv4/vs/sync_threshold 
]]></programlisting>
		<para>
but I can only find the last one on my system. 
according to Connection Synchronisation by Horms, there seems a patch for this.
but what's the difference between ip_vs_user_sync_simple and sync-daemon within ipvsadm.
and why it seemed to work without the two files, were they set the default values?
		</para>
	</blockquote>
	<para>
Peter Mueller
	</para>
	<para>
<ulink url="http://www.ultramonkey.org/papers/conn_sync/conn_sync.shtml">conn_sync</ulink>
(http://www.ultramonkey.org/papers/conn_sync/conn_sync.shtml),
and a more in-depth example of HOWTO-doit:
<ulink url="http://www.ultramonkey.org/papers/lvs_jan_2004/stuff/lvs_jan_2004.pdf">lvs_jan_2004.pdf</ulink>
(http://www.ultramonkey.org/papers/lvs_jan_2004/stuff/lvs_jan_2004.pdf).
	</para>
	<para>
Horms 04 Feb 2005 
	</para>
	<para>
<filename>ip_vs_user_sync_simple</filename> is userspace;
the <command>ipvsadm</command> controlled daemon is in the kernel.
I had worked on the synchonisation code
for a customer, and we decided to make a userspace daemon
to match up with some requirements for that customer. In a nutshell,
its easier to write user-space code than kernel code. It also
addressed a number of concerns I had with the in-kernel code
at the time. However, the kernel code problems have all been fixed now.
So unless you desparately want to do some hacking, the
in-kernel, ipvsadm-controlled daemon is my recomendation.
	</para>
	<para>
Sebastian Vieira <emphasis>sebvieira (at) gmail (dot) com</emphasis>
	</para>
	<blockquote>
I've noticed that upon a failover, not all connections are sync'd (via
syncdaemons) to the backup director. I read in the docs for ultramonkey (not
using it ... I think ... but that was the only source I could find)
something about <filename>/proc/sys/net/ipv4/vs/sync_threshold</filename> 
and how to manipulate
this. If I understand things correctly, <filename>sync_threshold has 2 values</filename>. 
By default they are 3 and 50, meaning that after 3 packets the connection will
be initially synchronised. After that, each 50 sent packets will cause the
connection to be synchronised. That is, if i understand it correctly :)
	</blockquote>
	<para>
Ratz 10 Nov 2006 
	</para>
	<para>
I think this is a sound understanding of the mechanism.
	</para>
	<blockquote>
Now I recall reading somewhere that there is a certain timeout involved. I
mean that if no packets are sent for a certain time, the connection will not
be synchronised. I don't know if this is true, but this could be the reason.
	</blockquote>
	<para>
Yes, the "templates" are sent once but within the interval specified.
	</para>
	</section>
	<section id="synchd_broadcast">
	<title>The synchd produces broadcast traffic</title>
	<para>
If the synchd sends its traffic over the RIP network and it's been a while
since you set the LVS up, you might forget that it sends broadcasts.
	</para>
	<para>
Dan Brown <emphasis>danb (at) zu (dot) com</emphasis> 19 Apr 2006
	</para>
	<blockquote>
		<para>
I've been watching errant traffic via tcpdump trying to track some unrelated
problems and have noticed there is a lot of broadcast traffic coming from
the active director.
The traffic all looks like this:
		</para>

<programlisting><![CDATA[
09:13:04.016297 IP 216.94.150.8.32848 > 224.0.0.81.8848: UDP, length 28
]]></programlisting>
		<para>
According to some archive posts, this is how Apache session information is
shared.  I haven't dug deeper into the tcp traffic to figure out if this is
true.  
These broadcasts occur every 2-6 seconds and aren't on a consistent
schedule.  I have a dedicated set of interfaces for heartbeat information
(which I thought also shared the session information) and it looks like
this:
		</para>

<programlisting><![CDATA[
]]></programlisting>
09:38:14.093733 IP 10.0.0.1.32847 > 10.0.0.2.ha-cluster: UDP, length 159
09:38:14.319831 IP 10.0.0.2.32807 > 10.0.0.1.ha-cluster: UDP, length 158
09:38:15.095778 IP 10.0.0.1.32847 > 10.0.0.2.ha-cluster: UDP, length 159
09:38:15.317917 IP 10.0.0.2.32807 > 10.0.0.1.ha-cluster: UDP, length 158
		<para>
I get a pair of broadcasts once per second.  I expect this as it is
configured that way.
The broadcast info to 224.0.0.81.8848 is not configured in <filename>ha.cf</filename>, and
neither director has mcast settings on any device.
So what is the information being broadcast on the external internet device?
I shouldn't be seeing _ANY_ broadcast packets over the external interface as
far as I'm concerned.  
		</para>
	</blockquote>
	<para>
Graeme Fowler <emphasis>graeme (at) graemef (dot) net</emphasis>
	</para>
	<para>
This is the LVS synchronisation daemon pushing state information from
the master to the backup director (and it is in fact multicast, not
broadcast, see http://www.iana.org/assignments/multicast-addresses).
	</para>
	<para>
You should have an ipvs_syncmaster process on your master, and an
ipvs_syncbackup process on the backup. This gives you the stateful
failover which is so desirable upon director failure.
	</para>
	<para>
It is possible to put this traffic onto a separate interface (like your
heartbeat network) to save it being sent out to all the machines on the
frontend network, but how that's configured depends on which application
you use you manage your LVS.
	</para>
	<itemizedlist>
		<listitem>
ipvsadm: --mcast-interface interface
		</listitem>
		<listitem>
keepalived: lvs_sync_daemon_interface option in the VRRP instance section
		</listitem>
		<listitem>
ldirectord: seems not to have the option in the CVS version I'm looking
at (Id: ldirectord,v 1.136 2006/04/05 02:12:24 horms) but can be driven
alongside ipvsadm anyway quite happily, providing you don't stomp on the
functionality provided by ldirectord.
		</listitem>
	</itemizedlist>
	<para>
Horms 25 Aug 2006
	</para>
	<para>
The data is completely unsecured. Anyone who joins the multicast
group (opens a socket) can get the packets. Though they probably
aren't that interesting. What is intersting is that they can also
inject packets, to say flood the connection table with entries.
I've never crafted an attack, but I'm pretty sure the scope is ample.
	</para>
	<para>
I worked on some code a few years ago to move part of the
synchronisation into user-space, and secure it using a signature
and a shared secret. Now that crypto-api is in the kernel (and has
been for years) it should be easy enough to move this code into
the kernel, which is a less invasive change.
	</para>
	<para>
I wonder if there is any interest in this, as there certainly
wasn't when I worked on it before.
	</para>
	</section>
	<section id="server_state_sync_demon_mailing_list">
	<title>from the mailing list</title>
	<para>
Dave Augustus <emphasis>davea (at) support (dot) kcm (dot) org</emphasis>
14 Nov 2002
	</para>
	<blockquote>
		<para>
We are currently building an LVS and are close to deployment. All
machines have 2 nics- 1 public and 1 private. I want to use the private
for the connection sync daemon.
		</para>
		<itemizedlist>
			<listitem>
2 directors: master and backup
			</listitem>
			<listitem>
4 realservers
			</listitem>
		</itemizedlist>
		<para>
All directors and realservers using same kernel: 2.4.19,
ipvsadm v1.21 2002/07/09 (compiled with popt and IPVS v1.0.6).
		</para>
		<para>
When I specify on Master Director:
		</para>
<programlisting><![CDATA[
--start-daemon=master --mcast-interface=eth1
]]></programlisting>
		<para>
and on the backup Director:
		</para>
<programlisting><![CDATA[
--start-daemon=backup --mcast-interface=eth1
]]></programlisting>
		<para>
No connection information is available on the backup using these
settings. Also, my message log for the Master Director lists:
"kernel: IPVS: ip_vs_send_async error."
However, when I change the mcast-interface to eth0, the connection sync
works fine and no errors are reported.
		</para>
		<para>
	...
		</para>
		<para>
Now for my belated reply( I just deployed an 8 server LVS):
The workaround I came up was simply dropping the --mcast statement
altogether. The traffic now is handled on the eth0 interface by default.
I didn't want to do it this way. The bug seemed to crop up whenever I
specified ANY interface..
		</para>
	</blockquote>
	<para>
<emphasis>tuliol (at) sybatech (dot) com</emphasis> Jun 20, 2004 
	</para>
	<blockquote>
		<para>
Currently I have connection synchronization working between directors.  The 
setup is configured by manually running the commands:
		</para>
ipvsadm --start-daemon master #Master Linux director
ipvsadm --start-daemon backup #Slave Linux director
		<para> 
My question is: Is there a way to automatically start those 2 processes by 
putting a setting in the ldirectord config file or somewhere else?
		</para>
	</blockquote>
	<para>
Horms
	</para>
	<para>
Ldirectord is one option. However it only really makes sense if
you are running it as a stand alone daemon, as you want the
synchronisation daemons running all the time.
If you are using something like heartbeat to start and stop ldirectord,
then you don't want the synchronisation daemons handled there,
else the synchronisation daemon won't run when the ldirectord
resource is relinqushed on a node, and this really isn't what you want.
<command>ipvsadm</command> has an init script, You should be able to use that
to start and stop the daemons. 
	</para>
	<blockquote>
		<para>
Well here's what I am going to be doing in my next cluster going live
very soon now (sm). If anyone sees anything silly please let me know.
Note that if you copy my config you will have to change
<filename>/etc/ha.d/update</filename>'s SSH line to the proper host, 
and reverse it for the backup host. 
You will also probably want an ssh-public key login setup,
although I'm not certain I'm going to do this.
		</para>
<programlisting><![CDATA[
</etc/ha.d/resource.d/lvsstate.sh>
#!/bin/sh
# script to set the sync state properly on both LVS servers.

case "$1" in
  start)
    /sbin/ipvsadm --stop-daemon
    /sbin/ipvsadm --start-daemon master
  ;;
  stop)
    /sbin/ipvsadm --stop-daemon
    /sbin/ipvsadm --start-daemon backup
  ;;
esac

exit 0

</etc/ha.d/haresources>
IPaddr::ip.goes.here.here \
...
ldirectord::ldirectord.cf \
lvsstate.sh

</etc/ha.d/update>
#!/bin/sh
# script for updating ldirectord nicely.  created 06/05/2001 PM

# first, backup ldirectord.cf in case someone messes up later.
cp -f /etc/ha.d/conf/ldirectord.cf
/etc/ha.d/conf/backup.of.ldirectord.cf

# next, scp the ldirectord.cf file over to the other director
# the two LVS servers will have to have public-key acceptance for this to work.
scp /etc/ha.d/conf/ldirectord.cf lvs2-priv:/etc/ha.d/conf/.

# make sure the state is set properly for the active server
ssh rwclvs2-priv /etc/ha.d/lvsstate.sh stop
/etc/ha.d/lvsstate.sh start

# reload ldirectord
killall -HUP ldirectord

# give it a few seconds to allow the config to set
sleep 10

# now display configuration
ipvsadm -L
ipvsadm -L --daemon
]]></programlisting>
	</blockquote>
	<para>
James Bromberger <emphasis>jbromberger (at) fotango (dot) com</emphasis>
	</para>
	<para>
we run ldirectord on both master and standby hosts ALL the time. 
We also run <command>ipvsadm --start-daemon master</command> and 
<command>ipvsadm --start-daemon backup</command> on BOTH hosts all the time (2.6 
kernel). The ONLY thing that heartbeat is doing is bringing the service 
IP addresses up and down. That way ldirectord doesn't need 10 seconds 
or so to check services before they come into service: everything is 
instant. Maybe this is wrong, but it works really well. Our failover 
time is less than half a second, and all state is retained. Fail back 
can happen immediately as well.
	</para>
	<para>
unknown: who asked about the changes needed to the heartbeat
scripts for syncd
	</para>
	<para>
Peter Mueller <emphasis>pmueller (at) sidestep (dot) com</emphasis> 29 Nov 2004
	</para>
	<para>
I am using a very simple script for this purpose, 
called through heartbeat/haresources. The quick summary seems to
be go with a solution similar to mine for 2.4, and use a "slave and master on
both servers" solution for 2.6 kernels. 
See the 
<ulink url="http://marc.theaimsgroup.com/?l=linux-virtual-server&amp;m=108924839319403&amp;w=2">
full thread</ulink>
(http://marc.theaimsgroup.com/?l=linux-virtual-server&amp;m=108924839319403&amp;w=2)
for all the details.
	</para>
	<para>
Joe - which I think refers to this
	</para>
	<para>
Well here's what I am going to be doing in my next cluster going live
very soon now (sm).  If anyone sees anything silly please let me know.
Note that if you copy my config you will have to change
/etc/ha.d/update's SSH line to the proper host, and reverse it for the
backup host.  You will also probably want an ssh-public key login setup,
although I'm not certain I'm going to do this.
	</para>
<programlisting><![CDATA[
</etc/ha.d/resource.d/lvsstate.sh>
#!/bin/sh
# script to set the sync state properly on both LVS servers.

case "$1" in
  start)
    /sbin/ipvsadm --stop-daemon
    /sbin/ipvsadm --start-daemon master
  ;;
  stop)
    /sbin/ipvsadm --stop-daemon
    /sbin/ipvsadm --start-daemon backup
  ;;
esac

exit 0

</etc/ha.d/haresources>
IPaddr::ip.goes.here.here \
...
ldirectord::ldirectord.cf \
lvsstate.sh

</etc/ha.d/update>
#!/bin/sh
# script for updating ldirectord nicely.  created 06/05/2001 PM

# first, backup ldirectord.cf in case someone messes up later.
cp -f /etc/ha.d/conf/ldirectord.cf
/etc/ha.d/conf/backup.of.ldirectord.cf

# next, scp the ldirectord.cf file over to the other director
# the two LVS servers will have to have public-key acceptance for this
to work.
scp /etc/ha.d/conf/ldirectord.cf lvs2-priv:/etc/ha.d/conf/.

# make sure the state is set properly for the active server
ssh rwclvs2-priv /etc/ha.d/lvsstate.sh stop
/etc/ha.d/lvsstate.sh start

# reload ldirectord
killall -HUP ldirectord

# give it a few seconds to allow the config to set
sleep 10

# now display configuration
ipvsadm -L
ipvsadm -L --daemon
]]></programlisting>
	<para>
Sebastiaan Veldhuisen Jun 03, 2005
	</para>
	<blockquote>
		<para> 
 we just implemented a 2nd director for our HA LVS environment and we 
 want to do connection synchronization between the master and the backup 
 director through ipvsadm
		</para>
		<para>
 1) Should the backup server list connections its received?
		</para>
	</blockquote>
	<para>
Horms
	</para>
	<para>
No
	</para>
	<blockquote>
 2) If not, how do I verify that it's updated its internal tables?
	</blockquote>
	<para>
<command>ipvsadm -L -c -n</command>. 
The connections will show up in the connection table
in the Established state.
	</para>
	<blockquote>
3) Does it work if I always run both a master and a slave sync daemon at 
the same time on both directors, even if ipvsadm is only running on the 
master?
	</blockquote>
	<para>
In more recent versions of the kernel, yes.
	</para>
	</section>
	<section id="mixed_32_64_bit_syncd">
	<title>Bug (fixed) in syncd: mixed endianness on directors</title>
	<para>
Hopefully this is in the standard ipvs release now. Although Justin says that
this is an endianness problem, it appears to be a 32/64 bit problem.
	</para>
	<para>
Justin Ossevoort <emphasis>justin (at) snt (dot) utwente (dot) nl</emphasis> 30 Sep 2004
	</para>
	<para>
There was a small bug in the ip_vs_sync.c code that made it impossible
for 2 servers of different endian to sync with each other 
(<emphasis>e.g.</emphasis> a sparc (big endian) and a i386 (little endian) based system). 
The problem was in the message size. All other data seems to be correctly rearranged to
network byte order except for this one (probably because the size is
used from the moment the data is being gathered to the moment it is send).
  This caused "IPVS: bogus message" messages in my dmesg.
	</para>
	<para>
This patch fixes this problem by converting the m->size at the last
moment before sending it to network byte order. And changing it back to
host order right before the message is processed. The patch is made
agains the Linux kernel version 2.6.8.1.
	</para>
<programlisting><![CDATA[
--- linux-2.6.8.1/net/ipv4/ipvs/ip_vs_sync.c    2004-08-14
12:54:46.000000000 +0200
+++ linux-2.6.8.1-fix/net/ipv4/ipvs/ip_vs_sync.c    2004-09-30
11:54:53.000000000 +0200
@@ -16,6 +16,7 @@
   *    Alexandre Cassen    :    Added master & backup support at a time.
   *    Alexandre Cassen    :    Added SyncID support for incoming sync
   *                    messages filtering.
+ *    Justin Ossevoort    :    Fix endian problem on sync message size.
   */

  #include <linux/module.h>
@@ -279,6 +280,9 @@
      char *p;
      int i;

+    /* Convert size back to host byte order */
+    m->size = ntohs(m->size);
+
      if (buflen != m->size) {
          IP_VS_ERR("bogus message\n");
          return;
@@ -569,6 +573,23 @@
      return len;
  }

+static void
+ip_vs_send_sync_msg(struct socket *sock, struct ip_vs_sync_buff *sb)
+{
+    int msize;
+    struct ip_vs_sync_mesg *m;
+
+    m = sb->mesg;
+    msize = m->size;
+
+    /* Put size in network byte order */
+    m->size = htons(m->size);
+
+    if (ip_vs_send_async(sock, (char *)m, msize) != msize)
+        IP_VS_ERR("ip_vs_send_async error\n");
+
+    ip_vs_sync_buff_release(sb);
+}

  static int
  ip_vs_receive(struct socket *sock, char *buffer, const size_t buflen)
@@ -605,7 +626,6 @@
  {
      struct socket *sock;
      struct ip_vs_sync_buff *sb;
-    struct ip_vs_sync_mesg *m;

      /* create the sending multicast socket */
      sock = make_send_sock();
@@ -618,20 +638,12 @@

      for (;;) {
          while ((sb=sb_dequeue())) {
-            m = sb->mesg;
-            if (ip_vs_send_async(sock, (char *)m,
-                         m->size) != m->size)
-                IP_VS_ERR("ip_vs_send_async error\n");
-            ip_vs_sync_buff_release(sb);
+            ip_vs_send_sync_msg(sock, sb);
          }

          /* check if entries stay in curr_sb for 2 seconds */
          if ((sb = get_curr_sync_buff(2*HZ))) {
-            m = sb->mesg;
-            if (ip_vs_send_async(sock, (char *)m,
-                         m->size) != m->size)
-                IP_VS_ERR("ip_vs_send_async error\n");
-            ip_vs_sync_buff_release(sb);
+            ip_vs_send_sync_msg(sock, sb);
          }

          if (stop_master_sync)
]]></programlisting>
	<para>
Special credit goes to: Byte Internetdiensten (my current employer) for
supplying the testbed that triggered this bug and the time sponsored to
fix it.
	</para>

<programlisting><![CDATA[
--Boundary_(ID_ibHwHyEMlHthCV5bMNxEug)
Content-type: text/plain; name="fix-ipvs_sync-endian.diff"
Content-disposition: inline; filename="fix-ipvs_sync-endian.diff"
Content-transfer-encoding: 7bit

--- linux-2.6.8.1/net/ipv4/ipvs/ip_vs_sync.c	2004-08-14 12:54:46.000000000 +0200
+++ linux-2.6.8.1-fix/net/ipv4/ipvs/ip_vs_sync.c	2004-09-30 11:54:53.000000000 +0200
@@ -16,6 +16,7 @@
  *	Alexandre Cassen	:	Added master & backup support at a time.
  *	Alexandre Cassen	:	Added SyncID support for incoming sync
  *					messages filtering.
+ *	Justin Ossevoort	:	Fix endian problem on sync message size.
  */
 
 #include <linux/module.h>
@@ -279,6 +280,9 @@
 	char *p;
 	int i;
 
+	/* Convert size back to host byte order */
+	m->size = ntohs(m->size);
+
 	if (buflen != m->size) {
 		IP_VS_ERR("bogus message\n");
 		return;
@@ -569,6 +573,23 @@
 	return len;
 }
 
+static void
+ip_vs_send_sync_msg(struct socket *sock, struct ip_vs_sync_buff *sb)
+{
+	int msize;
+	struct ip_vs_sync_mesg *m;
+
+	m = sb->mesg;
+	msize = m->size;
+
+	/* Put size in network byte order */
+	m->size = htons(m->size);
+
+	if (ip_vs_send_async(sock, (char *)m, msize) != msize)
+		IP_VS_ERR("ip_vs_send_async error\n");
+	
+	ip_vs_sync_buff_release(sb);
+}
 
 static int
 ip_vs_receive(struct socket *sock, char *buffer, const size_t buflen)
@@ -605,7 +626,6 @@
 {
 	struct socket *sock;
 	struct ip_vs_sync_buff *sb;
-	struct ip_vs_sync_mesg *m;
 
 	/* create the sending multicast socket */
 	sock = make_send_sock();
@@ -618,20 +638,12 @@
 
 	for (;;) {
 		while ((sb=sb_dequeue())) {
-			m = sb->mesg;
-			if (ip_vs_send_async(sock, (char *)m,
-					     m->size) != m->size)
-				IP_VS_ERR("ip_vs_send_async error\n");
-			ip_vs_sync_buff_release(sb);
+			ip_vs_send_sync_msg(sock, sb);
 		}
 
 		/* check if entries stay in curr_sb for 2 seconds */
 		if ((sb = get_curr_sync_buff(2*HZ))) {
-			m = sb->mesg;
-			if (ip_vs_send_async(sock, (char *)m,
-					     m->size) != m->size)
-				IP_VS_ERR("ip_vs_send_async error\n");
-			ip_vs_sync_buff_release(sb);
+			ip_vs_send_sync_msg(sock, sb);
 		}
 
 		if (stop_master_sync)

]]></programlisting>
	</section>
</section>
<section id="LVS-HOWTO.realserver_failure" xreflabel="realserver failure">
<title>LVS: Realserver failure handled by Mon</title>
	<section id="realserver_failover_mon_intro">
	<title>Introduction</title>
	<para>
Don't even think about doing this till you've got your LVS working properly.
If you want the LVS to survive a server or director failure, you
can add software to do this after you have the LVS working.
For production systems, failover may be useful or required.
			</para><para>
An agent external to the ipvs code on the director is used to monitor the services.
LVS itself can't monitor the services as LVS is just a packet switcher.
If a realserver fails, the director doesn't get the failure, the client does.
For the standard LVS-Tun and LVS-DR setups (ie receiving packets by an ethernet
device and not by TP), the reply
packets from the realserver go to its default gw and don't go through the director,
so the LVS can't detect failure even if it wants to.
For some of the mailings concerning why
the LVS does not monitor itself and why an external agent (eg mon) is used
instead, see the postings on <link linkend="agent">external agents</link>.
			</para><para>
In a failure protected LVS, if the realserver at the end of a connection fails,
the client will loose their connection to the LVS,
and the client will have to start with a new connection, as would happen
on a regular single server.
With a failure protected LVS, the failed realserver will be switched
out of the LVS and a working new server will be made available to you transparently
(the client will connect to one of the still working servers, or possibly a new server
if one is brought on-line).
			</para><para>
If the service is http, loosing the connection is not a problem for the
client: they'll get a new connection next time they click on a link/reload.
For services which maintain a connection, loosing the connection will
be a problem.
			</para><para>
<blockquote><para>
ratz <emphasis>ratz (at) tac (dot) ch</emphasis> 16 Nov 2000
			</para><para>
This is very nasty for persistent setups
in an e-commerce environment. Take for example a simple e-com site
providing some subjects to buy. You can browse and view all their
goodies. At a certain point you want to buy something. Ok, it is
common nowadays that people can buy over the Internet with CC. Obviously
this is done f.e. with SSL. SSL needs persistency enabled in the
lvs-configuration. Imaging having 1000 users (conn ESTABLISHED)
that are entering their VISA information when the database server
crashes and the healthcheck takes out the server; or even more simple
when the server/service itself crashes. Ok, all already established
connections (they have a persistent template in the kernel space)
are lost and these 1000 users have to reauthenticate. How does this
look from a clients point of view which has no idea about the technology
behind a certain site.
</para></blockquote>
			</para><para>
Here the functioning and setup of "mon" is described.
In the Ultra Monkey version of LVS, ldirectord fills the same role.
(I haven't compared ldirectord and mon. I used mon because it was available
at the time, while ldirectord was either not available or I didn't know about it.)
The configure script
will setup mon to monitor the services on the realservers.
			</para><para>
        Get "mon" and "fping" from
http://www.kernel.org/software/mon/ (I'm using mon-0.38.20)
			</para><para>
(from <emphasis>ian.martins (at) mail (dot) tju (dot) edu</emphasis> - comment out
line 222 in fping.c if compiling under glibc)
			</para><para>
			</para><para>
        Get the perl package "Period" from
CPAN, ftp://ftp.cpan.org)
			</para><para>
To use the fping and telnet monitors, you'll need the tcp_scan
binary which can be built from satan. The standard version of
satan needs patches to compile on Linux. The patched version is
at
			</para><para>
ftp://sunsite.unc.edu/pub/Linux/system/network/admin
	</para></section>
	<section id="NIC_failure">
	<title>ethernet NIC failure, and channel bonding</title>
	<para>
There was a lengthy thread on using multiple NICs to handle NIC failure.
Software/hardware to handle such failures is common for unices
which run expensive servers (<emphasis>e.g.</emphasis> Solaris) but is less common
in Linux.
                	</para><para>
Beowulfs can use multiple NICs to increase thoughput by bonding them together (channel bonding),
but redundancy/HA is not important for beowulfs - if a machine fails, it is fixed on the spot.
There is no easy way to un-bond NICs - you have to reboot the computer :-(
                	</para><para>
Michael McConnell <emphasis>michaelm (at) eyeball (dot) com</emphasis> 06 Aug 2001
<blockquote><para>
I want to take advantage of dual NICS in the realserver to provide redundancy.
Unfortunately the default gw issue comes up.
</para></blockquote>
                	</para><para>
Michael E Brown <emphasis>michael_e_brown (at) dell (dot) com</emphasis> 09 Aug 2001
<blockquote><para>
Yes, this is a generally available feature with most modern NICS. It is
called various things: channel bonding, trunking, link aggregation. There
is a native linux driver that implements this feature in a generic way. It
is called the bonding driver. It works with any NIC. look in
drivers/net/bond*. Each NIC vendor also has a proprietary version that
works with only their NIC. I gave urls for intel's product, iANS. Broadcom
and 3com also have this feature. I believe there is a standard for this:
802.1q.
</para></blockquote>
John Cronin
<blockquote><para>
It would be nice if it could work across multiple switches, so if a
single switch failed, you would not lose connectivity (I think the
adaptive failover can do this, but that does not improve bandwidth).
                	</para><para>
Jake Garver <emphasis>garver (at) valkyrie (dot) net</emphasis> 08 Aug 2001
<blockquote><para>
No it wouldn't be nice because it would put a tremendous burden on the
link connecting the switches.  If you are lucky, this link is 1Gb/sec, much
slower than back planes which or 10Gb/sec and up.  In general, you don't
want to "load balance" your switches. Keep as much as you can on the same
back plane.
</para></blockquote>
So, are there any Cisco Fast EtherChannel experts out there?  Can
FEC run across multiple switches, or at least across multiple Catalyst
blades?  I guess I can go look it up, but if somebody already knows,
I don't mind saving myself the trouble.
<blockquote><para>
Fast EtherChannel cannot run across multiple switches.  A colleague spent
weeks of our time proving that.  In short, each switch will see a distinct link,
for a total of two, but your server will think it has one big one.  The
switches will not talk to each other to bond the two links and you don't want
them to for the reason I stated above.  Over multiple blades, that depends on your
switch.  Do a "show port capabilities" to find out; it will list the ports
that can be grouped into an FEC group.
</para></blockquote>
</para></blockquote>
			</para><para>
Michael E Brown <emphasis>michael_e_brown (at) dell (dot) com</emphasis>
<blockquote><para>
If you want HA, have one machine (machine A) with bonded channels
connected to switch A, and have another machine (machine B) with bonded
channels connected to switch B.
			</para><para>
If you want to go super-paranoid, and have money to burn on links that
won't be used during normal operations: have one machine (machine A) with
bonded channels connected to switch A, and have backup bonded channels to
switch B. Have software that detects failure of all bonded channels to
switch A and fails over your IP to switch B (still on machine A). Have
another machine (B), with two sets of bonded channels connected to switch
C and switch D. lather, rinse, repeat. On Solaris, IP failover to backup
link is called IP Multipathing, IIRC. New feature of Solaris 8. Various HA
softwares for Linux, notably Steeleye Lifekeeper and possibly
LinuxFailsafe, support this as well.
</para></blockquote>
			</para><para>
John Cronin
<blockquote><para>
For the scenario described above (two systems), in many cases machine
A is active and machine B is a passive failover, in which case you
have already burned some money on an entire system (with bonded
channels, no less) that won't be used during normal operations.
			</para><para>
Considering I can get four (two for each system) SMC EtherPower
dual port cards for about $250, including shipping, or four Zynx
Netblaster quad cards for about $820, if I shop around carefully,
or $1000 for Intel Dual Port Server adapters or $1600 for Adaptec/Cogent
ANA-6944 quad cards, if a name brand is important), the cost seems less
significant when viewed in this light (not to mention the cost of two
Cisco switches that can do FEC too).
</para></blockquote>
			</para><para>
Back to channel bonding
(John Cronin)
<blockquote><para>
	<blockquote><para>
I presume it's not doable.
	</para></blockquote>
			</para><para>
I think "not doable" is an incorrect statement - "not done" would
be more precise.  For the most part, beowulf is about performance,
not HA.  I know that Intel NICs can use their own channel
aggregation or Cisco Fast-EtherChannel to aggregate bandwidth
AND provide redundancy.  Unfortunately, these features are
only available on the closed-source Microsoft and Novell platforms.
			</para><para>
http://www.intel.com/network/connectivity/solutions/server_bottlenecks/config_1.htm
			</para><para>
<blockquote><para>
Having 2 NICs on a machine with one being spare, is relatively
new. No-one has implemented a protocol for redundancy AFAIK.
</para></blockquote>
			</para><para>
I assume that you mean both of these statements to apply to Linux
and LVS only.  Sun has had trunking for years, but IP multipathing
is the way to go now as it is easier to set up.  You do get some
bandwidth improvements for OUTBOUND connections only, on a per
connection basis, but the main feature is redundancy.
			</para><para>
Look in http://docs.sun.com/ for IP, multipathing, trunking.
			</para><para>
Sun also has had Network Adapter Fail-Over groups (NAFO groups) in Sun
Cluster 2.X for years, and in Sun Cluster 3.0.  Veritas Cluster Server
has an IPmultiNIC resource that provides similar functionality.  Both
of these allow for a failed NIC to be more or less seamlessly replaced
by another NIC.  I would be surprised if IBM HACMP has not had a similar
feature for quite some time.  In most cases these solutions do not
provide improved bandwidth.
			</para><para>
<blockquote><para>
The next question then is how often does a box fail in such
a way that only 1 NIC fails and everything else keeps working?
I would expect this to be an unusual failure mode and not
worth protecting against. You might be better off channel bonding
your 2 NICs and using the higher throughput (unless you're compute
bound).
</para></blockquote>
			</para><para>
I would agree, with one exception.  If you have the resources to
implement redundant network paths farther out into your infrastructure,
then having redundant NICs is much more likely to lead to improved
availability.  For example if you have two NICs, which are plugged into
to two different switches, which are in turn plugged into two different
routers, then you start to get some real benefit.  It is more complicated
to setup (HA isn't easy most of the time), but with the dropping prices
of switches and routers, and the increased need for HA in many environments,
this is not as uncommon as it might sound, at least not in the ISP and
hosting arena.
			</para><para>
I am not trying to slam LVS and Linux HA products - to the contrary;
I am trying to inspire some talented soul to write a multipathing
NIC device driver we can all benefit from.  ;)  I make my living
doing work on Sun boxes, but I use Linux on my Dell Inspiron 8000
laptop (my primary workstation, actually - it's a very capable system).
I would recommend Linux solutions in many situations, but in most
cases my employers won't bite, as they prefer vendor supported
solutions in virtually every instance, while complaining about
the official vendor support.
</para></blockquote>
			</para><para>
<blockquote><para>
for channel bonding both NICS on the host have the same IP and MAC address.
You need to split the cabling for the two lots of NICs, so you don't have
address collisions - you'll need two switches.
<blockquote><para>
John Cronin
			</para><para>
You either need multiple switches, or switches that understand and
are willing participants in the channel aggregation method being used.
Cisco makes switches that do Fast EtherChannel, and Intel makes adapters
that understand this protocol (but again, not currently using Linux).
Intel adapters also have their own channel aggregation scheme, and I
think the Intel switches could also facilitate this scheme, but Intel
is getting out of the switch business.  Unfortunately, none of the
advanced Intel NIC features are available using Linux (it would be
nice to have the hardware IPsec support on their newest adapters,
for example).
</para></blockquote>
			</para><para>
Michael E Brown <emphasis>michael_e_brown (at) dell (dot) com</emphasis>
<blockquote><para>
Depends on which kind of bonding you do. Fast Etherchannel depends on all
of the nics being connected to the same switch. You have to do configure
the switch for trunking. Most of the standardized trunking methods I have
seen require you to configure the switch and have all your nics connected
to the same switch.
</para></blockquote>
</para></blockquote>
			</para><para>
			</para><para>
<blockquote><para>
You either need multiple switches, or switches that understand and
are willing participants in the channel aggregation method being used.
Cisco makes switches that do Fast EtherChannel, and Intel makes adapters
that understand this protocol (but again, not currently using Linux).
			</para><para>
Michael E Brown <emphasis>michael_e_brown (at) dell (dot) com</emphasis>
<blockquote><para>
Not true. You can download the iANS software from Intel. Not open source,
but that is different from "not available".
			</para><para>
look in http://isearch.intel.com for ians+linux.
			</para><para>
Also, if you want channel bonding without intel proprietary drivers, see
</para></blockquote>
<programlisting><![CDATA[
/usr/src/linux/drivers/net/bonding.c:
/*
 * originally based on the dummy device.
 *
 * Copyright 1999, Thomas Davis, tadavis (at) lbl (dot) gov
 * Licensed under the GPL. Based on dummy.c, and eql.c devices.
 *
 * bond.c: a bonding/etherchannel/sun trunking net driver
 *
 * This is useful to talk to a Cisco 5500, running Etherchannel, aka:
 *      Linux Channel Bonding
 *      Sun Trunking (Solaris)
 *
 * How it works:
 *    ifconfig bond0 ipaddress netmask up
 *      will setup a network device, with an ip address.  No mac address
 *      will be assigned at this time.  The hw mac address will come from
 *      the first slave bonded to the channel.  All slaves will then use
 *      this hw mac address.
 *
 *    ifconfig bond0 down
 *         will release all slaves, marking them as down.
 *
 *    ifenslave bond0 eth0
 *      will attache eth0 to bond0 as a slave.  eth0 hw mac address will
either
 *      a: be used as initial mac address
 *      b: if a hw mac address already is there, eth0's hw mac address
 *         will then  be set from bond0.
 *
 * v0.1 - first working version.
 * v0.2 - changed stats to be calculated by summing slaves stats.
 *
 */
]]></programlisting>
</para></blockquote>
			</para><para>
Michael McConnell
<blockquote><para>
This definately does it!
			</para><para>
It create this excellent kernel module, it contains ALL.
I just managed to get this running on a Tyan 2515 Motherboard that has two
Onboard Intel Nics.
			</para><para>
I've just tested failover mode, works *PERFECT* not even a single packet dropped!
I'm gonna try out adaptive load balancing next, and i'll let you know how I make out.
			</para><para>
ftp://download.intel.com/df-support/2895/eng/ians-1.3.34.tar.gz
</para></blockquote>
			</para><para>
			</para><para>
Michael E Brown <emphasis>michael_e_brown (at) dell (dot) com</emphasis>
			</para><para>
<blockquote><para>
Broadcom also has proprietary channel bonding drivers for linux.
The problem is getting access to this driver. I could not find
any driver downloads from their website. It is possible that only
OEMs have this driver. Dell factory installs this driver for RedHat 7.0
(and will be on 7.1, 7.2). You might want to e-mail Broadcom and ask.
			</para><para>
Also
<blockquote><para>
Broadcom also has an SSL offload card which is coming out and it has open
source drivers for linux.
			</para><para>
http://www.broadcom.com/products/5820.html
			</para><para>
You need the openssl library and kernel.
			</para><para>
The next release of Red Hat linux will have this
support integrated in. The Broadcom folks are working closely with the
OpenSSL team to get their userspace integrated directly into 0.9.7. Red
Hat has backported this functionality into their 0.9.6 release.
			</para><para>
If you look at Red Hat's latest public beta, all the support is there and
is working.
			</para><para>
Since there aren't docs yet, the "bcm5820" rpm is
the one you want to install to enable everything. Install this RPM, and it
contains an init script that enables and disables the OpenSSL "engine"
support as appropriate. Engine is the new OpenSSL feature that enables
hardware offload.
</para></blockquote>
</para></blockquote>
		</para>
		<section id="channel_bonding">
		<title>more on channel bonding</title>
		<para>
<blockquote><para>
Paul wrote
			</para><para>
Interface bond0 comes up fine with eth1 and eth2 no problem.  Bond1
fails miserably every time.  I'm going to take that issue up on the
bonding mailing list.
</para></blockquote>
			</para><para>
Roberto Nibali <emphasis>ratz (at) drugphish (dot) ch</emphasis> 07 Mar 2002
			</para><para>
Which patch did you try? Is it the following:
			</para><para>
http://prdownloads.sourceforge.net/bonding/bonding-2.4.18-20020226
			</para><para>
Did you pass max_bonds=2 when you loaded the bonding.o module? Without
that you have no chance. Read the source (if you haven't already) to see
what other fancy parameters you might want to pass.
			</para><para>
<blockquote><para>
This is driven in part by our desire to see how far we can push lvs.  I
know it does 100mb/s in and out.  If it can keep 2 channels full, I'll
add a thirds, fourth,fifth, etc as necessary.
</para></blockquote>
			</para><para>
Read http://www.sfu.ca/acs/cluster/nic-test.html to get the impression
of what happens if you try to bond too many NICs.
		</para>
		</section>
	</section>
	<section id="service_failout">
	<title>Service/realserver failout: mon, ldirectord</title>
	<para>
To activate realserver failover, you can install mon on the director.
Several people have indicated that they have written/are using other schemes.
RedHat's piranha has monitoring code,
and handles director failover and is documented there.
	</para>
	<para>
ldirectord handles director failover and is part of the Linux High Availability project.
The author of ldirectord is Jacob Rief 
<emphasis>jacob (dot) rief (at) tis (dot) at</emphasis>
with most of the later add-ons and code cleanup by Horms, 
who is using it with Linux=HA/UltraMonkey.
	<note>
		<para>
Jacob 12 Feb 2004
		</para>
		<para>
Since Jun 2003, I've handed over developement to Horms.
I'm now using <command>keepalived</command>.
It's faster, cleaner in design and also much smarter,
because you don't need any extra heartbeat.
		</para>
	</note>		
ldirectord needs Net::SSLeay only if you are
monitoring https (Emmanuel Pare <emphasis>emman (at) voxtel (dot) com</emphasis>, Ian S. McLeod
<emphasis>ian (at) varesearch (dot) com</emphasis>)
	</para>
	<para>
To get ldirectord -
	</para>
	<para>
Jacob Rief <emphasis>jacob (dot) rief (at) tis (dot) at</emphasis>
	</para>
<programlisting><![CDATA[
the newest version available from
cvs.linux-ha.org:/home/cvs/
user guest,
passwd guest
module-name is: ha-linux
file: ha-linux/heartbeat/resource.d/ldirectord
documentation: ha-linux/doc/ldirectord
]]></programlisting>
	<para>
ldirectord is also available from
http://reserve.tiscover.com/linux-ha/ (link dead May 2002)
	</para>
	<para>
Andreas Koenig <emphasis>andreas (dot) koenig (at) anima (dot) de</emphasis> 7 Jun 2001
	</para>
	<para>
cvs access is described in http://lists.community.tummy.com/pipermail/linux-ha-dev/1999-October/000212.html
	</para>
	<para>
Here's a possible alternative to mon -
	</para>
	<para>
Doug Bagley <emphasis>doug (at) deja (dot) com</emphasis>  17 Feb 2000
	</para>
	<blockquote>
		<para>
Looking at mon and ldirectord, I wonder what kind of work is planned
for future service level monitoring?
		</para><para>
mon is okay for general purposes, but it forks/execs each monitor
process, if you have 100 real services and want to check every 10
seconds, you would fork 10 monitor processes per second.  This is
not entirely untenable, but why not make an effort to make the
monitoring process as lightweight as possible (since it is running
on the director, which is such an important host)?
		</para><para>
ldirectord, uses the perl LWP library, which is better than forking,
but it is still slow.  It also issues requests serially (because LWP
doesn't really make parallel requests easy).
		</para><para>
I wrote a very simple http monitor last night in perl that uses
non-blocking I/O, and processes all requests in parallel using
select().  It also doesn't require any CPAN libraries, so installation
should be trivial.  Once it is prototyped in perl, conversion to C
should be straightforward.  In fact, it is pretty similar to the
Apache benchmark program (ab).
		</para><para>
In order for the monitor (like ldirectord) to do management of the
ipvs kernel information, it would be easier if the /proc interface to
ipvs gave a more machine readable format.
		</para>
	</blockquote>
	<para>
Michael Sparks <emphasis>zathras (at) epsilon3 (dot) mcc (dot) ac (dot) uk</emphasis>
	</para>
	<para>
Agreed :-)
	</para>
<programlisting><![CDATA[
It strikes me that rather than having:
type serviceIP:port mechanism
  -> realip:port tunnel weight active inactive
  -> realip:port tunnel weight active inactive
  -> realip:port tunnel weight active inactive
  -> realip:port tunnel weight active inactive
]]></programlisting>
	<para>
If the table was more like:
	</para>
<programlisting><![CDATA[
type serviceIP:port mechanism realip:port tunnel weight active inactive
]]></programlisting>
	<para>
Then this would make shell/awk/perl/etc scripts that do things with this
table easier to cobble together.
	</para>
	<blockquote>
That seems like a far reaching precedent to me.  On the other hand, if
the <command>ipvsadm</command> command wished to have a option to represent that
information in XML, I can see how that could be useful.
	</blockquote>
	<para>
This reminds me I should really finish tweaking the prog I wrote to allow
pretty printing of the <command>ipvsadm</command> table, and put it somewhere else for others
to play with if they like - it allows you to specify a template file for
formatting the output of of ipvsadm, making displaying the stuff as XML,
HTML, plain text, etc simpler/quicker. (It's got a few hardcoded settings
at the mo which I want to ditch first :-)
	</para>
	</section>
	<section id="ldirectord_multithreaded">
	<title>Is ldirectord multithreaded? (ldirectord running high %CPU)</title>
	<para>
Joe: This came up after Eric Robinson found his misconfigured ldirectord running 50-99% CPU.
	</para>
	<para>
Horms 5 Dec 2008 
	</para>
	<para>
The basic answer is yes.
By default ldirectord does not take advantage of multiple cores,
though as discussed in the previous thread, its workload can be split up,
and that would cause allow it to use multiple cores.
LVS does take advantage of multiple cores by virtue of being in the kernel
- assuming you are using an SMP kernel. The issue of how well it can use
multiple cores is a complex topic, and the results would depend on the
workload.
	</para>
	<para>
Its important to note that generally speaking ldirectord should not be
using a lot of CPU resources - and if it is then some refactoring of the
code for the situation at hand would be time well spent.  LVS (and the rest
of the Linux network stack, which it uses) may on the other hand consume a
reasonable ammount of CPU resource if it is dealing with a lot of packets /
connections.
	</para>
	<para>
Joe: Here's Eric's problem 
	</para>
<programlisting><![CDATA[
top
.
.
Mem:    516304k total,   506348k used,     9956k free,    45448k buffers
Swap:  1048568k total,        4k used,  1048564k free,   369656k cached

  PID USER      PR  NI  VIRT  RES  SHR S %CPU %MEM    TIME+  COMMAND
 2762 root      17   0 13708 9884 1744 S 50.4  1.9  13386:29 ldirectord
28957 root      15   0  7108 2320 1848 S  0.3  0.4   0:00.03 sshd
.
.
]]></programlisting>
	<para>
Fernanda G Weiden <emphasis>fernanda (at) softwarelivre (dot) org</emphasis>
	</para>
	<para>
Using multiple processes for different vips would help to isolate the
problem, at least. Maybe there is a weird external check or something
killing the machine.
	</para>
	<para>
Graeme
	</para>
	<para>
81 days uptime is 116640 minutes; that means ldirectord has consumed &gt;10% 
of the CPU in the time the server's been up. What's the health check
interval here?
	</para>
	<para>
With (say) 100 virtual servers, 2 realservers each, an interval of 10
seconds means 200 checks every ten seconds (nominally). Assuming a 0.1
second latency for each check, you're talking overlapping checks there
so a given check thread is only half way through running when it starts
again.
	</para>
	<para>
Horms
	</para>
	<para>
I'm not entirely sure what overlapping means here, but a single
ldirectord process runs checks in series. One runs until it
finishes or times out, then the next one. There is no parallisation.
        </para>
	<para>
Graeme
	</para>
	<para>
It would appear that ldirectord isn't being given a chance to draw
breath. Ever.
	</para>
	<para>
Horms
	</para>
	<para>
Ldirectord isn't that smart. Each ldirectord process just sits in a loop
that looks a bit like this
	</para>
<programlisting><![CDATA[
while (1) {
        run check 1 and wait for it to either succeed or time-out;
        run check 2 and wait for it to either succeed or time-out;
        ...
        run check n and wait for it to either succeed or time-out;

        if configuration file has changed
                if $AUTOCHECK is set
                        re-read configuration file;
        else
                sleep $CHECKINTERVAL;
}
]]></programlisting>
	<para>
So unless something odd is happening with the configuration file,
it should always get a chance to take a breath for $CHECKINTERVAL seconds.
	</para>
	<para>
Horms
	</para>
	<para>
It seems odd to me that Ldirectord would take up so much CPU,
its primarily either a) sending small amounts of data and waiting
for a reply or b) sleeping. So if it is consuming lots of CPU
I suspect a bug, probably in one of the checks (or more specifically
one of the modules that is used for one of the checks). There have
been problems with the HTTPS check leaking memory in the past, so I
would start by seeing if that is the culprit.
	</para>
	<para>
In answer to the multi-threading question - no ldirectord is not
multi-threaded, though you can split your configuration up into
multiple configuration files and run multiple instances of ldirectord.
I can handle the forking for you, or you can do it manually.
	</para>
	<para>
Somewhere in the thread it was suggested that you could split your
configuration up so that you have  one ldirectord process per virtual
service as a means of attempting to narrow down the problem. I think that
this is a good idea.
	</para>
	<para>
A long time ago there was an effort to use non-blocking IO to allow
ldirectord to run multiple checks in parallel in a single processes.
However the code (in the supporting modules) did not work well.
	</para>
	<para>
The primary motivation for parallelising ldirectord either within
a single process or with multiple processes is usually to minimise
the delays inherent in running checks serially. This would actually
result in increased CPU usage - as it would be doing more work in
a given space of time.
	</para>
	<para>
With regards to LVS, it is almost certainly not the cause of ldirectord
taking up 50% of CPU.  ldirectord only configures LVS. And this is done by
forking an ipvsadm process. So if there was a problem with ldirectord
configuring LVS, it should show up as ipvsadm processes consuming lots of
resources.  (Although I guess it is possible that ldirectord is having
trouble forking ipvsadm.)
	</para>
	<para>
Graeme
	</para>
	<para>
To measure packet throughput
	</para>
<programlisting><![CDATA[
ipvsadm -L -n --stats
ipvsadm -L -n --rate
]]></programlisting>
	<para>
Those two commands will get you pretty far down the road of what you
need in terms of packets/sec, conns/sec and so on. --rate will give you
the instantaneous rate, where --stats will give you counters since this
LVS was started. This is useful for post-processing to get overall
averages.
	</para>
	<para>
Given the large number of services and realservers you have, I think
this is the key. Looking at the config file (if I read it correctly) you
have:
	</para>
<programlisting><![CDATA[
60x tomcat services, 2 realservers each == 120 checks
60x MySQL services, 1 realserver each   ==  60 checks
5x  other services, 1 or 2 realservers each == 7 checks
]]></programlisting>
	<para>
That's a total of 187 checks to be run every two seconds. If we make it
a round 200 (since the maths is then easier!) then you're talking a
maximum latency of 0.01 seconds per check.
It would appear that ldirectord isn't being given a chance to draw
breath. Ever.
	</para>
	<para>
Just as a test, what happens if you move the checkinterval out to (say)
5, 10, 20 or 30 seconds? Can you tolerate that level of pause if
something happens to a realserver?
	</para>
	<para>
Eric
	</para>
	<blockquote>
I changed it to 5 seconds, but no significant change was apparent. Then
I changed it to 10 seconds and there was a definite, observable drop in
CPU utilization.  A graph of the past 6 hours shows that usage has now
flattened out and is now averaging less than 10%.  
	</blockquote>
	<para>
Graeme
	</para>
	<para>
We have now narrowed the cause of the problem down to health checks.
	</para>
	<para>
Eric
	</para>
	<blockquote>
		<para>
As for tolerating longer timeouts: I don't know. 
These are medical applications, and doctors are often
grumpy about transient glitches in their applications while trying to
document patient encounters. I'm thinking something like this might
possibly work for the short term:
		</para>
<programlisting><![CDATA[
checkinterval=10
checktimeout=5
negotiatetimeout=8
checkcount=1
]]></programlisting>
		<para>
But it would still be a temporary solution and this raises a general
question about load-balancer scaling. Right now I have 120 VS, but in a
year or two it will be 240. In 4 years it could be 500+. I can't just
keep increasing the checkinterval. Ultimately, I'm going to have to try
multiple instances of ldirectord.
		</para>
		<para>
Which raises a question about LVS. Could it get confused with multiple
ldirectord instances constantly forking ipvsadm?
		</para>
	</blockquote>
	<para>
Graeme
	</para>
	<para>
As long as they are managing discrete pools of virtual and real servers,
then no I don't think it will *unless* you hit the problem someone else
reported very recently where realservers seem to migrate between
virtuals at random. Horms was going to try to work on that, but it might
be tricky to isolate.
	</para>
	<para>
Horms
	</para>
	<para>
ldirectord (or any other code that manages LVS from user-space) may get
confused, if one process is reading things and another is changing things
for the same virtual server - though as Graeme says, if they are managing
discrete pools this should not be a problem, with the caveat that there
seems to be a bug in that code in ldirectord.
	</para>
	<para>
It is not possible to confuse LVS itself (unless there is a bug I don't
know about). It just does what it is configured to do. And it uses locking to
ensure that only one user-space process can change things at a time. So
even if user-space is making multiple changes simultaneously (on multiple
processors or cores) to the same real server in the same virtual service,
the LVS kernel code will serialise these changes and something sensible
should result - albeit perhaps not what the multiple user-space processes
were expecting.
	</para>
	<para>
In other words, LVS serialises changes from user-space.
	</para>
	<para>
Graeme
	</para>
	<para>
For such a large number of realservers I think you may need to get
creative with your healthchecking. You could use the "checkcommand"
setting to ldirectord to read a value from a file which is kept updated
by some other script which can check in parallel. Unfortunately I can't
pull one of those out of a hat right now... :)
	</para>
	<para>
Horms
	</para>
	<para>
Yes, I agree that some sort of creativity is in order.
I did some work on making ldirectord more scalable, but that was a long
time ago, and for a somewhat different scenario. The main outcome of that
work was fwmark support in both LVS and ldirectord, which allowed many
virtual services with the same real servers to be aggregated.
	</para>
	<para>
Graeme
	</para>
	<para>
Thinking about it laterally, how does something like Nagios cope with a
very large number of service checks? It does them in parallel, by
running multiple threads. So does OpenNMS, and Zabbix, and in fact
pretty much every one of the decent (fsvo "decent") NMS apps I've ever
used.
	</para>
	<para>
Horms
	</para>
	<para>
As ldirectord is written in Perl, doing non-blocking IO to parallelise
things is difficult - or more to the point, appeared to not work the last
time it was tried. I believe that keepalived, which is written in C, has an
easier time here.
	</para>
	<para>
On the other hand ldirectord does have a forking option, which parallelises
things by forking a process for each virtual service. Though now
that I think about it, it might be better if it used a pool of processes,
if you have 50 virtual services it will try and fork 50 processes for
each iteration of the main loop!
	</para>
	<para>
It also allows you to split up the configuration file manually and fork
at that granularity at start-up.
	</para>
	<para>
Later:
I missread the code, the processes should only be forked on startup,
and then re-forked if they die. Not forked for each iterration
of the main loop. But still, a pool might be a good idea, albeit
more complex than the current code.
	</para>
	<para>
Joe
	</para>
	<para>
In the early days of LVS, all failover was set to at least 
30secs as the tcpip stack is designed to tolerate somewhere 
between 30-90sec (depending on the OS) of lost packets (if 
routing goes down) before sending back icmp errors to the 
sending node. On that understanding, all applications can 
expect silence on that time scale before the routing 
underneath rearranges itself.
	</para>
	<para>
For the number of times you have a forced failover of a 
realserver (once every couple of months at most), I can't 
imagine that doctors will notice. Planned downtime will 
involve setting the weight to 0 and then shutting down the 
node, when all connections are dropped
	</para>
	<para>
Graeme
	</para>
	<para>
Not being entirely au fait with ldirectord, I had a read of the source
code this morning and found the following which might (or might not)
help you out:
	</para>
	<blockquote>
		<para>
fork = yes/no
		</para>
		<para>
If yes, then ldirectord will spawn a child proccess for every virtual
server, and run checks against the real servers from them.  This will
increase response times to changes in real server status in configura-
tions with many virtual servers.  This may also use less memory then
running many seperate instances of ldirectord.  Child processes will be
automaticly restarted if they die.
		</para>
		<para>
Default: no
		</para>
	</blockquote>
	<para>
I was going to suggest modifying ldirectord to fork health check
processes out for each VS, but Horms (or maybe Jacob) already did it :)
	</para>
	<para>
That should help. You'll end up with a lot of processes running but they
should be able to deal with the shorter check interval far better than
screaming through hundreds of checks every two seconds.
	</para>
	<note>
Ryan Castellucci <emphasis>ryan (dot) castellucci (at) gmail (dot) com</emphasis>
has submitted a patch for this (see: http://hg.linux-ha.org/dev/rev/3d3d903779b2)
	</note>
	</section>
	<section id="ldirectord_from_command_line">
	<title>overriding ldirectord health checks from the command line</title>
	<para>
Joe: Eric found that when he brought down/up the service running on the realserver,
that ldirectord's health checking would change the weight of the realserver in
the ipvsadm table to 0/1 (as expected). 
However, for a healthy realserver, when Eric changed the weight to 0 via <command>ipsvadm</command> 
ldirectord's health checking didn't reset the weight back to 1.
This behaviour of ldirectord is an unintended part of the design.
Since Eric (and other people) like this behaviour, 
it will now be a part of the specification of ldirectord. 
	</para>
	<para>
Robinson, Eric <emphasis>eric (dot) robinson (at) psmnv (dot) com</emphasis> 4 Dec 2008
	</para>
	<para>
On my load balancer, you can see that I have two RS listening on port
3001, and both are up..
	</para>
<programlisting><![CDATA[
[root@lb1 ]# ipvsadm|grep 3001
TCP  extrovert.mycharts.md:3001 lblc persistent 360
  -> 192.168.10.62:3001           Masq    1      0          0
  -> 192.168.10.61:3001           Masq    1      0          0
[root@lb1 scripts]#
]]></programlisting>
	<para>
Now I'll stop the service listening on the server at 192.168.10.61...
	</para>
<programlisting><![CDATA[
[root@appftp1 ]# service tomcat5_001 stop
Stopping tomcat: Using CATALINA_BASE:   /alley/site001/tomcat5
Using CATALINA_HOME:   /alley/site001/tomcat5
Using CATALINA_TMPDIR: /alley/site001/tomcat5/temp
Using JAVA_HOME:       /usr/java/j2sdk1.4.2_09
]]></programlisting>
	<para>
Back on the load balancer, the down server is detected immediately...
	</para>
<programlisting><![CDATA[
[root@lb1 /]# ipvsadm|grep 3001
TCP  extrovert.mycharts.md:3001 lblc persistent 360
  -> 192.168.10.62:3001           Masq    1      0          0
  -> 192.168.10.61:3001           Masq    0      0          0
[root@lb1 /]#
]]></programlisting>
	<para>
Now back on the RS, I'll start the service back up...
	</para>
<programlisting><![CDATA[
[root@appftp1 /]# service tomcat5_001 start|grep "startup in"
INFO: Server startup in 4023 ms
[root@appftp1 /]# 
]]></programlisting>
	<para>
The LB instantly detects the RS is back up...
	</para>
<programlisting><![CDATA[
[root@lb1 /]# ipvsadm|grep 3001
TCP  extrovert.mycharts.md:3001 lblc persistent 360
  -> 192.168.10.62:3001           Masq    1      0          0
  -> 192.168.10.61:3001           Masq    1      0          0 
[root@lb1 /]#
]]></programlisting>
	<para>
So we know the healthchecks are working, right?
	</para>
	<para>
But now look at this. On the LB, I'll change the weight manually, check
it, wait 60 seconds, and check it again...
	</para>
<programlisting><![CDATA[
[root@lb1 /]# ipvsadm -e -t 192.168.5.100:3001 -r 192.168.10.61 -w 0 -m
[root@lb1 /]# ipvsadm|grep 3001
TCP  extrovert.mycharts.md:3001 lblc persistent 360
  -> 192.168.10.62:3001           Masq    1      0          0
  -> 192.168.10.61:3001           Masq    0      0          0
[root@lb1 /]# sleep 60
[root@lb1 /]# ipvsadm|grep 3001
TCP  extrovert.mycharts.md:3001 lblc persistent 360
  -> 192.168.10.62:3001           Masq    1      0          0
  -> 192.168.10.61:3001           Masq    0      0          0
[root@lb1 /]#
]]></programlisting>
	<para>
Still down after a full minute! And it will *stay* down until I run
ipvsadm with -w 1
	</para>
	<para>
This is what makes me wonder why I seem to get different behavior from
the command line than from the healthchecks. I'm sure it must be
something simple that I am overlooking.
	</para>
	<para>
Graeme 04 Dec 2008
	</para>
	<para>
I just played with this and observed the same behaviour, and I think I
can summarise it as:
	</para>
	<para>
Manage your LVS manually, or automate it with keepalived/ldirectord.
Don't do both.
	</para>
	<para>
I get the feeling that both of the above will *change* the weight (or
remove a server from the pool) when there's a state change, but if the
state remains the same the in-memory structures will stay the same so
the actual weight assigned in the mix of user/kernel space that's in use
at this point remains the same.
	</para>
	<para>
If you change weight using a tool like ipvsadm, then *that* weight will
apply until something changes to make the automation system change
something.
	</para>
	<para>
For the record, I've used a MISC_CHECK with keepalived before in order
to "manually" quiesce a server by simply appending the IP address to a
text file or creating an empty file with the same name as an IP/port
pair in the pool. This can then be checked for existence every
delay_loop, and if it exists make the script exit with a weight which
sets the realserver's weight to zero.
This has meant I haven't ever ended up in the situation you're seeing,
so I did have to check :)
	</para>
	<para>
Jason Ledford <emphasis>jledford (at) biltmore (dot) com</emphasis> 4 Dec 2008 
	</para>
	<para>
I inquired about this a while back.  Ldirectord sets weight differently then ipvsadm, so if you set it with ipvsadm them
ldirectord will come behind you and change it to what the config is.  Based on help found here I use a script like this to
take a server offline.  You should be able to tailor for your needs to make a server come back also.  The sed command is
the important part:
	</para>
<programlisting><![CDATA[
echo "Config backed up"
/bin/cp /etc/ha.d/ldirectord.cf /etc/ha.d/ldirectord.cf.backup
/bin/sed 's/       real=10.37.2.9:25 masq 1/       real=10.37.2.9:25 masq 0/g' $
/bin/mv /etc/ha.d/ldirectord.cf.new /etc/ha.d/ldirectord.cf
echo "Now syncing with tbcsrv907"
/usr/bin/scp /etc/ha.d/ldirectord.cf tbcsrv907:/etc/ha.d/ldirectord.cf
echo "Spamone is Disabled"
]]></programlisting>
	<para>
I put that in a script and can run it when needed to drain my servers.  I also have the reverse in a script so I can bring it
back when I need.  I back it up first in case of a mistake.  I take it a step further and run these scripts from Webmin so
there is no need to even login to the server.
	</para>
	<para>
Horms 5 Dec 2008 
	</para>
	<para>
LVS runs inside the kernel and is configured from user-space.
The ipvsadm command line is a tool to do this and ldirectord
uses also tool. LVS does not (at this time) offer a way for user-space
programmes to see updates that have been made by third parties (though
now I think of this, the netlink interface that was added in 2.6.28
could likely be extended to do this). So if a user uses ipvsadm
to change something, ldirectord doesn't know about it.
	</para>
	<para>
ldirectord could poll the LVS setup and reset things that don't match its
view of the world, but it doesn't. Or more to the point it only does that
at the following times:
	</para>
	<itemizedlist>
		<listitem>
when it starts
		</listitem>
		<listitem>
when it is restarted
		</listitem>
		<listitem>
when it rereads the configuration file
		</listitem>
	</itemizedlist>
	<para>
Other than the times listed above - which all run through the startup code -
ldirectord only alters the LVS configuration when the state of a
real-server changes, from up to down or drom down to up.
	</para>
	<para>
So if you alter the state of a real server (or any other part of the LVS
configuration) using ipvsadm then that change will remain until one of
the three events listed above occurs or the state of the modified
real-server changes.
	</para>
	<para>
Personally, I would be a lot more comfortable in altering LVS's setup
by modifying ldirectord.cf as needed. As you never know when an event
that triggers ldirectord to do something might occur. But you may be
comfortable with this behaviour - its up to you.
	</para>
	<para>
Eric
	</para>
	<blockquote>
		<para>
For that very reason, the current behavior seems perfect to me. When I
place a server in "administratively down" mode, I *want* LVS to ignore
commands that may be triggered by ldirectord's health checks. That way I
can maintain the services on the RS (stop and start tomcat, for
instance) and not worry about the server suddenly becoming available to
users.
		</para>
		<para>
I also like being able to manipulate this behavior from the command
line. No need to edit a config file (or worry about remembering to
un-edit it). I can even schedule drain/fill changes with the at command.
It just feels right to me.
		</para>
	</blockquote>
	<para>
As for if/when this behaviour might change. Its not really an intentional
part of the design - more a side effect of LVS historically not providing
notifications of configuration changes to user-space. And I really do
think that managing the system through ldirectord.cf is a better way to go.
But there was a proposal made to me once that ldirectord should actually
take notice of third-party changes and incorporate that into its
configuration file. So I guess that if/when ldirectord was to take
notice of third-party changes, then the availability of three modes might
make sense:
	</para>
	<itemizedlist>
		<listitem>
Ignore them (until a change event occurs) - the current behaviour
		</listitem>
		<listitem>
Reverse them - the behaviour you were originally expecting
		</listitem>
		<listitem>
Incorporate them into the configuration
		</listitem>
	</itemizedlist>
	<para>
Graeme Fowler also mentioned keepalived. I imagine that it behaves
in a similar way to ldirectord, but I have not examined the code recently,
so I am just guessing.
	</para>
	<para>
Robinson, Eric <emphasis>eric (dot) robinson (at) psmnv (dot) com</emphasis> 5 Dec 2008 
	</para>
	<para>
This makes a great deal of sense to me. I can see where all three
options could be useful, but I really don't want to be without option 1 (Ignore them).
It is what makes what I call "drain mode" possible, which is a
wonderfully graceful way to maintain servers. I set the weight to 0 then
I go away. Existing sessions continue uninterrupted, but new ones to
that RS are not possible. The user count gradually drops to zero, at
which time I am free to power off the server or whatever. No advance
notification to users is required. No staying up late to catch the
server when nobody is on it. I just put it in drain mode during normal
production hours. The next day when all the users are off of it, I can
maintain it at my convenience. When I'm done, I issue an ipvsadm command
to put the server in "fill mode" and it starts servicing clients. I've
been using this approach for a year and it has saved enormous amounts of
time and energy.
	</para>
	<para>
One other reason that I like manipulating the behavior from the
command line is that I sometimes make mistakes in ldirectord.cf that I
don't catch until much later. I worry about messing up the config and
inadvertently breaking user's access to all 170 realservers. (That's why
I don't take advantage of ldirectord's callback directive to copy the
config file to the other load balancer. I'd rather do it manually. The
last thing I need is to screw up my config on both load balancers at the
same time!)
	</para>
	</section>
	<section id="Mon">
	<title>Mon for server/service failout</title>
	<para>
Here's the prototype LVS
	</para><para>
<programlisting><![CDATA[
                        ________
                       |        |
                       | client |
                       |________|
			   |
                           |
                        (router)
                           |
			   |
                           |       __________
                           |  DIP |          |
                           |------| director |
                           |  VIP |__________|
                           |
                           |
                           |
         ------------------------------------
         |                 |                |
         |                 |                |
     RIP1, VIP         RIP2, VIP        RIP3, VIP
   ______________    ______________    ______________
  |              |  |              |  |              |
  | realserver1  |  | realserver2  |  | realserver3  |
  |______________|  |______________|  |______________|
]]></programlisting>
			</para><para>
Mon has two parts:
			</para><para>
<itemizedlist>
<listitem><para>monitors: these are programs (usually perl scripts) which are run
periodically to detect the state of a service. E.g. the telnet monitor
attempts to login to the machine of interest and checks whether a
program looking like telnetd responds (in this case looking for the
string "login:"). The program returns success/fail. Monitors have
been written for many services and new monitors are easy to write.
</para></listitem><listitem><para>
Mon demon: reads a config file, specifying the hosts/services
to monitor and how often to poll them (with the monitors).
The conf file lists the actions for failure/success of each host/service.
When a failure (or recovery) of a service is detected by a
monitor, an "alert" (another perl script) is run. There are
alerts which send email, page you or write to a log. LVS
supplies a "virtualserver.alert" which executes ipvsadm
commands to remove or add servers/services, in response to
host/services changing state (up/down).
</para></listitem></itemizedlist>
	</para>
	</section>
	<section id="failover_big_caveat">
	<title>Monitoring the service running on the VIP on the realserver from the director</title>
	<para>
*Trap for the unwary*
			</para><para>
Mon runs on the director, but...
			</para><para>
Remember that you cannot connect to any of the LVS controlled
services from within the LVS (including from the director)
(also see the "gotcha" section in the
<link linkend="mini-HOWTO">LVS-mini-HOWTO</link>).
You can only connect to the LVS'ed services from the outside (eg from the client).
If you are on the director, the packets will not
return to you and the connection will hang. If you are connecting from
the outside (ie from a client) you cannot tell which server you have connected to.
This means that mon (or any agent), running on the director
(which is where is needs to be to execute <command>ipvsadm</command> commands),
cannot tell whether an LVS controlled service is up or down.
			</para><para>
With LVS-NAT an agent on the director can access services on the
RIP of the realservers (on the director you can connect to
the http on the RIP of each realserver).
Normal (i.e. non LVS'ed) IP communication is unaffected on the private
director/realserver network of LVS-NAT. If ports are not re-mapped
then a monitor running on the director can watch the httpd on
server-1 (at 10.1.1.2:80). If the ports are
re-mapped (eg the httpd server is listening on 8080), then you
will have to either modify the http.monitor (making an
http_8080.monitor) or activate a duplicate http service on port
80 of the server.
			</para><para>
For LVS-DR and LVS-Tun the service on the realserver is listening
to the VIP and you cannot connect to this from the director.
The solution to monitoring services under control of the LVS
for LVS-DR and LVS-Tun is
to monitor proxy services whose accessability should closely
track that of the LVS service. Thus to monitor an LVS http
service on a particular server, the same webpage should also be
made available on another IP (or to 0.0.0.0), not controlled by
LVS on the same machine.
			</para><para>
Example:
			</para><para>
<programlisting><![CDATA[
LVS-Tun, LVS-DR
lvs IP (VIP): eth0 192.168.1.110
director:     eth0 192.168.1.1/24 (normal login IP)
              eth1 192.168.1.110/32 (VIP)
realserver:  eth0 192.168.1.2/24 (normal login IP)
              tunl0 (or lo:0) 192.168.1.110/32 (VIP)
]]></programlisting>
			</para><para>
On the realserver, the LVS service will be on the tunl (or lo:0)
interface of 192.168.1.110:80 and not on 192.168.1.2:80. The IP
192.168.1.110 on the realserver 192.168.1.2 is a non-arp'ing
device and cannot be accessed by mon. Mon running on the director
at 192.168.1.1 can only detect services on 192.168.1.2 (this is
the reason that the director cannot be a client as well). The
best that can be done is to start a duplicate service on
192.168.1.2:80 and hope that its functionality goes up and down
with the service on 192.168.1.110:80 (a reasonable hope).
			</para><para>
<programlisting><![CDATA[
LVS-NAT
lvs IP (VIP): eth0 192.168.1.110
director:     eth0 192.168.1.1/24 (outside IP)
              eth0:1 192.168.1.110/32 (VIP)
              eth1 10.1.1.1/24 (DIP, default gw for realservers)
realserver:  eth0 10.1.1.2/24
]]></programlisting>
			</para><para>
Some services listen to 0.0.0.0:port, <emphasis>i.e.</emphasis> will listen on all IPs
on the and you will not have to start a duplicate service.
	</para>
	<para>
Joe
	</para>
	<para>
The director, which has the VIP, can't send a packet
to the VIP and expect it to go to the realserver.
Thus you need a parallel service running on the RIP (or the 
service on the realserver bound to 0.0.0.0). You can get 
around this by doing an rsh/ssh request to the RIP and 
running a command to check the service running on the VIP.
	</para>
	<para>
Graeme Fowler <emphasis>graeme (at) graemef (dot) net</emphasis> 19 May 2006
	</para>
	<para>
Alternatively setup an iptables rule on the realserver to snag the
packets aimed at the RIP and DNAT them to the VIP instead:
	</para>
<programlisting><![CDATA[
iptables -i $RIP_INTERFACE \
         -p tcp -m tcp -s $DIP -d $RIP \
         --dport 80 -j DNAT --to-destination $VIP
]]></programlisting>
	<para>
Ah... but I see your realservers are w2k servers, so that won't work.
Humbug.
You may need to use IIS to do this, and have it run a passthrough script
of some sort to attempt to fetch the app server index page from the
local instance of the server application. If it fails, generate an
appropriate error and pass that back to ldirectord. This is akin to
Joe's recommendation to RSH/SSH, but using a webserver instead.
	</para>
	</section>
	<section id="about_mon">
	<title>About Mon</title>
	<para>
Mon doesn't know anything about the LVS, it just detects the up/down
state of services on remote machines and will execute the commands
you tell it when the service changes state. We give Mon a script which
runs <command>ipvsadm</command> commands to remove services from the <command>ipvsadm</command> table when
a service goes down and another set of <command>ipvsadm</command> commands when the service
comes back up.
			</para><para>
Good things about Mon:
			</para><para>
<itemizedlist>
<listitem><para>It's independant of LVS, <emphasis>i.e.</emphasis> you can setup and debug the LVS without
Mon running.
</para></listitem><listitem><para>You can also test mon independantly of LVS.
</para></listitem><listitem><para>The monitors and the demon are independant.
</para></listitem><listitem><para>Most code is in perl (one of he "run anywhere" languages) and
code fixes are easy.
</para></listitem></itemizedlist>
			</para><para>
Bad things about Mon:
			</para><para>
<itemizedlist>
<listitem><para>I upgraded to 0.38.20 but it does't run properly.
I downgraded back to v0.37l. (Mar 2001 - Well I was running 0.37l.
I upgraded to perl5.6 and some of the monitors/alerts don't work anymore.
Mon-0.38.21 seems to work, with minor changes in the output and mon.cf file.)
</para></listitem><listitem><para>the author doesn't reply to e-mail.
</para></listitem></itemizedlist>
			</para><para>
mon-0.37l, keeps executing alerts every polling period following an up-down transition.
Since you want your service polled reasonable often (eg 15secs), this means you'll
be getting a pager notice/email every 15secs once a service goes down.
Tony Bassette <emphasis>kult (at) april (dot) org</emphasis> let me know that mon-0.38 has a numalert command
limiting the number of notices you'll get.
			</para><para>
Mon has no way of merging/layering/prioritising failure info.
If a node fails you get an avalanch of notices
that all the services on that node died too.
<blockquote><para>
Ted Pavlic <emphasis>tpavlic (at) netwalk (dot) com</emphasis> 2 Dec 2000
			</para><para>
    If you are careful, you can avoid this. For example, it is easy to write
a simple script (a super monitor)
which runs every monitor you want. This way only one message
is sent when one or more services goes down on a system.
Unless you specify the actual failure in the message,
you will bring the entire system goes down when one service fails.
			</para><para>
    There are other alternatives to make sure you only receive one notice
when a service goes down, but are you sure you would want that? What if
genuinely two services on a system go down but all the other services are
up? I, personally, would want to receive notifications about both services.
			</para><para>
    Ideally, what you want is a dependency setup. Most other system monitors
(like the popular "WhatsUp" by IpSwitch (or whatever they call themselves
now)) that will only send you one notification if, for example, the ICMP
monitor reports a failure. This functionality can also be easily built into
the monitors.
			</para><para>
    So the way I see it, mon is fine, but sometimes the monitors one uses
with mon might need a little work. Mon is nice because it is so versatile
and pluggable. It's modular and doesn't lock one into using some proprietary
scripting language to build monitors. Of course, this also makes it very
slow.
			</para><para>
    All of these things can be improved, of course, in a number of ways
which can be addressed and fixed one by one. However, most people have gone
with ldirectord, so mon, in this application, seems to really have been
forgotten. :(
			</para><para>
    I use mon and have been using it for a long time now and have no real
problems with it. My biggest problem was that both of my redundant
linuxdirectors notified me when things went down. I just wrote in a simple
addition to the mailto script which figured out if the machine on which it
was running was a master and if and ONLY if it was, it would send a message.
That solved that problem.
			</para><para>
    Now you should note that I have a made quite a few changes to mon to
make it more LinuxDirector-friendly. Rather than configuring mon through its
configuration scripts, I configure mon and <command>ipvsadm</command> all through some very
simple configuration files I use that control both equally. This required
quite a bit of hacking inside mon to get it to dynamically create
configuration data, but all of this modification isn't needed for the
average LVS-admin.
			</para><para>
    Abstract: mon ain't really that bad. If ldirectord was everything I'd
want it to be, it'd be mon.... consequence: I use mon. :)
</para></blockquote>
	</para>
	</section>
	<section id="mon_install">
	<title>Mon Install</title>
        <note>
		<para>
This writeup was done with early (<emphasis>ca.</emphasis> 1999) versions of mon.
Ken Brownfield (Mar 2006) has an updated version of the lvs.alert files
<ulink url="files/lvs.alert.tar.gz">lvs.alert.tar.gz</ulink>
		</para>
	</note>
	<para>
Mon is installed on the director.
Most of mon is a set of perl scripts. There are few files to be
compiled - it is mostly ready to go (rpc.monitor needs to be
compiled, but you don't need it for LVS).
You do the install by hand.
	</para>
<programlisting><![CDATA[
$ cd /usr/lib
$ tar -zxvof /your_dirpath/mon-x.xx.tar.gz
]]></programlisting>
	<para>
this will create the directory <filename>/usr/lib/mon-x.xx/</filename> 
with <filename>mon</filename> and its files already installed.
LVS comes with <filename>virtualserver.alert</filename> (goes in <filename>alert.d</filename>) and
<filename>ssh.monitor</filename> (goes in <filename>mon.d</filename>).
Make the directory <filename>mon-x.xx</filename> accessable as <filename>mon</filename> by linking it
to <filename>mon</filename> or by renaming it
	</para>
<programlisting><![CDATA[
$ln -s mon-x.xx mon
or
$mv mon-x.xx mon
]]></programlisting>
	<para>
Copy the man files (<filename>mon.1</filename> etc) into <filename>/usr/local/man/man1</filename>
aheck that you have the perl packages required for mon to run
	</para>
<programlisting><![CDATA[
$perl -w mon
]]></programlisting>
	<para>
do the same for all the perl <filename>alerts</filename> and <filename>monitors</filename> that you'll be
using (<filename>telnet.monitor, dns.monitor, http_t.monitor, ssh.monitor</filename>).
	</para>
	<para>
DNS in <filename>/etc/services</filename> 
is known as <filename>domain</filename> and <filename>nameserver</filename>, 
not as <filename>dns</filename>. 
To allow the use of the string <filename>dns</filename> in the
<filename>lvs_xxx.conf</filename> files and to enable the configure script
to autoinclude
the <filename>dns.monitor</filename>, add the string <filename>dns</filename> 
to the port 53 services in
<filename>/etc/services</filename> with an entry like
	</para>
<programlisting><![CDATA[
    domain		53/tcp		nameserver dns	# name-domain server
    domain		53/udp		nameserver dns
]]></programlisting>
	<para>
<filename>Mon</filename> expects executables to be in /bin, /usr/bin or /usr/sbin.
The location of perl in the alerts is <filename>#!/usr/bin/perl</filename> (and not
<filename>/usr/local/bin/perl</filename>) - make sure this is compatible with your
setup. (Make sure you don't have one version of perl in /usr/bin
and another in /usr/local/bin).
	</para>
	<para>
The configure script will generate the required <filename>mon.cf</filename> file for
you (and if you like copy it to the cannonical location of <filename>/etc/mon</filename>).
	</para>
	<para>
Add an <filename>auth.cf</filename> file to <filename>/etc/mon</filename>.
I use
	</para>
<programlisting><![CDATA[
#auth.cf ----------------------------------
# authentication file
#
# entries look like this:
# command: {user|all}[,user...]
#
# THE DEFAULT IS TO DENY ACCESS TO ALL IF THIS FILE
# DOES NOT EXIST, OR IF A COMMAND IS NOT DEFINED HERE
#

list:		all
reset:		root
loadstate:	root
savestate:	root
term:		root
stop:		root
start:		root
set:		root
get:		root
dump:		root
disable:	root
enable:		root

#end auth.cf ----------------------------
]]></programlisting>
	</section>
	<section id="mon_configure">
	<title>Mon Configure</title>
	<para>
This involves editing <filename>/etc/mon/mon.cf</filename>, which contains information
about
			</para><para>
<itemizedlist>
<listitem><para>nodes monitored
</para></listitem><listitem><para>how to detect if a node:service is up (does the node ping,
   does it serve http...?)
</para></listitem><listitem><para>what to do when the node goes down and what to do later when
   it comes back up.
</para></listitem></itemizedlist>
			</para><para>
The mon.cf generated by the configure script
			</para><para>
<itemizedlist>
<listitem><para> assigns each node to its own group (nodes are brought down one
   at a time rather than in groups - I did this because it was
   easier to code rather than for any good technical reason).
			</para><para>
</para></listitem><listitem><para>detects whether a node is serving some service (eg
   telnet/http) selecting, if possible, a monitor for that
   service, otherwise defaulting to fping.monitor which detects
   whether the node is pingable.
			</para><para>
</para></listitem><listitem><para>on failure of a realserver, mon sends mail to root (using
   mail.alert) and removes the realserver from the <command>ipvsadm</command> table
   (using virtualserver.alert).
			</para><para>
</para></listitem><listitem><para>on recovery sends mail to root (using mail.alert) and adds
   the realserver back to the pool of working realservers in the
   <command>ipvsadm</command> table (using virtualserver.alert).
</para></listitem></itemizedlist>
	</para>
	</section>
	<section id="testing_mon_without_lvs">
	<title>Testing mon without LVS</title><para>
The instructions here show how to get mon working in two steps.
First show that mon works independantly of LVS, then second bring
in LVS.
			</para><para>
The example here assumes a working LVS-DR with one realserver and
the following IPs. LVS-DR is chosen for the example here as you can
set up LVS-DR with all machines on the same network. This allows
you to test the state of all machines from the client (ie using
one kbd/monitor). (Presumably you could do it from the director
too, but I didn't try it.)
			</para><para>
<programlisting><![CDATA[
lvs IP (VIP): eth0 192.168.1.110
director:     eth0 192.168.1.1/24 (admin IP)
              eth0:1 192.168.1.110/32 (VIP)
realserver:   eth0 192.168.1.8/24
]]></programlisting>
			</para><para>
On the director, test ping.monitor (in /usr/lib/mon/mon.d) with
			</para><para>
<programlisting><![CDATA[
$ ./fping.monitor 192.168.1.8
]]></programlisting>
			</para><para>
You should get the command prompt back quickly with no other
output. As a control test for a machine that you know is not on
the net
			</para><para>
<programlisting><![CDATA[
$ ./fping.monitor 192.168.1.250
192.168.1.250
]]></programlisting>
			</para><para>
ping.monitor will wait for a timeout (about 5secs) and then
return the IP of the unpingable machine on exit.
			</para><para>
Check test.alert (in /usr/lib/mon/alert.d) - it writes a file in /tmp
			</para><para>
<programlisting><![CDATA[
$ ./test.alert foo
]]></programlisting>
			</para><para>
you will get the date and "foo" in
<filename>/tmp/test.alert.log</filename>
			</para><para>
As part of generating the <filename>rc.lvs_dr</filename> script, 
you will also have
produced the file <filename>mon_lvsdr.cf</filename>. 
To test mon, move <filename>mon_lvs.dr</filename> to <filename>/etc/mon/mon.cf</filename>
			</para><para>
<programlisting><![CDATA[
#------------------------------------------------------
#mon.cf
#
#mon config info, you probably don't need to change this very much
#

alertdir   = /usr/lib/mon/alert.d
mondir     = /usr/lib/mon/mon.d
#maxprocs    = 20
histlength = 100
#delay before starting
#randstart = 60s

#------
hostgroup LVS1 192.168.1.8

watch LVS1
#the string/text following service (to OEL) is put in header of mail messages
#service "http on LVS1 192.168.1.8"
service fping
	interval 15s
	#monitor http.monitor
	#monitor telnet.monitor
	monitor fping.monitor
	allow_empty_group
	period wd {Sun-Sat}
	#alertevery 1h
		#alert mail.alert root
		#upalert mail.alert root
		alert test.alert
		upalert test.alert
		#-V is virtual service, -R is remote service, -P is protocol, -A is add/delete (t|u)
		#alert virtualserver.alert -A -d -P -t -V 192.168.1.9:21 -R 192.168.1.8
		#upalert virtualserver.alert -A -a -P -t -V 192.168.1.9:21 -R 192.168.1.8 -T -m -w 1

#the line above must be blank

#mon.cf---------------------------
]]></programlisting>
			</para><para>
Now we will test mon on the realserver 192.168.1.8 independantly
of LVS. Edit /etc/mon/mon.cf and make sure that all the
monitors/alerts except for fping.monitor and test.alert are
commented out (there is an alert/upalert pair for each alert,
leave both uncommented for test.alert).
			</para><para>
Start mon with <filename>rc.mon</filename> (or S99mon)
Here is my <filename>rc.mon</filename> (copied from the mon package)
			</para><para>
<programlisting><![CDATA[
# rc.mon -------------------------------
# You probably want to set the path to include
# nothing but local filesystems.
#

echo -n "rc.mon "

PATH=/bin:/usr/bin:/sbin:/usr/sbin
export PATH

M=/usr/lib/mon
PID=/var/run/mon.pid

if [ -x $M/mon ]
	then
	$M/mon -d -c /etc/mon/mon.cf -a $M/alert.d -s $M/mon.d -f 2>/dev/null
	#$M/mon -c /etc/mon/mon.cf -a $M/alert.d -s $M/mon.d -f
fi
#-end-rc.mon----------------------------
]]></programlisting>
			</para><para>
After starting mon, check that mon is in the ps table (ps -auxw |
grep perl).  When mon comes up it will read mon.cf and then check
192.168.1.8 with the fping.monitor. On finding that 192.168.1.8
is pingable, mon will run test.alert and will enter a string like
			</para><para>
<programlisting><![CDATA[
Sun Jun 13 15:08:30 GMT 1999 -s fping -g LVS3 -h 192.168.1.8 -t 929286507 -u -l 0
]]></programlisting>
			</para><para>
into /tmp/test.alert.log. This is the date, the service (fping),
the hostgroup (LVS), the host monitored (192.168.1.8), unix time
in secs, up (-u) and some other stuff I didn't need to figure out
to get everything to work.
			</para><para>
Check for the "-u" in this line, indicating that 192.168.1.8 is up.
			</para><para>
If you don't see this file within 15-30secs of starting mon, then
look in /var/adm/messages and syslog for hints as to what failed
(both contain extensive logging of what's happening with mon).
(Note: syslog appears to be buffered, it may take a few more
secs for output to appear here).
			</para><para>
If neccessary kill and restart mon
			</para><para>
<programlisting><![CDATA[
$ kill -HUP `cat /var/run/mon.pid`
]]></programlisting>
			</para><para>
Then pull the network cable on machine 192.168.1.8.  In 15secs or
so you should hear the whirring of disks and the following entry
will appear in /tmp/test.alert.log
			</para><para>
Sun Jun 13 15:11:47 GMT 1999 -s fping -g LVS3 -h 192.168.1.8 -t 929286703 -l 0
			</para><para>
Note there is no "-u" near the end of the entry indicating that
the node is down.
			</para><para>
Watch for a few more entries to appear in the logfile, then
connect the network cable again. A line with -u should appear in
the log and no further entries should appear in the log.
			</para><para>
If you've got this far, mon is working.
			</para><para>
Kill mon and make sure root can send himself mail on the
director. Make sure sendmail can be found in /usr/lib/sendmail
(put in a link if neccessary).
			</para><para>
Next activate <filename>mail.alert</filename> and <filename>telnet.monitor</filename> in <filename>/etc/mon/mon.cf</filename>
and comment out <filename>test.alert</filename>. (Do not restart mon yet)
			</para><para>
Test <filename>mail.alert</filename> by doing
			</para><para>
<programlisting><![CDATA[
$ ./mail.alert root
hello
^D
]]></programlisting>
			</para><para>
root is the address for the mail, hello is some arbitrary STDIN
and controlD exits the <filename>mail.alert</filename>. Root should get some mail with
the string "ALERT" in the subject (indicating that a machine is
down).
			</para><para>
Repeat, this time you are sending mail saying the machine is up
(the "-u")
			</para><para>
<programlisting><![CDATA[
$ ./mail.alert -u root
hello
^D
]]></programlisting>
			</para><para>
Check that root gets mail with the string "UPALERT" in the
subject (indicating that a machine has come up).
			</para><para>
Check the <filename>telnet.monitor</filename> on a machine on the net. You will need
tcp_scan in a place that perl sees it. I moved it to /usr/bin.
Putting it in /usr/local/bin (in my path) did not work.
			</para><para>
<programlisting><![CDATA[
$ ./telnet.monitor 192.168.1.8
]]></programlisting>
			</para><para>
the program should exit with no output.  Test again on a machine
not on the net
			</para><para>
<programlisting><![CDATA[
$ ./telnet.monitor 192.168.1.250
192.168.1.250
]]></programlisting>
			</para><para>
the program should exit outputting the IP of the machine not on
the net.
			</para><para>
Start up mon again (eg with <filename>rc.mon</filename> or S99mon), watch for one
round of mail sending notification that telnet is up (an
"UPALERT) (note: for mon-0.38.21 there is no initial UPALERT).
There should be no further mail while the machine
remains telnet-able.  Then pull the network cable and watch for
the first ALERT mail. Mail should continue arriving every mon
time interval (set to 15secs in <filename>mon_lvs_test.cf</filename>). Then plug the
network cable back in and watch for one UPALERT mail.
			</para><para>
If you don't get mail, check that you re-edited <filename>mon.cf</filename> properly
and that you did kill and restart mon (or you will still be
getting <filename>test.alerts</filename> in /tmp). Sometimes it takes a few seconds
for mail to arrive. If this happens you'll get an avalanche when
it does start.
			</para><para>
If you've got here you are really in good shape.
			</para><para>
Kill mon (kill `cat /var/run/mon.pid`)
	</para>
	</section>
	<section id="alert_sending_commands_to_LVS">
	<title>Can virtualserver.alert send commands to LVS?</title>
	<para>
(virtualserver.alert is a modified version of Wensong's orginal
file, for use with 2.2 kernels. I haven't tested it back with a
2.0 kernel. If it doesn't work and the original file does, let me
know)
			</para><para>
run virtualserver.alert (in /usr/lib/mon/alert.d) from the
command line and check that it detects your kernel correctly.
			</para><para>
$ ./virtualserver.alert
			</para><para>
you will get complaints about bad ports (which you can ignore,
since you didn't give the correct arguments). If you have kernel
2.0.x or 2.2.x you will get no other output.  If you get unknown
kernel errors, send me the output of `uname -r`. Debugging print
statements can be uncommented if you need to look for clues here.
			</para><para>
Make sure you have a working LVS-DR LVS serving telnet on a
realserver. If you don't have the telnet service on realserver
192.168.1.8 then run
			</para><para>
$ipvsadm -a -t 192.168.1.110:23 -r 192.168.1.8
			</para><para>
then run <command>ipvsadm</command> in one window.
			</para><para>
$ipvsadm
			</para><para>
and leave the output on the screen. In another window run
			</para><para>
$ ./virtualserver.alert   -V 192.168.1.110:23 -R 192.168.1.8
			</para><para>
this will send the down command to ipvsadm. The entry for telnet
on realserver 192.168.1.8 will be removed (run <command>ipvsadm</command> again).
			</para><para>
Then run
			</para><para>
$ ./virtualserver.alert -u -V 192.168.1.110:23 -R 192.168.1.8
			</para><para>
and the telnet service to 192.168.1.8 will be restored in the
director:/etc/lvs# ipvsadm table.
	</para>
	</section>
	<section id="mon_with_lvs">
	<title>Running mon with LVS</title>
	<para>
Connect all network connections for the LVS and install a LVS-DR
LVS with INITIAL_STATE="off" to a single telnet realserver. Start
with a file like lvs_dr.conf.single_telnet_off adapting the IP's
for your situation and produce the mon_xxx.cf and rc.lvs_xxx
file. Run rc.lvs_xxx on the director and then the realserver.
			</para><para>
The output of <command>ipvsadm</command> (on the director) should be
			</para><para>
<programlisting><![CDATA[
grumpy:/etc/mon# ipvsadm
IP Virtual Server (Version 0.9)
Protocol Local Address:Port Scheduler
      -> Remote Address:Port   Forward Weight ActiveConn FinConn
TCP 192.168.1.110:23 rr
]]></programlisting>
			</para><para>
showing that the scheduling (rr) is enabled, but with no entries
in the <command>ipvsadm</command> routing table. You should NOT be able to telnet
to the VIP (192.168.1.110) from a client.
			</para><para>
Start mon (it's on the director). Since the realserver is already
online, mon will detect a functional telnet on it and trigger an
upalert for mail.alert and for virtualserver.alert. At the same
time as the upalert mail arrives run <command>ipvsadm</command> again. You should
get
			</para><para>
<programlisting><![CDATA[
grumpy:/etc/mon# ipvsadm
IP Virtual Server (Version 0.9)
Protocol Local Address:Port Scheduler
      -> Remote Address:Port   Forward Weight ActiveConn FinConn
TCP 192.168.1.110:23 rr
      -> 192.168.1.8:23        Route   1      0          0
]]></programlisting>
			</para><para>
which shows that mon has run <command>ipvsadm</command> and added direct routing of
telnet to realserver 192.168.1.8. You should now be able to
telnet to 192.168.1.110 from a client and get the login prompt
for machine 192.168.1.8.
			</para><para>
Logout of this telnet session, and pull the network cable to the
realserver. You will get a mail alert and the entry for
192.168.1.8 will be removed from the <command>ipvsadm</command> output.
			</para><para>
Plug the network cable back in and watch for the upalert mail and
the restoration of LVS to the realserver (run <command>ipvsadm</command> again).
			</para><para>
If you want to, confirm that you can do this for http instead of
telnet.
			</para><para>
You're done. Congratulations. You can use the mon_xxx.cf files
generated by the configure script from here.
	</para></section>
	<section id="agent"><title>Why is the LVS monitored for failures/load by an external agent rather than by the kernel?</title><para>
<blockquote><para>
Patrick Kormann <emphasis>pkormann (at) datacomm (dot) ch</emphasis>
			</para><para>
Wouldn't it be nice to have a
switch that would tell <command>ipvsadm</command> 'If one of the realservers is
unreachable/connection refused, take it out of the list of realservers for
x seconds' or even 'check the availability of that server every x seconds,
if it's not available, take it out of the list, if it's available again, put
it in the list'.
</para></blockquote>
			</para><para>
Lars
			</para><para>
That does not belong in the kernel. This is definetely the job of a userlevel
monitoring tool.
			</para><para>
I admit it would be nice if the LVS patch could check if connections directed
to the realserver were refused and would log that to userlevel though, so we
could have even more input available for the monitoring process.
			</para><para>
<blockquote><para>
 and quirks to make lvs a real high-availability system. The problem is that
 all those external checks are never as effective as a decition be the
 'virtual server' could be.
</para></blockquote>
			</para><para>
That's wrong.
			</para><para>
A userlevel tool can check reply times, request specific URLs from the servers
to check if they reply with the expected data, gather load data from the real
servers etc. This functionality is way beyond kernel level code.
			</para><para>
<blockquote><para>
Michael Sparks <emphasis>zathras (at) epsilon3 (dot) mcc (dot) ac (dot) uk</emphasis>
			</para><para>
Personally I think monitoring of systems is probably one of the things the
lvs system shouldn't really get into in it's current form. My rationale
for this is that LVS is a fancy packet forwarder, and in that
job it excels.
			</para><para>
For the LVS code to do more than this, it would require for TCP services
the ability to attempt to connect to the *service* the kernel is load
balancing - which would be a horrible thing for a kernel module to do. For
UDP services it would need to do more than pinging...  However, in neither
case would you have a convincing method for determining if the *services*
on those machines was still running effectively, unless you put a large
amount of protocol knowledge into the kernel. As a result, you would
still need to have external monitoring systems to find out whether the
services really are working or not.
			</para><para>
For example, in the pathological case (of many that we've seen :-) of a
SCSI subsystem failure resulting in indestructable inodes on a cache box,
a cache box can reach total saturation in terms of CPU usage, but still
respond correctly to pings and TCP connections. However nothing else (or
nothing much) happens due to the effective system lockup. The only way
round such a problem is to have a monitoring system that knows about this
sort of failure, and can then take the service out.
			</para><para>
There's no way this sort of failure could be anticipated by anyone, so
putting this sort of monitoring into the kernel would create a false
illusion of security - you'd still need an auxillary monitoring system.
Eg - it's not just enough for the kernel to mark the machine out of
service - you need some useful way of telling people what's gone wrong (eg
setting off people's pager's etc), and again, that's not a kernel thing.
</para></blockquote>
			</para><para>
Lars
			</para><para>
Michael, I agree with you.
			</para><para>
However, it would be good if LVS would log the failures it detects. ie, I
_think_ it can notice if a client receives a port unreachable in response to a
forwarded request if running masquerading, however it cannot know if it is
running DR or tunneling because in that case it doesn't see the reply to the
client.
			</para><para>
<blockquote><para>
 _think_ it can notice if a client receives a port unreachable in response to a
</para></blockquote>
			</para><para>
Wensong
			</para><para>
Currently, the LVS can handle ICMP packets for virtual services, and
forward them to the right place. It is easy to set the weight of the
destination zero or temperarily remove the dest entry directly, if an
PORT_UNREACH icmp from the server to the client passes through the LVS
box.
			</para><para>
If we want the kernel to notify monitoring software that a realserver
is down in order to let monitoring software keep consistent state of
virtual service table, we need design efficient way to notify
monitoring, more code is required. Anyway, there is a need to develop
efficient communication between the LVS kernel and monitoring software,
for example, monitoring software get the connection number efficiently,
it is time-consuming to parse the big IPVS table to get the connection
numbers; how to efficiently support ipvsadm -L &lt;protocol, ip, port&gt;? it
is good for applications like Ted's 1024 virtual services. I checked the
procfs code, it still requires one write_proc and one read_proc to get
per virtual service print, it is a little expensive. Any idea?
			</para><para>
<blockquote><para>
 Currently, the LVS can handle ICMP packets for virtual services, and
 forward them to the right place. It is easy to set the weight of the
 destination zero or temperarily remove the dest entry directly, if an
 PORT_UNREACH icmp from the server to the client passes through the LVS
 box.
</para></blockquote>
			</para><para>
Julian Anastasov <emphasis>uli (at) linux (dot) tu-varna (dot) acad (dot) bg</emphasis>
			</para><para>
        PORT_UNREACH can be returned when the packet is rejected from the
realserver's firewall. In fact, only UDP returns PORT_UNREACH when the
service is not running. TCP returns RST packet. We must carefully handle
this (I don't know how) and not to stop the realserver for all clients if
we see that one client is rejected. And this works only if the LVS box is
default gw for the realservers, i.e. for any mode: MASQ(it's always def
gw), DROUTE and TUNNEL (PROT_UNREACH can be one of the reasons not to
select other router for the outgoing traffic for these two modes). But LVS
cn't detect the outgoing traffic for DROUTE/TUNNEL mode. For TUNNEL it can
be impossible if the realservers are not on the LAN.
			</para><para>
        So, the monitoring software can solve more problems. The TCP stack
can return PORT_UNREACH but if the problem with the service in the real
server is more complex (realserver died, daemon blocked) we can't expect
PORT_UNREACH. It is send only when the host is working but the daemon is
stooped. Please restart this daemon. So, don't rely on the realserver,
in most of the cases he can't tell  "Please remove me from the VS
configuration, I'm down" :) This is job for the monitoring software to
exclude the destinations and even to delete the service (if we switch to
local delivery only, i.e. when we switch from LVS to WEB only mode for
example). So, I vote for the monitoring software to handle this :)
			</para><para>
Wensong
			</para><para>
Yeah, I prefer that monitoring software handles this too, because it
is a unified approach for LVS-NAT, LVS-Tun and LVS-DR, and monitoring
software can detect more failures and handle more things according to
the failures.
			</para><para>
What we discuss last time is that the LVS kernel sets the destination
entry unavailable in virtual server table if the LVS detect some icmp
packets (only for LVS-NAT) or RST packet etc. This approach might
detect this kinds of problems just a few seconds earlier than the
monitoring software, however we need more code in kernel to notify the
monitoring software that kernel changes the virtual server table, in
order to let the monitoring software keep the consistent view of the
virtual server table as soon as possible. Here is a tradeoff.
Personally, I prefer to keeping the system simple (and effective),
only one (monitoring software) makes decision and keeps the consistent
view of VS table.
	</para>
	</section>
	<section id="running_multiple_directors">
	<title>Running multiple directors (each with their own IP)</title>
	<para>
On a normal LVS (one director, multiple realservers being failed-over
with mon), the single director is a SPOF (single point of failure).
Director failure can be handled (in principle) with heartbeat.
In the meantime, you can have two directors
each with their own VIP known to the users and set them up to talk to
the same set of realservers. (You can have two VIP's on one director
box too).
	</para>
	<para>
Michael Sparks <emphasis>michael (dot) sparks (at) mcc (dot) ac (dot) uk</emphasis>
	</para>
	<blockquote>
Also has anyone tried this using 2 or more masters - each master with it's
own IP? (*) From what I can see theoretically all you should have to do is
have one master on IP X, tunneled to clients who recieve stuff via tunl0,
and another master on IP Y, tunneled to clients on tunl1 - except when I
just tried doing that I can't get the kernel to accept the concept of a
tunl1... Is this a limitation of the IPIP module ???
	</blockquote>
	<para>
Stephen D. WIlliams <emphasis>sdw (at) lig (dot) net</emphasis>
	</para>
	<para>
Do aliasing. I don't see a need for tunl1. In fact, I just throw
a dummy address on tunl0 and do everything with tunl0:0, etc.
	</para>
	<para>
We plan to run at least two LinuxDirector/DR systems with
failover for moving the two (or more) public IP's between the
systems. We also use aliased, movable IP's for the realserver
addresses so that they can failover also.
	</para>
	</section>
	<section id="scripts_demarco">
	<title>Mon scripts from Christopher DeMarco</title>
	<para>
Christopher DeMarco <emphasis>cdemarco (at) fastmail (dot) fm</emphasis> 27 Jul 2004 
	</para>
	<para>
I'm not running heartbeat at the site in question, and wasn't thrilled
about setting  it up between the director  and two  realservers.  More
importantly,  Mon is generalizable  to  an org-wide monitoring  system
(which heartbeat is  not).   Mon has  a wider  range of service  check
scripts and alerts than ldirectord has and is therefore more flexible.
If somebody wanted to monitor ipvs but take action ONLY by alpha pager
(i.e.  *not* modifying ipvs) then  Mon would be  more appropriate than
ldirectord.
	</para>
	<itemizedlist>
		<listitem>
<ulink url="files/demarco_ipvs.monitor">ipvs.monitor</ulink>:
Checks whether the specified virtual service is defined, and,
optionally, whether it has any realservers defined.
		</listitem>
		<listitem>
<ulink url="files/demarco_ipvs.alert">ipvs.alert</ulink> :
Brings virtual services and realservers up and down.
		</listitem>
	</itemizedlist>
	</section>
</section>
<section id="LVS-HOWTO.Mueller-HA" xreflabel="setting up Linux-HA from rpms">
<title>LVS: Setting up Linux-HA for directors (mostly by using rpms)</title>
<note>
<para>
Mar 2003:
I had difficultly with the scripts provided with Heartbeat and wrote my
own.
I haven't written them up as I expect I'll put any spare time
into Alexandre's
<xref linkend="keepalived_vrrpd"/>
which automatically handles the arp-caching problem of failover.
Ard van Breeman had trouble too and has IPaddr script is included
<link linkend="IPaddr">below</link>
</para>
</note>

<para>
This was posted to the mailing list by Peter Mueller
Peter Mueller <emphasis>pmueller (at) sidestep (dot) com</emphasis> on 17Sep2001.
(The original was in html with DOS carriage control.
I've converted it by hand. There may be some parsing errors. Joe)
</para>

<para>
original mon files from Juri,
data posted from personal experience or mailing list (linux-ha or LVS) or
respective websites.
</para>

<para>
urls
</para>

<itemizedlist>
	<listitem>
<ulink url="http://www.kernel.org/pub/software/admin/mon/html/">mon</ulink>
	</listitem>
	<listitem>
<ulink url="http://www.ultramonkey.org/">ultramonkey</ulink>
	</listitem>
	<listitem>
<ulink url="http://www.linux-ha.org/download/GettingStarted.html">
getting started with Linux-HA</ulink>
	</listitem>
</itemizedlist>
<note>
<para>
these scripts assume mon 0.99.2.  For simplicity in install I
downloaded mon-0.38rpm (couldn't find new 0.99.2 rpm) and upgraded to 0.99.2
via source.  I then changed appropriate lines in /etc/rc.d/init.d/mon.
</para>
</note>
	<section id="linux_ha_mini_howto">
	<title>linux-ha howto</title>
	<para>
This document is a mini how-to get heartbeat working between two
individually working LVS boxes.  It is certainly not intended to be
all-encompasing document detailing everything imagineable.  What it is
intended to deliver is an 'essential steps' to getting LVS-HA
functional.  And you definitely should have two individually
functioning boxes before even attempting this.  (Yes, go back and test
your setup with each box to insure it works!).
			</para><para>
Another important note to add is that I have only tested this setup
with Ultramonkey RPMs.  I don't know if your setup will work.  I
wouldn't trust this document unless you do the same.  (I would be
interested in knowing if the HA features are the same for all
'heartbeat' setups..)
			</para><para>
PS. - apologies if this document is RedHat biased, I'm running from
VALinux boxes that are RedHat configured.
	</para></section>
	<section><title>Fix the (possible) ethernet alias issue.</title><para>
By now you've setup a dummy alias device on each LVS box (most likely
eth0:0).  This alias device is unecessary and potentially problematic
in the HA-setup.  The reason for this is that the heartbeat software
(/etc/ha.d/resource.d/) actually creates a new eth0:0 device on the
active box. If you have an eth0:0 (or whatever) alias configured for
your VIP on the standby director box, you might get a " VSbox2 kernel:
Uh Oh, MAC address 00:02:B3:03:9A:13 claims to have our IP address
(vip.ip.goes.here) (duplicate IP conflict likely)" error!  Not good...
			</para><para>
If I were you I'd move your alias script out of your
/etc/sysconfig/network-scripts/ directory and restart networking to
clear out that alias. Alternatively, if you are using shell scripts
then you should modify those to not control alias ips.
	</para></section>
	<section id="multiple_VIPs_2"><title>Configure /etc/ha.d/. files.</title><para>
<itemizedlist>
<listitem><para> authkeys
			</para><para>
authkeys MUST be permission-set to 600 or 400 from what I have read.
Be sure this is the case.  authkeys should contain something like
<programlisting><![CDATA[
auth 2
#1 crc
2 sha1 passwordhere
#3 md5 Hello!
]]></programlisting>
			</para><para>
Since you want to make sure this file is the same on both machines, get
it setup on one box and scp or ftp the file over to the other.
			</para><para>
</para></listitem><listitem><para>haresources
			</para><para>
haresources is convoluted to understand until you have a working setup.
The example config show things like :
			</para><para>
<programlisting><![CDATA[
#just.linux-ha.org	135.9.216.110 httpa
]]></programlisting>
when something like :
primary.director.box.goes.here shared.resources.address.here http
<programlisting><![CDATA[
#vs1.foo.com vip.foo.com http # <-- put actual IP down instead of vip.foo.com
vs1.foo.com IPaddr::10.10.10.10 ldirectord::ldirectord.cf # <-- if you use ldirector like this
# multiple VIP example follows
# vs1.so.com IPaddr::10.10.10.10 IPaddr::10.10.10.254 ldirectord::ldirectord.cf
]]></programlisting>
			</para><para>
It's important to note that the box listed in the first box is
considered the 'primary' director box and usually takes control in the
event of uncertainty.  (Definitely look at nice_failback in ha.cf if
you're interested in this thread).
			</para><para>
</para></listitem><listitem><para>ha.cf
			</para><para>
high-availability configuration file.  yep, looks like the meat of the
subject!  I'll just post my config, which assumes you use ttyS0 and
eth0 for your links to the other director.
			</para><para>
<programlisting><![CDATA[
#       File to wirte debug messages to debugfile /var/log/ha-debug
#       File to write other messages to logfile /var/log/ha-log
#       Facility to use for syslog()/logger logfacility     local0
#       keepalive: how many seconds between heartbeats
keepalive 1
#       deadtime: seconds-to-declare-host-dead
deadtime 20
#       hopfudge maximum hop count minus number of nodes in config
#hopfudge 1
#       serial  serialportname ...
serial  /dev/ttyS0
#       Only for serial ports.  It applies to both PPP/UDP and "raw" ports
#       This means run PPP over ports ttyS1 and ttyS2
#       Their respective IP addresses are as listed.
#       Note that I enforce that these are local addresses.
#	Other addresses are almost certainly a mistake.
#ppp-udp        /dev/ttyS1 10.0.0.1 /dev/ttyS2 10.0.0.2
#       Baud rate for both serial and ppp-udp ports...
baud    19200
#       What UDP port to use for udp or ppp-udp communication?
udpport 694
#       What interfaces to heartbeat over?
udp     eth0
#       Watchdog is the watchdog timer.
#	If our own heart doesn't beat for
#       a minute, then our machine will reboot.
#watchdog /dev/watchdog
#       Nice_failback sets the behavior when performing a failback:
#
#       - if it's on, when the primary node starts or comes back from any
#         failure and the cluster is already active, i.e. the secondary
#         server performed a failover, the primary stays quiet, acting as a
#         secondary.  This way some operations like syncing disks can be
#         easily done.
#       - if it's off (default), the primary node will always be the primary,
#         whenever it's powered on.
nice_failback off		# <-- might want to turn this on after you get things working
#       Tell what machines are in the cluster
#       node    nodename ...    -- must match uname -n
node    vs1.foo.com	# <-- must match uname -n !
node    vs2.foo.com	# <-- must match uname -n !
]]></programlisting>
</para></listitem></itemizedlist>
	</para></section>
	<section>
	<title>Stop ldirectord from starting, ensure heartbeat starts on reboot</title>
	<para>
<programlisting><![CDATA[
/etc/rc.d/init.d/ldirectord stop.
/usr/sbin/chkconfig --level 2345 ldirectord off
/usr/sbin/chkconfig --level 345 heartbeat on # <-- run on whatever init levels you want
]]></programlisting>
	</para></section>
	<section>
	<title>starting heartbeat and verifying functionality</title><para>
At this point you should have linux-director NOT
running on both boxes.  If you type ipvsadm -L on either box you should get:
<programlisting><![CDATA[
[root@vs1 ha.d]# ipvsadm -L
IP Virtual Server version 0.9.11 (size=3D4096)
Prot LocalAddress:Port Scheduler Flags
  -> RemoteAddress:Port          Forward Weight ActiveConn InActConn
]]></programlisting>
			</para><para>
Now start up heartbeat.  tail /var/log/messages, and /var/log/ha-log
for important log information.  My /var/log/messages looks like :
			</para><para>
<programlisting><![CDATA[
Apr 24 13:12:38 vs1 heartbeat[2070]: Configuration validated. Starting heartbeat.
Apr 24 13:12:39 vs1 heartbeat[2075]: Starting serial heartbeat on tty /dev/ttyS0
Apr 24 13:12:39 vs1 heartbeat[2075]: UDP heartbeat started on port 694 interface eth0
Apr 24 13:12:39 vs1 heartbeat[2077]: node vs1.internal.smartbasket.com -- link eth0: status up
Apr 24 13:12:39 vs1 heartbeat[2077]: node stage-monitor -- link /dev/ttyS0: status up
Apr 24 13:12:39 vs1 heartbeat[2077]: node stage-monitor -- link eth0: status up
]]></programlisting>
			</para><para>
And a quick check of ifconfig on the primary director shows the alias
interface (eth0:0) appears.  Note that eth0:0 is *NOT* present when
heartbeat isn't running.
<programlisting><![CDATA[
[root@vs1 ha.d]# ifconfig -a
eth0      Link encap:Ethernet  HWaddr 00:02:B3:06:B6:45 =20
          inet addr:10.0.1.5  Bcast:10.0.1.255  Mask:255.255.255.0
          UP BROADCAST RUNNING MULTICAST  MTU:1500  Metric:1
          RX packets:106550 errors:0 dropped:0 overruns:0 frame:0
          TX packets:75338 errors:0 dropped:0 overruns:0 carrier:0
          collisions:0 txqueuelen:100=20
          Interrupt:10 Base address:0xd000=20

eth0:0    Link encap:Ethernet  HWaddr 00:02:B3:06:B6:45 =20
          inet addr:10.0.1.10  Bcast:10.0.1.255  Mask:255.255.255.0
          UP BROADCAST RUNNING MULTICAST  MTU:1500  Metric:1
          Interrupt:10 Base address:0xd000=20
]]></programlisting>
			</para><para>
A ps aux on the active director shows :
			</para><para>
<programlisting><![CDATA[
root      1648  0.0  0.1  1444  868 ttyS0    SL   13:17   0:00 /usr/lib/heartbeat/heartbeat
root      1650  0.0  0.1  1332  748 ttyS0    SL   13:17   0:00 /usr/lib/heartbeat/heartbeat
root      1651  0.0  0.1  1332  736 ttyS0    SL   13:17   0:00 /usr/lib/heartbeat/heartbeat
root      1652  0.0  0.1  1328  736 ttyS0    S    13:17   0:00 /usr/lib/heartbeat/heartbeat
root      1653  0.0  0.1  1332  732 ttyS0    SL   13:17   0:00 /usr/lib/heartbeat/heartbeat
root      1654  0.0  0.1  1328  728 ttyS0    S    13:17   0:00 /usr/lib/heartbeat/heartbeat
root      1775  0.0  0.8  5352 4388 ttyS0    S    13:17   0:00 perl /etc/ha.d/resource.d/ldirectord ldir
root      1869  0.0  0.1  2344  724 pts/0    R    13:20   0:00 ps aux
]]></programlisting>
	</para></section>
	<section>
	<title>Test your fail-over features, understand HA.</title>
	<para>
At this point you should test around your failover functionality and
learn how your setup works.  You also need to customize your ha.cf file
to the specifications for your site.
	</para>
	<para>
As noted in the 'getting started' document mentioned in the url section
above, be certain to NOT yank all heartbeat medium cables at once! This will
cause a 'split brain' scenario and you won't be happy! Test failover
possibilities one at a time, or catastrophically!
	</para>
	</section>
	<section>
	<title>Configuration of mon - recommended</title>
	<itemizedlist>
	<listitem>
	<para>
add lines to <filename>/etc/services</filename>
	</para>
<programlisting><![CDATA[
mon             2583/tcp                        # MON
mon             2583/udp                        # MON traps
]]></programlisting>
	</listitem>
	<listitem>
	<para>
install Perl modules
	</para><para>
get modules,files from 10.0.0.34 ftp, directory /mon, install.
	</para><para>
Convert-BER, Period, Time-HiRes, Mon, fping
	</para>
	</listitem>
	<listitem>
	<para>
	convert headers into perl headers
	</para>
<programlisting><![CDATA[
cd /usr/include
h2ph *.h sys/*.h asm/*.h
]]></programlisting>
	</listitem>
	<listitem>
	<para>
install mon-rpm
	</para><para>
to get <filename>/etc/rc.d/init.d/mon</filename> and other nice features
automate-installed. afterwards update to the latest source available
to get bug fixes. I recommend untarring in <filename>/usr/src/mon-x</filename> and
symlinking that directory to <filename>/usr/src/mon</filename> for simplicity and ease of
upgrade.
	</para>
	</listitem>
	<listitem>
<para>
install mon.cf file into /etc/mon/
	</para><para>
modify if appropriate (ie,
change the gateway that it monitors). the mon.cf file contains lots
of configuration options which you should be familiar with, such as log
locations. Example included below.
	</para>
	</listitem>
	<listitem>
<para>
copy any specific monitors from staging or production to
your new box.
	</para><para>
In this example we are using a few extraneous monitors :
fping.monitor, pid.monitor, heartbeat.alert, and
restartheartbeat.alert.  all '.monitor' files go in the 'mon.d' folder,
and all '.alert' files go in the alert.d folder.
	</para>
	</listitem>
	<listitem>
<para>
change the /etc/rc.d/init.d/mon file to point to appropriate paths
	</para><para>
change /usr/lib/mon to /usr/src/mon and the cf line to
/etc/mon/mon.cf.  (either that or copy from a working server).
	</para>
	</listitem>
	<listitem>
<para>
make sure a copy of fping is in the restricted path solicited by
/etc/rc.d/init.d/mon.
	</para><para>
 one way of fixing this is via a simple 'cp
/usr/local/sbin/fping /usr/sbin' (or /usr/local/bin or anywhere in your
path).
	</para>
	</listitem>
	<listitem>
<para>
create /etc/mon/monusers.cf.
			</para><para>
Instructions in man file (man mon).
			</para>
<programlisting><![CDATA[
#!/bin/bash
# example heartbeat.alert from Juri
# Script to start/stop heartbeat daemon
# Put a line like
# alert heartbeat.alert
# or
# upalert heartbeat.alert
# in your mon config file

HEARTBEAT="/etc/rc.d/init.d/heartbeat"
if [ $9 = "-u" ]; then
	$HEARTBEAT start
else
	$HEARTBEAT stop
fi
]]></programlisting>

<programlisting><![CDATA[
#!/bin/sh
# example pid.mon from Juri
# Script for mon to check wether a process is running or not.
# Invoke with
# monitor pid.monitor process

/sbin/pidof -s $1 > /dev/null 2>&1

if [ $? -eq "0" ]; then
	echo "$1 running"
	exit 0
else
	echo "$1 not running"
	exit 1
fi
]]></programlisting>

<programlisting><![CDATA[
# Sample mon.cf configuration file for mon, originally from Juri
#
# You have to restart mon after editing this file in order for your
# changes to take effect.

authtype	=	userfile
userfile	=	/etc/mon/monusers.cf
cfbasedir	=	/etc/mon
alertdir	=	/usr/src/mon/alert.d
mondir		=	/usr/src/mon/mon.d
logdir		=	/var/log/mon
dtlogfile	=	/var/log/mon/downtime
dtlogging	=	yes
historicfile	=	/var/log/mon/history
maxprocs	=	20
histlength	=	100
monerrfile	=	/var/log/mon/errfile

# Hostgroup entries
#hostgroup node1 stage-monitor
#
#hostgroup node2 vs1
#
hostgroup gateway 10.0.1.2

#hostgroup heartbeat localhost


###########
# Gateway #
###########

watch gateway
	service fping
		interval 10s
		monitor fping.monitor
		#comp_alerts	<-- default starting in mon 0.99.1
		period NORMAL: wd {Sun-Sat}
			numalerts 1
			alertafter 3
			alert heartbeat.alert
			upalert restartheartbeat.alert # read mon file

#############
# Heartbeat #
#############

#watch heartbeat
#	service heartbeat
#		interval 15s
#		monitor pid.monitor /usr/lib/heartbeat/heartbeat
#		depend gateway:fping
#		dep_behavior m
#		period NORMAL: wd {Sun-Sat}
#			#alert restartheartbeat.alert
#			upalert heartbeat.alert

##############
# First node #
##############
#
#watch node1
#	service http
#		interval 10s
#		monitor http.monitor
#		period NORMAL: wd {Sun-Sat}
#			alert restart.alert httpd ;;
#		period ADVANCED: wd {Sun-Sat}
#                       alert mail.alert root
#			alert reboot.alert
#			alertafter 3
#			alertevery 1m
# Example for testing disk operations
#	service disk
#		interval 10s
#		monitor nfs.monitor /vol/shared/0/ ;;
#		period wd {Sun-Sat}
#                        alert mail.alert -s 'REBOOT: Disk not responding!' root
#			alert hardreboot.alert
#			alertafter 2
#			alertevery 1m
# Example for testing rpc based services such as nfs, nis etc.
#	service rpc
#		interval 10s
#		monitor rpc.monitor -r mountd -r nfs
#		period wd {Sun-Sat}
#                        alert mail.alert root
#			alertafter 2
#                        alertevery 1m
###############
# Second node #
###############
#
#watch node2
# Example for testing disk operations
#	service disk
#		interval 10s
#		monitor nfs.monitor /tmp ;;
#		period wd {Sun-Sat}
#                       alert mail.alert root
#			alert hardreboot.alert
#			alertafter 2
#			alertevery 1m
# Example for testing samba
#	service samba
#		interval 15s
#		monitor tcp.monitor -p 139 localhost
#		period wd {Sun-Sat}
#                        alert restart.alert smb
#		period ADVANCED: wd {Sun-Sat}
#                        alert mail.alert root
#			alert reboot.alert
#			alertafter 3
#			alertevery 1m
]]></programlisting>
		</listitem>
	</itemizedlist>
	</section>
</section>
<section id="LVS-HOWTO.heartbeat" xreflabel="heartbeat">
<title>LVS: Director failover using heartbeat</title>
	<section id="heartbeat_intro">
	<title>Introduction</title>
	<para>
Heartbeat is a component of the Linux-HA code.
This section describes setup of heartbeat.
There is a writeup
on <xref linkend="LVS-HOWTO.Mueller-HA"/> elsewhere here.
	</para>
	</section>
	<section id="heartbeat_serial_ethernet">
	<title>On using serial and ethernet connections for heartbeat</title>
	<para>
Here are comments
I picked up from mostly from the Linux-HA mailing list
	</para>
	<para>
on using serial and/or ethernet heartbeat
	</para>
	<para>
anon
	</para>
	<blockquote>
		<para>
I have successfully setup a 2 node HA solution.
The heartbeat is establishes vie ttyS0 and eth1.
Both nodes have specific tasks and take over the tasks of the other
node if something wents wrong.
Now I have a few questions:
		</para>
		<para>
I think a serial line is the last thing that goes down when
anything wents wrong. So it could be possible that all network
services die and the node is still considered to be up and running
if ttyS0 still provides heartbeat.
In this case I have a half dead node with no network but the 2nd node
won't takeover. Now I could only use heartbeat on eth1 or even eth0 but
this setup is, according to the howto's, not the best.
		</para>
	</blockquote>
	<para>
Lorn Kay <emphasis>lorn_kay (at) hotmail (dot) com</emphasis> 02 Jul 2002
	</para>
	<para>
It can cause a failover when the only problem is a NIC failure. Depending on
your app. this may not be a good thing. High network traffic can also clog
the network path for the heartbeats and start a failover when you don't want
one. (See past postings on the list from Alan for how to tune heartbeat to
avoid this problem).
	</para>
	<para>
I believe the design philosophy of heartbeat [someone please correct me if
I'm wrong] is that heartbeats are distinct from resource monitoring.
Heartbeat's job is simply to listen to heartbeats and only decide if the
other server is dead or alive (true to its name "heartbeat").
	</para>
	<para>
It is considered a hack to run heartbeats on the public or resource network
and use them to detect a failure of a resource. Resource monitoring (at the
moment) needs to be handled by another program like "mon".
	</para>
	<blockquote>
I also tried to use the softdog module, but I don't quite know when it
should be used. So I can't test that.
The nicest thing would be to tell heartbeat what it should do if only
the ttyS0 is up and everything else is down.
Or better, that it should check the ip's it should take over and if the IP
doesn't respond it should take it (?)
	</blockquote>
	<para>
A design principle of HA systems (per "Blueprints for High Availability:
Designing Resilient Distributed Systems") is three distinct paths to the
servers: resource-path (or public path), heartbeat, and administrative.
However, having said all this, I still think a simple one-nic server
configuration with all three paths configured as virtual (IP alias) paths
over one NIC makes sense in some situations. If the NIC goes down (in these
cases) then failover is a good thing. It is also easier to configure
heartbeat by itself than heartbeat+mon.
	</para>
	<para>
Maybe someone on the list will further explain why this is a bad thing, or
what is in store for the future of heartbeat. But at the moment, some of us
are doing it this way.
	</para>
	<para>
Alan Robertson <emphasis>alanr (at) unix (dot) sh</emphasis> 02 Jul 2002
	</para>
	<para>
OK...  Here's the deal...
If you monitor the network, and discover that you can't connect, then you
can theoretically fail over gracefully to another machine very quickly,
without any fencing or stonith, or anything else.
If you can't communicate with the other node, then you must assume it is
somehow deranged, and have to fence it off from the world, and you can't
gracefully take things over.  It takes longer, and if STONITH is configured,
then it also reboots the other machine, which is really just fine, and
doesn't need to be rebooted.
Also, it could be that neither node has access to the outside world, and
then taking things over is a wasted effort and may result in a cycle of each
machine rebooting the other until network connectivity is restored.
	</para>
	<para>
We are in the throes of desigining a new cluster manager for linux-ha.  That
would solve this problem.
We have a nice membership layer already tested (but not yet in CVS).  The
rest is probably 3-6K lines of code.
	</para>
	<para>
Daniel Khan
	</para>
	<blockquote>
Thinking about a solution I had a (maybe naive) idea.
If any heartbeat connection to node2 fails node1 uses the remaining
connection (ttyS or eth) to ask node2 to run some self checks.
With some basic checks it should be possible to find out if someting is wrong.
	</blockquote>
	<para>
Alan Robertson <emphasis>alanr (at) unix (dot) sh</emphasis> 02 Jul 2002
	</para>
	<para>
That's commonly done in one form or another.  The current code doesn't do
that.  But -- this is the general idea - that loss of communication reduces
your options for recovery.
	</para>
	<blockquote>
And another newbie question on stonith:
I have allready read the basic info's on stonith, but haven't found a paper
about its configuration with heartbeat. Can you point me to the right destination.
	</blockquote>
	<para>
OK...  First of all - you need a STONITH device - which is a piece of
hardware.  Then you need to configure your particular device.
	</para>
	<blockquote>
I thought STONITH does some ssh trick.
Sorry - no device - missunderstood the whole thing.
	</blockquote>
	<para>
You *can* use a STONITH ssh device, but it doesn't work when the system is
sick or incommunicado, so it's only useful for testing.
	</para>
	<blockquote>
I read that Watchdog (Softdog in my case) will shutdown/reboot the Node
itself if it appears to be dead (no heartbeat).
How can I do a test on this. I don't quite understand how the node itself
can declare itself to be sick (it could also be the node on the other side)
	</blockquote>
	<para>
It's not quite like that...
	</para>
	<para>
Heartbeat listens for heartbeats from every machine in the cluster,
including from itself.  Every time it *hears* its own heartbeat, it tickles
the watchdog timer.  If the system is hung in the kernel, or heartbeat is
hung internally somehow, or the scheduler or I/O subsystem doesn't allow it
to run for a while, then after about a minute of not getting tickled by
heartbeat, the watchdog timer will trigger, and the system will undergo an
ungraceful reboot.
	</para>
	<para>
If you're using softdog, then certain kinds of kernel hangs (those that keep
the timer interrupt from happening), will not be caught.  Most will be
caught, but not all.
	</para>
	<para>
If you have a hardware timer, then no software problem whatsoever will cause
it to hang indefinitely.
	</para>
	<para>
malcolm <emphasis>lists (at) netpbx (dot) org</emphasis> 14 Jun 2006 
	</para>
	<para>
If you plug in a null modem cable (as well as your current ethernet connection)
for the heartbeat, it will resolve the issue.
In order for a ping node to work, the heartbeat must still be active,
you can't do it just over one link (<emphasis>e.g.</emphasis> ethernet) or you'll get a split brain.
	</para>
	</section>
	<section id="IPaddr">
	<title>Ard van Breeman's replacement for IPaddr using ip and arping</title>
	<para>
Ard van Breemen <emphasis>ard (at) telegraafnet (dot) nl</emphasis> 25 Feb 2003
	</para>
	<para>
I always had troubles using IPaddr.
I therefore made 
<ulink url="files/IPaddr_ip">IPaddr_ip</ulink>
(http://www.austintek.com/LVS/LVS-HOWTO/HOWTO/files/IPaddr_ip),
which uses 
<command>ip</command> instead of <command>ifconfig</command>, 
and <command>arping</command> instead of <command>sendarp</command>.
	</para>
	</section>
</section>
<section id="LVS-HOWTO.UML" xreflabel="User Mode Linux">
<title>LVS: Running LVS under UML (User Mode Linux), by Brett Elliot</title>
<para>
User Mode Linux (UML) is a version of Linux, written by Jeff Dike,
that boots and runs kernels as a job.
(VMWare does the same thing.)
UML thus can be running several Linux kernels, you can log
into each Linux job separately, and each linux job appears to
be a kernel running on its own machine.
You can simulate ethernet devices (and other hardware) in each
kernel and you can setup IP networks between the different kernels.
You can simulate CPUs and have each kernel think it's running on
a 64-way SMP machine. Of course you won't get any more performance
than from one CPU, but you can test your 64-way CPU code.
You can setup and test a full LVS with redundant directors and
multiple realservers, all on your laptop (Horms and Ratz do this
using VMWare, since UML wasn't available till a couple of years ago).
With multiple kernels running on the resources that normally run only
one kernel, resources can become limiting.
In particular, with the kernel allocating all memory and not swapping
any out till the memory is needed for something else, the job kernels
are always fighting for memory (at least they were in 2002, it appears
now that you limit the amount of memory available to each linux job).
</para>
<para>
The following write up on setting up LVS under UML was sent in by Brett Elliot
<emphasis>brettspamacct (at) fastclick (dot) com</emphasis> 25 Feb 2004
</para>
	<section id="uml_introduction">
	<title>Introduction</title>
	<para>
User Mode Linux(UML) allows you to run linux inside itself.
Linux Virtual Server(LVS) allows you to load
balance traffic between machines.
Using both of these together can be useful.
	</para>
	<para>
It is assumed that the reader has read both the UML HOWTO and the LVS HOWTO.
	</para>
	<para>
The nomeclature of the two types of kernels is not clear in the UML-HOWTO.
	</para>
	<itemizedlist>
		<listitem>
			<para>
<emphasis role="bold">UML kernels:</emphasis>
The name of the kernels that are run as executables
(at the command prompt you run <command>./linux</command>).
			</para>
			<para>
The UML kernel is a regular kernel that has been patched with the
kernel specific UML code.
			</para>
		</listitem>
		<listitem>
			<para>
<emphasis role="bold">host kernel:</emphasis>
The name of the kernel whose job it is to execute the UML kernels.
			</para>
			<para>
The host kernel can be a regular unmodified, unpatched, kernel (from ftp.kernel.org).
			</para>
			<para>
If you want to run the UML kernels faster, you use the "skas" patch
on the host kernel.
The UML kernel recognises the skas patch and will make use of it,
running much faster.
With the skas patch, you will notice 4 processes in the host kernel
(but not the processes launched by the UML kernels).
Without the skas patch, the processes running under the UML kernel
appear in the host kernel process table.
			</para>
		</listitem>
	</itemizedlist>
	<para>
For example, I had a 2.4.23 machine.
I wanted to run a 2.6.2 UML kernel under it.
I patched the 2.6.2 kernel with the UML patch
(<command>make ARCH=um menuconfig</command>,
then <command>make ARCH=um linux</command>) to make a UML kernel linux executable
in the /usr/src/linux-2.6.2 directory.
From the 2.4.23 host kernel,
I ran the linux-2.6.2 UML executable kernel.
	</para>
	<para>
To make the UML kernel run faster,
I patched the 2.4.23 host kernel with the skas patch, and rebooted.
I re-ran the 2.6.2 UML kernel, which recognized the skas patch and ran much faster.
	</para>
	</section>
	<section id="ethernet_bridging">
	<title>Ethernet bridging</title>

		<section id="overview">
		<title>Overview</title>
		<para>
Please refer to the
<ulink url="http://edeca.net/articles/bridging/index.html">
UML Bridging HOWTO</ulink>
(http://edeca.net/articles/bridging/index.html)
for a detailed explanation.
Basically ethernet bridging allows us to create an
ethernet bridge in the kernel and attach ethernet
interfaces to it. We can create an arbitrary ethernet
interface with its own MAC address using the tun
interface, then attache tun interfaces to the ethernet
bridge, allowing for communication between interfaces.
We then "hand off" the ethernet interface created to the
UML kernel.
		</para>
		</section>
		<section id="prerequisites">
		<title>Prerequisites</title>
		<para>
You will need to recompile the host kernel and install
user-space tools on the host kernel machine.
		</para>
		<para>
On the host kernel (the kernel housing the UML kernel),
enable "802.1d Ethernet Bridging" (CONFIG_BRIDGE)
under "Networking options" and enable "Universal TUN/TAP
device driver support" (CONFIG_TUN) under "Network device support".
Recompile the kernel.
		</para>
		<note>
there is no need to modify the UML kernel
configuration.
		</note>
		<para>
For the userspace tools on the host kernel machine
you will need the bridge utils and tun utils.
You will also need <filename>maketundev.sh</filename>
to create the <filename>tun</filename> device:
		</para>
<programlisting><![CDATA[
#!/bin/sh
#
#  Universal TUN/TAP device driver.
#  Copyright (C) 1999-2000 Maxim Krasnyansky <max_mk@yahoo.com>
#
#  Create TUN and TAP devices in /dev
#
#  $Id: create_dev,v 1.2 2000/10/28 21:22:37 maxk Exp $
#

case $1 in
   2.2*)
        TUN_MAJOR=90
        TUN_MINOR=0
        TAP_MINOR=128
        #
        # TUN
        rm -f /dev/tun*
        for i in 0 1 2 3; do
           mknod /dev/tun$i c ${TUN_MAJOR} $i
        done
        #
        # TAP
        rm -f /dev/tap*
        for i in 0 1 2 3; do
           mknod /dev/tap$i c ${TUN_MAJOR} `expr $i + ${TAP_MINOR}`
        done
        ;;

   2.4*)
        TUN_MAJOR=10
        TUN_MINOR=200
        if [ ! -d /dev/net ]; then
           mkdir /dev/net
        fi
        rm -f /dev/net/tun
        mknod /dev/net/tun c ${TUN_MAJOR} ${TUN_MINOR}
        ;;

   *)
        echo "Unknown kernel version"
        ;;

esac
]]></programlisting>

		</section>
		<section id="bridging_to_the_world">
		<title>Ethernet bridging to the world</title>
		<para>
This will show you how to bring up the UML kernel so it
is connected to the world.
		</para>
		<para>
We assume that the host kernel
(<emphasis>i.e.</emphasis> the kernel which houses the UML kernel)
has IP address 10.1.1.219.
The UML kernel will have IP address 10.1.1.220.
First, run <filename>maketundev.sh kernel_version</filename> to create the
<filename>tun</filename> device(s).
Next, you will need to execute the following commands:
		</para>
<programlisting><![CDATA[
ifconfig eth0 0.0.0.0 promisc up
brctl addbr uml-bridge
brctl setfd uml-bridge 0
brctl sethello uml-bridge 0
brctl stp uml-bridge off
ifconfig uml-bridge 10.1.1.219 netmask 255.0.0.0 up
brctl addif uml-bridge eth0
tunctl uml-conn0
ifconfig uml-conn0 0.0.0.0 promisc up
brctl addif uml-bridge uml-conn0
]]></programlisting>
		<para>
For a detailed description of what these commands do,
please see the
<ulink url="http://edeca.net/articles/bridging/index.html">
UML Bridging HOWTO</ulink>
(http://edeca.net/articles/bridging/index.html).
These commands set up an ethernet
bridge with the name of <filename>uml-bridge</filename>,
attach <filename>eth0</filename> to it
in promiscuous mode and create an ethernet interface
called <filename>uml-conn0</filename> in promiscuous mode which is attached
to <filename>uml-bridge</filename>. In this manner, two ethernet interfaces,
<filename>eth0</filename> and <filename>uml-conn0</filename>
will be part of the same network.
Ethernet packets sent to <filename>eth0</filename> will be intelligently
sent to <filename>uml-conn0</filename> and vice versa, acting as a sort of
switch in the linux kernel. Note that if you are
connected to the host machine via the network and enter
the commands interactively, you will be disconnected
unless you execute the above commands in a script.
		</para>
		<para>
Next we must simply run the UML kernel (run the UML "linux"
executable) and provide <filename>uml-conn0</filename> as its ethernet device:
		</para>
<programlisting><![CDATA[
./linux eth0=tuntap,uml-conn0
]]></programlisting>
		<para>
Then, within UML linux, set the IP to 10.1.1.220. You
should be able to ping 10.1.1.219 and the outside world
within the UML you just created.
		</para>
		</section>
		<section id="local_ethernet_bridging">
		<title>Local ethernet bridging</title>
		<para>
This will show you how to bring up the UML kernel,
so it can communicate with one or more UML kernels on the same machine,
but not allowing for outside network connectivity within the UMLs.
This could be used for testing a multi-node environment,
without affecting others on the networks.
		</para>
		<para>
We assume, like before, that the host kernel has IP address 10.1.1.219,
although this isn't terribly important for this example.
We will then add to the host kernel IP address 172.16.1.1,
then give the UML kernel IP address 172.16.1.2.
So, you can ping the UML kernel, by pinging its IP address 172.16.1.2,
from the host kernel and you can ping from the UML kernel to the
host kernel at IP 172.16.1.1. The UML kernel will not,
however, be able to communicate to the outside world.
		</para>
		<para>
First run <filename>maketunedev.sh kernel_version</filename> then run:
		</para>
<programlisting><![CDATA[
brctl addbr uml-bridge
brctl setfd uml-bridge 0
brctl sethello uml-bridge 0
brctl stp uml-bridge off
tunctl -t uml-conn0
ifconfig uml-conn0 0.0.0.0 promisc up
brctl addif uml-bridge uml-conn0
ifconfig uml-bridge 172.16.1.1 up
]]></programlisting>
		<para>		
This sequence of commands will set up a bridge named
<filename>uml-bridge</filename> then it will create
<filename>tun</filename> interface <filename>uml-conn0</filename>.
It will attach 172.16.1.1 to the uml-bridge for the
host kernel. We then invoke the UML, giving it
<filename>uml-conn0</filename> for its ethernet address:
		</para>
<programlisting><![CDATA[
linux eth0=tuntap,uml-conn0
]]></programlisting>
		<para>
Configure the UML to use IP address 172.16.1.2 and the
host and UML kernels can communicate via IPs
172.16.1.1. and 172.16.1.2 respectively. You can create
more than one UML kernel, giving each IPs in the
172.16.0.0 network. The only caveat is that you must
assign a unique ethernet address to each one as they
will by default use ethernet address fe:fd:0:0:0:0. So
for the second UML you can do the following,
after bringing up the network:
		</para>
<programlisting><![CDATA[
ifconfig eth0 hw ether fe:fd:01:00:00:00
]]></programlisting>
		<para>
to force it to use ethernet address fe:fd:01:00:00:00
		</para>
		</section>
	</section>
	<section id="putting_it_together">
	<title>Putting it all together: UML + LVS examples (not finished)</title>
		<section id="ethernet_bridging_to_the_world">
		<title>Ethernet bridging to the world</title>
		<para>
We will have 1 UML kernel acting as the LVS director
for clients and realservers located on outside machines.
		</para>
		</section>
		<section id="local_ethernet_bridging_with_2_uml_kernels">
		<title>Local ethernet bridging with 2 UML kernels</title>
		<para>
We will have 1 UML kernel for the director and 1 for
the realserver. We can connect from the host kernel to
the director, routing to the realserver, but we cannot
communicate to the outside world. This allows us to do
multinode testing within one machine while not
disturbing anyone else.
		</para>
		</section>
	</section>
</section>
<section id="LVS-HOWTO.policy_routing" xreflabel="Policy Routing">
<title>LVS: Newer networking tools: Policy Routing</title>
	<section id="policy_routing_intro">
	<title>Introduction</title>
	<para>
The standard network tools
(<emphasis>e.g.</emphasis> <command>ifconfig</command>,
<command>route</command> and <command>netstat</command>)
aren't capable of setting up some of the features used in newer LVSs <emphasis>e.g.</emphasis>
<link linkend="NAT_clients_in_LVS-DR">routing based on src_addr</link>.
For this we use <command>iproute2</command>, which allows routing based on almost any of the parameters
of a packet (src, dest, proto, tos...).
<filename>iproute2</filename> is available at
<ulink url="ftp://ftp.inr.ac.ru/ip-routing/">iproute2-current.tar.gz</ulink>.
<filename>iproute2</filename> implements similar functionality to cisco's IOS.
	</para>
	<para>
For nodes attached to only one network 
(leaf nodes, <emphasis>i.e.</emphasis> there is only one possible route for packets),
then <command>ifconfig</command> and <command>route</command> are just fine.
If multiple routes exist then <filename>iproute2</filename> is needed.
	</para>
	<para>
Presumably routing in Linux and the setup of LVS
will move more toward using <command>iproute2</command>.
The configure script will use the <filename>iproute2</filename> package 
to do some configuration if you have it installed.
	</para>
	<para>
Instead of aliases (<emphasis>e.g.</emphasis> eth0:110) <filename>iproute2</filename> uses labels.
<filename>ip_tables</filename> is based on the same underlying code 
and also requires labels to recognise ip_aliases.
If you want to see the network as <filename>ip_tables</filename> sees it, 
you need the iproute2 tools.
	</para>
	<para>
<filename>iproute2</filename> is not compatible with
<command>ifconfig</command>,<command>route</command> and <command>netstat</command>.
The entries added by the iproute2 tools are not seen by ifconfig/route etc
and the output of ifconfig/route etc will be incorrect.
You can't tell from looking at the output of ifconfig/route
whether iproute2 commands have been run  - you just have to know.
The iproute2 tools correctly interpret the results of ifconfig/route commands
and will give the correct state of the network.
	</para><para>
Unfortunately the user interface to iproute2 is not easy.
	</para>
	<itemizedlist>
		<listitem>
			<para>
The documentation is not easy to read (although it was all Julian needed).
			</para><para>
Ratz suggested "Policy Routing Using Linux" by Matthew G. Marsh,
Pub Sams 2001, ISBN 0-672-32052-5, to get you started (it helped me).
(Oct 2002) Ratz has just found that the book is also
<ulink url="http://www.policyrouting.org/PolicyRoutingBook/ONLINE/TOC.html">online</ulink>
			</para>
			<para>
Padraig Brady <emphasis>padraig (at) antefactor (dot) com</emphasis> suggests
<ulink url="http://lartc.org/howto/index.html">
Linux Advanced Routing and Traffic Control HOWTO</ulink>.
			</para>
			<para>
See <ulink url="http://linux-ip.net/">Guide to IP Layer Network Administration with Linux</ulink>
(http://linux-ip.net/) where Appendix C has information on using the <filename>iproute2</filename> tools.
			</para>
		</listitem>
		<listitem>
			<para>
The output from the commands is difficult to parse
(see the comments in the configure script
for more details) - <emphasis>i.e.</emphasis> it's not machine readable.
If the route is 0/0 then it is not listed in the output and the next
output item shifts one field.
This means that you have to know the route before you can parse
the output.
Ratz is developing a <link linkend="ifcfg">wrapper for iproute2</link>
that will give machine readable output.
(To have a command line utility which is not machine readable is intolerable.)
			</para>
		</listitem>
	</itemizedlist>
	<para>
There are other problems
	</para>
	<para>
Joe, Dec 2003
	</para>
	<blockquote>
The latest on Alexey's ftp site is 2.4.7 from Jan 2002. Is this really the latest?
	</blockquote>
	<para>
Alejandro Mery <emphasis>amery (at) geeks (dot) cl</emphasis> 24 Dec 2003
	</para>
	<para>	
2.4.7-now-ss010824 is the official lastest 'stable' but Bert Hubert (ahu)
(<ulink url="http://ds9a.nl/">Bert's website</ulink>, http://ds9a.nl/)
from lartc.org had an 'almost-branch' with some fixes and improvements with the date 2002-10-20.
Bert's code is downloadable at
<ulink url="http://ds9a.nl/cgi-bin/viewcvs.cgi/iproute2-ahu/iproute2-ahu.tar.gz?tarball=1&amp;only_with_tag=HEAD">
http://ds9a.nl/cgi-bin/viewcvs.cgi/iproute2-ahu/iproute2-ahu.tar.gz?tarball=1&amp;only_with_tag=HEAD"
</ulink>.
Sadly both Bert's and Alexey's code are unmantained.
	</para>
	</section>
	<section id="iproute2">
	<title>Policy Routing and ifconfig</title>
	<para>
Example:
	</para>
	<blockquote>
		<para>
In a normally functioning LVS-DR, with routing setup by &quot;route&quot;
the realservers will be sending packets with the following routing
		</para>
		<itemizedlist>
			<listitem>
src_addr=VIP dest_addr=0/0. dest=0/0 - route via default gw
			</listitem>
			<listitem>
src_addr=RIP dest_addr=RIP network. dest=RIP network - route to RIP network
			</listitem>
		</itemizedlist>
		<para>
In LVS-DR a packet leaving the realserver can exit
via the default gw or the director.
In the standard setup, packets with dst_addr=RIPnetwork
are put onto the local network and all other packets are sent to the default gw.
		</para><para>
If instead the routing is setup by &quot;iproute2&quot;, packets with src_addr=VIP are
sent to the default gw, while packets with src_addr=RIP are put onto the local network.
The realservers will be sending packets with the following routing
		</para>
		<itemizedlist>
			<listitem>
src_addr=VIP dest_addr=0/0. src=VIP - route via default gw
			</listitem>
			<listitem>
src_addr=RIP dest_addr=RIP network. src=RIP - route to RIP network
			</listitem>
		</itemizedlist>
		<para>
The result for a normal working LVS, will be the same (<emphasis>i.e.</emphasis>
the LVS will still work).
However with the standard setup,
packets with scr_addr=RIP cannot get to the outside world (the director
does not have a default route to 0/0).
If a process needs this (<emphasis>e.g.</emphasis> the operator needs
to telnet out, or the realserver needs DNS), then those
packets from the RIP can be NAT'ed out via the director
(or you can setup the realservers as if they are
part of a <xref linkend="3-Tier_lvs"/> LVS).
For security, all packets from the VIP have to go out the
default gw (including any to say the DIP, which will be dropped
by rules on the default gw, to prevent spoofing).
		</para>
		<itemizedlist>
			<listitem>
src_addr=VIP dest_addr=RIP network. src=VIP - route via default gw, will be dropped
			</listitem>
			<listitem>
src_addr=RIP dest_addr=0/0. src=RIP - route to RIP network. If the director
has the correct NAT rules, then these packets can pass to the outside world.
			</listitem>
		</itemizedlist>
	</blockquote>
	<para>
Lawrence Strydom <emphasis>laurie (at) midafrica (dot) com</emphasis>
26 May 2003
	</para>
	<blockquote>
Is it possible to set up heartbeat between a Linux
and a Windose box. The MS box will be the master node and the Linux box
will provide redundancy.(dont ask! it is what the client wants)
	</blockquote>
	<para>
Horms
	</para>
	<para>
It should be theoretically possible to run heartbeat on Windows.
But to my knowledge no one has done this in the past.
The heartbeat code is reasonably portable (between different
Unix-like operating systems) but it is likely that
you will need to do quite a lot of work to get it to
compile and work correctly on Windows.
I have no experince with using cygwin so I can't comment
any further than that.
	</para>
	</section>
	<section id="FIB">
	<title>Various debugging techniques for routes</title>
	<para>
(with Julian)
	</para>
	<para>
(I needed this information to setup a one-net LVS-NAT LVS.
However since it is about routing and not LVS specifically,
maybe I should move it elsewhere.)
	</para>
	<para>
The routes added with <command>route</command> go into the kernel FIB
(Forwarding information base) route table. The contents are
displayed with <command>route</command> (or <command>netstat -a</command>).
	</para>
	<para>
Following an icmp redirect, the route updates go into the kernel's
route cache (route -C).
	</para>
	<para>
You can flush the route cache with
	</para>
<programlisting><![CDATA[
	echo 1 > /proc/sys/net/ipv4/route/flush
or
	ip route flush cache
]]></programlisting>
	<para>
Here's the route cache on the realserver before any packets are sent.
	</para>
<programlisting><![CDATA[
realserver:/etc/rc.d# route -C
Kernel IP routing cache
Source          Destination     Gateway         Flags Metric Ref    Use Iface
realserver      director        director              0      1        0 eth0
director        realserver      realserver      il    0      0        9 lo
]]></programlisting>
	<para>
With icmp redirects enabled on the director, repeatedly running
<command>traceroute</command>
to the client shows the routes changing from 2 hops to 1 hop.
This indicates that the realserver has received an icmp redirect
packet telling it of a better route to the client.
	</para>
<programlisting><![CDATA[
realserver:/etc/rc.d# traceroute client
traceroute to client (192.168.1.254), 30 hops max, 40 byte packets
 1  director (192.168.1.9)  0.932 ms  0.562 ms  0.503 ms
 2  client (192.168.1.254)  1.174 ms  0.597 ms  0.571 ms
realserver:/etc/rc.d# traceroute client
traceroute to client (192.168.1.254), 30 hops max, 40 byte packets
 1  director (192.168.1.9)  0.72 ms  0.581 ms  0.532 ms
 2  client (192.168.1.254)  0.845 ms  0.559 ms  0.5 ms
realserver:/etc/rc.d# traceroute client
traceroute to client (192.168.1.254), 30 hops max, 40 byte packets
 1  client (192.168.1.254)  0.69 ms *  0.579 ms
]]></programlisting>
	<para>
Although <command>route</command> shows no change in the FIB, the route cache
has changed.
(The new route of interest is bracketted by &gt;&lt; signs in the table below.)
	</para>
<programlisting><![CDATA[
 realserver:/etc/rc.d# route -C
 Kernel IP routing cache
 Source          Destination     Gateway         Flags Metric Ref    Use Iface
 client          realserver      realserver      l     0      0        8 lo
 realserver      realserver      realserver      l     0      0     1038 lo
 realserver      director        director              0      1      138 eth0
>realserver      client          client                0      0        6 eth0<
 director        realserver      realserver      l     0      0        9 lo
 director        realserver      realserver      l     0      0      168 lo
]]></programlisting>
	<para>
Packets to the client now go directly to the client instead of via
the director (which you don't want).
	</para>
	<para>
It takes about 10mins for the client's route cache to expire
(experimental result).
The timeouts may be in <filename>/proc/sys/net/ipv4/route/gc_*</filename>,
but their location and values are well encrypted in the sources :)
(some more info from Alexey at
<ulink url="http://marc.theaimsgroup.com/?l=linux-kernel$amp;m=91754108723334$amp;w=2">
LVS archives</ulink>)
	</para>
	<para>
Here's the route cache after 10mins.
	</para>
<programlisting><![CDATA[
realserver:/etc/rc.d# route -C
Kernel IP routing cache
Source          Destination     Gateway         Flags Metric Ref    Use Iface
realserver      realserver      realserver      l     0      0     1049 lo
realserver      director        director              0      1      139 eth0
director        realserver      realserver      l     0      0        0 lo
director        realserver      realserver      l     0      0      236 lo
]]></programlisting>
	<para>
There are no routes to the client anymore. Checking with <command>traceroute</command>,
shows that 2 hops are initially required to get to the client (i.e.
the routing cache has reverted to using the director as the route
to the client). After 2 iterations, icmp redirects route the packets
directly to the client again.
	</para>
<programlisting><![CDATA[
realserver:/etc/rc.d# traceroute client
traceroute to client (192.168.1.254), 30 hops max, 40 byte packets
 1  director (192.168.1.9)  0.908 ms  0.572 ms  0.537 ms
 2  client (192.168.1.254)  1.179 ms  0.6 ms  0.577 ms
realserver:/etc/rc.d# traceroute client
traceroute to client (192.168.1.254), 30 hops max, 40 byte packets
 1  director (192.168.1.9)  0.695 ms  0.552 ms  0.492 ms
 2  client (192.168.1.254)  0.804 ms  0.55 ms  0.502 ms
realserver:/etc/rc.d# traceroute client
traceroute to client (192.168.1.254), 30 hops max, 40 byte packets
 1  client (192.168.1.254)  0.686 ms  0.533 ms *
]]></programlisting>
	<para>
If you now turn off icmp redirects on the director.
	</para>
<programlisting><![CDATA[
director:/etc/lvs# echo 0 > /proc/sys/net/ipv4/conf/all/send_redirects
director:/etc/lvs# echo 0 > /proc/sys/net/ipv4/conf/default/send_redirects
director:/etc/lvs# echo 0 > /proc/sys/net/ipv4/conf/eth0/send_redirects
]]></programlisting>
	<para>
Checking routes on the realserver -
	</para>
<programlisting><![CDATA[
realserver:/etc/lvs# netstat -rn
Kernel IP routing table
Destination     Gateway         Genmask         Flags   MSS Window  irtt Iface
127.0.0.0       0.0.0.0         255.0.0.0       U         0 0          0 lo
0.0.0.0         director        0.0.0.0         UG        0 0          0 eth0
]]></programlisting>
	<para>
nothing has changed here.
	</para><para>
Flush the kernel routing table and show the kernel routing table -
	</para>
<programlisting><![CDATA[
realserver:/etc/lvs# ip route flush cache
realserver:/etc/lvs# route -C
Kernel IP routing cache
Source          Destination     Gateway         Flags Metric Ref    Use Iface
realserver      director        director              0      1        0 eth0
director        realserver      realserver      l     0      0        1 lo
]]></programlisting>
	<para>
There are now no routes to the client.
	</para><para>
Now when you send packet to the client, the route stays via the director
needing 2 hops to get to the client. There are no one hop packets
to the client.
	</para>
<programlisting><![CDATA[
realserver:/etc/rc.d# traceroute client
traceroute to client (192.168.1.254), 30 hops max, 40 byte packets
 1  director (192.168.1.9)  0.951 ms  0.56 ms  0.491 ms
 2  client (192.168.1.254)  0.76 ms  0.599 ms  0.574 ms
realserver:/etc/rc.d# traceroute client
traceroute to client (192.168.1.254), 30 hops max, 40 byte packets
 1  director (192.168.1.9)  0.696 ms  0.562 ms  0.583 ms
 2  client (192.168.1.254)  0.62 ms  0.603 ms  0.576 ms
realserver:/etc/rc.d# traceroute client
traceroute to client (192.168.1.254), 30 hops max, 40 byte packets
 1  director (192.168.1.9)  0.692 ms *  0.599 ms
 2  client (192.168.1.254)  0.667 ms  0.603 ms  0.579 ms
realserver:/etc/rc.d# traceroute client
traceroute to client (192.168.1.254), 30 hops max, 40 byte packets
 1  director (192.168.1.9)  0.689 ms  0.558 ms  0.487 ms
 2  client (192.168.1.254)  0.61 ms  0.63 ms  0.567 ms
realserver:/etc/rc.d# traceroute client
traceroute to client (192.168.1.254), 30 hops max, 40 byte packets
 1  director (192.168.1.9)  0.705 ms  0.563 ms  0.526 ms
 2  client (192.168.1.254)  0.611 ms  0.595 ms *
realserver:/etc/rc.d# traceroute client
traceroute to client (192.168.1.254), 30 hops max, 40 byte packets
 1  director (192.168.1.9)  0.706 ms  0.558 ms  0.535 ms
 2  client (192.168.1.254)  0.614 ms  0.593 ms  0.573 ms
]]></programlisting>
	<para>
The kernel route cache
	</para>
<programlisting><![CDATA[
 realserver:/etc/rc.d# route -C
 Kernel IP routing cache
 Source          Destination     Gateway         Flags Metric Ref    Use Iface
 client          realserver      realserver      l     0      0       17 lo
 realserver      realserver      realserver      l     0      0        2 lo
 realserver      director        director              0      1        0 eth0
>realserver      client          director              0      0       35 eth0<
 director        realserver      realserver      l     0      0       16 lo
 director        realserver      realserver      l     0      0       63 lo
]]></programlisting>
	<para>
shows that the only route to the client (labelled with &gt;&lt;) is via the director.
	</para><para>
For send_redirects, what's the difference between all, default and eth0?
	</para>
	<para>
Julian
	</para>
	<blockquote>
		<para>
see the
<ulink url="http://marc.theaimsgroup.com/?l=linux-virtual-server$amp;m=97932487110806$amp;w=2">
LVS archives</ulink>
		</para>
		<para>
When the kernel needs to check for a feature
(<emphasis>e.g.</emphasis> <filename>send_redirects</filename>)
it uses calls like:
		</para>
<programlisting><![CDATA[
if (IN_DEV_TX_REDIRECTS(in_dev)) ...
]]></programlisting>
		<para>
These macros are defined in <filename>/usr/src/linux/include/linux/inetdevice.h</filename>
		</para>
		<para>
The macro returns a value using expression from
<filename>all/&lt;var&gt;</filename> and <filename>&lt;dev&gt;/&lt;var&gt;</filename>.
So, these macros check for example for:
<filename>all/send_redirects || eth0/send_redirects</filename>
or
<filename>all/hidden &amp;&amp; eth0/hidden</filename>.
		</para>
		<para>
when you create eth0 for first time using <command>ifconfig eth0 ... up</command>
<filename>default/send_redirects</filename>
is copied to <filename>eth0/send_redirects</filename> from the
kernel, internally. <emphasis>i.e.</emphasis> <filename>default/</filename>
contains the initial values
the device inherits when it is created. This is the safest way a
device to appear with correct
<filename>conf/&lt;dev&gt;/</filename>
values.
		</para>
		<para>
When we put a value in
<filename>all/&lt;var&gt;</filename>
you can assume that we set the
<filename>&lt;var&gt;</filename>.
When we put value in
<filename>all/&lt;var&gt;</filename>
you can assume that we set the
<filename>&lt;var&gt;</filename>
for all devices in this way:
		</para>
<programlisting><![CDATA[
                all/<var>       the macro returns:
for &&          0               0
for &&          1               the value from <dev>/<var>
for ||          0               the value from <dev>/<var>
for ||          1               1
]]></programlisting>
		<para>
This scheme allows the different devices to have different values
for their vars.
<emphasis>e.g.</emphasis> if we set 0 to <filename>all/send_redirects</filename>,
the 3th line applies to the values,
<emphasis>i.e.</emphasis> the result from the macro is the real
value in <filename>&lt;dev&gt;/send_redirects</filename>.
If we set 1 to <filename>all/send_redirects</filename>
according to the 4th line, the macro always returns 1 regardless
of the <filename>&lt;dev&gt;/send_redirects</filename>.
		</para>
	</blockquote>
	<para>
how to debug/understand TCP/IP packets?
	</para>
	<para>
Julian
	</para>
	<blockquote>
		<para>
        The
<ulink url="http://www.ietf.cnri.reston.va.us/rfc.html">
RFC documents
http://www.ietf.cnri.reston.va.us/rfc.html
</ulink>
are your friends.
        The numbers you need:
		</para>
<programlisting><![CDATA[
793     TRANSMISSION CONTROL PROTOCOL
1122    Requirements for Internet Hosts -- Communication Layers
1812    Requirements for IP Version 4 Routers
826     An Ethernet Address Resolution Protocol
]]></programlisting>
		<para>
for <command>tcpdump</command>, see <command>man tcpdump</command>.
		</para>
	</blockquote>
	<para>
for Microsoft NT _server_
	</para>
	<para>
<emphasis>Steve (dot) Gonczi (at) networkengines (dot) com</emphasis>
	</para>
	<blockquote>
there is a uSoft supplied packet capture utility as well.
	</blockquote>
	<para>
also -W. Richard Stevens: TCP-IP Illustrated, Vol 1, a good
intro into packet layouts and protocol basics. (anything
by Stevens is good - Joe).
	</para>
	<para>
Ivan Figueredo <emphasis>idf (at) weewannabe (dot) com</emphasis>
	</para>
	<blockquote>
for windump - http://netgroup-serv.polito.it/windump/
	</blockquote>
	</section>
	<section id="src_routed_packets">
	<title>checking source routed packets</title>
	<para>
Packets leaving a LVS-DR realserver can have src_addr=VIP or src_addr=RIP.
If the default gw is different for each packet, it would be
nice to have a command line testing tool like ping or traceroute
to test the route. The normal tools will create packets with
src_addr=RIP and you won't be able to test the packets with src_addr=VIP.
	</para>
	<para>
Roberto Nibali <emphasis>ratz (at) tac (dot) ch</emphasis> 22 May 2001
	</para>
	<para>
maybe <ulink url="http://www.hping.org/">hping</ulink> can help you.
	</para>
	<para>
Joe
	</para>
	<blockquote>
Ah, the file hping2.8 is the
man page <emphasis>i.e.</emphasis> {hping2}.8 - I thought it was v2.8 of hping.
	</blockquote>
	<para>
How about:
	</para>
<programlisting><![CDATA[
ip route get $IP?
]]></programlisting>
	<blockquote>
	didn't know about "get". yes that works. It's like a -C with
iptables. I'd still like to send a packet and see where it goes rather
than getting an answer about where it is expected to go.
	</blockquote>
	<para>
Julian
	</para>
	<para>
Not possible with src interface "lo" but possible with source
address configured in "lo". Oh yes, "source interface" for some tools
means "get one address from this iface and use it". In most of the
cases these tools don't do the Right Thing.
	</para>
	<para>
from iproute2
	</para>
<programlisting><![CDATA[
$ ping -I src dst
]]></programlisting>
or
<programlisting><![CDATA[
arping -I if -s src dst
]]></programlisting>
	</section>
	<section id="ip_noarp">
	<title>handling arp problem with iproute2</title>
	<para>
see <ulink url="http://www.ssi.bg/~ja/#noarp">
Julian's notes and patches to handle the arp problem with iproute2</ulink>
(this is somewhat developemental).
	</para>
	</section>
	<section id="ip_commands">
	<title>ip commands you mightn't know about</title>
		<section>
		<title>ip route get</title>
		<para>
from Julian
		</para>
		<para>
This will look at the routing tables and tell you the route to xxx.xxx.xxx.xxx
		</para>
<programlisting><![CDATA[
ip route get xxx.xxx.xxx.xxx
]]></programlisting>
		</section>
		<section>
		<title>ip route append</title>
		<para>
If you already have a route from A to B, and want to add another, you can't,
you have to <emphasis>append</emphasis> the extra route.
		</para>
		<para>
dynnema <emphasis>dynnema (at) yahoo (dot) com</emphasis> Mar 22 2002
		</para>
		<para>
Lets say I got one RS and two NAT DIRs.
		</para>
<programlisting><![CDATA[
 RS:
 RIP1:   192.168.1.2/24 dev eth0
 RIP2    192.168.2.2/24 dev eth0:10

 DIR1:
 VIP:    x.x.x.69        eth0:110
 DIP     192.168.1.1

 DIR2:
 VIP:    x.x.x.70        eth0:110
 DIP     192.168.2.1
]]></programlisting>
		<para>
I add the first route
		</para>
<programlisting><![CDATA[
ip route add src 192.168.1.2 via 192.168.1.1
]]></programlisting>
		<para>
but then I can't add the second route:
		</para>
<programlisting><![CDATA[
ip route add src 192.168.2.2 via 192.168.2.1:
"RTNETLINK answers: File exists"
]]></programlisting>
		<para>
Careful reading of IProute mailing list was very useful.
It should be
		</para>
<programlisting><![CDATA[
ip route append src 192.168.2.2 via 192.168.2.1
]]></programlisting>
		</section>
	</section>
	<section id="ratz_on_iproute2">
	<title>Ratz's corrections on common iproute2/aliases misconceptions</title>
	<para>
Joe: we used to have ip aliases with ifconfig.
We still have ip aliases, but as of kernel 2.1.128, the semantics has changed.
Be careful using the old style ip aliases (<emphasis>e.g.</emphasis> eth0:1, lo:127) 
with the newer tools (<emphasis>e.g.</emphasis> iproute2), which expect a different syntax.
	</para>
	<para>
Ratz 25 Nov 2003
	</para>
	<itemizedlist>
		<listitem>
the basic problem with <command>route/netstat -rn</command> is,
that they only see the main table, which is rather limited.
		</listitem>
		<listitem>
<filename>iproute2</filename>
uses labels to provide the same ip aliases as are used by <command>ifconfig</command>.
It's not up to the tool to decide if labels work or
not. The misconception people have with ip aliasing is that people
think an aliased interface is a logically separated interface while
it is _not_. And this is the case since 2.1.128 or so.
		</listitem>
		<listitem>
			<para>
<filename>ipchains</filename> doesn't recognize alias neither because since the 2.2.x
kernel we moved to the <filename>iproute2</filename> architecture.
			</para>
			<note>
Joe: in other parts of the HOWTO, 
I've incorrectly said the changeover started with the 2.4 kernels. 
Hopefully this error has been fixed.
The change from 2.2 to 2.4 involved the different packet path
through the kernel and the replacement of <command>ipchains</command> with 
<ulink url="http://www.netfilter.org/">netfilter</ulink> (http://www.netfilter.org).
Netfilter is most familiar through its user space tool <command>iptables</command>
which defines rule set for packets.
			</note>
			<para>
Packet filtering on aliases stopped working after
the decay of <command>ipfwadm</command> in the old 2.0.x kernel days. 
Today you can still filter on so-called ip aliases but as the name implies you
specify the IP ADDRESSS as a classifier and if you want to restrict it further, 
you add the underlying _physical_ interface definition to the classifying rule.	
			</para>
		</listitem>
		<listitem>
		<para>
<filename>iproute2</filename> is compatible with <command>ifconfig/route/netstat</command>
but not vice versa.
The two biggest issues people new to <filename>iproute2</filename> have to struggle with are:
		</para>
		<itemizedlist>
			<listitem>
if you add secondary ip addresses without a label (alias interface)
<command>ifconfig</command> is confused and doesn't print the information
			</listitem>
			<listitem>
if you add rules for branching into different routing tables than
the main routing table, <command>route</command> or <command>netstat -rn</command>
will not show you those routes. 
This also the case for blackhole, throw, unreachable and prohibit routes.
			</listitem>
		</itemizedlist>
		</listitem>
	</itemizedlist>
	<para>
Ratz <emphasis>ratz (at) drugphish (dot) ch</emphasis> 07 Mar 2007
	</para>
	<para>
Before the arrival of the Linux kernel version 2.2 a network device named
eth0:3 was actually a "real" (kernel-wise) network device by the name of eth0:3. 
You could filter on that device and you could route on that device
(please send this packet out eth0:3).
	</para>
	<para>
After that the Linux network model changed and the so called logical/virtual
devices were degraded to aliases. 
The nomenclature was never standardised, so in the 2.0.x kernels, 
a device eth0:3 was called an alias, but it was a real independant device.
In later kernels, the name alias meant "another name for".
In current kernels, an alias is actually a string related to an IP address, 
nothing more and nothing less. 
It has no semantic meaning whatsoever, 
besides being a backwards compatible string for the <command>ifconfig</command> tool. 
	</para>
	<para>
The label is optional for secondary IP addresses.
Secondary IPs configured with <command>iproute2</command> without an explicit label 
do not show up in <command>ifconfig</command>. 
	</para>
	<note>
If the first IP configured on an interface with <command>ip addr add</command> is 192.168.1.1/24,
then any subsequent addresses in that network (192.168.1.2/24..192.168.1.254/24) will be
secondary addresses and 192.168.1.1 will be the primary address. 
If the primary address is removed, then all secondary addresses will also be removed.
If another address not in that network is added (<emphasis>e.g.</emphasis> 10.10.1.1/16
or 192.168.1.5/30) then it will be another primary address.
	</note>
	<para>
Going the other direction, an alias configured with <command>ifconfig</command>
always shows up in <command>ip addr show</command>.
	</para>
<programlisting><![CDATA[
ifconfig intf:label ip.ad.dr.ess netmask ne.tm.as.k broadcast br.oa.dc.ast up
]]></programlisting>
	<para>
is essentially the same as
	</para>
<programlisting><![CDATA[
ip addr add ip.ad.dr.ess/cidr brd + dev intf label intf:label
ip link set dev intf up
]]></programlisting>
	<para>
Sentences like "Network aliases or IP aliases or device aliases don't work
with netfilter anymore" are not correct, since it's rather the other way
around, but generally not a correct sentence, since no packet filtering
mechanism ever worked with pure strings :).
If you want to filter on an alias, find out its corresponding IP address
(using <command>ip addr show</command>) and filter based on the IP address 
and the physical underlying interface. So:
	</para>
<programlisting><![CDATA[
1.1.1.1 eth0
1.1.2.1 eth0:3
1.1.3.1 eth0:foobar
]]></programlisting>
	<para>
If you want to filter based on eth0:3, you set up a filter as follows
on eth0 and 1.1.2.1 (didn't check on the correct syntax):
	</para>
<programlisting><![CDATA[
iptables -t filter -A INPUT -j DROP -i eth0 -s 1.1.2.1 ...
]]></programlisting>
	<note>
you can't filter on eth0:3 and iptables doesn't use labels either.
So you can't use interfaces in iptables rules.
	</note>
	<para>
A Linux host/router is behaving like modern managed (application) switch:
There is no assignment anymore of IP addresses to network interface cards.
An IP address is attached to the host and this confuses most people,
especially when they have multiple NICs in their node and configure
different IP addresses to each NIC, ping one IP address and get the reply
from a seemingly different collision domain. This means, that for example
even though one can be physically connected only to eth0 with IP address
192.168.1.1 and having eth1 with IP address 10.10.10.10 non-wired to a
switch, he/she will be able to ping 10.10.10.10 through eth0. This is
because IP addresses do not belong to network interface cards. Also one
reason why you can filter per network interface card and also per IP address.
In some cases, the machine will have a route to (say) 10.10.10.10,
but you don't have a routing entry for /32 IP addresses and they'll still reply.
	</para>
	<note>
Joe: the Marsh book, p8, explains that from 2.2.x, 
when you configure an IP on a NIC, 
the route to that network is configured as well
(<emphasis>i.e.</emphasis> you don't have to add a route to the network,
as you did with the 2.0.x kernels). 
If you don't want the route, 
you have to configure a host (<emphasis>i.e.</emphasis> /32) address. 
	</note>
	<para>
There is no assignment anymore of IP addresses to network interface cards. 
An IP address is attached to the host and this confuses most people.
	</para>
	<para> 
Joe
	</para>
	<blockquote>
yes. So why are addresses configured with the name of the NIC (eth0, eth1)? 
Why not just tell the kernel which IPs it has and let it figure out what to do with all the NICs?
	</blockquote>
	<para>
How?
	</para>
	<para>
An IP alias or logical/virtual device is simply a string, which you'll
clearly see in the output of <command>ip addr show</command>:
	</para>
<programlisting><![CDATA[
root@laphish2:~# ip addr show
1: lo: <LOOPBACK,UP,10000> mtu 16436 qdisc noqueue
    link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00
    inet 127.0.0.1/8 scope host lo
2: eth0: <NO-CARRIER,BROADCAST,MULTICAST,UP> mtu 1500 qdisc pfifo_fast qlen 1000
    link/ether 00:08:74:9d:e7:0a brd ff:ff:ff:ff:ff:ff
3: eth1: <BROADCAST,MULTICAST,UP,10000> mtu 1500 qdisc pfifo_fast qlen 1000
    link/ether 00:0b:db:22:82:53 brd ff:ff:ff:ff:ff:ff
    inet 192.168.1.32/24 brd 192.168.1.255 scope global eth1
4: vmnet8: <BROADCAST,MULTICAST,UP,10000> mtu 1500 qdisc pfifo_fast qlen 1000
    link/ether 00:50:56:c0:00:08 brd ff:ff:ff:ff:ff:ff
    inet 172.16.39.1/24 brd 172.16.39.255 scope global vmnet8
5: vmnet1: <BROADCAST,MULTICAST,UP,10000> mtu 1500 qdisc pfifo_fast qlen 1000
    link/ether 00:50:56:c0:00:01 brd ff:ff:ff:ff:ff:ff
    inet 192.168.136.1/24 brd 192.168.136.255 scope global vmnet1
]]></programlisting>
	<para>
If I add a new IP address to the host, 
I can specify a physical interface to which it will add the routing entries 
and that "alias" string (label in <filename>iproute2</filename> speak):
	</para>
<programlisting><![CDATA[
root@laphish2:~# ip addr add 7.7.7.7/32 brd + dev eth0 label "eth0joe_bloggs"
root@laphish2:~# ip addr add 8.8.8.8/29 brd + dev eth0 label "eth0:ratzfatz"
root@laphish2:~# ip addr show dev eth0
2: eth0: <NO-CARRIER,BROADCAST,MULTICAST,UP> mtu 1500 qdisc pfifo_fast qlen 1000
    link/ether 00:08:74:9d:e7:0a brd ff:ff:ff:ff:ff:ff
    inet 7.7.7.7/32 scope global eth0joe_bloggs
    inet 8.8.8.8/29 brd 8.8.8.15 scope global eth0:ratzfatz

root@laphish2:~# ip route show dev eth0 table main
8.8.8.8/29  proto kernel  scope link  src 8.8.8.8
]]></programlisting>
	<para>
Even the eth0 is a string with no special meaning:
	</para>
<programlisting><![CDATA[
root@laphish2:~# ip link set dev eth0 down
root@laphish2:~# ip link set dev eth0 name kkk
root@laphish2:~# ip addr show dev eth0
Device "eth0" does not exist.
root@laphish2:~# ip addr show dev kkk
2: kkk: <BROADCAST,MULTICAST> mtu 1500 qdisc pfifo_fast qlen 1000
    link/ether 00:08:74:9d:e7:0a brd ff:ff:ff:ff:ff:ff
    inet 7.7.7.7/32 scope global kkk
    inet 8.8.8.8/29 brd 8.8.8.15 scope global kkk:2
root@laphish2:~# ip link set dev kkk up
root@laphish2:~# ip addr show dev kkk
2: kkk: <NO-CARRIER,BROADCAST,MULTICAST,UP> mtu 1500 qdisc pfifo_fast qlen 1000
    link/ether 00:08:74:9d:e7:0a brd ff:ff:ff:ff:ff:ff
    inet 7.7.7.7/32 scope global kkk
    inet 8.8.8.8/29 brd 8.8.8.15 scope global kkk:2
]]></programlisting>
	<para>
This should remedy the last concerns regarding the Linux networking on the
link and addressing level. What is interesting though is that if you rename
an existing device, the associated labels will get renames as well and
enumerated, so <command>ifconfig</command> will find it.
	</para>
	<para>
And for some final fun:
	</para>
<programlisting><![CDATA[
root@laphish2:~# ip addr add 9.9.9.9/29 brd + dev kkk label "kkklllllvvvv"
root@laphish2:~# ifconfig
eth1      Link encap:Ethernet  HWaddr 00:0B:DB:22:82:53
          inet addr:192.168.1.32  Bcast:192.168.1.255  Mask:255.255.255.0
          UP BROADCAST RUNNING MULTICAST  MTU:1500  Metric:1
          RX packets:71064 errors:0 dropped:0 overruns:0 frame:0
          TX packets:59472 errors:0 dropped:0 overruns:0 carrier:0
          collisions:0 txqueuelen:1000
          RX bytes:71731379 (68.4 MiB)  TX bytes:7894335 (7.5 MiB)
          Interrupt:11 Base address:0x8800

kkk       Link encap:Ethernet  HWaddr 00:08:74:9D:E7:0A
          inet addr:7.7.7.7  Bcast:0.0.0.0  Mask:255.255.255.255
          UP BROADCAST MULTICAST  MTU:1500  Metric:1
          RX packets:0 errors:0 dropped:0 overruns:0 frame:0
          TX packets:0 errors:0 dropped:0 overruns:0 carrier:0
          collisions:0 txqueuelen:1000
          RX bytes:0 (0.0 b)  TX bytes:0 (0.0 b)
          Interrupt:11 Base address:0x6c00

kkk:2     Link encap:Ethernet  HWaddr 00:08:74:9D:E7:0A
          inet addr:8.8.8.8  Bcast:8.8.8.15  Mask:255.255.255.248
          UP BROADCAST MULTICAST  MTU:1500  Metric:1
          Interrupt:11 Base address:0x6c00

kkklllllvvvv: error fetching interface information: Device not found
root@laphish2:~# ip addr show dev kkk
2: kkk: <NO-CARRIER,BROADCAST,MULTICAST,UP> mtu 1500 qdisc pfifo_fast qlen 1000
    link/ether 00:08:74:9d:e7:0a brd ff:ff:ff:ff:ff:ff
    inet 7.7.7.7/32 scope global kkk
    inet 8.8.8.8/29 brd 8.8.8.15 scope global kkk:2
    inet 9.9.9.9/29 brd 9.9.9.15 scope global kkklllllvvvv
]]></programlisting>
	<para>
Not only does ifconfig not show all the IP addresses configured to kkk, 
it also barfs about an unknown device, 
which actually is a label for an IP address. 
Thankfully we have iproute2, 
which displays the exact state of configuration.
	</para>
	</section>
	<section id="ifcfg">
	<title>Ratz's wrappers (for iproute2)</title>
	<para>
One of the problems with the <filename>iproute2</filename> utils is that
the syntax is not machine readable (and difficult for humans too).
Ratz has built some wrappers around these utils.
	</para>
	<para>
Ratz 25 Nov 2003
	</para>
	<para>
If you guys are interested I'll offer my first semi-official release of
some of the replacement tools I've written for ifconfig/route. You can
download them from
<ulink url="http://www.drugphish.ch/~ratz/iproute2/">Ratz's wrappers
http://www.drugphish.ch/~ratz/iproute2/</ulink>
	</para>
	<para>
It's still not really scriptable
(I wrote it
with really gross bash constructs and by using
external tools ;).
BUT, it solves some of architectural principles, such as separation of
concern, correctness, flexibility, conceptional integrity, coupling and
cohesion! You are given two tools to maintain almost everything network
related. (I'm aware that iptables/netfilter and mii-tool, ethtool are
also network related)
	</para>
	<para>
<command>ifconfig</command> gives you the (wrong) impression
that <filename>eth0:0</filename> is an interface,
just as others in the output <command>ifconfig -a</command>.
This is not true.
The <filename>iproute2</filename> tools
correctly displays the relationship between aliases/labels and
their corresponding physical interface.
	</para>
	<para>
Example:
	</para>

<programlisting><![CDATA[
laphish:~ # ifconfig -a | grep -A2 eth0
eth0      Link encap:Ethernet  HWaddr 00:20:E0:68:71:3A
           inet addr:172.23.2.131  Bcast:172.23.255.255  Mask:255.255.0.0
           inet6 addr: fe80::220:e0ff:fe68:713a/64 Scope:Link
--
eth0:0    Link encap:Ethernet  HWaddr 00:20:E0:68:71:3A
           inet addr:10.98.43.233  Bcast:10.98.43.255  Mask:255.255.255.0
           UP BROADCAST RUNNING MULTICAST  MTU:1500  Metric:1
--
eth0:foo  Link encap:Ethernet  HWaddr 00:20:E0:68:71:3A
           inet addr:10.23.7.233  Bcast:10.23.7.255  Mask:255.255.255.0
           UP BROADCAST RUNNING MULTICAST  MTU:1500  Metric:1
laphish:~ #
]]></programlisting>
	<para>
Sure, one could argue that all HWaddr of those "interfaces" are the same
and thus something with the interpretation of them being _real_ physical
interfaces must be fishy. But it gives you the wrong idea of connection
or entity relationship between link and ip layer.
	</para>
	<para>
Now let's compare the same output for iproute2:
	</para>
<programlisting><![CDATA[
laphish:~ # ip addr show dev eth0
2: eth0: <BROADCAST,MULTICAST,UP> mtu 1500 qdisc pfifo_fast qlen 100
     link/ether 00:20:e0:68:71:3a brd ff:ff:ff:ff:ff:ff
     inet 172.23.2.131/16 brd 172.23.255.255 scope global eth0
     inet 10.23.7.233/24 brd 10.23.7.255 scope global eth0:foo
     inet 10.98.43.233/24 brd 10.98.43.255 scope global eth0:0
     inet 10.239.10.1/24 brd 10.239.10.255 scope global eth0
     inet6 fe80::220:e0ff:fe68:713a/64 scope link
laphish:~ #
]]></programlisting>
	<para>
As you can see we have a physical interface (link layer entity) called
eth0 and associated with this interface we have 5 (not 4 like with
ifconfig) IP addresses. And you can certainly well spot the labels which
in ifconfig were displayed as independant interfaces at the end of each
line starting with inet, right?
	</para>
	<para>
Plus there you certainly noted that in the second output we have one
additional address which was not shown in the ifconfig output but is
very well routable and _is_ a valid configuration. I simply didn't want
to put an alias there.
	</para>
	<para>
Tools like <command>ipchains</command> and <command>iptables</command>
and their underlying state machine are better off matching for ip
addresses and the _one_ physical interface those are attached to then
trying to fiddle around with a label that is optional and doesn't give
you real valuable information. Additionally with <filename>iproute2</filename>
you have a
better approach to conceptional integrity which is one of the key
ingredients of architectures in that you say that even if I have
multiple addresses for one interface I still send out the packet through
the physical interface and not through a labeled, aliased or virtual
interface.
	</para>
	<para>
<command>ifconfig</command>
is an example of a "hiding complexity" tool.
Hiding complexity is a concept the software industry has not yet adopted
to the
extent that we can trust it, and thus <command>ifconfig</command>
is broken by design.
	</para>
	<para>
The reasons why people still use those deprecated tools are:
	</para>
	<itemizedlist>
		<listitem>
All other Unices still have those and it worked reliably for 10+ years
		</listitem>
		<listitem>
Most Linux Distributors except (notably) SuSE haven't switched their
   network setup to the iproute2 concept yet.
		</listitem>
		<listitem>
Documentation was seriously lacking and the tools are ... uhmm to a
   certain degree complex and incoherent in their syntax and semantics.
		</listitem>
	</itemizedlist>
	</section>
</section>
<section id="LVS-HOWTO.weird_hardware">
<title>LVS: Weird hardware (and software)</title>
	<section id="arp_caching">
	<title>Arp caching defeats Heartbeat switchover</title>
	<para>
Claudio Di-Martino <emphasis>claudio (at) claudio (dot) csita (dot) unige (dot) it</emphasis>
	</para>
	<blockquote>
		<para>
I've set up a LVS using direct routing composed of two linux-2.2.9
boxes with the 0.4 patch applied. The load balancer acts as a
local node too. I configured mon to monitor the state of the
services and update the redirect table accordingly. I also
configured heartbeat so that when the load balancer fails the
second machine takes over the virtual ip, sets up the redirect
table and starts mon. When the load balancer restarts, the backup
reconfigures itself as a realserver, drops the interface alias
that carries the virtual ip, stops mon, clears the redirect
table.  Although the configuration of the two machines is set up
correctly it fails to restore the load balancer due to arp
caching problems.
		</para>
		<para>
It seems that the local gateway keeps routing requests for the
VIP to the load balancer backup. Sending gratuitous arp
packets from the load balancer doesn't have effect since the
interface of the backup is still alive and responding.
		</para>
		<para>
Has anyone encountered a similar problem and is there a hack or a
proper solution to take back control of the virtual ip?
		</para>
	</blockquote>
	<para>
Antony Lee <emphasis>AntonyL (at) hwl (dot) com (dot) hk</emphasis>
	</para>
	<blockquote>
		<para>
I am new to LVS and I have a problem in setting up two LVSes
for failover issue. The problem is related to the ARP caching
of the primary LVS' MAC address in the realservers and the
router connected to the Internet. The problem leads all the
Internet connections stalled until all ARP caching in Web
Servers and router to be expired. Can anyone help to solve
the problem by making some changes in the Linux LVS ?
(It is because I am not able to change the router ARP cache
time. The router is not owned by the Web hosting company not by me.)
		</para>
		<para>
In each LVS, there are two network card installed. The eth0 is connected to
a router which is connected to the Internet. The eth1 is connected to a
private network which is the same segment as the two NT IIS4.
		</para>
<programlisting><![CDATA[
The eth0 of the primary LVS is assigned an IP address 202.53.128.56
The eth0 of the backup LVS is assigned an IP address 202.53.128.57
The eth1 of the primary LVS is assigned an IP address 192.128.1.9
The eth1 of the primary LVS is assigned an IP address 192.128.1.10
]]></programlisting>
		<para>
In addition, both primary and backup LVS have enabled the IPV4 FORWARD and
IPV4 DEFRAG. In the file /etc/rc.d/rc.local the following command was also
added:
		</para>
<programlisting><![CDATA[
ipchains -A -j MASQ 192.168.1.0/24 -d 0.0.0.0/0
]]></programlisting>
		<para>
I use the piranha to configure the LVS so that the two LVS have a common
IP address 202.53.128.58 in the eth0 as eth0:1. And have a IP address
192.128.1.1 in the eth1 as eth1:1
		</para>
		<para>
The pulse daemon is also automatically be run when the two LVSes were
booted.
		</para>
		<para>
In my configuration, the Internet clients can still access to our
Web server with one of the NT was disconnected from the LVS. The backup
LVS --CAN AUTOMATICALLY-- take up the role of the primary LVS when
the primary LVS is shut down or disconnected from the backup LVS.
However, I found that all the NT Web Servers cannot reach the backup
LVS through the common IP address 192.128.1.1, and all the Internet clients
stalled to connect to our web servers.
		</para>
		<para>
Later, I found that the problem may due to the ARP caching in the Web
Servers and router. I tried to limit the ARP cache time to 5 seconds
in the NT servers and half of the problem has solved ,i.e. the NT
Web servers can reach the backup LVS through the common IP
address 192.128.1.1 when the primary LVS was down. However, it
is still cannot be connected through the Internet clients
when the LVS failover occur.
		</para>
	</blockquote>
	<para>
Wensong
	</para>
	<blockquote>
		<para>
I just tried two LVS boxes with piranha 0.3.15. When the primary LVS stops
or fails, the backup will take over and send out 5 Gratuitous Arp
packets for the VIP and the NAT router IP respectively, which should clean
the ARP caching in both the web servers and the external router.
		</para><para>
After the LVS failover occurs, the established connections from the
clients will be lost in the current version, and the clients need to
re-connection the LVS.
		</para>
<programlisting><![CDATA[
.. 5 ARP packets for each IP address, and 10 for both the VIP and
the NAT router IP. I saw the log file as follows:

Mar  3 11:12:14 PDL-Linux2 pulse[4910]: running command "/sbin/ifconfig" "eth0:5" "192.168.10.1" "up"
Mar  3 11:12:14 PDL-Linux2 pulse[4908]: running command "/usr/sbin/send_arp" "-i" "eth0" "192.168.10.1" "00105A839CBE" "172.26.20.255" "ffffffffffff"
Mar  3 11:12:14 PDL-Linux2 pulse[4913]: running command  "/sbin/ifconfig" "eth0:1" "172.26.20.118" "up"
Mar  3 11:12:14 PDL-Linux2 kernel: send_arp uses obsolete (PF_INET,SOCK_PACKET)
Mar  3 11:12:14 PDL-Linux2 pulse[4909]: running command "/usr/sbin/send_arp" "-i" "eth0" "172.26.20.118" "00105A839CBE" "172.26.20.255" "ffffffffffff"
Mar  3 11:12:17 PDL-Linux2 nanny[4911]: making 192.168.10.2:80 available
]]></programlisting>
		<para>
I don't know if the target addresses of the 2 send_arp commands are set
correctly. I am not sure if it is different when broadcast or source IP is
used as target address, or any target address is OK.
		</para>
	</blockquote>
	<para>
Horms
	</para>
	<blockquote>
Are there just 5 ARPs or 5 to start this and then more gratuitous
ARPs at regular intervals. If the gratuitous ARPs only occur at
fail-over then once the ARP caches on hosts expire there is
a chance that a failed host - whose kernel is still functional -
could reply to an ARP request.
	</blockquote>
	<para>
<emphasis>wanger (at) redhat (dot) com</emphasis>
	</para>
	<blockquote>
		<para>
When we put this together, I talked to Alan Cox about this.  His
opinion was that send 5 ARPs out at 2 seconds apart.  If there is
something out there listening and cares, then it will pick it up.
		</para><para>
The way piranha works, as long as the kernel is alive, the backup (or
failed node) will not maintain any interfaces that are Piranha managed.
In other words, it removes any of those IPs/interfaces from its routing
table upon failure recovery.
		</para>
	</blockquote>
	</section>
	<section id="router_weirdness">
	<title>Weird Hardware I: cisco catalyst routers gratuitously cache arp data (failover is slow)</title>
	<para>
Some hardware manufacturers release equipment with broken tcpip implementations.
	</para>
	<para>
Sean Roe May 06, 2004 
	</para>
	<blockquote>
		<para>
I was looking for some info on cisco catalyst switches to help speed up
the failover between my two director boxes. I have the following LVS-NAT setup:
		</para>
<programlisting><![CDATA[
                   |--------|-----|WebServer1|
       -- |LVS01|--|Cisco   |-----|WebServer2|
       |           |        |-----|WebServer3|
 ------|           |Catalyst|-----|WebServer4|
       |           |        |-----|WebServer5|
       -- |LVS02|--|Switch  |-----|WebServer6|
                   |--------|
  Virt     LVS                    Real
  IP       Servers                Servers
]]></programlisting>
		<para>
My Problem is that if lvs01 fails lvs takes over the load, 
but it takes forever (5-6 minutes).
for the realservers to start using the new director.
It also seems that it works faster, 
if I actually restart the httpd on each webserver. 
This is a LVS-NAT with multiple virtual IPS going to different ports on the webservers.
		</para>
	</blockquote>
	<para>
John Reuning <emphasis>john (at) metalab (dot) unc (dot) edu</emphasis> 23 Apr 2004
	</para>
	<para>
I've seen a similar delay in failover when using cisco routers.  They
don't update the internal MAC address table after receiving gratuitous
arp packets during an LVS director failover event.  I don't know if the
heartbeat package uses arps to fail over, but keepalived does.  Cisco
routers seem to need icmp packets before they'll update the MAC address
table.  For LVS, the problem here is that the router continues to send
traffic to the VIP at the master's hw address instead of shifting to the
backup's hw address.
	</para>
	<para>
However, this wouldn't explain why your realservers route to the wrong
address.  The realservers and the LVS directors are on the same network
segment, right?  
	</para>
	<para>
The problem isn't with the layer-2 switches, it's with the
next-hop router (the external default gateway for the LVS directors). 
It's common behavior with Cisco routers to update their arp cache table
in response to source-generated packets but not in response to
gratuitous arp packets.
	</para>
	<para>
Peter Mueller 
	</para>
	<para>
I've seen a similar delay in failover when using cisco routers.  
	</para>
	<para>
Malcolm Turnbull <emphasis>malcolm (at) loadbalancer (dot) org</emphasis> 24 Apr 2004
	</para>
	<para>
Me too, ISPs often configure managed routers to not respond to arp 
requests. You tend to have to ask them to flush the routing table if you 
change any of your router facing ips.
I'm sure the routers can be configured to respond to ARPs
	</para>
	<para>
Horms 07 May 2004
	</para>
	<para>
Sounds like there could be a problem with your gratuitous arps
that are supposed to effect failover. 
I have used catalyst swithces quite a lot, in fact both my
test rack and the main switch for the network here at VA Japan
used catalyst switches. I have found that they are quite aggressive
about caching ARP information, and in some cases seem to effect
proxy arp. But the current send_arp code in heartbeat seems to work just
fine. Actually, I some times run that command manually after rearanging
IP addresses on machines.
	</para>
	</section>
	<section id="weird_hardware_II">
	<title>Weird Hardware II: autonegotiation failure on cisco CSS 11050</title>
	<para>
Ed Fisher <emphasis>efisher (at) mrskin (dot) com</emphasis> 08 Feb 2005
	</para>
	<para>
We're trying to setup LVS to serve as a drop-in replacement for a pair 
of Cisco CSS 11050s. 
We aren't doing any fancy layer 7 stuff on the CSS, 
like passing certain directories to other servers, 
or anything like that.
I got it all setup, working, 
and I was able to drop it in for the CSSes pretty smoothly.  
Our traffic spikes on the CSS reach 90mbit/s.  
Not huge by a lot of standards, but still sizable.  
The CSS was pushing out about 50mbit/s when we cut over to the LVS-NAT box, 
and traffic immediately dropped to about 20mbit/s, never breaking 30.
A test download from a box on another network, 
with a 100mbit connection to the Internet, 
was able to download a single file at well over 40mbit/s through the CSS.  
Through the LVS, it peaked at 1Mbit/s at the beginning 
and then quickly fell to about 300kbit/s after a few seconds, and stayed there.
The hardware for the LVS machine: P4 2.26ghz, 2GB of memory.  
Two e1000 NICs, but both are hooked up to 100mbit switches, 
since we haven't done our gigabit upgrade yet.
	</para>
	<para>
The problem turned out to be that I was plugging into an extreme 24e2 switch, 
which was uplinked to an extreme 1i router.  
It was the connection between the 24e2 and the 1i that was bad.  
The 1i was set to force full duplex, the switch was set to autonegotiate, 
and so was, for annoying reasons, defaulting to half duplex.   
I plugged the LVS machine directly into the 1i, 
set the port to auto-negotiate on the 1i and the LVS machine, 
and linked up at 1000baseT FD and performance increased dramatically. 
Testing without the css in the mix showed I was indeed able to saturate the link.
	</para>
	</section>
	<section id="firewall_weirdness">
	<title>Weird Hardware III: Watchguard firewall at client site</title>
	<para>
Jacob Coby <emphasis>jcoby (at) listingbook (dot) com</emphasis> 29 Jul 2005
	</para>
	<blockquote>
		<para>
I've got a client IP addr that, on occassion, 
takes up a mass of connections and leaves them in an ESTABLISHED state.  
The IP addr is of a business that uses our website, 
but it's causing a DOS of sorts. 
		</para>
		<para>
Software:
		</para>
<programlisting><![CDATA[
ipvsadm v1.21 2002/07/09 (compiled with popt and IPVS v1.0.4)
kernel-2.4.20-28.7.um.3
redhat 7.3
]]></programlisting>
		<para>
Symptoms:
		</para>
		<itemizedlist>
			<listitem>
Connections jump from 50-100 up to 300-600.
			</listitem>
			<listitem>
A single IP address takes up 80-90% of those connections.
			</listitem>
			<listitem>
All of the connections from that ip address are in the ESTABLISHED state.
			</listitem>
			<listitem>
Very few of them are actually sending/receiving data 
(when using <command>tcpdump -xX -s 1024  "host bad.ip.addr"</command>).  
   I see a few packets with the F and S flags set.
			</listitem>
		</itemizedlist>
		<para>
I have disabled Keepalive on the real servers (Keepalive on allows them to close connection by themselves). 
It's too expensive to keep enabled for our site.
Any ideas?  snort logs don't show anything malicious from the ip.
Because these are all ESTABLISHED connections to our website, 
they're taking up an apache process, and eventually locking everyone else out.
		</para>
	</blockquote>
	<para>
Graeme Fowler
	</para>
	<para>
Since it's an application-level problem your LVS is doing exactly what it should :)
	</para>
	<para>
Jacob
	</para>
	<blockquote>
Yeah, that's what I was thinking.  
I didn't know if LVS was accidently not FIN'ing connections or whatever.
	</blockquote>
	<para>
Graeme
	</para>
	<para>
If you switch on the extended status and server-status handlers in Apache, 
you can check what Apache thinks is happening, at the very least. 
If it's always the same source IP, 
I'd consider tracking down what the machine is 
and seeing if (for example) it's a broken proxy, 
or whether you can actually route back to it 
- if the latter then it could be a simple network problem (or even a complex one!).
	</para>
	<para>
Jacob
	</para>
	<blockquote>
I'd forgotten about the server-status modules.. I've actually got them enabled.
As for trying to route back to the ip addr, good idea.  
I'll try that next time the issue happens.
I know the ip addr is a NAT firewall, 
so it could be the firewall, 
it could be an office computer, 
or it could be a personal notebook causing the problem.  
They've scanned all of their computers for viruses.  
My only thought at this point is some spyware is screwing up the tcp stack 
and isn't closing connections.
	</blockquote>

	<para>
later...
	</para>
	<blockquote>
As an update, we traced this back to a problem with the firewall the company is using.  
Both firewalls are made by Watchguard (http://www.watchguard.com).  
They are different models - 
one is a Firebox and I'm not sure what the other is.  
The Firebox apparently can operate in two NAT modes: direct (?) and proxy.  
In direct mode, it is leaving hundreds of connections in the EST state.  
In proxy mode, it works correctly.
The other firewall can only act in direct mode, 
so it is still causing a problem.
	</blockquote>
	</section>
	<section id="weird_hardware_IV">
	<title>Weird Hardware IV: wrong device gets MAC address</title>
	<note>
An HP ProCurve switch is used in this installation, 
but Horms doesn't think it's the problem.
	</note>
	<para>
Troy Hakala <emphasis>troy (at) recipezaar (dot) com</emphasis> 
	</para>
	<blockquote>
In an LVS-NAT setup, on a rare occassion, the ARP cache of one of the 
realservers gets the wrong MAC address for the director, I assume after a
re-ARP. It gets the MAC of eth0 instead of eth1. It's easy to fix with an
arp -s, but I'd like to understand why this happens.
	</blockquote>
	<para>
Horms 18 Nov 2005
	</para> 
	<para>
Taking a wild guess, I would say that eth1 is handling a connection
that has the VIP as the local address. And during the course of
that connection, the local arp cache expires. The director
sends an arp-request to refresh its cache. However, the
source address of the ARP requests is the VIP, as it is a connection
to the VIP that caused the ARP requests. ARP requests actually
act as ARP announcements. And thus the MAC of eth0 is advertised
as the MAC of the VIP.
	</para>
	<para>
Just a guess. If its correct, then this is exactly the
problem that the arp_announce proc entry is designed to address.
Or alternatively you can use <xref linkend="arptables"/>.
	</para>
	<para>
This is the second half of the ARP problem that has to be solved
when doing LVS-DR, and I have some limited explanation of it
at http://www.ultramonkey.org/3/topologies/hc-ha-lb-eg.html#real-servers
Just ignore the bits that aren't about either <filename>arp_announce</filename> or
<command>/sbin/arptables -A OUT -j mangle</command>...
	</para>
	<para>
It could also be that for some completely perverse reason
eth1 is receiving an ARP request for the VIP. If that case
you are really in the same boat as using LVS-DR.
	</para>
	</section>
	<section id="weird_hardware_V">
	<title>Weird Hardware V: SonicWAll firewall rewriting sequence numbers</title>
	<para>
G. Allen Morris III <emphasis>gam3-lvs-users (at) gam3 (dot) net</emphasis>6 Mar 2006
	</para>
	<para>
It seems that the firewall changes the sequence number of packets
comming in (changing them again on the way out). This of course breaks
LVS-Tun as the sequence number does not get restored when it leaves the
network wrapped in the IPIP packet.
	</para>
	<para>
I can not find any SonicWALL documentation and would like to know if
anyone here knows if there is a fix for this.
	</para>
	</section>
	<section id="weird_hardware_VI">
	<title>Weird Hardware VI: cisco 2924XL switch</title>
	<para>
Tony Spencer <emphasis>tony (at) games-master (dot) co (dot) uk</emphasis> 10 Mar 2006
	</para>
	<para>
We have a couple LVS's running on Centos 4.2 they are working fine and
failover as they should, the backup server takes the VIP when the primary
server is taken offline.
However I've noticed an issue when the failover occurs.
	</para>
	<para>
From inside our network we can get to web sites and radius server using the
VIP when the failover occurs.
But from outside our network we can't, the connection fails.
Both servers are plugged into a Cisco 2924XL switch which sees the IP move
from one port to another when it fails over.
Into the same switch is our upstream link also.
	</para>
	<para>
Could it be an arp issue with the upstream because the MAC address of the
VIP has changed?
I thought this at first but even when I brought the primary server backup so
the VIP was on the same MAC address it still wouldn't work.
	</para>
	</section>
	<section id="weird_hardware_VII" xreflabel="weird hardware VII">
	<title>Weird Hardware VII: unknown switches don't defragment</title>
	<para>
Andreas Lundqvist <emphasis>lvs (at) rsv (dot) se</emphasis> 1 Nov 2006 
	</para>
	<para>
I have a LVS running on Suse Sles9 with three linux realservers and direct routing.
This is part of our intranet that spans nationwide and upon launch here this 
Monday I had not run into any problems what so ever. 
This isn't the case anymore..
My problem is that clients in two sites in different city's are getting their 
connections the status FIN_WAIT and will not timeout, so now I have 15000 
FIN_WAIT's per realserver and still rising each day.
Other sites including the site I'm in does not have this problem, my 
FIN_WAIT's from my PC times out just fine.
	</para>
	<para>
I'm told by our network guy's that just these two sites are indeed running 
different network hardware than our other sites (cisco). 
	</para>
	<para>
Later - We seem to have found a workaround.
The problem is that our WAN only allows packets with maximum size of 1518 and 
with encryption headers we exceed that. Our other site's fix this in their 
switches before sending it out on our WAN but this is apparently not 
supported in the switches on my two problem site's.
So the fix was to lower MTU on my three Realservers to 1400.
I had to reboot my LVS server to free the hanging FIN_WAIT's 
- I tried to just unload the modules but it just hung the rmmod command.
	</para>
	</section>
	<section id="weird_hardware_VIII" xreflabel="weird hardware VIII">
	<title>Weird Hardware VIII: bad routers/routing tables at ISP</title>
	<para>
Matthew <emphasis>matthew (at) matthewboehm (dot) com</emphasis>, 20 Feb 2007
	</para>
	<para>
We've been running a 3 machine setup (1 dir, 2 rs) in TUN mode for
about the past 2 months.
Recently we've had this affliction where if you goto the VIP,
everything is super slow. 
But if you goto RS1 or RS2 everything is blazing fast (about a 10x difference in bandwidth).
This problem started this morning for the 2nd time. It happened about
2 weeks ago but we did nothing to the setup and the problem seemed to
fix itself. But now that it's happened again we need some answers.
I'd also add that my connection from home doesn't have this problem.
From home, the VIP, RS1 and RS2 are all blazing fast. 
But we just had a
customer call from Chicago who was getting slow speeds.
Here in our office its slow as well to VIP but not to RS1, RS2.
	</para>
	<para>
Matthew <emphasis>matthew (at) matthewboehm (dot) com</emphasis> 22 Feb 2007 
	</para>
	<para>
Well isn't this fan-damn-tastic. Turns out it wasn't our problem at all.  
We noticed that things started picking up speed around 3.  
We all assumed it was because I moved the VIP to point to RS1, thus bypassing the LVS.
From our hosting provider, thePlanet.com:
	</para>
	<blockquote>
After careful analysis of outbound throughput issues with various providers The Planet engineers determined that a gradual route
table exhaustion was at the core of an increasing number of issues. It was determined that to repair this issue an emergency
reload of the router dsr01.dllstx3 was required. At approximately 2:42pm CST we reloaded this router. There was a brief period
of packet loss as the redundant assumed the load and at 2:51pm CST as the router re-converged. By 2:53pm CST all traffic was
forwarding normally.
	</blockquote>
	<para>
Amazing.
	</para>
	</section>
	<section id="wierd_hardware_IX">
	<title>Possible Wierd Hardware (or driver) IX: Broadcom GigE card</title>
	<note>
This is one of those frustrating set of posts where the person disappears without letting us know what happened.
We don't know if there really is a problem, or what it is. 
It might serve as an example of how to go about figuring out such problems.
	</note>
	<para>
Jesse Cantara <emphasis>jesse_cantara (at) esupport (dot) com</emphasis> 20 Jul 2007 
	</para>
	<para>
I'm trying to figure out a problem I'm having with my LVS-NAT setup.
It's a very simple setup, one director, two networks (director has two
nics, one on lan one on internet), three webservers on LAN only on port
80. The issue I'm having is occasionally and randomly the director will
apparently just sever the connection when trying to download a file from
the webserver. I have performed these tests just fine without issue:
1) Downloading a file directly from the director to a client
2) Downloading a file from the webserver to the director
So it would appear that the physical connection is OK, I can make
connections to the individual machines without problem, just when
connecting through the director to the webserver.
	</para>
	<para>
What happens is I will be downloading a file, and it will hang (at
random points during the download, sometimes not at all), and not continue.
<command>ipvsadm</command> will show "ESTABLISHED" on that connection for quite a long
time, then "ERR!" after it times out I believe.
Watching the traffic on a packet-sniffer client-side shows that directly
before the failure, my client keeps sending the same "ack" message back
to the server over and over, and the server appears to not recognize it.
	</para>
	<para>
later...
	</para>	
	<para>
This might be a hardware/driver issue. I'm having basically the exact 
same problem when attempting to use IPTABLES on the director just as a 
simple NAT router to one webserver (trying to isolate the problem), and 
I still get the exact same behavior (connection closes randomly). So the 
problem doesn't appear to be limited to IPVS anyway.
The machine I'm using for the director/router is a Dell 860 with a 
Broadcom NetXtreme BCM5721 with the "Tigon3" (tg3.ko) driver.
	</para>
	<para>
Here is the config of my machines:
CentOS 5
latest kernel 2.6.18-8.1.8.el5
ipvsadm v1.24
IPVS v1.2.0
	</para>
	<para>
later...
	</para>
	<para>
It is definitely a driver issue. The tg3 broadcom 
kernel module doesn't seem to work properly at gigabit speeds. 100 mbit 
works fine (which is OK in this situation).
	</para>
	<para>
Tobias Klausmann <emphasis>klausman (at) schwarzvogel (got) de</emphasis> 23 Jul 2007
	</para>
	<para>
Then I'd look into the matter more closely. We use about 1k
machines with tg3 chips, some 500 of them in farms using GE links
and have had no hiccups whatsoever (beyond the usual amount of
simply broken hardware which was replaced). CErtainly no
systemativ error.
Don't forget that your switching infrastructure might be at
fault, too.
	</para>
	<para>
Jesse
	</para>
	<para>
The device on my machine is the Broadcom BCM5721, and the reason why I 
decided that the driver was at fault is because I found somebody else 
online with the same problem and that particular model of Broadcom NIC.
	</para>
	<para>
Tobias
	</para>
	<para>
My fault, I neglected to take into consideration that the tg3
driver supports more than one particular chip(set).
Our machines have BCM5703X GE chips. We also have machines that
have BCM5708 chips, but those are served by another driver
(bnx2).
	</para>
	<para>
The question is on which layer the error originates (as opposed
to where you *see* it). This can be as simple as using wireshark
to see the connection break down (can be a hassle if it takes
long to trigger) or be as full-fledged as bringing in a hardware
network analyzer. The order should be obvious :)
	</para>
	<para>
Jesse
	</para>
	<para>
I have replaced some of the switching hardware, but not all of it. The 
reason why I don't think it is the switch or cables is because direct 
system-to-system communication works just fine, it's only when I'm doing 
any sort of packet-forwarding (with lvs-nat or just simple iptables 
port-forwarding).
	</para>
	<para>
That surely points to software rather than hardware. Do you have
any funky iptable setups that might interfere? Also you might
want to try to use add-in GE boards but keep everything else the
same. Intel's EEPro1000 might be worth a try - it uses an
entirely different driver, yet it's readily available. That way,
you could rule out both the NIC hw and the driver.
	</para>
	</section>
	<section id="slow_nics">
	<title>slow nics</title>
	<para>
With everyone expecting 1GBps throughput, you need to choose your ethernet cards carefully.
Mikio was using 2.6.18, which has proven to be a buggy kernel. 
Someone recommended that he get a better kernel.
	</para>
	<para>
Mikio Kishi <emphasis>mkishi (at) 104 (dot) net</emphasis> 24 Nov 2008
	</para>
	<blockquote>
With new connections/sec &gt;15,000, %CPU  ksoftirqd went to 100% 
eth0: (PCI Express:2.5GB/s:Width x1), eth0: Intel(R) PRO/1000 Network Connection.
	</blockquote>
	<para>
Graeme
	</para>
	<para>
There's only so many
interrupts you can generate from one NIC before the CPU wedges - and in
most cases every packet generates in interrupt. If you're using
plain-old-PCI, you get less throughput than more advanced PCI variants.
	</para>
	</section>
	<section id="PCI-X">
	<title>PCI-X nics</title>
	<para>
Joe:
commodity PCI-X has not worked well, due to clock skews on 
the 2X-wide bus (you can't get 128 lines to go up and down together). 
IBM got it to work in their high end 
hardware because they made the mobo and the NIC and could 
guarantee that they would work together on their 
implementation of the PCI-X bus. The chances of a commodity 
PCI-X mobo working with someone else's PCI-x NIC aren't real 
good and PCI-X has been abandonned for PCI-e.
	</para>
	<para>
Sashi Kant <emphasis>sashi (dot) kant (at) eng (dot) admob (dot) com</emphasis> 24 Oct 2008 
was having RX Packet drops on high traffic LVS in DR setup.
	</para>
	<para>
Here's his cure:
	</para>
	<itemizedlist>
		<listitem>
Intel PCIe gigabit dual port card with RX buffer tuned at 1024 using
ethtool
		</listitem>
		<listitem>
No need for port channel as switch ports are Gig capable and
bandwidth is not an issue.
		</listitem>
		<listitem>
Bonding will be used in active-backup mode as it is not negatively
impacting the server.
		</listitem>
		<listitem>
No more packet drops at 60k pps with above changes.
		</listitem>
		<listitem>
Getting rid of Broadcom PCI-X cards from HA servers.
		</listitem>
	</itemizedlist>
	</section>
	<section id="Microsoft_http" xreflabel="Microsoft_http">
	<title>Microsoft http clients and servers violate the RFC for TCP/IP</title>
	<para>
<ulink url="http://grotto11.com/blog/slash.html?+1039831658">
In case you're getting funny results
</ulink>
	</para>
	</section>
	<section id="ie_ssl_bug">
	<title>MSIE SSL bugs</title>
		<section id="msie_ssl_bug_1">
		<title> MSIE SSL bug 1</title>
		<para>
Benoit Gauthier <emphasis>gauthier (at) circum (dot) com</emphasis> 22 May 2008 
		</para>
		<blockquote>
			<para>
We are experiencing a bizarre problem involving LVS, SSL and Internet
Explorer. 
			</para>
			<para>
We have an LVS cluster comprised of one load balancer connecting to
six real servers. Each real server serves Apache requests to a ,cgi
script located on a backend server that is accessed by each node using
NFS. This setup has worked well so far, both using regular requests
and SSL requests.
			</para>
			<para>
A problem appeared last week soon after we migrated the cluster from
using public IP addresses for real servers to using local (192.168) IP
addresses (i.e., we went from DR to NAT). Non-SSL requests are handled
fine. SSL requests made directly to the backend server (i.e., avoiding
the LVS cluster) are handled fine. SSL request handled by the LVS
cluster are fine if they are issued by any browser other than Internet
Explorer 5 (and Internet Explorer 6 in the case of one tester). But
Internet Explorer 5 SSL requests to the load balancer are sometimes
handled correctly, but, other times, they either return the same page
instead of the requested page or they return a browser error page
(browser cannot reach the page).
			</para>
			<para>
To add to the difficulty, it appears that these errors are not
actually produced by the Apache server: one of the testers has a slow
Internet connection and can clearly feel a lag when the next page is
being properly processed; when an error page is returned, it comes up
immediately, suggesting that no Internet communication took place.
			</para>
			<para>
We can replicate the
problem fairly easily. The problem does NOT recur if we limit the
&lt;img&gt; tags on the page to a single image. If we add a second &lt;img&gt; tag
(coded as &lt;img src=dir/image.gif&gt;), we can produce the problem.
The images are all static (not dynamically generated).
			</para>
			<para>
We added a "persistent=300" line in ldirector.conf. To no avail.
			</para>
		</blockquote>
		<para>
Graeme
		</para>
		<para>
Hrm. Has your Apache SSL config got the following lines?
		</para>
<programlisting><![CDATA[
SetEnvIf User-Agent ".*MSIE.*" \
         nokeepalive ssl-unclean-shutdown \
         downgrade-1.0 force-response-1.0
]]></programlisting>
		<para>
They can be set in the vhost context, or globally.
See <ulink url="http://www.modssl.org/docs/2.8/ssl_faq.html#ToC49">ssl_faq.html</ulink>
(http://www.modssl.org/docs/2.8/ssl_faq.html#ToC49) for details.
		</para>
		<para>
Also, have you got keepalives switched on in your Apache config?
		</para>
		<para>
Benoit
		</para>
		<blockquote>
			<para>
The following instruction was in the general definition of the ssl
portion:
<programlisting><![CDATA[
BrowserMatch ".*MSIE.*" \
         nokeepalive ssl-unclean-shutdown \
         downgrade-1.0 force-response-1.0
]]></programlisting>
and no keepalive instruction elsewhere in the Apache config.
			</para>
			<para>
I inserted this right after the "Listen 443" in the
Apache SSL configuration:
			</para>
<programlisting><![CDATA[
SetEnvIf User-Agent ".*MSIE.*" \
         nokeepalive ssl-unclean-shutdown \
         downgrade-1.0 force-response-1.0
]]></programlisting>
			<para>
as opposed to the 'BrowserMatch ".*MSIE.*"' instruction that I already
had. And this worked! After about 50 page tests, no errors were
reported.
			</para>
			<para>
Thanks again. And let's all pray for the demise of Internet Explorer.
			</para>
		</blockquote>
		</section>
		<section id="msie_ssl_bug_2">
		<title> MSIE SSL bug 2</title>
		<para>
Daniel Kerrutt <emphasis>d (dot) kerrutt (at) googlemail (dot) com</emphasis> 25 Jun 2008 
		</para>
		<blockquote>
			<para>
I posted this subject to microsoft.public.internetexplorer.general,
but wanted to ask for help here, too.
			</para>
			<para>
I have a problem while connecting to a loadbalanced website via SSL.
Sometimes IE is displaying an "Page cannot be displayed" error
message. Sometimes the error is happening instantly, sometimes after
entering the URL 3-4 times.
			</para>
			<para>
Server software is Apache 2.2 / mod_ssl
Keep-Alive is forced to turn off with the following configuration
statement with SSL connections:
			</para>
<programlisting><![CDATA[
SetEnvIf User-Agent ".*MSIE.*" nokeepalive ssl-unclean-shutdown
downgrade-1.0 force-response-1.0
]]></programlisting>
		</blockquote>
		<para>
Joe
		</para>
		<para>
Graeme replied to a similar problem on 22 May (IE and 
apache/ssl). Go look in the archives.
the source of the problem is described here.
http://www.modssl.org/docs/2.8/ssl_faq.html#ToC49
I don't know why this is a problem when connecting through a director, 
but not when connecting directly, so I may not understand the problem
		</para>
		<para>
Daniel
		</para>
		<blockquote>
			<para>
Ok, finally its fixed..
Turned out that SSL session cache was not activated across all
realservers - so I did hit the IE bug.... *use head with wall*
			</para>
			<para>
Although not a problem of LVS itself, it might be an environment where
users possibly meet this MSIE bug.
Right now I cannot confirm that the error is happening _only_ through
LVS, because there was an inconsistent configuration throughout the
realservers with my setup, which I did not notice.
This means that I maybe tested the direct connection on a proper
configured realserver, but another case could perhaps confirm that
(http://archive.linuxvirtualserver.org/html/lvs-users/2008-05/msg00062.html).
			</para>
			<para>
One part of the solution was turning off keep-alive for MSIE clients
as posted before by Graeme
(http://archive.linuxvirtualserver.org/html/lvs-users/2008-05/msg00074.html),
which is not configured by default with a standard Debian Apache setup
(AFAIR).
			</para>
			<para>
But in my case, the actual error was something else:
Make sure that the SSLSessionCache is activated, like described at the
bottom of the subject here:
http://www.modssl.org/docs/2.8/ssl_faq.html#ToC49
			</para>
<programlisting><![CDATA[
SSLSessionCache        shmcb:/var/run/apache2/ssl_scache(512000)
SSLSessionCacheTimeout  300
]]></programlisting>
			<para>
The SSLSessionCache directive should be activated by default with a
standard Apache setup.
But in my case it happened that it was not activated across all the realservers.
			</para>
			<para>
All solutions are described in the SSL-FAQ
http://www.modssl.org/docs/2.8/ssl_faq.html#ToC49, therefore you can
possibly refer to the SSL-FAQ somewhere in the HOWTO, because users
might meet this problems within the LVS environment.
			</para>
		</blockquote>
		</section>
	</section>
</section>
<section id="LVS-HOWTO.wisdom">
<title>LVS: Misc/FAQ/Wisdom from the mailing list</title>
	<para>
These topics were too short or not central enough to LVS operation
to have their own section.
	</para>
	<section id="multiple_VIPs">
	<title>Having one director handling multiple LVS sites, Multiple VIPs</title>
	<para>
Multiple VIPs (and their associated services) can co-exist independantly
on an LVS.
On the director, add the extra IPs to a device facing the internet.
On the realservers, for LVS-DR||VS-Tun, add the VIPs to a device
and setup services listening to the ports.
On the realservers, for LVS-NAT, add the extra services to the RIP.
	</para>
	<para>
Keith Rowland wrote:
	</para>
	<blockquote>
 Can I use Virtual Server to host multiple domains on the
 cluster? Can VS be setup to respond to multiple 10-20 different
 IP addresses and use the clusters to reposnd to any one of them
 with the proper web directory.
	</blockquote>
	<para>
James CE Johnson <emphasis>jjohnson (at) mobsec (dot) com</emphasis>
	</para>
	<para>
If I understand the question correctly, then the answer is yes :-)
I have one system that has two IP addresses and responds to two names:
	</para>
<programlisting><![CDATA[
  foo.mydomain.com  A.B.C.foo  eth1
  bar.mydomain.com  A.B.C.bar  eth1:0
]]></programlisting>
	<para>
On that system (kernel 2.0.36 BTW) I have LVS setup as:
	</para>
<programlisting><![CDATA[
  ippfvsadm -A -t A.B.C.foo:80 -R 192.168.42.50:80
  ippfvsadm -A -t A.B.C.bar:80 -R 192.168.42.100:80
]]></programlisting>
	<para>
To make matters even more confusing, 192.168.42.(50|100) are
actually one system where eth0 is 192.168.42.100 and eth0:0 is
192.168.42.50.  We'll call that 'node'.
	</para>
	<para>
Apache on 'node' is setup to serve foo.mydomain.com on ...100 and
bar.mydomain.com on ...50.
	</para><para>
It took me a while to sort it out but it all works quite nicely.
I can easily move bar.mydomain.com to another node within the
cluster by simply changing the ippfvsadm setup on the externally
addressable node.
	</para>
	<para>
Tao Zhao 6 Nov 2001
	</para>
	<blockquote>
what if I need multiple VIPs on the realserver?
	</blockquote>
	<para>
Julian Anastasov <emphasis>ja (at) ssi (dot) bg</emphasis> 06 Nov 2001
	</para>
<programlisting><![CDATA[
for i in 180 182 182
do
	ip addr add X.Y.Z.$i dev dummy0
done
]]></programlisting>
	<para>
There is also an example for
<link linkend="multiple_VIPs_2">setting up multiple VIPs on HA</link>.
	</para>
	</section>
	<section id="lvs_inetd" xreflabel="LVS and inetd">
	<title>Setting up a fake service on the realserver with inetd</title>
	<para>
Ratz <emphasis>ratz (at) tac (dot) ch</emphasis>
	</para>
	<para>
We're going to set up a LVS cluster from scratch.
you need
	</para>
	<itemizedlist>
		<listitem>
4 machines (2 realserver, 1 load balancer, 1 client) wired like described in
  various sketches throughout this howto.
		</listitem>
		<listitem>
fun and some spare time (actually quite some if it doesn't work out the first
  time like described)
		</listitem>
	</itemizedlist>
	<para>
The goal is to set up an loadbalanced tcp application. The application will
consist of a own written shell script being invoked by inetd. As you might have
guessed, security is very low priority, you should get the idea behind this. Of
course I should take xinetd and of course I should use a tcpwrapper and maybe
even SecurID authentication but here the goal is to understand the fundamental
design principals of a LVS cluster and its deploy. All instructions will be done
as root.
	</para>
	<para>
Setting up the realserver
	</para>
<programlisting><![CDATA[
Edit /etc/inetd.conf and add following line:
lvs-test        stream  tcp     nowait  root    /usr/bin/lvs-info       lvs-info

Edit /etc/services and add following line:
lvs-test        31337/tcp               # supersecure lvs-test port
]]></programlisting>
	<para>
Now you need to get inetd running. This is different for every Unix. So please
have a look at it yourself. You verify if it's running with 'ps ax|grep [i]netd'
And to verify if it really runs this port you do a 'netstat -an|grep LISTEN' and
if there is a line:
	</para>
<programlisting><![CDATA[
tcp        0      0 0.0.0.0:31337           0.0.0.0:*               LISTEN
]]></programlisting>
	<para>
you're one step closer to the truth. Now we have to supply the script that will
be called if you connect to realserver# port 31337. So simply do this on your
command line (copy 'n' paste):
	</para>
<programlisting><![CDATA[
cat > /usr/bin/lvs-info << EOF && chmod 755 /usr/bin/lvs-info
#!/bin/sh

echo "This is a test of machine `ifconfig -a | grep HWaddr | awk '{print $1}'`"
echo
EOF
]]></programlisting>
	<para>
Now you can test if it really works with telnet or <xref linkend="phatcat"/>:
	</para>
<programlisting><![CDATA[
telnet localhost 31337
phatcat localhost 31337
]]></programlisting>
	<para>
This should spill out something like:
	</para>
<programlisting><![CDATA[
hog:/ # phatcat localhost 31337
This is a test of machine 192.168.1.11

hog:/ #
]]></programlisting>
	<para>
If it worked, do the same procedure to set up the second realserver.
Now we're ready to set up the load balancer. These are the required commands to
set it up for our example:
	</para>
<programlisting><![CDATA[
director:/etc/lvs# ipvsadm -A -t 192.168.1.100:31337 -s wrr
director:/etc/lvs# ipvsadm -a -t 192.168.1.100:31337 -r 192.168.1.11 -g -w 1
director:/etc/lvs# ipvsadm -a -t 192.168.1.100:31337 -r 192.168.1.12 -g -w 1
]]></programlisting>
	<para>
Check it with ipvsadm -L -n:
	</para>
<programlisting><![CDATA[
hog:~ # ipvsadm -L -n
IP Virtual Server version 0.9.14 (size=4096)
Prot LocalAddress:Port Scheduler Flags
  -> RemoteAddress:Port          Forward Weight ActiveConn InActConn
TCP  192.168.1.100:31337 wrr
  -> 192.168.1.12:31337          Route   1      0          0
  -> 192.168.1.11:31337          Route   1      0          0
hog:~ #
]]></programlisting>
	<para>
Now if you connect from outside with the client node to the VIP=192.168.1.100
you should get to one of the two realserver (presumably to ~.12) Reconnect to
the VIP again an you should get to the other realserver. If so, be happy, if
not go back, check netstat -an, ifconfig -a, arp-problem, routing tables and so
on ...
	</para>
	</section>
	<section id="bringing_down_realserver">
	<title>How to bring down a realserver for maintenance (eg swap disks)</title>
	<para>
I want to use virtual server functionality to allow switching over
from one pool of server processes to another without an interruption
in service to clients.
	</para>
	<para>
Michael Sparks <emphasis>sparks (at) mcc (dot) ac (dot) uk</emphasis>
	</para>
	<para>
current realservers : A,B,C
servers to swap into the system instead  D,E,F
	</para>
	<itemizedlist>
		<listitem>
Add servers D,E,F into the system all with fairly high weights (perhaps
ramping the weights up slowly so as not to hit them too hard:-)
		</listitem>
		<listitem>
Change the weights of servers A,B,C to 0.
		</listitem>
		<listitem>
All new traffic should now go to D,E,F
		</listitem>
		<listitem>
When the number of connections through A,B,C reaches 0, remove them from
the service. This can take time I know but...
		</listitem>
	</itemizedlist>
	<para>
Joe
	</para>
	<para>
A planned feature for <command>ipvsadm</command> will be to give a realserver a
weight of 0 (now implemented). This realserver will not be sent any new connections
and will continue serving its current connections till they
close. You may have to wait a while if a user is downloading a
40M file from the realserver.
	</para>
	<para>
"Duran, Richard" <emphasis>RDuran (at) dallasairmotive (dot) com</emphasis>
01 Oct 2004
	</para>
	<blockquote>
Is it possible to take a realserver offline in such a way that existing connections are immediately redirected to another realserver? We've had the need to do this before and don't know what else to do beyond either (1) setting the weight to "0" and iterating through a process of disconnecting "inactive" users/sessions and hoping that they don't reconnect within the 5 minute persistence_timeout, or (2) removing the host-specific entry from keepalived.conf (brutally disconnecting everyone).
	</blockquote>
	<para>
Joe
	</para>
	<para>
If you're talking about transferring an existing tcpip connection: no
	</para>
	<para>
Malcolm Turnbull
	</para>
	<para>
A brutal disconnect is the usual way to go. <command>ldirectord</command>
handles it cleanly
	</para>
	</section>
	<section id="temporarily_removing_a_realserver">
	<title>keepalived: temporarily removing a realserver from view of keepalived; abnormal termination of keepalived</title>
	<para>
Jacob Smullyan 2006-02-13 
	</para>
	<blockquote>
		<para>
It is a tribute to lvs that I've forgotten most of what I once knew
about it, because I set up LVS-DR with keepalived about three years
ago and it has run without a hiccup ever since.  As a result, I'm
rusty, so forgive me if this is a stupid or frequently asked question.
 		</para>
		<para>
How should I go about taking a server temporarily out of rotation? 
Since I am using keepalived, I know I can simply turn off the service
it depends on -- but in fact I want to replace that service with a new
application on the same port (which will go live a few minutes/hours
later).   I am aware of some alternatives:
 		</para>
		<itemizedlist>
			<listitem>
configure keepalived's health check to rely on some aspect on the
old application, then swap the configuration when I want to go live with the new
 application.
			</listitem>
			<listitem>
temporarily run the new application on a different ip.
			</listitem>
			<listitem>
simply comment out that realserver in keepalived.conf temporarily,
or add a healthcheck that will never be satisfied.
			</listitem>
			<listitem>
directly delete the ipvsadm config for that server (but what about
the backup director, and how if at all will keepalived interfere with that?)
			</listitem>
			<listitem>
get a job more suitable for a dim-witted person like myself.
			</listitem>
		</itemizedlist>
		<para> 
But all these are workarounds; what I really want is to tell the
director (or keepalived), "retain all configuration, but temporarily
drop this realserver until I remove the block".  Is there a way to do
that?
		</para>
	</blockquote>
	<para>
Graeme Fowler <emphasis>graeme (at) graemef (dot) net</emphasis> 13 Feb 2006 
	</para>
	<para>
On the director(s), assuming you use eth0 as the interface forwarding
the packets to the realservers...
	</para>
<programlisting><![CDATA[
iptables -I OUTPUT -o eth0 -s $VIP -d $RIP -j REJECT
]]></programlisting>
	<para>
That'll stop keepalived doing any healthchecks whatsoever on the
realserver you need to work on. Simply replace -I with -D when you're
done.
	</para>
	<para>
The same thing can be achieved by "null" routing the RIP on the director
too, but I'll leave that as an exercise :)
	</para>
	<para>
Mark <emphasis>msalists (at) gmx (dot) net</emphasis> 15 Feb 2006
	</para>
	<para>
I usually do one of the two:
	</para>
	<para>
You can use the commandline ipvsadm-command to get a list of all nodes and manipulate (add/remove) nodes.
Use it to remove and later add the node again. This will not influence any other nodes of the configuration.
If you get totally lost, just restart ldirectord and it will come back up with the regular configuration.
	</para>
	<para>
Or, as second option, 
use the http negotiation mechanism that uses a string comparison of a certain URL 
against an expected string pattern.
Have it check against a dummy html page and put a flag in there that ldirectord 
checks against to determine if the host is supposed to be in the pool or not. 
Modify the flag manually to take the node out.
	</para>
	<para>
<emphasis>gastruc (at) steek (dot) com</emphasis> 4 Dec 2008 
	</para>
	<blockquote>
After an error in keepalived configuration on backup server, it is left
with all the VIP addresses
	</blockquote>
	<para>
Siim Poder <emphasis>windo (at) p6drad-teel (dot) net</emphasis> 05 Dec 2008 
	</para>
	<para>
If - for example - you kill keepalived with -9, it will leave all
addresses there. And if you restart keepalived later on, it will refuse
to manage those addresses - probably for safety (not to touch what it
hasn't created). IMO this causes more trouble than good - why would you
be touching keepalived-managed addresses manually if you weren't asking
for trouble? You can always change the configuration and force
keepalived to make the changes you want.
	</para>
	<para>
There are/were some bugs with keepalived and reload and it doesn't
handle configuration errors well so your problem certanly doesn't
suprise me.
	</para>
	<para>
When this happens, I usually kill keepalived and remove all the
(non-administrative) addresses manually (as you have a bunch, it may be
wise to have a script laying around for that). Then restart keepalived
to re-add the addresses (and claim ownership of them) or stay in standby
if it's the backup node.
	</para>
	</section>
	<section id="creating_lvs_on_the_fly">
	<title>Howto turn your single node ftp/http server into an LVS without taking it off-line</title><para>
			</para><para>
<emphasis>e.g.</emphasis> if you want to test LVS on your BIG Sunserver and how
to restore an LVS to a single node server again.
			</para><para>
<programlisting><![CDATA[
current ftp server:        standalone  A

planned LVS (using LVS-DR): realserver A
		           director    Z
]]></programlisting>
			</para><para>
Setup the LVS in the normal way with the director's VIP being a
new IP for the network. The IP of the standalone server will now
also be the IP for the realserver. You can access the realserver
via the VIP while the outside users continue to connect to the
original IP of A.  When you are happy that the VIP gives the
right service, change the DNS IP of your ftp site to the VIP.
Over the next 24hrs as the new DNS information is propagated to
the outside world, users will change over to the VIP to access
the server.
			</para><para>
To expand the number of servers (to A, B,...), add another server
with duplicated files, add an extra entry into the director's
tables with ipvsadm.
			</para><para>
To restore - in your DNS, change the IP for the service to the
realserver IP. When no-one is accessing the VIP anymore, unplug
the director.
	</para>
	</section>
	<section id="lvs_shutdown">
	<title>shutdown of LVS</title>
	<para>
			</para><para>
You can't shutdown an LVS.
However you can stop it forwarding by clearing the <command>ipvsadm</command> table (ipvsadm -C),
then allow all connections to expire (check the active connections with ipvsadm)
and then remove the ipvs modules (rmmod).
Since ip_vs.o requires ip_vs_rr.o etc, you'll have to remove ip_vs_rr.o first.
			</para><para>
<blockquote><para>
Do you know how to shutdown LVS?
I tried rmmod but it keeps saying that the device is busy.
</para></blockquote>
			</para><para>
Kjetil Torgrim Homme <emphasis>kjetilho (at) linpro (dot) no</emphasis> 18 Aug 2001
			</para><para>
Run ipvsadm -C.  You also need to remove the module(s) for the
balancing algorithm(s) before rmmod ip_vs.  Run lsmod to see which
modules these are.
			</para><para>
Roy Walker <emphasis>Roy (dot) Walker (at) GEZWM (dot) com</emphasis> 18 Mar 2002 could not cleanly shutdown his
director (LVS 1.0, 2.4.18) which hung at "Send TERM signal". The suggested
cure, was to bring down the LVS first (we haven't heard back if it works).
	</para>
	</section>
	<section id="beowulf">
	<title>Other projects like LVS - Beowulf</title>
	<para>
The difference between a beowulf and an LVS:
			</para><para>
The Beowulf project has to do with processor clustering over a
network -- parallel computing... Basically putting 64 nodes up
and running that all are a part of a collective of resources.
Like SMP -- but between a whole bunch of machines with a fast
ethernet as a backplane.
			</para><para>
LVS, however, is about load-balancing on a network. Someone puts
up a load balancer in front of a cluster of servers. Each one of
those servers is independent and knows nothing about the rest of
the servers in the farm. All requests for services go to the load
balancer first. That load balancer then distributes requests to
each server. Those servers respond as if the request came
straight to them in the first place. So -- with the more servers
one adds -- the less load goes to each server.
			</para><para>
A person might go to a web site that is load balanced, and their
requests would be balanced between four different machines. (Or
perhaps all of their requests would go to one machine, and the
next person's request would go to another machine)
			</para><para>
However, a person who used a Beowulf system would actually be
using one processing collaborative that was made up of multiple
computers...
			</para><para>
I know that's not the best explanation of each, and I apologize
for that, but I hope it at least starts to make things a little
clearer. Both projects could be expanded on to a great extent,
but that might just confuse things farther.
			</para><para>
(Joe) -
			</para><para>
both use several (or a lot of) nodes.
			</para><para>
A beowulf is a collection of nodes working on a single
computation.  The computation is broken into small pieces and
passed to a node, which replies with the result. Eventually the
whole computation is done.  THe beowulf usually has a single user
and the computations can run for weeks.
			</para><para>
An LVS is a group of machines offering a service to a client. A
dispatcher connects the client to a particular server for the
request. When the request is completed, the dispatcher removes
the connection between the client and server. The next request
from the same client may go to a different server but the client
cannot tell which server it has connected to. The connection
between client and server may only be seconds long
			</para><para>
from a posting to the beowulf mailing list by Alan Heirich -
			</para><para>
Thomas Sterling and Donald Becker made "Beowulf" a registered
service mark with specific requirements for use:
			</para><para>
<programlisting><![CDATA[
-- Beowulf is a cluster
-- the cluster runs Linux
-- the O/S and driver software are open source
-- the CPU is multiple sourced (currently, Intel and Alpha)
]]></programlisting>
			</para><para>
I assume they did this to prevent profit-hungry vendors from
abusing this term; can't you just imagine Micro$oft pushing a
"Beowulf" NT-cluster?
			</para><para>
(Joe - I looked up the Registered Service Marks on the internet
and Beowulf is not one of them.)
			</para><para>
(Wensong)
Beowulf is for parallel computing, Linux Virtual Server is for
scalable network services.
			</para><para>
They are quite different now. However, I think they may be
unified under "single system image" some day. In the "single
system image", every node can see a single system image (the same
memory space, the same process space, the same external storage),
and the processes/threads can be transparently migrated to other
nodes in order to achieve load balance in the cluster. All the
processes are checkpointed, they can be restarted in the node or
the others if they fails, full fault tolerant can be made here.
It will be easy for programmers to code because of single space,
they don't need to statically partition jobs to different sites
and let them communicate through PVM or MPI. They just need
identify the parallelism of his scientific application, and fork
the processes or generate threads, because processes/threads will
be automatically load balanced on different nodes. For network
services, the service daemons just need to fork the processes or
generates threads, it is quite simple. I think it needs lots of
investigation in how to implement these mechanisms and make the
overhead as low as possible.
			</para><para>
What Linux Virtual Server has done is very simple, Single IP
Address, in which parallel services on different nodes is
appeared as a virtual service on a single IP address. The
different nodes have their own space, it is far from "single
system image". It means that we have a long way to run. :)
	</para>
	</section>
	<section id="eddie">
	<title>Projects like LVS - Eddie</title>
	<para>
Eddie http://www.eddieware.org
			</para><para>
(Jacek Kujawa <emphasis>blady (at) cnt (dot) pl</emphasis>)
Eddie is a load balancing software, using NAT (only NAT), for
webservers, written in language erlang. Eddie include intelligent
HTTP gateway and Enhanced DNS.
			</para><para>
(Joe)
Erlang is a language for writing distrubuted applications.
	</para>
	</section>
	<section id="redundant_file_systems">
	<title>Recommendations for a redundant file system, RAID</title>
	<para>
<blockquote><para>Shain Miley 4 Jun 2001
			</para><para>
any recommendations for Level 5 SCSI RAID?
</para></blockquote>
			</para><para>
Matthew S. Crocker <emphasis>matthew (at) crocker (dot) com</emphasis> 04 Jun 2001
			</para><para>
I have had very good luck with Mylex. We use the DAC960 which is a bit old
now but if the newer stuff works as well as what I have I would highly
recommend it.
You might also want to think about putting your data on a NAS and seperate
your CPU from your harddrives
			</para><para>
Don Hinshaw <emphasis>dwh (at) openrecording (dot) com</emphasis> 04 Jun 2001
			</para><para>
Mylex work well.
I use ICP-Vortex (http://www.icp-vortex.com/index_e.html, link dead Jan 2003)
which are supported by the Linux kernel.
I've also had good luck with
<ulink url="http://www.adaptec.com/worldwide/product/proddetail.html?prodkey=ASR-3400S&amp;cat=%2fTechnology%2fRAID%2fRAID+for+Mid-Range+Servers">Adaptec 3200s and 3400si</ulink>.
	</para></section>
	<section id="extended_testing_is_needed">
	<title>on the need for extended testing</title>
	<para>
(this must have been solved,
no-one is complaining about memory leaks now :-)
			</para><para>
<blockquote><para>
Jerry Glomph Black <emphasis>black (at) real (dot) com</emphasis>
			</para><para>
We have successfully used 2.0.36-vs (direct routing method), but
it does fail at extremely high loads. Seems like a cumulative
effect, after about a billion or so packets forwarded. Some kind
of kernel memory leak, I'd guess.
</para></blockquote>
	</para>
	</section>
	<section id="aliased_devices_bringing_down">
	<title>Bringing down aliased devices</title>
	<note>
	<para>
This is no longer a problem if you use the new
<xref linkend="LVS-HOWTO.policy_routing"/>.
	</para>
	</note>
	<para>
			</para><para>
(without bringing them all down)
			</para><para>
Problem: if down/delete an aliased device (eg eth0:1) you
also bring down the other eth0 devices. This means that you
can't bring down an alias remotely as you loose your connection
(eth0) to that machine. You then have to go the console of the
remote machine to fix it by rmmod'ing the device driver for the
device and bring it up again.
			</para><para>
The configure script handles this for you and will exit (with
instructions on what to do next) if it finds that an aliased
device needs to be removed by rmmod'ing the module for the NIC.
			</para><para>
(I'm not sure that all of the following is accurate, please
test yourself first).
			</para><para>
(Stephen D. WIlliams <emphasis>sdw (at) lig (dot) net</emphasis>)
whenever you want to down/delete an alias, first set its netmask
to 255.255.255.255. This avoids also automatically downing
aliases that are on the same netmask and are considered
'secondaries' by the kernel.
			</para><para>
			</para><para>
(Joe)
To bring up an aliased device
			</para><para>
$ifconfig eth0:1 192.168.1.10 netmask 255.255.255.0
			</para><para>
to bring eth0:1 down without taking out eth0, you do
it in 2 steps, first change the netmask
			</para><para>
$ifconfig eth0:1 192.168.1.10 netmask 255.255.255.255
			</para><para>
then down it
			</para><para>
$ifconfig eth0:1 192.168.1.10 netmask 255.255.255.255 down
			</para><para>
then eth0 device should be unaffected, but the eth0:1
device will be gone.
			</para><para>
This works on one of my machines but not on another
(both with 2.2.13 kernels).  I will have to look
into this. Here's the output from the machine for
which this procedure doesn't work.
			</para><para>
Examples:
Starting setup. The realserver's regular IP/24 on eth0,
the VIP/32 on eth0:1 and another IP/24 for illustration
on eth0:2. Machine is SMP 2.2.13 net-tools 1.49
			</para><para>
<programlisting><![CDATA[
chuck:~# ifconfig -a
eth0      Link encap:Ethernet  HWaddr 00:90:27:71:46:B1
          inet addr:192.168.1.2  Bcast:192.168.1.255  Mask:255.255.255.0
          UP BROADCAST RUNNING ALLMULTI MULTICAST  MTU:1500  Metric:1
          RX packets:6071219 errors:0 dropped:0 overruns:0 frame:0
          TX packets:6317319 errors:0 dropped:0 overruns:4 carrier:0
          collisions:757453 txqueuelen:100
          Interrupt:18 Base address:0x6000

eth0:1    Link encap:Ethernet  HWaddr 00:90:27:71:46:B1
          inet addr:192.168.1.110  Bcast:192.168.1.110  Mask:255.255.255.255
          UP BROADCAST RUNNING ALLMULTI MULTICAST  MTU:1500  Metric:1
          Interrupt:18 Base address:0x6000

eth0:2    Link encap:Ethernet  HWaddr 00:90:27:71:46:B1
          inet addr:192.168.1.240  Bcast:192.168.1.255  Mask:255.255.255.0
          UP BROADCAST RUNNING ALLMULTI MULTICAST  MTU:1500  Metric:1
          Interrupt:18 Base address:0x6000

lo        Link encap:Local Loopback
          inet addr:127.0.0.1  Mask:255.0.0.0
          UP LOOPBACK RUNNING  MTU:3924  Metric:1
          RX packets:299 errors:0 dropped:0 overruns:0 frame:0
          TX packets:299 errors:0 dropped:0 overruns:0 carrier:0
          collisions:0 txqueuelen:0

chuck:~# netstat -rn
Kernel IP routing table
Destination     Gateway         Genmask         Flags   MSS Window  irtt Iface
192.168.1.110   0.0.0.0         255.255.255.255 UH        0 0          0 eth0
192.168.1.0     0.0.0.0         255.255.255.0   U         0 0          0 eth0
127.0.0.0       0.0.0.0         255.0.0.0       U         0 0          0 lo
0.0.0.0         192.168.1.1     0.0.0.0         UG        0 0          0 eth0

Deleting eth0:1 with netmask /32

chuck:~# ifconfig eth0:1 192.168.1.110 netmask 255.255.255.255 down
chuck:~# ifconfig -a
eth0      Link encap:Ethernet  HWaddr 00:90:27:71:46:B1
          inet addr:192.168.1.2  Bcast:192.168.1.255  Mask:255.255.255.0
          UP BROADCAST RUNNING ALLMULTI MULTICAST  MTU:1500  Metric:1
          RX packets:6071230 errors:0 dropped:0 overruns:0 frame:0
          TX packets:6317335 errors:0 dropped:0 overruns:4 carrier:0
          collisions:757453 txqueuelen:100
          Interrupt:18 Base address:0x6000

eth0:2    Link encap:Ethernet  HWaddr 00:90:27:71:46:B1
          inet addr:192.168.1.240  Bcast:192.168.1.255  Mask:255.255.255.0
          UP BROADCAST RUNNING ALLMULTI MULTICAST  MTU:1500  Metric:1
          Interrupt:18 Base address:0x6000

lo        Link encap:Local Loopback
          inet addr:127.0.0.1  Mask:255.0.0.0
          UP LOOPBACK RUNNING  MTU:3924  Metric:1
          RX packets:299 errors:0 dropped:0 overruns:0 frame:0
          TX packets:299 errors:0 dropped:0 overruns:0 carrier:0
          collisions:0 txqueuelen:0


If you do the same thing with eth0:2 with the /24 netmask
			</para><para>
chuck:~# ifconfig eth0:2 192.168.1.240 netmask 255.255.255.0 down
chuck:~# ifconfig -a
eth0      Link encap:Ethernet  HWaddr 00:90:27:71:46:B1
          inet addr:192.168.1.2  Bcast:192.168.1.255  Mask:255.255.255.0
          UP BROADCAST RUNNING ALLMULTI MULTICAST  MTU:1500  Metric:1
          RX packets:6071237 errors:0 dropped:0 overruns:0 frame:0
          TX packets:6317343 errors:0 dropped:0 overruns:4 carrier:0
          collisions:757453 txqueuelen:100
          Interrupt:18 Base address:0x6000

lo        Link encap:Local Loopback
          inet addr:127.0.0.1  Mask:255.0.0.0
          UP LOOPBACK RUNNING  MTU:3924  Metric:1
          RX packets:299 errors:0 dropped:0 overruns:0 frame:0
          TX packets:299 errors:0 dropped:0 overruns:0 carrier:0
          collisions:0 txqueuelen:0

tunl0     Link encap:IPIP Tunnel  HWaddr
          unspec addr:[NONE SET]  Mask:[NONE SET]
          NOARP  MTU:1480  Metric:1
          RX packets:0 errors:0 dropped:0 overruns:0 frame:0
          TX packets:0 errors:0 dropped:0 overruns:0 carrier:0
          collisions:0 txqueuelen:0

]]></programlisting>
	</para>
	</section>
	<section id="multiple_ips_on_director">
	<title>Multiple IPs on the Director</title>
	<para>
Michael Sparks
			</para><para>
It's useful for the director to have 3 IP addresses. One which is the real
machines base IP address, one which is the virtual service IP address, and
then another virtual IP address for servicing the director. The reason for
this is associated with director failover.
			</para><para>
Suppose:
<itemizedlist>
<listitem><para>
X realservers pinging director on real IP A (assume a heartbeat style
    monitor) serving pages off virtual IP V. (IP A would be in place of
    hostip above)
			</para><para>
</para></listitem><listitem><para>Director on IP A fails, backup director (*) on IP B comes online taking
    over the virtual IP V. By not taking over IP A, IP B can watch for IP
    A to come back online via the network, rather than via a serial link
    (etc).
			</para><para>
</para></listitem><listitem><para> Problem is the realservers are still sending to IP A for the heartbeat
    code to be valid on IP B, the realservers need to send their pings to
    IP B instead. IMO the easiest solution is to allocate a we need a
    "heartbeat"/monitor virtual IP. (this is the vhostip)
</para></listitem></itemizedlist>
	</para>
	</section>
	<section id="testimonials">
	<title>Testimonials</title>
	<para>
This isn't particularly inclusive. We don't pester people for
testimonials as we don't want to scare people from posting to the
mailing list and we don't want inflated praise.
People seem to understand this and don't
pester us with their performance data either.
The quotes below aren't scientific data, but it is nice to hear.
The people who don't like LVS presumably go somewhere else,
and we don't hear any complaints from them.
			</para><para>
			</para><para>
			</para><para>
<blockquote><para>
"Daniel Erd&ouml;s" 2 Feb 2000
			</para><para>
 How many connections did you really handled? What are your impressions and
 experiences in "real life"? What are the problems?
</para></blockquote>
			</para><para>
Michael Sparks <emphasis>zathras (at) epsilon3 (dot) mcc (dot) ac (dot) uk</emphasis>
			</para><para>
Problems - LVS provides a load balancing mechanism, nothing more, nothing
less, and does it *extremely* well. If your back end realservers are
flakey in anyway, then unless you have monitoring systems in place to take
those machines out of service as soon as there are problems with those
servers, then users will experience glitches in service.
			</para><para>
NB, this is essentially a realserver stability issue, not an LVS issue -
you'd need good monitoring in place anyway if you weren't using LVS!
			</para><para>
Another plus in LVS's favour in something like this over the commercial
boxes, is the fact that the load balancer is a Unix type box - meaning
your monitoring can be as complex or simple as you like. For example load
balancing based on wlc could be supplemented by server info sent to the
director.
			</para><para>
<blockquote><para>
Drew Streib <emphasis>ds (at) varesearch (dot) com</emphasis> 23 Mar 2000
			</para><para>
I can vouch for all sorts of good performance from lvs. I've had single
processor boxes handle thousands of simultaneous connections without
problems, and yes, the 50,000 connections per second number from the VA
cluster is true.
			</para><para>
lvs powers SourceForge.net, Linux.com, Themes.org, and VALinux.com.
SourceForge uses a single lvs server to support 22 machines, multiple
types of load balancing, and an average 25Mbit/sec traffic. With
60Mbit/sec of traffic flowing through the director (and more than 1000
concurrent connections), the box was having no problems whatsoever, and in
fact was using very little cpu.
			</para><para>
Using DR mode, I've sent request traffic to an director box resulting in
near gigabit traffic from the realservers. (Request traffic was on the
order of 40Mbit.)
			</para><para>
I can say without a doubt that lvs toasts F5/BigIP solutions, at least in
our real world implementations. I wouldn't trade a good lvs box for a
Cisco Local Director either.
			</para><para>
<blockquote>
The 50,000 figure is unsubstantiated and was _not_ claimed by anyone at VA
Linux Systems. A cluster with 16 apache servers and 2 LVS servers in a was
configured for Linux World New York but due to interconnect problems the
performance was never measured - we weren't happy with the throughput of the
NICs so there didn't seem to be a lot of point. This problem has been
resolved and there should be an opportunity to test this again soon.
</blockquote>
			</para><para>
In recent tests, I've taken multinode clusters to tens of thousands of
connections per second. Sorry for any confusion here. The exact 50,000
number from LWCE NY is unsubstantiated.
</para></blockquote>
			</para><para>
Jerry Glomph Black <emphasis>black (at) real (dot) com</emphasis> 23 Mar 2000
			</para><para>
We ran a very simple LVS-DR arrangement with one PII-400 (2.2.14 kernel)directing
about 20,000 HTTP requests/second to a bank of about 20 Web servers answering
with tiny identical dummy responses for a few minutes.   Worked just fine.
			</para><para>
Now, at more terrestrial, but quite high real-world loads, the systems run just
fine, for months on end.   (using the weighted-least-connection algorithm,
usually).
			</para><para>
We tried virtually all of the commercial load balancers, LVS beats them
all for reliability, cost, manageability, you-name-it.
	</para>
	</section>
	<section id="tls">
	<title>Transport Layer Security(TLS)</title>
	<para>
Noma wrote Nov 2000
			</para><para>
Are you going to implement TLS(Transport Layer Security) Ver1.0 on LVS?
			</para><para>
<blockquote><para>
Wensong
			</para><para>
I haven't read the TLS protocol, so don't know if the TLS transmits IP
address and/or port number in payload. In most cases, it should not,
because SSL doesn't.
			</para><para>
If it doesn't, you can use either of three VS/NAT, LVS-Tun and LVS-DR
methods. If it does, LVS-Tun and LVS-DR can still work.
</para></blockquote>
			</para><para>
Ted Pavlic <emphasis>tpavlic (at) netwalk (dot) com</emphasis>, Nov 2000
<blockquote><para>
I don't see any reason why LVS would have any bearing on TLS. As far as LVS
was concerned, TLS connections would just be like any other connections.
			</para><para>
			</para><para>
Perhaps you are referring to HTTPS over TLS? Such a protocol has not been
completed yet in general, and when it does it still will not need any extra
work to be done in the LVS code.
			</para><para>
The whole point of TLS is that one connects to the same port as usual and
then "upgrades" to a higher level of security on that port. All the secure
logic happens at a level so high that LVS wouldn't even notice a change.
Things would still work as usual.
</para></blockquote>
			</para><para>
Julian Anastasov <emphasis>ja (at) ssi (dot) bg</emphasis>
<blockquote><para>
	This is an end-to-end protocol layered on another transport
protocol. I'm not a TLS expert but as I understand TLS 1.0 is
handled just like the SSL 3.0 and 2.0 are handled, i.e. they
require only a support for persistent connections.
</para></blockquote>
	</para>
	</section>
	<section id="setting_up_hot_spare">
	<title>Setting up a hot spare server</title>
	<para>
<blockquote><para>
Mark Miller <emphasis>markm (at) cravetechnology (dot) com</emphasis> 09 May 2001
			</para><para>
We want a
configuration where two Solaris based web servers will be setup in a primary
and secondary configuration.  Rather than load balancing between the two we
really want the secondary to act as a hot spare for the primary.
			</para><para>
Here is a quick diagram to help illustrate this question:
			</para><para>
<programlisting><![CDATA[
                  Internet		LD1,LD2 - Linux 2.4 kernel
                      |			RS1,RS2 - Solaris
                   Router
                      |
               -------+-------
               |             |
             -----         -----
             |LD1|         |LD2|
             -----         -----
               |             |
               -------+-------
                      |
                    Switch
                      |
               ---------------
               |             |
             -----         -----
             |RS1|         |RS1|
             -----         -----
]]></programlisting>
</para></blockquote>
			</para><para>
			</para><para>
Paul Baker <emphasis>pbaker (at) where2getit (dot) com</emphasis> 09 May 2001
			</para><para>
Just use heartbeat on the two firewall
machines and heartbeat on the two Solaris machines.
			</para><para>
<blockquote><para>
Horms <emphasis>horms (at) vergenet (dot) net</emphasis> 09 May 2001
			</para><para>
You can either add and remove servers from the virtual service (using
ipvsadm) or toggle the weights of the servers from zero to non-zero values.
</para></blockquote>
			</para><para>
<blockquote><para>
Alexandre Cassen <emphasis>alexandre (dot) cassen (at) wanadoo (dot) fr</emphasis> 10 May 2001
			</para><para>
For your 2 LDs you need to run a Hot standby protocol. Hearthbeat can be
used, you can also use vrrp or hsrp. I am actually working on the IPSEC AH
implementation for vrrp. That kind of protocol can be usefull because your
LD backup server can be used even if it is in backup state (you simply
create 2 LDs VIP and set default gateway of your serveur pool half on LD1
and half on LD2).
			</para><para>
For your webserver hot-spare needs, you can use the next
<ulink url="http://keepalived.sourceforge.net">keepalived</ulink>
in which there will be "sorry server" facility. 
This mean exactly what you need => You have a RS server pool, 
if all the server of this RS server pool are down then the sorry server is
placed into the <command>ipvsadm</command> table automaticaly. 
If you use keepalived keep in mind that you will use NAT topology.
</para></blockquote>
			</para><para>
<blockquote><para>
Joe 11 May 2001
			</para><para>
Unless there's something else going on that I don't know about, I expect
this isn't a great idea. The hot spare is going to degrade (depreciate,
disk wear out - although not quite as fast, software need upgrading)
just as fast idle as doing work.
			</para><para>
You may as well have both working all the time and for the few hours of
down time a year that you'll need for planned maintenance, you can make
do with one machine. If you only need the capacity of 1 machine, then
you can use two smaller machines instead.
</para></blockquote>
	</para></section>
	<section id="lvs_of_lvss">
	<title>An LVS of LVSs</title>
	<para>
Since an LVS obeys unix client/server semantics, an LVS can
replace a realserver (at least in principle, no-one has done this yet).
Each LVS layer could have its own forwarding method, independantly
of the other LVSs.
The LVS of LVSs would look like this, with realserver_3 being in
fact the director of another LVS and having no services running
on it.
			</para><para>
<programlisting><![CDATA[
                        ________
                       |        |
                       | client |
                       |________|
			   |
                           |
                        (router)
                           |
			   |
                           |       ____________
                           |  DIP |            |
                           |------| director_1 |
                           |  VIP |____________|
                           |
                           |
                           |
         ------------------------------------
         |                 |                |
         |                 |                |
     RIP1, VIP         RIP2, VIP        RIP3, VIP
   ______________    ______________    _____________
  |              |  |              |  |             |
  | realserver1  |  | realserver2  |  | realserver3 |
  |              |  |              |  | =director_2 |
  |______________|  |______________|  |_____________|
                                            |
                                            |
         ------------------------------------
         |                 |                |
         |                 |                |
     RIP4, VIP         RIP5, VIP        RIP6, VIP
   ______________    ______________    ______________
  |              |  |              |  |              |
  | realserver4  |  | realserver5  |  | realserver6  |
  |              |  |              |  |              |
  |______________|  |______________|  |______________|
]]></programlisting>
			</para><para>
If all realservers were offering http and only realservers1..4 were offering ftp,
then you would (presumably) setup the directors with the following weights
for each service:
			</para><para>
<itemizedlist>
<listitem><para>director_1: realserver1 http,ftp=1; realserver2 http,ftp=1;realserver3 http=3,ftp=1
</para></listitem><listitem><para>director_2: realserver4 http,ftp=1; realserver5 http=1 (no ftp);realserver3 http=1 (no ftp)
</para></listitem></itemizedlist>
			</para><para>
You might want to do this if realservers4..6 were on a different network
(<emphasis>i.e.</emphasis> geographically remote).
In this case director_1 would be forwarding by LVS-Tun,
while director_2 could use any forwarding method.
			</para>
		<section>
		<title>An LVS of LVSs: using Windows/Solaris machines with LVS-Tun</title>
		<para>
			</para><para>
This is the sort of ideas we were having in the early days.
It turns out that not many people are using LVS-Tun,
most people are using Linux realservers,
and not many people are using geographically distributed LVSs.
			</para><para>
Joe, Jun 99
			</para><para>
 For the forseeable future many of the servers
 who could benefit from the LVS will be microsoft
 or Solaris. The problem is that they don't have
 tunneling. A solution would be to have a linux
 box in front of each realserver on the link
 from the director to the realserver. The
 linux box appears to be the server to the director
 (it has the real IP eg 192.168.1.2) but does not
 have the VIP (eg 192.168.1.110). The linux box
 decapsulates the packet from the director and now
 has a packet from the client to the VIP. Can the
 linux box route this packet to the realserver (presumably
 to an lo device on the realserver)?
			</para><para>
 The linux box could be a diskless 486 machine booting
 off a floppy with a patched kernel, like the
 machines in the Linux router project.
			</para><para>
			</para><para>
<blockquote><para>
Wensong 29 Jun 1999
			</para><para>
We can use nested (hyprid) LinuxDirector approach. For example,
<programlisting><![CDATA[
    LVS-Tun   ---->   LVS-NAT ---->  RealServer1
         |                 |       ...
         |                 ----->  RealServer2
         |
         |           ....
         |
         |
         -------->   LVS-NAT  ....
]]></programlisting>
Real Servers can run any OS. A LVS-NAT load balancer usually
can schedule over 10 general servers. And, these LVS-NATs
can be geographically distributed.
			</para><para>
By the way, LinuxDirector in kernel 2.2 can use LVS-NAT,
VS-TUN and LVS-DR together for servers in a single configuration.
</para></blockquote>
		</para>
		</section>
	</section>
	<section id="lvs_on_mainframe">
	<title>LVS on a Linux/IBM mainframe</title>
	<para>
Kyle Sparger <emphasis>ksparger (at) dialtoneinternet (dot) net</emphasis> 18 Sep 2001
			</para><para>
I'm familiar with the s/390;  the zSeries 900 will be
similar, but on a 'next-gen' scale -- It's 64-bit
and I expect 2-3 times the maximum capacity.
			</para><para>
<itemizedlist>
<listitem><para> The s/390 is ONLY, at most, a 12-way machine in a single frame, 24-way
in a two-frame configuration.  The CPU's are not super-powered;
they're normal CPU's, so imagine a normal 12-24 way, and you have a
good idea.  It does have special crypto-processors built in, if you
can find a way to use them.
			</para><para>
</para></listitem><listitem><para> The s/390, however, has an obnoxiously fast bus -- 24GByte/s.  Yes, I
did mean gigabytes.  Also, I/O takes up almost no CPU time, as the
machines have sub-processors to take care of it.
			</para><para>
</para></listitem><listitem><para> The s/390 is a 31bit machine -- yes, 31.  One bit defines whether the
code is 16 or 31 bit code.  The z/900 is a 64-bit machine.
Note that the s/390, afaik, suffers when attempting to access memory
over a certain amount, like any 31/32 bit machine would -- 2 gigs can
be addressed in a single clock cycle;  greater than that takes longer
to process, since it requires more than 32 bits to address.
			</para><para>
			</para><para>
</para></listitem><listitem><para> From top to bottom, the entire machine is redundant.  There is no
single point of failure anywhere in the machine.  According to IBM's
docs, the MTBF is 30 years.  It calls IBM when it's broken, and they
come out and fix it.  The refrigerator ad was no joke ;)
Of course, this doesn't protect you from power outages, but
interestingly enough, if I recall correctly, all RAM is either SRAM,
or battery backed -- the machine will come back up and continue right
where it left off when it lost power.  No restarting instances or
apps required.  No data lost.
</para></listitem></itemizedlist>
			</para><para>
There are five premises for the cost-savings:
			</para><para>
<itemizedlist>
<listitem><para>You don't have to design a redundant system -- it's already built in.
</para></listitem><listitem><para>One machine is easier to manage than n number servers.
</para></listitem><listitem><para>One machine uses less facilities than n number servers.
</para></listitem><listitem><para>A single machine, split many ways, can result in higher utilization.
</para></listitem><listitem><para>Linux, Linux, Linux.  All the free software you can shake a stick at.
</para></listitem></itemizedlist>
			</para><para>
On the flip-side, there are some constraints:
<itemizedlist>
<listitem><para>If you have 500 servers, all at 80% CPU usage, there's no way you're
going to cram them all onto the mainframe.  Part of the premise is
that most servers sit at only a fraction of their maximum capacity.
</para></listitem><listitem><para> The software must be architecture compatible.
</para></listitem><listitem><para> Mainframe administrators and programmers are rare and expensive.
</para></listitem></itemizedlist>
			</para><para>
The ideal situation for an s/390 or z/Series is an application which is
not very CPU intensive, but is highly I/O intensive, that must _NEVER_ go
down.  Could that be why many companies do databases on them?  Think
airline ticketing systems, financial systems, inventory, etc :)
Realize, however, that your cost of entry is probably going to be well
over a million dollars, unless you want a crippled entry-level box.
You probably don't want to buy this server to run your web site.
You probably want to buy it to run your database.
That being said, if you happen to order more than you really need -- a
reasonably common phenomenon in IT shops -- you can now run Linux
instances with that extra capacity. :)
	</para>
	</section>
	<section id="mqseries">
	<title>mqseries</title>
	<para>
The LVS worked for a client connected directly to the director,
but not from a client on the internet.
			</para><para>
<blockquote><para>
Carlos J. Ramos <emphasis>cjramos (at) genasys (dot) es</emphasis> 12 Mar 2002
			</para><para>
Now, it seems to be solved by using static routes to hosts instead
of using static routes to networks.
			</para><para>
There is also another important note.
Directors uses MQSeries from IBM, the starting sequence in haresources
was mqseries masq.lvs (script for NAT), it looks that the 1 minute
needed by mqseries to get up was confusing(!?) masq.lvs or ldirectord.
We have just change the order to get up mqseries and masq.lvs, rising up
first masq.lvs and finally mqseries.
			</para><para>
With these two changes it works perfectly.
</para></blockquote>
	</para></section>
	<section id="log_files">
	<title>LVS log files</title>
	<para>
Chris Ruegger
	</para>
	<blockquote>
Does LVS maintain a log file or can I configure it to use one so
I can see a history of the requests that came in and how it forwarded them?
	</blockquote>
	<para>
Joe 1 Apr 2002
	</para>
	<para>
It doesn't but it could. LVS does make statistics available.
	</para>
	<para>
Another question is whether logging is a good idea. The director is a
router with slightly different rules than a regular router. It is designed
to handle 1000's requests/sec and operate with no spinning media (eg on a flash card).
There's no way you can log all connections to a disk and maintain
throughput. You couldn't even review the contents of the logs. People do
write filter rules, looking for likely problems and logging suspicious
packets. Even reviewing those files overwhelmes most people.
	</para>
	<para>
Ratz 2 Apr 2002
	</para>
	<para>
LVS works on L4. Maybe the following command will make you happy:
	</para>
<programlisting><![CDATA[
echo 666 > /proc/sys/net/ipv4/vs/debug_level
]]></programlisting>
	<para>
Joe - is 666 the logging level of the beast?
	</para>
	<para>
Horms 06/20/2005
	</para>
	<para>
LVS is part of the kernel. 
And as such any logging is done through the kernel.
If LVS was compiled with support for debugging information, then
<filename>/proc/sys/net/ipv4/vs/debug_level</filename> will exist. 
If you run
	</para>
<programlisting><![CDATA[
echo 0 > /proc/sys/net/ipv4/vs/debug_level
]]></programlisting>
	<para>
then it will turn logging off.
If you echo any value greater than 0, it will increase the verbosity
of logging. I believe the useful range of values is from 1 - 12.
That is, once you get to 12, you have as much debugging information
as you will get, and increasing the value won't give you any more.
For a running server, I'd suggest a value of 3 or less.
	</para>
	<para>
Graeme
	</para>
	<para>
The debug logs above are (at the higher levels) hugely detailed, far more so 
than most people would require, and (oddly enough) are best suited for 
debugging problems with the LVS module code itself than anything else.
	</para>
	<para>
If what you want is heartbeat or healthcheck monitoring, there are a 
number of applications which do this; the most common approaches are 
(in no particluar order):
	</para>
	<itemizedlist>
		<listitem>
heartbeat + mon
		</listitem>
		<listitem>
ldirectord
		</listitem>
		<listitem>
keepalived
		</listitem>
	</itemizedlist>
	</section>
	<section id="linux_vlan"><title>LVS and linux vlan</title><para>
<blockquote><para>
Matt Stockdale
			</para><para>
         Does the current LVS code work in conjuction with the linux vlan
 code? We'd like to have a central load balancing device, that connects
 into our core switch w/ a dot1q trunk, and can have virtual interfaces on
 any of our many netblocks/vlans.
</para></blockquote>
			</para><para>
Benoit Gaussen <emphasis>bgaussen (at) fr (dot) colt (dot) net</emphasis> 20 Mar 2002
			</para><para>
I tested it and it works. The only problem I encountered is a MTU problem
with eepro100 driver and 8021q code. However there is a small patch on
8021q website.
My config was linux 2.4.18/lvs 1.0.0 configured with LVS-NAT.
	</para>
	</section>
	<section id="multi_router">
	<title>multi-home, multi-router LVS</title>
	<para>
Matthew S. Crocker <emphasis>matthew (at) crocker (dot) com</emphasis> 29 Oct 2002
	</para>
	<blockquote>
	<para>
I use LVS in a multi-homed,  multi-router HSRP setup.
	</para><para>
Each LVS is connected to a seperate switch
Each Router is connected to each switch and my upstream providers.
We use BGP4 to talk with our upstream providers.
Routers use HSRP failover for an IP address that the LVS boxes use as a
gateway address.
	</para><para>

The LVS setup is pretty much a standard LVS-NAT install using keepalived.
Each LVS has a default route pointing to an IP address which is a virtual
IP and part of the HSRP router failover system.
	</para><para>

The Routers are standard cisco 7500 series running BGP4 between themselves
and my providers.  They also run HSRP (Hot Swap Router Protocol) between
their ethernet interfaces.
	</para><para>

With my setup I can lose a link, a router, a switch or an LVS box and not
go down.
	</para>
	</blockquote>
	</section>
	<section id="freeze">
	<title>Horror story, mostly from slow file system with disk intensive application</title>
	<para>
This was a long thread. The poster's application worked fine on a single
server, but suffered intermittant freezes when moved to an LVS. Although
many suggestions were offered, none helped and the poster had to figure
it out by himself. In the meantime the poster changed from LVS-NAT to LVS-DR
and rearranged his setup several times over a period of about 3 weeks.
	</para>
	<para>
Jan Abraham <emphasis>jan_abraham (at) gmx (dot) net</emphasis> 11 Nov 2003
	</para>
	<para>
I've solved the issue this morning. Combination of two
independent problems:
	</para>
	<itemizedlist>
		<listitem>
		<para>
Problem A:
		</para>
		<itemizedlist>
			<listitem>
Poorly written PHP application (lucky me, not my fault...) -> tons of
PHP includes on every request (<emphasis>i.e.</emphasis> lots of disk accesses).
			</listitem>
			<listitem>
lack of noatime,nodiratime in <filename>/etc/fstab</filename>, more disk accesses.
			</listitem>
			<listitem>
			<para>
Use of ext3 with the default data mode (ordered)
I should be beaten for this. Still, it's a unknown issue why it worked
well when running on a single server (without LVS).
			</para>
			<para>
I'm not an expert in filesystems, but I can imagine that the ext3
journal ran out of space and holds the system until all entries were
written on their respective places. Just an idea.
"man mount" suggests to use "writeback" as data mode to improve
performance, with the risk of having some files containing old data
fragments after a crash.
			</para>
			<para>
The reason I choosed a journaling file system was to minimize down time
after a crash. For now, I've switched back to ext2, but I'll do some new
attempts with the suggested writeback mode on ext3.
			</para>
			<para>
I think it shall be written with bright red letters:
"do not use journaling filesystem without noatime,nodiratime on a high
traffic website".
			</para>
			</listitem>
		</itemizedlist>
		</listitem>
		<listitem>
		<para>
Problem B:
		</para>
		<para>
A switch that mysteriously sends packets to the wrong servers.
We've
replaced the switch two times, now all packets arrive where they should.
I'll try to get back to LVS-DR tomorrow.
		</para>
		</listitem>
	</itemizedlist>
	<para>
Jacob Coby <emphasis>jcoby (at) listingbook (dot) com</emphasis> 12 Nov 2003
	</para>
	<para>
If you aren't using it already, take a look at the PHP Accelerator
(http://www.php-accelerator.co.uk/).  It made a HUGE difference in our
ability to serve dynamic content quickly.  Our site is made up of about 75k
loc of PHP (plus an additonal 20kloc of support code in php), of which about
~35k is used per page, including at least 8 includes per page.  We serve up
some 7 million pages/month (~110gb).  We aren't a huge site, but we're able
to support this with a dual PIII 733 running at max at 60%.
	</para>
	<para>
Using PHPA reduced the server load by about 50%, improved latency and page
rendering times by anywhere from 50 - 300%, and allowed us to continue using
our single web server for at least another 2 years without moving to
multiple, load balanced servers.  Load balancing is still in the future, but
more or less for reduncancy than anything else.
	</para>
	</section>
	<section id="RTNETLINK">
	<title>RTNETLINK answers:</title>
	<para>
Son Nguyen, 8 Jul 2005
	</para>
<programlisting><![CDATA[
root@realserver [~]# ip route get from CIP to VIP iif tunl0
RTNETLINK answers: Invalid argument
]]></programlisting>
	<para>
Horms
	</para>
	<para>
I suspect that
the route in question is unknown to the kernel.
<emphasis>e.g.</emphasis> my box is 172.16.4.222 and the gateway is 172.16.0.1.
	</para> 

<programlisting><![CDATA[
# ip route get from 172.16.4.222 to 172.16.0.1
172.16.0.1 from 172.16.4.222 dev eth0 
    cache  mtu 1500 rtt 3ms rttvar 5ms cwnd 2 advmss 1460 hoplimit 64
]]></programlisting>

<programlisting><![CDATA[
# ip route get from 172.16.4.223 to 172.16.0.1
RTNETLINK answers: Invalid argument
]]></programlisting>

	<para>
Reid Sutherland <emphasis>mofino (at) gmail (dot) com</emphasis> 4 Aug 2005
	</para>
	<para>
Enable IP Advanced Routing and then whatever else you need under that.
	</para>
	</section>
	<section id="chokes_at_600">
	<title>LVS chokes on 600+ connections</title>
	<para>
Andrei Taranchenko <emphasis>andrei (at) towerdata (dot) com</emphasis> 25 Aug 2005 
	</para>
	<blockquote>
		<para>
We have an active director with 256 MB RAM, and two nodes.
When I do a stress test, the client starts getting timeouts when the
number of *inactive* connections hits 600 or so. If I take out a node,
the same number of inactive connections is easily handled by a node, but
it is still a problem for the director.
The nodes and the director are connected on the hub, and the director is
the default gateway. The nodes are also connected to the rest of the
network on the other interface (they need to see the database, etc).
		</para>
	</blockquote>
	<para>
Horms
	</para>
	<para>
Perhaps there is some issue with the kernel's network stack, and it
could be resolved by trying a different version. 256Mb of ram should be
able to handle a lot more than 600 connections (they consome 100 or so
bytes each). That is, unless your box is very low on memory for other 
reasons. I've done tests with LVS going up to 3,000,000 connections,
on boxes with around 512Mb or ram (I don't remember exactly), so it
shouldn't be an LVS problem.
	</para>
	</section>
	<section id="anti_load_balancing">
	<title>Anti load balancing: all traffic required to go to one realserver</title>
	<para>
This is the opposite of what LVS is designed to do. 
Only a manager would ask for this.
	</para>
	<para>
Cristi 
	</para>
	<blockquote>
I have a LVS NAT setup running for some time now. I want, for management 
issues, that connections to the VIP from a certain host (i don't even 
need granularity) to always be redirected to RS01, for example.
If this cannot be done via ipvs, could you please sugest another course 
of action?
	</blockquote>
	<para>
Graeme 10 Nov 2008
	</para>
	<para>
Combine netfilter marks (fwmarks) and a virtual service based on mark values instead of VIP.
Catch packets from 1.2.3.4 destined for the VIP service port and set a mark:
	</para>
<programlisting><![CDATA[
iptables -t mangle -I INPUT -s 1.2.3.4/32 -d $VIP -p tcp --dport $VIP_PORT -j MARK --set-mark 0x1234
ipvsadm -A -f 0x1234
ipvsadm -a -f 0x1234 -r 192.168.10.1:0 -m
]]></programlisting>
	<para>
This way, hopefully, all packets from 1.2.3.4 will end up being handled
by 192.168.0.10 only. Give it a try.
	</para>
	</section>
</section>
<section id="LVS-HOWTO.L7_switch" xreflabel="L7 Switch">
<title>LVS: L7 Switching</title>
	<section id="l7_intro" xreflabel="L7 switch Introduction">
	<title>Introduction</title>
	<para>
Switching packets based on the content of the payload (L7 switching)
is something of a holy grail.
However, inspecting packet contents is slow (==CPU intensive)
compared to L4 switching and should not be regarded as a panacea.
Commercial L7 switches are expensive.
It's better, where possible, to handle switching at the L4 layer.
This can often by done by <xref linkend="L7_ratz"/> in an L4 friendly manner.
	</para>
	<para>
<ulink url="http://www.netfilter.org/">Netfilter</ulink>
has code for inspecting the contents of packets through the
<emphasis>u32</emphasis> option.
Presumably this could be coupled with fwmark to setup an LVS.
As well there is an L7 Filter for netfilter: 
see <ulink url="http://l7-filter.sourceforge.net/HOWTO-kernel/">
Application Layer Packet Classifier for Linux</ulink>
(http://l7-filter.sourceforge.net/HOWTO-kernel/).
	</para>
	<para>
There are others who think that L7 switching should be handled by
the app.
	</para>
	<para>
malcolm <emphasis>lists (at) netpbx (dot) org</emphasis> 02 Jun 2006
	</para>
	<blockquote>
	<para>
LVS doesn't do L7 'cause L7 should be done by your app 
(<emphasis>i.e.</emphasis> that's what L7 is for.)
	</para>
	</blockquote>
	<para>
Malcolm's statement makes perfect sense technically, 
but when suits are faced with the choice 
of finding someone to recode the application,
which will take time and will have to be tested, 
or paying an awful lot of money to bring in an L7 switch
(which comes with a slick sales team and guaranteed support),
the coder looses out.
	</para>
	<para>
Malcolm <emphasis>lists (at) loadbalancer (dot) org</emphasis> 23 Nov 2006 
	</para>
	<para>
Willy Tarreau's written HAProxy which I'm just testing now and so far it looks very good.
Supports cookie insertion and SNAT etc.
	</para>
	<para>
Ratz - it's rock solid
	</para>
	<para>
A writeup of the situations requiring L7 switching
and the mechanisms used to implement them
is in the documentation on the <link linkend="DRWS">DRWS website</link>.
Although at one time they had to be handled at L7,
now solutions have been found at L4.
	</para>
	<itemizedlist>
		<listitem>
		<para>
		session partitioned
		</para>
		<para>
L7 switching will direct all packets in an SSL session to the same realserver.
At L4 this can be done with persistence. For a session involving
multiple ports (<emphasis>e.g.</emphasis> http, https), this can be handled
by <link linkend="fwmark_persistence_granularity">fwmark with persistence</link>.
		</para>
		<blockquote>
		<para>
Motse <emphasis>gis89517 (at) cis (dot) nctu (dot) edu (dot) tw</emphasis> 16 Apr 2002
L4 persistence works well, if the web servers have the same contents,
but not if two servers contain two (different)
kinds of PHP codes which use session management.
Some products solve this problem by inserting a cookie with the IP of
back-end node. In this way, the web switch can redirect the request based on
cookies. These products still have the same problem as L4 persistence with
all web servers needing to have the same content.
URL switching does not work at this situation.
In my code, I rewrite the PHPSESSION cookie name originally as
		</para>
<programlisting><![CDATA[
PHPSESSION=OOOUNNVJUFTYDKLNIUGTDRTYJUVL::POIOP
to
DRCCDDDDON=OOOUNNVJUFTYDKLNIUGTDRTYJUVL::POIOP
where
        CC -> content support 0~255
        DDDD -> back-end server ID
1 rewrite the cookie name --> need not to modify the HTTP HEADER
2 rewrite the cookie name --> server A and server B can have different PHP code.
]]></programlisting>
		<para>
A request may have two or more than two special cookies.
The rewrite works at the realserver's packet filter.
The cookie will be rewritten back at the packet filter too.
In this way all of web server can have different content.
		</para>
		</blockquote>
		<para>
If your LVS is a squid farm, then some (<emphasis>e.g.</emphasis> e-commerce) sites, will lock
you out if the separate requests for hits on one page come from multiple squids.
Your squid farm should not be setup this way -
see <link linkend="scheduling_squids">scheduling squids</link>
		</para>
		</listitem>
		<listitem>
		<para>
		content partitioned
		</para>
		<para>
Requests in a single HTTP keep-alive connection may need to access different servers.
The L4 solution is to keep content identical on all servers.
In the situation where content is <link linkend="dynamic_images">dynamically generated</link>,
fwmark or shared directories can be used (<emphasis>i.e.</emphasis> the L4 friendly application method).
		</para>
		</listitem>
		<listitem>
		<para>
routing based on content, cookies, url, SSL ID
		</para>
		<para>
You shouldn't use cookies (see <xref linkend="cookie"/>).
You can handle <xref linkend="requests_based_on_URL"/>
to a limited extent.
As for requests based on SSL ID, no-one has an L4 solution.
You may be able to find a application level solution.
		</para>
		</listitem>
	</itemizedlist>
	</section>
	<section id="KTCPVS">
	<title>KTCPVS</title>
	<para>
Preliminary L7 code,
<ulink url="http://www.linuxvirtualserver.org/software/ktcpvs/ktcpvs.html">KTCPVS</ulink>,
has been written by Wensong.
Some documentation is in the source code.
	</para>
	<para>
For a write up on cookie injection see <xref linkend="mod_backhand"/>.
	</para>
	</section>
	<section id="DRWS">
	<title>DRWS</title>
	<para>
<blockquote><para>Ping-Tzay Tsai <emphasis>gis89517 (at) cis (dot) nctu (dot) edu (dot) tw</emphasis> 12 Apr 2002
			</para><para>
I have implemented a direct routed web switch, which is a layer 7 load
balancer with three new mechanisms. The code is a patch to ipvs
0.9.8.
You can get it from the
DRWS project website (http://speed.cis.nctu.edu.tw/&#126;motse/drws.htm, link dead Oct 2002)
			</para><para>
some benchmark using webbench 4.1 :
<programlisting><![CDATA[
1 KTCPVS-0.0.5        1250 request/sec   82 Mbits/sec
2 DRWS 0.0.0-alpha  2550 request/sec   109 Mbits/sec
]]></programlisting>
three web servers at back end  - PIII 1G with 256MB eepro,
the load balancer PIII 866 128MB eepro.
</para></blockquote>
	</para>
	</section>
	<section>
	<title>Alexandre's (unamed) L7 code</title>
	<para>
Alexandre Cassen <emphasis>Alexandre (dot) Cassen@free (dot) fr</emphasis> 11 Dec 2006
	</para>
	<para>
Just this quick email to announce the launch of 
<ulink url="http://www.linux-l7sw.org">www.linux-l7sw.org</ulink>
a new opensource project for layer7 switching. 
After discussions with wensong, I decided to start a new project to try to create a 'new'
switching/loadbalancing code. The low level forwarding engine use TCP Splicing. Current code is a
simple HTTP/1.0 proxy but will extend to rich featured stuff soon (if I found enought time). Had to
spend lot of time in kernel stuff and global design. Current splicing code doesnt support TCP
Selective Ack nor Windows scaling.
	</para>
	<para>
I have setup a mailing list at sf.net
<ulink url="http://lists.sourceforge.net/mailman/listinfo/linux-l7sw-devel">
http://lists.sourceforge.net/mailman/listinfo/linux-l7sw-devel</ulink>. 
But I am monitoring LVS ml too, just can be good to
localize email on this topics into a dedicated mailing list.
	</para>
	</section>
	<section>
	<title>UltraMonkey-L7</title>
	<para>
Hideaki Kondo <emphasis>toreno4257 (at) nifty (dot) com</emphasis> 2006-06-12
	</para>
	<para>
I'm one of the parties concerned of UltraMonkey-L7 project.
<ulink url="http://ultramonkey-l7.sourceforge.jp/index_en.html">
UltraMonkey-L7 project</ulink>
(http://ultramonkey-l7.sourceforge.jp/index_en.html).
There aren't any english manuals at present except for the above web page.
	</para>
	<para>
There are problems compiling kssl support and if you get it to compile 
there is no guarantee that kssl operates correctly. 
In fact, kssl was developed and tested using vanilla kernel 2.4.26 only.
So kssl doesn't support redhat kernel at present.
Also you have to apply the kernel patch for kssl 
(kssl-0.2.0-1/patch/linux-2.4.26-pre6-crypto_cpy.patch) to vanilla kernel-2.4.26 source code.
I don't recommend that you use kssl.
Because kssl needs the vanilla kernel (2.4.26 or maybe later ) and
the kernel patch, and a redhat support isn't received to you.
Besides, kssl needs the specific SSL accelerrator (AEP1000L) for high performance.
Sadly, AEP1000L became manufacturing discontinuance. 
The main functionality of kssl is reverse proxy with SSL support.
So you can substitute a revese proxy software for kssl.
For example, Apache(mod_proxy+mod_ssl), Squid, Delegate, Pound etc.
	</para>
	<para>
P.S. Kssl was developed by NTT COMWARE through Simon Horman's large support.
	</para>
	<para>
Konstantin Ivanov <emphasis>Konstantin.Ivanov () planetdiscover ! com</emphasis> 2007-05-25 
	</para>
	<para>
Is it possible based on the URL address for the load balancer to forward 
the requests to a particular real servers. What I need to do is for 
example for a domain name domain1.com just server1 and server2 will 
respond, and for domain2.com server 1 and server3 will respond. I tried 
looking at UltraMonkey-L7 project but you can match only the file names 
in the URL like this:
	</para>
<programlisting><![CDATA[
l7vsadm -A -t 192.168.8.58:80 -m url --pattern-match '*.html' -s rr
l7vsadm -a -t 192.168.8.58:80 -m url --pattern-match '*.html' -r 10.0.0.10:80
]]></programlisting>
	<para>
I know that one workaround is to have several virtual IP's on the load 
balancer and then match based on that, but I need a functionality 
similar to what Pound Load Balancer does.
	</para>
	</section>
	<section>
	<title>from the mailing list about L7 switching</title>
	<para>
Michael Sparks <emphasis>Michael.Sparks (at) wwwcache (dot) ja (dot) net</emphasis> 12 Jul 1999
	</para>
	<para>
Some of the emerging redirection switches on the
market support something known as Level 7 redirection
which essentially allows the redirector to look at the
start of the TCP data stream, by spoofing the initial
connection and making load balancing based on what it
sees there. (Apologies if I'm doing the equivalent of
"teaching your grandma to suck eggs", but at least this way
there's less mis-understanding of what I'm getting at/after)
			</para><para>
For example if we have X proxy-cache servers, we could
spoof an HTTP connection, grab the requested URL, and
hash it to one of those X servers. If it was possible
to look inside individual UDP packets as well, then we
would be able to route ICP (inter cache prototol) packets
in the same way. The result is a cluster that looks like
a single server to clients.
	</para>
	<blockquote>
		<para>
Wensong
		</para><para>
Do you mean that these X proxy-cache servers are not
equivalent, and they are statically partitioned to fetch
different objects? for example, the proxy server 1 is
to cache European URLs, and the proxy server 2 is to
cache Asian URLs, then there is a need to parse the
packets to grab the requested URL. Right?
        	</para><para>
If you want to do this, I think Apache's mod_rewrite
and mod_proxy can be used to group these X proxy-cache
servers as a single proxy server. Since the overhead
of dispatching requests in application level is high,
its scalability may not be very good, the load balancer
might be a bottleneck when there are 4 proxy servers
or more.
        	</para><para>
The other way is to copy data packet to userspace to
grap the request if the request is in a single UDP packet,
the userspace program select a server based on the request
and pass it back to the kernel.
		</para>
	</blockquote>
	<para>
For generic HTTP servers this could also allow the server
to farm cgi-requests to individual machines, and the normal
requests to the rest. (eg allowing you to buy a dual/quad
processor to handle soley cgi-requests, but cheap/fast
servers for the main donkey work.)
	</para>
	<para>
Wensong
	</para>
	<blockquote>
It is statically partitioned. Not very flexible and scalable.
	</blockquote>
	<para>
We've spoken to a number of commercial vendors in the past
who are developing these things but they've always failed
to come up with the goods, mainly citing incompatibility
between our needs and their designs :-/
	</para>
	<para>
Any ideas how complicated this would be to add to your
system?
	</para>
	<para>
Wensong
	</para>
<blockquote>
	<para>
If these proxy-cache servers are identical(they are the same
of all kind of URL requests), I have a good solution to
use LVS to build a high-performance proxy server.
	</para>
<programlisting><![CDATA[
request
|-<--fetch objects directly
|                    |-----Squid 1---->reply users directly
|->LinuxDirector  ---|
  (LVS-Tun/VS-DR)    |-----Squid 2
                     |     ...
                     |-----Squid i
]]></programlisting>
	<para>
Since LVS-Tun/VS-DR is on client-to-server half connection,
squid servers can fetch object directly from the Internet
and return objects directly to users. The overheading of
forwarding request is low, scalabilty is very good.
	</para><para>
The ICP is used to query among these Squid servers. In order
to avoid the mulitcasting storm, we can add one more NIC in
each squid server for ICP query, we can call it multicast
channel.
	</para>
	</blockquote>
	<para>
again Michael,
	</para><para>
The reason I asked if the code could be modified to do this:
	</para>
<programlisting><![CDATA[
look at the start of the TCP data stream, by spoofing the initial
connection and making load balancing based on what it sees there.
]]></programlisting>
	<para>
Is to enable us to do this:
	</para>
	<orderedlist>
		<listitem>
Spoof the connection until we're able to grab the URL requested in
      the HTTP header.
		</listitem>
		<listitem>
Based on that info make a decision as to which server should deal
with the request.
		</listitem>
		<listitem>
		<para>
Fake the start of a TCP request to that server, making it look like
      it's come from the original client, based on the info we got from
      the original client in 1) And when we reach the end of the data we
      recieved from 1) stop spoofing and hand over the connection.
		</para><para>
Boxes like the Arrowpoint CS100/CS800 do this sort of thing, but their
configurable options for 2) isn't complex enough.
		</para>
		</listitem>
		<listitem>
Forward UDP packets after looking inside the payload, seeing if it's
      an ICP packet and if so forwarding based on the ICP payload.
		</listitem>
	</orderedlist>
	<para>
The reason for 1,2 and 3 is to have deterministic location of cached data,
to eliminate redundancy in the cache system, and to reduce intra-cache
cluster communication. The reason for 4 is because the clients of our
caches are caches themselves - they're the UK National Academic root level
caches servicing about a 3/4 billion requests per month during peak
periods.
	</para><para>
Also 2) can be used in future to implement a cache-digest server to serve
a single cache digest for the entire cluster to eliminate delays for
clients caused by ICP. (During peak periods this is large.)
	</para><para>
The boxes from Arrowpint can do 1-3, but not 4 for example, and being
proprietory hardware...
	</para><para>
Essentially the ICP+cache digest thing for the cluster is the biggest nut
- squid 2.X in a CARP mode can do something similar to 1,2 and 3, at the
expense of having to handle a large number of TCP streams, but wouldn't
provide a useful ICP service (it would always return ICP MISS), and can't
provide the cache digest service. (Or would at least return empty digests)
	</para>
<blockquote>
I have a good solution to use LVS to build a high-performance proxy
server.
</blockquote>
	<para>
Fine (to an extent) for the case where requests are coming from browsers,
but bad where the clients are caches:
	</para>
	<itemizedlist>
		<listitem>
Client sends ICP packet to Linux Director, forwarded to cache X
resulting in a ICP HIT reply, so client sends HTTP request to Linux
Director, which forwards request to cache Y, resulting in a MISS, Y
grabs from X, no major loss.
		</listitem>
		<listitem>
However same scenario with X and Y flipped, results in ICP MISS, where
there would've been a cluster hit. Pretty naff really!
		</listitem>
	</itemizedlist>
	<para>
It's even worse with cache digests...
	</para><para>
We've had to say this sort of thing to people like Alteon, etc too...
(Lots more details in an overview at
http://epsilon3.mcc.ac.uk/&#126;zathras/WIP/Cache_Cooperation/).
	</para><para>
later...
	</para><para>
A slightly better discussion of how these techniques
can be used is at: http://www.ircache.net/Cache/Workshop99/Papers/johnson-0.ps.gz)
	</para>
	<para>
Wensong
	</para>
	<blockquote>
		<para>
	I have read the paper "Increasing the performance of transparent caching
with content-aware cache bypass". If no inter-cache cooperation is
concerned, it can be easily done on Linux, you don't need to buy
expensive arrowpoint. As for availability, Linux boxes are reliable
now. :)
		</para><para>
I can modify the transparent proxy on Linux to do such a content-aware
bypass and content-aware switching. The content-aware bypass will enable
fetch non-cacheable objects directly, and the content-aware switching
can let your cache cluster not overlapped.
		</para>
	</blockquote>
	</section>
	<section id="TCPSP">
	<title>What is TCPSP?</title>
	<para>
Aihua Liu <emphasis>liuah (at) langchaobj (dot) com (dot) cn</emphasis>
May 26, 2003
	</para>
	<blockquote>
What is <ulink url="http://www.linuxvirtualserver.org/software/tcpsp/index.html">TCPSP</ulink>?
	</blockquote>
	<para>
Horms
	</para>
	<para>
I believe there
is a small ammount of documentation on TCPSP in the tarball
provided.
	</para>
	<para>
IPVS is an implementation of layer 4 loadbalancing for the Linux Kernel.
That is, it allows you to create virtual services which load
balance traffic to realservers.
	</para>
	<para>
TCPSP is an implementation of TCP socket splicing for the Linux Kernel.
This means that you can open a pair of sockets in user space
and then join them together in the kernel.
For example a daemon that listens for connections from end-users and
then makes a corresponding connection to a real-server. Then after
the connection is set up, the two sockets are spliced and all
further traffic between the sockets is handled by the kernel.
This avoids the kernel to userspace and userspace to kernel copies
and context switches that are required to handle the sockets
in user space.
	</para>
	<para>
In sort, TCPSP may be useful for implementing Layer 7 swiching
where the begining of a connection is handled in user-space
but the remainder of the connection is handled in the kernel.
	</para>
	<blockquote>
		<para>
From what I know, TCPSP'work as follows:
		</para>
		<orderedlist>
			<listitem>
Client builds up the connection with director first.
			</listitem>
			<listitem>
After the director receives the client requests, then
it sets up connection with the selected real-server and sends the
requests to it.
			</listitem>
			<listitem>
Real-server send replies to director.
			</listitem>
			<listitem>
Director receives the replies from the realserver and
responses to the client through tcp-splicing.
			</listitem>
		</orderedlist>
	<para>
Is this correct?
	</para>
	</blockquote>
	<para>
Horms
	</para>
	<para>
That is how an application that uses TCPSP could work.
And is more or less how the demonstration programme works.
But, TCPSP is just a mechanism, to allow you
to splice connections. It is not a programme itself.
	</para>
	<para>
Alexandre Cassen <emphasis>Alexandre (dot) Cassen (at) wanadoo (dot) fr</emphasis>
	</para>
	<para>
In step 2; parse the client request at layer7 level, then select
the remote realserver to connect to (run the loadbalancing
algorithm). When selected, the director creates a new socket
to the selected realserver.
Then the director forwards the incoming client request at layer7.
In the linux kernel,
zerocopy is used to speed processing to forward the client
request.
	</para>
	<para>
Step 4:
To speed up the process, both sockets are spliced when the
realserver has been selected and connect established.
That way we optimize time for
upstream forwarding.
	</para>
	<para>
We also need to know how to unsplice the socket pair.
Unsplicing can be done using the application specific header
to detect end of stream forwarding. For HTTP/SSL we can use
for example the "Content-Length:" header value to detect
end of stream and to unsplice socket pair. But For efficient
applications and because most of webserver are using HTTP/1.1
there is a big benefit keeping as possible the socket pair
spliced since client->webserver are using "HTTP/1.1 keepalive"
connection (persistent), so that the remote webserver on the
realserver is still connected
after the first GET is processed. Thus we optimize the forwarding
but it is more difficult to know when socket pair must be
unspliced.
	</para>
	<blockquote>
Does the current implementation support unsplicing at all?
	</blockquote>
	<para>
Alexandre
	</para>
	<para>
I  spoke about this with Wensong last month,
but we haven't done it yet.
	</para>
	<blockquote>
I agree that is probably isn't needed very much,
especially in the keepalive case.
	</blockquote>
	<para>
Yes, but we need to handle failover (dead realservers),
mainly the problem of peer connection error reflected to socket descriptor.
	</para>
	</section>
</section>
<section id="LVS-HOWTO.geographically_distributed">
<title>LVS: Geographically distributed load balancing</title>
<para>
What people want is to be able to determine the closest realserver
(by some internet metric) to any particular client.
This section is ideas on geographically distributed serving,
not all LVS.
</para>
<para>
LVS-Tun allows your realservers to be on different networks to your director
<emphasis>i.e.</emphasis> anywhere, including on different continents.
</para>
	<section if="location_from_IP">
	<title>Determining Location from the IP</title>
	<para>
Blocks of IPs are assigned to ISPs and shouldn't move much.
In principle the locations of the ISPs are known. 
It should be possible to produce a mapping of IP to city/country.
	</para>
	<para>
Malcolm <emphasis>lists (at) loadbalancer (dot) org</emphasis> 07 Apr 2007
	</para>
	<para>   
ultradns.com (and others to I'm sure) have a managed service that uses a
combination of BGP and Global DNS to map IP to location.
They can do it pretty well as they have high level DNS servers and its a
very tricky thing to do well.
Some people would even argue it's impossible:
<ulink url="http://www.tenereillo.com/GSLBPageOfShame.htm">
Why DNS based Global Server Load Balancing (GSLB) Doesn't Work</ulink>
(http://www.tenereillo.com/GSLBPageOfShame.htm).
	</para>
	<para>
David Black <emphasis>dave (at) jamsoft (dot) com</emphasis>09 Apr 2007
	</para>
	<para>
For work, I implemented an expanded variation of this at http://www.caraytech.com/geodns/
...and using this database get pretty accurate IP-to-US state mappings,
in addition to country: http://www.maxmind.com/app/geolitecity
	</para>
	<para>
Not perfect - nothing like this is - 
but definitely a functional optimization.   
My applications so far are to direct clients to the
"nearest" web server cluster and VPN gateway for the purpose of minimizing latency.   
I stuff the names to be geo-balanced into a
subdomain served only by a group of nameservers running the above code
and database.
	</para>
	<para>
Stefan Schmidt <emphasis>zaphodb--lvs-users (at) zaphods (dot) net</emphasis> 9 May 2007 
	</para>
	<para>
I remember seeing a RIPE presentation 
(http://www.ripe.net/ripe/meetings/ripe-41/presentations/routing-opperman/index.html)
on that topic, but it seems the project's website (http://www.bgpdns.org/) 
has already vanished from the net. 
If I remember correctly, part of it was a patch for djb's tinydns server.
The presentation mentions supersparrow btw.
As far as geographic loadbalancing via DNS 
(http://www.micro-gravity.com/wiki/index.php?page=GeoDns
http://wiki.blitzed.org/DNS_balancing)
goes: Wikipedia is using the geo backend for PowerDNS (http://doc.powerdns.com/)
and seems happy with it (http://www.nedworks.org/~mark/presentations/hd2006/).
	</para>
	</section>
	<section id="geographic_supersparrow">
	<title>Supersparrow</title>
	<para>
Horms has written <xref linkend="supersparrow"/>.
Super Sparrow works differently than and is incompatible with LVS.
Super Sparrow uses <ulink url="http://www.zebra.org">zebra</ulink>
to fetch BGP4 routing information 
from which you can determine the number of AS hops between client and server.
Documentation on BGP is hard to find (the early zebra docs had none).
Horms suggests a http://www.netaxs.com/&#126;freedman/bgp/bgp.html
"BGP Routing Part 1"  by Avi Freeman of Akami.
It's somewhat Cisco centric and there is no part 2 yet,
but is applicable to zebra.
This site disappeared in Jul 2002 (look for cached versions),
but Avi Freedman has his
<ulink url="http://www.freedman.net/">own webpage</ulink>
with some BGP links and a note that he's writing a book on BGP.
	</para>
	<note>
2004: The documentation for zebra and dynamic routing is much better -
see <xref linkend="dynamic_routing"/>.
	</note>
	<para>
horms 8 May 2007
	</para>
	<para>
I'm very interested in doing more work in this area,
but I'm very distracted by other things.
	</para>
	<para>
Horms 30 Aug 2004 
	</para>
	<para>
I have some code which creates a small routing daemon, that gets
all its data from a list of routes you provide at run time.
Its at 
<ulink url="http://cvs.sourceforge.net/viewcvs.py/supersparrow/supersparrow/ssrs/">ssrs</ulink>
(http://cvs.sourceforge.net/viewcvs.py/supersparrow/supersparrow/ssrs/).
I also have some code to help generate the list of routes
from BGP dumps from (Cisco) routers
at
<ulink url="http://cvs.sourceforge.net/viewcvs.py/vanessa/scratch/inet_map/">inet_map</ulink>
(http://cvs.sourceforge.net/viewcvs.py/vanessa/scratch/inet_map/).
And I have a patch to Bind 9 to add supersparrow support
<ulink url="http://www.supersparrow.org/download/wip/bind9/">bind 9 support</ulink>
(http://www.supersparrow.org/download/wip/bind9/).
All this needs a bit of polish, as appart from hacking on it
for my own personal use I haven't done any work on it for a while.
It does work, and is actually used for www.linuxvirtualserver.org
	</para>
	<para>
Fortunately the format of the
<filename>/etc/ssrs.routes</filename> file 
is simple.
Each line has a prefix followed by an AS number <emphasis>e.g.</emphasis> 
	</para>

<programlisting><![CDATA[
212.124.87.0/24  1234
213.216.32.0/19  1235
195.245.215.0/24 7
195.47.255.0/24  7
217.76.64.0/20   1234
193.236.127.0/24 1234
]]></programlisting>
	<para>
All the prefixes are stored in a red-black tree and the most speficic
prefix for the request will take presedence. 
If you have
	</para>

<programlisting><![CDATA[
212.124.87.0/24  1234
212.124.87.1/32  7
]]></programlisting>
	<para>
Then if you look up the AS for 212.124.87.1 you will get 7.
If you look up the AS for 212.124.87.2 you will get 1234.
	</para>
	<para>
You can telnet to the ssrsd daemon, it will ask you for a password
but doesn't actually check it, so just put in whatever you like -
I should probably fix that up too :)
	</para>
	<para>
Josh Marshall Aug 09, 2004
	</para>
	<blockquote>
		<para> 
I've been looking into
implementing something like supersparrow to get high availability /
fastest connection for our web servers. We have some servers in
Australia and some in the USA and some in Holland. I'm interested in
the dns method of getting the closest server for the client connecting
so that we don't have to do http redirects and have multiple webnames
configured. That's a bit further along.
		</para>
		<para> 
I'm wondering if I need to have a bgp daemon with a public AS number
to be able to get the information needed to determine the best path
for the client.  I have done some tests and read loads of
documentation but am not sure how to get the information without
having a public AS number. The supersparrow documentation describes
what appears to be an internal solution so doesn't show whether this
is possible or not.
		</para>
	</blockquote>
	<para>
Horms 14 Oct 2004
	</para>
	<para>
The way that supersparrow was designed is that you have access
to BGP information for each site that you have servers located at.
You do not need a public AS number to get this information, however
you do need _read only_ access to your provider's BGP information.
Unfortunately this can be difficult to get your hands on.
	</para>
	<blockquote>
I guess I'm also wondering whether I should be looking at supersparrow
- I know that the software was written a few years ago, but the idea
behind it and the amount of processing it needs to do I can imagine it
doesn't need to be actively maintained.
	</blockquote>
	<para>
Yes it does have that apperarence. But I am actually in the process
of sprucing it up a lot. Most of what I have so far is
in the cvs repository
http://sourceforge.net/cvs/?group_id=10726,
http://www.vergenet.net/linux/vanessa/cvs.shtml.
About the only thing of note still
missing is the patch for bind 9
http://www.supersparrow.org/download/wip/bind9/ .
But please feel free to play with what
is there.
	</para>
	<blockquote>
If anyone has any advice as to what I can do, to get the best path
information with (or without) bgp without having a public AS number
I'd really appreciate it.
	</blockquote>
	<para>
I have been toying with a few ideas to cope with not being able to get
access to BGP at colocation sites. One of the ideas that I had was to
provide a static list of networks and what site they should map to. I
implimented this as ssrsd which is in the CVS tree now. ssrsd
understands that for instance 10.0.0.0/25 is part of 10.0.0.0/18 and
will choose the site listed for 10.0.0.0/25 over the one for
10.0.0.0/18. Of course you still have to create the list somehow and at
this stage it isn't at all dynamic. But it can work quite well.
	</para>
	<para>
However many people have thought about geographically distributed LVSs.
for historical completeness here are some of their musings.
	</para>
	</section>
	<section id="michael_sparks">
	<title>sharing/separate routers</title>
	<para>
Michael Sparks <emphasis>zathras (at) epsilon3 (dot) mcc (dot) ac (dot) uk</emphasis> 2000-03-08
	</para>
	<blockquote>
 I'm curious about the physical architecture of a cluster of servers
 where "the realservers have their own route to the client."  (Like in
 LVS-DR and LVS-Tun) How have people achived this in real life?  Does
 each realserver actually have it's own dedicated router and Internet
 connection?  Do you set up groups of realservers where each group
 shares one line?
	</blockquote>
	<para>
Nissim
	</para>
	<para>
It could do it this way or it can share resources.
We've got 3 LVS based clusters, based
around LVS-Tun. The reason for this is because one of the clusters is at a
different location (about 200 miles from where I'm sitting) , and this
allows us to configure all the realservers in the same way thus:
	</para>
<programlisting><![CDATA[
tunl0:1 - IP of LVS balanced cluster1
tunl0:2 - IP of LVS balanced cluster2
tunl0:3 - IP of LVS balanced cluster3 (remote)
]]></programlisting>
	<para>
The only machines that ends up getting configured differently then are
just the directors.
	</para>
	<para>
So whilst machines are nominally in one of the three clusters, if (say)
the remote cluster is overloaded, it can take advantage of the extra
machines in the other two clusters, which then reply directly back to the
client - and vice versa.
	</para>
	<para>
In that situation a client in (say) Edinburgh, could request an object via
the director at Manchester, and if the machines are overloaded there, have
the request forwarded to London, which then requests the object via a
network completely separate from the director's and returns the object to
the client.
	</para>
	<para>
That UK Nat cache likely to be introducing another node at another
location in the country at some point in the near future which will be
very useful. (The key advantage is that at each location we gain X more
Mbit/s of bandwidth to utilise making service better for users.)
	</para>
	</section>
	<section id="geographic_bgp4">
	<title>Other uses of BGP4 with LVS</title>
	<note>
The thread here is a bit of a logical mess.
The original postings are not in either archive, 
so I can't straighten it out anymore.
	</note>
	<para>
Joe:
	</para>
	<blockquote>
how do I get BGP info from a BGP router to the director?
	</blockquote>
	<para>
Lars Marowsky-Bree <emphasis>lmb (at) teuto (dot) net</emphasis> 23 Jul 1999
	</para>
	<para>
If you telnet to the BGP4 port (port 179) of the the router running BGP4
	</para>
<programlisting><![CDATA[
#telnet router bgp
]]></programlisting>
	<para>
and do a
	</para>
<programlisting><![CDATA[
"sh ip route www.yahoo.com"
]]></programlisting>
	<para>
for example, you will get something like this
	</para>
<programlisting><![CDATA[
Routing entry for 204.71.192.0/20, supernet
  Known via "bgp 8925", distance 20, metric 0
  Tag 1270, type external
  Last update from 139.4.18.2 1w5d ago
  Routing Descriptor Blocks:
  * 139.4.18.2, from 139.4.18.2, 1w5d ago
      Route metric is 0, traffic share count is 1
      AS Hops 4
]]></programlisting>
	<para>
This address is 4 AS hops away from me.
You can also find out this information using SNMP if I recall correctly.
	</para>
	<para>
The most cool idea would be to actually run a routing daemon on the cluster
manager (like gated or Zebra (see www.zebra.org)), then we wouldn't even need
to telnet to the router but could run fully self contained using an IBGP feed.
Zebra is quite modular even and could possibly be made to integrated more
tightly with the dispatcher...
	</para>
	<para>
Joe
	</para>
	<blockquote>
It must have been your other mail where you said that this was simple
but not everyone knew about it. I just found out why. My cisco
tcipip routing book has 2 pages on BGP. They told me to find a cisco
engineer to "discuss my needs" with if I wanted to know more about BGP
	</blockquote>
	<para>
There is actually some sort of nice introduction hidden on
www.cisco.com, search for BGP4.
"Internet Routing Architecture"
from Cisco Press covers everything you might want to know about
BGP4.
	</para>
	<para>
_All_ routers, participating in global Internet routing,
hold a full view of the routing table, reflecting their view of the network.
They know how many AS (autonomous systems) are in between them
and any reachable destination on the network.
If they have multiple choices (ie multiple connections, so called
multi homed providers), they select the one with the shortest AS path and
install it into their routing table.
	</para>
	<para>
Now, one sets up a dispatcher which has BGP4 peerings with all participatin g
clusters. Since the dispatcher only installs the best routes to all targets in
it's routing table, it is a simple lookup to see which cluster is closest to
the client.
	</para>
	<para>
If a cluster fails, the peering with the dispatcher is shutdown and the backup
routes (the views learned from other clusters) take over.
	</para>
	<para>
This is actually very nice and well tested technology,
since it is what makes the internet work.
	</para>
	<para>
It requires cooperation on part of the ISP hosting the cluster, that he
provides a read-only "IBGP" feed to the cluster manager inside his AS.
	</para>
	<para>
BGP4 AS hops may not be directly related to latency.
However,
it tells you how many backbones are in between you and how many are not,
which does have a tight relationship to the latency. And you can use the
BGP4 route-maps etc to influnce the load balancing on an easy way - if you
got one cluster from which a certain part of the Internet is reached via a
slow satellite link, you can automatically lower the preference for all
routes comeing in via that satellite link and not use that.
	</para>
	<para>
Ted Pavlic <emphasis>tpavlic (at) netwalk (dot) com</emphasis> 9 Sep 1999:
	</para>
	<para>
For now AS hops probably are useful - we have two mirrors on
different continents.
	</para>
	<para>
Lars
	</para>
	<para>
You do NOT and cannot run OSPF here. OSPF is an "IGP"
(interior routing protocol) which can't be usefully applied here.
	</para>
	<blockquote>
I suppose I figured large networks might all share OSPF information, but I
guess that they wouldn't share too much OSPF information between different
geographical locations. (And I'm guessing that the latency between the load
balancer and the user will PROABABLY almost exactly the same as the latency
between the end-servers and the user...so...) I never claimed that I knew
much of anything about BGP or OSPF, but thought that if BGP wasn't very
helpful... OSPF might be. :) (It was a shot in the dark - a request for
comments, if anything)
	</blockquote>
	<para>
Of course, you not only want to figure BGP4, but also load and availability.
We should investigate what other geogrpahical load balancers do.
A lot of them setup large proxy'ing networks.
	</para>
	<blockquote>
AFAICT, a lot of geographical load balancing systems seem to use their own
means of finding which server is best per end-user. I think, for decent load
balancing on that sort of scale, most balancers have to invent their own
wheel.
	</blockquote>
	<para>
This by no means is an easy task -- doing decent geographical load
balancing. Companies put in a good deal of R and D to do just this and customers
pay a good deal of money for the results.
	</para>
	<blockquote>
Worse comes to worst, have a perl script look-up the name of the machine
that made the request... grab the first-level domain... figure out which
continent it should go on.
	</blockquote>
	<para>
DNS has no guaranteed reply times at all.
	</para>
	<blockquote>
it wasn't a serious suggestion for production.
Just simply a way to divy out which mirror got which request.
	</blockquote>
	</section>
	<section id="geographic_bridging">
	<title>Geographically remote nodes connected by Bridging</title>
	<para>
Andy Wettstein <emphasis>awettstein (at) cait (dot) org</emphasis> 15 Jul 2003
	</para>
	<blockquote>
		<para>
I am trying to extend
an lvs-dr to a different physical location with the help of an etherIP
bridge.  I am using 2 openBSD boxes to do this, if you want to see the
details look at this almost all the way at the bottom:
http://www.openbsd.org/cgi-bin/man.cgi?query=brconfig&amp;sektion=8.  I am
not using IPSec so that is not causing me any problems.
		</para>
		<para>
Anyway, I have all normal LAN traffic working correctly, so I'm sure the
EtherIP bridge is working correctly, but if I have a server that is in an
LVS cluster the server never sees that traffic that is being sent to it
as part of the cluster.
		</para>
	</blockquote>
	<para>
Ratz
	</para>
	<para>
Do you rewrite MAC addresses on the bridge? How does a tcpdump look like on
all the director, the bridge and the node on the other side? How are the
neighbour tables set up?
	</para>
	<blockquote>
		<para>
I don't do any MAC address rewriting on the bridge.
This is my test service:
		</para>
<programlisting><![CDATA[
TCP  192.168.0.45:8000 wlc
  -> 192.168.0.48:8000    Route   1      0          0
]]></programlisting>
		<para>
The openbsd box with the director on its physical lan is set up like this
(all real ips changed):
		</para>
<programlisting><![CDATA[
vlan0: flags=8943<UP,BROADCAST,RUNNING,PROMISC,SIMPLEX,MULTICAST> mtu 1500
        address: 00:02:b3:d0:36:0d
        vlan: 57 parent interface: em0
        inet6 fe80::202:b3ff:fed0:360d%vlan0 prefixlen 64 scopeid 0x1a
        inet 192.168.0.1 netmask 0xffffff80 broadcast 192.168.0.127

gif1: flags=8051<UP,POINTOPOINT,RUNNING,MULTICAST> mtu 1280
        physical address inet 172.20.1.2 --> 172.20.1.3
        inet6 fe80::206:5bff:fefd:ef23%gif1 ->  prefixlen 64 scopeid 0x30

bridge0: flags=41<UP,RUNNING>
        Configuration:
                priority 32768 hellotime 2 fwddelay 15 maxage 20
        Interfaces:
                gif1 flags=3<LEARNING,DISCOVER>
                        port 48 ifpriority 128 ifcost 55
                vlan0 flags=3<LEARNING,DISCOVER>
                        port 26 ifpriority 128 ifcost 55
]]></programlisting>
		<para>
The openbsd box with the member of the cluster (traffic never gets to it):
		</para>
<programlisting><![CDATA[
vlan1: flags=8943<UP,BROADCAST,RUNNING,PROMISC,SIMPLEX,MULTICAST> mtu 1500
        address: 00:02:b3:d0:32:78
        vlan: 57 parent interface: em0
        inet6 fe80::202:b3ff:fed0:3278%vlan1 prefixlen 64 scopeid 0x1c

gif1: flags=8051<UP,POINTOPOINT,RUNNING,MULTICAST> mtu 1280
        physical address inet 172.20.1.3 --> 172.20.1.2
        inet6 fe80::206:5bff:fe3e:6d58%gif1 ->  prefixlen 64 scopeid 0x31

bridge0: flags=41<UP,RUNNING>
        Configuration:
                priority 32768 hellotime 2 fwddelay 15 maxage 20
        Interfaces:
                gif1 flags=3<LEARNING,DISCOVER>
                        port 49 ifpriority 128 ifcost 55
                vlan1 flags=3<LEARNING,DISCOVER>
                        port 28 ifpriority 128 ifcost 55
]]></programlisting>
		<para>
the tcpdumps show only packets through bridge0 on the side of the
bridge with the director on it.  I can't see any traffic on gif1.
		</para>
		<para>
192.168.0.0 is subnetted so 192.168.0.143 goes through the openbsd box,
which is also our router.  That just gave me an idea.  Testing from an IP
that doesn't need to be routed...Works!!
		</para>
		<para>
So going through
		</para>
<programlisting><![CDATA[
192.168.0.143/26 -> 192.168.0.129/26 -> 192.168.0.48/25
                              ^^^
                              router interface on openbsd box (vlan2)
]]></programlisting>
		<para>
doesn't work, but going
		</para>
<programlisting><![CDATA[
   192.168.0.61/25 -> 192.168.0.48/25
]]></programlisting>

		<para>
without a route does work.
		</para>
	</blockquote>
	<para>
A little later...
	</para>
	<blockquote>
		<para>
I looked into this a little bit further.  The problems I was having were
mostly due to the OpenBSD firewall not keeping state on those
connections that needed to be routed by that router/etherIP bridge
machine.  After I got that fixed traffic would show up on the cluster
node and the node would try to reply, but I would never see the return
traffic.  So after doing a little further investigation the tcpdumps
showed me that the traffic needed to be fragmented because on that
bridge the mtu is 1280.  So I set the mtu to 1280 on the the cluster
node and everything works.
		</para>
		<para>
So you can add that as another way to geographically extend the LVS.
Although it is a little inefficient since all broadcasted lan traffic
gets transmitted, but that isn't a problem for me.
		</para>
	</blockquote>
	</section>
	<section id="load_balancing_by_DNS" xreflabel="Load Balancing by DNS">
	<title>Load Balancing by DNS (round robin DNS)</title>
	<para>
Round robin DNS was one of the first attempts at loadbalancing servers.
Horms tried it in the late '90's but was defeated by the cacheing of
DNS information in local servers (you can set TTL=0, but quite sensibly, 
not all servers honour TTL=0).
	</para>
	<para>
Malcolm Turnbull <emphasis>malcolm (at) loadbalancer (dot) org</emphasis> 24 Jun 2004
	</para>
	<blockquote>
See the 
fud section on my site, under the GSLB bit
(http://www.loadbalancer.org/fud.html, link dead Feb 2005)
which goes to
<ulink url="http://www.tenereillo.com/GSLBPageOfShame.htm">
Why DNS Based Global Server Load Balancing (GSLB) Doesn't Work</ulink>
(http://www.tenereillo.com/GSLBPageOfShame.htm).
	</blockquote>
	<para>
The summary of the page is that most browsers (netscape, IE) have their own
DNS cache (15-30mins expiration). 
This, together with caching in local DNS servers,
will defeat any attempt to loadbalance or failover by DNS.
	</para>
	<para>
Torsten Schlabach <emphasis>tschlabach (at) gmx (dot) net</emphasis> 11 May 2007
	</para>
	<para>
Is it possible to have an LVS (or components of an LVS) at as of two data centers, for dedundancy?
	</para> 
	<para>
If we want to build a reliable service on the Internet (say a
website, for example) we can have one A record for www.oursite.net point
to one IP address only. So we would want that IP address to
transparently fail over between two data centers.
Of course we can put two (or more) servers into different data centers
but one IP will be routed to one physical destination, won't it?
So wouldn't it make sense for someone who owns a network infrastructure
to offer IPVS as a service and have the IP address point to whatever
real servers which I can configure?
	</para>
	<para>
Volker Jaenisch <emphasis>volker (dot) jaenisch (at) inqbus (dot) de</emphasis> 11 May 2007
	</para>
	<para>
One way to achieve this is to use the DNS.
If you give your domain e.g. yourdomain.com more than one IP e.g.
	</para>
<programlisting><![CDATA[
Datacenter1 : IP = 123.123.123.1
Datacenter2 : IP = 146.234.12.2
]]></programlisting>
	<para>
the DNS performes a round robin loadbalancing on DNS -&gt; IP resolving.
The first time a webbrowser accesses yourdomain.com it will get the first IP
and your customer lands in DC1. If the next webbrowser accesses
yourdomain.com
it will land in DC2. Next in DC1 and so on.
The only problem with this approach is to assure that the DNS TTL settings
are long enougth so that a typical costomer will not be switched from DC to DC
within its actual session.
	</para>
	<para>
A second and from my point of view the most important is the need for
synchronisation of
your data e.g. your databases and the filesystem over the WAN between the
DCs.
The databases you can share across the two locations using a sequoia
DB-Cluster for e.g. MySQL, PGSQL databases.
The filesystem mirroring can be done using DRBD0.8 and a cluster filesystem.
	</para>
	<para>
We have done some testing in that direction. This approach is due to the
synchronisation not ideal
for high traffic sites with many changes in the shared filesystem or the
shared DB-Cluster.
If you have a low/medium traffic site with extreme need for high
availability this scheme may help you.
	</para>
	<para>
But please be warned - this approach is definitivly not the cheap one. Such
a WAN distributed Cluster
is in the order of $100,000 and more.
	</para>
	<para>
Torsten Schlabach schrieb:
	</para>
	<para>
We have made some testing on how long webbrowsers will cache the DNS
information. It seems as that the DNS information
is hold longer in the webbroser than the given TTL. So this gives hope to
reduce the TTL to say 10 Seconds.
Now you will need a third instance that monitors your two DCs. If one of the
DCs went down the monitoring instance have to modify the DNS entry.
	</para>
	<blockquote>
Joe: I haven't looked for 10yrs or so, but back then DNS servers would not honour
a TTL less than some reasonably long time (a day?) so their cache would be
useful.
	</blockquote>
	<para>
Volker
	</para>
	<para>
Our two big ISPs in germany respect the TTL set by the
domain provider.
	</para>

<programlisting><![CDATA[
mira2:~# dig @195.50.140.250 inqbus.de


;; ANSWER SECTION:
inqbus.de.              300     IN      A       193.239.28.142

mira2:~# dig @195.50.140.250 inqbus.de

; <<>> DiG 9.2.4 <<>> @195.50.140.250 inqbus.de

;; ANSWER SECTION:
inqbus.de.              297     IN      A       193.239.28.142
]]></programlisting>
	<para>
As you see the TTL decreases on consequtive queries, as expected. The DNS
server queried is a DNS server of the second largest ISP in germany.
	</para>
	<blockquote>
Joe: I take it that the situation is different nowadays. What's the point of
having DNS servers if every query requires a hit to the root servers?
	</blockquote>
	</section>
	<section id="son_of_supersparrow">
	<title>BIND, BGP with load balancing (more ideas from Horms)</title>
	<para>
In a thread where someone suggested load balancing by round robin DNS...
	</para>
	<para>
<emphasis>jkreger (at) lwolenczak (dot) net</emphasis> Jun 24, 2004 
suggested that you get your routing information from 
BGP, which is fed a fake table.
	</para>
	<para>
Horms
	</para>
	<para>
I have some code to do this. 
Basically it creates a small routing daemon, that gets
all its data from a list of routes you provide at run time.
Its here
<ulink url="http://cvs.sourceforge.net/viewcvs.py/supersparrow/supersparrow/ssrs/">
here</ulink>
(http://cvs.sourceforge.net/viewcvs.py/supersparrow/supersparrow/ssrs/).
I also have 
<ulink url="http://cvs.sourceforge.net/viewcvs.py/vanessa/scratch/inet_map/">
some code to help generate the list of routes
from BGP dumps from (Cisco) routers</ulink>
(http://cvs.sourceforge.net/viewcvs.py/vanessa/scratch/inet_map/">)
and 
<ulink url="http://www.supersparrow.org/download/wip/bind9/">
a patch to Bind 9 to add supersparrow support</ulink>
(http://www.supersparrow.org/download/wip/bind9/).
	</para>
	<para>
All this needs a bit of polish, as appart from hacking on it
for my own personal use I haven't done any work on it for a while.
It does work - it is actually used for www.linuxvirtualserver.org
	</para>
	</section>
	<section id="commercial_geographically_distributed">
	<title>Commercial Geographically Distributed Servers</title>
	<para> 
How does a client in Ireland gets sent to a server in England,
while someone on the east coast of USA gets a server in NewYork?
The machine name is the same in both cases.
	</para>
	<para>
Malcolm <emphasis>lists (at) loadbalancer (dot) org</emphasis> 21 Nov 2006 
	</para>
	<para>
You either use:
	</para>
	<itemizedlist>
		<listitem>
Server side re-direct
		</listitem>
		<listitem>
DNS based geographic load balancing
		</listitem>
		<listitem>
BGP
		</listitem>
		<listitem>
Combination of BGP and Geographic DNS
		</listitem>
	</itemizedlist>
	<para>
UltraDNS.com do a managed service for this at about $400 per month per DNS entry,
which is one of the best ways of doing it.
	</para>
	<para>
Josh Marshall <emphasis>josh (at) worldhosting (dot) org</emphasis> 22 Nov 2006 
	</para>
	<para>
We use the supersparrow software (written by Horms) on our DNS servers 
and it works really well for
sites between our Australian and Holland datacenters. 
I don't have the co-operation of our uplinks so
I fake the BGP and with a few scripts it also handles failover to one site. 
My employer's site www.worldhosting.org is handled this way.
	</para>
	<para>
First you have to run a patched version of bind9 
(I have debian packages for anyone who needs them) -
get the source from http://www.supersparrow.org/
Or add the following to your /etc/apt/sources.list,
 for my supersparrow and patched bind9 packages
deb http://debian.worldhosting.org/supersparrow sarge main
(woody packages also available, replace sarge with woody)
	</para>
	<para>
Create in your bind config something like:
	</para>
<programlisting><![CDATA[
zone "www.worldhosting.org" {
       type master;
       database "ss --host 127.0.0.1 --route_server ssrs --password XXXX \
          --debug --peer 64600=210.18.215.100,64601=193.173.27.8 \
          --self 193.173.27.8 --port 7777 --result_count 1\
          --soa_host ns.worldhosting.org. --soa_email hostmaster.worldhosting.org.\
          --ns ns.worldhosting.org. --ns ns.au.worldhosting.org. --ttl 7 --ns_ttl 60"; \
};
]]></programlisting>
	<para>
This snippet sets the www to use 210.18.215.100 if the peer is set to 64600 
and 193.173.27.8 if the peer is 64601, 
the ttl for the A record is 60 seconds 
and the self is the default response for this nameserver 
(on the secondary nameserver make this the other address). 
Set the password to the same as in <filename>/etc/supersparrow.conf</filename>
	</para>
	<para>
Create three files to describe the routes in normal and failed modes. In our setup:
	</para>
<programlisting><![CDATA[
$ cat ssrs.routes.AUonly
0.0.0.0/0       64600

$ cat ssrs.routes.NLonly
0.0.0.0/0       64601

$ head ssrs.routes.normal
128.184.0.0/16  64600
128.250.0.0/16  64600
129.78.0.0/16   64600
129.94.0.0/16   64600
129.96.0.0/16   64600
129.127.0.0/16  64600
129.180.0.0/16  64600
130.56.0.0/16   64600
130.95.0.0/16   64600
130.102.0.0/16  64600
]]></programlisting>
	<para>
The <filename>ssrs.routes.normal</filename> file contains all the subnets 
you wish to force to use the respective peer.
	</para>
	<para>
Create a script that does a http test periodically 
(we do it every 5 minutes as the web servers don't go down frequently) 
if both sites work, symlink the file to <filename>/etc/ssrs.routes</filename>. 
If only one works, symlink the file for the site that works 
(<emphasis>i.e.</emphasis> AUonly or NLonly) to <filename>/etc/ssrs.routes</filename>. 
Then check to see if the config has changed and if so, restart supersparrow. 
I use the <filename>check_http</filename> script from the
nagios package to do the test. See below for my script:
	</para>

<programlisting><![CDATA[
----------------

#!/bin/sh

PATH=/sbin:$PATH
# Supersparrow results
SSNORMAL=0
SSAUONLY=1
SSNLONLY=2

AUIP=210.18.215.100
NLIP=193.173.27.8

AUW=0
NLW=0

#ping -c 2 $AUIP >/dev/null && AUP=1
#ping -c 2 $NLIP >/dev/null && NLP=1

/sbin/check_http -H $NLIP -u /index.html -p 80 -t 20 >/dev/null && NLW=1
/sbin/check_http -H $AUIP -u /index.html -p 80 -t 20 >/dev/null && AUW=1

# Do the tests again in case there was a hiccup

/sbin/check_http -H $NLIP
/sbin/check_http -H $AUIP -u /index.html -p 80 -t 20 >/dev/null && AUW=1


if [ $NLW -eq 1 ]
then
       if [ $AUW -eq 1 ]
       then
               OPMODE="Normal Operation"
               SPARROW=$SSNORMAL
       else
               OPMODE="NL running but AU down"
               SPARROW=$SSNLONLY
       fi
else
       if [ $AUW -eq 1 ]
       then
               OPMODE="AU running but NL down"
               SPARROW=$SSAUONLY
       else
               OPMODE="AU and NL down"
               SPARROW=$SSNORMAL
       fi
fi

if [ $SPARROW -eq $SSNORMAL ]
then
       ln -sf /var/named/supersparrow/ssrs.routes.normal /etc/ssrs.routes
fi

if [ $SPARROW -eq $SSAUONLY ]
then
       ln -sf /var/named/supersparrow/ssrs.routes.AUonly /etc/ssrs.routes
fi
if [ $SPARROW -eq $SSNLONLY ]
then
       ln -sf /var/named/supersparrow/ssrs.routes.NLonly /etc/ssrs.routes
fi

md5sum -c /etc/ssrs.routes.md5sum &>/dev/null && exit
/etc/init.d/supersparrow reload
md5sum /etc/ssrs.routes > /etc/ssrs.routes.md5sum
echo Supersparrow: $OPMODE

-------------
]]></programlisting>
	<para>
With a DNS server at each location, if there is a international routing problem 
that prohibits them communicating with each other, 
then the server will set all responses to point the www at the local hosting location. 
Then any sites on the net that can get to that DNS server will use the www that is there 
(and therefore, high chances of working)
	</para>
	<para>
Ratz 22 Nov 2006
	</para>
	<para>
If we are talking about web services, a nice but not very known and sometimes also not feasible
approach is the proxy.pac URL hash load balancing, best explained at:
http://naragw.sharp.co.jp/sps/ and
http://naragw.sharp.co.jp/sps/sps-e.html .
	</para>
	</section>
	<section id="geographically_distributed_from_the_mailing_list">
	<title>from the mailing list</title>
	<para>
David Carlson <emphasis>dcarlson (at) culminex (dot) com</emphasis> 11 Dec 2002
	</para>
	<blockquote>
	<para>
We are putting a bid in on a fairly major web site.
The client has asked for 24/7/365 reliability.
We were initially going to bid a Linux virtual server direct routing
solution with main and backup Linux directors in a multihomed data
centre.
We were proposing the following hardware:
	</para>
	<itemizedlist>
		<listitem>
Linux Director and Backup director to route the requests to Real servers
on the LAN
		</listitem>
		<listitem>
Real servers 1 and 2 to do the work and route data back to the user
		</listitem>
		<listitem>
DB server 1 to provide the data to the realservers.
		</listitem>
	</itemizedlist>
	<para>
However, our partner has come up with an interesting wrinkle. They have
a second data centre where they can host a mirror of our site. It uses a
different company for main internet service, so it is not only
geographically removed, but has different power and internet service
too.
	</para>
	<para>
We are now going back and revisiting out hardware configuration. It
would seem that with two physical locations, we should use IP tunneling.
http://www.linuxvirtualserver.org/VS-IPTunneling.html. In this case, our
hardware configuration would be
	</para>
	<itemizedlist>
		<listitem>
At Main location: Linux director, Real page server 1, DB Server 1
		</listitem>
		<listitem>
At alternate location: backup linux director, Real page server 2, DB server 2
		</listitem>
	</itemizedlist>
	<para>
We've never done this before. But if it works, it would sure increase
our claimed reliability as we can talk about multihomed, geographically
separate, entirely redundant systems.
	</para>
	<para>
My questions are - what do we do with the Linux Director at the main
site to have a failover solution.  If the internet service to the main
site fails, how does the alternate site know to take over receiving
requests? Given that it is elsewhere on the WAN, how does the backup
site update local routers with the virtual IP? Do we need a backup Linux
director at the alternate site? What about if the main site Internet is
OK but the Main Linux director fails. Will a backup director at the
alternate site take over and still send requests to realserver 1 at the
main site.
	</para>
	</blockquote>
	<para>
Horms:
	</para>
	<blockquote>
		<para>
It probably needs a bit of TLC but it is pretty simple so should work
without too much bother. I'd be quite happy to work with someone to make
this so. I'm using it myself on a very small (experimental) site wihtout
too much bother.  I also have a patch to make it work with bind9 that
I'm happy to send anyone who is interested.
		</para>

		<blockquote>
Peter Mueller <emphasis>pmueller (at) sidestep (dot) com</emphasis>:
The bind9 patch uses recursive-DNS to geo-locate users and send them to
specific locations?  (Is this what 3DNS does?)
		</blockquote>

		<para>
The bind9 patch, works in conjunction to return DNS results based
on the source IP address of the DNS request - i.e. the IP
address of the DNS server. So yes, it tries to return results
based on someonese network/geographic location.
I can't really comment on 3DNS as I have not used it, but I believe
that it does something similar.
		</para>
	</blockquote>

	<para>
Matthew S. Crocker <emphasis>matthew (at) crocker (dot) com</emphasis>
	</para>
	<blockquote>
	<para>
This is what Akamai does.  They use BGP table information to build a
network map and then announced DNS information based on the closest
server.  For example, I have 3 akamai servers in my network. When I use
DNS to lookup a.1234.akamai.net I get the IP address of my servers.  If I
go into some equipment on a different network the same name gives me
different IPs.  It is always the IP closest to me network wise.
	</para>
	<para>
Go to www.msnbc.com, view source and search for akamai.net.
You'll see the reference a799.g.akamai.net.
Traceroute to that name; from home it is 63.240.15.152, 12 hops away.
From work, it is one of my IP's and 2 hops away :). Pretty cool actually.
	</para>
	<para>
Using DNS to load-balance between clusters based on network BGP data.
Then have each cluster setup as a LVS HA cluster to load balance locally.
	</para>
	</blockquote>
	</section>
</section>
<section id="LVS-HOWTO.non-modified_realservers">
<title>LVS: Loadbalancing with unmodified realservers</title>
<note>
	<para>
The requirement to work with modified realservers is 
one of the differences between LVS and commercial realservers.
LVS requires the following modifications -
	</para>
	<itemizedlist>
		<listitem>
LVS-NAT: default gw has to point to DIP
		</listitem>
		<listitem>
LVS-DR: requires non-arp'ing VIP; default gw cannot be DIP (easy to do)
		</listitem>
		<listitem>
LVS-Tun: requires VIP (which can arp); IPIP decapsulation; default gw cannot be DIP (easy)
		</listitem>
	</itemizedlist>
</note>
<para>
In the commercial world, you initially have one server. 
Then later you want more reliability or throughput and decide
you need a loadbalancer in front of several copies of the server.
At this stage the configuration of the server is cast in stone
by the bureaucrats.
The only thing you're allowed to do
is make multiple copies of the server (all with the same IP)
and go find a loadbalance that will work with this setup.
Flexible bureaucrats will allow a different IP on the
different realservers, but this is the limit
(you aren't allowed to change the default gw).
Of course the people who set these requirements, 
have the money to make their wishes come true.
</para>
<para>
Alex Rousskov runs a Cacheoff 
<ulink url="http://www.web-polygraph.org/">PolyGraph</ulink>
(http://www.web-polygraph.org/)
which tests loadbalancers.
I wanted to enter an LVS director (he supplies the realservers). 
One of the requirements was that the realservers not be modified. 
This left us with LVS-NAT with a 2.0 or 2.2 kernel, which back then was a lot slower than LVS-DR.
I didn't enter.
</para>
<para>
This section discusses what (little) we know about commercial loadbalancers and 
what can be done to make LVS work with minimally modified realservers. 
</para>  
	<section id="F5_snat">
	<title>SNAT (was F5-SNAT)</title>
	<para>
Sep 2009
	</para>
	<para>
Hannes Eder, an intern at Google, 
has released patches to <filename>ipvs()</filename> and netfilter, 
to allow the LVS director to load balance, while outputting SNAT.
(It's not in the kernel yet and we don't know when it will be coming out.)
You want this if you need to duplicate a single server in a loadbalancing environment,
but for administrative reasons aren't allowed to reconfigure it, except to change the IP 
(<emphasis>e.g.</emphasis> you aren't allowed to change the default gw).
(see the older postings at the end of this section for other reasons people want this.) 
	</para>
	<para>
You will need
	</para>
	<itemizedlist>
		<listitem>
a <filename>ipvs</filename> kernel module with Hannes' patches 
(we don't know how you'll know this yet;
an entry in <filename>/proc</filename>, release notes...?)
		</listitem>
		<listitem>
the <filename>ipvs</filename> extension to <filename>iptables</filename>, 
which is in the <filename>libxt_ipvs</filename> 
user-space lib for netfilter matcher <filename>xt_ipvs</filename>
		</listitem>
	</itemizedlist>
	<para>
Here's how you use it. 
The client is connecting to VIP:8080 (192.168.100.30:8080),
the realservers are on 192.168.10.0/24, 
the src_addr for the SNAT'ed packets is 192.168.10.10:8080
(this can be anything on the inside of the director, 
presumably the DIP would be simplest to use).
	</para>
<programlisting><![CDATA[
% ipvsadm -A -t 192.168.100.30:8080 -s rr
% ipvsadm -a -t 192.168.100.30:8080 -r 192.168.10.20:8080 -m
# ...

# Source NAT for VIP 192.168.100.30:8080
# the vport, vaddr options require a patched iptables
% iptables -t nat -A POSTROUTING -m ipvs --vaddr 192.168.100.30/32 --vport 8080 \ 
	-j SNAT --to-source 192.168.10.10
]]></programlisting>
	<para>
Hannes Eder <emphasis>heder (at) google (dot) com</emphasis> 3 Sep 2009
	</para>
	<blockquote>
	<para>
It's similar to the F5-SNAT, although it does not do such nifty stuff as: "F5 will
also check the response of the real server and if it fails re-send the
commands from the cache to another server..." nice but definitely
layer7 proxy stuff.
	</para>
	<para>
The source IP (as seen by the realserver) will be what
you spec in the iptables "-j SNAT --to-source", 192.168.10.10 in this case.  
Netfilter NAT tries alter to alter the connection as little as possible, 
<emphasis>i.e.</emphasis> it tries to keep
the source port the same as the port from the client
(see <ulink url="http://www.netfilter.org/documentation/HOWTO/NAT-HOWTO-6.html#ss6.3">Netfilter section 6.3; saying how to mangle the packets; mapping in depth</ulink> 
http://www.netfilter.org/documentation/HOWTO/NAT-HOWTO-6.html#ss6.3 for more details.)  
	</para>
	<para>
You can remap the source port (and whatever netfilter SNAT allows you to do)
<emphasis>e.g.</emphasis>
<programlisting><![CDATA[
iptables -t nat -A POSTROUTING -p tcp -m ipvs --vaddr 192.168.100.30 \
--vport 8082 -j SNAT --to-source 192.168.10.10:1-1024
]]></programlisting>
taken more or less from:
<ulink url="http://www.netfilter.org/documentation/HOWTO/NAT-HOWTO-6.html#ss6.1">
Netfilter section 6.1, SNAT</ulink> 
(http://www.netfilter.org/documentation/HOWTO/NAT-HOWTO-6.html#ss6.1)
	</para>
	<para>
The code changes are
	</para>
	<itemizedlist>
		<listitem>
IPVS:
update the nf_conntrack tuple in reply direction, 
<emphasis>i.e.</emphasis> instead of VIP, 
set the source to RIP, 
as the reply packet will come from the realserver.  
Disclaimer: Some more work needs to be done here for the FTP protocol.
Remove the IPVS post-routing netfilter hook, 
to allow the packets to traverse further 
to the netfilter source NAT-ing hook (NF_IP_PRI_NAT_SRC).
		</listitem>
		<listitem>
Netfilter: A new netfilter matcher (xt_ipvs for kernel-space and libxt_ipvs for
user-space), which allows matching the IPVS properties of a packet,
such as VIP address, port, etc.
		</listitem>
	</itemizedlist>
	</blockquote>
	<para>
Here is the old material about SNAT in LVS.
	</para>
	<para>
This is musings from the mailing list about a type of functionality 
we don't have in LVS.
	</para>
	<para>
Paulo F. Andrade <emphasis>pfca (at) mega (dot) ist (dot) utl (dot) pt</emphasis> 11 Jul 2006 
	</para>
	<para>
What I want is the following:
	</para>
	<itemizedlist>
		<listitem>
for inbound connections I want packets with CIP->VIP translate to DIP->RIP
		</listitem>
		<listitem>
for outbound connections (the responses from the real servers) packets with RIP->DIP translate to
VIP->CIP
		</listitem>
	</itemizedlist>
	<para>
LVS-NAT only does DNAT, meaning CIP->VIP changes to CIP->RIP 
and the response from RIP->CIP to VIP->CIP.
The problem is that after LVS changes the VIP to RIP for inbound connections, 
it seems that packets don't traverse the POSTROUTING chain to get SNAT'ed.
Is there a workaround for this?
	</para>
	<para>
Graeme Fowler <emphasis>graeme (at) graemef (dot) net</emphasis>
	</para>
	<para>
Surely what you're asking for is a proxy rather than a director?
	</para>
	<para>
malcolm <emphasis>lists (at) netpbx (dot) org</emphasis> 13 Jul 2006 
	</para>
	<para>
I think this is what F5 calls SNAT mode (which confuses LVS people).
It's really nifty and flexible
and I don't see why it can't be done at layer 4 with LVS...
But LVS would need to be moved to the Forward chain rather than the INPUT one.
Pretty similar to LVS-NAT so not really a proxy (it's not looking at the packet contents)
I think it would be a massive improvement.. I'd even consider sponsoring someone to do it?
	</para>
	<para>
F5 will also check the response of the real server and if it fails 
re-send the commands from the cache to another server...
nice but definitely layer7 proxy stuff...
	</para>
	<para>
You want this because:
	</para>
	<itemizedlist>
		<listitem>
Doesn't require changes to the real servers. (not even the default gateway)
		</listitem>
		<listitem>
Works across subnets (and possibly WANs)
		</listitem>
	</itemizedlist>
	<para>
I think Kemp technologies have managed to do it with their LVS implementation...
I get a lot of customers who have their real servers so locked down they can't modify them at all.
	</para>
	<para>
Malcolm Turnbull <emphasis>malcolm (at) loadbalancer (dot) org</emphasis> 4 Dec 2008
	</para>
	<para>
It would be nice if you could do full SNAT in LVS and even better
transparent SNAT using tproxy (not sure if thats even possible at layer 4) (Joe: it isn't) .....
But thats a big ask for the developers...
However Haproxy will easily fit your current requirements, have you looked at that?
	</para>
	<para>
Joe - Here's an example of someone wanting to use F5-SNAT
	</para>
	<para>
Hoffman, Jon <emphasis>Jon (dot) Hoffman (at) acs-inc (dot) com</emphasis> 11 Oct 2006 
	</para>
	<blockquote>
		<para>
I have two networks that are physcally located in different locations 
(lets say city X and city Y).  
In city X we have our web servers, run by our team there.  
In city Y we have our load balancer that we are tring to set up as a
demo to show how LVS works.  
We can not set our default gateway of our web
servers to be the load balancer because we are trying to test LVS and can
not take our web servers out of production to test a new load balancer.  
And we want to see the load balancing working with our present servers.
What is happening is our client makes a request to our director, the
director sends the request to our web server and the web
server responses directly back to the client, who has no idea why that
server is sending the packet to it.
		</para>
		<para>
It does not make sense as to why I can
not masqurade the request to the real server.
For example:
To really strip things down, say I have the following
		</para>
<programlisting><![CDATA[
Client: 192.168.10.10
director:  192.168.10.250
realserver:  172.18.1.200, 172.18.1.201, 172.18.1.202
]]></programlisting>
		<para>
The client makes a request to the director, which then makes the
request to one of the realservers but (according to my tcpdump) the request
appears to come from the client (192.168.10.10), therefore the real server
tries to send the request directly back to the client.  Is there a way to
make the request to the realserver appear to come from the director, so the realserver
sends the request back to the director (without changing the default gw on the
realserver) rather than to the client?  It
just seems like there should be a way to do this.
		</para>
	</blockquote>
	<para>
Malcolm <emphasis>lists (at) loadbalancer (dot) org</emphasis> 11 Oct 2006
	</para>
	<para>   
Unfortunately the answer is no.
Packets can't be SNAT'd after being LVS'd.
In my limited understanding this is because LVS bypasses netfilter
after it has grabbed the packets from the INPUT chain
	</para>
	<para>
Joe - ip_vs would have to be in the FORWARD chain for this to work.
	</para>
	<para>
Nicklas Bondesson <emphasis>nicklas (dot) bondesson (at) mindping (dot) com</emphasis> 24 Feb 2007
	</para>
	<para>
The SNAT rule is not working without the NFCT patch -
this is why got my hands on the patch in the first place.
I have scenarios like this:
	</para>
<programlisting><![CDATA[
Request:
CLIENT -> VIP[with_public_ip_1] -> A_REAL_SERVER[private_ip_1]

Response:
A_REAL_SERVER[private_ip_1] -> VIP[with_public_ip_1] -> CLIENT

---

Request:
CLIENT -> VIP[with_public_ip_2] -> A_REAL_SERVER[private_ip_2]

Response:
A_REAL_SERVER[private_ip_2] -> VIP[with_public_ip_2] -> CLIENT
]]></programlisting>
	<para>
I'm not sure if i'm beeing clear here, but in simple words: the same public
ip address that the client uses to connect to the LVS should be used as
source ip in the response to the client.
I have multiple public ip addresses that i need to source nat.
The firewall is on the same box as the director.
Any pointers?
	</para>
	<para>
Julian 24 Feb 2007
	</para>
	<para>
	Aha, I see why you are using snat_reroute. But I want to
note the following things:
	</para>
	<itemizedlist>
		<listitem>
- you need to set snat_reroute only if you have ip rules with source
address where packets from VIP1 and VIP2 don't go to same nexthop.
If you have only one possible gateway then the kernel has already
attached this GW to the packet at routing time, so there is no need to
waste CPU to try to reroute it somewhere else by VIP if there is no 
other alternative gateway.
		</listitem>
		<listitem>
- you don't need iptables SNAT rules to SNAT traffic because 
netfilter will not reroute it. Netfilter simply does not bind to
nexthop for NAT connections. Also, you can not expect IPVS packets to 
reach netfilter in POST_ROUTING, the SNAT rule will not see them.
		</listitem>
	</itemizedlist>
	<para>
	ok, but what do you see, what is the real problem? Packets are
dropped and don't reach uplink router or they are not routed properly
when you have 2 or more uplinks? Do you have source-based IP rules?
	</para>
	<para>
Nicklas Bondesson <emphasis>nicklas (dot) bondesson (at) mindping (dot) com</emphasis>
	</para>
	<para>
I am still unable to SNAT traffic leaving the box. 
I'm runnng the director and firewall on the same box.
And this is how I do SNAT: 
	</para>
<programlisting><![CDATA[
iptables -t nat -A POSTROUTING -o eth0 -j SNAT --to-source 11.22.33.44
]]></programlisting>
	<para>
Janusz Krzysztofik <emphasis>jkrzyszt (at) tis (dot) icnet (dot) pl</emphasis> 23 Feb 2007 
	</para>
	<para>
Niklas, if you mean masquerading of LVS-DR client IPs on their way to real 
servers, you can try my approach described below.
	</para>
	<para>
When I tried Julian's patch several month ago (I am not sure if this have 
changed), I found it not suitable for use on a director that would also do 
masquerading (SNAT) of client IPs. I have learned that when Julian 
says "SNAT" he means processing of packets coming from an LVS-NAT driven real 
server (OUT direction) while forwarding them to clients. IN direction packets 
never pass through the netfilter nat POSTROUTING hook (and conntrack 
POSTROUTING as well), the are sent out directly by ip_vs_out() with optional 
ip_vs_conntrack_confirm().
	</para>
	<para>
Some time ago I have set up an LVS-DR based internet gateway that not only 
accepts connections from the internet to a VIP and redirects them to several 
RIPs (typical IPVS usage), but also rediects connections from intranet 
clients to the internet through serveral DSL/FrameRelay links, or their 
respective routers acting as real servers (similiar to LVS driven transparent 
cache cluster case). As I have no control over these routers (they are 
managed by their respective providers), I have to do masquerading (or SNAT) 
on the director itself to avoid putting several more boxes in between. In 
order to achieve this functionality, I have started with a "hardware" method 
of sending IN packets back to the director via several vlans set up over 2 
additional network interfaces connected with a crossover cable. Then I have 
created a small patch that affects processing of LVS-DR packets only (and 
bypass as well), so they are not caught by ip_vs_out() and just travel 
through all netfilter POSTROUTNG hooks, including nat and conntrack. This 
solution works for me as expected.
	</para>
	<para>
In my opinion, Julian's patch is particularily suitable for LVS-NAT, where any 
other approach would probably not work at all. Furthermore, it looks for me 
that Julian's way (or maybe any way) of connection tracking could be not 
applicable to LVS-TUN, where packets leaving the director are encapsulated 
before they reach ip_vs_out(). But for LVS-DR there are probably two good 
ways at least: Julian's, but without masquerading, and my own, that I have 
successfully used for several months now.
	</para>
	<para>
My patch applies cleanly against debian linux-source-2.6.18-3 version 2.6.18-7 
and is also available at 
http://www.icnet.pl/download/ip_vs_dr-conntrack.patch
	</para>
<programlisting><![CDATA[
Signed-off-by: Janusz Krzysztofik <jkrzyszt@tis.icnet.pl>
================================================
--- linux-source-2.6.17-2-e49_9.200610211740/net/ipv4/ipvs/ip_vs_core.c.orig    
2006-06-18 03:49:35.000000000 +0200
+++ linux-source-2.6.17-2-e49_9.200610211740/net/ipv4/ipvs/ip_vs_core.c 
2006-10-21 21:38:20.000000000 +0200
@@ -672,6 +672,9 @@ static int ip_vs_out_icmp(struct sk_buff
 	if (!cp)
 		return NF_ACCEPT;

+	if (IP_VS_FWD_METHOD(cp) == IP_VS_CONN_F_DROUTE)
+		return NF_ACCEPT;
+
 	verdict = NF_DROP;

 	if (IP_VS_FWD_METHOD(cp) != 0) {
@@ -801,6 +804,9 @@ ip_vs_out(unsigned int hooknum, struct s
 		return NF_ACCEPT;
 	}

+	if (IP_VS_FWD_METHOD(cp) == IP_VS_CONN_F_DROUTE)
+		return NF_ACCEPT;
+
 	IP_VS_DBG_PKT(11, pp, skb, 0, "Outgoing packet");

 	if (!ip_vs_make_skb_writable(pskb, ihl))
--- linux-source-2.6.17-2-e49_9.200610211740/net/ipv4/ipvs/ip_vs_xmit.c.orig    
2006-06-18 03:49:35.000000000 +0200
+++ linux-source-2.6.17-2-e49_9.200610211740/net/ipv4/ipvs/ip_vs_xmit.c 
2006-10-21 21:22:56.000000000 +0200
@@ -127,7 +127,6 @@ ip_vs_dst_reset(struct ip_vs_dest *dest)

 #define IP_VS_XMIT(skb, rt)                            \
 do {                                                   \
-	(skb)->ipvs_property = 1;                       \
 	(skb)->ip_summed = CHECKSUM_NONE;               \
 	NF_HOOK(PF_INET, NF_IP_LOCAL_OUT, (skb), NULL,  \
 		(rt)->u.dst.dev, dst_output);           \
@@ -278,6 +277,7 @@ ip_vs_nat_xmit(struct sk_buff *skb, stru
 	/* Another hack: avoid icmp_send in ip_fragment */
 	skb->local_df = 1;

+	skb->ipvs_property = 1;
 	IP_VS_XMIT(skb, rt);

 	LeaveFunction(10);
@@ -411,6 +411,7 @@ ip_vs_tunnel_xmit(struct sk_buff *skb, s
 	/* Another hack: avoid icmp_send in ip_fragment */
 	skb->local_df = 1;

+	skb->ipvs_property = 1;
 	IP_VS_XMIT(skb, rt);

 	LeaveFunction(10);
@@ -542,6 +543,7 @@ ip_vs_icmp_xmit(struct sk_buff *skb, str
 	/* Another hack: avoid icmp_send in ip_fragment */
 	skb->local_df = 1;

+	skb->ipvs_property = 1;
 	IP_VS_XMIT(skb, rt);

 	rc = NF_STOLEN;
]]></programlisting>
	</section>
	<section id="netscaler">
	<title>NetScaler</title>
	<para>
Bill Omer <emphasis>bill (dot) omer (at) gmail (dot) com</emphasis> 22 May 2007 
	</para>
	<para>
A NetScaler is a hardware load balancer, a commercial product.  
A NetFiler is a network attached storage device which can/does sit behind a NetScaler.
The client connects to the VIP.  
The director (a netscaler) then modifies the packet headers.    
The first packet is MASQ'd to the RIP, with src=CIP.   
The realserver then replies directly to the client, with src_addr=RIP.  
The client then replies directly to the real, 
which the netsaller assigned from the initial connection.
From what I understand, the NetScaler
modifies the packet headers and all connections avoid the director
after the initial packet is modified.
	</para>
	<para>
Philip M <emphasis>disordr (at) gmail (dot) com</emphasis> 22 May 2007 
	</para>
	<para>
The netscalers (a commercial load balancer from Citrix), 
is actually a pretty cool device. 
I like them, although lots of my colleagues don't. 
However, they are expensive, and for small remote offices where we
set up a few local services (LDAP/DNS/HTTP),  setting up a pair of
Netscalers is quite expensive. 
I therefore turned to LVS to see if it could be a practical replacement for the Netscalers. 
Turns out, that LVS does some pretty cool stuff, but not everything that the Netscalers do. 
Additionally, you need to run other packages, to take care of the things that came default
to the netscaler, such as director failover (I'm using heartbeat) and service monitoring/failover (I'm using ldirecord).
	</para>
	<para>
In my environment the default gateway for all of my Real Servers points not to the Load balancer, 
but rather to another router. 
This prevents and LVS-NAT from working in our environment.
So far as I can tell, there's no way to do LVS-NAT with your real-servers if
they do not point to the Load balancer as the default GW. 
This functionality works on the Netscalers because essentially, 
the Netscaler is proxying the connection. 
LVS-NAT does DNAT only. We require source and destination nat (proxying).
	</para>
	<para>
Main features of the Netscaler that we needed in a replacement are:
	</para>
	<itemizedlist>
		<listitem>
Direct routing form of SLB. (netscalers call this DSR, direct server
return).
		</listitem>
		<listitem>
concept of "backup vips". If all the local services (realservers) in an
office fail, we need the load balancer to fail over to a remote site.
As such, my co-worker and I, are using HA-proxy in addition to LVS, 
to handle the Failover mode in the ldirectord setup.
		</listitem>
		<listitem>
ability to properly route to a remote site
		</listitem>
	</itemizedlist>
	<para>
Well, we use lvs+heartbeat+ldirectord+haproxy to replace the netscalers in
our small remote offices. The failover VIP in our ldirectord/haproxy set up,
fails over to a remote netscaler VIP.
Our netscalers sit in a "1 armed" (one network) mode. 
They hang off the switch - only load balanced traffic goes through it.
	</para>
	</section>
	<section id="omer_redirect_with_masq">
	<title>Using MASQ with REDIRECT to accept packet on realserver to replace a NetScaler</title>
	<para>
Bill Omer <emphasis>bill (dot) omer (at) gmail (dot) com</emphasis> 22 May 2007 
	</para>
	<para>
The goal for my project was
to develop something in-house to replace the NetScalers.
In my configuration on an extremely large network, 
I'm using LVS-DR to load balance web and app servers.  
However the realservers do not have the VIP.
To get the realservers to accept packets for the VIP,
you need to follow the procedures outlined in 
<xref linkend="LVS-HOWTO.transparent_proxy"/>,
particularly <xref linkend="TP_2.4_problems"/>.
The loadbalanced service is listening on the RIP (not the VIP)
(note the nat table option).
I'm using a 2.4 kernel on the realservers.
	</para>
<programlisting><![CDATA[
realserver:# /sbin/iptables -t nat -A PREROUTING -d $VIP -p tcp --dport 0:65535  -j REDIRECT
realserver:# echo 1 > /proc/sys/net/ipv4/ip_forward
]]></programlisting>
	<para>
I've been using it to handle thousands of continuous connections with
many services (including telnet and ssh) without issue.
	</para>
	<para>
The only downside to using my LVS-DR solution vs. NetSalers right now
is the inability to add a real without *any* modifications what so
ever to the OS.  Granted, I have automated the process to be as
painless as possible to add a single iptables rule, but with a
NetScaler, you don't have to do anything.  At all.  No tun interface,
no routing through the director, nothing at all.
This is the only remaining downside to using LVS in my organization.
	</para>
	</section>
	<section id="philip_m_backup_server">
	<title>Using HAProxy with LVS to substitute for the remote server failover of a NetScaler</title>
	<para>
Philip M <emphasis>disordr (at) gmail (dot) com</emphasis> 22 May 2007
	</para>
	<para>
The main deficiency in LVS is that it can't forward to another (remote) server
when the realservers fail. 
We handled that with HAProxy. Our setup is
	</para>
	<itemizedlist>
		<listitem>
2 Directors
		</listitem>
		<listitem>
2 Real servers
		</listitem>
		<listitem>
1 remote backup site
		</listitem>
	</itemizedlist>
	<para>
We do LVS-DR for local services. We have the VIP IP configured on the
Directors as well as dummy interfaces on the real servers.
If both real-servers fail, in the ldirectord configs we have a "failover IP" set. 
This failover IP is another (LocalNode) IP on the director.
The LocalNode IP, is being listened to by the HA-Proxy userspace daemon,
which proxies the request to the remote server (Netscaler backup listening on the VIP).
The director is the default gw for the remote machine;
the reply comes back to HAProxy which returns the packet to the CIP.
	</para>
	<para>
Its complicated, but it works, except that HAproxy doesn't do UDP. :(   now
we're going to investigate dnsproxy. ugh...
	</para>
	</section>
</section>
<section id="LVS-HOWTO.virtualised_realservers">
<title>LVS: Virtualised Hosts in a Linux Virtual Server</title>
	<section id="intro_virtualised_realservers">
	<title>Introduction</title>
	<para>
(Jul 2007)
This is an amalgamation of posts by 
Gerry Reno <emphasis>greno (at) verizon (dot) net</emphasis>,
Rio <emphasis>rio (at) forestoflives (dot) com</emphasis>
and Volker Jaenisch <emphasis>volker (dot) jaenisch (at) inqbus (dot) de</emphasis>
starting with this posting
<ulink url="http://lists.graemef.net/pipermail/lvs-users/2007-June/019329.html">LVS and OpenVZ</ulink>
(http://lists.graemef.net/pipermail/lvs-users/2007-June/019329.html).
	</para>
	<para>
"realserver" is an LVS term referring to the nodes being loadbalanced by the director.
Until now, each realserver has been a separate piece of hardware.
But now with virualisation, it's possible for a realserver to be 
a virtual server (or one of many realservers) running inside a bigger piece of hardware
(<emphasis>e.g.</emphasis> a 4 core machine with 16GByte RAM and 4 NICs).
	</para>
	<para>
I've never liked the LVS nomenclature; e.g. "virtual", 
"realserver", but since I couldn't come up with an 
alternative and no-one else seemed to mind, I've just 
accepted it. We haven't had too much problems with the word 
"virtual" since LVS hasn't been loadbalancing anything virtual. 
However if realservers are going to be virtualised, 
there's going to be lots of name space collisions.
	</para>
	<para>
The first virtualisation enviroment was VMWare, 
which ran guest OS's (Windows, Linux, MacOS), 
with each guest appearing to be running on a separate machine.
Now as well there is Xen, QEMU, Linux-VServer and OpenVZ.
	</para>
	<para>
There are two types of virtualised machines, 
each of which appear to be separate machines to the user and to the outside network. 
(I hope I have the nomenclature right here).
For a more thorough review of the properties of the various virtualisers see
<ulink url="http://en.wikipedia.org/wiki/Comparison_of_virtual_machines">
Comparison of virtual machines</ulink>.
	</para>
	<itemizedlist>
		<listitem>
			<para>
<emphasis role="bold">VM</emphasis> (virtual machine): each VM has it's own kernel. 
This is a relatively heaviweight setup and uses more resources on the host.
Processes can run amok in a VM without much likelihood of causing problems to other VMs.
			</para>
			<para>
examples: VMWare, XEN, QEMU
			</para>
		</listitem>
		<listitem>
			<para>
<emphasis role="bold">VE</emphasis> (virtual environment): 
each VE is a supercharged Linux chroot environment. 
There is only one kernel running on the node, shared by all the VEs. 
An errant process is more likely to cause problems to another VE 
than in the VM situation, but it's still an unlikely possibility.
VE hosts are just huge schedulers for the apps that run inside 
the VE's. There is very little wasted resources. You can get many many 
more VE's on a host that you can VM's.
The VE solution is trailing behind VM solution for now, 
but as soon as the VE support framework lands in the kernels, 
then things will change. 
			</para>
			<para>
Here's a description from the Linux-VServer webpage
			</para>
			<blockquote>
				<para>
The Linux-VServer technology is a soft partitioning concept based on Security 
Contexts which permits the creation of many independent Virtual Private 
Servers (VPS) that run simultaneously on a single physical server at full 
speed, efficiently sharing hardware resources.
				</para>
				<para>
A VPS provides an almost identical operating environment as a conventional 
Linux server. All services, such as ssh, mail, web and database servers can 
be started on such a VPS, without (or in special cases with only minimal) 
modification, just like on any real server.
				</para>
				<para>
Each VPS has its own user account database and root password and is isolated 
from other virtual servers, except for the fact that they share the same 
hardware resources."
				</para>
			</blockquote>
			<para>
examples: OpenVZ, Linux-VServer.
			</para>
		</listitem>
	</itemizedlist>
	<para>
Each virtual machine has access to all the hardware resources on a machine
(unless restricted by ulimit), 
so if the other virtual machines are idle, 
a busy virtual machine will be given all the CPUs.
Each virtual machine will have its own virtaul NIC(s).
	</para>
	<para>
The reason for moving to virtual machines is cost.
Gerry replaced 3 racks of nodes with 1/3 rack of a larger server.
Virtual server-clusters speeds up time-to-production for the real server-clusters
by an order of magnitude,
early enough to steer the project in the right direction, 
before the customer has invested in expensive hardware.
You can predict the number of realservers needed to reach a 
performance goal.
It is more expensive to run 84 pieces of hardware in multiple racks. 
Electricity costs, physical storage space 
costs, hardware costs, environmental conditioning costs, etc. 
It is cheaper to run a few hosts running virtuals than to run real hardware. 
	</para>
	<para>
Here's a description of one VE setup:
	</para>
	<blockquote>
		<para>
because one web server handling all these websites is a literal mess in 
organization. one company has their own virtual server because we host 36 
websites for them and we wanted to stick them all together... we 
place 'dangerous' type web admins in separated servers so if they mess it up 
it doesnt affect the rest of them. a single server would affect them all. 
other customers, due to one reason or another have their own virtual server 
and they host a number of their own sites. we have one web server for 
our 'generically safe' customers which hosts 400 domains and is namespace 
only so we do glob domains together when it is safe otherwise we protect all 
our customers from the unsafe ones, or if they have a number of sites, we 
place them in one server. another reason for making it by customer when they 
host a number of their own sites is ease of shutting them off if they dont 
pay. i simply do vserver $servername stop and thats all there is to it. i 
dont have to hunt individual sites and disable each one.
		</para>
		<para>
another reason for using a number of VE as everyone is calling it is if i 
decide i want to move a service to a different machine, i simply move the 
entire virtual server over and start it on the new machine and it is done. no 
playing with o/s configs or anything. the only thing that gets involved is 
machine architecture change such as moving a virtual from an amd64 to an 
intel processor i686 machine but since we no longer have that issue to worry 
about it is simple.
		</para>
		<para>
each VE has its own primary ip like any hardware box would. i can also assign 
multiple ips to virtuals as needed.
		</para>
		<para>
unless i specifically tell a VE to use only 1 or 2 processors, they all have 
use of all 4 as the host machine's kernel decides is best. since there is 
only the kernel on the host, it decides how the cpus are used by the virtuals 
unless like i said i specifically configure cpu usage/limits etc per virtual, 
which i have not had a need to do yet. if i should decide to adjust cpu usage 
on a particular virtual, i only have to do it on that one, i don't need to 
compensate with cpu configuration on all the others.
		</para>
		<para>
on ours, they simply multihonme the nic. eg.. eth0 primary addr is host, 
eth0:0 is virtual_1 eth0:2 is virtual_2 etc...
to the virtual machine it appears to be its own nic even though the 
virtual server has no networking code to mess with a nic.
		</para>
	</blockquote>
	<para>
One problem is the setup of the virtual network. 
You should be familiar with linux-bridges (act like switches) and ip-routing. 
If firewalling is included things become complex.
	</para>
	<para>
In some virtual machines you can live migrate a virtual machine.
	</para>
	<itemizedlist>
		<listitem>
live migration: OpenVZ 
		</listitem>
		<listitem>
no live migration: Linux-VServer 
		</listitem>
	</itemizedlist>
	<para>
Ben Hollingsworth <emphasis>ben (dot) hollingsworth (at) bryanlgh (dot) org</emphasis> 29 Jun 2007
	</para>
	<para>
I had trouble finding anything for RHEL4, so a few months ago, I started
writing my own instructions, which you can view at:
http://www.jedi.com/obiwan/technology/ultramonkey-rhel4.html
Alas, I got sidetracked before I finished the setup, so this document is
incomplete.  I'm back at it now (hence my presence on the list again),
so if anybody more familiar with the project wants to tell me what I've
overlooked, I'm all ears.
	</para>
	</section>
	<section id="vwmare">
	<title>Virtualised Realsevers: VMWare/Xen</title>
	<para>
People are using VWWare to run multiple realservers inside a large machine.
This can be cheaper than running the same number of realservers.
However be aware that you need a machine with enough resources to
handle all the VMWare realservers.
	</para>	
	<para>
Paolo Penzo <emphasis>paolo (dot) penzo (at) bancatoscana (dot) it</emphasis> 01 Jun 2007
	</para>
	<para>
Do not use vmware  guests as LVS directors: as soon as free bandwidth 
goes down, the directors start to failover due to missing sync packages. 
I was running this setup at the very beginning, but then I moved the 
directors to physical servers.
Vmware can be fine for realservers until the vmware itself is not 
overloaded, in such case realservers will go in and out of the LVS 
cluster due to check mechanism.
	</para>
	<para>
Stuart walmsley <emphasis>stuart (at) vio (dot) com</emphasis> 01 Jun 2007
	</para>
	<para>
I am running a LVS pair using keepalived with just over 20 mixed windows /
Linux hosts in 10 clusters all running over 3 VM ESX servers.
Each server has 16 cores, 64 Gig of memory and multiple bonded Gig NIC's
with all the OS's living on a shared 4Gig SAN fabric.
It performs very well and has meet all requirements in terms of both
performance and Availability and offers great flexibility.
As is always the case with VM ware you must ensure you have enough I/O and
memory to meet the needs of all the virtual hosts or overall performance
will be miserable.
	</para>
	<para>
Sebastian Vieira <emphasis>sebvieira (at) gmail (dot) com</emphasis>, 1 Jun 2007 
	</para>
	<para>
Yes, i can imagine that with such hardware, hosting 20 machines is a piece
of cake. Still, the possibility of one guest pulling all resources to
itself, exists. And ESX doesn't have a quota/limit feature to deal with
these problems, which is why i can't recommend putting LVS on VMware.
The bonded NICs help :)
	</para>
	<para>
Stuart walmsley 
	</para>
	<para>
VM actually enables very granular resource allocation both at the server
instance level and resource group level allow the grouping of sets of
application servers.
The cost of the hardware is lower that 10 individual servers and still has
expansion capability so is a very cost effective route.
LVS was a critical piece of the puzzle when looking at how to halt my server
sprawl and enable a virtualization strategy.
	</para>
	<para>
Gary W. Smith <emphasis>gary (at) primeexalia (dot) com</emphasis> 1 Jun 2007 
	</para>
	<para>
We also run several of instances in VMWare as well. We have separate
disks for the OS and the guests, which helps with the disk bottleneck.
As for the performance, our VM's are limited to single CPU's so the host
general has plenty of CPU time to do its work.
We've been running this configuration for some time now (two years?,
don't remember when the first one was put up but I do remember we were
using Linux-HA 1.0).  Anyway, we really haven't had any problems at all.
OTOH, we have had problems with Xen clustering, which other people have
claimed works better.  But in our case I think it's the underlying
distro.
	</para>
	<para>
Alexander Osorio <emphasis>maosorionet (at) gmail (dot) com</emphasis> 2 Jun 2007 
	</para>
	<para>
I have a machine with 2 dual core processors, for Linux i
have 4 processors, and running only one realserver in the machine is
wasting the other processors.
So, i'm looking for a way to run in the same PC, for example, 4
process (one per processor)
but i can have only one ip:port for the clients, the clients are POS
wireless terminals that connect to one ip:port, and i need to do load
balancing between the connections.
	</para>
	<para>
Graeme Fowler <emphasis>graeme (at) graemef (dot) net</emphasis> 03 Jun 2007
	</para>
	<para>
Run a Xen host. Have several Xen guests - one for the director, and two
for the realservers. That way, although it's all virtual, it'll look
real to the guests.
	</para>
	<para>
Horms 5 Jun 2007 
	</para>
	<para>
You can tag a process to a processor with the (newish) cpusets feature.
Though I think in this case that would be somewhat silly.
	</para>
	<para>
If you want to use LVS for this, wouldn't an easy way be
to bind the processes to 127.0.0.1 and 127.0.0.2 respectively
and set them up as the real-servers in LVS.
	</para>
	<para>
That said, using fork-on-connect or preforking in the user-space
application, and making sure you have at least as many processes as
processors, is likely to be an easier and better way to go.
	</para>
	</section>
	<section id="lvs_in_a_box">
	<title>Running a test LVS (director, backup director and realservers) on one box (UML, VMWare)</title>
	<blockquote>
Can I load both the ipvs code and the failover code
in a single stand alone machine?
	</blockquote>
	<para>
Joe 09 Jul 2001
	</para>
	<para>
VMWare?
	</para>
	<para>
Henrik Nordstrom <emphasis>hno (at) marasystems (dot) com</emphasis>
	</para>
	<para>
<ulink url="http://user-mode-linux.sourceforge.net/">user-mode-linux</ulink>
works beautifully for simulating a network of Linux
boxes on a single CPU. Use it extensively when hacking on netfilter/iptables,
or when testing our patches on new kernels and/or ipvs versions.
Also has the added benefit that you can run the kernel under full
control of gdb, which greatly simplifies tracking kernel bugs down if you get
down to kernel hacking.
	</para>
	<para>
Joe
	</para>
	<para>
I attended a talk by the UML author at OLS 2001. It's pretty smart
software. You can have virtual CPUs, NICs... - you can have a virtual 64-way
SMP machine running on your 75MHz pentium I.
The performance will be terrible, but you can at least test your application on it.
	</para>
	</section>
	<section id="vwmare_ntp">
	<title>VMWare problems with ntp</title>
	<para>
Apparently linux running under VMWare doesn't keep time.
	</para>
	<para>
Todd Lyons <emphasis>tlyons (at) ivenue (dot) com</emphasis> 16 Nov 2005 
	</para>
	<para>
ntp under vmware causes major problems.  The longer it runs, the more it
"compensates" for things.  It jumps back and forth, further and further
each time, until after a few days, it is jumping back and forth *hours*,
wreaking all kind of havoc on a linux system that's using nfs or samba.
I've seen a vmware system that exhibited this with both RedHat and
Gentoo.  The original poster is correct to be using ntpdate instead of
ntp daemon.  It's the only way to keep the time reasonably close.
Personally, I'd tell him to do it more often, such as:
	</para>
<programlisting><![CDATA[
  * * * * * /usr/sbin/ntpdate time.server.com >/dev/null 2>&1
]]></programlisting>
	<para>
substitute your own internal time server for "time.server.com".
	</para>
	<para>
Sebastiaan Veldhuisen <emphasis>seppo (at) omaclan (dot) nl</emphasis> 16 Nov 2005 
	</para>
	<para>
This has nothing to do with LVS and/ or heartbeat. I guess you are 
running a Linux guest within a Linux host vmware server (or ESX)? If so, 
there are known problems with clock fluctiations in guests VM's.
We run our Development servers on VMWare ESX and GSX and had large clock 
fluctuations. The VMWare TID's weren't directly much helpfull in solving 
the problem.
	</para>
	<para>
How we fixed it:
	</para>
	<itemizedlist>
		<listitem>
- vmware-linux-tools are not helpfull in solving this problem. You don't 
need them to fix the time issue
		</listitem>
		<listitem>
- On the  VMWare Server management console webinterface, go to Options , 
Advanced Settings, and search for the option  Misc.TimerHardPeriod. 
Default value is 1000 , adjust it to 333.
		</listitem>
	</itemizedlist>
	<para>
On the linux  guest machine:
	</para>
	<itemizedlist>
		<listitem>
-For Grub edit: /boot/grub/menu.lst  add "clock=pmtmr" to add the end of 
your current kernel and reboot.
		</listitem>
		<listitem>
-For Lilo edit: /etc/lilo.conf and add to the append rule of your 
current kernel "clock=pmtmr". Run lilo and reboot.
		</listitem>
	</itemizedlist>
	<para>
-This should fix your problem (run ntpd on both host and guest OS, no 
vmware-tools)
	</para>
	<para>
More info on this issue (not appropriate fix though):
	</para>
<programlisting><![CDATA[
http://www.vmware.com/support/kb/enduser/stdadp.php?pfaqid=1339
http://www.vmware.com/support/kb/enduser/stdadp.php?pfaqid=1420  
https://www.vmware.com/community/thread.jspa?forumID21&threadID13498&messageID=138110#138110 
https://www.vmware.com/community/thread.jspa?forumID21&threadID16921&messageID=185408#185408  
http://www.vmware.com/support/kb/enduser/stdadp.php?pfaqid=1518
]]></programlisting>
	<para>
Bunpot Thanaboonsombut <emphasis>bunpotth (at) gmail (dot) com</emphasis> 18 Nov 2005 
	</para>
	<para>
VMware KB is erroneous.  
Add "clock = pit" in the same line of "kernel" in grub.conf like this
	</para>
<programlisting><![CDATA[
kernel /vmlinuz-2.6.9-22.EL ro root=/LABEL=/ rhgb quiet clock=pit
]]></programlisting>
	<para>
Kit Gerrits <emphasis>kitgerrits (at) gmail (dot) com</emphasis> 22 Dec 2008
	</para>
	<para>
It -IS- possible to keep several hosts in sync time-wise in VMware, even on
a simple laptop.
I am currently running an LVS cluster and 2 webservers on my laptop with
VMWare Server 1.0.7 and 1GB RAM.
There have been no spontaneous cluster failovers (yet) today.
	</para>
	<itemizedlist>
		<listitem>
For GSX / VMware Server:
Pass the following options to the kernel via <filename>grub.conf</filename>:
<programlisting><![CDATA[
clock=pit nosmp noapic nolapic
]]></programlisting>
		</listitem>
		<listitem>
For RHEL5/CentOS5, you should use the following:
<programlisting><![CDATA[
clocksource=pit nosmp noapic nolapic
]]></programlisting>
		</listitem>
	</itemizedlist>
	<para>
Because this will disable all of Linux' intelligent clock tricks, you'll
need to run NTPd to keep your clock in sync.
More info at:
http://kb.vmware.com/selfservice/microsites/search.do?language=en_US&amp;cmd=displayKC&amp;externalId=1420
	</para>
	<para>
For ESX servers,  the solution is 'simpler':
You need to lower the minimum time between clok requests:
	</para>
<programlisting><![CDATA[
Configuration --> Software --> Advanced Settings --> Misc --> Misc.TimerMinHardPeriod
]]></programlisting>
	<para>
Lower this value (it is in microseconds)
More info at:
http://kb.vmware.com/selfservice/microsites/search.do?language=en_US&amp;cmd=displayKC&amp;externalId=2219
	</para>
	</section>
	<section id="tcp_checksum_bug">
	<title>Xen tcpip checksum bug</title>
	<note>
the fix is at the end of the posting.
	</note>
	<para>
Matthias Saou <emphasis>thias (at) spam.spam.spam.spam.spam.spam.spam.egg.and.spam.freshrpms.net</emphasis> 7 Aug 2007 
	</para>
	<para>
I'm setting up various Xen guests, and want to use LVS to load-balance
web traffic across them. I've tried two similar simple setups, and with
both I see the same issue where LVS doesn't work properly when the
director send the request to a real server on the same physical Xen
host.
	</para>
	<para>
Scenario 1 :
	</para>
	<itemizedlist>
		<listitem>
- 3 physical servers (Xen Hosts) with eth0 and eth1
		</listitem>
		<listitem>
- 3 web servers (Xen guests), one per host, listening only on eth1
		</listitem>
		<listitem>
- LVS NAT is configured using keepalived on the first Xen Host
		</listitem>
	</itemizedlist>
	<para>
When I make a web request to the LVS director, it works fine when it
sends it to the 2nd or 3rd web servers, but only gets about the first
12kb of the page when it sends it to the 1st web server (the only one
on the same Xen Host as LVS). For pages smaller than 12kb, no problem.
	</para>
	<para>
Scenario 2 :
	</para>
	<itemizedlist>
		<listitem>
- 3 physical servers (Xen Hosts) with eth0 and eth1
		</listitem>
		<listitem>
- 3 web servers (Xen guests), one per host, listening only on eth1
		</listitem>
		<listitem>
- 1 LVS director (Xen guest), on the first Xen Host, eth0 and eth1
		</listitem>
	</itemizedlist>
	<para>
The exact same problem happens.
Here are a few more details :
	</para>
	<itemizedlist>
		<listitem>
- RHEL5 x86_64 with latest 2.6.18-8.1.8.el5xen kernel
		</listitem>
		<listitem>
- keepalived package from Fedora recompiled for RHEL5
		</listitem>
		<listitem>
- net.ipv4.ip_forward = 1 on the LVS director
		</listitem>
		<listitem>
- -A POSTROUTING -s 192.168.0.0/255.255.0.0 -o eth0 -j MASQUERADE
		</listitem>
	</itemizedlist>
	<para>
If I remove the "local" web server from the keepalive/LVS
configuration, it works fine, since it only sends to the real servers
on the other physical servers, but that would mean not using the first
physical server's CPU power and memory, which I don't want to be
wasting.
	</para>
	<para>
I'm pretty sure this has something to do with connection tracking
and/or the bridges Xen configures, but I don't know what to try to fix
the issue.
	</para>
	<blockquote>
what happens if you have the director(s) on a separate host, 
<emphasis>i.e.</emphasis> not the Xen host?
	</blockquote>
	<para>
Then it works. I tried to keep it short in my initial email, but maybe
I've kept it too short. There is no problem when the director has no
real server on the same Xen host (physical machine). And it's not a web
server issue, as all Xen guests are perfect clones of each other.
For the record, the final setup I wanted was like this :
	</para>
<programlisting><![CDATA[
                   Internet
                      |
    +---------+---------+---------+---------+  Public LAN
    |         |         x         x         x
    |         |
  Xen1      Xen2      Xen3      Xen4      Xen5
  Web1+LVS1 Web2+LVS2 Web3      Web4      Web5
    |         |         |         |         |
    +---------+---------+---------+---------+  Private LAN
]]></programlisting>
	<para>
With Xen1 and Xen2 running two keepalived instances with VRRP for
redundancy and LVS+NAT for web load-balancing and failover, through the
Private LAN.
	</para>
	<para>
This setup works, expect for the issue I've outlined :
	</para>
<programlisting><![CDATA[
- When LVS1 is active, requests to Web1 have issues
- When LVS2 is active, requests to Web2 have issues
]]></programlisting>
	<para>
I'm pretty sure it's some obscure(-ish) Linux bridge or connection
tracking problem. In this particular setup, it's not that much of an
issue (5 real servers, only 4 used at a given time), so what I did was
exclude Web1 from LVS1's configuration and Web2 from LVS2's. But I'm
now setting up a similar configuration with only 3 physical servers, so
excluding one means 1/3rd less "horse power" for the cluster, which is
quite a waste.
	</para>
	<para>
I'm quite surprised no one has run into this before. Has anyone here
already set up LVS with Xen in some similar way and have it work?
	</para>
	<para>
I've continued searching, and I've found this post on the xen-users
list reporting a similar problem :
http://lists.xensource.com/archives/html/xen-users/2006-11/msg00480.html
As Xen gains popularity, I guess we'll be more and more facing this
issue. I'll continue digging to try and find a solution.
	</para>
	<para>
I'm still convinced it has something to do with connection tracking and
bridges, but I still haven't been able to debug it.
	</para>
	<para>
Basically packets go like this when the issue is seen :
	</para>
<programlisting><![CDATA[
- dom0 peth0 ->
- dom0 xenbr0 ->
- dom0 vif7.0 ->
- domUa eth0 -> This is where LVS is running
- domUa eth1 ->
- dom0 vif7.1 ->
- dom0 xenbr1 ->
- dom0 vif10.1 ->
- domUb eth1 -> This is where the web server answers
- dom0 vif10.1 ->
- dom0 xenbr1 ->
- dom0 vif7.1 ->
- domUa eth1 -> This is where SNAT/MASQUERADE occurs
- domUa eth0 ->
- dom0 vif7.0 ->
- dom0 xenbr0 ->
- dom0 peth0 -> Back to the Internet

dom0 : Xen Host
domUa : Xen guest running LVS+NAT using dom0's vif7.0 and vif7.1
domUb : Xen guest running a web server using dom0's vif10.1 only
]]></programlisting>
	<para>
There is nothing "fancy" in my setup, meaning that I've only configured
the minimum possible iptables rules to get things working, and it
actually works but only sends back partial files to the client. With a
test php script doing a phpinfo() I always got around 12kB, but I since
tried with a simple static file from which I always get exactly 16384
Bytes, while the file itself is a few hundred Bytes long. I'm pretty
sure that value of 16384 Bytes isn't a coincidence...
	</para>
	<para>
When domUa queries a real server on a different physical machine, the
main difference is that instead of going through xenbr1, from vif7.1 to
vif10.1, it goes to peth1 and off to the other Xen Host's NIC. But it
actually "stays inside xenbr1" too, which is why I'm confused.
	</para>
	<para>
Graeme Fowler <emphasis>graeme (at) graemef (dot) net</emphasis>
	</para>
	<blockquote>
		<para>
Humo(u)r me. If the following isn't set to 0 already, try it:
		</para>
<programlisting><![CDATA[
echo 0 > /proc/sys/net/ipv4/tcp_sack
]]></programlisting>
		<para>
It's possible that you're hitting a bug which was fixed in 2.6.12... you
shouldn't have it in 2.6.18, but anything is possible. Especially
regressions.
		</para>
		<para>
For more details around this, see
https://lists.netfilter.org/pipermail/netfilter/2005-June/061101.html
and
http://linuxgazette.net/116/tag/6.html
		</para>
	</blockquote>
	<para>
The symptoms are very similar indeed. I just tried, but it didn't help.
Thanks a lot for the suggestion, though.
Does anyone know how I could try and track down the TCP connection
problem? I.e. know if it's the Xen host, the LVS director Xen guest or
the web server Xen guest which is "getting something wrong"?
I'm been doing a lot of basic tcpdumps, and only see that at some
point, clients are still receiving data from the LVS address, to the
same port even, but no longer consider it as the followup to the
previously received data.
	</para>
	<para>
later...
	</para>
	<para>
Daniel P. Berrange (who hacks extensively on Xen over at Red Hat)
suggested it might be a TCP checksum offload issue... and it was!
The solution is simply to use <command>ethtool -K ethX tx off</command> 
on all relevant
interfaces, and it all starts working as expected.
	</para>
	<blockquote>
Joe: turning off checksums could cause other problems. I hope there's
a better solution somewhere.
	</blockquote>
	</section>
	<section id="xen_nat">
	<title>Random observations thrashing around trying to get Xen/LVS-NAT working</title>
	<para>
Josh Mullis <emphasis>josh (at) mullis (at) cox (dot) com</emphasis> 17 Sep 2008 
	</para>
	<blockquote>
		<para>
The traffic still gets to the vm, but just can't seem to make it back
out through the NAT. Here's my setup
		</para>
<programlisting><![CDATA[
 - 1 physical server running as Xen Dom0 (Director)
         -LAN ip: 10.0.0.80
         -NAT ip: 192.168.122.1
                 -Natting is setup thorugh default xen network scripts
 
         -ipvsadm -A -t 10.0.0.80:53 -s rr
         -ipvsadm -a -t 10.0.0.80:53 -r 192.168.122.10:53 -m
         -ipvsadm -A -u 10.0.0.80:53 -s rr
         -ipvsadm -a -u 10.0.0.80:53 -r 192.168.122.10:53 -m
 
 
 - 1 domU (realserver) on this box (Will add others in the future)
         -ip: 192.168.122.10
         -gw: 192.168.122.1
         -running BIND
]]></programlisting>
		<para>
From a host on the 10.0.0.0 network, 
I can do a dig @10.0.0.80 and do not get a response.
I do however see the traffic on the 192.168.122.10 virtual machine 
from this host on the 10.0.0.0.
		</para>
	</blockquote>
	<para>
ipvsuser <emphasis>ipvsuser (at) itsbeen (dot) sent (dot) com</emphasis>
	</para>
	<para>
This may not be helpful, but I run a bunch of stuff on vanilla domUs
F8 and never have had any trouble
	</para>
	<itemizedlist>
		<listitem>
I don't mess with the default bridge or networking set up by Xen/libvirt
		</listitem>
		<listitem>
I use DR, not NAT
		</listitem>
		<listitem>
I use a domU for the director as well as the real servers
		</listitem>
		<listitem>
I use keepalived because the only thing the director is "HA"ing is the VIPs, 
so HA/ldirector seems like overkill in this case. Put the backup director on a 
separate dom0.
		</listitem>
		<listitem>
I have domU real servers on the same dom0 as the director and on other dom0s 
and I haven't seen any problems.
		</listitem>
		<listitem>
I would recommend not putting any part of the LVS stuff directly on the dom0 
and seeing if that works. Also, I am a DR die hard, but I think esp. in the 
case of Xen, it seems to work great, fast set up, painless.
		</listitem>
	</itemizedlist>	
	<para>
Graeme
	</para>
	<para>
Simple question: does the realserver (the VM, 192.168.122.10) have a
route direct back to the 10.0.0.0/whatever network?
More specific routes will override the default, so having a direct route
means the traffic will not necessarily traverse the director and will
therefore not be un-NATted on the way back.
Is there some sort of virtual ethernet bridge affecting it with both
network segments on the same "virtual cable"?
	</para>
	<para>
On the realservers, the default route *must* be via the notional
"inside" interface of the director for LVS-NAT to work. If the default
route goes a different way, then the traffic returning to the client is
not un-NATted correctly and may result in a hung connection.
	</para>
	<para>
There is an exception, however: if the clients come from a small, known,
pool of addresses (which may apply in your case) then there must be a
route back from the clients to that network range (or those ranges) via
the director so that un-NATting can happen. Other traffic - such as that
sourced from the realserver for example for OS updates - can go
whichever way you want it to, and in fact I normally make it my practice
to ensure that the traffic emanating from the realservers for this type
of operation doesn't appear to come from the VIP anyway.
	</para>
	<para>
In summary: for NAT to work, traffic back to clients must go via the
director.
	</para>
	<para>
Josh
	</para>
	<blockquote>
Only has def gateway of 192.168.122.1, which knows how to get to 10.0.0.0 .
Tried the direct routeanyway, but did not help.
"route add 10.0.0.0 gw 192.168.122.1"
I can do a dig from the physical server OS to the 192.168.122.10 vm, 
which is going through the bridge.  This works perfect.
	</blockquote>
	<para>
Laurentiu C. Badea (L.C.) <emphasis>lc (at) waat (dot) com</emphasis>
	</para>
	<para>
Xen creates a virtual bridge and adds a few iptables rules to control 
access and do NAT for its clients, while the host domain becomes their 
gateway. So you have the LVS setup sitting on top of a NAT router.
	</para>
	<para>
I would take a look at the iptables setup and check the packet counters 
during a query, especially on reject rules. Then try to insert rules to 
make it work and make sure the ruleset is maintained across reboots (Xen 
dynamically inserts rules when the bridges are brought up).
	</para>
	<para>
David Dyer-Bennet <emphasis>dd-b (at) dd-b (dot) net</emphasis>
	</para>
	<para>
Try iptables-save (not iptables -L) to see *all* the tables (in an incompatible format).
The default route on each of the realserver "systems" (quotes to remind us
that they may be xen guests not physical systems) needs to be set to the
private net virtual IP of the LVS system.
And the LVS NAT works *only* for packets routed in by the LVS; the
realservers can't initiate outgoing connections beyond the private LAN
(unless you turn on ordinary NAT on the LVS, which is not the same thing
as LVS NAT).
	</para>
	<para>
You don't need the "secondary" addresses for the LVS nodes (that's the
terminology from piranha-gui; one of the problems here is that there's
lots of conflicting terminology being used in different tools around all
this stuff).
	</para>
	<para>
The LVS node needs two real (corporate lan, or internet) IPs and two
virtual (private network for the cluster) IPs; one each outside and
inside.  The virtual IPs will be moved between the two LVS nodes on
failover, whereas the real IPs will stay with the hardware they're
assigned to.
	</para>
	<para>
The private virtual IP must be configured in each realserver as the
gateway node.
	</para>
	<para>
My impression is that getting that wrong is both the easiest and most
common way of getting packets to go in but not come out; but that
impression may be specific to redhat/centos setups using piranha-gui,
which you haven't mentioned using (but it's what I'm using, hence it
influences what I know).
	</para>
	<para>
Here's my ipvsadm output:
	</para>
<programlisting><![CDATA[
sh-3.2# /sbin/ipvsadm
IP Virtual Server version 1.2.1 (size=4096)
Prot LocalAddress:Port Scheduler Flags
  -> RemoteAddress:Port           Forward Weight ActiveConn InActConn
TCP  prcvmod01.employer.local     wlc
  -> 172.17.0.4:http              Masq    8      0          0
  -> 172.17.0.3:http              Masq    8      0          0
sh-3.2#
]]></programlisting>
	<para>
172.17. is the private internal lan for the cluster.  .4 and .3 there are
realservers, separate physical systems in my case (they'll have Xen and
multiple virtual servers on them soon).
	</para>
	<para>
prcvmod01.employer.local is the public (corporate lan) virtual IP for the
service (it's 192.168.1.16).  The LVS system itself has its own corporate
lan IP of 192.168.1.14.
	</para>
	<para>
The iptables look like:
	</para>
<programlisting><![CDATA[
sh-3.2# /sbin/iptables-save
# Generated by iptables-save v1.3.5 on Wed Sep 17 14:32:03 2008
*filter
:INPUT ACCEPT [7375193:1143767059]
:FORWARD ACCEPT [396083:75791540]
:OUTPUT ACCEPT [6115668:423106080]
-A INPUT -i virbr0 -p udp -m udp --dport 53 -j ACCEPT
-A INPUT -i virbr0 -p tcp -m tcp --dport 53 -j ACCEPT
-A INPUT -i virbr0 -p udp -m udp --dport 67 -j ACCEPT
-A INPUT -i virbr0 -p tcp -m tcp --dport 67 -j ACCEPT
-A FORWARD -d 192.168.122.0/255.255.255.0 -o virbr0 -m state --state RELATED,ESTABLISHED -j ACCEPT
-A FORWARD -s 192.168.122.0/255.255.255.0 -i virbr0 -j ACCEPT
-A FORWARD -i virbr0 -o virbr0 -j ACCEPT
-A FORWARD -o virbr0 -j REJECT --reject-with icmp-port-unreachable
-A FORWARD -i virbr0 -j REJECT --reject-with icmp-port-unreachable
-A FORWARD -m physdev  --physdev-in vif5.0 -j ACCEPT 
COMMIT
# Completed on Wed Sep 17 14:32:03 2008
# Generated by iptables-save v1.3.5 on Wed Sep 17 14:32:03 2008
*nat
:PREROUTING ACCEPT [1498599:131914689]
:POSTROUTING ACCEPT [398187:28611428]
:OUTPUT ACCEPT [409849:29413401]
-A POSTROUTING -s 192.168.122.0/255.255.255.0 -j MASQUERADE
-A POSTROUTING -o eth0 -j MASQUERADE
COMMIT
# Completed on Wed Sep 17 14:32:03 2008
]]></programlisting>
	<para>
The most obvious difference is just that you're running your virtual
server on the same box, and I'm not.  I started out trying to run it all
on one box, and gave up.  I think I now understand the things I gave up
on, and I think it should work in just one box with my current config --
but I haven't tried it yet.  I'm going to get it working in the simple
case of multiple boxes first, and *then* add in the complexity of some
realservers on the same hardware as the LVS director.
	</para>
	</section>
</section>
<section id="LVS-HOWTO.unsupported">
<title>LVS: Linux Distributions prepatched with LVS, Unsupported LVS addons</title>
	<section id="prepatched_distributions">
	<title>Distributions prepatched with LVS</title>
	<note>
Joe, May 2006: LVS has been in the standard kernels for quite a while now. 
Much of this section is now irrelevant.
	</note>
	<para>
LVS is patched into the kernels in some distributions.
Other distributions have kernels that won't patch with LVS.
It's impossible for us to support any of this. Your best
approach is to talk to the vendor. One solution would be to
have LVS in the standard kernel, and the patches applied by
distros would have to be compatible with LVS. This solution
hasn't been available.
Our approach has been to tell you that you're on your own.
This has solved our problem, but still some people need to
use these distros.
In some work situations,
the suits like using known distributions for security reasons.
However, security should be set by specification
(<emphasis>e.g.</emphasis> must pass a set of tests)
rather than implementation
("we'll accept the Fred distro").
In this way any box can be certified,
without knowing the implementation details.
Changes to the software can be recertified
without restricting the software on the box.
	</para>
	</section>
	<section id="pbs_nutshell" xreflabel="PB's Nutshell">
	<title>PB's Nutshell HOWTO for Piranha/LVS-NAT</title>
	<para>
PB <emphasis>peterbaitz (at) yahoo (dot) com</emphasis> 12 Apr 2002
	</para>
	<blockquote>
	<para>
Here's <ulink url="http://baitz.com/lvs.html">
PB's Piranha/LVS NUTSHELL HOWTO Site</ulink>
	</para>
	</blockquote>
	<note>
		<para>
Joe: &lt;rant&gt; Occasionally someone outside the LVS mailing list,
who has been paid by their employer to write some LVS code,
releases their code without any support,
without consulting us beforehand to see if the code would be useful,
and does not offer to help with our code with similar functionality.
Piranha is one of these.
The only point of this code is to claim turf, rather than to help LVS.
When people try it out and can't get it to work, and can't get any
help from the author/vendor,
they come to the LVS mailing list expecting us to fix their problem.
My response is to boycott the code.
		</para>
		<para>
However other people think differently and are happy to use such code.
If you get code to work with LVS that has been developed by these outside
people, then it's fine with me. You can ask about this code on the LVS mailing
list, but you'll have to realise that the pool of people who know about it
is smaller and that other people on the mailing list
(<emphasis>e.g.</emphasis> me)
have a jaundiced view of the code after dealing with the people who produced it.
		</para>
		<para>
Piranha is a RedHat product.
If you want more information about it,
you should contact RedHat, who has setup a Piranha mailing list.
(There is not much information available there
according to people who've tried it.)
Some people on the LVS mailing list may be able to answer
questions on Piranha, so there is no harm in posting
Piranha questions there.
		</para>
		<para>
The files on the LVS website have all the capabilities of LVS
and are supported on the mailing list.
If you want supported LVS functionality,
you could start with the standard LVS files.
&lt;/rant&gt;
		</para>
	</note>
	</section>
	<section id="installing_on_redhat">
	<title>Horms advice for installing on RedHat systems</title>
	<para>
Ramish Patel:
	</para>
	<blockquote>
I am using Red Hat Linux 7.2, kernel 2.4.7-10, and I have attempted to
apply numerous patches to it for lvs, only two of which have been
successfully applied without errors
	</blockquote>
	<para>
Horms <emphasis>horms (at) verge (dot) net (dot) au</emphasis> 31 Jul 2002
	</para><para>
Firstly I would strongly recommend that you start with
a kernel from kernel.org (such as 2.4.18) rather than
using Red Hat's Kernel unless you know what you
are doing. ipvs-1.0.4 does not work out of the box with
the Kernel shipped with Red Hat 7.2 and vice versa.
	</para><para>
However if you want to do this here is a rough guide.
	</para>
	<itemizedlist>
		<listitem>
You need to apply the linux_kernel_ksyms.c.diff and linux_net_netsyms.c.diff
		</listitem>
		<listitem>
You need to remove the existing version of LVS which is
   present in the 7.2 kernel. You can do this by examining
   the patches that are provided with the kernel src.rpm
   and the spec.file.
		</listitem>
		<listitem>
Compile the kernel - a few minor things may fail. Again this is the "way of pain".
		</listitem>
		<listitem>
Build the kernel modules provided in the ipvs/ subdirectory
   of ipvs-1.0.4.tar.gz. You will need to make modifications
   to the source to get this to work, but they should be minor.
		</listitem>
	</itemizedlist>
	</section>
	<section id="RH_recipe_Kramarov">
	<title>Recipe and LVS binaries for RedHat from Alex Kramarov</title>
	<para>
The recipe was posted
<ulink url="http://www.in-addr.de/pipermail/lvs-users/2002-August/006422.html">
in the mailing list</ulink>.
	</para>
	<para>
Alex has started (Sep 2002) maintaining
<ulink url="http://www.nrh-up2date.org/howto/lvs/">
http://www.nrh-up2date.org/howto/lvs/
RedHat LVS kernel binaries</ulink>
	</para>
	</section>
	<section id="RH_prepatched_LVS_from_the_mailing_list">
	<title>recipes for installing with RedHat from the mailing list</title>
	<para>
This recipe bypasses all the problems of trying to figure out which version of
LVS that RedHat has patched into the kernel. You ignore the RedHat patches
and build a recent LVS as modules.
	</para>

	<para>
Matthew S. Crocker <emphasis>matthew (at) crocker (dot) com</emphasis> 26 Nov 2002
	</para>
	<blockquote>
Redhat 8.0 comes with LVS in the kernel but I think it is version 1.0.4.
I have had good luck by just rebuilding the latest patches and installing
them in the modules directory.  I don't patch the kernel,  I'm hoping the
kernel patch is pretty stable and hasn't changed in a while.
So, just install the RH kernel rpm,  the kernel-source RPM. Then install
ipvs-1.0.7, and make modules_install.
	</blockquote>

	<para>
pb <emphasis>peterbaitz (at) yahoo (dot) com</emphasis> 26 Nov 2002
	</para>

	<blockquote>
I know Red Hat 8.0 with the following RPMs:

<programlisting><![CDATA[
ipvsadm-1.21-4
piranha-0.7.0-3
scsi_reserve-0.7-6
]]></programlisting>

works fine for NAT Routing EXCEPT the Piranha-GUI is
all messed up due to some Apache 2 and/or PHP scripts
thing. Therefore I've stuck with Red Hat 7.3 plus all
errata including latest kernel
kernel-smp-2.4.18-18.7.x
and the above RPM's all work nicely on 7.3.
	</blockquote>

	<para>
Alex Kramarov <emphasis>alex (at) incredimail (dot) com</emphasis> 26 Nov 2002
	</para>

	<blockquote>
kernel-smp-2.4.18-18.7.x also has the same patch applied (1.0.4). and you
shouldn't feel sorry that you have to use 7.3 - 8.0 is far from being a
stable server platform. don't use hearteat (if you cluster your directors)
with that kernel though - only with 2.4.18-10 or earlier.
	</blockquote>

	<para>
pb <emphasis>peterbaitz (at) yahoo (dot) com</emphasis> 26 Nov 2002
	</para>

	<blockquote>
I am using kernel 2.4.18-18.7 in both directors
at the moment and heartbeat has worked fine.  And just
prior to this time, they had kernel 2.4.18-17.7 and
also worked perfectly - failover was always fine.
	</blockquote>
	</section>
	<section id="hidden_rpm">
	<title>Hidden RPMs</title>
	<para>
Gegory Boehnlein <emphasis>damin (at) damin (dot) nacs (dot) net</emphasis>
10 Aug 2003
	</para>
	<para>
	I spent a lot of time making modified RedHat 7.3 RPMS (before I
discovered the UltraMonkey page) to deploy Julian's hidden arp patch. Now
that I know UltraMonkey will be doing this on a regular basis, I'l most
likely just implement their kernel. For those that are interested, the
results of my work can be downloaded from:
	</para>
<programlisting><![CDATA[
ftp://ftp.nacs.net/pub/lvs

kernel-2.4.20-19.7.lvs.i386.rpm
kernel-2.4.20-19.7.lvs.src.rpm
kernel-BOOT-2.4.20-19.7.lvs.i386.rpm
kernel-doc-2.4.20-19.7.lvs.i386.rpm
kernel-source-2.4.20-19.7.lvs.i386.rpm
README.kernel
]]></programlisting>
	<para>
This is a drop in replacement for RedHat 7.3 systems that
implements the following patch for LVS-DR Real Servers.
	</para>
<programlisting><![CDATA[
http://www.ssi.bg/~ja/hidden-2.4.20pre10-1.diff
]]></programlisting>
	<para>
The purpose of this patch is to change the ARP behavior for addresses
attached to specific interface:
	</para>
	<orderedlist>
		<listitem>
don't reply for broadcast probes
		</listitem>
		<listitem>
don't announce the addresses in the ARP probes
		</listitem>
		<listitem>
the addresses are not
selected by the source address autoselection mechanism.
		</listitem>
	</orderedlist>
	</section>
</section>
<section id="LVS-HOWTO.useful">
<title>LVS: Useful things that have no other place</title>
	<section id="ramdisk">
	<title>Ramdisk</title>
	<para>
I needed a ramdisk of more than 4M once and couldn't find the
instructions for setting it up. Here they are
	</para>
	<para>
Jerry Glomph Black <emphasis>black (at) real (dot) com</emphasis>
	</para>
	<para>
You specify the ramdisk size when you load the rd module, as an option.
	</para>
<programlisting><![CDATA[
/sbin/insmod rd rd_size=32768
/sbin/mke2fs -m0 /dev/ram0
mount -t ext2 /dev/ram0 /mnt
]]></programlisting>
	<para>
Vijay Patil <emphasis>vijay (at) euler (dot) ece (dot) iisc (dot) ernet (dot) in</emphasis>
23 May 2000
	</para>
	<para>
add a line to <filename>lilo.conf</filename> like
	</para>
<programlisting><![CDATA[
ramdisk=16384
]]></programlisting>
	<para>
run lilo and reboot
	</para>
	</section>
	<section id="cscope">
	<title>cscope</title>
	<para>
cscope is a code symbol navigating tool.
	</para><para>
from Patrick O'Rourke, <emphasis>orourke (at) missioncriticallinux (dot) com</emphasis>
	</para><para>
A cscope for Linux is at http://sourceforge.net/projects/cscope/
	</para>
	</section>
	<section id="neutral_currents">
	<title>Neutral currents in multiphase power lines with non-linear loads (like computers with switching power supplies)</title>
	<para>
An article from Mirus
on the unbalance in 3-phase power lines caused by non-linear loads
(http://www.mirusinternational.com/pages/q&amp;a_fr.html, link dead Jan 2003).
	</para><para>
From the International Technology Industry Council:
	</para><para>
Three Phase Power Source Overloading Caused by Small Computers and Electronic Office Equipement
(link dead Feb 2003 http://www.itic.org/technical/3phase.html).
	</para><para>
and
	</para>
	<para>
<ulink url="http://www.itic.org/technical/ite_grnd.pdf">
Guidelines for Grounding Information Technology Equipement</ulink>
	</para>
	</section>

	<section id="phatcat" xreflabel="phatcat"><title>netcat/phatcat</title>

	<para>
	<command>netcat</command> is a universal low level client.
You can use it to inspect responses from servers.
(Formerly it was at http://l0pht.com/&#126;weld/netcat/nc110.tgz,
but this url no longer on the net and the original author has disappeared.
This URL refers through to a URL "atstake.com", which has the NT
binary of netcat, but not the unix source.)
It's available (again May 2003) at
(http://www.atstake.com/research/tools/network_utilities/, nope link dead Feb 2005).
Because of the disappearance, Ratz started maintaining his own version
<ulink url="http://www.drugphish.ch/projects/network/phatcat/">phatcat</ulink>.
	</para>
	<para>
	<note>
if you're using <command>phatcat</command> as a telnet client, remember to use the "-t" option.
	</note>
	</para>
	</section>
</section>
<section id="LVS-HOWTO.FAQ">
	<title>LVS: FAQ</title>
	<section><title>When will LVS be ported to Solaris, xxxBSD...?</title><para>
LVS is all kernel code. It's hard enough to write for one kernel.
No-one is contemplating porting LVS to any other OS's.
			</para><para>
There is a <link linkend="other_solutions">FreeBSD loadbalancer project (HUT)"</link>.
	</para></section>
	<section>
	<title>Is there a HOWTO in Japanese, French, Italian, Mandarin...?</title>
	<para>
There is the
<ulink url="http://www.austintek.com/LVS/LVS-HOWTO/mini-HOWTO/LVS-mini-HOWTO-pt.html">
LVS-mini-HOWTO in Portuguese</ulink> translated by Carlos Cherem.
	</para>
	<para>
One person offered to translate the HOWTO into Italian a long time
ago and I haven't heard from him since. Another person recently
(May 2001) offered to translate it into Japanese. From the number
of Japanese HOWTO's I find in google searches, I'd say there is a good
chance of having a Japanese HOWTO sometime.
	</para>
	</section>
</section>
<programlisting><![CDATA[
]]></programlisting>
</article>
